# rag/cli_chat.py
import yaml
import jieba

from rag.pipeline import run_rag_stream
from rag.retrieval import DualIndexHybridRetriever
from llm.base import build_llm


def load_llm_cfg():
    cfg = yaml.safe_load(open("configs/rag.yaml", "r", encoding="utf-8"))
    return cfg["llm"]


def main():
    print("ğŸ§  RAG Assistantï¼ˆè¾“å…¥ exit é€€å‡ºï¼‰")

    # ---------- 0) åˆå§‹åŒ– ----------
    jieba.initialize()

    # ---------- 1) LLM ----------
    llm_cfg = load_llm_cfg()
    llm = build_llm(llm_cfg)

    # ---------- 2) Retrieverï¼ˆåªåˆå§‹åŒ–ä¸€æ¬¡ï¼Œéå¸¸é‡è¦ï¼‰ ----------
    retriever = DualIndexHybridRetriever(index_root="data/index")

    # ---------- 3) REPL ----------
    while True:
        query = input("\nğŸ‘¤ ä½ ï¼š").strip()
        if not query:
            continue
        if query.lower() in {"exit", "quit"}:
            print("ğŸ‘‹ å†è§")
            break

        # ---------- 4) æµå¼è¾“å‡º ----------
        print("ğŸ¤– åŠ©æ‰‹ï¼š", end="", flush=True)
        for delta in run_rag_stream(query, llm, retriever):
            print(delta, end="", flush=True)

        # ---------- 5) æµå¼ç»“æŸåï¼šç»“æ„åŒ–è¯æ® ----------
        result = getattr(run_rag_stream, "last_result", None)
        if not result:
            continue

        print("\n\nğŸ“Œ citations:")
        for c in result["citations"]:
            print(f"  - {c}")

        print("\nğŸ“„ top_chunks:")
        for i, c in enumerate(result["top_chunks"], 1):
            print(
                f"  {i}) {c['chunk_id']} | page={c['page']} | score={c['rerank_score']:.4f}"
            )


if __name__ == "__main__":
    main()
