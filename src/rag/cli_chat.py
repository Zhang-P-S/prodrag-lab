# rag/cli_chat.py
import os
import warnings
import contextlib
import yaml

# âœ… è¿™äº›è¦æ”¾åœ¨å°½é‡é å‰çš„ä½ç½®ï¼ˆåœ¨ import jieba/transformers ç­‰ä¹‹å‰æ›´å¥½ï¼‰
# 1) é™éŸ³ Python warningsï¼ˆä¾‹å¦‚ pkg_resources deprecatedï¼‰
warnings.filterwarnings("ignore")

# 2) é™éŸ³ transformers æ—¥å¿—ï¼ˆloading / deprecatedï¼‰
os.environ.setdefault("TRANSFORMERS_VERBOSITY", "error")
os.environ.setdefault("TOKENIZERS_PARALLELISM", "false")

# 3) å°½é‡å…³æ‰ tqdm è¿›åº¦æ¡ï¼ˆå¾ˆå¤š from_pretrained ä¼šç”¨åˆ°ï¼‰
os.environ.setdefault("TQDM_DISABLE", "1")

import jieba  # æ”¾åˆ°ç¯å¢ƒå˜é‡è®¾ç½®åå† import

from rag.pipeline import run_rag_stream
from rag.retrieval import DualIndexHybridRetriever
from llm.base import build_llm


@contextlib.contextmanager
def suppress_stdout_stderr():
    """
    åªåœ¨æ¨¡å‹/ç´¢å¼•åŠ è½½é˜¶æ®µç”¨ï¼šåæ‰ç¬¬ä¸‰æ–¹åº“çš„ print å’Œ warning è¾“å‡ºï¼Œé¿å…åˆ·å±ã€‚
    æ³¨æ„ï¼šå¼‚å¸¸ä»ä¼šæŠ›å‡ºï¼Œåªæ˜¯ä¸æ‰“å°ä¸­é—´å™ªéŸ³ã€‚
    """
    with open(os.devnull, "w") as fnull:
        with contextlib.redirect_stdout(fnull), contextlib.redirect_stderr(fnull):
            yield


def load_llm_cfg(cfg_path: str):
    cfg = yaml.safe_load(open(cfg_path, "r", encoding="utf-8"))
    return cfg["llm"]


def main():
    print("ğŸ§  RAG Assistantï¼ˆè¾“å…¥ exit é€€å‡ºï¼‰")

    # ---------- 0) åˆå§‹åŒ–ï¼ˆé™éŸ³ï¼‰ ----------
    with suppress_stdout_stderr():
        jieba.initialize()

    # ---------- 1) LLMï¼ˆé™éŸ³åŠ è½½ï¼‰ ----------
    llm_cfg = load_llm_cfg("configs/rag.yaml")
    with suppress_stdout_stderr():
        llm = build_llm(llm_cfg)

    # ---------- 2) Retrieverï¼ˆé™éŸ³åŠ è½½ï¼‰ ----------
    with suppress_stdout_stderr():
        retriever = DualIndexHybridRetriever(index_root="data/index")

    # ---------- 3) REPL ----------
    while True:
        query = input("\nğŸ‘¤ ä½ ï¼š").strip()
        if not query:
            continue
        if query.lower() in {"exit", "quit"}:
            print("ğŸ‘‹ å†è§")
            break

        # ---------- 4) æµå¼è¾“å‡º ----------
        print("ğŸ¤– åŠ©æ‰‹ï¼š", end="", flush=True)
        for delta in run_rag_stream(query, llm, retriever):
            print(delta, end="", flush=True)

        # ---------- 5) æµå¼ç»“æŸåï¼šç»“æ„åŒ–è¯æ® ----------
        result = getattr(run_rag_stream, "last_result", None)
        if not result:
            continue

        print("\n\nğŸ“Œ citations:")
        for c in result["citations"]:
            print(f"  - {c}")

        print("\nğŸ“„ top_chunks:")
        for i, c in enumerate(result["top_chunks"], 1):
            print(f"  {i}) {c['chunk_id']} | page={c['page']} | score={c['rerank_score']:.4f}")


if __name__ == "__main__":
    main()
