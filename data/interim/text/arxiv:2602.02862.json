{"doc_id": "arxiv:2602.02862", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2602.02862.pdf", "meta": {"doc_id": "arxiv:2602.02862", "source": "arxiv", "arxiv_id": "2602.02862", "title": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search", "authors": ["Eric Yang", "Jong Ha Lee", "Jonathan Amar", "Elissa Ye", "Yugang Jia"], "published": "2026-02-02T22:10:32Z", "updated": "2026-02-02T22:10:32Z", "summary": "Large Language Models (LLMs) trained for average correctness often exhibit mode collapse, producing narrow decision behaviors on tasks where multiple responses may be reasonable. This limitation is particularly problematic in ordinal decision settings such as clinical triage, where standard alignment removes the ability to trade off specificity and sensitivity (the ROC operating point) based on contextual constraints. We propose STEER (Steerable Tuning via Evolutionary Ensemble Refinement), a training-free framework that reintroduces this tunable control. STEER constructs a population of natural-language personas through an offline, constrained quality-diversity search that promotes behavioral coverage while enforcing minimum safety, reasoning, and stability thresholds. At inference time, STEER exposes a single, interpretable control parameter that maps a user-specified risk percentile to a selected persona, yielding a monotonic adjustment of decision conservativeness. On two clinical triage benchmarks, STEER achieves broader behavioral coverage compared to temperature-based sampling and static persona ensembles. Compared to a representative post-training method, STEER maintains substantially higher accuracy on unambiguous urgent cases while providing comparable control over ambiguous decisions. These results demonstrate STEER as a safety-preserving paradigm for risk control, capable of steering behavior without compromising domain competence.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2602.02862v1", "url_pdf": "https://arxiv.org/pdf/2602.02862.pdf", "meta_path": "data/raw/arxiv/meta/2602.02862.json", "sha256": "572a9ca9d92cb39bffe9d67cd74e7bc13b85e7c0754007e58d5c756062dd926a", "status": "ok", "fetched_at": "2026-02-18T02:19:59.177699+00:00"}, "pages": [{"page": 1, "text": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search\nEric Yang 1 Jong Ha Lee 1 Jonathan Amar 1 Elissa Ye 1 Yugang Jia 1\nAbstract\nLarge Language Models (LLMs) trained for av-\nerage correctness often exhibit mode collapse,\nproducing narrow decision behaviors on tasks\nwhere multiple responses may be reasonable. This\nlimitation is particularly problematic in ordinal\ndecision settings such as clinical triage, where\nstandard alignment removes the ability to trade\noff specificity and sensitivity (the ROC operating\npoint) based on contextual constraints. We pro-\npose STEER (Steerable Tuning via Evolutionary\nEnsemble Refinement), a training-free framework\nthat reintroduces this tunable control. STEER con-\nstructs a population of natural-language personas\nthrough an offline, constrained quality–diversity\nsearch that promotes behavioral coverage while\nenforcing minimum safety, reasoning, and stabil-\nity thresholds. At inference time, STEER exposes\na single, interpretable control parameter that maps\na user-specified risk percentile to a selected per-\nsona, yielding a monotonic adjustment of decision\nconservativeness. On two clinical triage bench-\nmarks, STEER achieves broader behavioral cover-\nage compared to temperature-based sampling and\nstatic persona ensembles. Compared to a repre-\nsentative post-training method, STEER maintains\nsubstantially higher accuracy on unambiguous ur-\ngent cases while providing comparable control\nover ambiguous decisions. These results demon-\nstrate STEER as a safety-preserving paradigm for\nrisk control, capable of steering behavior without\ncompromising domain competence.\n1. Introduction\nLarge Language Models (LLMs) are rapidly being deployed\nas decision-support tools in high-stakes domains such as\nclinical triage, financial planning, and legal judgments\n(Tyler et al., 2024; Lee et al., 2025; Rashidian et al., 2025;\nVukovi´c et al., 2025; Kolkman et al., 2024). In these set-\n1Verily Life Sciences, Dallas, TX, USA. Correspondence to:\nEric Yang <eryang@verily.com>.\nPreprint. February 4, 2026.\ntings, models are decision partners that must align with the\nuser-specific operational constraints. However, a critical\nlimitation that prevents their safe, widespread deployment\nis their inability to consistently steer model behavior along\na risk spectrum. In traditional machine learning, optimality\nis managed by selecting an operating point on the Receiver\nOperating Characteristic (ROC) curve, allowing operators to\nexplicitly trade off specificity and sensitivity based on con-\ntextual needs (Stanfield, 2015). For instance, a resource-rich\nhospital may prioritize minimizing undertriage, whereas a\ncapacity-strained facility requires stricter criteria (Justice\net al., 2025). Consequently, the utility of an AI decision\nsupport system depends not only on its accuracy but on its\ntunable risk tolerance, which is the ability to reliably adjust\nits operating point along a continuum of valid judgments.\nCurrent paradigms for aligning LLMs, such as Reinforce-\nment Learning from Human Feedback (RLHF), are funda-\nmentally at odds with this requirement. By training models\nto maximize average correctness, these techniques inadver-\ntently induce mode collapse in ambiguous scenarios (Meng\net al., 2024; Kirk et al., 2023; Hamilton, 2024). The opti-\nmization process sharpens the predictive distribution around\na single response, effectively collapsing the rich spectrum of\nplausible expert interpretations into a low-entropy point es-\ntimate. This locks models into a static, one-size-fits-all risk\nposture that fails to represent the tail opinions crucial for\nsafety-critical deliberation. Furthermore, standard prompt-\ning offers no deterministic mechanism to navigate latent\ndiversity. While automated prompt optimization can dis-\ncover a static configuration, it fails to provide the continuous\ncontrol required for runtime adjustment.\nIn this work, we introduce Steerable Tuning via Evolu-\ntionary Ensemble Refinement (STEER), a framework that\nunlocks the ability to select a precise operating point with-\nout retraining (Figure 1). We formulate steerability as a\ndistributional search problem. Unlike standard sampling\nmethods that uncontrollably maximize entropy which of-\nten leads to hallucinations, STEER employs a constrained\nquality-diversity search. This evolutionary process explic-\nitly optimizes for behavioral coverage (filling gaps in the\nrisk spectrum) while strictly enforcing minimum thresholds\nfor safety, reasoning-coherence, and variance regularization.\nAt inference time, we introduce a mechanism that maps the\nensemble’s ordinal outputs to a single scalar parameter, ef-\n1\narXiv:2602.02862v1  [cs.AI]  2 Feb 2026\n"}, {"page": 2, "text": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search\nFigure 1. STEER Reintroduces the Risk Operating Point. (A) Problem: Standard models exhibit mode collapse, shrinking the\ndistribution of valid disagreement (gray curve). They are also unsteerable, reacting erratically to prompts (blue arrows). (B) The STEER\nFramework: STEER enhances this distribution via a constrained quality-diversity evolutionary search. This creates a deterministic\nconservativeness dial (P). (C) Context-Aware Control: The system generates a steerable ordinal performance curve (analogous to an\nROC), enabling users to select a precise operating point (P) that satisfies specific sensitivity/specificity requirements.\nfectively enabling the risk dial for operational control. Our\nmain contributions are summarized as follows:\n• Quality-Diversity for Output Space Coverage: We\nintroduce a constrained evolutionary search that sys-\ntematically builds an ensemble to fill voids in the\nmodel’s estimated risk distribution.\n• Deterministic Inference Control: We propose Infer-\nence with Percentile Tuning, a mechanism that pro-\nvides a monotonic conservativeness dial. This allows\nusers to granularly manage the trade-off between over-\ntriage and undertriage (the ROC operating point) with-\nout retraining.\n• Empirical Safety Preservation on Unambiguous\nCases: We demonstrate on two clinical benchmarks\nthat STEER achieves broader behavioral coverage com-\npared to temperature-based sampling and static persona\nensembles. Compared to a representative post-training\nmethod, STEER maintains substantially higher accu-\nracy on unambiguous urgent cases while providing\ncomparable control over ambiguous decisions.\n2. Related Works\nWhile the problem of mode collapse has spurred research\nacross training, inference, and optimization, existing solu-\ntions largely treat diversity as a static objective rather than a\ndynamic, steerable operational parameter. We depart from\nthese paradigms by reframing the goal: we do not solely\nseek to restore the distribution, but to instrument it for con-\nsistent human control.\nTraining-Time Distributional Alignment. Attempts to\nmitigate mode collapse most often intervene during post-\ntraining. Spectrum Tuning tunes base models on curated dis-\ntributional tasks to better approximate valid output spaces\n(Sorensen et al., 2025). Similarly, methods like DivPO\nand DARLING explicitly modify the RLHF objective, inte-\ngrating diversity rewards to penalize semantic redundancy\n(Lanchantin et al., 2025; Li et al., 2025). However, these\nsolutions face limitations. First, their requirement to modify\nmodel parameters limit them to open-weight models. This\nrenders them inapplicable to the many powerful proprietary\nsystems that are most frequently deployed in high-stake\nsettings. Second, they produce static artifacts with rigid\nlearned distributions. Adapting to a shifting risk profile\n(e.g., pandemic vs. normal operations) requires expensive\nretraining rather than simple inference-time reconfiguration.\nThird, global distributional updates can inadvertently de-\ngrade performance on unambiguous inputs, exhibiting a\nform of catastrophic forgetting where the model unlearns\nfundamental knowledge in its pursuit of diversity. Finally,\ntraining-time methods require the curation of massive multi-\n2\n"}, {"page": 3, "text": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search\ntask datasets (e.g., the 40-source SPECTRUM SUITE) and\nsignificant compute for parameter updates. STEER cir-\ncumvents these limitations entirely. As a model-agnostic\nframework, it applies to any SOTA model and offers supe-\nrior flexibility, allowing users to define and swap objective\nfunctions without modifying model weights.\nInference-Time Elicitation and Control. To avoid the\ncosts of retraining, recent work has explored prompting\nstrategies to elicit latent diversity. Verbalized Sampling\n(VS) instructs models to articulate probabilities over a list\nof potential answers (Zhang et al., 2025). However, VS\nmaximizes diversity blindly, expanding the output space\nwithout guaranteeing that the generated options cover the\nspecific risk gaps relevant to safety-critical decision-making.\nCrucially, it lacks a mechanism for actionable selection. It\npresents ranges of options but provides no policy to navigate\nthem. STEER advances beyond this by coupling elicited\ndiversity with Inference with Percentile Tuning, transform-\ning the chaotic distribution into an ordered risk spectrum.\nSTEER distinguishes from SteerConf, which employs se-\nmantic steering (e.g., ”be very cautious”) but for a funda-\nmentally different objective of confidence calibration (Zhou\net al., 2025). SteerConf utilizes the ensemble to triangulate\nthe single most reliable answer and assign it a calibrated\nprobability score, effectively treating ensemble variance as\nuncertainty to be resolved. In contrast, STEER treats this\nvariance as a valid policy landscape to be navigated. Rather\nthan collapsing the ensemble to a single truth based on inter-\nnal certainty, STEER maps the ensemble’s outputs to ordinal\nlevels of care. This allows the user to select a decision based\non external risk tolerance via our conservativeness dial, a\ncapability that current methods do not support.\nEvolutionary Optimization and Multi-Agent Systems.\nThe fundamental distinction between STEER and existing\npersona-based frameworks lies in the optimization objective.\nMulti-agent debate (Du et al., 2023; Liang et al., 2023; Suz-\ngun & Kalai, 2024) and prompt evolution (Agrawal et al.,\n2025; Fernando et al., 2023; Guo et al., 2023; Yang et al.,\n2023) methods incentivize consensus or optimize for a sin-\ngle best prompt or answer. This effectively fixes the model\nto a static operating point, failing to provide the continu-\nous control required for dynamic environments. STEER\nreverses this paradigm by adopting a quality-diversity per-\nspective (maximizing valid coverage) (Qian et al., 2024).\nRather than converging on one optimal agent, STEER uti-\nlizes operators to evolve a population that explicitly max-\nimizes diversity. This ensures the ensemble spans the full\nordinal risk spectrum, transforming the goal from maximiz-\ning accuracy to maximizing valid operational range.\n3. Problem Formulation\nWhile validated in clinical triage, our framework applies to\nany ordinal decision process (e.g., credit risk, legal evalua-\ntion). We formalize the challenge not as classification, but\nas a constrained search for behavioral diversity.\n3.1. Latent Context and Acceptable Disagreement\nLet x denote an input case and y ∈Y an ordinal deci-\nsion (e.g., triage level 1–5 representing urgency level of\ncare). For ambiguous inputs, there exists a latent distribu-\ntion P(y|x) over acceptable decisions induced by expert\ndisagreement and contextual uncertainty. While this dis-\ntribution is not directly observable, its existence motivates\nmethods that preserve decision diversity rather than col-\nlapsing to a single mode. Standard alignment techniques\noptimize toward a singular reference, effectively treating\nthis valid disagreement as noise. We define mode collapse\nas the loss of this latent variance, rendering models inca-\npable of representing professional disagreement or adapting\nto shifting risk thresholds.\n3.2. Defining Behavioral Diversity\nWe formally define the diversity we seek to recover. Let the\npersona pool be P. Each rater persona j ∈P produces an\nordinal decision RC(i, j) ∈{1, . . . , K} for case i, where\nK indexes the discrete ordinal decision categories. For each\ncase i, we define the empirical distribution over ordinal\ndecisions induced by the persona pool as:\npi(k) =\n1\n|P|\nX\nj∈P\nI[RC(i, j) = k],\nk = 1, . . . , K\n(1)\nwhere I is the indicator function. We quantify behavioral\ndiversity using the normalized per-case decision entropy:\n˜H(pi) = −\n1\nlog K\nK\nX\nk=1\npi(k) log pi(k)\n(2)\nLet A denote the subset of ambiguous cases. We define the\nglobal diversity objective D(P) as the mean entropy across\nthese ambiguous inputs:\nD(P) =\n1\n|A|\nX\ni∈A\n˜H(pi)\n(3)\nD(P) is high when, on ambiguous cases, the personas dis-\ntribute decisions across multiple valid ordinal levels, and\nlow when the population collapses to a single response. We\nemphasize that D(P) is defined purely in terms of observed\nmodel outputs and does not encode safety, validity, or cor-\nrectness.\n3\n"}, {"page": 4, "text": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search\n3.3. Constrained Quality-Diversity Search\nWe frame the problem as a quality-diversity search. We seek\nto find a population P that maximizes the diversity objec-\ntive D(P) subject to strict feasibility constraints on every\nindividual persona j. Let S(j), C(j), and V (j) denote the\nsafety, coherence, and variance scores for a persona (defined\nformally in Section 3.5).\nWe define the set of feasible personas Φ as those meeting\nminimum thresholds τ:\nΦ = {j | S(j) ≥τsafe∧C(j) ≥τcoh∧V (j) ≤τvar} (4)\nOur objective is to discover a population P ⊆Φ that max-\nimizes Eq. 3. This formulation ensures that we maximize\nbehavioral coverage strictly within the bounds of safety,\nreasoning validity, and signal stability. Note that to main-\ntain population health during evolution, these thresholds τ\nare implemented as adaptive percentiles rather than fixed\nabsolute values (Appendix B.4).\n3.4. Persona Bias Model\nTo systematically navigate the search space to maximize\nD(P), we require a low-dimensional embedding of each\npersona’s behavior. We utilize a Maximum Likelihood Es-\ntimation (MLE) formulation, treating the discrete ordinal\nlabels y ∈{1, . . . , K} as integer scores to enable continu-\nous parameter estimation. We model the observed urgency\nRC(i, j) for case i by persona j as:\nRC(i, j) = Θi + uj + ϵij\n(5)\nwhere Θi represents the latent case-specific difficulty and\nuj is the scalar bias parameter for the persona. The term ϵij\ncaptures the residual variance (s2\nj), representing the degree\nto which a persona’s behavior deviates from a consistent\nlinear bias trend. Here, uj serves as the behavioral de-\nscriptor for persona j. While entropy (Eq. 3) is the global\nobjective, uj is the coordinate used by the evolutionary\nalgorithm to identify gaps and target specific regions of\nthe risk spectrum. We acknowledge that modeling ordinal\ndata as continuous variables is a deliberate simplification.\nHowever, our goal is not to fully model expert cognition\nor calibrate density estimation, but to construct an ordered\nensemble that spans a monotonic axis of conservativeness.\nTreating labels as integers provides a robust proxy for this\nranking purpose. To ensure model identifiability (resolv-\ning the shift-invariance between Θ and u), we enforce a\ncentering constraint P\ni Θi = 0 during optimization.\n3.5. Regularization Constraints\nTo prevent the system from achieving maximal entropy via\nrandom noise (hallucinations) or stochastic instability, we\ndefine the constraint functions from Eq. 4. While these con-\nstraints can be customized to domain-specific needs (e.g.,\nadding fairness or tone constraints), for our clinical applica-\ntion we define:\n• Safety Constraint S(j): Ensures ground-truth align-\nment on unambiguous inputs. The ensemble must\nmaintain high accuracy (≥τsafe) on cases where con-\nsensus exists, preventing the model from losing funda-\nmental domain knowledge in blind pursuit of diversity.\n• Coherence Constraint C(j): Ensures reasoning valid-\nity. Generated rationales must rely on present evidence\nrather than hallucinated antecedents, enforcing a mini-\nmum standard of logical soundness.\n• Variance Constraint V (j): Ensures signal stability.\nWe minimize intra-persona inconsistency, estimated\nvia the residual variance (s2\nj) of the persona’s outputs\nrelative to the linear bias model. This penalizes per-\nsonas that behave erratically (noisy residuals) rather\nthan following a consistent risk posture.\n3.6. Control Mechanism: The Ordinal Performance\nCurve\nFinally, we define the steerability of the system via the\nordinal performance curve. This metric plots overtriage vs\nundertriage rates as the selection parameter P sweeps from\n0 to 100. While a static model represents a single fixed\npoint on this 2D plane, our framework aims to generate\nthe frontier, enabling operators to dynamically select an\noperating point that satisfies desired tolerances.\n4. Method: The STEER Framework\nSTEER comprises an offline evolutionary search for a per-\nsona ensemble and an online inference mechanism (Figure\n2). The offline evolution enables low-latency inference.\n4.1. Phase 1: Persona Evolution via Constrained\nQuality-Diversity Search\nWe construct the persona ensemble using an iterative evolu-\ntion procedure that progresses through evaluation, selection,\nand generation. This loop continues until a compute budget\nor a convergence metric (e.g. coverage plateau) is met. We\nexplicitly frame this as a heuristic search designed to trade\nformal optimality guarantees for practical applicability to\nblack-box models.\n4.1.1. INITIALIZATION\nThe process begins with an initial seed persona pool. This\nstep offers a key opportunity to inject domain knowledge,\nwhere users may seed the pool with known expert archetypes\n(e.g., “risk-averse clinician“, “efficiency-focused triage\n4\n"}, {"page": 5, "text": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search\nFigure 2. The STEER Framework. (A) Evolution: We iteratively optimize a persona population to maximize bias diversity subject to\nconstraints. (B) Assembly: The evolved pool is distilled into a compact team to ensure uniform spectral coverage. (C) Inference: At\ndeployment, the team acts as a distributional generator. The Inference with Percentile Tuning mechanism acts as a conservativeness dial.\nnurse“) or start with a smaller, generic set to rely more\nheavily on the algorithm’s discovery capabilities.\n4.1.2. EVALUATION\nIn each generation, every active persona is evaluated on am-\nbiguous cases and unambiguous cases to compute three de-\nscriptors. First, we aggregate the ordinal outputs (RC) and\napply the Maximum Likelihood Estimation (MLE) model\n(Eq. 5). We fit the parameters Θ and u by minimizing the\nmean squared error loss L = P\ni,j(RC(i,j)\nobs −(Θi + uj))2\nvia PyTorch and the Adam optimizer (Kingma & Ba, 2014),\nsubject to the identifiability constraint P Θi = 0. The vari-\nance parameter s2\nj is subsequently calculated as the mean\nsquared residual of persona j’s predictions, serving as a\nproxy for behavioral inconsistency. Second, we compute\na reasoning coherence score to penalize hallucinations or\nlogical disconnects. While we implement this via an LLM-\nas-judge for scalability in our experiments, we emphasize\nthat this is a modular slot for any domain-appropriate reward\nsignal (e.g., rule-based logic checks or human feedback) and\nis not intrinsic to the optimization algorithm itself. Third,\nwe calculate a safety score by measuring strict accuracy\nspecifically on the subset of unambiguous cases.\n4.1.3. SELECTION\nWe apply feasibility constraints (Sec 3.3) sequentially. The\nsafety constraint (S(j) ≥τsafe) discards personas failing a\nstrict accuracy threshold on unambiguous cases, ensuring\nthe ensemble maintains domain competence. The coherence\nconstraint (C(j) ≥τcoh) prunes the bottom tier of the pop-\nulation based on LLM-judge reasoning scores. Finally, the\nvariance constraint (V (j) ≤τvar) removes high-variance\npersonas within bias-clustered groups (see Appendix B.5)\nto distinguish systematic bias from random noise.\n4.1.4. GENERATION\nTo discover new behaviors, we employ two operators: (1)\nGap Filling, where the meta-LLM generates a persona be-\ntween two neighbors to bridge discontinuities in the sorted\nbias list; and (2) Edge Expansion, where it generates valid\npersonas more conservative or aggressive than the current\npopulation extremes to extend the dynamic range.\n4.2. Phase 2: Final Team Assembly\nOnce the evolution loop terminates, we distill the large opti-\nmized pool into a compact champion team for deployment.\nThis step is motivated by practical efficiency. While a mas-\nsive ensemble maximizes theoretical coverage, the marginal\ngain in diversity diminishes rapidly with team size, whereas\nthe computational cost of inference scales linearly. To ap-\nproximate the full spectrum’s coverage using N personas\n(corresponding to a budget of N inferences per case), we\nemploy a coverage-based selection algorithm. The assembly\nbegins by anchoring the team with the most conservative\n5\n"}, {"page": 6, "text": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search\nand aggressive personas from the pool to preserve the full\noperational dynamic range. We then partition the remaining\nbias spectrum between these extremes into equal-width in-\ntervals corresponding to the remaining team slots. Within\neach bucket, we select a single representative persona by\nprioritizing candidates first by their safety and coherence\nscores, and then by minimizing variance. In the event of\na sparse region where a bucket is empty, the algorithm se-\nlects the highest-quality available persona nearest to that\nbucket’s center. Alternatively, one can use specialized set\ncover algorithms, which we leave as future work.\n4.3. Inference with Percentile Tuning\nDuring deployment, the final team functions as a distribu-\ntional generator, where N personas produce distinct predic-\ntions for a given case. Because the evolutionary search is\noffline and these inference queries are fully parallelizable,\nSTEER maintains latency comparable to a single model call.\nTo translate this distribution into a single actionable deci-\nsion, we apply Inference with Percentile Tuning. This de-\nterministic mechanism first sorts the N outputs by urgency\nmagnitude (e.g., from ”Self-care” to ”Emergency”). A user-\nspecified parameter P ∈[0, 100] (the conservativeness dial)\nis then mapped to a rank index k = ⌊P\n100 ×(N −1)⌋, and the\nsystem outputs the decision at rank k. Because the outputs\nare sorted, this function guarantees monotonicity, where\nincreasing P strictly results in an output that is either equal\nto or more conservative than the previous state.\n5. Experimental Setup\nWe evaluate STEER on two real-world clinical decision-\nmaking tasks: a public benchmark for reproducibility and a\nprivate EHR dataset to test generalizability.\n5.1. Datasets\nMIETIC (MIMIC-IV-Ext Triage Instruction Corpus).\n(Shen & Guo, 2025) To evaluate performance in emergency\ndepartment triage, we utilize MIETIC, a structured dataset\nof 9,629 expert-validated triage cases derived from MIMIC-\nIV (Johnson et al., 2024). Each case includes chief com-\nplaints, vital signs, demographics, and medical history, la-\nbeled with the Emergency Severity Index (ESI) from 1 (most\nurgent) to 5 (least urgent). We use ESI-3 (Moderate Risk)\nas the ambiguous set for evolution (N = 1028) and ESI-\n1/5 as the unambiguous safety set (N = 2218) to enforce\nconstraints.\nReal-World EHR Symptom Triage. To assess generaliza-\ntion, we utilize a de-identified, proprietary dataset curated\nfrom real-world Electronic Health Records (EHR) contain-\ning 560 patient cases. This dataset focuses on symptom\nurgency assessment in a telehealth context. Each case ag-\ngregates a comprehensive patient context, consisting of: (1)\na patient summary and last encounter notes; (2) retrieved\nEHR structured data (medications, recent labs, conditions);\nand (3) a multi-turn conversation between a patient simu-\nlator and an AI physician agent established in prior work.\nThe output space consists of a 5-point ordinal urgency scale\nranging from emergency/urgent care (Level 1) to self-care\n(Level 5). Ground truth was established by three senior\nhuman physicians. Cases with unanimous consensus on the\nextremes (Level 1 or 5) constitute the unambiguous split\n(N=109). All other cases, characterized by inter-annotator\ndisagreement or intermediate urgency, constitute the am-\nbiguous split (451). We partition each dataset into 70/15/15\ntraining, validation, and testing splits (see Appendix A).\n5.2. Models and Baselines\nWe conduct two sets of experiments to isolate the impact of\ninference-time steering versus post-training alignment.\nExperiment I: Evolutionary Discovery with Closed-\nSource Models. The evaluation demonstrates how STEER\nunlocks distributional capabilities in SOTA proprietary mod-\nels where weight access is impossible. We use GPT-5-mini\nas the base model (Singh et al., 2025). To ensure a fair\ncomparison, we hold the compute budget constant and use\nidentical system prompts across all methods, varying only\nthe injected persona instructions (Appendix B).\nFirst, we evaluate a high-temperature sampling baseline,\nwhere the base model is queried 10 times per case with tem-\nperature T = 1.0 to elicit stochastic diversity. Second, we\nevaluate a static persona baseline, consisting of 10 distinct\npersonas randomly sampled from the same expert seed pool\nused to initialize evolution (Appendix B.2). This compari-\nson isolates the specific value of evolutionary optimization\nover human-curated heuristics. For our proposed method,\nwe first evolve a large pool of 75 personas using the STEER\nalgorithm. To analyze the efficiency-diversity trade-off, we\nthen distill this pool into champion teams of varying sizes\n(N ∈{5, 10, 20, 30}). Finally, we apply the Inference with\nPercentile Tuning mechanism across the outputs of all three\nmethods (high-temp, static, and STEER) to generate and\ncompare their respective performances.\nExperiment II: Inference vs. Post-Training. To compare\nour inference-time framework against a representative post-\ntraining intervention, we utilize the open-source Gemma\nfamily of models (Gemma Team et al., 2024). In this exper-\niment, we apply STEER (20 evolved personas + Percentile\nTuning) to the standard instruction-tuned Gemma-3-12B-IT\nmodel. We benchmark this against the pre-trained Spectrum-\nTuned version of the same base model (Sorensen et al.,\n2025). Both models utilize the same base prompt structure\n(Appendix B). We utilize the general-purpose checkpoint\nfine-tuned on distributional tasks to assess off-the-shelf steer-\n6\n"}, {"page": 7, "text": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search\nability. We generate 20 outputs per case using standard tem-\nperature sampling (T = 1.0) to elicit the model’s learned\ndiversity. To isolate the impact of the distributional source\n(inference-time personas vs. post-training weights), we ap-\nply Percentile Tuning to the outputs of both models. This\nensures strictly comparable steerability mechanisms.\n5.3. Evaluation Metrics\nBecause ambiguous cases (Level 3) lack a singular ground\ntruth, we define performance relative to the midpoint. Over-\ntriage is defined as estimating higher urgency (ˆy < 3), while\nundertriage is estimating lower urgency (ˆy > 3). The or-\ndinal performance curve plots the trade-off between the\novertriage rate and the safe rate (1 −undertriage rate), gen-\nerated by sweeping the control parameter P ∈[0, 100]. We\nquantify the valid operating region via the ordinal AUC,\ncalculated using right-step integration P(xi+1 −xi)yi.\n6. Results\nWe demonstrate that STEER: (1) significantly enhances\noperational range vs. baselines; (2) provides deterministic\ncontrol over the ROC point; and (3) prevents the catastrophic\nforgetting seen in post-training. Error bars in all figures\nrepresent 95% bootstrap confidence intervals calculated via\nresampling test cases (n = 2000 iterations).\n6.1. Steerability in Closed-Source Models\nFigure 3 illustrates that STEER consistently outperforms\nboth baselines in Ordinal AUC, enhancing output space\ncoverage. On the EHR Triage task, STEER achieves an\nAUC gain of 0.429 over the baseline, nearly double the\nstatic team’s performance. The evolutionary process suc-\ncessfully discovers non-intuitive bias gaps that manual cura-\ntion misses. Additionally, we observe diminishing returns\nwith respect to team size. A team size of N = 10 cap-\ntures the majority of the diversity gain (e.g., +0.393 on\nEHR Triage) while incurring only 33% of the inference\ncost of the N = 30 team, confirming the efficiency of\nour coverage-based assembly selection. This allows practi-\ntioners to select the optimal deployment configuration for\nresource-constrained environments.\n6.2. Deterministic Control via Percentile Tuning\nWe next evaluate the controllability of the expanded range.\nFigure 4 visualizes the impact of the conservativeness dial\non the predicted case distribution. An operator increasing\nthe conservativeness must be guaranteed that the model\nbehavior will shift in one direction. STEER’s Percentile\nTuning mechanism enforces this by sorting the ensemble’s\noutputs. Increasing the percentile P results in a strictly\nnon-decreasing shift in urgency. The proportion of cases\nFigure 3. Evolutionary Steerability vs. Baselines. Ordinal AUC\ngain of STEER ensembles (varying size N ∈{5, 10, 20, 30})\nrelative to high-temperature sampling (N = 10) and static persona\nbaselines (N = 10) for (A) MIETIC Triage and (B) EHR Triage.\npredicted as high-acuity rises while low-acuity predictions\nfall, eliminating erratic behavior associated with standard\nprompt engineering. Notably, the high-temperature sam-\npling baseline and STEER differ significantly in sensitiv-\nity—the magnitude of change elicited by the dial. The\nbaseline exhibits a constrained dynamic range, where the er-\nror rates remain relatively static regardless of the percentile\nselected. This highlights mode collapse, where the model’s\ninternal variance is too narrow to be effectively steered. In\ncontrast, STEER unlocks a wide operating window. For\nEHR triage, by shifting the dial from P = 20 to P = 80,\nthe system reduces the risk of undertriage from ≈60% to\n< 5%, granting the operator meaningful control over the\nsafety profile. For MIETIC, STEER marginally widens the\ndecision boundaries compared to the baseline. The STEER\ncurves achieve a lower undertriage rate at high percentiles,\nproving more responsive for tuning the system to specific\nconservativeness preferences.\n6.3. Inference-Time vs. Post-Training Alignment\nFinally, we compare STEER against Spectrum Tuning, a\nrepresentative post-training method. We evaluate whether\nenhancing the output space coverage via post-training is\nsuperior to improving it via STEER. As shown in Figure 5\n(Panels A & B), STEER applied to a standard instruction-\ntuned model achieves Ordinal AUC scores highly compet-\n7\n"}, {"page": 8, "text": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search\nFigure 4. Deterministic Risk Control via Percentile Tuning.\nThe effect of the Percentile Selection dial on the predicted urgency\ndistribution for STEER (N = 10) vs. the high-temperature base-\nline (N = 10) on (A) MIETIC and (B) EHR Triage. Higher\npercentiles (P →100) correspond to strictly more conservative\n(urgent) predictions.\nitive with the Spectrum-Tuned model (0.859 vs. 0.634 on\nMIETIC; 0.964 vs. 0.980 on EHR). This result shows that\ninference-time evolution can sufficiently enhance valid out-\nput space. Crucially, Panels C and D reveal a failure mode\nin the post-training approach. The Spectrum-Tuned model\nsuffers significant degradation on unambiguous urgent cases\nassessed for safety, dropping to 49.6% accuracy on MIETIC\nand 51.2% on EHR. This indicates that Spectrum Tuning\nreduces the model’s domain competence to increase diver-\nsity. In contrast, STEER maintains high safety performance\n(80.9% and 94.9% respectively). This robustness is a con-\nsequence of our constrained optimization objective (Rsafe),\nwhich allows STEER to pursue diversity without sacrificing\nreliability on critical, unambiguous cases.\n7. Conclusion\nCurrent alignment paradigms optimize for average correct-\nness, inadvertently collapsing valid professional disagree-\nment into a single point estimate. This renders models rigid,\nstripping them of the ability to trade off sensitivity and\nspecificity (the ROC operating point) based on changing\nenvironmental constraints.\nFigure 5. Inference-Time Evolution vs. Post-Training Align-\nment. Comparison between Spectrum Tuning (red) and STEER\n(blue) on Gemma-3-12B-IT. (A, B) Steerability: Ordinal AUC\nscores on the MIETIC and EHR Triage datasets. (C, D) Safety:\nAccuracy on the unambiguous urgent safety sets.\nIn this work, we introduced STEER, a framework that re-\nstores this control by transforming frozen, black-box models\ninto tunable instruments. By reformulating steerability as\na constrained Quality-Diversity search, we demonstrated\nthat it is possible to expand the latent spectrum of valid\nrisk perspectives without expensive retraining. Our evolu-\ntionary approach successfully discovers bias gaps, while\nour Percentile Tuning mechanism provides the determin-\nistic monotonicity required for safety-critical deployment.\nCrucially, our results show that this inference-time interven-\ntion matches the steerability of state-of-the-art post-training\nmethods while preventing the catastrophic forgetting of fun-\ndamental safety knowledge on unambiguous cases. This\nsuggests a new paradigm for reliable AI, where reliability\nis defined not by a single static output, but by the system’s\nability to be calibrated to the user’s operational tolerance.\nOur work opens clear avenues for future investigation. First,\nwhile STEER expands the valid spectrum, the computational\ncost of ensemble inference scales linearly with team size.\nFuture work could explore distillation techniques to com-\npress the diverse team into a single, conditionally steerable\nadapter. Second, our current evaluation focused on ordinal\ndecision tasks. Expanding the framework’s constraints and\ntuning mechanisms to support open-ended generation re-\nmains an active challenge. Finally, while we demonstrate\nutility in clinical triage, the framework’s core principle of\nmanaging risk via calibrated diversity is broadly applicable\nto legal, financial, and ethical reasoning, warranting further\nvalidation in these domains.\nUltimately, STEER represents a step toward pluralistic AI\nsystems that do not merely dictate a single ”correct” answer,\nbut empower human experts with a transparent, controllable\nrange of valid options.\n8\n"}, {"page": 9, "text": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search\nImpact Statement\nPromoting Pluralism and Context-Aware Safety. Stan-\ndard alignment techniques optimize for average correctness,\nartificially collapsing valid professional disagreement into a\nsingle ”safe” mode. By employing quality-diversity search\nto recover the latent spectrum of expert opinion, our frame-\nwork enables context-aware safety. This allows AI systems\nto adapt their sensitivity/specificity trade-off (the ROC op-\nerating point) to dynamic environmental constraints rather\nthan imposing a rigid risk posture that may be locally dis-\nastrous. This is particularly impactful for democratizing\nhigh-quality decision support in under-resourced environ-\nments where retraining models is infeasible.\nEthical Risks of Tunable Efficiency. The introduction of a\ndeterministic risk dial introduces friction between clinical\nsafety and economic efficiency. There is a non-trivial risk\nthat operators could utilize the dial to minimize overtriage\nstrictly for cost-saving purposes, effectively automating un-\ndertriage to an ethically unacceptable level. However, we\nargue that current black-box models effectively make this de-\ncision implicitly (and rigidly). STEER makes this trade-off\ntransparent. Nonetheless, deployment must be accompanied\nby strict governance protocols where the operating point\n(P) is treated as a clinical calibration parameter governed\nby medical directors, rather than a user preference.\nStability of Inference-Time Governance. Because STEER\nfunctions as an external wrapper around a frozen base model,\nsafety becomes a runtime dependency rather than a static\nweight property. This creates a risk of alignment drift. If the\nunderlying proprietary model is updated, quantized, or (in\nthe case of APIs) silently patched, the ensemble’s evolved\ncalibration may degrade. Our inference-time approach re-\nquires continuous monitoring and potential re-evolution to\nmaintain its safety guarantees against API shifts.\nReferences\nAgrawal, L. A., Tan, S., Soylu, D., Ziems, N., Khare, R.,\nOpsahl-Ong, K., Singhvi, A., Shandilya, H., Ryan, M. J.,\nJiang, M., Potts, C., Sen, K., Dimakis, A. G., Stoica, I.,\nKlein, D., Zaharia, M., and Khattab, O. GEPA: Reflective\nprompt evolution can outperform reinforcement learning.\n2025.\nDu, Y., Li, S., Torralba, A., Tenenbaum, J. B., and Mordatch,\nI. Improving factuality and reasoning in language models\nthrough multiagent debate. 2023.\nFernando, C., Banarse, D., Michalewski, H., Osindero, S.,\nand Rockt¨aschel, T. Promptbreeder: Self-referential self-\nimprovement via prompt evolution. 2023.\nGemma Team, Mesnard, T., Hardin, C., Dadashi, R., Bhu-\npatiraju, S., Pathak, S., Sifre, L., Rivi`ere, M., Kale,\nM. S., Love, J., et al.\nGemma: Open models based\non gemini research and technology, 2024. URL https:\n//arxiv.org/abs/2403.08295.\nGuo, Q., Wang, R., Guo, J., Li, B., Song, K., Tan, X., Liu,\nG., Bian, J., and Yang, Y. EvoPrompt: Connecting LLMs\nwith evolutionary algorithms yields powerful prompt op-\ntimizers. 2023.\nHamilton, S. Detecting mode collapse in language models\nvia narration. 2024.\nJohnson, A., Bulgarelli, L., Pollard, T., Gow, B., Moody, B.,\nHorng, S., Celi, L. A., and Mark, R. MIMIC-IV, 2024.\nJustice, J., Kohn, M. D., and Walker, III, J. R. EMS re-\nverse triage. In StatPearls. StatPearls Publishing, Trea-\nsure Island (FL), April 2025.\nURL https://www.\nncbi.nlm.nih.gov/books/NBK482234/. [Up-\ndated 2025 Apr 6].\nKingma, D. P. and Ba, J. Adam: A method for stochastic\noptimization. 2014.\nKirk, R., Mediratta, I., Nalmpantis, C., Luketina, J., Ham-\nbro, E., Grefenstette, E., and Raileanu, R. Understanding\nthe effects of rlhf on llm generalisation and diversity,\n2023.\nKolkman, D., Bex, F., Narayan, N., and van der Put, M.\nJustitia ex machina: The impact of an ai system on legal\ndecision-making and discretionary authority. Big Data &\nSociety, 11(2):20539517241255101, 2024. doi: 10.1177/\n20539517241255101. URL https://doi.org/10.\n1177/20539517241255101.\nLanchantin, J., Chen, A., Dhuliawala, S., Yu, P., Weston,\nJ., Sukhbaatar, S., and Kulikov, I. Diverse preference\noptimization. 2025.\nLee, J., Shang, T., Baik, J. Y., Duong-Tran, D., Yang, S., Li,\nL., and Shen, L. From promising capability to pervasive\nbias: Assessing large language models for emergency\ndepartment triage, 2025.\nLi, T., Zhang, Y., Yu, P., Saha, S., Khashabi, D., Weston, J.,\nLanchantin, J., and Wang, T. Jointly reinforcing diversity\nand quality in language model generations. 2025.\nLiang, T., He, Z., Jiao, W., Wang, X., Wang, Y., Wang,\nR., Yang, Y., Shi, S., and Tu, Z. Encouraging divergent\nthinking in large language models through Multi-Agent\ndebate. 2023.\nMeng, T., Mehrabi, N., Goyal, P., Ramakrishna, A., Gal-\nstyan, A., Zemel, R., Chang, K.-W., Gupta, R., and Peris,\nC. Attribute controlled fine-tuning for large language\nmodels: A case study on detoxification, 2024.\n9\n"}, {"page": 10, "text": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search\nQian, C., Xue, K., and Wang, R.-J. Quality-Diversity algo-\nrithms can provably be helpful for optimization. 2024.\nRashidian, S., Li, N., Amar, J., Lee, J. H., Pugh, S., Yang, E.,\nMasterson, G., Cha, M., Jia, Y., and Vaid, A. Ai agents\nfor conversational patient triage: Preliminary simulation-\nbased evaluation with real-world ehr data, 2025.\nShen, Q. and Guo, Q. MIMIC-IV-Ext triage instruction\ncorpus, 2025.\nSingh, A., Fry, A., Perelman, A., Tart, A., Ganesh, A., El-\nKishky, A., McLaughlin, A., Low, A., Ostrow, A., Anan-\nthram, A., et al. Openai GPT-5 system card, August 2025.\nURL https://arxiv.org/abs/2601.03267.\nSorensen, T., Newman, B., Moore, J., Park, C., Fisher, J.,\nMireshghallah, N., Jiang, L., and Choi, Y. Spectrum\ntuning: Post-training for distributional coverage and in-\ncontext steerability, 2025.\nStanfield, L. M. Clinical decision making in triage: An inte-\ngrative review. J. Emerg. Nurs., 41(5):396–403, Septem-\nber 2015.\nSuzgun, M. and Kalai, A. T. Meta-prompting: Enhancing\nlanguage models with task-agnostic scaffolding. 2024.\nTyler, S., Olis, M., Aust, N., Patel, L., Simon, L., Tri-\nantafyllidis, C., Patel, V., Lee, D. W., Ginsberg, B.,\nAhmad, H., and Jacobs, R. J. Use of artificial intelli-\ngence in triage in hospital emergency departments: A\nscoping review. Cureus, 16(5):e59906, May 2024. doi:\n10.7759/cureus.59906. Erratum in: Cureus. 2025 Sep\n24;17(9):c315. doi: 10.7759/cureus.c315.\nVukovi´c, D. B., Dekpo-Adza, S., and Matovi´c, S.\nAI\nintegration in financial services: a systematic review\nof trends and regulatory challenges. Humanities and\nSocial Sciences Communications, 12:562, 2025.\ndoi:\n10.1057/s41599-025-04850-8. URL https://doi.\norg/10.1057/s41599-025-04850-8.\nYang, C., Wang, X., Lu, Y., Liu, H., Le, Q. V., Zhou, D., and\nChen, X. Large language models as optimizers. Septem-\nber 2023.\nZhang, J., Yu, S., Chong, D., Sicilia, A., Tomz, M. R.,\nManning, C. D., and Shi, W. Verbalized sampling: How\nto mitigate mode collapse and unlock LLM diversity.\nOctober 2025.\nZhou, Z., Jin, T., Shi, J., and Li, Q. SteerConf: Steering\nLLMs for confidence elicitation. 2025.\n10\n"}, {"page": 11, "text": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search\nA. Dataset Details & Statistics\nA.1. MIETIC (Public Benchmark)\nPreprocessing and Input Formatting. The MIETIC dataset is derived from MIMIC-IV emergency department notes\n(Shen & Guo, 2025; Johnson et al., 2024). Raw clinical notes sometimes contain information that would only be known\nafter triage (data leakage). To address this, we preprocessed the notes into a single narrative string containing only the\n“Chief Complaint,” “Vitals,” and “Medical History.” We employed a separate LLM ((GPT-5-mini) to perform information\nextraction, strictly retaining information that the patient could reasonably have known or presented with before being seen\nby a physician.\nSynthetic Input Example. Below is an illustrative example of the preprocessed input format. Note: This is a synthetic\ncase generated to mirror the style and structure of the dataset while protecting patient privacy. It does not represent a real\nindividual.\nInput String: “A 72-year-old male with a history of COPD and chronic heart failure presents to the ED reporting worsening\nshortness of breath and fluid retention over the past 3 days. He notes increased swelling in lower extremities and difficulty\nsleeping flat. On arrival, vitals were BP 135/85, HR 110, RR 28, and SpO2 91% on room air. PMH includes hypertension,\nhyperlipidemia, and type 2 diabetes. Patient arrived via private vehicle.”\nClass Distributions. We utilized specific Emergency Severity Index (ESI) levels to define our training and safety sets. ESI-3\nserves as the source of ambiguous cases for evolution, while ESI-1 (Most Urgent) and ESI-5 (Least Urgent) serve as safety\nconstraints. The demographic and clinical characteristics of these subsets are detailed below.\nTable 1. Demographic Statistics (MIETIC)\nStatistic\nESI-1 (Critical)\nESI-3 (Ambiguous)\nESI-5 (Non-Urgent)\nCount (N)\n955\n1028\n1263\nGender\nMale\n530 (55.5%)\n428 (41.6%)\n748 (59.2%)\nFemale\n425 (44.5%)\n598 (58.2%)\n515 (40.8%)\nUnknown\n0 (0%)\n2 (0.2%)\n0 (0%)\nAge (Years)\nMean (SD)\n63.9 (17.8)\n45.6 (18.4)\n35.4 (14.5)\nMedian\n66.0\n44.0\n29.0\nRange\n18 – 91\n0 – 91\n18 – 82\nTable 2. Distribution of Chief Complaints by ESI Level (MIETIC)\nCategory\nESI-1\nESI-3\nESI-5\nNeurological\n263\n73\n2\nRespiratory\n218\n82\n19\nGastrointestinal\n113\n299\n1\nInjuries\n110\n131\n315\nCardiovascular\n89\n45\n26\nConstitutional\n67\n44\n13\nMusculoskeletal\n24\n201\n33\nGenitourinary\n10\n75\n0\nDermatological\n18\n29\n239\nPoisoning\n15\n4\n4\nSensory Organs\n3\n5\n93\nPsychological\n8\n10\n24\nEndocrine/Metabolic\n6\n4\n0\nReproductive\n4\n11\n0\nOther / Unclassified\n7\n15\n494\n11\n"}, {"page": 12, "text": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search\nA.2. Real-World EHR Triage (Proprietary)\nDataset Construction. This dataset consists of de-identified telehealth encounters. The input for each case is constructed\nby concatenating three distinct data sources into a single context string: (1) A generated patient summary and notes from\nthe last encounter; (2) Structured EHR data including active medications, recent lab results, and problem lists; and (3) A\nmulti-turn dialogue transcript between a patient simulator and an AI physician agent.\nSafety vs. Ambiguity Criteria. Ground truth was established by three senior human physicians. We defined the subsets\nbased on inter-annotator consensus:\n• Safety Sets (Level 1 & 5): Cases where all three annotators unanimously agreed on the extreme labels: “Urgent\ncare/Emergency” (Level 1) or “Self-care” (Level 5).\n• Ambiguous Set (Level 3): All remaining cases, which largely consist of disagreements (e.g., split decisions between\nPCP and ER), intra-rater ambiguity (e.g. multiple acceptable decisions within 1 annotator), or unanimous consensus on\nthe intermediate “Follow up with PCP” label.\nInter-Annotator Agreement. The Fleiss’ Kappa scores (Table 3) highlight the inherent subjectivity of the task. While\nagreement is relatively higher for critical emergencies (κ ≈0.57), it drops significantly for intermediate dispositions,\nconfirming that ambiguity is a feature of the domain rather than label noise.\nAgreement Metric Definitions. To interpret the inter-annotator reliability reported in Table 3, we define the calculated\nmetrics as follows:\n• Fleiss’ Kappa: A statistical measure for assessing the reliability of agreement between a fixed number of raters (n = 3)\nwhen assigning categorical ratings. It corrects for agreement occurring by chance.\n• Avg Pairwise Kappa: The arithmetic mean of Cohen’s Kappa scores calculated for every unique pair of raters (Rater\nA vs. B, A vs. C, B vs. C). This provides a more granular view of pairwise consistency compared to the aggregate\nFleiss’ metric.\n• % Unanimous Agreement: The percentage of cases where all three annotators were in exact agreement (either all\nassigning the label or all rejecting it). This represents the rate of unambiguous consensus.\n• Assignment Rate: The prevalence of the label within the dataset, calculated as the mean percentage of cases assigned\nthat specific label across all annotators. This contextualizes the Kappa scores, as agreement metrics can be sensitive to\nhighly imbalanced class distributions.\nTable 3. Human Annotator Agreement Statistics (EHR Triage)\nLabel Category\nFleiss’ Kappa\nAvg Pairwise κ\n% Unanimous\nAssignment Rate\nSelf-care\n0.448\n0.452\n64.1%\n31.7%\nFollow up with PCP\n0.310\n0.340\n49.3%\n57.1%\nUrgent / Emergency\n0.569\n0.570\n86.3%\n12.1%\nTable 4. Demographic Statistics (EHR Triage)\nStatistic\nLevel 1 (Critical)\nLevel 3 (Ambiguous)\nLevel 5 (Self-Care)\nCount (N)\n76\n451\n33\nGender\nMale\n19 (25.0%)\n83 (18.4%)\n7 (21.2%)\nFemale\n57 (75.0%)\n368 (81.6%)\n26 (78.8%)\nAge (Years)\nMean (SD)\n50.5 (18.1)\n55.2 (18.6)\n58.4 (17.6)\nMedian\n52.5\n56.0\n61.0\nRange\n17 – 95\n17 – 96\n25 – 96\n12\n"}, {"page": 13, "text": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search\nTable 5. Distribution of Chief Complaints by Care Level (EHR Triage)\nCategory\nLevel 1\nLevel 3\nLevel 5\nRespiratory\n56\n144\n16\nMusculoskeletal\n7\n107\n1\nGenitourinary\n2\n81\n2\nGastrointestinal\n3\n36\n3\nSensory Organs\n2\n22\n0\nInjuries\n0\n13\n0\nReproductive\n0\n10\n0\nDermatological\n1\n10\n0\nNeurological\n1\n9\n2\nCardiovascular\n0\n4\n9\nConstitutional\n3\n7\n0\nOther\n1\n8\n0\nB. Algorithm Implementation Details\nB.1. Inference Prompts\nThe final system prompts used during deployment differ slightly by dataset to align with the specific ordinal scale (ESI\nvs. Care Level). In both cases, the {persona block} is injected dynamically based on the specific agent persona being\nqueried.\nB.1.1. SYSTEM PROMPT (MIETIC)\n- {persona block}\nYour task is to assign an Emergency Severity Index (ESI) level (1–5) to the patient described below, consistent with both the\ncase data and your overall approach.\nFirst, carefully review the case details. Next, use your clinical reasoning and reference the ESI definitions provided. Let your\nperspective as described above guide how you interpret the information and weigh risks or resources.\nPatient Case: {patient case}\n[... Standard ESI 1-5 Definitions Omitted for Brevity ...]\nGuidelines\n• Count the type, not the number of individual tests (e.g., CBC + Lytes = 1 Lab Resource).\n• Only include those resources most needed.\nThink through your decision step by step, referencing both the case and your persona’s approach. Respond only in the following\nJSON format: {\"reasoning\":\n\"...\", \"esi level\":\n<int>}\nB.1.2. SYSTEM PROMPT (HV TRIAGE)\n- {persona block}\nYour task is to assign a care level (1–5) to the patient described below, consistent with both the case data and your overall\napproach.\nFirst, carefully review the case details. Next, use your clinical reasoning and reference the care level definitions provided. Let\nyour perspective as described above guide how you interpret the information and weigh risks or urgency.\nPatient Case: {patient case}\n[... Care Level 1-5 Definitions Omitted for Brevity ...]\nThink through your decision step by step, referencing both the case and your persona’s approach. Respond only in the following\nJSON format: {\"reasoning\":\n\"...\", \"care level\":\n<int>}\nB.2. Initialization (Seed Personas)\nThe evolutionary process was initialized with a small set of ”seed” personas representing distinct, manually curated triage\nphilosophies. These served as the genetic ancestors for the initial population. Below are a few illustrative examples:\n13\n"}, {"page": 14, "text": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search\n• The Vital Signs Anchor: You are a methodical triage nurse who begins every case by carefully reviewing the patient’s\nvital signs before considering history or symptoms. You believe vital stability provides the clearest initial snapshot of\nrisk, and you use this as your anchor for further triage decision-making. Only after confirming stability do you weigh\nother presenting details for escalation.\n• The Narrative Interpreter: You are a nurse who prefers a narrative approach, starting with the patient’s story and\ndescription of symptoms. You find that understanding the timeline, progression, and patient concerns helps you\ncontextualize clinical findings. You then map these qualitative details to the formal ESI criteria to arrive at your triage\ndecision.\n• The Guideline Adherent: You are an evidence-driven triage nurse who always consults hospital protocols and the\nlatest ESI criteria before making a decision. Your workflow involves referencing each criterion in order, checking\noff whether each is met based strictly on documented data, and minimizing subjective interpretation. You value\nreproducibility and adherence to established guidelines above all.\nFor the Static Persona baseline used in Experiment I, we randomly sample N personas from this same seed pool. This\nensures that any performance gain observed in STEER is attributable to the evolutionary optimization of the population,\nrather than the quality of the initial prompt engineering.\nB.3. Evolutionary Prompts\nB.3.1. MUTATION PROMPT (GAP FILLING)\nTo generate personas that interpolate between existing risk postures, the Meta-LLM (GPT-5-mini) is provided with\n”Reference Personas” (neighbors in the bias sort) and the following instructions:\nObjective: Create a realistic [Role] persona that would demonstrate triage behavior in a [Setting] with a bias estimate of\napproximately [Target Bias].\nUnderstanding the Bias Framework:\n• Negative bias: Perceives cases as more urgent/serious than typical (Conservative).\n• Positive bias: Perceives cases as less urgent than typical (Lenient).\nTarget: Create a persona whose triage philosophy and decision-making patterns would naturally produce bias ≈[Target Bias].\nContext: Filling gap between existing personas at [Start Bias] and [End Bias].\n[...Reference Personas Inserted Here...]\nGeneration Guidance: Consider weaving together elements like:\n• Formative Events: What experiences shaped their approach to uncertainty?\n• Clinical Philosophy: How do they balance caution vs. efficiency?\nRequirements: Format as second person (’You are...’), 3-5 sentences.\nB.3.2. EDGE EXPANSION PROMPT\nTo push the boundaries of the ensemble’s operational range, the Meta-LLM (GPT-5-mini) is instructed to extrapolate beyond\nthe current extremes:\nObjective: Create a [Role] with extreme but realistic triage patterns in a [Setting]. Target bias: [Target Bias] (More\n[Conservative/Lenient] than current extreme).\nContext: This persona represents an outlier at the edge of the bias distribution—significantly more extreme than typical\nphysicians.\n[...Current Extreme Personas Inserted Here...]\nGeneration Guidance: What might drive such extreme patterns?\n• For Extreme Conservatism: Professional trauma (missed diagnosis), medicolegal anxiety, critical care background.\n• For Extreme Leniency:\nResource-constrained training (stewardship), confidence in home monitoring, anti-\nmedicalization philosophy.\nRequirements: Format as second person (’You are...’), 3-5 sentences.\n14\n"}, {"page": 15, "text": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search\nB.3.3. COHERENCE JUDGE PROMPTS\nHere, practitioners can customize important standards that personas must maintain as to not to sacrifice task competence in\nblind pursuit of diversity. As an example, we employ 2 LLM-as-a-Judges system (GPT-o4-mini) to score generated personas\non a 0–4 scale for clinical soundness and fact grounding. The final coherence score C(j) used for filtering is calculated as\nthe arithmetic mean of these two component scores.\nJudge 1: Clinical Soundness Rubric\n• Score 4 (Exceptional): Identifies key findings including important clinical details, demonstrates sophisticated medical\nreasoning with risk stratification, and considers differential diagnosis or complicating factors.\n• Score 3 (Strong): Identifies key findings with appropriate clinical detail, establishes a clear logical connection from\nclinical presentation to the decision, and is medically sound with coherent reasoning flow.\n• Score 2 (Acceptable): Identifies main clinical findings and makes a decision with clear justification, though the\nreasoning may lack some detail or sophistication.\n• Score 1 (Weak): Mentions some relevant points but has major gaps in clinical logic, misses key findings, or the\nreasoning is incomplete, unclear, or superficial.\n• Score 0 (Poor): Contains major medical errors, contradictions, or misconceptions, ignores critical clinical findings, or\nthe reasoning is circular, nonsensical, or entirely off-topic.\nJudge 2: Grounding Rubric\n• Score 4 (Excellently Grounded): References specific case facts with good detail, claims are clearly supported by case\ninformation, and appropriately notes information gaps when relevant.\n• Score 3 (Well Grounded): References specific facts from the case, major claims are supported by case information,\nand there is no significant invented information.\n• Score 2 (Adequately Grounded): References key case facts appropriately and makes reasonable clinical inferences,\nthough it could include more specific details.\n• Score 1 (Weakly Grounded): Mentions the case in general terms but makes unsupported assumptions not warranted\nby the case, or relies on very generic reasoning.\n• Score 0 (Not Grounded): Invents facts that contradict or aren’t in the case, makes major unsupported assumptions\npresented as facts, or directly contradicts stated case information.\nB.4. Hyperparameters\nThe following hyperparameters control the evolutionary dynamics and filtering rigor.\n15\n"}, {"page": 16, "text": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search\nTable 6. Evolutionary Algorithm Hyperparameters\nParameter\nDescription\nEvolutionary Dynamics\nn generations = 5\nThe maximum number of evolutionary cycles (generations) per-\nformed to refine the pool and can be customized by practitioners\ndepending on resource constraints and validation performance.\ntarget pool size = 75\nThe fixed capacity of the persona population. After filtering,\nthe pool is generated to this size to maintain computational\ntractability.\ngap filling ratio = 0.7\nThe proportion of new personas generated by interpolating be-\ntween existing ones (Gap Filling) vs. extrapolating (Edge Ex-\npansion).\nedge expansion ratio = 0.3\nThe proportion of generation budget dedicated to pushing the\nmin/max boundaries of the risk spectrum.\nSafety & Quality Filtering\nsafety percentile = 0.8\nRelative Safety: Personas must rank in the top 80th percentile\nof the population on safety cases (ESI 1/5) to survive.\nsafety threshold = 0.9\nAbsolute Safety: Personas must achieve at least 90% accuracy\non unambiguous safety cases. (Personas meeting either the\npercentile or threshold criteria are retained).\ncoherence percentile = 0.85\nThe percentile cutoff for reasoning quality. The bottom 15% of\npersonas (as scored by the Coherence Judge) are culled in every\ngeneration.\nvariance percentile = 0.85\nThe percentile cutoff for consistency. Within identified clusters\nof similar bias, the 15% of personas with the highest internal\nvariance (instability) are removed.\nB.5. Variance Constraint Implementation Details\nTo operationalize the variance constraint without imposing arbitrary absolute thresholds, we utilize an adaptive, density-based\nfiltering approach.\nClustering Algorithm: We employ a deterministic sequential distance algorithm. Personas are sorted by their estimated bias\nparameter (uj). Consecutive personas are grouped into the same cluster if the absolute difference in their bias |ui −ui+1| is\nless than a dynamic threshold δ.\nAdaptive Threshold Determination: The distance threshold δ is calibrated automatically in Generation 1 to match the\npopulation density:\n1. Calculation: δ is initialized as 25% of the current total bias range (max(u) −min(u)), clamped to the interval\n[0.05, 0.5] ESI units.\n2. Validation: We validate this threshold using DBSCAN density checks. If DBSCAN yields ≤1 cluster despite a bias\nrange > 0.3, the threshold is tightened to 15% of the range to force separability.\n3. Persistence: The determined threshold is frozen and reused for all subsequent generations to ensure consistent filtering\nstandards.\nFiltering Logic:\n• Minimum Size: Clusters with fewer than 4 personas are treated as outliers and are exempt from variance pruning (to\npreserve rare, extreme perspectives).\n• Pruning: Within valid clusters (N ≥4), we calculate the 85th percentile of the residual variance (s2\nj) distribution.\nPersonas exceeding this local threshold (the top 15% noisiest members of that specific risk posture) are discarded.\n16\n"}, {"page": 17, "text": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search\nC. Evolutionary Trajectory and Targeting Accuracy\nThis appendix details the performance of the evolutionary algorithm in managing bias distributions across generations and\nits precision in targeting specific bias values (Gap Filling) and expanding the range of observed biases (Edge Expansion).\nC.1. Bias Distribution Evolution\nThe evolution of persona bias distributions over three generations is shown in Figure 6. The violin plots visualize the density\nof bias values (ESI units) for the (A) MIETIC and (B) EHR Triage datasets.\nWe observe a consistent trajectory across both datasets. Generation 1 exhibits a relatively narrow distribution, representing\nthe initial seed personas. In Generation 2, the bias spread expands significantly, indicating the algorithm’s exploration phase\nwhere it successfully diversifies persona behaviors. By Generation 3, the distributions begin to converge and spread out,\nsuggesting the algorithm is refining the population around the most viable or representative bias characteristics.\nFigure 6. Evolution of Persona Bias Distributions. Violin plots displaying the distribution of bias values (ESI units) across three\ngenerations for (A) MIETIC and (B) EHR Triage datasets. The plots illustrate an initial expansion of bias diversity in Gen 2 followed by a\nconvergence in Gen 3.\nC.2. Targeting Accuracy: Gap Filling and Edge Expansion\nTo assess the model’s control over persona generation, we evaluated gap filling, which is the ability to generate a persona that\ntargets a specific, missing bias value. Figure 7 illustrates the relationship between the target bias (the bias value requested by\nthe prompt) and the actual bias (the measured bias of the generated persona).\nThe scatter plots reveal a strong positive correlation between the target and actual values, with Pearson correlation coefficients\nof r = 0.738 for MIETIC and r = 0.815 for EHR Triage. This high correlation indicates that the underlying Meta LLM\npossesses a sophisticated understanding of the language space of bias. Given relevant examples, it successfully maps abstract\nnumerical bias targets into the semantic nuances required to instantiate those biases in persona descriptions.\n17\n"}, {"page": 18, "text": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search\nFigure 7. Gap Filling Precision: Target vs. Actual Bias. Scatter plots comparing the targeted bias value against the actual evaluated bias\nfor (A) MIETIC (n = 75) and (B) EHR Triage (n = 120). The dashed line represents perfect targeting. The high Pearson correlation (r)\nindicates the model’s strong capability to translate numerical bias targets into semantic persona attributes.\nPERFORMANCE STATISTICS\nThe statistical analysis further confirms the efficacy of the targeting mechanism.\nGap Filling (Precision)\n• MIETIC (n = 75):\n– Excellent (bias error < 0.2): 56.0% (42/75)\n– Good (bias error 0.2–0.5): 44.0% (33/75)\n– No personas fell into the “Acceptable” or “Poor” categories.\n• EHR Triage (n = 120):\n– Excellent (bias (error < 0.2): 70.0% (84/120)\n– Good (bias error 0.2–0.5): 28.3% (34/120)\n– The average targeting error was notably low at 0.155 ESI units.\nEdge Expansion (Range)\n• MIETIC (n = 34): 73.5% of attempts reached at least the top/bottom 10% of the current range. Successful expansion\nattempts extended the range by an average of +0.546 ESI units.\n• EHR Triage (n = 54): 48.1% of attempts reached at least the top/bottom 10% of the current range. Successful\nattempts extended the range by an average of +0.053 Care Level units.\nD. Qualitative Case Studies\nTo validate that the quantitative gains in AUC and distribution coverage correspond to meaningful clinical diversity, we\npresent qualitative examples of personas generated by STEER. These case studies demonstrate the algorithm’s ability to\nperform targeted gap filling (generating a specific risk posture to bridge a distributional void) and edge expansion (pushing\nthe boundaries of the operational range).\n18\n"}, {"page": 19, "text": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search\nD.1. Gap Filling (Interpolation)\nThe Gap Filling operator identifies voids in the bias spectrum and prompts the Meta-LLM to generate a persona with a\nspecific target bias. The examples below demonstrate the precision of this mechanism, where the generated persona’s actual\nbias (measured empirically in the subsequent generation) aligns with the target bias.\nD.1.1. CASE 1: MIETIC (TARGETING MODERATE CONSERVATISM)\nContext: The algorithm identified a coverage gap in the moderately conservative region (Target Bias ≈−0.37).\n• Target Bias: −0.366 (ESI units)\n• Actual Bias Achieved: −0.364 (Error: 0.003)\n• Status: Successful Interpolation\nGenerated Persona:\n”You are an emergency physician trained at a busy Level I trauma center... working nights in a 60,000-visit urban ED. After\na young patient with ’atypical’ chest pain died of an unrecognized PE early in your career, you adopted a low threshold for\nescalation: you prioritize ruling out ’can’t-miss’ diagnoses, pay close attention to subtle symptoms and borderline vitals, and\noften choose observation or admission when uncertainty remains... Your clinical philosophy errs toward caution—you accept\nsome loss of throughput to lower the risk of adverse outcomes.”\nD.1.2. CASE 2: EHR TRIAGE (TARGETING DEEP CONSERVATISM)\nContext: The algorithm targeted a specific void in the ”Deep Conservative” tail for the proprietary telehealth dataset.\n• Target Bias: −0.765 (Care Level units)\n• Actual Bias Achieved: −0.766 (Error: 0.001)\n• Status: Successful Interpolation\nGenerated Persona:\n”You are an emergency physician... with 13 years in a busy 50-bed urban ED... A formative near-miss early in your career — a\nyoung patient with vague chest pain who was discharged and later died of a PE — left you with a low tolerance for missed\nserious disease, so you habitually treat borderline presentations as potential red flags. You favor early objective testing... and\ngive extra weight to subtle vital-sign trends... Patient safety and avoiding diagnostic uncertainty drive your decisions.”\nD.2. Edge Expansion (Extrapolation)\nThe Edge Expansion operator aims to discover valid perspectives that lie outside the current min/max boundaries of the\nensemble.\nD.2.1. CASE 3: MIETIC (PUSHING THE LENIENT FRONTIER)\nContext: The ensemble’s lenient (positive bias) boundary was stuck at +0.35. The system attempted to discover a valid,\nmore resource-conscious perspective.\n• Goal: > +0.352 (More Lenient)\n• Actual Bias Achieved: +1.133 (Extension: +0.781)\n• Status: Successful Edge Extension\nGenerated Persona:\n19\n"}, {"page": 20, "text": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search\n”You are an emergency physician who habitually reads presentations as far less urgent than your peers, developed from a\ndecade working in resource-scarce rural and military hospitals where admitting every borderline patient was impossible...\nThose years... trained you to prioritize stewardship over exhaustive in-house workups... Your clinical philosophy is high\ntolerance for ongoing symptoms: stable vitals, benign basic testing, and a plausible outpatient plan are usually enough to send\npatients home.”\nD.2.2. CASE 4: EHR TRIAGE (PUSHING THE CONSERVATIVE FRONTIER)\nContext: Attempting to extend the conservative boundary beyond the current maximum of −0.88.\n• Goal: < −0.880 (More Conservative)\n• Actual Bias Achieved: −1.000 (Extension: −0.120)\n• Status: Successful Edge Extension\nGenerated Persona:\n”You are a triage clinician whose default is extreme caution... You were shaped by a young patient’s unexpected cardiac\narrest after a discharge early in your career, a subsequent malpractice claim, and years working in ICU/trauma units... You\ncannot tolerate diagnostic uncertainty... you read benign presentations through the lens of ’what if this deteriorates.’ You\nare emotionally driven by vigilance and a conviction that avoiding rare but devastating outcomes justifies resource-intensive,\ndefensive decision-making.”\n20\n"}]}