{"doc_id": "arxiv:2512.23440", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2512.23440.pdf", "meta": {"doc_id": "arxiv:2512.23440", "source": "arxiv", "arxiv_id": "2512.23440", "title": "ClinDEF: A Dynamic Evaluation Framework for Large Language Models in Clinical Reasoning", "authors": ["Yuqi Tang", "Jing Yu", "Zichang Su", "Kehua Feng", "Zhihui Zhu", "Libin Wang", "Lei Liang", "Qiang Zhang", "Keyan Ding", "Huajun Chen"], "published": "2025-12-29T12:58:58Z", "updated": "2025-12-29T12:58:58Z", "summary": "Clinical diagnosis begins with doctor-patient interaction, during which physicians iteratively gather information, determine examination and refine differential diagnosis through patients' response. This dynamic clinical-reasoning process is poorly represented by existing LLM benchmarks that focus on static question-answering. To mitigate these gaps, recent methods explore dynamic medical frameworks involving interactive clinical dialogues. Although effective, they often rely on limited, contamination-prone datasets and lack granular, multi-level evaluation. In this work, we propose ClinDEF, a dynamic framework for assessing clinical reasoning in LLMs through simulated diagnostic dialogues. Grounded in a disease knowledge graph, our method dynamically generates patient cases and facilitates multi-turn interactions between an LLM-based doctor and an automated patient agent. Our evaluation protocol goes beyond diagnostic accuracy by incorporating fine-grained efficiency analysis and rubric-based assessment of diagnostic quality. Experiments show that ClinDEF effectively exposes critical clinical reasoning gaps in state-of-the-art LLMs, offering a more nuanced and clinically meaningful evaluation paradigm.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2512.23440v1", "url_pdf": "https://arxiv.org/pdf/2512.23440.pdf", "meta_path": "data/raw/arxiv/meta/2512.23440.json", "sha256": "b451f36f9a5f542fc408939ed177e2c92cf8aeefb1ebd64c7faf5f95e8fcc31e", "status": "ok", "fetched_at": "2026-02-18T02:23:36.448876+00:00"}, "pages": [{"page": 1, "text": "ClinDEF: A Dynamic Evaluation Framework for Large Language Models in\nClinical Reasoning\nYuqi Tang1,2,3∗, Jing Yu1,4∗, Zichang Su1 , Kehua Feng1,3 , Zhihui Zhu1 ,\nLibin Wang2 , Lei Liang5 , Qiang Zhang1,2 , Keyan Ding1† , Huajun Chen1,3†\n1ZJU-Hangzhou Global Scientific and Technological Innovation Center, Zhejiang University\n2ZJU-UIUC Institute, Zhejiang University\n3College of Computer Science and Technology, Zhejiang University\n4The Polytechnic Institute, Zhejiang University 5AntGroup\n{yuqi.22}@intl.zju.edu.cn, {yujing17, dingkeyan, huajunsir}@zju.edu.cn\nAbstract\nClinical diagnosis begins with doctor-patient inter-\naction, during which physicians iteratively gather\ninformation, determine examination and refine dif-\nferential diagnosis through patients’ response. This\ndynamic clinical-reasoning process is poorly rep-\nresented by existing LLM benchmarks that fo-\ncus on static question-answering.\nTo mitigate\nthese gaps, recent methods explore dynamic med-\nical frameworks involving interactive clinical dia-\nlogues. Although effective, they often rely on lim-\nited, contamination-prone datasets and lack granu-\nlar, multi-level evaluation. In this work, we pro-\npose ClinDEF, a dynamic framework for assessing\nclinical reasoning in LLMs through simulated di-\nagnostic dialogues. Grounded in a disease knowl-\nedge graph, our method dynamically generates pa-\ntient cases and facilitates multi-turn interactions be-\ntween an LLM-based doctor and an automated pa-\ntient agent. Our evaluation protocol goes beyond\ndiagnostic accuracy by incorporating fine-grained\nefficiency analysis and rubric-based assessment of\ndiagnostic quality. Experiments show that ClinDEF\neffectively exposes critical clinical reasoning gaps\nin state-of-the-art LLMs, offering a more nuanced\nand clinically meaningful evaluation paradigm.\n1\nIntroduction\nLarge language models (LLMs) have demonstrated increas-\ning potential in healthcare applications, including clinical de-\ncision support, patient-facing chatbots, and automated medi-\ncal documentation [Omiye et al., 2024; McDuff et al., 2025;\nFalcetta et al., 2023]. As these systems move closer to in-\ntegration within real-world clinical environments, the need\nfor rigorous and clinically meaningful evaluation of their\nreasoning capabilities becomes critical [Tang et al., 2024;\nCabral et al., 2024; Goh et al., 2024; Qiu et al., 2025a].\n∗Equal contribution.\n†Corresponding Author\nExisting evaluation paradigms primarily rely on static\nbenchmarks [Jin et al., 2020; Pal et al., 2022; Zuo et al.,\n2025], such as multiple-choice exams or single-turn ques-\ntion answering. However, this approach contrasts with clin-\nical practice, where diagnosis begins with medical consul-\ntation and involves active information gathering, continual\nrefinement of differential diagnoses, and evidence integra-\ntion [Gruppen et al., 1991; Brush and Brophy, 2017]. Con-\nsequently, while static benchmarks are useful for measuring\nfactual recall, they fail to capture the interactive and iterative\nnature of clinical reasoning and often suffer from informa-\ntion leakage or benchmark contamination [Xu et al., 2024;\nChen et al., 2025], leaving a significant gap in evaluating\nLLMs’ reliability in real-world clinical settings.\nTo mitigate these biases, recent techniques [Liu et al.,\n2025; McCoy et al., 2025; Chiu et al., 2025; Zhang et\nal., 2025] have begun exploring dynamic medical evaluation\nframeworks aimed at assessing the ability of LLMs to en-\ngage in interactive patient conversations. Frameworks such as\nAIPatient [Yu et al., 2024], CRAFT-MD [Johri et al., 2025],\nand MedKGEval [Yu et al., 2025b] have been adopted to effi-\nciently simulate realistic medical dialogues and assess LLMs’\nreasoning ability in real-time settings. Despite their effec-\ntiveness, these methods typically rely on small, static sets of\npre-defined cases, which are prone to data contamination and\ndo not offer a multi-level, fine-grained assessment of clinical\nreasoning performance.\nTo address these challenges, we propose ClinDEF, a dy-\nnamic framework for assessing clinical reasoning in LLMs\nthrough simulated multi-turn doctor-patient diagnostic dia-\nlogues. ClinDEF moves beyond static test formats by mod-\neling the diagnosis as a dynamic interaction among three\nagents: a patient agent that provides symptom descriptions,\nan examiner agent that returns medical examination reports,\nand a doctor agent instantiated by the target LLM under eval-\nuation. Grounded in a structured disease knowledge graph,\nour framework enables controlled generation of diverse pa-\ntient cases with nuanced symptom profiles and plausible dif-\nferential diagnoses. Through this interactive setup, ClinDEF\ncaptures core aspects of the clinical reasoning process, in-\ncluding hypothesis generation, test ordering, differential revi-\nsion, and diagnostic efficiency. Our evaluation protocol ex-\narXiv:2512.23440v1  [cs.CL]  29 Dec 2025\n"}, {"page": 2, "text": "tends beyond result-based metrics by incorporating process-\noriented analysis and a fine-grained, rubric-based assessment\nof diagnostic quality across multiple dimensions, such as log-\nical consistency, differential breadth, and cognitive flexibility,\noffering a more comprehensive and clinically grounded ap-\npraisal of model behavior.\nOur contributions can be summarized as follows:\n• Dynamic evaluation framework for clinical reason-\ning: We propose ClinDEF, a dynamic diagnostic frame-\nwork that evaluates LLMs’ clinical reasoning through\ninteractive, scalable multi-turn diagnostic conversations.\n• Knowledge-grounded case generation and process-\naware assessment: We develop a disease knowledge\ngraph-driven pipeline for generating diverse and dy-\nnamic patient cases, and introduce process-aware met-\nrics that evaluate both diagnostic efficiency and quality.\n• Comprehensive analysis of LLM diagnostics: We em-\npirically reveal that our framework uncovers systematic\nreasoning deficiencies in state-of-the-art LLMs and pro-\nviding actionable insights for developing more reliable\nclinical LLMs.\n2\nRelated Works\nStatic Medical Benchmarks\nThe evaluation of LLMs in\nthe medical domain has largely relied on static question-\nanswering benchmarks [Kung et al., 2023; Zhao et al., 2023;\nQiu et al., 2025b; Huang et al., 2025; Arora et al., 2025].\nRepresentative datasets such as PubMedQA [Jin et al., 2019],\nMedQA [Jin et al., 2020], and MedMCQA [Pal et al., 2022]\nassess models primarily through factual recall and biomed-\nical knowledge retrieval. Recent efforts, for instance Med-\nCaseReasoning [Wu et al., 2025], are constructed from open-\naccess case reports and aim to evaluate how models in-\nfer diagnoses using clinician-authored diagnostic reasoning.\nMedBench [Liu et al., 2024] curates the largest available\nevaluation dataset covering 43 clinical specialties and con-\nducts multi-faceted assessments of medical LLMs.\nWhile\nthese benchmarks have advanced the measurement of medical\nknowledge in LLMs, they remain focused on final-answer ac-\ncuracy or lexical overlap metrics (e.g., BLEU, ROUGE) and\nfail to capture the dynamic and evolving nature of medical\ndialogue.\nDynamic Medical Benchmarks\nRecent work has at-\ntempted to address these gaps through dynamic medical\nevaluation frameworks involving multi-turn clinical dia-\nlogues [Yu et al., 2024; Liu et al., 2025; McCoy et al., 2025;\nCroxford et al., 2025].\nCRAFT-MD [Johri et al., 2025]\nuses simulated multi-agent systems, including clinical, pa-\ntient, grader, and expert agents, to evaluate LLMs in a con-\ntrolled clinical environment. MedKGEval [Yu et al., 2025b]\nintroduces a knowledge-graph-based multi-agent evaluation\nframework that simulates realistic, dynamic medical dia-\nlogues and monitors LLM behavior in real time. However,\nthese studies often rely on small, static benchmarks suscep-\ntible to data contamination and fail to provide a multi-level,\nfine-grained evaluation of the model’s clinical reasoning ca-\npabilities. We aim to fill this gap by introducing ClinDEF, a\ndynamic evaluation framework that evaluates LLMs through\nsimulated doctor–patient dialogues.\n3\nMethods\nIn this section, we introduce the proposed ClinDEF, a dy-\nnamic evaluation framework with three main components: (1)\nknowledge-grounded case generation, (2) a multi-agent en-\nvironment for diagnostic dialogue, and (3) a comprehensive\nevaluation protocol, as illustrated in Figure 1.\n3.1\nKnowledge-Grounded Case Generation\nA central goal of ClinDEF is to construct evaluation cases\nthat are both diagnostically faithful and resistant to contam-\nination from pretraining corpora. To this end, we formulate\ncase generation as a mapping\nG : (KG, KE, Θ) 7→C,\n(1)\nwhere KG is a structured disease–symptom knowledge\ngraph, KE is an unstructured medical encyclopedia, Θ is a\ngenerative LLM, and C is the resulting case profile. For each\ndiagnostic session, G first samples a disease node d ∈KG and\nretrieves the corresponding descriptive passage Td ⊂KE.\nConditioned on (d, Td), the generator Θ synthesizes patient\ndemographics Pd\ninfo and symptom manifestations Sd under a\nset of medical consistency constraints derived from the topol-\nogy of KG. This dynamic and knowledge-grounded sam-\npling ensures that each case is coherent with domain exper-\ntise while being previously unseen, thus mitigating the risk of\nmemorization by evaluated models. The output of this pro-\ncess is a structured case profile\nC =\n\u0000d, Td, Pinfo, Sd\n\u0001\n.\n(2)\nThis profile serves as the latent ground truth from which the\npatient agent simulates dialogue, the examiner agent provides\ntest results and against which the doctor agent’s reasoning is\nevaluated.\nCompared with static, hand-curated clinical vignettes, the\ndynamically generated cases offer complementary advan-\ntages: (1) Contamination resistance, since the space of pos-\nsible cases is huge and instantiated dynamically at evaluation\ntime; (2) Knowledge-grounded consistency, because symp-\ntoms and attributes are sampled under explicit structural con-\nstraints of KG and thus remain clinically coherent; and (3)\nControlled clarity, as all case elements are derived from cu-\nrated sources rather than noisy records, making the evaluation\nless confounded by missing or ambiguous information. No-\ntably, we emphasize that real-world clinical cases remain the\ngold standard; our contribution lies in providing a controlled,\ncontamination-free method for generating cases.\n3.2\nMulti-Agent Environment for Diagnostic\nDialogue\nThe design of ClinDEF is inspired directly by the structure\nof real-world medical consultations, where physicians, pa-\ntients, and clinical examination systems interact in comple-\nmentary ways. To capture this interactive reasoning process,\nwe introduce a multi-agent environment that formalizes di-\nagnostic dialogue as a structured interaction among agents.\n"}, {"page": 3, "text": "Patient\n[Initial] I’ve been coughing badly lately, and I also have a bit of a fever. I \nfeel somewhat short of breath\nDoctor\n[Thinking] The patient presents with cough, fever, and shortness of \nbreath … suggesting a possible respiratory infection (pneumonia, acute \nbronchitis, or COPD exacerbation) …. Further differentiation requires \nclarifying the nature of the cough (dry/productive, sputum color) …\n[Ask] Is your cough dry or productive? If productive, what is the color of \nyour sputum?\nPatient\nMy cough started as a dry cough, but now I have some sputum. The \nsputum is white in color.\na. Knowledge-Grounded Case Generation\nc. Diagnostic Dialogue\nd. Evaluation Metric\nPatient Agent\nSymptoms\nDemographic\nPersonal History\nDoctor\n[Thinking] The patient’s cough changed from dry to productive with white \nsputum … suggesting possible viral infection or early bacterial \ninfection … less indicative of purulent infection (e.g., typical bacterial \npneumonia), though not excluded … with fever and shortness of breath … \nfurther physical examination needed for severity and lung findings … to \ndifferentiate pneumonia, bronchitis, or other pulmonary diseases\n[Test: Physical examination]\nExaminer\nPhysical examination result: On auscultation of both lungs, fine \ncrackles and wheezing were heard\nExaminer Agent\nPhysical Examination\nLaboratory Test\nRadiology Report\nFinal Diagnosis: Community-acquired pneumonia\n...\nDoctor\n Agent\nAsk\nTest\nDiagnose\nb. Multi-Agent Environment \nQuality\nReasoning Chain\n…\nPatient Case\nSAMPLE\nDisease\nRETRIEVE\nPatient \ndemographics\nSymptom\nmanifestations\nKnowledge \nGraph\nMedical \nEncyclopedia\nDisease description\nGENERATE\n...\nFinal Diagnosis\nEfficiency\nResult  \nDiagnosis Accuracy\nInformation Gathering\n(CCE, HC)\nPositive Findings   \nPer Turn\nTotal Dialogue  \nTurns\nPositive Hit \nRate\nReasoning Process\n(ECI, TJ, DDx)\nConclusion & Safety\n(DC, DU)\nReasoning\nFinal Diagnosis\nActions\nFigure 1: Overview of ClinDEF. (a) Knowledge-grounded case generation combines a disease–symptom knowledge graph with medical\nencyclopedia text to synthesize patient cases. (b) A multi-agent environment models diagnostic consultation, where the Doctor Agent (LLM\nbeing evaluated) interacts with Patient and Examiner Agents through actions Ask, Test, and Diagnose. (c) A diagnostic dialogue example\nillustrates information gathering, hypothesis revision, and evidence integration, leading to a final diagnosis. (d) Evaluation metrics encompass\ndiagnostic accuracy, efficiency, and quality.\nThis paradigm goes beyond conventional static QA settings\nby simulating the iterative and multi-source evidence gather-\ning that underpins clinical reasoning.\nAgent Roles\nBefore modeling the dialogue, we first define\nthe key actors in the environment. Real clinical encounters\ninvolve multiple participants with clearly delineated respon-\nsibilities, and we mirror this division by assigning each role\nto a dedicated agent\nA = {AD, AP , AE},\n(3)\ncorresponding to the doctor, the patient, and the examiner.\nThe Doctor Agent AD represents the LLM under evaluation\nand serves as the sole deliberative agent, tasked with iden-\ntifying the ground-truth disease d through iterative informa-\ntion gathering and reasoning. In contrast, the Patient Agent\nAP and Examiner Agent AE function as responsive environ-\nmental simulators: AP provides symptom reports and de-\nmographic information grounded in the case profile C, while\nAE delivers laboratory test results and imaging reports upon\nrequest. Together, these three agents define the interactive\necosystem within which diagnostic reasoning is tested.\nDialogue Dynamics\nThe consultation is modeled as a tem-\nporally ordered sequence of utterances, capturing the evolv-\n"}, {"page": 4, "text": "ing state of the dialogue:\nHt = (u1, u2, . . . , ut),\nt = 1, 2, . . . , T.\n(4)\nHere, Ht encodes all information exchanged up to time t,\nserving as the shared memory across agents. The dialogue\nis initialized by the Patient Agent AP , which generates the\nfirst utterance u1 containing the chief complaint based on the\nsymptom manifestation Sd ∈C:\nu1 = AP (Sd).\n(5)\nFor each subsequent turn, the active agent generates the\nnext utterance conditioned on the Ht−1 and the case profile\nC. This recursive structure ensures that reasoning is path-\ndependent, reflecting the way physicians revise hypotheses\nbased on accumulating evidence rather than isolated inputs.\nAgent Actions\nTo emulate structured clinical reasoning,\nthe Doctor Agent AD operates within a discrete action space:\nAD = {Ask, Test, Diag},\n(6)\nand at each turn, it produces an action and the associated out-\ncomes based on the dialogue history:\n(aD\nt , oD\nt ) = AD(Ht−1),\naD\nt ∈AD.\n(7)\nThe action Ask produces an outcome oD\nt\n= qt, which cor-\nresponds to a natural language query aimed at eliciting sub-\njective information about symptoms or history. Test results\nin oD\nt = rt, denoting a request for an objective examination.\nDiag outputs oD\nt = dt, representing the model’s final diag-\nnostic decision that terminates the interaction. By abstracting\nphysician behavior into these three canonical moves, we iso-\nlate the fundamental reasoning primitives that drive clinical\nconsultations while keeping the evaluation tractable and re-\nproducible.\nIn contrast, the Patient AP and Examiner AE agents are\ndeterministic simulators that do not possess an autonomous\naction space. Their behavior is a reactive response to the Doc-\ntor’s action aD\nt , governed by the case profile C. We define\nthem as part of the environment’s response mechanism.\nEnvironment Response\nOnce the Doctor Agent issues\n(aD\nt , oD\nt ), the environment determines which simulation\nagent (i.e., AP or AE) responds and produces the utterance\nut:\nut =\n\n\n\nAP (qt | C),\nif aD\nt = Ask ∧oD\nt = qt,\nAE(rt | C),\nif aD\nt = Test ∧oD\nt = rt,\nEnd,\nif aD\nt = Diag ∧oD\nt = dt.\n(8)\nEach response ut is strictly constrained by the structured case\nprofile C, ensuring consistency between the simulated dia-\nlogue and the ground-truth disease d. In practice, this means\nthat subjective responses from AP always align with the\nsymptom set in C, while test results generated by AE reflect\nmedically plausible outcomes tied to d. This design guaran-\ntees that any observed errors in reasoning are attributable to\nthe Doctor Agent rather than noise in the environment.\nHistory Update\nAfter each interaction, the dialogue his-\ntory is updated recursively:\nHt = Ht−1 ⊕(oD\nt , ut).\n(9)\nThis operation appends the doctor’s action outcome and the\ncorresponding response to the evolving dialogue state. By\nfeeding Ht back into the next decision of AD, the frame-\nwork naturally captures the iterative nature of hypothesis re-\nfinement. The process continues until either a diagnosis is\nstated via aD\nt\n= Diag or the maximum turn limit Tmax is\nreached, ensuring bounded yet realistic interactions. The re-\nsulting dialogue trajectory provides a complete trace of the\nreasoning process, which is later used for both outcome-based\nand process-oriented evaluation.\n3.3\nEvaluation Metrics\nTo comprehensively assess the clinical reasoning capabili-\nties of LLMs, we designed a multi-faceted evaluation pro-\ntocol. Inspired by Objective Structured Clinical Examina-\ntions (OSCE) widely used in medical education [Fu et al.,\n2025], which emphasizes structured, multi-dimensional eval-\nuation of clinical reasoning, this protocol moves beyond mea-\nsuring only the final diagnostic accuracy to also scrutinize the\nefficiency and quality of the diagnostic process. This enables\ndeeper insights into how LLMs gather information, revise hy-\npotheses, and justify decisions, mirroring the cognitive work-\nflow of expert clinicians. Specifically, the evaluation metrics\nare described as follows.\nDiagnostic Accuracy\nThis dimension focuses on the ac-\ncuracy of the final diagnosis, measuring whether the Doc-\ntor Agent correctly identifies the patient’s disease. It serves\nas a fundamental measure of the model’s clinical decision-\nmaking, forming the basis for further evaluation of diagnostic\nefficiency and quality.\nDiagnostic Efficiency\nThis dimension evaluates how effec-\ntively the Doctor Agent gathers clinically relevant informa-\ntion and progresses toward the final diagnosis. It is measured\nalong three complementary indicators:\n1. Total Dialogue Turns: The overall number of turns re-\nquired to reach a correct diagnosis, reflecting efficiency\nin information gathering and decision-making.\n2. Positive Findings Per Turn: The positive findings per\ncase, indicating how much clinically useful information\nis elicited in each dialogue.\n3. Negative Findings Per Turn: The negative findings per\ncase, reflecting how much clinically non-present condi-\ntions are ruled out in each dialogue.\n4. Positive Hit Rate: The proportion of positive find-\nings among all findings, capturing the precision of in-\nformation gathering by minimizing irrelevant or non-\ncontributory data.\nDiagnostic Quality\nTo evaluate the more nuanced aspects\nof the diagnostic process, we employ an “LLM-as-a-Judge”\nparadigm grounded in established OSCE evaluation princi-\nples for quantitative assessment, producing a diagnostic qual-\nity score (DQS). Detailed descriptions of the evaluation and\n"}, {"page": 5, "text": "Algorithm 1: Implementation of ClinDEF\nInput: Structured medical knowledge graph KG,\nUnstructured medical encyclopedia KE, Patient\ninformation generator Θ, Doctor Agent AD (LLM to\nbe evaluated), Patient Agent AP , Examiner Agent\nAE, Maximum dialogue turns Tmax, Evaluation\nmetrics M\nOutput: Diagnostic accuracy, efficiency, and reasoning\nquality score\n// Step 1:\nDynamic Case Generation\n1 Sample a disease node d ∼KG;\n2 Retrieve disease-specific descriptive text\nTd ←Query(d, KE);\n3 Generate patient demographics Pinfo and symptom set Sd\nusing Θ;\n4 Construct a case profile C = (d, Td, Pinfo, Sd);\n// Step 2:\nMulti-Agent Initialization\n5 Initialize AP , AE, and AD;\n6 Initialize dialogue history H0 = ∅;\n7 u1 ←AP (Sd) H1 ←H0 ⊕u1;\n8 t ←1;\n// Step 3:\nDiagnostic Dialogue Loop\n9 while t < Tmax and no diagnosis stated do\n10\n(aD\nt , oD\nt ) ←AD(Ht−1)\n11\nif aD\nt = Ask ∧oD\nt = qt then\n12\nut ←AP (qt | C);\n13\nelse if aD\nt = Test ∧oD\nt = rt then\n14\nut ←AE(rt | C);\n15\nelse if aD\nt = Diag ∧oD\nt = dt then\n16\nbreak;\n17\nHt ←Ht−1 ⊕(aD\nt , ut) t ←t + 1;\n18 end\n// Step 4:\nEvaluation\n19 if aD\nt = Diag ∧oD\nt = dt then\n20\nCompute diagnostic accuracy: I(dt = d);\n21\nCompute diagnostic efficiency (e.g., number of turns t,\npositive findings);\n22\nCompute reasoning quality using the evaluation rubric\nM;\n23 end\n24 else\n25\nMark the session as timeout failure;\n26 end\n27 return Evaluation scores (Accuracy, Efficiency, Quality)\nvalidation of the “LLM-as-a-Judge” procedure are provided\nin Appendix A3. Specifically, a high-performing LLM eval-\nuates each diagnostic dialogue using a clinically grounded\nrubric composed of seven weighted dimensions:\nDQSi =\nX\nd∈D\nwd · Si,d,\n(10)\nwhere D = {CCE, HC, ECI, TJ, DDx, DC, DU} denotes the\nset of evaluation dimensions, grouped into three clinically\nmeaningful categories:\n1. Information Gathering: Chief Complaint Exploration\n(CCE) and History Completeness (HC), assessing the\nthoroughness, structure, and clinical relevance of initial\nsymptom elicitation and patient history collection.\n2. Reasoning Process: Evidence Chain Integrity (ECI),\nTest Justification (TJ), and Differential Diagnosis\n(DDx), evaluating the logical coherence of diagnostic\nassertions, appropriateness of test ordering, and breadth\nand prioritization of plausible alternative diagnoses.\n3. Conclusion and Safety: Diagnostic Correctness (DC)\nand Diagnostic Uncertainty (DU), measuring the align-\nment of the final diagnosis with available evidence and\nguidelines, as well as the responsible acknowledgment\nand management of diagnostic ambiguity.\nHere, wd represents the predefined clinical weight for dimen-\nsion d (with P\nd∈D wd = 1), and Si,d is the score assigned to\ncase i on dimension d. Detailed definitions and scoring rubric\nfor each dimension are provided in Appendix A5.\n4\nExperiments\n4.1\nExperimental Setup\nModels\nWe select 15 advanced LLMs, including 7 pro-\nprietary models (GPT-4o, GPT-4.1, GPT-4.1-mini, GPT-5-\nmini, GPT-5-nano [Hurst et al., 2024], Gemini-2.5-Pro [Team\net al., 2023], Claude-4-Sonnet [Anthropic, 2025]), 8 open-\nsource general-purpose models (DeepSeek-V3 [DeepSeek-\nAI et al., 2024], DeepSeek-R1 [Guo et al., 2025], Qwen2.5-\n7B-Instruct, Qwen3-8B(with explicit thinking), Qwen3-\n235B-A22B, Qwen3-Next-80B-A3B [Yang et al., 2025],\nLlama-4-Scout, Llama-4-Maverick [Meta, 2025]). More de-\ntails about these models are presented in Table A2.\nSettings\nTo ensure a fair, reproducible, and clinically rel-\nevant evaluation, we maintained standardized experimental\nconditions across all evaluated models. We randomly gener-\nated 5 distinct sets of test cases, each containing 300 unique\npatient cases, and conducted five independent runs for each\nmodel. This helps capture random variations in case genera-\ntion and model behavior, making the evaluation more diverse\nand reliable. The Doctor Agents are the LLMs being eval-\nuated, while the Patient and Examiner Agents were imple-\nmented with GPT-5, strictly constrained to case profile con-\ntent. Inference used temperature = 0.0 and top-p = 1.0. Di-\nalogues started with the patient’s chief complaint and ended\nupon diagnosis or after Tmax of 15 turns.\n4.2\nDiagnostic Accuracy Analysis\nTable 1 show the diagnosis accuracy of 15 LLMs on Clin-\nDEF. The evaluation of diagnostic accuracy across the mod-\nels reveals a clear hierarchy in performance, ranging from\n48.27% to 72.87%.\nClosed-source models (e.g., Gemini-\n2.5-Pro, GPT-4.1-mini, Claude-Sonnet-4) consistently oc-\ncupy the top tier, suggesting that proprietary scaling, align-\nment, or domain-specific tuning may confer an advantage\nin clinical diagnosis under interactive conditions.\nAmong\nopen-source models, Llama-4-Maverick and DeepSeek-V3\ndemonstrate competitive performance, narrowing the gap\nwith their closed-source counterparts. Interestingly, GPT-4.1-\nmini slightly outperforms its larger counterpart GPT-4.1 in\n"}, {"page": 6, "text": "Table 1: Diagnostic accuracy, efficiency, and quality (mean ± standard error) on ClinDEF, including Acc. (diagnostic accuracy), Tot. Turns\n(total dialogue turns), Pos./Neg. Find. (positive/negative findings), PHR (positive hit rate), and DQS (diagnostic quality score).\nModel\nAcc. ↑\nTot. Turns ↓\nPos. Find. ↑\nNeg. Find. ↓\nPHR ↑\nDQS ↑\nGemini-2.5-Pro\n72.87 ± 1.43\n6.57 ± 0.14\n5.17 ± 0.11\n2.22 ± 0.17\n69.93 ± 1.90\n70.0 ± 0.8\nGPT-4.1-mini\n71.73 ± 0.98\n8.27 ± 0.11\n7.97 ± 0.24\n4.60 ± 0.16\n63.41 ± 1.31\n69.5 ± 0.7\nClaude-Sonnet-4\n69.60 ± 2.28\n6.52 ± 0.08\n6.98 ± 0.09\n2.84 ± 0.18\n71.09 ± 1.50\n68.6 ± 0.4\nGPT-4.1\n69.47 ± 2.36\n6.35 ± 0.07\n5.36 ± 0.08\n3.71 ± 0.11\n59.11 ± 0.91\n66.7 ± 0.7\nLlama-4-Maverick\n69.47 ± 3.01\n6.99 ± 0.10\n5.36 ± 0.12\n2.61 ± 0.10\n67.23 ± 1.12\n65.2 ± 0.7\nDeepSeek-V3\n68.73 ± 2.77\n5.71 ± 0.08\n5.66 ± 0.08\n3.14 ± 0.11\n64.31 ± 0.72\n63.9 ± 1.2\nGPT-5-mini\n67.67 ± 2.36\n5.59 ± 0.11\n5.01 ± 0.13\n3.43 ± 0.22\n59.35 ± 1.22\n63.7 ± 1.0\nDeepSeek-R1\n63.40 ± 2.55\n3.86 ± 0.07\n3.51 ± 0.05\n1.67 ± 0.06\n67.74 ± 0.93\n63.5 ± 0.7\nGPT-4o\n63.13 ± 1.98\n5.34 ± 0.08\n4.57 ± 0.08\n3.14 ± 0.08\n59.25 ± 0.77\n60.4 ± 1.1\nGPT-5-nano\n63.00 ± 2.51\n5.74 ± 0.12\n4.78 ± 0.09\n3.22 ± 0.17\n59.74 ± 1.44\n59.8 ± 0.6\nQwen3-235B-A22B\n59.87 ± 2.16\n5.11 ± 0.06\n5.05 ± 0.14\n2.65 ± 0.09\n65.58 ± 1.30\n58.4 ± 0.7\nQwen3-Next-80B-A3B\n57.87 ± 1.73\n4.84 ± 0.08\n3.76 ± 0.06\n2.92 ± 0.19\n56.25 ± 1.77\n57.0 ± 0.7\nLlama-4-scout\n55.73 ± 2.66\n6.07 ± 0.13\n5.31 ± 0.22\n3.26 ± 0.11\n62.00 ± 1.49\n56.4 ± 0.8\nQwen3-8B\n50.93 ± 2.47\n4.32 ± 0.07\n4.05 ± 0.08\n3.44 ± 0.12\n54.06 ± 1.02\n54.7 ± 0.6\nQwen2.5-7B\n48.27 ± 1.55\n5.66 ± 0.08\n5.07 ± 0.10\n3.62 ± 0.15\n58.35 ± 1.46\n52.7 ± 0.4\ndiagnostic accuracy, suggesting that model size or parameter\ncount alone does not guarantee superior clinical reasoning.\n4.3\nDiagnostic Efficiency Analysis\nTable 1 also shows a clear trade-off between efficiency and\naccuracy.\nDeepSeek-R1 was the most efficient, requiring\nonly 4.41 turns on average, but gathered the least positive\nand negative findings and achieved only moderate accuracy.\nClaude-Sonnet-4 demonstrates a highly efficient approach. It\nachieved the highest Positive Hit Rates (71.09%), enabling it\nto reach a highly accurate diagnosis within a moderate num-\nber of dialogue turns. Conversely, GPT-4.1-mini exempli-\nfied a more exhaustive approach. It was the slowest model,\nwith 8.37 turns, but used this extended dialogue to gather the\nmost positive and negative findings, leading to its high ac-\ncuracy of 71.73%. The top-performing model, Gemini-2.5-\nPro, demonstrated a balanced and effective strategy. In sum-\nmary, the highest diagnostic accuracy was achieved through\na more comprehensive and efficient line of questioning that\neffectively balances conversational length with high-quality\ninformation gathering.\n4.4\nDiagnostic Quality Analysis\nTo comprehensively evaluate clinical reasoning, we assess\nmodel performance using the Diagnostic Quality Score (DQS\nin Eq. 10), a composite metric based on seven clinically val-\nidated dimensions. These dimensions are grouped into the\nfollowing three phases of the diagnostic process.\nInformation Gathering Evaluation\nA critical finding\nfrom Figure 2 and Table A1 is that information gathering rep-\nresents a significant area of weakness across all tested large\nlanguage models. As measured by Chief Complaint Explo-\nration (CCE) and History Completeness (HC), the models\nconsistently scored in the low to moderate range, far below\nthe maximum possible score of 10 for each dimension. For\ninstance, the highest scores observed were only 6.3 for CCE\n(Claude-Sonnet-4) and 3.8 for HC (Qwen2.5-7B), indicating\na universal deficiency in this fundamental clinical skill. In\nreal-world clinical practice, thorough and accurate informa-\ntion gathering is fundamental to patient safety, and models\nmust enhance their capabilities in this area. This deficit high-\nlights that LLMs falter in the active diagnostic process: rather\nthan strategically probing to reduce uncertainty, they remain\npassive and reactive. Such deficits in diagnostic process cre-\nate a critical gap between knowing medical facts and perform-\ning authentic clinical reasoning.\nCore Reasoning Process Evaluation\nThe core reasoning\nprocess is where the top-performing models truly distinguish\nthemselves. As shown in Figure 2 and Table A1, Gemini-2.5-\nPro achieved the highest score in Evidence Chain Integrity\n(ECI), followed by GPT-5-mini and GPT-4.1-mini. In Test\nJustification (TJ), most models demonstrated strong perfor-\nmance, with scores generally high across the board. This in-\ndicates that explaining the reasoning behind a specific clinical\naction aligns well with the structured reasoning capabilities\nof current LLMs. However, despite these strengths, mod-\nels still show limitations when required to integrate incom-\nplete or ambiguous evidence. In differential diagnosis (DDx),\nLLMs also exhibited notable performance variability.\nDiagnostic Conclusion and Clinical Safety\nThe final\nphase of our evaluation assesses the models’ ultimate per-\nformance in Diagnostic Correctness (DC) and their ability to\nexpress Diagnostic Uncertainty (DU), a crucial element for\nsafe clinical application. As the most heavily weighted com-\nponent, Diagnostic Correctness scores were closely aligned\nwith the overall rankings. However, across all models, we\nobserve a striking insufficiency in acknowledging Diagnos-\n"}, {"page": 7, "text": "ECI\n(20)\nHC\n(10)\nCCE\n(10)\nDQS\n(100)\nDU\n(10)\nDC\n(30)\nDD\n(10)\nTJ\n(10)\nGemini-2.5-Pro\nClaude-Sonnet-4\nGPT-4o\nGPT-4.1\nECI\n(20)\nHC\n(10)\nCCE\n(10)\nDQS\n(100)\nDU\n(10)\nDC\n(30)\nDD\n(10)\nTJ\n(10)\nQwen3-8B\nGPT-5-mini\nGPT-5-nano\nGPT-4.1-mini\nECI\n(20)\nHC\n(10)\nCCE\n(10)\nDQS\n(100)\nDU\n(10)\nDC\n(30)\nDD\n(10)\nTJ\n(10)\nQwen3-235B-A22B\nLlama-4-Scout\nLlama-4-Maverick\nDeepSeek-R1\nFigure 2: The Diagnostic Quality Score (DQS, 100) and fine-grained scores across seven dimensions of clinical reasoning. Chief Complaint\nExploration (CCE, 10), History Completeness (HC, 10), Evidence Chain Integrity (ECI, 20), Test Justification (TJ, 10), Differential Diagnosis\n(DDx, 10), Diagnostic Correctness (DC, 30), and Diagnostic Uncertainty (DU, 10).\ntic Uncertainty. LLMs overwhelmingly issue definitive di-\nagnoses despite incomplete evidence, rarely adopting provi-\nsional judgments or considering “watchful waiting”. Even\nthe top-performing models score only 4 out of 10, as reported\nin Figure 2 and Table A1. This overconfidence creates the\nillusion of certainty and poses a potential safety risk, as it\nmay obscure diagnostic ambiguity and mislead users. Reli-\nable clinical models must therefore be designed not only to\nmaximize correctness but also to reason explicitly about what\nis unknown.\nFigure 3: Doctor Agent rankings across three Patient–Examiner\nAgent foundation models (GPT-5,\nGemini-3-Pro, Claude-4.5-\nSonnet). The parallel coordinates plot shows each Doctor Agent’s\nrank under different simulator LLMs.\n4.5\nSensitivity of Patient-Examiner Agent’s\nFoundation Model\nTo further analyze the robustness of our framework against\npotential biases introduced by the choice of Patient-Examiner\nAgent foundation models, we conduct ablation studies on\nClinDEF by evaluating the same set of Doctor Agents and test\ncases using three different simulator LLMs: GPT-5, Gemini-\n3-Pro, and Claude-4.5-Sonnet. For each setting, models were\nranked by diagnostic accuracy, and the resulting rankings ex-\nhibit strong agreement across all backbone pairs: GPT vs.\nGemini (ρ = 0.946), GPT vs. Claude (ρ = 0.954), and Gem-\nini vs. Claude (ρ = 0.964). Figure 3 illustrates that 7 out\nof 15 models exhibit identical rankings across all judges, and\nthe Top-4 models remain perfectly aligned across all judges.\nThis consistency indicates that ClinDEF is largely robust to\nthe choice of Patient–Examiner Agent backbone and yields\nstable, backbone-agnostic conclusions regarding comparative\nmodel performance.\n4.6\nDataset and Environment Evaluation\nTo ensure the reliability of our results, we conducted a thor-\nough quality assessment of the dataset and simulation envi-\nronment. Five licensed clinicians independently evaluated a\nshared set of 200 randomly sampled cases, examining two\nkey criteria: Information Leakage and Clinical Fidelity. We\nexamine whether the correct diagnosis was disclosed by Pa-\ntient Agent or Examiner Agent during the dialogue.\nRe-\nviewers found that 99.0% of cases contained no such infor-\nmation leakage. We further assess the clinical coherence of\nPatient and Examiner Agent outputs, finding that 93.5% of\ncases were judged realistic and medically consistent. These\nresults support the fidelity of our knowledge-grounded simu-\nlation pipeline. More details about the data quality verifica-\ntion process are provided in appendix A4.\n"}, {"page": 8, "text": "5\nConclusions\nIn this work, we introduced a dynamic framework designed\nto evaluate the clinical reasoning capabilities of LLMs. Clin-\nDEF moves beyond static exam-style benchmarks through\nsimulated diagnostic dialogue. By systematically evaluating\ndiagnostic accuracy, efficiency, and the quality of the reason-\ning process across multiple dimensions, we provide a unified\nand clinically meaningful paradigm to quantify how LLMs\ncan think like doctors. Our experimental findings reveal that,\ndespite impressive diagnostic accuracy, existing models ex-\nhibit critical deficiencies in the clinical reasoning process.\nEven state-of-the-art LLMs demonstrate significant weak-\nnesses in diagnostic quality, underscoring the need for sub-\nstantial advancements in developing more reliable LLMs.\nReferences\n[Anthropic, 2025] AI Anthropic. System Card: Claude Opus\n4 & Claude Sonnet 4. Claude-4 Model Card, 2025.\n[Arora et al., 2025] Rahul\nK\nArora,\nJason\nWei,\nRe-\nbecca\nSoskin\nHicks,\nPreston\nBowman,\nJoaquin\nQui˜nonero-Candela,\nFoivos\nTsimpourlas,\nMichael\nSharman, Meghan Shah, Andrea Vallone, Alex Beutel,\net al.\nHealthbench: Evaluating large language models\ntowards improved human health.\narXiv:2505.08775,\n2025.\n[Bai et al., 2024] Ge Bai, Jie Liu, Xingyuan Bu, Yancheng\nHe, Jiaheng Liu, Zhanhui Zhou, Zhuoran Lin, Wenbo Su,\nTiezheng Ge, Bo Zheng, et al. MT-Bench-101: A fine-\ngrained benchmark for evaluating large language models\nin multi-turn dialogues. arXiv:2402.14762, 2024.\n[Brush and Brophy, 2017] John E. Brush and James M. Bro-\nphy. Sharing the process of diagnostic decision making.\nJAMA Internal Medicine, 177(9):1245, September 2017.\n[Cabral et al., 2024] Stephanie Cabral, Daniel Restrepo, Za-\nhir Kanjee, Philip Wilson, Byron Crowe, Raja-Elie Ab-\ndulnour, and Adam Rodman. Clinical reasoning of a gen-\nerative artificial intelligence model compared with physi-\ncians. JAMA internal medicine, 184(5):581–583, 2024.\n[Chen et al., 2025] Simin Chen, Yiming Chen, Zexin Li, Yi-\nfan Jiang, Zhongwei Wan, Yixin He, Dezhi Ran, Tianle\nGu, Haizhou Li, Tao Xie, and Baishakhi Ray. Recent ad-\nvances in large langauge model benchmarks against data\ncontamination: From static to dynamic evaluation, 2025.\n[Chiu et al., 2025] Christopher Chiu, Silviu Pitis, and Mi-\nhaela van der Schaar. Simulating Viva voce examinations\nto evaluate clinical reasoning in large language models.\narXiv:2510.10278, 2025.\n[Croxford et al., 2025] Emma Croxford, Yanjun Gao, Elliot\nFirst, Nicholas Pellegrino, Miranda Schnier, John Caskey,\nMadeline Oguss, Graham Wills, Guanhua Chen, Dmitriy\nDligach, et al.\nEvaluating clinical ai summaries with\nlarge language models as judges. npj Digital Medicine,\n8(1):640, 2025.\n[DeepSeek-AI et al., 2024] DeepSeek-AI, Aixin Liu, Bei\nFeng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda\nLu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang,\nChong Ruan, Damai Dai, Daya Guo, Dejian Yang, Deli\nChen, Dongjie Ji, Erhang Li, Fangyun Lin, Fucong Dai,\nFuli Luo, Guangbo Hao, Guanting Chen, Guowei Li,\nH. Zhang, and Han Bao et al. DeepSeek-V3 technical re-\nport, 2024.\n[Falcetta et al., 2023] Frederico\nSoares\nFalcetta,\nFer-\nnando Kude De Almeida, Jana´ına Conceic¸˜ao Sutil Lemos,\nJos´e Roberto Goldim, and Cristiano Andr´e Da Costa. Au-\ntomatic documentation of professional health interactions:\nA systematic review. Artificial Intelligence in Medicine,\n137:102487, March 2023.\n[Fu et al., 2025] Zhihui Fu, Yuhong Wu, Lingling Xu, Fen\nCai, Ren Liu, and Zhehan Jiang.\nOptimizing cost-\neffectiveness in remote objective structured clinical exam-\ninations through targeted double scoring methodologies.\nMedical Education Online, 30(1), 2 2025.\n[Goh et al., 2024] Ethan Goh, Robert Gallo, Jason Hom,\nEric Strong, Yingjie Weng, Hannah Kerman, Jos´ephine A\nCool, Zahir Kanjee, Andrew S Parsons, Neera Ahuja,\net al. Large language model influence on diagnostic rea-\nsoning: a randomized clinical trial. JAMA network open,\n7(10):e2440969–e2440969, 2024.\n[Gruppen et al., 1991] Larry D. Gruppen, Fredric M. Wolf,\nand John E. Billi. Information gathering and integration\nas sources of error in diagnostic decision making. Medical\nDecision Making, 11(4):233–239, 1991.\n[Guo et al., 2025] Daya Guo, Dejian Yang, Haowei Zhang,\nJunxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shi-\nrong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: In-\ncentivizing reasoning capability in llms via reinforcement\nlearning. arXiv:2501.12948, 2025.\n[Huang et al., 2025] Quankeng Huang, Yuqi Tang, Hao Li,\nYang Yu, Zhihua Wang, Linfang Xiao, Wenchao Jiang,\nand Keyan Ding. Multi-dimensional perceptual quality as-\nsessment for magnetic resonance images. Health Informa-\ntion Science and Systems, 13(1):65, 2025.\n[Hurst et al., 2024] Aaron Hurst, Adam Lerer, Adam P\nGoucher, Adam Perelman, Aditya Ramesh, Aidan Clark,\nAJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford,\net al. GPT-4o system card. arXiv:2410.21276, 2024.\n[Jin et al., 2019] Qiao Jin, Bhuwan Dhingra, Zhengping Liu,\nWilliam W Cohen, and Xinghua Lu.\nPubMedQA:\nA dataset for biomedical research question answering.\narXiv:1909.06146, 2019.\n[Jin et al., 2020] Di Jin, Eileen Pan, Nassim Oufattole, Wei-\nHung Weng, Hanyi Fang, and Peter Szolovits.\nWhat\ndisease does this patient have?\na large-scale open do-\nmain question answering dataset from medical exams.\narXiv:2009.13081, 2020.\n[Johri et al., 2025] Shreya\nJohri,\nJaehwan\nJeong,\nBen-\njamin\nA\nTran,\nDaniel\nI\nSchlessinger,\nShannon\nWongvibulsin,\nLeandra\nA\nBarnes,\nHong-Yu\nZhou,\nZhuo Ran Cai, Eliezer M Van Allen, David Kim, et al. An\nevaluation framework for clinical use of large language\n"}, {"page": 9, "text": "models in patient interaction tasks.\nNature medicine,\n31(1):77–86, 2025.\n[Kung et al., 2023] Tiffany H Kung, Morgan Cheatham,\nArielle Medenilla, Czarina Sillos, Lorie De Leon, Camille\nElepa˜no, Maria Madriaga, Rimel Aggabao, Giezel Diaz-\nCandido, James Maningo, et al.\nPerformance of chat-\ngpt on usmle: potential for ai-assisted medical educa-\ntion using large language models.\nPLoS digital health,\n2(2):e0000198, 2023.\n[Liu et al., 2024] Mianxin Liu, Weiguo Hu, Jinru Ding, Jie\nXu, Xiaoyang Li, Lifeng Zhu, Zhian Bai, Xiaoming Shi,\nBenyou Wang, Haitao Song, et al. Medbench: A compre-\nhensive, standardized, and reliable benchmarking system\nfor evaluating chinese medical large language models. Big\nData Mining and Analytics, 7(4):1116–1128, 2024.\n[Liu et al., 2025] Zhaocheng\nLiu,\nQuan\nTu,\nWen\nYe,\nYu Xiao, Zhishou Zhang, Hengfu Cui, Yalun Zhu, Qiang\nJu, Shizheng Li, and Jian Xie.\nExploring the inquiry-\ndiagnosis relationship with advanced patient simulators.\narXiv:2501.09484, 2025.\n[McCoy et al., 2025] Liam G McCoy, Rajiv Swamy, Nid-\nhish Sagar, Minjia Wang, Stephen Bacchi, Jie Ming Nigel\nFong, Nigel CK Tan, Kevin Tan, Thomas A Buckley, Pe-\nter Brodeur, et al. Assessment of large language models\nin clinical reasoning: A novel benchmarking study. NEJM\nAI, 2(10):AIdbp2500120, 2025.\n[McDuff et al., 2025] Daniel McDuff, Mike Schaekermann,\nTao Tu, Anil Palepu, Amy Wang, Jake Garrison, Karan\nSinghal, Yash Sharma, Shekoofeh Azizi, Kavita Kulkarni,\net al. Towards accurate differential diagnosis with large\nlanguage models. Nature, pages 1–7, 2025.\n[Meta, 2025] Meta. Llama 4: Leading intelligence. unrivaled\nspeed and efficiency. the most accessible and scalable gen-\neration of llama is here., 2025.\n[Omiye et al., 2024] Jesutofunmi A. Omiye, Haiwen Gui,\nShawheen J. Rezaei, James Zou, and Roxana Daneshjou.\nLarge language models in medicine: The potentials and\npitfalls : A narrative review. Annals of Internal Medicine,\n177(2):210–220, February 2024.\n[OpenAI et al., 2025] OpenAI, Aaron Hurst, and et al. Gpt-5\nsystem card. Technical report, OpenAI, August 2025.\n[Pal et al., 2022] Ankit Pal, Logesh Kumar Umapathi, and\nMalaikannan Sankarasubbu. MEDMCQA: A large-scale\nmulti-subject multi-choice dataset for medical domain\nquestion answering. In Conference on health, inference,\nand learning, pages 248–260. PMLR, 2022.\n[Qiu et al., 2025a] Pengcheng Qiu, Chaoyi Wu, Shuyu Liu,\nWeike Zhao, Zhuoxia Chen, Hongfei Gu, Chuanjin Peng,\nYa Zhang, Yanfeng Wang, and Weidi Xie. Quantifying the\nreasoning abilities of LLMs on real-world clinical cases.\narXiv:2503.04691, 2025.\n[Qiu et al., 2025b] Pengcheng Qiu, Chaoyi Wu, Shuyu Liu,\nWeike Zhao, Zhuoxia Chen, Hongfei Gu, Chuanjin Peng,\nYa Zhang, Yanfeng Wang, and Weidi Xie. Quantifying the\nreasoning abilities of LLMs on real-world clinical cases,\nMarch 2025.\n[Tang et al., 2024] Xiangru Tang, Anni Zou, Zhuosheng\nZhang, Ziming Li, Yilun Zhao, Xingyao Zhang, Arman\nCohan, and Mark Gerstein. Medagents: Large language\nmodels as collaborators for zero-shot medical reasoning.\nIn Findings of the Association for Computational Linguis-\ntics: ACL 2024, pages 599–621, 2024.\n[Tang et al., 2025] Yuqi Tang, Kehua Feng, Yunfeng Wang,\nZhiwen Chen, Chengfei Lv, Gang Yu, Qiang Zhang, and\nKeyan Ding.\nLearning an efficient multi-turn dialogue\nevaluator from multiple judges. arXiv:2508.00454, 2025.\n[Team et al., 2023] Gemini Team, Rohan Anil, Sebastian\nBorgeaud, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut,\nJohan Schalkwyk, Andrew M Dai, Anja Hauth, Katie Mil-\nlican, et al. Gemini: a family of highly capable multimodal\nmodels. arXiv:2312.11805, 2023.\n[Wilcox, 2012] Rand R Wilcox. Introduction to robust esti-\nmation and hypothesis testing. Academic press, 2012.\n[Wu et al., 2025] Kevin Wu, Eric Wu, Rahul Thapa, Kevin\nWei,\nAngela Zhang,\nArvind Suresh,\nJacqueline J.\nTao, Min Woo Sun, Alejandro Lozano, and James\nZou.\nMedCaseReasoning:\nEvaluating and learning\ndiagnostic reasoning from clinical case reports, 2025.\narXiv:2505.11733.\n[xAI and et al, 2025] xAI and et al. Grok 4.1 model card.\nTechnical report, xAI, November 2025.\n[Xu et al., 2024] Cheng Xu, Shuhao Guan, Derek Greene,\nand M-Tahar Kechadi. Benchmark data contamination of\nlarge language models: A survey, 2024.\n[Yang et al., 2025] An Yang, Anfeng Li, Baosong Yang, Be-\nichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang\nGao, Chengen Huang, Chenxu Lv, Chujie Zheng, Dayi-\nheng Liu, Fan Zhou, Fei Huang, Feng Hu, Hao Ge, Hao-\nran Wei, Huan Lin, Jialong Tang, Jian Yang, Jianhong Tu,\nJianwei Zhang, et al. Qwen3 technical report, 2025.\n[Yu et al., 2024] Huizi Yu, Jiayan Zhou, Lingyao Li, Shan\nChen, Jack Gallifant, Anye Shi, Xiang Li, Jingxian He,\nWenyue Hua, Mingyu Jin, et al. Simulated patient systems\nare intelligent when powered by large language model-\nbased ai agents. arXiv:2409.18924, 2024.\n[Yu et al., 2025a] Jing\nYu,\nYuqi\nTang,\nKehua\nFeng,\nMingyang Rao, Lei Liang, Zhiqiang Zhang, Mengshu\nSun, Wen Zhang, Qiang Zhang, Keyan Ding, et al.\nSciCUEval:\nA comprehensive dataset for evaluating\nscientific context understanding in large language models.\narXiv:2505.15094, 2025.\n[Yu et al., 2025b] Yuechun Yu, Han Ying, Haoan Jin, Wen-\njian Jiang, Dong Xian, Binghao Wang, Zhou Yang, and\nMengyue Wu. MedKGEval: A knowledge graph-based\nmulti-turn evaluation framework for open-ended patient\ninteractions with clinical LLMs. arXiv:2510.12224, 2025.\n[Zhang et al., 2025] Xiangxu Zhang, Lei Li, Yanyun Zhou,\nXiao Zhou, Yingying Zhang, and Xian Wu. Inflated excel-\nlence or true performance? rethinking medical diagnostic\nbenchmarks with dynamic evaluation. arXiv:2510.09275,\n2025.\n"}, {"page": 10, "text": "[Zhao et al., 2023] Zhengyun Zhao, Qiao Jin, Fangyuan\nChen, Tuorui Peng, and Sheng Yu. A large-scale dataset\nof patient summaries for retrieval-based clinical decision\nsupport systems. Scientific data, 10(1):909, 2023.\n[Zuo et al., 2025] Yuxin Zuo, Shang Qu, Yifei Li, Zhangren\nChen, Xuekai Zhu, Ermo Hua, Kaiyan Zhang, Ning Ding,\nand Bowen Zhou. MedXpertQA: Benchmarking expert-\nlevel medical reasoning and understanding, 2025.\n"}, {"page": 11, "text": "Appendix\nA1\nLimitations\nWhile ClinDEF offers a robust dynamic framework for eval-\nuating LLMs, it has several limitations.\nFirst, to sup-\nport dynamic evaluation and prevent test-set contamination,\nthe framework’s reliance on synthetically generated patient\ncases, while crucial for control and privacy, cannot fully repli-\ncate the complexity and unpredictability of real-world clini-\ncal scenarios. Second, the evaluation is conducted in a purely\ntext-based environment (using textual descriptions of imag-\ning rather than raw multi-modal inputs), which abstracts away\nthe critical multi-modal aspects of diagnosis. Future work\nshould aim to bridge this gap by incorporating more varied\nand complex case structures and exploring the integration of\nmulti-modal data, such as medical imaging, to create a more\nholistic assessment of clinical reasoning capabilities.\nA2\nMore Results on ClinDEF\nTable A1 shows the overall Diagnostic Quality Score and\nfine-grained results across seven clinical reasoning dimen-\nsions. Figure A1 presents the quantitative evaluation results\nof 15 LLMs on ClinDEF across three diagnostic metrics.\nA3\nLLM-as-a-Judge Evaluation and\nValidation\nLLM-as-a-Judge: To obtain a stable and unbiased estimate\nof diagnostic quality, we employ five state-of-the-art (SOTA)\nLLMs as judges, namely GPT-5.1 [OpenAI et al., 2025],\nClaude-Sonnet-4.5 [Anthropic, 2025], Gemini-3-Pro [Team\net al., 2023], Grok-4.1 [xAI and et al, 2025], Deepseek-\nV3.2 [DeepSeek-AI et al., 2024]. Notably, to mitigate evalu-\nator overfitting and self-preference, where an LLM evaluator\ntends to assign disproportionately higher scores to its own\noutputs than to others’, even when human evaluators would\nrate them equivalently, we deliberately select five SOTA\nLLMs distinct from those used as Doctor Agents [Tang et\nal., 2025]. Each judge is guided by a standardized evaluation\ntemplate (see Appendix A9), which requires them to output\nscores across seven fine-grained dimensions in a uniform for-\nmat, i.e., CCE, HC, ECI, TJ, DDx, DC, DU.\nAfter obtaining scores from all five LLM judges, we adopt\na Trimmed Mean aggregation strategy [Wilcox, 2012] to fur-\nther ensure the robustness of our results. For each dimension,\nwe discard the highest and lowest of the five LLM-assigned\nscores and compute the mean over the remaining three val-\nues. This method substantially reduces biases from any sin-\ngle judge and mitigates the impact of extreme cases, yielding\nmore robust and reliable assessments.\nHuman Expert Validation: To validate the reliability of the\nLLM-as-a-Judge procedure, we recruited three experts in the\nclinical decision-making, including two licensed physicians\nand one PhD student with formal training in clinical diagno-\nsis. The samples were stratified to ensure coverage across\ndiverse disease categories and varying levels of reasoning\ncomplexity, and all evaluators followed the same standardized\nprompts used for LLM judges. Compensation was provided\nat a rate of $15 per 10 cases reviewed, totaling $675 for 450\nannotated diagnostic cases. The entire expert review process\nwas completed within two days [Yu et al., 2025a].\nWe then quantify the correlation between model-generated\nscores and human expert ratings via Pearson and Spearman\ncoefficients.\nAcross all experts, Pearson correlations fell\nwithin 0.80–0.87, while Spearman correlations ranged from\n0.81–0.86, indicating consistently strong agreement. These\nresults demonstrate the robustness of LLM-as-a-Judge in our\nframework and can be effectively utilized for assessing diag-\nnostic reasoning quality.\nA4\nData Quality Verification\nTo further ensure the validity of the simulated diagnostic\nenvironment, we invited five licensed clinicians with di-\nverse medical specialties to participate in the evaluation: two\nattending physicians in internal medicine, one emergency\nmedicine physician, and two doctoral researchers with for-\nmal clinical diagnostic training. All clinicians had prior ex-\nperience reviewing structured medical cases and received sys-\ntematic training on our evaluation protocol. Each clinician in-\ndependently evaluated the same set of 200 randomly sampled\nsimulated cases and followed standard annotation guidelines\n(see Appendix A9). For each case, they assessed two key\ncriteria:\n• Information Leakage: Whether the confirmed diagno-\nsis was directly disclosed by the Patient or Examiner\nAgent before the Doctor Agent reached a diagnosis.\n• Clinical Fidelity: Whether the Patient and Examiner\nAgent’s outputs aligned with the disease’s characteristic\nclinical features and established medical reasoning.\nEach expert received $15 for every 20 cases reviewed, yield-\ning a total expenditure of $750 for the evaluation of all 200\ncases.\nThe review was completed over a five-day period.\nTo synthesize the five clinicians’ assessments, we applied a\nmajority-voting scheme [Bai et al., 2024] to obtain consensus\nannotations. Based on the aggregated labels, 99.0% of cases\nshowed no information leakage, and 93.5% were judged clin-\nically coherent and realistic. These findings confirm the relia-\nbility of the Patient and Examiner Agent outputs and demon-\nstrate the robustness of our knowledge-grounded simulation\npipeline.\nA5\nDetails for Diagnostic Quality Score\nThe definition of seven dimensions in the Diagnostic Quality\nScore (DQS) is:\n• Chief Complaint Exploration (CCE): The extent to\nwhich the agent systematically elicits and structures\nsymptom characteristics (onset, quality, location, sever-\nity, timing, aggravating/relieving factors, associated\nsymptoms) and identifies at least one clinical red flag\nwarranting urgent attention.\n• History Completeness (HC): The comprehensiveness\nand clinical relevance of collected patient history, in-\ncluding present illness, past medical/surgical history,\nmedications, allergies, family history, and social deter-\nminants — with explicit linkage to the diagnostic hy-\npothesis.\n"}, {"page": 12, "text": "Table A1: Overall Diagnostic Quality Score and Fine-Grained Performance Across Seven Clinical Reasoning Dimensions.\nModel\nCCE\nHC\nECI\nTJ\nDDx\nDC\nDU\nDQS ↑\nGemini-2.5-Pro\n5.2 ± 0.1\n2.6 ± 0.1\n18.1 ± 0.2\n9.3 ± 0.1\n8.0 ± 0.0\n24.0 ± 0.4\n2.7 ± 0.1\n70.0 ± 0.8\nGPT-5-mini\n5.6 ± 0.1\n2.9 ± 0.1\n17.5 ± 0.1\n8.9 ± 0.0\n8.1 ± 0.1\n22.5 ± 0.6\n4.0 ± 0.1\n69.5 ± 0.7\nGPT-4.1-mini\n6.2 ± 0.0\n3.4 ± 0.1\n17.2 ± 0.2\n8.6 ± 0.1\n6.8 ± 0.1\n23.3 ± 0.3\n3.1 ± 0.1\n68.6 ± 0.4\nGPT-4.1\n5.6 ± 0.1\n3.1 ± 0.1\n17.1 ± 0.2\n8.5 ± 0.1\n7.5 ± 0.1\n22.4 ± 0.4\n2.5 ± 0.1\n66.7 ± 0.7\nClaude-Sonnet-4\n6.3 ± 0.0\n3.1 ± 0.1\n16.9 ± 0.1\n8.0 ± 0.2\n7.2 ± 0.0\n21.8 ± 0.4\n2.1 ± 0.1\n65.2 ± 0.7\nDeepSeek-V3\n5.5 ± 0.0\n2.9 ± 0.1\n16.1 ± 0.4\n8.4 ± 0.1\n7.1 ± 0.1\n21.3 ± 0.6\n2.6 ± 0.1\n63.9 ± 1.2\nLlama-4-Maverick\n5.4 ± 0.1\n3.2 ± 0.1\n16.8 ± 0.2\n8.4 ± 0.1\n5.7 ± 0.1\n21.5 ± 0.8\n2.7 ± 0.1\n63.7 ± 1.0\nGPT-5-nano\n4.8 ± 0.1\n2.8 ± 0.1\n16.8 ± 0.2\n8.9 ± 0.1\n6.0 ± 0.1\n20.8 ± 0.5\n3.4 ± 0.0\n63.5 ± 0.7\nGPT-4o\n5.1 ± 0.1\n3.7 ± 0.1\n15.6 ± 0.4\n8.0 ± 0.1\n6.1 ± 0.2\n19.6 ± 0.6\n2.3 ± 0.1\n60.4 ± 1.1\nDeepSeek-R1\n4.1 ± 0.0\n2.4 ± 0.0\n15.3 ± 0.3\n8.1 ± 0.2\n7.5 ± 0.1\n20.3 ± 0.4\n2.1 ± 0.0\n59.8 ± 0.6\nQwen3-235B-A22B\n5.5 ± 0.1\n2.6 ± 0.1\n15.2 ± 0.4\n8.0 ± 0.1\n6.1 ± 0.1\n19.0 ± 0.4\n2.1 ± 0.0\n58.4 ± 0.7\nQwen3-Next-80B-A3B\n5.0 ± 0.0\n2.5 ± 0.1\n13.9 ± 0.2\n7.5 ± 0.1\n7.4 ± 0.1\n18.7 ± 0.5\n2.1 ± 0.0\n57.0 ± 0.7\nLlama-4-Scout\n5.6 ± 0.0\n3.2 ± 0.1\n14.7 ± 0.4\n7.7 ± 0.1\n4.9 ± 0.1\n18.3 ± 0.4\n2.0 ± 0.1\n56.4 ± 0.8\nQwen3-8B\n5.1 ± 0.0\n2.7 ± 0.1\n13.7 ± 0.2\n7.7 ± 0.1\n6.3 ± 0.1\n16.9 ± 0.4\n2.3 ± 0.0\n54.7 ± 0.6\nQwen2.5-7B\n5.2 ± 0.0\n3.8 ± 0.1\n12.7 ± 0.1\n7.4 ± 0.1\n5.4 ± 0.1\n15.9 ± 0.3\n2.4 ± 0.0\n52.7 ± 0.4\nFigure A1: Performance comparison of 15 LLMs across three key metrics on ClinDEF: Diagnostic Accuracy, Diagnostic Quality Score, and\nDiagnostic Efficiency (Dialogue turns).\n• Evidence Chain Integrity (ECI): The logical traceabil-\nity of each diagnostic assertion to documented clinical\nfindings (symptoms, signs, or test results), ensuring no\nunsupported inferential leaps or subjective speculation.\n• Test Justification (TJ): The appropriateness and clin-\nical rationale for ordering diagnostic tests, evaluated\nagainst guideline-based indications, risk stratification,\nand avoidance of under- or over-utilization.\n• Differential Diagnosis (DD): The breadth, clinical plau-\nsibility, and prioritization of alternative diagnoses —\nparticularly inclusion and explicit reasoning for high-\nrisk, treatable conditions that must be ruled out.\n• Diagnostic Correctness (DC): The alignment of the fi-\nnal diagnosis with available clinical evidence and estab-\nlished guidelines, incorporating appropriate qualifiers\n(e.g., “preliminary,” “suspected”) when certainty is lim-\nited, and avoiding contradictions with objective findings.\n• Diagnostic Uncertainty (DU): The agent’s explicit ac-\nknowledgment of diagnostic or prognostic uncertainty,\ncoupled with a concrete follow-up or verification plan,\nand documented communication of risks to the patient.\n"}, {"page": 13, "text": "Table A2: Summary of the LLMs assessed in our ClinDEF framework.\nModel Name\nCreator\n#Parameters\nAccess\nURL\nGPT-5-mini\nOpenAI\nundisclosed\nOfficial API\nhttps://chat.openai.com\nGPT-5-nano\nOpenAI\nundisclosed\nOfficial API\nhttps://chat.openai.com\nGPT-4.1\nOpenAI\nundisclosed\nOfficial API\nhttps://chat.openai.com\nGPT-4.1-mini\nOpenAI\nundisclosed\nOfficial API\nhttps://chat.openai.com\nGPT-4o\nOpenAI\nundisclosed\nOfficial API\nhttps://chat.openai.com\nClaude-4-Sonnet\nAnthropic\nundisclosed\nOfficial API\nhttps://claude.ai\nGemini-2.5-Pro\nGoogle\nundisclosed\nOfficial API\nhttps://gemini.google.com\nDeepSeek-V3\nDeepSeek\n671B(MoE)\nOfficial API\nhttps://www.deepseek.com\nDeepSeek-R1\nDeepSeek\n671B(MoE)\nOfficial API\nhttps://www.deepseek.com\nQwen2.5-7B-Instruct\nAlibaba\n7B\nWeights\nhttps://qwenlm.github.io\nQwen3-8B\nAlibaba\n8B\nWeights\nhttps://qwenlm.github.io\nQwen3-235B-A22B\nAlibaba\n235B(MoE)\nAlibabaCloud API\nhttps://qwenlm.github.io\nQwen3-Next-80B-A3B\nAlibaba\n80B(MoE)\nAlibabaCloud API\nhttps://qwenlm.github.io\nLlama-4-Scout\nMeta\n109B(MoE)\nNVIDIA NIM API\nhttps://www.llama.com/models/llama-4/\nLlama-4-Maverick\nMeta\n400B(MoE)\nNVIDIA NIM API\nhttps://www.llama.com/models/llama-4/\nA6\nDetailed Model Descriptions\nWe have selected 15 high-performing LLMs with varying\nscales for this paper. Qwen2.5-7B-Instruct and Qwen3-8B\nare deployed locally on a 2 NVIDIA 4090 GPUs. All All re-\nmaining models are accessed via their official APIs, with in-\nference hyperparameters fixed to temperature = 0.0 and top-\np = 1.0 to ensure deterministic generation. Detailed model\nspecifications are summarized in Table A2.\nA7\nUse of Large Language Models\nWe acknowledge the use of generative AI in this work.\nSpecifically,\nwe employed LLMs for the knowledge-\ngrounded synthesis of patient cases as described in Section\n3.1. LLMs were also used to instantiate the Patient and Ex-\naminer agents within our multi-agent simulation environment\n(Section 3.2) and to conduct the quantitative assessment of\ndiagnostic quality in our ”LLM-as-a-Judge” paradigm (Sec-\ntion 3.3). Finally, generative AI provided editorial assistance\nduring the preparation of this manuscript.\nA8\nPatient Profile Example\nCase Profile\nDemographics\n• Age: 35 years\n• Gender: Female\n• Occupation: Homemaker\n• Lifestyle:\nNon-smoker, occasional alcohol con-\nsumption\nPast Medical History\n• Previously diagnosed with pituitary adenoma.\n• History of severe postpartum hemorrhage compli-\ncated by hypovolemic shock, requiring blood trans-\nfusion and surgical intervention.\n• Currently on long-term hormone replacement ther-\napy:\n– Levothyroxine for hypothyroidism\n– Hydrocortisone for adrenal insufficiency\nFamily History\n• No significant family history of endocrine or pitu-\nitary disorders.\nPresenting Symptoms\n• Persistent fatigue and lethargy\n• Unexplained progressive weight gain\n• Secondary amenorrhea and decreased libido\n• Postpartum lactation failure\n• Intermittent headaches\nLaboratory Findings\n• Thyroid-Stimulating Hormone (TSH): Low\n• Free Thyroxine (FT4): Normal\n• Free Triiodothyronine (FT3): Normal\n• Prolactin (PRL): Elevated, with increased macro-\nprolactin (macro-PRL) fraction\nImaging\n• Pituitary MRI demonstrates reduced gland size\nwith heterogeneous signal intensity, findings sug-\ngestive of pituitary adenoma or sequelae of is-\nchemic injury.\n"}, {"page": 14, "text": "Table A3: Rubric for Diagnostic Quality Evaluation\nDimension (Max)\nScore Criteria\nChief Complaint\nExploration (10)\n10: Systematically explores main symptom characteristics (onset, severity, timing, as-\nsociated features)\n6: Covers most symptom aspects but misses minor details or one relevant red flag\n4: Records patient’s words without clarification of vague descriptions\n2: Generic description, omits multiple key symptom features\n0: Misses urgent symptoms requiring immediate attention\nHistory\nCompleteness (10)\n10: All major components addressed (Present Illness, Past History, Medications, Aller-\ngies, Family, Social) with adequate detail\n8: 4–5 components addressed with reasonable detail\n6: 3 components addressed, some details missing\n4: 2 components addressed, minimal details\n2: 1 component addressed\n0: No history details collected\nEvidence Chain\nIntegrity (20)\n20: All clinical judgments fully supported by documented evidence; reasoning is com-\nplete\n15: One judgment weakly supported\n10: Key diagnostic hypothesis lacks supporting evidence\n5: Contains unsupported subjective inferences\n≤2: Multiple conclusions lack objective basis or use non-evidence-based language\nTest\nJustification (10)\n10: Ordered tests match differential, follow guidelines, core tests included, indications\nclearly stated\n8: One test indication unclear or low-priority test delayed\n6: Over- or under-utilization of tests\n4: Tests weakly related to complaint or purpose not stated\n≤2: Test combination illogical or omits critical tests\nDifferential\nDiagnosis (10)\n10: ≥3 plausible diagnoses, includes must-not-miss, ranked by probability with ratio-\nnale\n8: 3 diagnoses listed but ranking or rationale insufficient\n6: Only 2 diagnoses, critical condition omitted\n3–5: Only 1 diagnosis or clinically implausible\n≤3: No differential or red-flag condition omitted\nDiagnostic\nCorrectness (30)\n30: Final diagnosis fully consistent with all evidence and guideline-aligned\n20–29: Correct but lacks confidence statement, partial ruling-out, or “preliminary” la-\nbel\n15–20: Primary diagnosis correct but misses comorbidity or part of reasoning unsup-\nported\n10–15: Partially incorrect or vague, no high-risk missed\n5–9: Contradicts key signs/tests or ignores red-flag\n0–4: Severely incorrect, could cause serious harm\nDiagnostic\nUncertainty (10)\n10: Explicitly acknowledges uncertainty, provides clear verification plan, communi-\ncates risks to patient\n7: Mentions uncertainty with plan but lacks specifics\n5–6: Uses vague terms without clear action\n3–4: Conceals uncertainty using absolute statements\n≤2: No mention of uncertainty or provides false reassurance\nA9\nDetailed Prompts\nPrompt for Generating Case Profile\nPlease generate a structurally rigorous, clinically\nauthentic, and medically educationally compliant\n“Standardized Patient Case” based on the follow-\ning disease description. The case must only contain\nthe following six specified sections. It is strictly pro-\nhibited to include diagnostic conclusions or treatment\nrecommendations.\n1. Basic Information\n• Age and Gender: Set reasonably based on the\nepidemiological characteristics of the disease\n(e.g., common age of onset, gender predispo-\n"}, {"page": 15, "text": "sition, genetic pattern).\n• Occupation/Status, Marital Status, Place of\nResidence: Be concise (1–2 sentences).\n• Family Genetic History (if applicable): Spec-\nify kinship (e.g., “father,” “aunt”), specific\ndisease manifestations, and age of onset.\n2. Past Medical History & Personal History\n• Past major illnesses, surgeries, trauma, infec-\ntion history (briefly described in chronologi-\ncal order).\n• Allergy history (drug/food/environmental),\nvaccination history (key vaccines only).\n• Personal living habits:\nSmoking/alcohol\n(amount and duration), exercise capacity, diet\nroutine, etc.\n• History of growth and development or psy-\nchosocial history (if disease-related, briefly\ndescribe key events or states).\n3. Chief Complaint and History of Present Illness\n• Chief Complaint: Describe in the patient’s\nfirst-person tone, not exceeding 20 words,\nfocusing on the most significant discomfort\n(e.g., “I have had chest tightness and pain for\ntwo weeks”).\n• History of Present Illness: Narrate along the\ntimeline—time of onset, possible triggers,\nsymptom evolution process (including key\ntime points), aggravating/alleviating factors,\nand current functional status. Must reflect the\nnatural course of the disease.\n4. Symptom List (Structured Presentation)\n• Each symptom must include the following\nthree elements:\n– Category (e.g., local signs, pain charac-\nteristics, functional impairment, systemic\nsymptoms, etc.)\n– Specific Manifestation (including details\nsuch as location, nature, intensity, fre-\nquency, duration, etc.)\n– Dynamic Trend (progressively worsening\n/ gradually alleviating / remaining stable)\n5. Physical Examination Summary (Described by\nSystems)\n• List only key positive signs and negative\nsigns of differential significance. Briefly de-\nscribe according to the following four cate-\ngories:\n– Inspection:\nAppearance abnormalities,\nskin changes, masses, deformities, etc.\n– Palpation:\nTenderness, texture, bound-\naries, mobility, temperature, etc.\n– Motion Examination: Range of motion of\njoints, muscle strength grading, reflex sta-\ntus, coordination, etc.\n– Measurement: Lesion size, quantity, pre-\ncise anatomical location (if applicable).\n6. Auxiliary\nExamination\nResults\n(Simulating\nReal Reports)\n• List completed key examinations and their\nobjective, quantitative results.\nEnsure they\nalign with the typical manifestations of the\ndisease:\n– Imaging: X-ray/MRI/CT/Ultra\nsound, etc. (include key descriptions)\n– Laboratory Tests: Complete blood count,\nbiochemical\nindicators,\ninflammation\nmarkers, tumor markers, etc.\n(provide\nqualitatively, no specific numerical values\nneeded)\n– Pathological/Genetic\nTesting\n(if\nper-\nformed): Histological description or name\nof gene mutation\n– Other Specialized Examinations:\ne.g.,\nnerve\nconduction\nvelocity,\npulmonary\nfunction tests, electrocardiogram, etc. (in-\nclude key parameters)\nAll content must be clinically authentic, with specific\ndata, and logically self-consistent. Fabrication of di-\nagnoses or treatments is prohibited.\nPrompt for Standardized Patient (Initial Presenta-\ntion)\nYou\nare\na\nstandardized\npatient\nwho\nfirmly\nbelieves\nyou\nhave\nthe\nfollowing\nillness:\n{disease description}.\nBased on this disease, simulate your first verbal\ncomplaint when meeting the doctor — designed to\ntest the physician’s diagnostic ability.\nInstructions:\n1. State only 1–2 main symptoms. Keep it simple\nand brief.\n2. Do not reveal the diagnosis. Avoid disease names\nor textbook terms.\n3. Only 1–2 sentences max.\nPreferably just one\nshort, natural sentence.\n4. Use colloquial, everyday language — as a real\npatient would speak. No medical jargon.\n5. Withhold all other symptoms. Wait for the doc-\ntor to ask follow-up questions.\nExample:\n“I’ve had this nasty cough for over a week and I’m\nreally tired all the time.”\n"}, {"page": 16, "text": "Prompt for Doctor Agent\nYou are a professional physician. Based on the pa-\ntient’s consultation record, you must make a clinical\njudgment. Your goal is to simulate a routine outpa-\ntient visit: rule out similar diseases and diagnose the\npatient’s condition. You may choose from the follow-\ning actions:\n1. Ask the patient for information, formatted as:\n[!Ask!](your question) — only one question per\nturn.\n2. Perform a physical examination, formatted as:\n[!Exam!](the specific physical exam item you\nneed) — only one item per turn.\n3. Order an auxiliary test, formatted as: [!Test!](the\nspecific test you require) — only one test per turn.\n4. Provide a diagnosis, formatted as:\n[!Diagno-\nsis!](your diagnosis) — must be a single, specific\ndisease name.\nYou may perform only one action per turn. Once you\nissue a diagnosis, it will be considered your final an-\nswer, and you will no longer be able to ask additional\nquestions or order further tests.\nYou must think before answering. Please strictly fol-\nlow the response format below:\nThought: (your reasoning process)\nAction: [!Ask!](your question) OR [!Exam!](your physi-\ncal exam item)OR [!Test!](your test request) OR [!Diagno-\nsis!](your diagnosis)\nConsultation record as follows: {chat history}\nBased on this information, provide your thought and ac-\ntion. You may ask only one question or request only one\ntest/exam.\nPrompt for Medical Examiner Agent\nYou are a medical technologist. Your task is to gener-\nate examination result reports based on the clinician’s\nrequested tests, the disease encyclopedia description,\nand existing patient information — combined with\nyour own medical knowledge of the disease.\nThe\npatient’s\ndisease\ndescription\nis:\n{self.disease description}\nThe\nexamination(s)\nrequested\nby\nthe\ndoctor:\n{doctor examination}\nFor any examination lacking specific data, you must\nrespond in the format of a professional hospital lab-\noratory or diagnostic report. Based on the requested\nexamination and your understanding of the disease,\nprovide a medically plausible result description.\nGuidelines:\n1. Respond directly to the doctor’s request — no ad-\nditional information.\n2. Describe results objectively. Do not include bi-\nased interpretations, disease names, or treatment\nsuggestions.\n3. For numerical results, only indicate: normal, ele-\nvated, or reduced — do not provide exact values.\n4. For examinations unrelated to the disease, respond\nwith “normal”.\n5. Strictly follow the output format:\n[!Positive!](your result)\nor\n[!Negative!](your\nresult)\n6. Format your response as a professional hospital\nexamination report. Include only the result for the\ncurrent test item — no extraneous content.\n7. If multiple tests are requested, respond to each one\nseparately, one per line. Example:\n[!Positive!](ECG result:\nSinus rhythm, normal\nheart rate.)\n[!Negative!](C-reactive protein:\nWithin normal\nrange.)\nPrompt for Patient Agent\nYou\nare\nan\nstandardized\npatient\nwho\nfirmly\nbelieves\nyou\nhave\nthe\nfollowing\nillness:\n{disease description}.\nBased on this disease description, carefully consider\nyour symptoms and respond to the doctor’s question:\n{doctor question}.\nPlease follow these principles when answering:\n1. Your answer should directly respond to the doc-\ntor’s question. Simulate a real patient’s response\nas realistically as possible, to evaluate the doctor’s\nclinical competence.\n2. Only answer the current question — no extra in-\nformation. Avoid overly professional or obscure\nlanguage. Do not include any irrelevant content.\n3. Do not copy verbatim from the disease description\nabove. Express your symptoms in colloquial, ev-\neryday, and layperson-friendly language.\n4. If the doctor asks multiple questions at once, an-\nswer each one separately. Each answer must fol-\nlow the above principles.\n5. You must respond according to the doctor’s spe-\ncific request. If your existing information does not\nfully match the request, improvise an appropriate\nresponse based on the question and your assumed\ncondition.\n6. Strictly follow the output format below:\n[!Positive!](your\nresponse)\nor\n[!Nega-\ntive!](your response)\n"}, {"page": 17, "text": "First, judge whether the doctor’s question is rel-\nevant to your disease and whether the symptom\nmentioned applies to you.\nIf relevant, begin with\n[!Positive!].\nIf not relevant, begin with\n[!Negative!]. Then state your response in nat-\nural language.\nFor multiple questions, respond to each on a separate\nline. Example:\n[!Positive!](I feel a bit of pain in my chest.)\n[!Negative!](I don’t feel dizzy at all.)\nPrompt for Diagnostic quality evaluation\nYou are a senior clinical expert with over 15 years of\nclinical experience. You are now appointed to con-\nduct a rigorous professional evaluation of the follow-\ning doctor’s consultation record and clinical reason-\ning process. Your scoring will be used for medical\nquality retrospective analysis and case review, and\nyou must ensure that the scoring criteria are aligned\nwith clinical practice requirements.\nPlease score the consultation content item by item ac-\ncording to the following 7 dimensions. Each score\nmust be an integer and determined based on clear evi-\ndence of clinical behavior. The basis for scoring must\nstrictly follow the standards listed below, without any\nlenient interpretation or subjective inference.\nOutput Format Requirements:\n- Output only standard JSON. The field order and\nstructure must be strictly as follows, with no com-\nments, line breaks, or extra text:\n{\n\"Depth of Chief Complaint Inquiry\":\nscore,\n\"Completeness of Medical History\":\nscore,\n\"Integrity of Evidence Chain\":\nscore,\n\"Appropriateness of Examinations\":\nscore,\n\"Differential Diagnosis\": score,\n\"Diagnostic Accuracy\": score,\n\"Uncertainty Management\": score\n}\nScoring Dimensions and Attainment\nStandards:\n1. Depth of Chief Complaint Inquiry (Max 10\npoints)\n• 10 points: Structurally collected symptom\ncharacteristics (onset, nature, location, in-\ntensity, triggers, relieving factors, associated\nsymptoms), and identified at least one ”red\nflag” sign (e.g., chest pain with cold sweats,\nheadache with altered consciousness).\n• 6 points: Covered basic symptom elements\nbut did not systematically inquire about spe-\ncific features or failed to identify red flags.\n• 4 points: Only recorded the patient’s own\nwords without clarifying vague descriptions\n(e.g., ”stomach discomfort” without specify-\ning location/nature).\n• 2 points: The description of the chief com-\nplaint is general, omitting key symptom di-\nmensions.\n• 0 points: Failed to identify symptoms requir-\ning emergency intervention (e.g., did not ask\nabout radiation for chest pain, or respiratory\ndistress at rest).\n• Deduction Triggers:\nFailure to actively\nprobe →max 3 points; Failure to record\nsymptom duration or frequency →max 2\npoints.\n2. Completeness of Medical History (Max 10\npoints)\n• Medical history includes: history of present\nillness, past medical history, medication his-\ntory, allergy history, family history, and social\nhistory. 2 points are awarded for each section\ncovered, up to a maximum of 10 points.\n3. Integrity of Evidence Chain (Max 20 points)\n• 20 points:\nEvery clinical judgment (e.g.,\n”considering infection,” ”leaning towards\ncardiogenic”) is supported by corresponding\nsymptoms, signs, or examination results. The\nreasoning chain is complete and logical.\n• 15 points:\nOne judgment is weakly sup-\nported by evidence (e.g., diagnosing ”pneu-\nmonia” without fever or lung auscultation\nrecords).\n• 10 points: Key diagnostic hypotheses lack\ndirect evidence (e.g., diagnosing ”cholecys-\ntitis” without recording Murphy’s sign).\n• 5 points: Subjective inferences are present\n(e.g., ”patient is anxious” without a HAMA\nscore or behavioral description).\n• ≤2 points: Multiple conclusions lack objec-\ntive basis, or non-evidence-based statements\nlike ”based on experience” or ”it feels like”\nare used.\n• Deduction Triggers: Using ”possibly” or\n”maybe” without noting the uncertainty →\nmax 3 points; Diagnosis contradicts recorded\ninformation →0 points.\n4. Appropriateness of Examinations (Max 10\npoints)\n"}, {"page": 18, "text": "• 10 points:\nExaminations are precisely\nmatched with differential diagnoses, comply\nwith clinical pathways/guidelines, no core\ntests are missed, no unnecessary over-testing,\nand indications for tests are clearly recorded.\n• 8 points: One test has an unclear indica-\ntion, or one low-priority test is delayed (e.g.,\nnot immediately checking amylase for gen-\neral abdominal pain).\n• 6 points: Obvious over-testing (e.g., ordering\nan MRI for a young patient with a headache\nwithout indications) or omission of high-risk\nscreening (e.g., not checking for pregnancy in\na woman of childbearing age with abdominal\npain).\n• 4 points: Tests are weakly related to the\nchief complaint or their clinical purpose is\nnot stated.\n• ≤2 points: The combination of tests is illog-\nical, or key tests for high-risk patients are not\nprioritized (e.g., not performing an ECG for\nchest pain).\n• Deduction Triggers: Failure to state the pur-\npose of a test →-1 point; Failure to arrange\ncore tests for a critical patient at the first visit\n→max 2 points.\n5. Differential Diagnosis (Max 10 points)\n• 10 points: Listed ≥3 reasonable differential\ndiagnoses, including ”highly lethal but treat-\nable” conditions (e.g., ACS, pulmonary em-\nbolism, stroke, ectopic pregnancy), ranked by\nclinical probability, with supporting or refut-\ning evidence for each.\n• 8 points: Listed 3 differential diagnoses but\nwithout ranking or with insufficient justifica-\ntion for exclusion.\n• 6 points:\nListed only 2 differential diag-\nnoses, failing to include a must-not-miss crit-\nical condition.\n• 3-5 points: Listed only 1 differential diagno-\nsis, or the differential is clearly unreasonable.\n• ≤3 points:\nNo differential diagnosis was\nmade, or a ”red flag” disease that must be\nruled out was missed.\n• Deduction Triggers: Failure to consider the\nmost dangerous diagnosis for the symptom\nspectrum (e.g., not considering subarachnoid\nhemorrhage for a headache) →0 points.\n6. Diagnostic Accuracy (Max 30 points)\n• 30 points: The final diagnosis is highly con-\nsistent with all clinical evidence, aligns with\nthe latest clinical guidelines, and has no logi-\ncal contradictions. If evidence is insufficient,\nit is clearly marked as a ”preliminary diagno-\nsis” or ”to be ruled out,” with justification.\n• 20-29 points: The diagnosis is correct but the\nconfidence level is not fully explained, key\ndifferentials are not systematically excluded,\nor the ”preliminary” status is not marked\nwhen evidence is slightly insufficient.\n• 15-20 points:\nThe diagnosis is generally\ncorrect but omits important comorbidities\nor complications (e.g., pneumonia without\nmentioning pleural effusion, diabetes without\nmentioning ketosis proneness), or some infer-\nences lack direct evidence.\n• 10-15 points: The diagnostic direction is par-\ntially incorrect or vague (e.g., misdiagnosing\n”cholecystitis” as ”gastritis”), but does not in-\nvolve missing a high-risk disease and does\nnot lead to significant clinical risk.\n• 5-9 points: The diagnosis contradicts key\npositive signs/test results (e.g., diagnosing\ngastritis when ECG suggests MI), or ignores\nred flags that must be addressed.\n• 0-4 points: The diagnosis is seriously wrong,\npotentially leading to life-threatening dan-\nger or irreversible harm (e.g., misdiagnos-\ning ”aortic dissection” as ”muscle strain,”\n”ectopic pregnancy” as ”irregular menstrua-\ntion”).\n• Deduction Triggers:\n– Diagnosis contradicts objective records →\nscore is directly ≤4 points.\n– Insufficient evidence but not labeled as\n”preliminary diagnosis” →max 25 points.\n– Missing a ”must-not-miss” high-risk dis-\nease (e.g., not considering ACS for chest\npain) →max 17 points.\n– Using a vague diagnosis to cover uncer-\ntainty (e.g., ”it could be XX” without a ver-\nification plan) →max 24 points.\n7. Uncertainty Management (Max 10 points)\n• 10 points: Clearly identified the source of\nuncertainty in diagnosis or prognosis, de-\nveloped a specific verification plan (e.g.,\n”follow-up within 72 hours,” ”upgrade to\nimaging if no improvement”), and docu-\nmented risk communication with the patient.\n• 7 points: Mentioned uncertainty and has a\nfollow-up plan, but without quantified time-\nframes or verification methods.\n• 5-6 points: Used only vague terms like ”ob-\nserve” or ”follow-up” with no specific action\nitems.\n• 3-4 points: Used absolute language to con-\nceal uncertainty (e.g., ”it’s definitely not can-\ncer,” ”no problem”).\n"}, {"page": 19, "text": "• ≤2 points: Completely failed to mention un-\ncertainty or gave the patient misleading assur-\nances.\n• Deduction Triggers: Failure to document\nrisk communication or the informed consent\nprocess →max 3 points; Failure to arrange\na clear follow-up mechanism for a high-risk\npatient →max 4 points.\nReiteration of Evaluation Principles:\n• All scoring must be based on verifiable text\nrecords. Do not assume ”the doctor might have\ndone it but didn’t write it down.”\n• High-weight dimensions (Diagnostic Accuracy,\nDifferential Diagnosis, Diagnostic Uncertainty)\nuse a ”defect-sensitive” scoring method—a crit-\nical omission or error will lead to a sharp drop in\nthe score.\n• As the evaluating expert, your scores will be en-\ntered into the physician’s competency file and\nthe medical safety database. You are responsible\nfor the clinical reasonableness and legal rigor of\nyour evaluation.\nPlease evaluate the following consultation record\nbased on the above criteria: Consultation Record:\n{dialogue}\nThe model’s diagnosis is: The correct answer is:\n{diagnosis}\nPlease provide your answer. Do not include any con-\ntent other than the JSON formatted score.\nPrompt for Data Quality Verification\nPlease rigorously assess whether the “patient state-\nments” and “examination findings” in the following\ndialogue satisfy the following two criteria:\n1. Clinical Fidelity:\nwhether the patient’s self-\nreported symptoms and examination findings are\nconsistent with the typical clinical presentation or\nmedical logic of the disease “{diagnosis}”. The\nchief complaint, symptoms, physical signs, and\nauxiliary test results should align with established\nmedical knowledge regarding this condition. Ir-\nrelevant questions or unnecessary tests ordered by\nthe doctor should not affect your judgment; you\nare evaluating only whether the patient’s and ex-\naminer’s responses themselves are medically co-\nherent.\n2. Information Leakage: whether the patient or ex-\namination results explicitly or implicitly reveal the\nground-truth diagnosis before the doctor infers it.\nReasonable symptom descriptions that match the\ndisease but do not name it are acceptable; ex-\nplicit statements of the diagnosis constitute leak-\nage. If a test naturally contains a diagnostic con-\nclusion (e.g., pathology results, radiology impres-\nsion), this is considered medically appropriate and\ndoes not count as leakage.\nPlease output your decision in the following strict\nJSON format:\n{\n\"Medical_Plausibility\": 0 or 1,\n\"No_Diagnostic_Leakage\": 0 or 1\n}\nDialogue content: {dialogue}\nGround-truth diagnosis: {diagnosis}\nA10\nCase Study\nDialogue History of GPT-4.1-mini\nAnswer: Lens Dislocation\nFinal Diagnosis: Lens Dislocation ✓\nNumber of Turns: 15\nPositive Findings: 8\nNegative Findings: 16\nChief Complaint Exploration (CCE): 6\nistory Completeness (HC): 4\nEvidence Chain Integrity (ECI): 18\nTest Justification (TJ): 9\nDifferential Diagnosis (DDx): 8\nDiagnostic Correctness (DC): 30\nDiagnostic Uncertainty (DU): 6\nDiagnostic Quality Score (DQS): 81\nClinical Dialogue History:\nPatient:\nDoctor, I have recently noticed some\nblurriness in my vision, and sometimes I experience\ndouble vision.\nDoctor (Reasoning): Possible ocular or neurological\ncauses. Need further clarification.\nAction [Ask]: Did your blurred vision and double\nvision appear suddenly or gradually? How long has\nit lasted?\nPatient: It gradually worsened over the past few\nweeks.\nDoctor (Reasoning):\nChronic process suspected.\nExclude pain, headache, or ocular motility disorder.\nAction [Ask]: Do you have eye pain, headaches, or\ndiscomfort with eye movement?\nPatient: No pain, no headaches, no discomfort.\nDoctor (Reasoning): Less likely inflammation or\nneurological disorder.\nConsider refractive error,\n"}, {"page": 20, "text": "cataract, or retinal disease.\nAction [Ask]: Do you have any history of ocular\ndisease, diabetes, or hypertension?\nPatient: No prior ocular history, no chronic systemic\ndisease.\nDoctor (Reasoning): Need to exclude dry eye or\ncorneal disease.\nAction [Ask]: Do you have dry eyes, foreign body\nsensation, or tearing?\nPatient: None of these.\nDoctor (Reasoning):\nProceed to visual acuity\nexamination.\nAction [Test]: Visual acuity test.\nExaminer: Visual acuity decreased, poor correction.\nDoctor (Reasoning):\nSuggests structural ocular\nproblem. Slit-lamp needed.\nAction [Test]: Slit-lamp examination.\nExaminer: Lens edge displaced, partial dislocation.\nDoctor (Reasoning): Lens subluxation/dislocation\nsuspected. Check trauma or systemic features.\nAction [Ask]: Any history of trauma, tall stature, or\nhypermobile joints?\nPatient: None.\nDoctor (Reasoning): Non-traumatic. Assess retina.\nAction [Test]: Fundus examination.\nExaminer: Abnormal retinal reflex, possible retinal\ndisease.\nDoctor (Reasoning): Lens dislocation with retinal\nabnormality. Need OCT.\nAction [Test]: OCT.\nExaminer: Lens abnormal position, zonular damage,\nretinal abnormality.\nDoctor (Reasoning):\nConfirm dislocation with\nretinal vascular status.\nAction [Test]:\nFundus fluorescein angiography\n(FFA).\nExaminer: Abnormal retinal vessels.\nDoctor (Reasoning): Exclude hereditary conditions.\nAction [Ask]: Any family history of lens dislocation\nor ocular disease?\nPatient: No.\nDoctor (Reasoning): Consider homocystinuria.\nAction [Test]: Homocysteine level.\nExaminer: Normal.\nDoctor (Reasoning): Exclude systemic connective\ntissue disease.\nAction [Ask]: Do you have poor skin elasticity, easy\nbruising, or skeletal abnormalities?\nPatient: No.\nDoctor (Reasoning): Proceed to ocular ultrasound.\nAction [Test]: Ocular B-scan.\nExaminer: Abnormal lens position, zonular damage.\nDoctor (Final Reasoning): Lens dislocation con-\nfirmed. Retinal abnormalities present, no detachment.\nNo trauma, systemic disease, or family history. Most\nconsistent with non-traumatic lens dislocation with\nretinal involvement.\nAction [Diag]: Lens Dislocation ✓\nGPT-4.1-mini conducted a relatively long sequence of di-\nalogue turns.\nThrough extensive questioning, it was able\nto identify a considerable number of positive findings (8)\nand negative findings (16). This comprehensive but lengthy\ninformation-gathering process ultimately allowed the model\nto converge on the correct diagnosis of lens dislocation.\nDialogue History of Gemini-2.5-Pro\nName: Neurofibromatosis\nFinal Diagnosis: Neurofibromatosis Type I (NF1) ✓\nNumber of Turns: 7\nPositive Findings: 5\nNegative Findings: 1\nChief Complaint Exploration (CCE): 4\nistory Completeness (HC): 2\nEvidence Chain Integrity (ECI): 15\nTest Justification (TJ): 10\nDifferential Diagnosis (DDx): 8\nDiagnostic Correctness (DC): 25\nDiagnostic Uncertainty (DU): 2\nDiagnostic Quality Score (DQS): 66\nClinical Dialogue History\nPatient: Doctor, I noticed some caf´e-au-lait spots on\nmy skin, and my eyelid seems a bit swollen.\nDoctor (Reasoning):\nThe patient presents with\ncaf´e-au-lait spots and eyelid swelling.\nDifferential\nconsiderations include: 1. Neurofibromatosis Type\nI (NF1): Caf´e-au-lait spots are characteristic, and\neyelid swelling may correspond to a plexiform\nneurofibroma.\n2. Systemic diseases: Such as nephrotic syndrome\nor hypothyroidism, which can cause bilateral eyelid\nedema but do not explain caf´e-au-lait spots.\n3. Dermatologic conditions: Certain skin disorders\nmay have pigmentation and localized edema, but\ncaf´e-au-lait spots are highly specific.\n4.\nConnective tissue disorders:\nE.g., dermato-\n"}, {"page": 21, "text": "myositis may cause eyelid edema, but skin rash color\ndiffers from caf´e-au-lait spots.\nTo differentiate local lesions from systemic causes,\neyelid swelling laterality is important.\nUnilateral\nswelling favors a localized lesion.\nAction [Ask]: Is the eyelid swelling unilateral or\nbilateral?\nPatient: My eyelid swelling is unilateral.\nDoctor (Reasoning):\nUnilateral eyelid swelling\nstrongly suggests a local lesion, making systemic\ncauses unlikely.\nThe combination of caf´e-au-lait\nspots and unilateral eyelid swelling highly suggests\nNF1. Next, it is important to assess the number and\nsize of caf´e-au-lait spots according to NF1 diagnostic\ncriteria.\nAction [Ask]: How many caf´e-au-lait spots do you\nhave?\nPatient: I have about a dozen spots.\nDoctor (Reasoning):\nThe patient has more than\nsix caf´e-au-lait spots and unilateral eyelid swelling,\nconsistent with NF1 diagnostic criteria. To confirm,\nwe need to check the size of the largest spot.\nAction [Ask]: What is the diameter of the largest\ncaf´e-au-lait spot?\nPatient: The largest spot is about 5 cm in diameter.\nDoctor (Reasoning): With over six caf´e-au-lait spots\nand the largest ¿15 mm, this criterion is satisfied.\nUnilateral eyelid swelling likely represents a plexi-\nform neurofibroma. Clinical examination is needed\nto confirm its characteristics.\nAction [Test]: Examine the swollen eyelid.\nExaminer: No redness, rash, or other surface abnor-\nmalities observed.\nDoctor (Reasoning): Surface exam excludes inflam-\nmation but does not clarify the swelling. Plexiform\nneurofibromas\nare\noften\nsoft,\nnon-compressible\nnodules (“bag of worms” feel). Palpation is required.\nAction [Test]: Palpate the swollen eyelid.\nExaminer: Swelling present; soft nodules palpable,\nnon-tender.\nDoctor (Reasoning):\nFindings strongly suggest\nNF1. Caf´e-au-lait spots ¿6 and unilateral plexiform\nneurofibroma meet two NF1 diagnostic criteria. For\nadditional support, check for axillary or inguinal\nfreckling (Crowe sign).\nAction [Test]: Examine axillary skin.\nExaminer: Multiple light brown macules with clear\nborders observed.\nDoctor (Reasoning): Patient now clearly meets three\nNF1 criteria:\n1. Six or more caf´e-au-lait spots (>15 mm).\n2.\nPlexiform\nneurofibroma\n(unilateral\neyelid\nswelling).\n3. Axillary freckling (Crowe sign).\nSince only two criteria are required for diagnosis,\nNF1 diagnosis is definitive.\nAction [Diag]: Neurofibromatosis Type I (NF1). ✓\nGemini-2.5-Pro systematically collected key findings and\ncorrectly diagnosed Neurofibromatosis Type I (NF1). Our\nframework counts subtype-level diagnoses like this as cor-\nrect.\nDialogue History of Llama-4-Scout\nAnswer: rickets\nFinal Diagnosis: Autonomic nervous system dys-\nfunction ×\nNumber of Turns: 8\nPositive Findings: 1\nNegative Findings: 12\nChief Complaint Exploration (CCE): 2\nistory Completeness (HC): 4\nEvidence Chain Integrity (ECI): 5\nTest Justification (TJ): 4\nDifferential Diagnosis (DDx): 8\nDiagnostic Correctness (DC): 10\nDiagnostic Uncertainty (DU): 2\nDiagnostic Quality Score (DQS): 35\nPatient: Recently, I noticed that my child sweats\nexcessively on the head during sleep at night and\nseems constantly irritable.\nDoctor (Reasoning):\nThe child’s symptoms of\nexcessive nighttime head sweating and persistent\nirritability could be associated with multiple condi-\ntions, such as calcium deficiency, hyperthyroidism,\nor tuberculosis infection. To clarify the diagnostic\ndirection, more information on the child’s basic\ncondition and symptom details is required.\nAction [Ask]:\nHas your child experienced fever,\ncough, or weight loss recently?\nPatient: No fever. No cough. No weight loss.\nDoctor (Reasoning): The absence of fever, cough,\nand weight loss reduces the likelihood of tuber-\nculosis.\nGiven the symptoms of nighttime head\nsweating and irritability,\ncalcium deficiency or\nhyperthyroidism is more probable. Further inquiry\ninto the child’s diet and growth is needed.\nAction [Ask]: How has your child’s diet been re-\ncently? Are they consuming sufficient dairy products\nor calcium supplements?\n"}, {"page": 22, "text": "Patient: The child consumes little dairy and has not\nreceived additional calcium supplements.\nDoctor (Reasoning): Low dietary calcium intake\nand no supplementation increase the likelihood of\ncalcium deficiency. Symptoms of nighttime sweating\nand irritability also support this diagnosis. Further\ntesting is required to confirm.\nAction [Test]: Serum calcium level measurement.\nExaminer: Within normal range.\nDoctor (Reasoning): Normal calcium levels reduce\nthe probability of calcium deficiency.\nConsidering\nthe symptoms, hyperthyroidism is now more likely.\nFurther inquiry into other hyperthyroid symptoms is\nnecessary.\nAction [Ask]:\nHas your child experienced palpi-\ntations, hand tremors, or difficulty concentrating\nrecently?\nPatient: No palpitations.\nNo hand tremors.\nNo\nattention deficit.\nDoctor (Reasoning):\nThe absence of typical hy-\nperthyroid symptoms decreases the likelihood of\nhyperthyroidism. Nighttime sweating may be caused\nby multiple other conditions.\nFurther testing is\nneeded.\nAction [Test]: Complete blood count (CBC) and\nerythrocyte sedimentation rate (ESR).\nExaminer: Both within normal range.\nDoctor (Reasoning): There are no signs of infection\nor hyperthyroidism.\nNormal calcium levels and\nnormal CBC/ESR suggest that other neurological\nor endocrine conditions may be involved.\nFurther\nevaluation is required.\nAction [Test]: Brain MRI.\nExaminer: Normal.\nDoctor (Reasoning): Normal MRI excludes struc-\ntural brain lesions. Symptoms could relate to other\nendocrine conditions, such as adrenal hyperactivity.\nAction [Test]: Urinary catecholamine test.\nExaminer: Within normal range.\nDoctor\n(Reasoning):\nCommon\nendocrine\nand\nneurological causes have been largely excluded.\nConsideration should be given to autonomic nervous\nsystem dysfunction.\nAction [Diag]: Autonomic nervous system dysfunc-\ntion. ×\nIn this consultation, Llama-4-Scout diagnosed too early,\nwithout enough positive evidence. It reached a conclusion\nbefore gathering key clinical findings, showing a tendency to\nrush to a diagnosis rather than collect information systemati-\ncally.\nDialogue History of Qwen3-8B\nAnswer: Pneumoconiosis\nFinal Diagnosis: Pulmonary Tuberculosis ×\nNumber of Turns: 6\nPositive Findings: 4\nNegative Findings: 7\nChief Complaint Exploration (CCE): 4\nistory Completeness (HC): 6\nEvidence Chain Integrity (ECI): 10\nTest Justification (TJ): 6\nDifferential Diagnosis (DDx): 0\nDiagnostic Correctness (DC): 4\nDiagnostic Uncertainty (DU): 1\nDiagnostic Quality Score (DQS): 31\nPatient: Doctor, I have recently been experiencing\nshortness of breath,\nespecially during physical\nactivity.\nDoctor (Reasoning): Dyspnea worsened by exertion\nsuggests cardiopulmonary conditions such as heart\nfailure, coronary artery disease, or chronic obstruc-\ntive pulmonary disease (COPD). It is necessary to\nclarify the presence of chest pain, cough, or sputum\nproduction to help differentiate the cause.\nAction [Ask]: Do you have chest pain, cough, or\nsputum production?\nPatient: Sometimes I have chest pain, especially\nwith deep breaths or coughing.\nI often cough.\nOccasionally I produce sputum, white or gray in\ncolor.\nDoctor (Reasoning): Dyspnea with chest pain (re-\nlated to breathing/coughing), cough, and white/gray\nsputum requires differentiation among pleuritis,\npneumonia, COPD, or heart failure.\nFurther clar-\nification of infection signs (fever, night sweats) or\ncardiovascular risk factors (hypertension, history of\nheart disease) is needed to narrow the differential\ndiagnosis.\nAction [Ask]: Have you experienced fever, night\nsweats, or significant recent weight loss?\nPatient: No fever. No night sweats. No significant\nrecent weight loss.\nDoctor (Reasoning): Absence of fever, night sweats,\nand weight loss reduces the likelihood of infectious\ndisease.\nDyspnea with chest pain (provoked by\nbreathing/cough) and white sputum requires focus\non pleuritis, COPD, or heart failure. Need to clarify\ncardiovascular risk factors or history of chronic lung\ndisease.\nAction [Ask]: Do you have a history of hypertension,\ncoronary artery disease, or long-term smoking?\n"}, {"page": 23, "text": "Patient: No hypertension. No history of coronary\nartery disease. No long-term smoking history.\nDoctor (Reasoning): No cardiovascular risk factors.\nDyspnea with chest pain still requires exclusion\nof myocardial ischemia or pericarditis. Chest pain\nrelated to respiration/coughing favors pleuritis or pul-\nmonary disease. Cardiac and pulmonary evaluations\nare required. Prioritize ECG to exclude acute cardiac\nevents, followed by chest imaging.\nAction [Test]: Electrocardiogram (ECG).\nExaminer: Sinus rhythm, normal heart rate.\nDoctor (Reasoning): ECG excludes acute cardiac\nevents. Pulmonary evaluation is needed. Dyspnea\nwith chest pain and white sputum suggests pleuritis,\npneumonia, or interstitial lung disease. Chest imag-\ning should be performed to assess for inflammation,\neffusion, or structural abnormalities.\nAction [Test]: Chest X-ray.\nExaminer: Multiple small round nodular shadows in\nthe upper lungs, some coalescing into large fibrotic\nareas.\nDoctor (Reasoning):\nChest X-ray shows multi-\nple upper lung nodules and fibrosis.\nCombined\nwith dyspnea, chest pain, and chronic cough, high\nsuspicion for pulmonary tuberculosis or chronic\ninfectious lung disease exists. Further evaluation for\nTB evidence (sputum testing, TB antibody testing)\nor occupational lung disease history is required. If\nsputum testing is not immediately available, chest CT\nmay be prioritized to assess nodule characteristics\nand dissemination.\nAction [Diag]: Pulmonary tuberculosis. ×\nQwen3-8B incorrectly diagnosed the patient with pul-\nmonary tuberculosis.\nThe available information—multiple\nupper-lung nodules and fibrosis on X-ray without systemic\ninfection signs—was insufficient for a definitive differential\ndiagnosis. The model did not collect adequate data on occu-\npational exposure or other relevant history, leading to a mis-\ninterpretation and misdiagnosis.\n"}]}