{"doc_id": "arxiv:2512.03838", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2512.03838.pdf", "meta": {"doc_id": "arxiv:2512.03838", "source": "arxiv", "arxiv_id": "2512.03838", "title": "Training and Evaluation of Guideline-Based Medical Reasoning in LLMs", "authors": ["Michael Staniek", "Artem Sokolov", "Stefan Riezler"], "published": "2025-12-03T14:39:02Z", "updated": "2025-12-03T14:39:02Z", "summary": "Machine learning for early prediction in medicine has recently shown breakthrough performance, however, the focus on improving prediction accuracy has led to a neglect of faithful explanations that are required to gain the trust of medical practitioners. The goal of this paper is to teach LLMs to follow medical consensus guidelines step-by-step in their reasoning and prediction process. Since consensus guidelines are ubiquitous in medicine, instantiations of verbalized medical inference rules to electronic health records provide data for fine-tuning LLMs to learn consensus rules and possible exceptions thereof for many medical areas. Consensus rules also enable an automatic evaluation of the model's inference process regarding its derivation correctness (evaluating correct and faithful deduction of a conclusion from given premises) and value correctness (comparing predicted values against real-world measurements). We exemplify our work using the complex Sepsis-3 consensus definition. Our experiments show that small fine-tuned models outperform one-shot learning of considerably larger LLMs that are prompted with the explicit definition and models that are trained on medical texts including consensus definitions. Since fine-tuning on verbalized rule instantiations of a specific medical area yields nearly perfect derivation correctness for rules (and exceptions) on unseen patient data in that area, the bottleneck for early prediction is not out-of-distribution generalization, but the orthogonal problem of generalization into the future by forecasting sparsely and irregularly sampled clinical variables. We show that the latter results can be improved by integrating the output representations of a time series forecasting model with the LLM in a multimodal setup.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2512.03838v1", "url_pdf": "https://arxiv.org/pdf/2512.03838.pdf", "meta_path": "data/raw/arxiv/meta/2512.03838.json", "sha256": "f4f3b0ec6a79f52b84eb99fc57b41880fe560e9fefeda72c2ac6f14276461dac", "status": "ok", "fetched_at": "2026-02-18T02:25:35.884621+00:00"}, "pages": [{"page": 1, "text": "TRAINING AND EVALUATION OF GUIDELINE-BASED\nMEDICAL REASONING IN LLMS\nMichael Staniek‡, Artem Sokolov‡,∗, Stefan Riezler‡,⋄\n‡Computational Linguistics & ⋄IWR, Heidelberg University, Germany\n∗Google DeepMind, Berlin, Germany\n<lastname>@cl.uni-heidelberg.de\nABSTRACT\nMachine learning for early prediction in medicine has recently shown breakthrough\nperformance, however, the focus on improving prediction accuracy has led to a\nneglect of faithful explanations that are required to gain the trust of medical prac-\ntitioners. The goal of this paper is to teach LLMs to follow medical consensus\nguidelines step-by-step in their reasoning and prediction process. Since consensus\nguidelines are ubiquitous in medicine, instantiations of verbalized medical infer-\nence rules to electronic health records provide data for fine-tuning LLMs to learn\nconsensus rules and possible exceptions thereof for many medical areas. Con-\nsensus rules also enable an automatic evaluation of the model’s inference process\nregarding its derivation correctness (evaluating correct and faithful deduction of a\nconclusion from given premises) and value correctness (comparing predicted val-\nues against real-world measurements). We exemplify our work using the complex\nSepsis-3 consensus definition. Our experiments show that small fine-tuned models\noutperform one-shot learning of considerably larger LLMs that are prompted with\nthe explicit definition and models that are trained on medical texts including con-\nsensus definitions. Since fine-tuning on verbalized rule instantiations of a specific\nmedical area yields nearly perfect derivation correctness for rules (and exceptions)\non unseen patient data in that area, the bottleneck for early prediction is not out-of-\ndistribution generalization, but the orthogonal problem of generalization into the\nfuture by forecasting sparsely and irregularly sampled clinical variables. We show\nthat the latter results can be improved by integrating the output representations of a\ntime series forecasting model with the LLM in a multimodal setup.\n1\nINTRODUCTION\nMedical consensus definitions are guidelines stated by a representative group of experts on how to\ndiagnose and treat a disease based on clinical evidence. From the perspective of logical inference,\nconsensus guidelines include deductive and inductive inference rules. Deductive rules have the\nform of if-then relations where the conclusion is certain given the correctness of the premise, for\nexample, in mapping thresholds on clinical measurements to step functions of diseases. If used for\nearly prediction purposes (a.k.a. prognosis), inductive inference rules are required where the if-then\nrelation between premise and conclusion is probabilistic. An illustrative example for a complex\nconsensus guideline is the Sepsis-3 definition that identifies an organ dysfunction as an acute change\nin total SOFA score ≥2 points consequent to an infection (Singer et al., 2016; Seymour et al., 2016).\nThe SOFA (Sepsis-Related Organ Failure Assessment) score itself constitutes a consensus definition\nthat is based on definitions for six organ systems, each defining thresholds on particular clinical\nvariables observed during a 24h window ((Vincent et al., 1996), see Table 5 in Appendix A.1). These\ncalculations comprise a logical rule system where time series forecasting (TSF) of clinical variables\nrepresents inductive rules, which are composed with deductive rules that calculate extrema over time,\nmap clinical measurements onto step functions, and calculate changes over time (see Figure 1).\n∗Participated in advisory capacity.\n1\narXiv:2512.03838v1  [cs.CL]  3 Dec 2025\n"}, {"page": 2, "text": "The goal of this work is to teach LLMs to follow the deductive and inductive rules of medical\nconsensus guidelines step-by-step in their prediction and reasoning process1, in order to foster the\ntrust of medical practitioners in the generated diagnosis or prognosis. We exemplify our work using\nthe complex Sepsis-3 consensus definition. Instantiations of verbalized medical inference rules\nto clinical patient data allow the model to learn the consensus rule and possible exceptions to the\nrule from patient examples in many medical areas (see Figure 2). Our work transfers learning of\ncompositional inference from mathematical problems to medical inference, with several advantages.\nFirst, consensus definitions are ubiquitous in medicine, ranging from guidelines for mental disorders\n(American Psychiatric Association, 2013) to neurological (McDonald et al., 2001) and physiological\ndiseases (KDIGO Acute Kidney Injury Work Group, 2012). For each area, verbalization of consensus\nrules can be done automatically by using templates (which can themselves be generated automatically\nby using LLMs) that describe each step of an application of a consensus rule system to patient\ndata. Furthermore, human curation can be integrated by annotating verbalized inference chains with\npossible exceptions and corrections to the rule. In contrast to prompting LLMs, supervised fine-tuning\nallows learning of rules and exceptions from example instantiations to patient data.\nSecond, the use of consensus rules enables an exact and automatic evaluation of the model’s inference\nprocess against a trusted medical gold standard. We present an evaluation setup that differentiates the\nderivation correctness of a trained model — measuring a model’s ability to learn to correctly deduce\na conclusion from a given premise — from a model’s value correctness — comparing the numerical\nvalue predicted in each inference step against real-world measurements. An evaluation of derivation\ncorrectness also can be seen to measure the faithfulness of the model’s inference process in the sense\nof checking for an accurate representation of the reasoning process behind the model’s prediction.\nOur results show that small fine-tuned models (LLaMA 8B parameters) outperform one-shot learning\nof considerably larger LLMs (LLaMA 70B parameters) that are given the explicit definition in the\nprompt, and LLMs that are trained on medical texts including the original consensus definitions\n(Me-LLaMA 8B parameters) under all evaluation metrics. In particular, fine-tuned LLMs show\nnearly perfect generalization to unseen patient data with respect to derivation correctness of rules and\nexceptions. This demonstrates that an adaptation of an LLM to verbalized rule instantiations for a\nspecific medical area likely guarantees consistent results in that area, whereas training or prompting\nmodels with the abstract definition texts is not sufficient. We conjecture that generalization across\nconsensus definitions in areas as different as psychiatry (based on interviews (American Psychiatric\nAssociation, 2013)), neurology (based partially on magnetic resonance imaging (McDonald et al.,\n2001)), or physiological diseases (based on vital signals and lab tests (KDIGO Acute Kidney Injury\nWork Group, 2012; Cederholm et al., 2019; Singer et al., 2016; Seymour et al., 2016)) is difficult to\nbridge without supervision. The bottleneck is thus not out-of-distribution generalization (Chu et al.,\n2025), but the orthogonal problem of generalization into the future, i.e., the inherent complexity of\ntime series forecasting of sparsely and irregularly sampled clinical variables. The latter results can be\nimproved by moving from a text-based encoding of clinical measurements to a multi-modal approach\nwhere the output representations of a TSF model are fed as additional input to the LLM.\n2\nRELATED WORK\nReasoning in LLMs\nRecent evaluations of the \"reasoning\" process of LLMs have shown that they\nare able to correctly solve sub-tasks of multi-step inference tasks, but fail to compose them into a fully\ncorrect inference path, especially in extrapolation to more complex out-of-distribution data (Dziri\net al., 2023; Zhang et al., 2023; Saparov & He, 2023; Yang et al., 2024; Mondorf & Plank, 2024). For\ncompositional inference problems in mathematics or logics, fine-tuning on so-called \"scratchpads\"\nhas been shown to yield consistently strong generalization (Nye et al., 2021; Hochlehnert et al., 2025).\nTo our knowledge, our work is the first one to apply an automatic generation of scratchpads for\nfine-tuning and step-by-step evaluation to the inference process of medical LLMs. Recent works\nhave addressed the aspect of faithfulness of chain-of-thought explanations of LLMs, asking whether\nthey accurately represent the underlying inference process of the model (Jacovi & Goldberg, 2020).\nFaithfulness in chain-of-thought reasoning has been enforced by incorporating deterministic solvers\ninto the inference process (Lyu et al., 2023; Xu et al., 2024). Evaluation of faithfulness has been\n1In the following, in order to avoid an anthropomorphic attribution of \"reasoning\" capabilities to LLMs, we\nwill speak of medical \"rules\" that are taught, and of an \"inference process\" that is being evaluated for the LLM.\n2\n"}, {"page": 3, "text": "Figure 1: Inductive and deductive inference rules in the Sepsis-3 Consensus Definition (Singer et al.,\n2016; Seymour et al., 2016). Deductive rules calculate extrema over time, map thresholds onto step\nfunctions for SOFA scores, and calculate total SOFA and changes over time. Inductive rules involve\ntime series forecasting of clinical variables 24 hours into the future.\ndone manually for LLMs with explicit (Turpin et al., 2023) and implicit biases (Arcuschin et al.,\n2025), or by defining automatic evaluation metrics of chain-of-thought inference processes (Lanham\net al., 2023; Wang et al., 2025b; Chen et al., 2025). The latter metrics are based on accuracy or\nconfidence of the generated LLM outputs, and can thus be considered \"reference-free\" evaluation\nmetrics, whereas a consensus rule can be used as a unique gold standard reference for evaluation.\nMedical Reasoning\nMedical reasoning has been characterized to include two contrasting mech-\nanisms, termed analytic versus non-analytic strategies (Eva, 2005), causal versus example-based\nknowledge (Norman, 2005), or contrasting external clinical evidence with individual clinical expertise\n(Sackett et al., 1996). To our knowledge, no attempt has been made so far to differentiate these\naspects in teaching and evaluating LLMs for healthcare. Instead, most evaluations are based on\nmedical question-answering (Liu et al., 2023; Singhal et al., 2025), while it has been shown that the\nvast majority of questions in medical QA benchmarks can be answered by factual recall, not requiring\nmulti-step inference at all (Thapa et al., 2025). While excelling in medical question-answering tasks,\nfew-shot LLMs suffer from prompt brittleness (Hochlehnert et al., 2025; Reese et al., 2024), fail in\nbasic TSF tasks (Merrill et al., 2024; Tan et al., 2024), and lack adherence to consensus guidelines\n(Hager et al., 2024). Various approaches have been presented to teach LLMs medical inference\nrules, e.g., by pre-training or fine-tuning on medical texts including consensus guidelines (Chen\net al., 2023; Xie et al., 2025), by learning from manually crafted demonstrations (Liu et al., 2025)\nor from knowledge graphs (Wu et al., 2025), or by eliciting emergent reasoning via reinforcement\nlearning(Yun et al., 2025; Chen et al., 2024; Zhang et al., 2025). However, with the exception of Fan\net al. (2025), the state-of-the-art in evaluation of medical reasoning is with respect to final-answer\naccuracy on standard medical question-answering benchmarks (see Wang et al. (2025a) for a survey).\nOur work uses trusted consensus rules as training data and, instantiated to different patients, as\ngold standard references for automatic step-by-step evaluation. This obviates the need for manual\nevaluation and yet allows to evaluate the inference process itself.\nEarly Prediction of Sepsis\nMachine learning for early prediction of sepsis starts by labeling clinical\ndata2, by applying a Sepsis consensus definition 3 to future clinical observations that are unseen to\nthe model, and then training models to predict the label based on clinical measurements observed\nseveral hours before. Examples are the machine learning approaches taken by the 104 participants in\nthe PhysioNet Challenge on \"Early Prediction of Sepsis from Clinical Data\" (Reyna et al., 2019), or\nthe 21 approaches described in a recent overview (Moor et al., 2021). Machine learning for early\nprediction of sepsis includes a broad variety of learning algorithms, from linear learners to deep\nlearning (see Reyna et al. (2019) and Moor et al. (2021)), up to most recent works using Transformers\n2E.g., MIMIC-III (Johnson et al., 2016), MIMIC-IV (Johnson et al., 2023), or eICU (Pollard et al., 2018).\n3Sepsis-3 or Sepsis-2 (Levy et al., 2003; Dellinger et al., 2013) in earlier works.\n3\n"}, {"page": 4, "text": "(Choi et al., 2024), graph neural networks (Yin et al., 2025), and pretrained LLMs (Li et al., 2024).\nThe setup of predicting a label that is the outcome of a consensus definition can be abstractly viewed\nas the prediction of an effect that is caused by applying a consensus definition to future values of\nclinical variables. Another option is to directly predict the causes by forecasting clinical variables,\nand determine the effect by applying the consensus definition to the forecasted values (Staniek et al.,\n2024). Our approach is most similar to the latter, with the important difference that our approach not\nonly learns rules, but also exceptions thereof from patient data.\n3\nTEACHING LLMS TO DIAGNOSE ACCORDING TO THE SEPSIS-3 DEFINITION\nDeductive Inference\nSepsis-3 contains several deductive inference steps: A first step is a calculation\nof \"worst\" values (minima or maxima) of clinical variables over 24 hours. The crucial deductive\ntask in Sepsis-3 can be seen as a deductive syllogism consisting of rules (the major premises)\nthat are instantiated to thresholds on clinical variables (the minor premises) that are mapped to\nstep functions for six SOFA subscores, yielding scores from 0 −4 (the conclusions). Each SOFA\nsubscore corresponds to an organ system, namely the central nervous system, and the cardiovascular,\nrespiratory, coagulation, liver, and renal organ systems. The rules themselves are abbreviated as SCNS,\nScardio, Sresp, Scoag, Sliver, and Srenal in the lower part of Figure 1 and shown in the columns in Table\n5 in Appendix A.1. The total SOFA score is calculated by summing these six subscores to a score\nranging from 0 −24, once for clinical measurements during the first 24 hours (SOFA1−24), and for\npredicted measurements in the next 24 hours (SOFA25−48). A further deductive inference step is the\ncomputation of a change ≥2 as\nSOFAdiff := [[(SOFA25:48 −SOFA1:24) ≥2]],\n(1)\nwhere [[a]] = 1 if a is true, 0 otherwise. Finally, a binary Sepsis label is assessed by combining the\nindicator function in Equation 1 with a binary indicator suspected_infection4, yielding\nSEPSIS := SOFAdiff ∧suspected_infection.\n(2)\nInductive Inference\nSepsis-3 is laid out to detect a life-threatening organ dysfunction by an acute\nchange in the total SOFA score. Measuring an increase in SOFA score over time requires TSF of\nfuture values of a set of clinical features F (see upper part of Figure 1), and an application of the\nSOFA definition to current and future clinical values. Formally, given a representation x of an input\ntime series, an output vector of predicted clinical values ˆyt ∈R|F | is produced. The features used\nin our experiments are 131 clinical measurements extracted from the MIMIC-III database (Johnson\net al., 2016). A full list is given in Appendix A.4. The TSF task in our experiments is defined to\npredict the next 24 hours from a history of preceding 24 hours. Dedicated models to perform the TSF\ntask are described in Appendix A.2.\nTeaching Verbalized Consensus Rules to Autoregressive LLMs\nAn approach to teaching LLMs\nto generate a chain of inference rules that adheres to a certain definition is to deploy an autoregressive\narchitecture where next-token prediction is based on a history of previously predicted tokens, and\ntoken-wise errors on a target inference chain can be backpropagated through the system. This\nprocedure coincides with standard supervised fine-tuning, where an input question, a gold-standard\nverbalization of the inference process, and the answer, is provided to the model during training. An\nexample for fine-tuning data including inference rules following the Sepsis-3 definition is shown in\nFigure 2, left column. The data starts with a verbalization of a sparse multivariate input time series of\nmeasurements for a 24 hour window, followed by an instruction to classify the patient as septic in the\nnext 24 hours, given information about suspected infection5. The third text block in the fine-tuning\ndata consists of a gold standard inference chain explaining the scores of the six SOFA systems from\nthe corresponding clinical measurements, and computing their sum, given the measurements of the\nfirst 24 hour window. The fourth text block includes forecasts of the clinical variables relevant for\nSOFA for the next 24 hours, and the corresponding inference about the six SOFA subscores, and\n4Following Singer et al. (2016); Seymour et al. (2016), a suspected infection is defined as a combination of\nantibiotics treatment and blood cultures, starting within the first 24 hours after admission.\n5The onset of suspicion of infection is thus given prior to the onset of salient organ dysfunction in our\napproach, corresponding to labeling scheme H1 of Cohen et al. (2024), and consistent with other work on early\nprediction of sepsis where suspected infection is included in the list of input features (Nemati et al., 2018).\n4\n"}, {"page": 5, "text": "Patient is 75.0 years old and is male. Given all the information in\nthis text, answer the question at the end. Here are the measurements:\nDBP at time -22.37: 49.0, SBP at time -22.37: 105.0, DBP at time\n-20.37: 52.0, GCS_eye at time -20.37: 4.0, GCS_motor at time\n-20.37: 6.0, GCS_verbal at time -20.37: 1.0, SBP at time -20.37:\n117.0, DBP at time -19.37: 56.0, FiO2 at time -19.37: 0.5, SBP at\ntime -19.37: 127.0, DBP at time -18.37: 43.0,...\nNow answer the following question:\nThe doctors suspect an\ninfection, based on this information and the other information in this\ntext, will the patient be classified as septic tomorrow?\nFirst we need to calculate the SOFA scores given the extracted\nvalues. The SOFA scores for the current time are the following:\nThe minimum value of GCS_eye is 4.0, GCS_motor is 6.0 and\nGCS_verbal is 1.0, this produces the sum 11.0 and means the CNS\nSOFA is 2. Because minimum MAP is 55.333, max Dopamine is 0,\nmax Dobutamine is 0, max Epinephrine is 0 and max Norepinephrine\nis 0 with a patient weight of 62.8 kg, the cardiovascular SOFA is\n1. Given that minimum PO2 is 100.0 and minimum FiO2 is 0.5 the\ncalculated PAO2FIO2 is 200.0, this means the respiratory SOFA is 2.\nBecause the minimum Platelet count is 310.0 the coagulation SOFA\nis 0. The maximum Bilirubin (Total) is 1 leading to a liver SOFA of\n0. Because total Urine output is 1095.0 and maximum creatinine in\nthe blood is 0.4 the renal SOFA is 0. To summarize: the patient has a\ntotal SOFA score of 5.\nNow we need to calculate the SOFA scores with forecasted\nvalues. The SOFA scores in the future based on the forecasted values\nare the following: The minimum value of GCS_eye will be 4.0,\nGCS_motor will be 6.0 and GCS_verbal will be 1.0, this produces\nthe sum 11.0 and means the CNS SOFA will be 2. Because future\nminimum MAP will be 65.333, future max Dopamine will be 0,\nfuture max Dobutamine will be 0, future max Epinephrine will be 0\nand future max Norepinephrine will be 0 with a patient weight of\n62.8 kg, the cardiovascular SOFA will be 1. Given that minimum\nPO2 will be 100.0 and minimum FiO2 will be 0.5 the forecasted\nPAO2FIO2 will be 200.0, this means the respiratory SOFA will be 2.\nBecause the Platelet count will be 310.0 the coagulation SOFA is\ngoing to be 0. The maximum Bilirubin (Total) will be 1 leading to a\nliver SOFA of 0. Because Urine output will be 150.0 and maximum\ncreatinine in the blood will be 0.4 the renal SOFA will be 4. To\nsummarize: the patient will have a future total SOFA score of 9.\nThis calculation means that the patient will likely experi-\nence a kidney failure since SOFA increased by 4. The patient will\ndevelop sepsis in the next 24 hours, because total SOFA increased\nby 4 and infection is suspected.\nPatient is 75.0 years old and is male. Given all the information in\nthis text, answer the question at the end. Here are the measurements:\nDBP at time -22.37: 49.0, SBP at time -22.37: 105.0, DBP at time\n-20.37: 52.0, GCS_eye at time -20.37: 4.0, GCS_motor at time\n-20.37: 6.0, GCS_verbal at time -20.37: 1.0, SBP at time -20.37:\n117.0, DBP at time -19.37: 56.0, FiO2 at time -19.37: 0.5, SBP at\ntime -19.37: 127.0, DBP at time -18.37: 43.0,...\nNow answer the following question:\nThe patient has an\nexisting precondition given by the ICD-10 code N18.9.\nThe\ndoctors suspect an infection, based on this information and the\nother information in this text, will the patient be classified as septic\ntomorrow?\nFirst we need to calculate the SOFA scores given the extracted\nvalues. The SOFA scores for the current time are the following:\nThe minimum value of GCS_eye is 4.0, GCS_motor is 6.0 and\nGCS_verbal is 1.0, this produces the sum 11.0 and means the CNS\nSOFA is 2. Because minimum MAP is 55.333, max Dopamine is 0,\nmax Dobutamine is 0, max Epinephrine is 0 and max Norepinephrine\nis 0 with a patient weight of 62.8 kg, the cardiovascular SOFA is\n1. Given that minimum PO2 is 100.0 and minimum FiO2 is 0.5 the\ncalculated PAO2FIO2 is 200.0, this means the respiratory SOFA is 2.\nBecause the minimum Platelet count is 310.0 the coagulation SOFA\nis 0. The maximum Bilirubin (Total) is 1 leading to a liver SOFA of\n0. Because total Urine output is 1095.0 and maximum creatinine in\nthe blood is 0.4 the renal SOFA is 0. To summarize: the patient has a\ntotal SOFA score of 5.\nNow we need to calculate the SOFA scores with forecasted\nvalues. The SOFA scores in the future based on the forecasted values\nare the following: The minimum value of GCS_eye will be 4.0,\nGCS_motor will be 6.0 and GCS_verbal will be 1.0, this produces\nthe sum 11.0 and means the CNS SOFA will be 2. Because future\nminimum MAP will be 65.333, future max Dopamine will be 0,\nfuture max Dobutamine will be 0, future max Epinephrine will be 0\nand future max Norepinephrine will be 0 with a patient weight of\n62.8 kg, the cardiovascular SOFA will be 1. Given that minimum\nPO2 will be 100.0 and minimum FiO2 will be 0.5 the forecasted\nPAO2FIO2 will be 200.0, this means the respiratory SOFA will be 2.\nBecause the Platelet count will be 310.0 the coagulation SOFA is\ngoing to be 0. The maximum Bilirubin (Total) will be 1 leading to a\nliver SOFA of 0. Because Urine output will be 150.0 and maximum\ncreatinine in the blood will be 0.4 the renal SOFA will be 4. To\nsummarize: the patient will have a future total SOFA score of 5.\nThe patient will not develop sepsis in the next 24 hours,\nbecause total SOFA increased by 0 and infection is suspected.\nFigure 2: Fine-tuning data including a verbalization of Sepsis-3 inference (left column) and inference\nunder an exception due to medical preconditions (right column). Differences are shown in bold blue\nfont. The general prompt is shown above the horizontal line, the gold standard answer below.\ntheir sum. The last text block contains a gold standard inference about the Sepsis prediction and the\nresponsible SOFA system, if applicable.\nHandling Exceptions to the Rules\nSince consensus rules cannot capture every individual disease\nprogression, it is important to consider the possibility of manual corrections to consensus-based\ninference by adding exceptions to the inference rules. A possible example are medical preconditions\nwith specific treatments, for example, dialysis in case of chronic kidney disease. While there is clear\nevidence that incorporating pre-existing medical conditions (comorbidities / chronic organ failure)\ncan improve sepsis prediction (Sarraf et al., 2024; Christensen et al., 2023), there is no consensus\non how certain preconditions which will alter clinical measurements and thus the SOFA score. In\ncase of a chronic kidney disease, a conservative exception might be to decide to disregard the kidney\nSOFA in the calculation of total SOFA, leading to an exception to the Sepsis-3 definition. We test\nthis hypothetical scenario by synthetic data. We synthesized fine-tuning data including exceptions\nto the rule by adding preconditions for five organ systems in form of ICD-10 codes. During data\ngeneration, each datapoint was randomly assigned a precondition, either one of the predefined types\nor the no-precondition option, with equal probability. An example for a verbalization is shown in\nFigure 2, right column. The format is the same as for inference according to the definition, except\n5\n"}, {"page": 6, "text": "Table 1: Derivation correctness of predicted values. Forced derivation correctness in brackets.\nvariable\none-shot\none-shot-70B\nme-llama\ndeepseek\nfine-tuned\npipeline\nmultimodal\ncurrent\nSCNS\n0.693\n0.803\n0.520\n0.288\n1.000\n1.000\n1.000\nScardio\n0.516\n0.696\n0.258\n0.338\n0.998\n0.998\n0.975\nSresp\n0.561\n0.302\n0.404\n0.279\n0.995\n0.996\n0.996\nScoag\n0.599\n0.763\n0.511\n0.381\n0.966\n0.966\n0.970\nSliver\n0.537\n0.864\n0.601\n0.336\n0.993\n0.992\n0.992\nSrenal\n0.537\n0.730\n0.396\n0.256\n1.000\n0.998\n1.000\nSOFA1:24\n0.543\n0.893\n0.777\n0.165\n1.000\n1.000\n0.999\nfuture\nSCNS\n0.504 (0.827)\n0.545 (0.895)\n0.399 (0.786)\n0.261 (0.823)\n1.000 (1.000)\n1.000 (1.000)\n1.000 (1.000)\nScardio\n0.580 (0.694)\n0.679 (0.714)\n0.353 (0.647)\n0.269 (0.671)\n0.987 (0.997)\n0.975 (0.997)\n0.965 (0.997)\nSresp\n0.530 (0.756)\n0.307 (0.827)\n0.384 (0.733)\n0.266 (0.722)\n0.995 (0.996)\n0.996 (0.996)\n0.995 (0.996)\nScoag\n0.661 (0.786)\n0.754 (0.818)\n0.519 (0.801)\n0.306 (0.747)\n0.967 (1.000)\n0.970 (0.999)\n0.966 (1.000)\nSliver\n0.534 (0.835)\n0.847 (0.969)\n0.599 (0.657)\n0.335 (0.776)\n0.992 (0.999)\n0.992 (0.999)\n0.992 (1.000)\nSrenal\n0.554 (0.708)\n0.737 (0.773)\n0.414 (0.690)\n0.251 (0.634)\n1.000 (1.000)\n1.000 (1.000)\n1.000 (1.000)\nSOFA25:48\n0.518 (0.875)\n0.868 (0.984)\n0.768 (0.992)\n0.148 (0.550)\n1.000 (1.000)\n0.999 (1.000)\n1.000 (1.000)\nSOFAdiff\n0.845 (0.740)\n0.891 (0.477)\n0.769 (0.414)\n0.503 (0.351)\n1.000 (1.000)\n1.000 (1.000)\n1.000 (1.000)\nSEPSIS\n0.859 (0.682)\n0.909 (0.727)\n0.769 (0.688)\n0.738 (0.521)\n1.000 (1.000)\n1.000 (1.000)\n1.000 (1.000)\nfor the inclusion of a precondition in the second text block — in our example, the ICD code N18.9\nindicating chronic kidney disease — implying an exception to the rule to disregard the SOFA score\nof the corresponding organ system in the fourth and fifth text blocks. We prepared the data such\nthat some preconditions are seen during training and testing, while we also chose some codes from\nthe same ICD class as out-of-distribution data that were only seen at test time. The codes and their\ndistribution are shown in Tables 9 and 10 in Appendix A.6.\n4\nEXPERIMENTAL SETUP\nData and Models\nIn our experiments, we use electronic health records (EHRs) from the MIMIC-III\ndata (Johnson et al., 2016). After filtering for patients with an ICU stay of at least 24 hours with\nreported gender and age of at least 18 years, our dataset contained 44,858 ICU stays with 56 million\ndata points. We split the data into partitions for fine-tuning (28,708), development (7,270), and testing\n(8,880). For computational reasons, we further subsampled 15,000 datapoints for fine-tuning, and\n3,000 datapoints for development and testing, respectively. The resulting percentage of positive\nSepsis cases in the test set was 7.33%. As features, we considered 131 clinical variables and the\ndemographic variables gender and age (see Appendix A.4). This selection comprises all vital signs\nand laboratory values used in the PhysioNet challenge for early prediction of sepsis (Reyna et al.,\n2019), together with information on suspected infection as in Nemati et al. (2018). The time series\nof clinical observations in the data were split into a 24 hour observation window, followed by a 24\nhour prediction window. During training and testing, we use a sliding window of 24 hours so that\nfull admission days are given as input and output. Using the consensus definition given by Table 5\nand Equation 2, SOFA scores and Sepsis label were calculated deterministically for the given data.\nFollowing this, features and SOFA scores were verbalized into texts as seen in Figure 2. In the\ncalculation of the ground truth, missing values are being carried forward from the previous day only.\nThe basic LLM used in our experiments is a pretrained Llama-3 model with 8B parameters (Grattafiori\net al., 2024) 6 used in one-shot mode. All one-shot experiments use the prompt shown in Appendix\nA.5 that includes the explicit Sepsis-3 rules together with an example instantiation to patient data.\nOur fine-tuned model uses LORA adapters (Hu et al., 2022) on verbalizations of inference processes.\nFurthermore, we use a dedicated medical TSF forecaster, pre-trained on MIMIC-III to improve the\ninductive inference part of the LLM (see Appendix A.2). The TSF model is used in two ways: First,\nwe extract predictions from the forecaster and augment the prompt with those predictions in a pipeline\napproach. In this approach, the Llama-3 model is still finetuned using LORA, but the forecaster is\nkept fixed. Second, we use a multimodal setup to connect the forecaster with the Llama-3 model.\nWe extract the full decoder prediction from the forecaster. The output vectors are then fed into a\nconnector MLP to produce vectors with Llama-3 embedding dimensionality. These time series \"token\nembeddings\" are then prepended to the actual text embeddings. The LORA adapters in the Llama-3\nmodel, the connector MLP, and the TSF model get updated during the finetuning process. A list of\nhyperparameter settings chosen on the validation set (except the default setting for the Llama-3 8B\n6https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct\n6\n"}, {"page": 7, "text": "Table 2: Derivation correctness for in- and out-of-distribution exceptions to inference rules.\nvariable\n% changes ID\n% changes OOD\nID score\nOOD score\nSOFA1:24\n0.404\n0.424\n1.000\n1.000\nSOFA25:48\n0.433\n0.452\n1.000\n1.000\nFigure 3: Derivation correctness (dashed blue arrows) checks for the predicted inference graph\nwhether each child node (conclusion) follows from the parent node (premise) according to the con-\nsensus rule. Value correctness (dotted red arrows) maps each node in the predicted inference graph\nto its corresponding node in the ground truth graph, consisting of real-world clinical measurements\nfor first and second 24 hours, and deterministic calculation of SOFA and SEPSIS on these values.\nmodel) is given in Appendix A.3. For further comparison, we use an 8B parameters LLM pretrained\non medical texts, including publications and wikipedia texts on consensus guidelines (me-llama\n(Xie et al., 2025)7), and a reasoning-style LLM (deepseek (DeepSeek-AI et al., 2025)8), and a 70B\npretrained Llama-3 model (one-shot-70B9), all in one-shot mode.\nEvaluation Metrics\nWe evaluate the generated output of LLMs in three different ways. First,\nwe evaluate the LLM output according to derivation correctness (dashed blue arrows in Figure 3)\nwhich checks whether each child node (conclusion) in the predicted inference graph follows from the\nparent node (premise) according to the consensus rule. This evaluation measures the ability of the\nLLM to learn the deductive inference rules of the consensus definition. Furthermore, it measures\nfaithfulness of the model’s inference process in the sense of checking for an accurate representation\nof the reasoning process behind the model’s prediction. In order to avoid trivial cases of derivation\ncorrectness, for example, inference of unchanged SOFA scores from unchanged future measurement\npredictions, we measure in addition forced derivation correctness. This is done by forcing the\ndecoder to use the correct inference chain up to a last measurement token of a SOFA system as\ncontext, then continuing the decoding process until the specified target node. Furthermore, we conduct\nan evaluation according to value correctness (dotted red arrows in Figure 3) which compares the\nnumerical value of each partial inference node in the prediction graph with a corresponding real-world\noutput. Since errors earlier in the inference necessarily propagate through the inference chain, this\nevaluation measures the utility of the LLM output in practical applications. Comparison in all three\ncases is done by parsing the LLM output for relevant keywords, extracting numbers, and checking\nif the predicted number lies in a specific interval around the true value. A match is considered\npositive if the result deviates from the true value by 5% (see Appendix A.7 for a discussion). In\ncase of value correctness, we calculate a contingency table by comparing the application of the\nSepsis-3 definition to a model involving forecasted clinical measurements with Sepsis-3 calculated for\nreal-world clinical measurements in the second 24 hours block. From this, metrics such as accuracy,\nspecificity, sensitivity and F1 are computed.\n7https://huggingface.co/YBXL/Med-LLaMA3-8B\n8https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B\n9https://huggingface.co/meta-llama/Llama-3.1-70B-Instruct\n7\n"}, {"page": 8, "text": "Table 3: Value correctness of predicted clinical variables compared to real-world measurements.\nAll fine-tuning improvements over one-shot learning are statistically significant according to an\napproximate randomization test.\nvariable\none-shot\none-shot-70B\nme-llama\ndeepseek\nfine-tuned\npipeline\nmultimodal\ncurrent\nGCS-eye\n0.855\n0.982\n0.764\n0.608\n0.998\n0.997\n0.998\nGCS-motor\n0.914\n0.980\n0.733\n0.616\n0.998\n0.998\n0.998\nGCS-verbal\n0.947\n0.985\n0.750\n0.635\n0.999\n0.998\n0.999\nMAP\n0.036\n0.219\n0.046\n0.089\n0.993\n0.976\n0.994\nDopamine\n0.875\n0.952\n0.754\n0.078\n0.972\n0.964\n0.968\nDobutamine\n0.905\n0.978\n0.785\n0.083\n0.993\n0.991\n0.992\nEpinephrine\n0.891\n0.965\n0.773\n0.082\n0.979\n0.980\n0.980\nNorepinephrine\n0.809\n0.875\n0.692\n0.076\n0.909\n0.895\n0.906\nWeight\n0.851\n0.765\n0.722\n0.280\n0.999\n0.999\n0.999\nPaO2/FiO2\n0.140\n0.559\n0.090\n0.059\n0.998\n0.997\n0.997\nPaO2\n0.533\n0.563\n0.352\n0.288\n0.998\n0.997\n0.997\nFiO2\n0.881\n0.711\n0.721\n0.479\n1.000\n1.000\n1.000\nPlatelet\n0.922\n0.966\n0.676\n0.664\n0.997\n0.996\n0.996\nBilirubin\n0.299\n0.275\n0.262\n0.177\n0.999\n0.998\n0.999\nUrine\n0.102\n0.262\n0.095\n0.037\n0.966\n0.761\n0.880\nCreatinine\n0.887\n0.970\n0.666\n0.408\n0.998\n0.998\n0.998\nfuture\nGCS-eye\n0.679\n0.710\n0.525\n0.357\n0.712\n0.743\n0.789\nGCS-motor\n0.783\n0.805\n0.620\n0.398\n0.811\n0.832\n0.869\nGCS-verbal\n0.806\n0.840\n0.648\n0.434\n0.848\n0.871\n0.895\nMAP\n0.110\n0.197\n0.125\n0.064\n0.274\n0.289\n0.294\nDopamine\n0.917\n0.966\n0.766\n0.386\n0.978\n0.987\n0.988\nDobutamine\n0.937\n0.982\n0.787\n0.388\n0.994\n0.993\n0.993\nEpinephrine\n0.933\n0.972\n0.779\n0.381\n0.989\n0.989\n0.989\nNorepinephrine\n0.861\n0.887\n0.710\n0.350\n0.913\n0.914\n0.913\nWeight\n0.851\n0.765\n0.722\n0.280\n0.915\n0.916\n0.914\nPaO2/FiO2\n0.073\n0.156\n0.053\n0.038\n0.565\n0.584\n0.596\nPaO2\n0.181\n0.179\n0.148\n0.098\n0.616\n0.659\n0.715\nFiO2\n0.738\n0.538\n0.613\n0.379\n0.821\n0.840\n0.867\nPlatelet\n0.283\n0.300\n0.236\n0.166\n0.364\n0.383\n0.396\nBilirubin\n0.180\n0.166\n0.169\n0.115\n0.811\n0.832\n0.866\nUrine\n0.064\n0.077\n0.069\n0.023\n0.133\n0.152\n0.183\nCreatinine\n0.360\n0.347\n0.295\n0.161\n0.395\n0.424\n0.455\n5\nRESULTS AND DISCUSSION\nLLMs Shine in Deductive Inference According to Consensus Rules\nOur first research question\nasks whether LLMs can learn the deductive inference rules underlying medical consensus definitions\nby fine-tuning on verbalized instantiations of the inference process to patient data. Table 1 shows\nthat all fine-tuned models, from basic fine-tuning with text encoding to pipeline and multimodal\napproaches, achieve nearly perfect derivation correctness. This includes mapping clinical variables to\nSOFA step functions for the first 24 hours (rows 1-7), mapping forecasted clinical variables to future\nSOFA scores (rows 8-15), and computing a Sepsis label (row 16). In contrast, one-shot learning\ndoes not perform nearly as good, even for models that include abstract consensus definitions in their\ntraining data (me-llama) or prompt and are significantly larger (one-shot-70B). Forced derivation\ncorrectness (in brackets in Table 1) shows that predictions using correct histories are very similar to\nusing predicted histories. Again, all one-shot learners underperform compared to fine-tuning.\nLLMs Can Learn Exceptions to Consensus Rules\nThe next question we ask is whether LLMs\ncan learn exceptions to the inference rules that might conflict with the consensus definition. In our\nhypothetical scenario, we synthesize examples where ICD codes indicate a medical precondition\nrelated to an organ system, with the exception to the rule implying that the SOFA score for the\nrespective organ system should be disregarded in the calculation of total SOFA and Sepsis. Table\n2 shows that the addition of preconditions to the premises caused changes in 40-45% of the cases,\nhowever, the derivation correctness of total SOFA scores was 100% without losing performance on\nexamples without preconditions. This shows that fine-tuning can indeed handle exceptions to the\nrule, opening the doors to possible extensions of our work to include human feedback in the loop.\n8\n"}, {"page": 9, "text": "Table 4: Value correctness of predicted SOFA and SEPSIS scores compared to derivations from real-\nworld clinical measurements. All fine-tuning improvements over one-shot learning are significant.\nvariable\none-shot\none-shot-70B\nme-llama\ndeepseek\nfine-tuned\npipeline\nmultimodal\ncurrent\nSCNS\n0.633\n0.794\n0.478\n0.239\n0.998\n0.997\n0.997\nScardio\n0.405\n0.6\n0.249\n0.273\n0.985\n0.971\n0.987\nSresp\n0.223\n0.411\n0.172\n0.128\n0.996\n0.994\n0.996\nScoag\n0.614\n0.761\n0.497\n0.428\n0.999\n0.999\n0.999\nSliver\n0.492\n0.809\n0.502\n0.208\n1.000\n0.999\n1.000\nSrenal\n0.540\n0.735\n0.412\n0.303\n0.997\n0.992\n0.996\nSOFA1:24\n0.111\n0.236\n0.076\n0.044\n0.979\n0.958\n0.981\nfuture\nSCNS\n0.532\n0.625\n0.408\n0.231\n0.701\n0.732\n0.760\nScardio\n0.426\n0.527\n0.295\n0.195\n0.700\n0.738\n0.745\nSresp\n0.201\n0.348\n0.163\n0.082\n0.746\n0.754\n0.780\nScoag\n0.618\n0.693\n0.483\n0.278\n0.839\n0.823\n0.834\nSliver\n0.492\n0.809\n0.502\n0.208\n0.945\n0.945\n0.945\nSrenal\n0.482\n0.620\n0.365\n0.211\n0.553\n0.451\n0.473\nSOFA25:48\n0.117\n0.176\n0.088\n0.059\n0.203\n0.220\n0.243\nSOFAdiff\n0.139\n0.167\n0.128\n0.127\n0.151\n0.147\n0.163\nSEPSIS Accuracy\n0.834\n0.857\n0.763\n0.692\n0.868\n0.873\n0.886\nSEPSIS Specificity\n0.876\n0.915\n0.788\n0.739\n0.936\n0.920\n0.922\nSEPSIS Sensitivity\n0.3318\n0.118\n0.455\n0.091\n0.263\n0.336\n0.386\nSEPSIS F1\n0.231\n0.108\n0.220\n0.042\n0.254\n0.272\n0.309\nThe Bottleneck Lies in Inductive Inference, not Out-of-Distribution Generalization\nOur final\nevaluation compares the results of partial inference steps to real-world clinical measurements and to\nSOFA and Sepsis scores derived from these. As shown in the first half of Table 3, the numerical values\nthat the LLM decoder has to extract from time series encodings are nearly perfect for fine-tuning\napproaches. The second half of Table 3 reveals the bottleneck of teaching medical inference rules to\nLLMs: Correctness of predicting values of 131 clinical variables 24 hours into the future drops from\nthe high nineties to values in the tens and twenties, especially for sparsely and irregularly observed\nlab values. The same is true for value correctness of predicted SOFA scores and Sepsis labels: As\nshown in Table 4, the numerical values produced by mapping clinical measurements in the first 24\nhours to SOFA scores are nearly perfect, however, mapping values of forecasted clinical variables\nto step functions severely impacts correctness, especially on metrics like F1 that are sensitive to\nimbalanced data. One-shot learning is impacted even more, while fine-tuning results can be improved\nby moving from a text-based encoding to coupling dedicated TSF encoders with the LLM.\nDiscussion\nLeveraging consensus rules that exist for many medical areas, consistent diagnoses for\nunseen patients and faithful medical inference even including exceptions to the rules can be achieved\nby fine-tuning LLMs on instantiations of the respective consensus rule system to patient data. In\ncontrast, training or prompting with abstract rules or on very large general-domain data is insufficient.\nSince an adaptation of an LLM to consensus rules for a specific medical area yields consistent results\nand faithful medical inference in that area, the bottleneck in consensus-based medical prediction\nlies in the orthogonal problem of generalization into the future, i.e., in the inherent complexity of\nforecasting of sparsely and irregularly sampled clinical variables for early prediction. This problem\nhinders medical prognosis, and needs to be addressed by improved TSF.\n6\nCONCLUSION\nLLMs have been shown to excel at various health-related tasks, however, diagnostic AI has not\nrealized the potential to actually reduce the cognitive demand and associated diagnostic errors of\nclinicians, due to a focus on predictive accuracy of final diagnostic labels (Adler-Milstein et al., 2021).\nFurthermore, instead of defining diagnostic excellence by perfect labeling based on fully established\nclinical criteria, Angus & Bindman (2022) advocate to learn patterns of clinical data that are yet\nunrecognized but still predictive of sepsis. Our approach can be seen as a first step towards these goals\nby putting a focus on teaching LLMs inference rules that support clinicians, and to learn exceptions to\nthe rules that can capture new clinical patterns. Our experiments show that LLMs perfectly generalize\ndeductive inference to unseen patients, while the bottleneck lies in inductive inference. Future work\n9\n"}, {"page": 10, "text": "shall address the TSF bottleneck of early prediction models, and elevate our work from simulating\nexceptions to the rule to learning them from real-world clinical data. Furthermore, we will investigate\nthe potential of task association learning (Cai et al., 2025) applied to related consensus definitions.\nREPRODUCIBILITY STATEMENT\nThis work is based on publicly available data and open-source code. Code to reproduce our exper-\niments is available at https://github.com/StatNLP/guideline_based_medical_\nreasoning_LLM\nREFERENCES\nJulia Adler-Milstein, Jonathan H. Chen, and Gurpreet Dhaliwal. Next-generation artificial intelligence\nfor diagnosis: From predicting diagnostic labels to \"wayfinding\". JAMA, 326(24):2467–2468,\n2021. URL https://doi.org/10.1001/jama.2021.22396.\nAmerican Psychiatric Association (ed.). Diagnostic and Statistical Manual of Mental Disorders. Fifth\nedition, 2013. URL https://doi/book/10.1176/appi.books.9780890425787.\nDerek C. Angus and Andrew B. Bindman. Achieving diagnostic excellence for sepsis. JAMA, 327\n(2):117–118, 2022. URL https://doi.org/10.1001/jama.2021.23916.\nIván Arcuschin, Jett Janiak, Robert Krzyzanowski, Senthooran Rajamanoharan, Neel Nanda, and\nArthur Conmy. Chain-of-thought reasoning in the wild is not always faithful. In ICRL Workshop\non Reasoning and Planning for Large Language Models, 2025. URL https://openreview.\nnet/forum?id=L8094Whth0.\nZiyang Cai, Nayoung Lee, Avi Schwarzschild, Samet Oymak, and Dimitris Papailiopoulos. Extrapo-\nlation by association: Length generalization transfer in transformers. arXiv, abs/2506.09251, 2025.\nURL https://arxiv.org/abs/2506.09251.\nT. Cederholm, G.L. Jensen, M.I.T.D. Correia, M.C. Gonzalez, R. Fukushima, T. Higashiguchi,\nG. Baptista, R. Barazzoni, R. Blaauw, A. Coats, A. Crivelli, D.C. Evans, L. Gramlich, V. Fuchs-\nTarlovsky, H. Keller, L. Llido, A. Malone, K.M. Mogensen, J.E. Morley, M. Muscaritoli, I. Nyulasi,\nM. Pirlich, V. Pisprasert, M.A.E. de van der Schueren, S. Siltharm, P. Singer, K. Tappenden,\nN. Velasco, D. Waitzberg, P. Yamwong, J. Yu, A. Van Gossum, C. Compher, Gordon L. Jensen,\nCompher Charlene, Tommy Cederholm, Andre Van Gossum, Maria Isabel T.D. Correia, M. Cristina\nGonzalez, Ryoji Fukushima, Takashi Higashiguchi, G. Baptista, R. Barazzoni, R. Blaauw, A. Coats,\nA. Crivelli, D.C. Evans, L. Gramlich, V. Fuchs, H. Keller, L. Llido, A. Malone, K.M. Mogensen,\nJ.E. Morley, M. Muscaritoli, I. Nyulasi, M. Pirlich, V. Pisprasert, M.A.E. de van der Schueren,\nS. Siltharm, P. Singer, K. Tappenden, N. Velasco, D. Waitzberg, P. Yamwong, and J. Yu. GLIM\ncriteria for the diagnosis of malnutrition – a consensus report from the global clinical nutrition\ncommunity. Clinical Nutrition, 38(1):1–9, 2019. URL https://doi.org/10.1016/j.\nclnu.2018.08.002.\nJunying Chen, Zhenyang Cai, Ke Ji, Xidong Wang, Wanlong Liu, Rongsheng Wang, Jianye Hou,\nand Benyou Wang. Huatuogpt-o1, towards medical complex reasoning with LLMs. arXiv,\nabs/2412.18925, 2024. URL https://arxiv.org/abs/2412.18925.\nYanda Chen, Joe Benton, Ansh Radhakrishnan, Jonathan Uesato, Carson Denison, John Schulman,\nArushi Somani, Peter Hase, Misha Wagner, Fabien Roger, Vlad Mikulik, Samuel R. Bowman, Jan\nLeike, Jared Kaplan, and Ethan Perez. Reasoning models don’t always say what they think. arXiv,\nabs/2505.05410, 2025. URL https://arxiv.org/abs/2505.05410.\nZeming Chen, Alejandro Hernández Cano, Angelika Romanou, Antoine Bonnet, Kyle Matoba,\nFrancesco Salvi, Matteo Pagliardini, Simin Fan, Andreas Köpf, Amirkeivan Mohtashami, Alexan-\ndre Sallinen, Alireza Sakhaeirad, Vinitra Swamy, Igor Krawczuk, Deniz Bayazit, Axel Marmet,\nSyrielle Montariol, Mary-Anne Hartley, Martin Jaggi, and Antoine Bosselut. Meditron-70b:\nScaling medical pretraining for large language models. arXiv, abs/2311.16079, 2023. URL\nhttps://arxiv.org/abs/2311.16079.\n10\n"}, {"page": 11, "text": "Jee-Woo Choi, Minuk Yang, Jae-Woo Kim, Yoon Mi Shin, Yong-Goo Shin, and Seung Park. Prog-\nnostic prediction of sepsis patient using transformer with skip connected token for tabular data.\nArtificial Intelligence in Medicine, 149:102804, 2024. URL https://doi.org/10.1016/j.\nartmed.2024.102804.\nErik E. Christensen, Christian H. Prebensen, Anders B. Martinsen, Elisabeth T. Stiff, Rune Hoff,\nDag Kvale, and Aleksander R. Holten. Mortality and sequential organ failure assessment score in\npatients with suspected sepsis: The impact of acute and preexisting organ failures and infection\nlikelihood. Critical Care Explorations, 5(2):e0895, 2023. URL https://doi.org/10.\n1097/cce.0000000000000865.\nTianzhe Chu, Yuexiang Zhai, Jihan Yang, Shengbang Tong, Saining Xie, Dale Schuurmans, Quoc V\nLe, Sergey Levine, and Yi Ma. SFT memorizes, RL generalizes: A comparative study of foundation\nmodel post-training. In Forty-second International Conference on Machine Learning (ICML),\n2025. URL https://openreview.net/forum?id=dYur3yabMj.\nSamuel N. Cohen, James Foster, Peter Foster, Hang Lou, Terry Lyons, Sam Morley, James Mor-\nrill, Hao Ni, Edward Palmer, Bo Wang, Yue Wu, Lingyi Yang, and Weixin Yang.\nSubtle\nvariation in sepsis-III definitions markely influences predictive performance within and across\nmethods.\nscientific reports, 14(1920):1–10, 2024.\nURL https://doi.org/10.1038/\ns41598-024-51989-6.\nDeepSeek-AI, Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu,\nQihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, Xiaokang Zhang, Xingkai Yu, Yu Wu, Z. F. Wu,\nZhibin Gou, Zhihong Shao, Zhuoshu Li, Ziyi Gao, Aixin Liu, Bing Xue, Bingxuan Wang, Bochao\nWu, Bei Feng, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan,\nDamai Dai, Deli Chen, Dongjie Ji, Erhang Li, Fangyun Lin, Fucong Dai, Fuli Luo, Guangbo Hao,\nGuanting Chen, Guowei Li, H. Zhang, Han Bao, Hanwei Xu, Haocheng Wang, Honghui Ding,\nHuajian Xin, Huazuo Gao, Hui Qu, Hui Li, Jianzhong Guo, Jiashi Li, Jiawei Wang, Jingchang\nChen, Jingyang Yuan, Junjie Qiu, Junlong Li, J. L. Cai, Jiaqi Ni, Jian Liang, Jin Chen, Kai Dong,\nKai Hu, Kaige Gao, Kang Guan, Kexin Huang, Kuai Yu, Lean Wang, Lecong Zhang, Liang Zhao,\nLitong Wang, Liyue Zhang, Lei Xu, Leyi Xia, Mingchuan Zhang, Minghua Zhang, Minghui Tang,\nMeng Li, Miaojun Wang, Mingming Li, Ning Tian, Panpan Huang, Peng Zhang, Qiancheng Wang,\nQinyu Chen, Qiushi Du, Ruiqi Ge, Ruisong Zhang, Ruizhe Pan, Runji Wang, R. J. Chen, R. L.\nJin, Ruyi Chen, Shanghao Lu, Shangyan Zhou, Shanhuang Chen, Shengfeng Ye, Shiyu Wang,\nShuiping Yu, Shunfeng Zhou, Shuting Pan, S. S. Li, Shuang Zhou, Shaoqing Wu, Shengfeng\nYe, Tao Yun, Tian Pei, Tianyu Sun, T. Wang, Wangding Zeng, Wanjia Zhao, Wen Liu, Wenfeng\nLiang, Wenjun Gao, Wenqin Yu, Wentao Zhang, W. L. Xiao, Wei An, Xiaodong Liu, Xiaohan\nWang, Xiaokang Chen, Xiaotao Nie, Xin Cheng, Xin Liu, Xin Xie, Xingchao Liu, Xinyu Yang,\nXinyuan Li, Xuecheng Su, Xuheng Lin, X. Q. Li, Xiangyue Jin, Xiaojin Shen, Xiaosha Chen,\nXiaowen Sun, Xiaoxiang Wang, Xinnan Song, Xinyi Zhou, Xianzu Wang, Xinxia Shan, Y. K. Li,\nY. Q. Wang, Y. X. Wei, Yang Zhang, Yanhong Xu, Yao Li, Yao Zhao, Yaofeng Sun, Yaohui Wang,\nYi Yu, Yichao Zhang, Yifan Shi, Yiliang Xiong, Ying He, Yishi Piao, Yisong Wang, Yixuan Tan,\nYiyang Ma, Yiyuan Liu, Yongqiang Guo, Yuan Ou, Yuduan Wang, Yue Gong, Yuheng Zou, Yujia\nHe, Yunfan Xiong, Yuxiang Luo, Yuxiang You, Yuxuan Liu, Yuyang Zhou, Y. X. Zhu, Yanhong\nXu, Yanping Huang, Yaohui Li, Yi Zheng, Yuchen Zhu, Yunxian Ma, Ying Tang, Yukun Zha,\nYuting Yan, Z. Z. Ren, Zehui Ren, Zhangli Sha, Zhe Fu, Zhean Xu, Zhenda Xie, Zhengyan Zhang,\nZhewen Hao, Zhicheng Ma, Zhigang Yan, Zhiyu Wu, Zihui Gu, Zijia Zhu, Zijun Liu, Zilin Li,\nZiwei Xie, Ziyang Song, Zizheng Pan, Zhen Huang, Zhipeng Xu, Zhongyu Zhang, and Zhen\nZhang. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv,\nabs/2501.12948, 2025. URL https://arxiv.org/abs/2501.12948.\nR.P. Dellinger, M.M. Levy, A. Rhodes, D. Annane, H. Gerlach, S.M.Opal, J.E. Sevransky, C.L.\nSprung, I.S. Douglas, /R. Jaeschke ant T.M. Osborn, M.E. Nunnally, S.R. Townsend, K. Reinhart,\nR.M. Kleinpell, D.C. Angus, C.S. Deutschman, F.R. Machado, G.D. Rubenfeld, S.A. Webb, R.J.\nBeale, J.L. Vincent, and R. Moreno. Surviving sepsis campaign: international guidelines for\nmanagement of severe sepsis and septic shock: 2012. Critical Care Medicine, 41(2):580–637,\n2013. URL http://dx.doi.org/10.1097/CCM.0b013e31827e83af.\nNouha Dziri, Ximing Lu, Melanie Sclar, Xiang Lorraine Li, Liwei Jiang, Bill Yuchen Lin, Sean\nWelleck, Peter West, Chandra Bhagavatula, Ronan Le Bras, Jena D. Hwang, Soumya Sanyal, Xiang\n11\n"}, {"page": 12, "text": "Ren, Allyson Ettinger, Zaid Harchaoui, and Yejin Choi. Faith and fate: Limits of transformers\non compositionality. In Thirty-seventh Conference on Neural Information Processing Systems\n(NeurIPS), 2023. URL https://openreview.net/forum?id=Fkckkr3ya8.\nKevin W. Eva. What every teacher needs to know about clinical reasoning. Med Educ, 39(1):98–106,\n2005. URL https://doi.org/10.1111/j.1365-2929.2004.01972.x.\nZiqing Fan, Cheng Liang, Chaoyi Wu, Ya Zhang, Yanfeng Wang, and Weidi Xie. Chestx-reasoner:\nAdvancing radiology foundation models with reasoning through step-by-step verification. arxiv,\nabs/2504.20930, 2025. URL https://arxiv.org/abs/2504.20930.\nAaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad\nAl-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, Amy Yang, Angela\nFan, Anirudh Goyal, Anthony Hartshorn, Aobo Yang, Archi Mitra, Archie Sravankumar, Artem\nKorenev, Arthur Hinsvark, Arun Rao, Aston Zhang, Aurelien Rodriguez, Austen Gregerson, Ava\nSpataru, Baptiste Roziere, Bethany Biron, Binh Tang, Bobbie Chern, Charlotte Caucheteux, Chaya\nNayak, Chloe Bi, Chris Marra, Chris McConnell, Christian Keller, Christophe Touret, Chunyang\nWu, Corinne Wong, Cristian Canton Ferrer, Cyrus Nikolaidis, Damien Allonsius, Daniel Song,\nDanielle Pintz, Danny Livshits, Danny Wyatt, David Esiobu, Dhruv Choudhary, Dhruv Mahajan,\nDiego Garcia-Olano, Diego Perino, Dieuwke Hupkes, Egor Lakomkin, Ehab AlBadawy, Elina\nLobanova, Emily Dinan, Eric Michael Smith, Filip Radenovic, Francisco Guzmán, Frank Zhang,\nGabriel Synnaeve, Gabrielle Lee, Georgia Lewis Anderson, Govind Thattai, Graeme Nail, Gregoire\nMialon, Guan Pang, Guillem Cucurell, Hailey Nguyen, Hannah Korevaar, Hu Xu, Hugo Touvron,\nIliyan Zarov, Imanol Arrieta Ibarra, Isabel Kloumann, Ishan Misra, Ivan Evtimov, Jack Zhang,\nJade Copet, Jaewon Lee, Jan Geffert, Jana Vranes, Jason Park, Jay Mahadeokar, Jeet Shah, Jelmer\nvan der Linde, Jennifer Billock, Jenny Hong, Jenya Lee, Jeremy Fu, Jianfeng Chi, Jianyu Huang,\nJiawen Liu, Jie Wang, Jiecao Yu, Joanna Bitton, Joe Spisak, Jongsoo Park, Joseph Rocca, Joshua\nJohnstun, Joshua Saxe, Junteng Jia, Kalyan Vasuden Alwala, Karthik Prasad, Kartikeya Upasani,\nKate Plawiak, Ke Li, Kenneth Heafield, Kevin Stone, Khalid El-Arini, Krithika Iyer, Kshitiz\nMalik, Kuenley Chiu, Kunal Bhalla, Kushal Lakhotia, Lauren Rantala-Yeary, Laurens van der\nMaaten, Lawrence Chen, Liang Tan, Liz Jenkins, Louis Martin, Lovish Madaan, Lubo Malo,\nLukas Blecher, Lukas Landzaat, Luke de Oliveira, Madeline Muzzi, Mahesh Pasupuleti, Mannat\nSingh, Manohar Paluri, Marcin Kardas, Maria Tsimpoukelli, Mathew Oldham, Mathieu Rita, Maya\nPavlova, Melanie Kambadur, Mike Lewis, Min Si, Mitesh Kumar Singh, Mona Hassan, Naman\nGoyal, Narjes Torabi, Nikolay Bashlykov, Nikolay Bogoychev, Niladri Chatterji, Ning Zhang,\nOlivier Duchenne, Onur Çelebi, Patrick Alrassy, Pengchuan Zhang, Pengwei Li, Petar Vasic,\nPeter Weng, Prajjwal Bhargava, Pratik Dubal, Praveen Krishnan, Punit Singh Koura, Puxin Xu,\nQing He, Qingxiao Dong, Ragavan Srinivasan, Raj Ganapathy, Ramon Calderer, Ricardo Silveira\nCabral, Robert Stojnic, Roberta Raileanu, Rohan Maheswari, Rohit Girdhar, Rohit Patel, Romain\nSauvestre, Ronnie Polidoro, Roshan Sumbaly, Ross Taylor, Ruan Silva, Rui Hou, Rui Wang, Saghar\nHosseini, Sahana Chennabasappa, Sanjay Singh, Sean Bell, Seohyun Sonia Kim, Sergey Edunov,\nShaoliang Nie, Sharan Narang, Sharath Raparthy, Sheng Shen, Shengye Wan, Shruti Bhosale,\nShun Zhang, Simon Vandenhende, Soumya Batra, Spencer Whitman, Sten Sootla, Stephane\nCollot, Suchin Gururangan, Sydney Borodinsky, Tamar Herman, Tara Fowler, Tarek Sheasha,\nThomas Georgiou, Thomas Scialom, Tobias Speckbacher, Todor Mihaylov, Tong Xiao, Ujjwal\nKarn, Vedanuj Goswami, Vibhor Gupta, Vignesh Ramanathan, Viktor Kerkez, Vincent Gonguet,\nVirginie Do, Vish Vogeti, Vítor Albiero, Vladan Petrovic, Weiwei Chu, Wenhan Xiong, Wenyin\nFu, Whitney Meers, Xavier Martinet, Xiaodong Wang, Xiaofang Wang, Xiaoqing Ellen Tan, Xide\nXia, Xinfeng Xie, Xuchao Jia, Xuewei Wang, Yaelle Goldschlag, Yashesh Gaur, Yasmine Babaei,\nYi Wen, Yiwen Song, Yuchen Zhang, Yue Li, Yuning Mao, Zacharie Delpierre Coudert, Zheng Yan,\nZhengxing Chen, Zoe Papakipos, Aaditya Singh, Aayushi Srivastava, Abha Jain, Adam Kelsey,\nAdam Shajnfeld, Adithya Gangidi, Adolfo Victoria, Ahuva Goldstand, Ajay Menon, Ajay Sharma,\nAlex Boesenberg, Alexei Baevski, Allie Feinstein, Amanda Kallet, Amit Sangani, Amos Teo,\nAnam Yunus, Andrei Lupu, Andres Alvarado, Andrew Caples, Andrew Gu, Andrew Ho, Andrew\nPoulton, Andrew Ryan, Ankit Ramchandani, Annie Dong, Annie Franco, Anuj Goyal, Aparajita\nSaraf, Arkabandhu Chowdhury, Ashley Gabriel, Ashwin Bharambe, Assaf Eisenman, Azadeh\nYazdan, Beau James, Ben Maurer, Benjamin Leonhardi, Bernie Huang, Beth Loyd, Beto De Paola,\nBhargavi Paranjape, Bing Liu, Bo Wu, Boyu Ni, Braden Hancock, Bram Wasti, Brandon Spence,\nBrani Stojkovic, Brian Gamido, Britt Montalvo, Carl Parker, Carly Burton, Catalina Mejia, Ce Liu,\nChanghan Wang, Changkyu Kim, Chao Zhou, Chester Hu, Ching-Hsiang Chu, Chris Cai, Chris\n12\n"}, {"page": 13, "text": "Tindal, Christoph Feichtenhofer, Cynthia Gao, Damon Civin, Dana Beaty, Daniel Kreymer, Daniel\nLi, David Adkins, David Xu, Davide Testuggine, Delia David, Devi Parikh, Diana Liskovich,\nDidem Foss, Dingkang Wang, Duc Le, Dustin Holland, Edward Dowling, Eissa Jamil, Elaine\nMontgomery, Eleonora Presani, Emily Hahn, Emily Wood, Eric-Tuan Le, Erik Brinkman, Esteban\nArcaute, Evan Dunbar, Evan Smothers, Fei Sun, Felix Kreuk, Feng Tian, Filippos Kokkinos, Firat\nOzgenel, Francesco Caggioni, Frank Kanayet, Frank Seide, Gabriela Medina Florez, Gabriella\nSchwarz, Gada Badeer, Georgia Swee, Gil Halpern, Grant Herman, Grigory Sizov, Guangyi, Zhang,\nGuna Lakshminarayanan, Hakan Inan, Hamid Shojanazeri, Han Zou, Hannah Wang, Hanwen Zha,\nHaroun Habeeb, Harrison Rudolph, Helen Suk, Henry Aspegren, Hunter Goldman, Hongyuan\nZhan, Ibrahim Damlaj, Igor Molybog, Igor Tufanov, Ilias Leontiadis, Irina-Elena Veliche, Itai\nGat, Jake Weissman, James Geboski, James Kohli, Janice Lam, Japhet Asher, Jean-Baptiste Gaya,\nJeff Marcus, Jeff Tang, Jennifer Chan, Jenny Zhen, Jeremy Reizenstein, Jeremy Teboul, Jessica\nZhong, Jian Jin, Jingyi Yang, Joe Cummings, Jon Carvill, Jon Shepard, Jonathan McPhie, Jonathan\nTorres, Josh Ginsburg, Junjie Wang, Kai Wu, Kam Hou U, Karan Saxena, Kartikay Khandelwal,\nKatayoun Zand, Kathy Matosich, Kaushik Veeraraghavan, Kelly Michelena, Keqian Li, Kiran\nJagadeesh, Kun Huang, Kunal Chawla, Kyle Huang, Lailin Chen, Lakshya Garg, Lavender A,\nLeandro Silva, Lee Bell, Lei Zhang, Liangpeng Guo, Licheng Yu, Liron Moshkovich, Luca\nWehrstedt, Madian Khabsa, Manav Avalani, Manish Bhatt, Martynas Mankus, Matan Hasson,\nMatthew Lennie, Matthias Reso, Maxim Groshev, Maxim Naumov, Maya Lathi, Meghan Keneally,\nMiao Liu, Michael L. Seltzer, Michal Valko, Michelle Restrepo, Mihir Patel, Mik Vyatskov,\nMikayel Samvelyan, Mike Clark, Mike Macey, Mike Wang, Miquel Jubert Hermoso, Mo Metanat,\nMohammad Rastegari, Munish Bansal, Nandhini Santhanam, Natascha Parks, Natasha White,\nNavyata Bawa, Nayan Singhal, Nick Egebo, Nicolas Usunier, Nikhil Mehta, Nikolay Pavlovich\nLaptev, Ning Dong, Norman Cheng, Oleg Chernoguz, Olivia Hart, Omkar Salpekar, Ozlem\nKalinli, Parkin Kent, Parth Parekh, Paul Saab, Pavan Balaji, Pedro Rittner, Philip Bontrager,\nPierre Roux, Piotr Dollar, Polina Zvyagina, Prashant Ratanchandani, Pritish Yuvraj, Qian Liang,\nRachad Alao, Rachel Rodriguez, Rafi Ayub, Raghotham Murthy, Raghu Nayani, Rahul Mitra,\nRangaprabhu Parthasarathy, Raymond Li, Rebekkah Hogan, Robin Battey, Rocky Wang, Russ\nHowes, Ruty Rinott, Sachin Mehta, Sachin Siby, Sai Jayesh Bondu, Samyak Datta, Sara Chugh,\nSara Hunt, Sargun Dhillon, Sasha Sidorov, Satadru Pan, Saurabh Mahajan, Saurabh Verma, Seiji\nYamamoto, Sharadh Ramaswamy, Shaun Lindsay, Shaun Lindsay, Sheng Feng, Shenghao Lin,\nShengxin Cindy Zha, Shishir Patil, Shiva Shankar, Shuqiang Zhang, Shuqiang Zhang, Sinong Wang,\nSneha Agarwal, Soji Sajuyigbe, Soumith Chintala, Stephanie Max, Stephen Chen, Steve Kehoe,\nSteve Satterfield, Sudarshan Govindaprasad, Sumit Gupta, Summer Deng, Sungmin Cho, Sunny\nVirk, Suraj Subramanian, Sy Choudhury, Sydney Goldman, Tal Remez, Tamar Glaser, Tamara\nBest, Thilo Koehler, Thomas Robinson, Tianhe Li, Tianjun Zhang, Tim Matthews, Timothy Chou,\nTzook Shaked, Varun Vontimitta, Victoria Ajayi, Victoria Montanez, Vijai Mohan, Vinay Satish\nKumar, Vishal Mangla, Vlad Ionescu, Vlad Poenaru, Vlad Tiberiu Mihailescu, Vladimir Ivanov,\nWei Li, Wenchen Wang, Wenwen Jiang, Wes Bouaziz, Will Constable, Xiaocheng Tang, Xiaojian\nWu, Xiaolan Wang, Xilun Wu, Xinbo Gao, Yaniv Kleinman, Yanjun Chen, Ye Hu, Ye Jia, Ye Qi,\nYenda Li, Yilin Zhang, Ying Zhang, Yossi Adi, Youngjin Nam, Yu, Wang, Yu Zhao, Yuchen Hao,\nYundi Qian, Yunlu Li, Yuzi He, Zach Rait, Zachary DeVito, Zef Rosnbrick, Zhaoduo Wen, Zhenyu\nYang, Zhiwei Zhao, and Zhiyu Ma. The Llama 3 herd of models. arXiv, abs/2407.21783, 2024.\nURL https://arxiv.org/abs/2407.21783.\nPaul Hager, Friederike Jungmann, Robbie Holland, Kunal Bhagat, Inga Hubrecht, Manuel Knauer,\nJakob Vielhauer, Marcus Makowski, Rickmer Braren, Georgios Kaissis, and Daniel Rueckert.\nEvaluation and mitigation of the limitations of large language models in clinical decision-making.\nNature Medicine, 30, 2024. URL https://doi.org/10.1038/s41591-024-03097-1.\nAndreas Hochlehnert, Hardik Bhatnagar, Vishaal Udandarao, Samuel Albanie, Ameya Prabhu, and\nMatthias Bethge. A sober look at progress in language model reasoning: Pitfalls and paths to\nreproducibility. In Second Conference on Language Modeling (COLM), 2025. URL https:\n//openreview.net/forum?id=90UrTTxp5O.\nEdward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,\nand Weizhu Chen. LoRA: Low-rank adaptation of large language models. In International\nConference on Learning Representations (ICLR), virtual, 2022. URL https://openreview.\nnet/forum?id=nZeVKeeFYf9.\n13\n"}, {"page": 14, "text": "Alon Jacovi and Yoav Goldberg. Towards faithfully interpretable NLP systems: How should we\ndefine and evaluate faithfulness? In Proceedings of the 58th Annual Meeting of the Association\nfor Computational Linguistics (ACL), Online, 2020. URL https://aclanthology.org/\n2020.acl-main.386/.\nAlistair E. W. Johnson, Lucas Bulgarelli, Lu Shen, Alvin Gayles, Ayad Shammout, Steven Horng,\nTom J. Pollard, Sicheng Hao, Benjamin Moody, Brian Gow, Li-wei H. Lehman, Leo A. Celi, and\nRoger G. Mark. MIMIC-IV, a freely accessible electronic health record dataset. Scientific Data,\n10(1), 2023. URL https://doi.org/10.1038/s41597-022-01899-x.\nAlistair E.W. Johnson, Tom J. Pollard, Lu Shen, Li wei H. Lehman, Mengling Feng, Mohammad\nGhassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G. Mark. MIMIC-III,\na freely accessible critical care database. Scientific Data, 3(1):160035, 2016. URL https:\n//doi.org/10.1038/sdata.2016.35.\nKDIGO Acute Kidney Injury Work Group. Kidney disease: Improving global outcomes (KDIGO) -\nCinical practice guideline for acute kidney injury. Kidney international supplements, 2(1):1–138,\n2012. URL doi:10.1038/kisup.2012.1.\nTamera Lanham, Anna Chen, Ansh Radhakrishnan, Benoit Steiner, Carson Denison, Danny Her-\nnandez, Dustin Li, Esin Durmus, Evan Hubinger, Jackson Kernion, Kamil˙e Lukoši¯ut˙e, Karina\nNguyen, Newton Cheng, Nicholas Joseph, Nicholas Schiefer, Oliver Rausch, Robin Larson, Sam\nMcCandlish, Sandipan Kundu, Saurav Kadavath, Shannon Yang, Thomas Henighan, Timothy\nMaxwell, Timothy Telleen-Lawton, Tristan Hume, Zac Hatfield-Dodds, Jared Kaplan, Jan Brauner,\nSamuel R. Bowman, and Ethan Perez. Measuring faithfulness in chain-of-thought reasoning. arXiv,\nabs/2307.13702, 2023. URL https://arxiv.org/abs/2307.13702.\nMitchell M. Levy, Mitchell P. Fink, John C. Marshall, Edward Abraham, Derek Angus, Deborah\nCook, Jonathan Cohen, Steven M. Opal, Jean-Louis Vincent, and Graham Ramsay. 2001 SC-\nCM/ESICM/ACCP/ATS/SIS International Sepsis Definitions Conference. Critical Care Medicine,\n31(04):1250–1256, 2003.\nURL https://doi.org/10.1097/01.ccm.0000050454.\n01978.3b.\nQiang Li, Hanbo Ma, Dan Song, Yunpeng Bai, Lina Zhao, and Keliang Xie. Early prediction of\nsepsis using chatgpt-generated summaries and structured data. Multimedia Tools and Applications,\npp. 1–23, 2024. URL https://doi.org/10.1007/s11042-024-18378-7.\nXiaohong Liu, Hao Liu, Guoxing Yang, Zeyu Jiang, Shuguang Cui, Zhaoze Zhang, Huan Wang,\nLiyuan Tao, Yongchang Sun, Zhu Song, Tianpei Hong, Jin Yang, Tianrun Gao, Jiangjiang Zhang,\nXiaohu Li, Jing Zhang, Ye Sang, Zhao Yang, Kanmin Xue, Song Wu, Ping Zhang, Jian Yang,\nChunli Song, and Guangyu Wang. A generalist medical language model for disease diagno-\nsis assistance. Nature Medicine, 31:932–942, 2025. URL https://doi.org/10.1038/\ns41591-024-03416-6.\nXin Liu, Daniel McDuff, Geza Kovacs, Isaac Galatzer-Levy, Jacob Sunshine, Jiening Zhan, Ming-\nZher Poh, Shun Liao, Paolo Di Achille, and Shwetak Patel. Large language models are few-shot\nhealth learners. arXiv, abs/2305.15525, 2023. URL https://doi.org/10.48550/arXiv.\n2305.15525.\nQing Lyu, Shreya Havaldar, Adam Stein, Li Zhang, Delip Rao, Eric Wong, Marianna Apidianaki, and\nChris Callison-Burch. Faithful chain-of-thought reasoning. In Proceedings of the 13th International\nJoint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific\nChapter of the Association for Computational Linguistics (IJCNLP), Nusa Dua, Bali, 2023. URL\n10.18653/v1/2023.ijcnlp-main.20.\nW. I. McDonald, A. Compston, G. Edan, D. Goodkin, H. P. Hartung, F. D. Lublin, H. F. McFarland,\nD. W. Paty, C. H. Polman, S. C. Reingold, M. Sandberg-Wollheim, W. Sibley, A. Thompson,\nS. van den Noort, B. Y. Weinshenker, and J. S. Wolinsky. Recommended diagnostic criteria for\nmultiple sclerosis: guidelines from the international panel on the diagnosis of multiple sclerosis.\nAnnals of Neurology, 50(1):121–127, 2001. doi: https://doi.org/10.1002/ana.1032.\n14\n"}, {"page": 15, "text": "Mike A Merrill, Mingtian Tan, Vinayak Gupta, Thomas Hartvigsen, and Tim Althoff. Language\nmodels still struggle to zero-shot reason about time series. In Findings of the Association for\nComputational Linguistics: EMNLP 2024, Miami, Florida, USA, 2024. URL 10.18653/v1/\n2024.findings-emnlp.201.\nPhilipp Mondorf and Barbara Plank. Beyond accuracy: Evaluating the reasoning behavior of large\nlanguage models - a survey. In First Conference on Language Modeling (COLM), 2024. URL\nhttps://openreview.net/forum?id=Lmjgl2n11u.\nMichael Moor, Bastian Rieck, Max Horn, Catherine Jutzeler, and Karsten Borgwardt. Early prediction\nof sepsis in the ICU using machine learning: A systematic review. Frontiers in Medicine, 8, 2021.\nURL https://doi.org/10.3389/fmed.2021.607952.\nShamim Nemati, Andre Holder, Fereshteh Razmi, Matthew D. Stanley, Gari D. Clifford, and\nTimothy G. Buchman. An interpretable machine learning model for accurate prediction of sepsis\nin the ICU. Critical Care Medicine, 46(4):547–553, 2018. URL http://dx.doi.org/10.\n1097/ccm.0000000000002936.\nGeoffrey Norman. Research in clinical reasoning: past history and current trends. Med Educ, 39(4):\n418–27, 2005. URL https://doi.org/10.1111/j.1365-2929.2005.02127.x.\nMaxwell I. Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David\nBieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, Charles Sutton, and\nAugustus Odena. Show your work: Scratchpads for intermediate computation with language\nmodels. arXiv, abs/2112.00114, 2021. URL https://arxiv.org/abs/2112.00114.\nTom J. Pollard, Alistair E. W. Johnson, Jesse D. Raffa, Leo A. Celi, Roger G. Mark, and Omar\nBadawi. The eICU collaborative research database, a freely available multi-center database for\ncritical care research. Scientific Data, 5(180178), 2018. URL https://doi.org/10.1038/\nsdata.2018.178.\nJustin T. Reese, Daniel Danis, J. Harry Caufield, Tudor Groza, Elena Casiraghi, Giorgio Valentini,\nChristopher J. Mungall, and Peter N. Robinson. On the limitations of large language models\nin clinical diagnosis. medRxiv, 2024. URL https://doi.org/10.1101/2023.07.13.\n23292613.\nMatthew A. Reyna, Christopher S. Josef, Russell Jeter, Supreeth P.B. Shashikumar, M. Brandon\nWestover, Shamim Nemati, Gari D. Clifford, and Ashish Sharma. Early prediction of sepsis from\nclinical data: The physionet/computing in cardiology challenge 2019. Critical Care Medicine, 48\n(2):210–217, 2019. URL https://doi.org/10.1097/CCM.0000000000004145.\nDavid L Sackett, William M C Rosenberg, J A Muir Gray, R Brian Haynes, and W Scott Richardson.\nEvidence based medicine: what it is and what it isn’t. BMJ, 312(7023):71–72, 1996. URL\nhttps://www.bmj.com/content/312/7023/71.\nAbulhair Saparov and He He. Language models are greedy reasoners: A systematic formal analysis of\nchain-of-thought. In The Eleventh International Conference on Learning Representations (ICLR),\n2023. URL https://openreview.net/forum?id=qFVVBzXxR2V.\nElie Sarraf, Alireza Vafaei Sadr, Vida Abedi, and Anthony S. Bonavia. Enhancing sepsis prognosis:\nIntegrating social determinants and demographic variables into a comprehensive model for critically\nill patients. Journal of Critical Care, 83:154857, 2024. URL https://doi.org/10.1016/\nj.jcrc.2024.154857.\nChristopher W. Seymour, Vincent X. Liu, Theodore J. Iwashyna, Frank M. Brunkhorst, Thomas D.\nRea, André Scherag, Gordon Rubenfeld, Jeremy M. Kahn, Manu Shankar-Hari, Mervyn Singer,\nClifford S. Deutschman, Gabriel J. Escobar, and Derek C. Angus. Assessment of clinical criteria\nfor sepsis for the third international consensus definitions for sepsis and septic shock (Sepsis-3).\nJAMA, 315(8):762–774, 2016. URL https://doi.org/10.1001/jama.2016.0288.\nMervyn Singer, Clifford S. Deutschman, and Christopher Warren Seymour. The third international\nconsensus definitions for sepsis and septic shock (Sepsis-3). JAMA, 315(8):801–810, 2016. URL\n10.1001/jama.2016.0287.\n15\n"}, {"page": 16, "text": "Karan Singhal, Tao Tu, Juraj Gottweis, Rory Sayres, Ellery Wulczyn, Mohamed Amin, Le Hou, Kevin\nClark, Stephen R. Pfohl, Heather Cole-Lewis, Darlene Neal, Qazi Mamunur Rashid, Mike Schaek-\nermann, Amy Wang, Dev Dash, Jonathan H. Chen, Nigam H. Shah, Sami Lachgar, Philip Andrew\nMansfield, Sushant Prakash, Bradley Green, Ewa Dominowska, Blaise Agüera y Arcas, Nenad\nTomašev, Yun Liu, Renee Wong, Christopher Semturs, S. Sara Mahdavi, Joelle K. Barral, Dale R.\nWebster, Greg S. Corrado, Yossi Matias, Shekoofeh Azizi, Alan Karthikesalingam, and Vivek\nNatarajan. Toward expert-level medical question answering with large language models. Nature\nMedicine, 2025. URL https://doi.org/10.1038/s41591-024-03423-7.\nMichael Staniek, Marius Fracarolli, Michael Hagmann, and Stefan Riezler. Early prediction of\ncauses (not effects) in healthcare by long-term clinical time series forecasting. Proceedings of\nMachine Learning Research: Machine Learning for Healthcare, 252:1–29, 2024. URL https:\n//arxiv.org/abs/2408.03816.\nMingtian Tan, Mike A Merrill, Vinayak Gupta, Tim Althoff, and Thomas Hartvigsen. Are language\nmodels actually useful for time series forecasting? In The Thirty-eighth Annual Conference on\nNeural Information Processing Systems (NeurIPS), 2024. URL https://openreview.net/\nforum?id=DV15UbHCY1.\nRahul Thapa, Qingyang Wu, Kevin Wu, Harrison Zhang, Angela Zhang, Eric Wu, Haotian Ye,\nSuhana Bedi, Nevin Aresh, Joseph Boen, Shriya Reddy, Ben Athiwaratkun, Shuaiwen Leon Song,\nand James Zou. Disentangling reasoning and knowledge in medical large language models. arXiv,\nabs/2505.11462, 2025. URL https://arxiv.org/abs/2505.11462.\nMiles Turpin, Julian Michael, Ethan Perez, and Samuel R. Bowman. Language models don’t\nalways say what they think: Unfaithful explanations in chain-of-thought prompting. In Thirty-\nseventh Conference on Neural Information Processing Systems (NeurIPS), 2023. URL https:\n//openreview.net/forum?id=bzs4uPLXvi.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N.\nGomez, Lukasz Kaiser, and Illia Polosukhin.\nAttention is all you need.\nIn Advances\nin Neural Information Processing Systems (NIPS), Long Beach,\nCA, 2017.\nURL\nhttps://proceedings.neurips.cc/paper_files/paper/2017/file/\n3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf.\nJ.L. Vincent, R. Moreno, J. Takala, S. Willatts, A. De Mendonça, H. Bruining, C. Reinhart, P. Suter,\nand L. Thijs. The SOFA (Sepsis-related Organ Failure Assessment) score to describe organ\ndysfunction/failure. Intensive Care Medicine, 22(7):707–710, 1996. URL https://doi.org/\n10.1007/BF01709751.\nWenxuan Wang, Zizhan Ma, Meidan Ding, Shiyi Zheng, Shengyuan Liu, Jie Liu, Jiaming Ji,\nWenting Chen, Xiang Li, Linlin Shen, and Yixuan Yuan. Medical reasoning in the era of llms: A\nsystematic review of enhancement techniques and applications. arXiv, abs/2508.00669, 2025a.\nURL https://arxiv.org/abs/2508.00669.\nZezhong Wang, Xingshan Zeng, Weiwen Liu, Yufei Wang, Liangyou Li, Yasheng Wang, Lifeng\nShang, Xin Jiang, Qun Liu, and Kam-Fai Wong. Chain-of-probe: Examining the necessity and\naccuracy of CoT step-by-step. In Findings of the Association for Computational Linguistics:\nNAACL 2025, Albuquerque, New Mexico, 2025b. URL https://aclanthology.org/\n2025.findings-naacl.140/.\nJuncheng Wu, Wenlong Deng, Xingxuan Li, Sheng Liu, Taomian Mi, Yifan Peng, Ziyang Xu, Yi Liu,\nHyunjin Cho, Chang-In Choi, Yihan Cao, Hui Ren, Xiang Li, Xiaoxiao Li, and Yuyin Zhou.\nMedreason: Eliciting factual medical reasoning steps in llms via knowledge graphs. arXiv, 2025.\nURL https://arxiv.org/abs/2504.00993.\nQianqian Xie, Qingyu Chen, Aokun Chen, Cheng Peng, Yan Hu, Fongci Lin, Xueqing Peng, Jimin\nHuang, Jeffrey Zhang, Vipina Keloth, Xinyu Zhou, Lingfei Qian, Huan He, Dennis Shung, Lucila\nOhno-Machado, Yonghui Wu, Hua Xu, and Jiang Bian. Medical foundation large language\nmodels for comprehensive text analysis and beyond. npj Digital Medicine, 8(1), 2025. URL\nhttps://doi.org/10.1038/s41746-025-01533-1.\n16\n"}, {"page": 17, "text": "Jundong Xu, Hao Fei, Liangming Pan, Qian Liu, Mong-Li Lee, and Wynne Hsu. Faithful logical\nreasoning via symbolic chain-of-thought. In Proceedings of the 62nd Annual Meeting of the\nAssociation for Computational Linguistics (ACL), Bangkok, Thailand, 2024. URL 10.18653/\nv1/2024.acl-long.720.\nHaotong Yang, Yi Hu, Shijia Kang, Zhouchen Lin, and Muhan Zhang. Number cookbook: Number\nunderstanding of language models and how to improve it. arXiv, abs/2411.03766, 2024. URL\nhttps://arxiv.org/abs/2411.03766.\nChangchang Yin, Shihan Fu, Bingsheng Yao, Thai-Hoang Pham, Weidan Cao, Dakuo Wang, Jeffrey\nCaterino, and Ping Zhang. Sepsiscalc: Integrating clinical calculators into early sepsis prediction\nvia dynamic temporal graph construction. arXiv, 2025. URL https://arxiv.org/abs/\n2501.00190.\nJaehoon Yun, Jiwoong Sohn, Jungwoo Park, Hyunjae Kim, Xiangru Tang, Yanjun Shao, Yonghoe\nKoo, Minhyeok Ko, Qingyu Chen, Mark Gerstein, Michael Moor, and Jaewoo Kang. Med-\nprm: Medical reasoning models with stepwise, guideline-verified process rewards, 2025. URL\nhttps://arxiv.org/abs/2506.11474.\nHonghua Zhang, Liunian Harold Li, Tao Meng, Kai-Wei Chang, and Guy Van den Broeck. On the\nparadox of learning to reason from data. In Proceedings of the Thirty-Second International Joint\nConference on Artificial Intelligence (IJCAI), pp. 3365–3373, 2023. URL https://doi.org/\n10.24963/ijcai.2023/375.\nSheng Zhang, Qianchu Liu, Guanghui Qin, Tristan Naumann, and Hoifung Poon. Med-RLVR: Emerg-\ning medical reasoning from a 3B base model via reinforcement learning. arXiv, abs/2502.19655,\n2025. URL https://arxiv.org/abs/2502.19655.\n17\n"}, {"page": 18, "text": "A\nAPPENDIX\nA.1\nSOFA SCORE\nTable 5: SOFA score for six organ systems, calculated by thresholding corresponding clinical\nmeasurements (Vincent et al., 1996). In our setting, we had to recalculate MAP (mean arterial\npressure) from SBP and DBP (systolic and diastolic blood pressure), the Horowitz coefficient from\nPaO2 and FiO2, and had no knowledge about the kind of mechanical ventilation. If no value for\ncalculation in a SOFA subsystem was available, we took a value of 0. Abbreviations: CNS = Central\nnervous system; GCS = Glasgow Coma Scale; MV = mechanically ventilated including CPAP; MAP\n= mean arterial pressure, UO = Urine output.\nCNS\nCardiovascular\nRespiratory\nCoagulation Liver\nRenal\nScore\nGCS\nMAP\nor vasopressors\nPaO2/FiO2\n(mmHg)\nPlatelets\n(×103/µl)\nBilirubin\n(mg/dl)\nCreatinine\n(mg/dl) or UO\n+0\n15\nMAP ≥70 mmHg\n≥400\n≥150\n< 1.2\n< 1.2\n+1\n13-14\nMAP < 70 mmHg\n< 400\n< 150\n1.2-1.9\n1.2-1.9\n+2\n10-12\ndopamine ≤5 µg/kg/min\nOR dobutamine (any dose)\n< 300\n< 100\n2.0-5.9\n2.0-3.4\n+3\n6-9\ndopamine > 5 µg/kg/min\nOR epinephrine ≤0.1 µg/kg/min\nOR\nnorepinephrine\n≤\n0.1\nµg/kg/min\n< 200\nAND MV\n< 50\n6.0-11.9\n3.5-4.9\nOR < 500 ml/day\n+4\n< 6\ndopamine > 15 µg/kg/min\nOR epinephrine > 0.1 µg/kg/min\nOR\nnorepinephrine\n>\n0.1\nµg/kg/min\n< 100\nAND MV\n< 20\n> 12.0\n> 5.0\nOR < 200 ml/day\n18\n"}, {"page": 19, "text": "A.2\nTIME SERIES FORECASTING\nOur TSF model uses the implementation of Staniek et al. (2024) which is based on a Transformer\nencoder-decoder architecture (Vaswani et al., 2017). First, sparse multivariate input time series are\nrepresented as quadruplets S = {(fi, ti, vi, ni)}n\ni=1, where fi ∈F is a clinical variable identifier,\nti ∈R≥0 is a time index, vi ∈R the observed value of fi at ti, and ni the unique stay identifier.\nThen the quadruplets for a 24 hour time series are encoded into a dense representation x where every\ntimestep is a vector of feature values representing one hour. We construct this vector by choosing\nthe first observed value during the represented hour for each feature. If no value was observed, we\nimpute zero which corresponds to the mean value due to standardization of the data. Additionally,\na mask indicating whether a value was imputed is generated and appended to the vector. For TSF,\nwe use a Transformer model with an autoregressive iterative multistep (IMS) decoder that generates\nan output vector ˆyt ∈R|F |. The predicted output ˆyt is a function of the history ˆy<t of predicted\ntimesteps until time t, the encoded input x, and the model parameters θ: ˆyt = fθ(ˆy<t, x). To perform\nlong-term TSF using the autoregressive setup, the outputs ˆyt from each time step t = 1, . . . , T are\nconcatenated. The complete model is trained with masked mean squared error (MSE).\nFigure 4: Time Series Forecasting using a dense encoder and iterative multistep decoder architecture.\n19\n"}, {"page": 20, "text": "A.3\nHYPERPARAMETERS AND COMPUTE INFRASTRUCTURE\nTable 6: Hyperparameter settings of the time series forecaster.\nHyperparameter\nvalue\nEmbedding Size\n512\nHidden size encoder\n512\nHidden size decoder\n512\n# Encoder layers\n2\n# Decoder layers\n1\nlearning rate\n0.0005\nattention heads encoder\n8\nattention heads decoder\n1\ndropout\n0.05\nmax epochs\n100\npatience (early stopping)\n6\nRandom Seed\nunixtime variation\n# GPUs\n1\nTraining all clock time\n5 hours\nGPU type\nNvidia GTX 1080 Ti\nTable 7: Hyperparameter settings of the multi-modal and LLM finetuning architectures.\nHyperparameter\nvalue\noptimizer\nadam\nlearning rate\n0.000002\nmax epochs\n10\nconnector first layer\n131x2096\nconnector second layer\n2096x4096\nlora-r\n16\nlora-alpha\n16\nlora-dropout\n0.1\nlora-target-modules\nall-linear\n# GPUs\n1\nTraining all clock time\n40 hours\nGPU type\nNVIDIA A100\nStarting model\nmeta-llama/Llama-3.1-8B-Instruct\n20\n"}, {"page": 21, "text": "A.4\nCLINICAL FEATURES\nTable 8: Feature list for MIMIC-III: Besides the following 131 dynamic variables, only age and\ngender were extracted. The 15 variables marked with an asterisk are directly used for calculating the\nSOFA score.\nALP\nEpinephrine*\nLDH\nPacked RBC\nALT\nFamotidine\nLactate\nPantoprazole\nAST\nFentanyl\nLactated Ringers\nPhosphate\nAlbumin\nFiO2*\nLevofloxacin\nPiggyback\nAlbumin 25%\nFiber\nLorazepam\nPiperacillin\nAlbumin 5%\nFree Water\nLymphocytes\nPlatelet Count*\nAmiodarone\nFresh Frozen Plasma\nLymphocytes (Absolute)\nPotassium\nAnion Gap\nFurosemide\nMBP\nPre-admission Intake\nBUN\nGCS_eye*\nMCH\nPre-admission Output\nBase Excess\nGCS_motor*\nMCHC\nPropofol\nBasophils\nGCS_verbal*\nMCV\nRBC\nBicarbonate\nGT Flush\nMagnesium\nRDW\nBilirubin (Direct)\nGastric\nMagnesium Sulfate (Bolus)\nRR\nBilirubin (Indirect)\nGastric Meds\nMagnesium Sulphate\nResidual\nBilirubin (Total)*\nGlucose (Blood)\nMechanically ventilated\nSBP*\nCRR\nGlucose (Serum)\nMetoprolol\nSG Urine\nCalcium Free\nGlucose (Whole Blood)\nMidazolam\nSodium\nCalcium Gluconate\nHR\nMilrinone\nSolution\nCalcium Total\nHalf Normal Saline\nMonocytes\nSterile Water\nCefazolin\nHct\nMorphine Sulfate\nStool\nChest Tube\nHeparin\nNeosynephrine\nTPN\nChloride\nHgb\nNeutrophils\nTemperature\nColloid\nHydralazine\nNitroglycerine\nTotal CO2\nCreatinine Blood*\nHydromorphone\nNitroprusside\nUltrafiltrate\nCreatinine Urine\nINR\nNorepinephrine*\nUrine*\nD5W\nInsulin Humalog\nNormal Saline\nVancomycin\nDBP*\nInsulin NPH\nO2 Saturation\nVasopressin\nDextrose Other\nInsulin Regular\nOR/PACU Crystalloid\nWBC\nDobutamine*\nInsulin largine\nPCO2\nWeight\nDopamine*\nIntubated\nPO intake\npH Blood\nEBL\nJackson-Pratt\nPaO2*\npH Urine\nEmesis\nKCl\nPT\nEoisinophils\nKCl (Bolus)\nPTT\n21\n"}, {"page": 22, "text": "A.5\nONE-SHOT PROMPT\nFor the given 24 hours of measurements, apply the definitions of the SOFA score given by the following table:\n{| class=\"wikitable\"\n!\n!Central nervous system\n!Cardiovascular system\n!Respiratory system\n!Coagulation\n!Liver\n!Renal function\n|-\n!Score\n! [[Glasgow coma scale]]\n! Mean arterial pressure OR administration of vasopressors required\n! PaO<sub>2</sub>/FiO<sub>2</sub> <nowiki>[mmHg (kPa)]</nowiki>\n! Platelets (x10<sup>3</sup>/ul)\n! Bilirubin (mg/dl) [umol/L]\n! Creatinine (mg/dl) [umol/L] (or urine output)\n|-\n! +0\n| 15 || [[Mean_arterial_pressure|MAP]] >= 70 mmHg || >= 400 (53.3) || >= 150 || < 1.2 [< 20] || < 1.2 [<\n110]\n,→\n|-\n! +1\n| 13-14 || MAP < 70 mmHg || < 400 (53.3) || < 150 || 1.2-1.9 [20-32] || 1.2-1.9 [110-170]\n|-\n! +2\n| 10-12 || [[dopamine]]\n<= 5 ug/kg/min or [[dobutamine]] (any dose) || < 300 (40) || < 100 || 2.0-5.9\n[33-101] || 2.0-3.4 [171-299]\n,→\n|-\n! +3\n| 6-9 || dopamine > 5 ug/kg/min OR [[epinephrine]] <= 0.1 ug/kg/min OR [[norepinephrine]]\n<= 0.1 ug/kg/min\n|| < 200 (26.7) '''and''' mechanically ventilated including CPAP || < 50 || 6.0-11.9 [102-204] ||\n3.5-4.9 [300-440] (or < 500 ml/day)\n,→\n,→\n|-\n! +4\n| < 6 || dopamine > 15 ug/kg/min OR epinephrine > 0.1 ug/kg/min OR norepinephrine > 0.1 ug/kg/min || < 100\n(13.3) '''and''' mechanically ventilated including CPAP || < 20 || > 12.0 [> 204] || > 5.0 [> 440] (or <\n200 ml/day)\n,→\n,→\n|}\nA patient is septic if suspected infection is positive and the future total SOFA score calculated with a best guess on how the values develop is\ntwo points (or more) higher than the current SOFA score.\nOnly answer like in the given example. Here is the example:\nPatient is 63.0 years old and is male. Given all the information in this text, answer the question at the end.\nHere are the measurements: DBP at time -23.68: 36.0, SBP at time -23.68: 71.0...\nNow answer the following question in the given format:\nDoctors suspect an infection, based on this information and the other information in this text, will the patient be classified as septic tomorrow?\nFirst we need to calculate the SOFA scores given the extracted values. The SOFA scores for the current time are the following:\nThe minimum value of GCS_eye is 4.0, GCS_motor is 6.0 and GCS_verbal is 5.0, this produces the sum 15.0 and means the CNS SOFA is 0.\nBecause minimum MAP is 43.333, max Dopamine is 0, max Dobutamine is 0, max Epinephrine is 0 and max Norepinephrine is 0 with a\npatient weight of 80 kg, the cardiovascular SOFA is 1.\nGiven that minimum PO2 is 141.0 and minimum FiO2 is 1 the calculated PAO2FIO2 is 141.0, this means the respiratory SOFA is 3.\nBecause the minimum Platelet count is 235.0 the coagulation SOFA is 0.\nThe maximum Bilirubin (Total) is 1.8 leading to a liver SOFA of 1.\nBecause total Urine output is 1585.0 and maximum creatinine in the blood is 1.4 the renal SOFA is 1.\nTo summarize: the patient has a total SOFA score of 6.\nNow we need to calculate the SOFA scores with forecasted values. The SOFA scores in the future based on the forecasted values are the\nfollowing:\nThe minimum value of GCS_eye will be 4.0, GCS_motor will be 6.0 and GCS_verbal will be 5.0, this produces the sum 15.0 and means the\nCNS SOFA will be 0.\nBecause future minimum MAP will be 55.667, future max Dopamine will be 0, future max Dobutamine will be 0, future max Epinephrine\nwill be 0 and future max Norepinephrine will be 0 with a patient weight of 80 kg, the cardiovascular SOFA will be 1.\nGiven that minimum PO2 will be 141.0 and minimum FiO2 will be 1 the forecasted PAO2FIO2 will be 141.0, this means the respiratory\nSOFA will be 3.\nBecause the Platelet count will be 295.0 the coagulation SOFA is going to be 0. The maximum Bilirubin (Total) will be 1.8 leading to a liver\nSOFA of 1.\nBecause Urine output will be 1635.0 and maximum creatinine in the blood will be 1.1 the renal SOFA will be 0.\nTo summarize: the patient will have a future total SOFA score of 5.\nThe patient will not develop sepsis in the next 24 hours, because total SOFA increased only by -1 and infection is suspected.\nThe example is now finished. Say \"The patient will develop sepsis\" in the last sentence if the criteria are met (if total SOFA changed by 2 and\ninfection is suspected).\nPatient is 76.0 years old and is female. Given all the information in this text, answer the question at the end.\nHere are the measurements: DBP at time -22.97: 56.0, GCS_eye at time -22.97: 4.0, GCS_motor at time -22.97: 6.0...\nNow answer the following question in the given format:\nThe doctors don’t suspect an infection, based on this information and the other information in this text, will the patient be classified as septic\ntomorrow?\n22\n"}, {"page": 23, "text": "A.6\nSETUP FOR LEARNING FROM PRECONDITIONS\nTable 9: Medical preconditions for five organ systems indicated by ICD-10 codes. In-distribution\n(ID) data were seen, out-of-distribution (OOD) data were unseen during fine-tuning.\nlung\nkidney\ncoagulation\nliver\ncardiovascular\nID\nJ40, J41, J42\nN18.9, N28\nD68.4, D68.5\nK70.0, K70.41\nI50.0, I50.9\nOOD\nJ44.9\nN19\nD68.6\nK70.3\nI50.1\nTable 10: ICD-10 Code frequency for in- and out-of-distribution testsets.\nICD-10 Code\n# ID Test\n# OOD Test\nJ40\n263\n194\nJ41\n239\n173\nJ42\n253\n194\nJ44.9\n-\n166\nN18.9\n266\n172\nN19\n-\n204\nN28\n281\n151\nD68.4\n242\n171\nD68.5\n244\n162\nD68.6\n-\n176\nI50.0\n264\n185\nI50.1\n-\n193\nI50.9\n229\n162\nK70.0\n230\n165\nK70.3\n-\n162\nK70.41\n215\n182\nNo-Preexisting\n274\n189\n23\n"}, {"page": 24, "text": "A.7\nDISCUSSION OF 5% ERROR MARGIN\nThe 5% margin for deviations of predictions is justified by the statistics from our experimental results.\nFor example, SOFA25:48 score ranges between 0 and 24. The experimental results in Figure 5 plot\nscores obtained by dividing predicted values by gold standard values for this metric, showing that a\n10% margin (dotted vertical lines) would include false positives, while a 5% margin does not. Similar\nresults are obtained for other predictions.\nFigure 5: Histogram of the scores obtained by dividing predicted by gold standard values for\nSOFA25:48 score. Dashed vertical lines show the 5% interval, dotted vertical lines show the 10%\ninterval\n24\n"}]}