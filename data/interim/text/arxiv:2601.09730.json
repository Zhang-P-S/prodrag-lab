{"doc_id": "arxiv:2601.09730", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2601.09730.pdf", "meta": {"doc_id": "arxiv:2601.09730", "source": "arxiv", "arxiv_id": "2601.09730", "title": "Clinical Document Metadata Extraction: A Scoping Review", "authors": ["Kurt Miller", "Qiuhao Lu", "William Hersh", "Kirk Roberts", "Steven Bedrick", "Andrew Wen", "Hongfang Liu"], "published": "2025-12-28T17:21:16Z", "updated": "2025-12-28T17:21:16Z", "summary": "Clinical document metadata, such as document type, structure, author role, medical specialty, and encounter setting, is essential for accurate interpretation of information captured in clinical documents. However, vast documentation heterogeneity and drift over time challenge harmonization of document metadata. Automated extraction methods have emerged to coalesce metadata from disparate practices into target schema. This scoping review aims to catalog research on clinical document metadata extraction, identify methodological trends and applications, and highlight gaps. We followed the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews) guidelines to identify articles that perform clinical document metadata extraction. We initially found and screened 266 articles published between January 2011 and August 2025, then comprehensively reviewed 67 we deemed relevant to our study. Among the articles included, 45 were methodological, 17 used document metadata as features in a downstream application, and 5 analyzed document metadata composition. We observe myriad purposes for methodological study and application types. Available labelled public data remains sparse except for structural section datasets. Methods for extracting document metadata have progressed from largely rule-based and traditional machine learning with ample feature engineering to transformer-based architectures with minimal feature engineering. The emergence of large language models has enabled broader exploration of generalizability across tasks and datasets, allowing the possibility of advanced clinical text processing systems. We anticipate that research will continue to expand into richer document metadata representations and integrate further into clinical applications and workflows.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2601.09730v1", "url_pdf": "https://arxiv.org/pdf/2601.09730.pdf", "meta_path": "data/raw/arxiv/meta/2601.09730.json", "sha256": "592ab1b13e05693ec3ccb0aa70c89c99e08463406854cb2e8263706a831bf2c1", "status": "ok", "fetched_at": "2026-02-18T02:23:43.665801+00:00"}, "pages": [{"page": 1, "text": "Clinical Document Metadata Extraction: A Scoping Review \nKurt Miller1,2, Qiuhao Lu3, William Hersh4, Kirk Roberts3, Steven Bedrick4, Andrew Wen3, \nHongfang Liu3 \n1Bioinformatics and Computational Biology Program, University of Minnesota, Rochester, MN, \nUSA.  \n2Center for Digital Health, Mayo Clinic, Rochester, MN, USA \n3McWilliams School of Biomedical Informatics, University of Texas Health Science Center at \nHouston, Houston, TX, USA \n4Division of Informatics, Clinical Epidemiology and Translational Data Science; Department of \nMedicine, Oregon Health & Science University, Portland, OR, USA \n \nCorresponding Author \nHongfang Liu \nMcWilliams School of Biomedical Informatics \nUniversity of Texas Health Science Center at Houston \nUniversity of Texas Health \nHouston, TX, USA \nHongfang.Liu@uth.tmc.edu \n \n \n \n"}, {"page": 2, "text": "Abstract \nObjectives \nClinical document metadata, such as document type, structure, author role, medical specialty, \nand encounter setting, is essential for accurate interpretation of information captured in clinical \ndocuments. However, vast documentation heterogeneity and drift over time challenge \nharmonization of document metadata. Automated extraction methods have emerged to coalesce \nmetadata from disparate practices into target schema. This scoping review aims to catalog \nresearch on clinical document metadata extraction, identify methodological trends and \napplications, and highlight gaps warranting further investigation. \nMethods \nWe followed the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-\nAnalyses Extension for Scoping Reviews) guidelines to identify articles from Ovid MEDLINE, \nOvid EMBASE, Scopus, Web of Science and external sources that perform clinical document \nmetadata extraction, either primarily as a methodology study, secondarily as a feature for a \ndownstream application, or for analysis. We initially identified and screened 266 articles \npublished between January 2011 and August 2025, then comprehensively reviewed 67 we \ndeemed relevant to our study. \nResults \nAmong the 67 articles included in our full text review, 45 were methodological, 17 used \ndocument metadata as features in a downstream application, and 5 analyzed document metadata \ncomposition. We observe myriad purposes for methodological study and application types. \nAvailable labelled public data remains sparse except for structural section datasets. Methods for \nextracting document metadata have progressed from largely rule-based and traditional machine \nlearning with ample feature engineering to transformer-based architectures with minimal feature \nengineering.  \nDiscussion and Conclusion \nClinical document metadata extraction research has accelerated over recent years. The \nemergence of large language models has enabled broader exploration of generalizability across \ntasks and datasets, allowing the possibility of advanced clinical text processing systems. We \nanticipate that research will continue to expand into richer document metadata representations \nand integrate further into clinical applications and workflows. \nKeywords \nElectronic Health Records, Clinical Document Metadata, Document Attributes, Document \nStructure, Information Extraction, Clinical Natural Language Processing \n"}, {"page": 3, "text": "1. Introduction \n \n1.1 Background \n \nThe digital transformation of healthcare continues to generate vast amounts of data within \nelectronic health records (EHRs) to capture information per patient encounter [1]. Although \ncapturing clinical information in structured formats is often preferred, these approaches suffer \nfrom limited expressiveness, rigidity, substantial design and maintenance costs, and added \ndocumentation burden for clinicians. Consequently, unstructured clinical narratives remain \nindispensable for representing the complexity of a patient’s condition, contextual environmental \nand lifestyle factors, and the reasoning that informs clinical assessments and treatment decisions \n[2 3]. The correct interpretation of clinical information embedded in those unstructured clinical \ndocuments requires document metadata such as document type, medical specialty, author role, \nencounter setting, and internal section structure or layout. For example, Speier et al. [4] identify \nsection, specialty and encounter setting information to perform topic modeling for automatic \nsummarization of clinical reports. Sharma et al. [5] incorporate derived note section structure \ninto a computational phenotyping system for obesity patients. More recently, retrieval augmented \ngeneration (RAG) systems integrating large language models (LLMs) with external knowledge \nsources, such as Nanua et al. [6] and Keerthana and Gupta [7], preprocess and index document \nmetadata to enhance retrieval performance during inference. \n \nHowever, document metadata is often incomplete, inconsistently structured, or otherwise implicit \nas well as varied across institutions [8]. Diverse documentation practices across departments and \nclinicians [9 10], migration from legacy systems [11], and drift of sublanguages and EHR use \nover time [12 13] contribute to extensive fragmentation of document metadata which hinder \nsecondary use and assimilation into clinical applications. Consequently, the task of document \nmetadata extraction or inference, as shown in Figure 1, is often required to facilitate accurate \ninterpretation of clinical information embedded in narrative documents. Various extraction \napproaches such as heuristic rules, traditional machine learning methods, advanced convolutional \nand recurrent neural network architectures, small transformer-based models, and more recently \nlarge language models (LLMs) have been adapted to this task. While most traditional approaches \nmay achieve adequate accuracy on certain corpora the given researchers focus on, they typically \nrequire substantial labelled data and suffer when applied to datasets from other domains or \ninstitutions. LLMs have markedly advanced performance and generalizability without labelled \ndata required for supervised ML models or fine-tuning. However, despite recent expansions of \npurported context window sizes and improvements in more complex tasks such as those \nrequiring biomedical reasoning, significant issues persist in leveraging LLMs for larger clinical \napplications dependent on external knowledge and/or large amounts of data. As examples, the \n“lost-in-the-middle problem” or “middle curse” [14 15], hallucinations and confabulations [16] \n"}, {"page": 4, "text": "[14], ambiguity of references within the input context to information outside the input context \n[17 18], and discordance between internal pretrained knowledge and external facts [19] [14] \nremain perplexing challenges across general and biomedical domains. \nNonetheless, supplementation of the input text in the LLM prompt with document metadata has \nbeen demonstrated to alleviate some of these issues with LLMs. For instance, performance in \nretrieval augmented generation (RAG) systems significantly improves when metadata is \nextracted prior to information retrieval during inference and included within or alongside the \nembedded content chunks [20] [14 21]. Similarly, other examinations of prompt engineering \ntechniques for clinical note understanding tasks exhibited superior accuracy with shorter input \ncontexts containing particular segments curated from the original note [22 23], suggesting that \nsegmenting a note into its sections and including only relevant sections, or including summaries \nand contextual information about the input text, can yield performance improvements over the \nentire note text or arbitrarily chunked segments. \n \nDespite the mounting need for this document metadata to be explicit and readily translatable \nbetween schema, limited attempts have been made recently to survey the literature for efforts to \nextract or analyze these document-level and structural attributes. Table 1 lists these literature \nreviews along with the year of the review and the dimensions of document metadata each review \ncovers. While these investigations contain valuable compilations of clinical document metadata \nextraction and analysis efforts from clinical text, each review only covers certain aspects of \ndocument metadata and cover work prior to the advent of modern LLMs.  \n \n \n \nFigure 1. Document metadata extraction and downstream clinical application workflow. Document metadata is \nextracted from clinical documentation by one or multiple methods then used in a variety of possible downstream applications. \n"}, {"page": 5, "text": "Table 1. Relevant Document Metadata Review Articles \nPublished Authors \nArticle Title \nDocument Metadata Reviewed \n2018 \nPomares-\nQuimbaya et \nal. \nCurrent Approaches to Identify Sections \nwithin Clinical Narratives from Electronic \nHealth Records: A Systematic Review \nSection, Subsection \n2022 \nUlrich et al. \nUnderstanding the Nature of Metadata: \nSystematic Review \nDocument Type \n2022 \nVorisek et al. \nFast Healthcare Interoperability Resources \n(FHIR) for Interoperability in Health \nResearch: Systematic Review \nDocument Type, Document \nStructure, Role, Visit Type \n2024 \nPeng et al. \nUse of Metadata-Driven Approaches for \nData Harmonization in the Medical \nDomain: Scoping Review \nClinical Setting, Document Type, \nSection \n \nThis review aims to fill the gaps between the previous reviews by more broadly covering the \nliterature on extracting this contextual information (i.e., document metadata) into a target schema \nrepresenting an institution’s internal context (i.e., schema) and by including the latest research \nefforts and technologies employed. By doing so, we intend to facilitate generalizable data \nharmonization and empower performant downstream applications which rely on contextual \ninformation about notes’ content. \n \nFor this scoping review, we surveyed the literature on clinical document metadata extraction to \ncatalog the trends of clinical document extraction data, methods, and applications. We focus on \narticles relating to the explicit extraction of the document and structural attributes of the \ndocument, either as a primary methodology, for incorporation in a downstream application, or for \nanalysis. By aggregating and examining this literature, we intend to answer the following \nresearch questions: \n1. What data is available and what tasks and applications do researchers leveraging that data \nattempt to address by using document-level metadata and note structure information? \n2. What types of document attribute and structure schema are being used to capture the \ncontext of the clinical documentation? \n3. What methods and architectures are employed to identify this metadata information from \nclinical documents? \n4. What is the research landscape of clinical document metadata extraction methods and \napplications? \n \n1.2 Working Definitions \nThe National Information Standards Organization (NISO) defines metadata as data created \nprimarily to describe other data, differentiating types of metadata that serve to either find and \nunderstand that data more easily (i.e., descriptive metadata), relate structural elements of a \nresource (i.e., structural metadata), or manage data resources (i.e., administrative metadata) [24]. \n"}, {"page": 6, "text": "In the clinical domain, metadata would refer to features and elements of clinical documentation \nin the context of the EHR. While many definitions of general clinical metadata might include any \ninformation describing clinical data, such as report findings or whether a body of text includes \nspecific diagnoses or phenotypes, we define document metadata in a clinical domain as data \npertaining to the clinical context in which the document was written which helps describe and \nmanage the document. For example, the dimensions of the LOINC Document Ontology [25] \nprovide apt examples of descriptive document metadata. Table 2 offers the definitions of these \nmetadata types according to the NISO [24], as well as examples of each of descriptive, \nadministrative, and structural types of clinical document metadata in a typical EHR. \n \nTable 2. Document Metadata Types and Examples in a Clinical Context \nMetadata Type* \nPurpose of Metadata* \nClinical Document Examples \nDescriptive Metadata \nFor finding or understanding a \nresource \nDocument Type (e.g., Radiology Report, \nDischarge Summary, Progress Note, etc), \nmedical specialty (Internal Medicine, \nNeurology, etc), encounter setting (e.g., ICU, \nhospital, office visit, etc), personnel role (e.g., \nphysician, nurse, PA, administrator) \nAdministrative Metadata \n- Technical Metadata \n- Preservation Metadata \n- Rights Metadata \n \n- For decoding and rendering files \n- Long-term management of files \n- Intellectual property rights \nattached to content \nFile and data types (e.g., RTF, HTML, XML, \nPDF, plain text), encoding, markup language \nand database schema, ETL/ELT history, \nresearch authorization \nStructural Metadata \nRelationships of parts of resources \nto one another \nSection, subsection, page number, table \ncolumn headers \nMarkup languages \nIntegrates metadata and flags for \nother structural or semantic \nfeatures within content \nLayout, intra-document styling and formatting \n*Obtained from NISO metadata type definitions [24] \nWe therefore define metadata extraction from clinical documents as the process of procuring this \ndescriptive and structural metadata from the raw document content, whether through direct \nextraction or by inference. We find that previous research either 1) examines an experimental \nmethodology for extracting these types of metadata, 2) engineers the metadata as a feature for a \ndownstream task, or 3) analyzes the composition of the metadata within or across EHRs. \n \n1.3 Statement of Significance \n \nProblem \nAs the volume and complexity of EHR data increases rapidly, the need to extract and adapt \ncontextual metadata information also grows, yet literature reviewing document metadata \nextraction methods and applications is sparse. \n \nWhat is Already Known \n"}, {"page": 7, "text": "Previous surveys of document metadata extraction focus on extraction of specific document \nmetadata attributes, such as section identification or document type classification methods, \ndeviating definitions of metadata, or efforts toward broader data harmonization. A more \ncomprehensive and updated compilation of the descriptive and structural metadata for clinical \ndocumentation is needed. \n \nWhat this Paper Adds \nThis scoping review compiles literature exploring methods for extracting document attributes \nand structure, including more recent trends since the advent of transformers and LLMs. \nMotivations for studies investigating the viability of these methods as well as downstream \napplications for which these document metadata are extracted as features are also examined. \n \n \n2. Methods \nWe opted for a scoping review due to the relatively underexplored nature of clinical document \nmetadata thus far in the literature, as the volume of literature on the topic was not enough to \nwarrant a full systematic review [26]. We leverage the Preferred Reporting Items for Systematic \nreviews and Meta Analyses (PRISMA) [27] extension for scoping reviews (PRISMA-ScR) [28] \nto perform our survey and analysis. \n2.1 Search Strategy \nFor this literature review, we sought articles covering various types of clinical metadata \nprocessing published between January 2011 and June 2025. Databases searched for literature \nincluded Ovid MEDLINE In-Process & Other Non-Indexed Citations, Ovid MEDLINE, Ovid \nEMBASE, Scopus, and Web of Science. Our search strategy across each database was similar: \nthe search query was composed of three distinct clauses which were each required to match at \nleast one term. The first clause specifies some part of the medical record – “Electronic Health \nRecord” or “EHR” or “medical record” or “clinical note” etc. The second component \nnecessitates that a language processing task of the data occurs: “NLP” or “extraction” or \n“classification” or “identification”, etc. The third clause stipulates the inclusion of some kind of \ndocument metadata context: “section” or “metadata” or “document type” or “specialty”, etc. \nOther articles obtained by recommendation from coauthors, web search, and via citation of \npapers found from the database search strategy were also included in our subsequent selection \nprocess for screening. \n2.2 Article Selection \nThe search strategy yielded 225 articles total across the databases queried, while 41 additional \narticles were discovered through other sources. After deduplication, 160 distinct articles \nremained for our initial title and abstract screening. The title and abstract screening of the \n"}, {"page": 8, "text": "combined 201 abstracts from both the database query and other sources filtered out articles \nwhose reference to contextual information and/or metadata was not the target task, part of the \nmethodology, or subject to analysis, leaving 102 articles for subsequent full-text screening. The \ncomprehensive full-text review used the following inclusion criteria: 1) use EHR data, 2) open \naccess, and 4) leverage clinical document metadata (e.g., document type, section, author role, \nmedical specialty, clinical setting, etc.) as part of either a) primary task methodology, b) \nsecondary to a downstream task, or c) analysis. Exclusion criteria were as follows: 1) preprints, \n2) closed access, 3) non-English article text, 4) only “metadata” included are domain- or disease-\nspecific, not relating to the clinical document or encounter setting, or 5) only “contextual” \ninformation leveraged is local semantic context, as opposed to broader structural or document \nprogrammatic context. After applying these inclusion and exclusion criteria during full-text \nreview, 65 articles were eligible for data extraction. A PRISMA-ScR flow chart of the article \nselection process, including categorization into the types of metadata usage, is represented in \nFigure 2. \n"}, {"page": 9, "text": " \n2.3 Data Extraction \nFor each of the selected articles, we collected information from the following categories: \n- \nDataset: the corpus or corpora used to evaluate the model, the source language of the \ndataset(s) \n- \nTask: the specific task(s) facilitated by the dataset \n- \nMetadata types: the document and/or structural metadata from the dataset incorporated \ninto the method \n- \nMetadata extraction approach: the method process, model architecture(s), word \nembedding method (if applicable), and any semantic, syntactic, and statistical \nrepresentations used \n \nFigure 2. Publication Selection Process. An overview of the PRISMA-ScR approach including articles identified \nfrom database search query and additional sources, deduplicated, screened, and included in our study for full \nreview. Reasons for exclusion of full-text articles are provided. Number of studies included for each category are \nalso shown. \n"}, {"page": 10, "text": "- \nApplication: if the article used the metadata extraction for a downstream application, the \ntype of application (risk prediction, clinical decision support, phenotyping, cohort \nretrieval, etc.) \n- \nPublication: the publication year, publication forum (conference or journal), and \npublisher subject (informatics, NLP, medical, etc) \n \n3. Results \n3.1 Data and Task \nOverall, 28/67 (41.8%) publications use at least one publicly available dataset for their metadata \nextraction method or metadata analysis, whereas 26/67 (38.8%) of the articles included in this \nstudy leverage only a proprietary dataset and 8/67 (11.9%) use a combination of public and \nprivate datasets.  \nTable 3 lists the publicly available datasets containing each type of metadata and the papers \nwhich used each of those datasets for the given metadata type. The note section document \nstructure metadata has the most public datasets available, most of which were annotated for \ni2b2/n2c2 shared tasks and were used for section segmentation, section classification, or both. In \ngeneral, the most used publicly available datasets were corpora labelled for i2b2/n2c2 shared \ntasks and/or derived from the large MIMIC-III corpus. \nDue to the relative dearth of publicly available datasets labelled with descriptive (non-structural) \nmetadata, many studies relied on private, proprietary datasets annotated and adjudicated by in-\nhouse experts. A significant share of researchers tackling a section identification task also opted \nfor labelling corpora obtained from their own institutions’ EHRs, such as UCLA [4], University \nof Pittsburgh [29], Mayo Clinic [30], and the VA [31 32]. In these instances, the target section \nschema or metadata task was usually customized to a defined set of outputs unique to the study, \nsuch as a custom section schema or subset of select document types.  \n \nTable 3. Publicly available corpora labelled with relevant metadata \nMetadata \nPublic Dataset \nDataset Description \nPapers \nSection, \nStructural \n2010 i2b2/VA \nChallenge [33] \nThe “VA Challenge” dataset with manually annotated \nreports by i2b2 and the VA Salt Lake City Health Care \nSystem from 3 institutions on Concepts, Assertions, and \nRelations in Clinical Text. This dataset was \nsubsequently annotated to include SOAP sections of \nclinical notes. \n[34-37] \ni2b2 2014 shared \ntask track 2 [38] \nThe i2b2/UTHealth “Risk Factors” shared task track 2, \nincluding risk factors for coronary artery disease such as \ndiabetes, smoking, and hypertension.  \n[39] \n"}, {"page": 11, "text": "THYME corpus \n[40] \nThe “Temporal Histories of Your Medical Events” \n(THYME) dataset includes extended labels from the \n2012 i2b2 temporal relation challenge dataset, \ncontaining over 1,200 consistently structured brain and \ncolon cancer oncology notes from the Mayo Clinic. \n[35-37] \nMIMIC-III Note \nEvents [41] \nICU Notes from the MIMIC-III NoteEvents table, \ncontaining several delimited sections across a handful of \ndifferent note types, can be used directly for section \nidentification tasks as the section heading formatting \nand language is uniform. \n[42-44] \nMedSecId [45] \nOver 2000 MIMIC-III notes spanning 5 categories \n(radiology notes, consultations, echo notes, discharge \nsummaries and physician progress notes) for 50 section \ntypes labelled to accommodate section identification \ntasks. \n[45] \nn2c2 2022 shared \ntasks 1 and 3 [46 \n47] \nAn annotated extension of MIMIC-III Progress Notes \ncontaining SOAP labels (shared task 1) as well as \nproblems in the Assessment sections linked to their \ncorresponding plans for treatment in the Plan section \n(shared task 3) \n[35 37 48] \nMTSamples \ndataset [49] \nSamples of medical transcription reports across 40 \nmedical specialties, delineated by section including \nSOAP sections, among additional subsections. \n[50] \nClinAIS at \nIberLEF 2023 [51 \n52] \nSpanish clinical documents derived from the CodiEsp \ncorpus [53] from Conference and Labs of the Evaluation \nForum (CLEF) eHealth 2020 conference, made of \nprimarily progress notes, annotated with 7 different note \nsection types \n[52 54] \nDocument \nType \nMIMIC-III Note \nEvents [41] \nThe MIMIC-III NoteEvents table contains a column \ndenoting the type of document for each note entry, \nenabling training and evaluation of document type \nclassification methods. \n[43] \n2013 CLEF e-\nHealth Challenge \ntask 2 [55] \nClinical reports labelled with acronyms and \nabbreviations along with their normalized UMLS \nconcept identifiers. Document headers/types are also \navailable, allowing for differential assignment by \ndocument \n[56] \nNHS psychiatric \nnotes [57] \nPsychiatric notes from the South London and Maudsley \nNHS Foundation Trust Biomedical Research Centre \n(SLAM BRC), harboring mental healthcare data for \npatients in the UK in a Case Register Interactive Search \ntool (CRIS) database, including different types of \nclinical documents \n[58] \nSpecialty \niDASH 2011 [59] \nIntegrating data for analysis, anonymization, and \nsharing (iDASH) - 10 medical specialties / departments \n[60 61] \n2013 and 2014 \nMedicare Claims \ndatasets [62] \nMedicare insurance claims derived from the List of \nExcluded Individuals and Entities (LEIE) database from \nthe Office of the Inspector General, available through \nthe Centers for Medicare & Medicaid Services website \n(CMS.gov) \n[63] \nKaggle Medical \nSpecialty \nClassification \nDataset [64] \nPatient visit notes spanning 18 medical specialties \nproducing the document, available as a Kaggle dataset \n[65] \n"}, {"page": 12, "text": " \n3.2 Document Metadata Extraction Approaches \nFigure 3 is a histogram depicting the number of articles employing each type of modeling \napproach each year from 2012 to August of 2025. After the previous comprehensive review of \nsection identification concluded in 2018 [71], the predominant method for section identification \n(segmentation and/or classification) and extraction of descriptive metadata has used transformer-\nbased architectures (denoted BERT in the figure). More recently, transformers with domain-\nspecific pretraining and LLMs have come into favor due to their relative ease of implementation, \nrequiring no fine-tuning or less data with minimal tuning, greater generalizability across datasets, \nand comparable or superior performance to the previous transformer-based state-of-the-art \nmodels. \n \nMTSamples \ndataset [49] \nSamples of medical transcription reports across 40 \nmedical specialties \n[66 67] \n2011 i2b2 VA \ntrack 1 [68] \nClinical notes and discharge summaries containing \nlabelled coreferences of People, Problems, Treatments, \nand Tests. People references can refer to departments \n[68] \nHuggingface \nchinese patient \nrecord triage NLP \ndataset [69] \n178,000 chinese patient records derived from a Medical \nQA dataset, containing labels for triage into 16 \ndepartment classes \n[70] \nRole \n2011 i2b2 VA \ntrack 1 [68] \nClinical notes and discharge summaries containing \nlabelled coreferences of People, Problems, Treatments, \nand Tests. People references can refer to personnel roles  \n[68] \n"}, {"page": 13, "text": " \nFigure 3. Trend of method architectures used to extract clinical document metadata by publication year. \nRule-based approaches include logical rules, heuristics and regular expressions used to explicitly parse syntax and \nsemantics from clinical text; Traditional ML refers to statistical and traditional machine-learning (ML) methods, \nincluding natural language processing (NLP)-specific algorithms that leverage machine-learning algorithms, \nexcluding neural network derivations; Deep Learning includes only non-transformer-based neural network models \nsuch as multilayer perceptron, recurrent and convolutional neural network models, as well as hybrid neural network \narchitectures; Transformer comprises transformer-based models with less than 7 billion parameters, whereas LLM \nrefers to transformer-based large language models of equal to or greater than 7 billion parameters.  \n \nTable 4 shows the model categories, architectures, features, and ontologies leveraged across the \ndocument metadata extraction research efforts we encountered. Articles using rule-based and \nstatistical or traditional ML as their primary, experimental models typically employed a selection \nfrom a range of possible features, techniques, and ontologies, whereas deep neural network (non-\ntransformer) and transformer model variants relied more on embeddings. For example, Yang et \nal. [72] incorporated trained word2vec and skip-gram embeddings, term frequency-inverse \ndocument frequency (TF-IDF), and Medical Subject Headings (MeSH), as well as SNOMED-CT \nand ICD-10 codes, as features for random forest, support vector machine, gradient boosting \ndecision tree, and logistic regression models in their section and document type classification \ntasks in a venous thromboembolism risk assessment application. Weng et al. [60] employed \n"}, {"page": 14, "text": "word2vec and paragraph vector embeddings, part-of-speech (PoS) tags, TF-IDF, and UMLS and \nSemantic Network concept representations as features into their CNN, CNN-LSTM, and SVM \nmodels in their medical domain classification pipeline. \nIn contrast, more recent transformer and LLM models tested only minimal tuning or “out-of-the-\nbox”, without tuning, instead leveraging existing models pretrained on biomedical domain data. \nOne exception to this was Zhou et al. [35], who employed continual pretraining across domain-  \nand task-specific data to a BioBERT model to evaluate portability across disparate institutional \ndata. None of the 6 recent implementations of LLM for metadata extraction leveraged any \nexplicit syntactic or statistical input features, and only Socrates et al. [73] used ontological \ninformation in the form of a custom entity list for their GPT-neo experimental LLM. \n \nTable 1. Model architectures and techniques \nCategory \nModel \nInput Features \nTraditional ML \nLogistic Regression [5 50 72 74-\n76] \n \nDecision Tree / Random Forest [5 \n72 76-78] \n \nSVM [5 29 60 68 70 72 79] \n \nCRF [32 39 56 80 81] \n \nLDA [4] \n \nNaïve Bayes [63 67] \n \nMarkov Model [82] \n \nStatistical Features: \n- n-grams [29 56 74-76] \n- TF-IDF [60 67 72 76 77] \n- Frequency vectors  \n \nSyntactic features (Part-of-Speech tags, \northographic features) \n- PoS [29 60 79] \n- Orthography [80] \n \nEmbeddings \n- Word2vec [60 72 77 79] \n- FastText [79] \n- BERT [78] \n \nOntological Entities: \n- UMLS [5 29 39 56 68] \n- MeSH [68 72] \n- RadLex [68] \n- Semantic Network [60] \n- SNOMED [68 72] \n- ICD-10 [72] \n- HPO [72] \n- LOINC DO [81] \n- Custom [83] \n \nDeep Learning \n(Non-\nTransformer) \nMLP [67] \nCNN [60 61 65 70 79 84-87] \n \nSequence \n- RNN [86-89] \n- LSTM [65 66 77 79 84-87] \nStatistical Features \n- TFIDF [60 77 85] \n \nSyntactic Features \n- PoS [60 79] \n \n"}, {"page": 15, "text": "- GRU [86 90] \n \nHybrid: \n- RCNN [91] \n- CNN-LSTM [60 86] \n- HGCN [89] \nEmbeddings \n- Character [84] \n- Word2vec [45 60 77 79 85 86 88] \n- GloVe [45 65 89] \n- FastText [45 79] \n- FLAIR [88] \n- Wikipedia2vec [88] \n- Paragraph2vec [60] \n- Custom [61 91] \n- BERT [87] \nTransformer-\nbased Models  \nGeneral-Purpose Models: \n- BERT [45 65 67 81 85 86 90-\n92] \n- RoBERTa [52 54] \n- DistilBERT [67 86 87] \n- ELECTRA [86] \n \nBiomedical Domain Encoder \nModels: \n- BioBERT [35 65 67 70 87 93] \n- ClinicalBERT [70 76 78] \n- BioClinicalBERT [36 44 77 87] \n- BioMedBERT [43 87] \n- BioMedRoBERTa [73] \n- PubMedBERT [87] \n- SapBERT [73] \n \nBiomedical Domain Decoder \nModels: \n- BioMedLM [36] \n \nMultilingual and Non-english \nEncoder Models \n- RoBERTa (Spanish) [54] \n- MBERT (multilingual) [93] \n- KMBERT (Korean) [86] \n- GBERT/GMedBERT (German) \n[94] \n- DistilBERT-pt (Portuguese) [93] \n- BioBERTpt (Portuguese) [93] \n \nGeneral Domain Decoder Models: \n- GPT-neo [73] \n \nMethods \n- Continual Pre-training [35 93] \n- Active learning / weak supervision \n[87] \n- Ensemble [35] \n \nOntological entities \n- UMLS [87] \n- Custom [86] \n- LOINC DO types [81] \nLLMs* \nBiomedical Domain Decoder \nModels: \n- Galactica [36] \n \nGeneral Domain Decoder Models: \n- Llama 2 [37 48 95] \n- FlanT5 XXL [36] \n \n"}, {"page": 16, "text": "- ChatGPT (GPT 3.5) [37 95] \n- Vicuna [37] \n- Gemma 2 [48 70] \n- Llama 3 [48 70] \n- GPT-4 [37 95 96] \n- Mistral [48] \n- GLM [70] \n- Qwen [70] \n \nFine-tuned/Instruction-tuned \nModels \n- Tulu2 [37] \n- Mistral OpenOrca [48] \n \n*LLMs are defined as transformer-based models with >= 7 billion parameters \n \n3.3 Applications \nAmong the 62 articles we consider in our review that perform clinical document metadata \nextraction (i.e., excluding “analysis” papers), 17 (28.6%) identify the document metadata in a \npreprocessing step to use as a feature in a downstream application. In our review, refer to these \nas “application” papers. Across these 17 articles, we found a variety of specific purposes for \nwhich document attributes were extracted and used as features. For this review, we group these \npurposes into six broader application type categories: text classification, information extraction, \ninformation retrieval, semantic processing, computational phenotyping and clinical decision \nsupport. Figure 4 is a Sankey diagram illustrating the use of public or proprietary data (stage 1); \ndocument metadata component(s) extracted (stage 2); whether the purpose of the article was a \nmethodology study, application, or analysis (stage 3); and, for the articles that target a \ndownstream application, the application category (stage 4). \nOf the 17 application papers, 9 (52.9%) incorporate a public dataset. Regarding the types of \ndocument attributes, 14/17 (82.4%) used section information and 4/17 (23.5%) used document \ntype, whereas 7/17 (41.2%) incorporated more than one attribute as input features to a model \nperforming a different, downstream task. One example of an application of multiple attributes \nwas the work of Speier et al [4], who used document type, physician medical specialty, and \nrelative document dates for their target tasks of computational phenotyping and text \nclassification. Kugic et al [95] integrated structural (section) and medical specialty information \ninto their pipeline for biomedical and clinical acronym disambiguation and resolution in English, \nGerman, and Portuguese clinical texts.  \n"}, {"page": 17, "text": "Between the six categories of application that we observed, computational phenotyping and \nsemantic processing tasks such as disease classification and coreference resolution, respectively, \nwere the most common. However, the distribution of these applications was distributed relatively \nevenly across the categories.  \n \n3.4 Research/publication context \nFigure 5 displays the frequency of publication venue types by research topic. Informatics \njournals and conferences were the most common venues for clinical document metadata \nresearch, representing 25/67 (37.3%) and 16/67 (23.9%) of the publications, respectively, or \n41/67 (61.2%) of the publications overall included in our review. Computer science/AI/NLP \nvenues were also a relatively common destination, representing 20/67 (29.9%) of the \n \nFigure 4. Clinical document metadata datasets, metadata types, article type, and applications. Counts next to \neach node title represent the unique combination of the number of corpora in the reviewed articles falling under that \ncategory and number of methodology motivations: a single article may be represented multiple times in this Sankey \ndiagram if it included multiple datasets for model training and evaluation and/or is a methodology study including \nmultiple motivations for conducting the study. The percentage of that count within the tier is also shown. The first \ntier Dataset Openness represents whether the dataset is publicly available or private/proprietary. The second tier for \nDocument Metadata Type represents the document attribute or structure dimension labelled in each dataset. The \nthird tier Article Type represents whether the dataset was used to evaluate a methodology (i.e., a methodology \nstudy), included as a feature for a downstream application, or a subject of analysis. The fourth tier represents either \nwhich use case(s) methodology studies mention as a motivation or for which downstream application type an \napplication article uses the document metadata. \n*Use case (methodology motivation) categories were created using generative AI. \n"}, {"page": 18, "text": "publications included here. Although medical/health/bioscience venues were considerably less \ncommon overall, their frequency appears to be increasing since the advent of larger language \nmodels in late 2022 and 2023. \n \n4. Discussion \nFor this scoping review, we have surveyed the data, methods, and applications that incorporate \ndocument metadata extraction, either as an exploration of a methodology for a primary task, as a \nfeature for a downstream clinical application, or that conduct metadata analysis. Our findings \npoint to a few general patterns and more recent trends warranting further consideration: the \ndearth of public document metadata corpora, the evolution of contextual modeling, the diversity \nof document metadata schemas, and the fragmentation of the publication landscape. Here, we \nexpound on those patterns, then discuss the current challenges and future frontiers as well as the \nlimitations in conducting this review. \n \n4.1 Dearth of Public Clinical Document Attribute Corpora \nWhile we did find several public corpora containing note section labels and the SOAP schema \nwas a somewhat commonly recurring standard, relatively few used the same set of sections. \nMoreover, corpora with annotated descriptive metadata were relatively sparse, as document type \nand medical specialty only had 3 and 4 public datasets, respectively. Although sometimes the \ninformation can be inferred or derived from other sources, public data was even more sparse for \n \nFigure 5. Publication Venue Type and Topic Counts. The journal and conference publications of each venue type \nare stacked for a given year. Publications in 2025 include through the month of August. \n"}, {"page": 19, "text": "clinical setting and author role, as we found no datasets which explicitly labelled and advertised \nthese document features. As a result, the lack of publicly available data, along with the high cost \nof corpus annotation, could be inhibiting further clinical document metadata extraction research. \nExcept for the document type and section label data that could be juxtaposed from MIMIC-III \ndata and the specialty and document type data available for the MTsamples transcript dataset \n[49], none of the other publicly available datasets comprise multiple different types of document \nmetadata, though some datasets other document structure or attribute information could be \ninferred from the content, such as simple section identification rules for the CLEF eHealth \nChallenge 2013 task 2 dataset [55]. \n \n4.2 Evolution of Contextual Modeling \nSince the emergence of the EHR as a primary source of patient information, the contextual \nmodeling approaches of document metadata appear to have undergone three somewhat distinct \nphases of development. The first phase, lasting until roughly 2015, relied heavily on hardcoded \nrules and regular expressions to identify key delimiters and terms within the text and targeted \nsection identification tasks. These were almost exclusive methodological studies or applications \nof semantic processing. Mowery et al. [29], Dai et al. [80], and Ganesan et al.[74] exemplify this \nphase in their studies evaluating rule-based section segmentation and classification methods. The \nsecond phase spanned roughly 2015 until late 2023, when traditional ML, more advanced NLP, \nneural network and transformer-based architectures were predominantly leveraged in tandem \nwith an assortment of feature types and feature engineering processes. Embeddings, syntactic \nand statistical features, and semantic or ontological representations, for example, were tested \nduring this era of contextual modeling. For transformer models such as BERT, additional \npretraining on biomedical domain corpora such as for BioBERT, PubMedBERT and \nBioClinicalBERT, as well as additional parameter tuning such as fine-tuning and continual \npretraining, were also employed and evaluated as potential avenues to improve performance and \ngeneralizability. The most recent phase, starting roughly around the advent of ChatGPT in early \n2023, relaxed the demand for feature engineering and expanded the dataset and task variety in \neach study. \nThe progression through these phases has coincided with increased capability of model types and \nlatent embedding spaces to represent words in their context, from explicit to implicit and from \nmonosemy to polysemy and homonymy. Rule-based and statistical ML modeling from the first \nphase of the review timeframe entails explicit dictionaries mapping words and/or concepts to \ninferences, such as document scores for TF-IDF. Early word embedding models such as \nword2vec use implicit relative representations of points in a high-dimensional vector space yet \nonly include only a single representation for each word. Later embeddings used in deep learning \narchitectures (e.g., CNNs, LSTMs, and transformers), such as GloVe and BERT contextual \nembeddings, integrated many definitions for a single word based on their context (i.e., polysemy) \n"}, {"page": 20, "text": "including words that share the same spelling but may have starkly contrasted meanings based on \ntheir context (i.e., homonymy). These contextual embeddings, learned during the pretraining and \nreinforcement learning from human feedback (RLHF) phases of model development, implicitly \nimpart context-based semantics thereby empowering greater generalizability across disparate \nsemantic contexts. The advancement from explicit to implicit modeling and monosemy to \npolysemy and homonymy has spurred recent interest in generalizability across tasks, \ntransferability across domains, and integration into larger, more complex applications. \n \n4.3 Diversity of Clinical Document Metadata Schemas \nThe sparsity of publicly available corpora with annotated document-level metadata as well as a \nlack of standardization across institution documentation and document metadata practices has \nnecessitated a reliance on proprietary datasets bearing many custom schemas tailored to each \nstudy’s unique research interests. While some section identification attempts still target the \nconventional SOAP and CDA schema, a greater proportion of these either used a modified \nversion of these schemas or delineate their own set of sections. Other document attributes such as \nmedical specialty and document type may include only a subset \nDue to the heterogeneity of schemas across healthcare institutions, there is a demand for flexible \nsolutions that can take a source dataset of any metadata schema and adapt it to a standardized or \ntarget schema. Recognizing this problem, Peng et al. [97] recently investigated efforts toward \ndata harmonization using ETL/ELT systems that can translate metadata between different \ninstitution’s schemas. \nRecent advances in model architectures and techniques allow internal encoding of knowledge \nabout general language imparted during pre-training (e.g., masking on general domain corpora) \nand post-training (e.g., RLHF) phases have enabled study of generalizable, portable solutions \nthat bridge these heterogenous metadata schemas. \n \n4.4 Diverging Definitions of Metadata \nDespite the NISO’s unambiguous definition of metadata and delineation of its subtypes [24], the \nsystematic review by Ulrich et al [98] on the nature of metadata reveals a discordance among \nresearchers as to what constitutes metadata and how to taxonomize it: hard and soft metadata \n[99], record-level and data value-level metadata [100], and context-dependent and context-\nindependent metadata [101]. Our observations on the usage of the term “metadata” as well as on \nthe diversity of document metadata schemas in the literature we reviewed corroborate those \nfindings. For example, Kim et al [102] define a metadata ontology relating clinical concepts \nidentified from the document into a formal tree structure, and Caufield et al [103] propose a \nclinical case report extraction approach for obtaining metadata as summaries of medical content \n"}, {"page": 21, "text": "contained within the given report. These metadata were excluded from our review because they \ndo not conform to our definition of metadata as document-level and structural dimensions of \nmetadata, but rather whether they include particular semantic information related to each of their \nrespective application tasks. \nAs “metadata” is generally more loosely defined as any data about data and the amount of ways \ndata can be described also grows, the amount of metadata schema and definitions of “metadata” \nwill also continue to grow. This rapid expansion of data descriptions, structures, and types \nunderscores an emerging need for a generalizable way to harmonize data from any source to a \ntarget EHR metadata schema. \n \n4.5 Manifold Methodological Motivations and Downstream Applications \nThe final (rightmost) tier in Figure 4 highlights the distribution of downstream applications for \nwhich document metadata extraction methodologies are used. These categories are high-level \nabstractions aggregated from our observations—the landscape of these motivations and \napplications was considerably diverse, as each category depicted in the diagram represents a \nrange of specific use cases. For example, motivations for studies of document metadata \nextraction methodologies include reducing administrative and physician burden by navigating \ninsurance claims and suggesting appropriate tags using section information such as the work of \nNair et al. [104], improving department triage using medical specialty prediction such as in Lee \net al. [86], as well as improving downstream applications like cohort discovery such as our work \nin Miller et al. [48]. For applications, “semantic processing” represents a group of specific use \ncases pertaining to identifying and relating semantic components of text, including named entity \nrecognition, coreference resolution, relation extraction, and acronym resolution, among others. \nFurther, the opportunity provided by LLMs will likely facilitate the application of document \nmetadata to more applications not detected as published, peer-reviewed and open-access work \nfor this scoping review, yet we observed are on the horizon. The myriad motivations and \napplications for which we found extraction of document metadata useful demonstrate the breadth \nof use cases to which it can be applied across healthcare and research. \n \n4.6 Mounting Interest in Document Metadata \nWhile some document attribute and structure extraction has been a topic of research prior to and \nthrough the beginning of the scope of this review, we observe a trend of increasing research over \nthe review period. The increase in journal and conference publications in the latter half of our \nreview period, from 2018 to 2025, in Figure 5 illustrates this growth. Figure 5 also exhibits a \ngreater diversity of publication venues in the latter half of the study period, showing that more \njournals and conferences accepting articles analyzing document metadata composition or \n"}, {"page": 22, "text": "investigating extraction methods. Moreover, the growth in document metadata interest does not \nappear to be limited to the English language. Although sparse non-English research existed prior \nto 2018, since then document metadata extraction methods have been explored across Spanish, \nPortuguese, German, Mandarin, Korean, and Finnish corpora. These trends of increasing journal \nand conference publications, diversity of publication venues, and breadth of natural language \ncorpora exhibit growing global interest in document metadata research. \n \n4.7 Current Challenges and Future Direction \nClinical applications leveraging large documents such as those employing information retrieval \nhave recently shown performance improvement when incorporating metadata filtering prior to \ndense or hybrid embedding search [14] or leveraging document metadata from the whole \ndocument or adjacent text segments to the target segment during indexing [21 48]. However, in \ninformation retrieval, challenges remain for how best to chunk information from these large \ndocuments, what information to include with the chunk when indexing, how to transform a query \nto precisely target the appropriate information, and how to retrieve and rank results using such \ndocument metadata. Which document metadata and other contextual information to introduce the \nmodel to in the prompt and in which stages will be an ongoing thread of exploration. \nLikewise, structural metadata is more than the section composition and order highlighted in this \nreview. As the NISO definitions of the types of metadata distinguishes, structural metadata can \nalso be visual layout or other information captured in html/xml or markdown, such as relative \npositioning, tabular information such as column headers, use of bullet points or numbering, and \nformatting/style which may communicate emphasis or otherwise provide context surrounding \ngiven text. Capturing this information is a challenging ask for the scanned images and PDF \ndocuments transferred between institutions as part of outside medical records. This challenge is \ndiscussed somewhat extensively by Goodrum et al. in [76], but otherwise there is relatively little \nexamination of this emerging challenge across clinical informatics research, possibly because \nmultimodal research integrating visual layout and textual information is still relatively young. \nBroader research efforts in “layout parsing” of unstructured documents with visual content such \nas PDFs into semi-structured markup (e.g., html) or markdown has been ongoing, but recent \nadvancements in modeling using LLMs, such as SmolDocling [105], have recently made rapid \nprogress in state-of-the-art performance on related tasks. \n \n4.8 Limitations \nThe selection of a few document-level and structural attributes among the diverging definitions \nof clinical document metadata, perhaps bias our review toward those document-level and \nstructural attributes we selected for this article. Descriptive metadata about alternative \nknowledge sources such as patient data or medical research, summary metadata about \n"}, {"page": 23, "text": "impressions or findings extracted from the document, type of procedure or imaging performed, \nand the body location of an imaging report could be considered as metadata at the document \nlevel yet were omitted from our search to constrain the scope of the review. Temporal \ninformation about the document or clinical event (e.g., document signed date or date of \nprocedure) could be also considered a dimension of document metadata but was not covered \nsince temporal modeling has its own expansive field of literature that would be infeasible to \ninclude here.  \n \nDocument-level and structural metadata extraction methods, especially those leveraged for \ndownstream applications, were commonly absent from abstracts and buried in descriptions of \nmethods, sometimes tersely depicted or even omitted from methods descriptions entirely. This \nobscurity was especially prevalent in studies that leverage metadata for a downstream \napplication, since the application task was often the focus of the article instead of the feature \nengineering process for the constituent metadata. Further, conflation of the aforementioned local, \nlinguistic context methods with the type of programmatic context we focus on in this study \nexacerbated the challenge of finding articles that meet our specific search criteria since mentions \nof “contextual information” often referred to only the local semantic context. Thus, due to the \ndifficulty in searching for and screening these methods including a programmatic context \ncomponent, we may have missed relevant articles or biased our search toward articles that \nreferenced document metadata in particular ways. \n \n5. Conclusion \nClinical document metadata is crucial for proper comprehension of patient encounter information \nand facilitating downstream applications, especially as unstructured clinical text captured about \npatient encounters becomes increasingly vast and heterogenous across healthcare organizations. \nWe conducted a scoping review of clinical document metadata extraction research from 2011 to \n2025 and characterized the data, methods, applications, and research context of the 67 articles we \nfound that represent the literature. We found that while publicly available data is limited, \nmethods and applications are advancing, interest in document metadata is growing, and the \npublication landscape is increasingly fragmented. We suspect that these trends will continue as \ndocument metadata and its associated data content continue to evolve and document metadata \nremains crucial for contextualizing unstructured clinical text content. \n \nDeclaration of competing interests \nThe authors declare that they have no competing interests. \n \n"}, {"page": 24, "text": "CRediT Authorship Statement \nKurt Miller: Writing – original draft, Methodology, Data curation, Investigation, Formal \nAnalysis, Conceptualization, Visualization, Validation. Qiuhao Lu: Investigation, Data curation. \nWilliam Hersh: Writing – review and editing, Conceptualization, Methodology. Kirk Roberts: \nWriting – review and editing, Conceptualization, Methodology. Steven Bedrick: Writing – \nreview and editing, Conceptualization. Andrew Wen: Writing – review and editing, \nInvestigation. Hongfang Liu: Writing – review and editing, Conceptualization, Methodology, \nInvestigation, Supervision, Project administration, Resources. \n \nFunding \nThis work was supported by the National Institutes of Health grant numbers R01LM011934 and \nR01LM014508. \n \nAcknowledgements \nWe thank Larry Prokop, Librarian, in the Mayo Clinic Libraries for contributions in drafting the \nsearch queries and conducting the search of databases for articles reviewed in this study. \n \nData Availability \nSee Supplementary Material. \n \nReferences \n \n1. Arndt BG, Micek MA, Rule A, Shafer CM, Baltus JJ, Sinsky CA. More Tethered to the EHR: \nEHR Workload Trends Among Academic Primary Care Physicians, 2019-2023. Ann Fam \nMed 2024;22(1):12-18 doi: 10.1370/afm.3047. \n2. Rosenbloom ST, Denny JC, Xu H, Lorenzi N, Stead WW, Johnson KB. Data from clinical \nnotes: a perspective on the tension between structure and flexible documentation. Journal \nof the American Medical Informatics Association 2011;18(2):181-86 doi: \n10.1136/jamia.2010.007237. \n3. Kuhn T, Basch P, Barr M, Yackel T. Clinical Documentation in the 21st Century: Executive \nSummary of a Policy Position Paper From the American College of Physicians. Annals of \nInternal Medicine 2015;162(4):301-03 doi: 10.7326/M14-2128. \n"}, {"page": 25, "text": "4. Speier W, Ong MK, Arnold CW. Using phrases and document metadata to improve topic \nmodeling of clinical reports. Journal of Biomedical Informatics 2016;61:260-66 doi: \nhttps://doi.org/10.1016/j.jbi.2016.04.005. \n5. Sharma H, Mao C, Zhang Y, et al. Developing a portable natural language processing based \nphenotyping system. BMC Medical Informatics and Decision Making 2019;19(3):78 doi: \n10.1186/s12911-019-0786-z. \n6. Nanua S, Steward R, Neely B, Datto M, Youens K. Retrieval-augmented generation for \ninterpreting clinical laboratory regulations using large language models. Journal of \nPathology Informatics 2025;19:100520 doi: https://doi.org/10.1016/j.jpi.2025.100520. \n7. Keerthana G, Gupta M. CLI-RAG: A Retrieval-Augmented Framework for Clinically \nStructured and Context Aware Text Generation with LLMs. 2025. \nhttps://ui.adsabs.harvard.edu/abs/2025arXiv250706715K (accessed July 01, 2025). \n8. Glynn EF, Hoffman MA. Heterogeneity introduced by EHR system implementation in a de-\nidentified data resource from 100 non-affiliated organizations. JAMIA Open \n2019;2(4):554-61 doi: 10.1093/jamiaopen/ooz035. \n9. Cohen GR, Friedman CP, Ryan AM, Richardson CR, Adler-Milstein J. Variation in Physicians’ \nElectronic Health Record Documentation and Potential Patient Harm from That \nVariation. Journal of General Internal Medicine 2019;34(11):2355-67 doi: \n10.1007/s11606-019-05025-3. \n10. Kang MJ, Rossetti SC, Knaplund C, et al. Nursing Documentation Variation Across Different \nMedical Facilities Within an Integrated Healthcare System. Comput Inform Nurs \n2021;39(12):845-50 doi: 10.1097/cin.0000000000000736 [published Online First: \n20210503]. \n11. Huang C, Koppel R, McGreevey JD, 3rd, Craven CK, Schreiber R. Transitions from One \nElectronic Health Record to Another: Challenges, Pitfalls, and Recommendations. Appl \nClin Inform 2020;11(5):742-54 doi: 10.1055/s-0040-1718535 [published Online First: \n20201111]. \n12. Shao Y, Divita G, Workman TE, Redd D, Garvin J, Zeng-Treitler Q. Clinical Sublanguage \nTrend and Usage Analysis from a Large Clinical Corpus, 2020. \n13. Miller K, Moon S, Fu S, Liu H. Contextual Variation of Clinical Notes induced by EHR \nMigration. AMIA Annu Symp Proc 2023;2023:1155-64 [published Online First: \n2024/01/15]. \n14. Zhang W, Zhang J. Hallucination Mitigation for Retrieval-Augmented Large Language \nModels: A Review. Mathematics 2025;13(5):856. \n15. On Context Utilization in Summarization with Large Language Models; 2024 August; \nBangkok, Thailand. Association for Computational Linguistics. \n16. Burford KG, Itzkowitz NG, Ortega AG, Teitler JO, Rundle AG. Use of Generative AI to \nIdentify Helmet Status Among Patients With Micromobility-Related Injuries From \nUnstructured Clinical Notes. JAMA Network Open 2024;7(8):e2425981-e81 doi: \n10.1001/jamanetworkopen.2024.25981. \n17. Zhao J, Ji Z, Feng Y, et al. Meta-Chunking: Learning Text Segmentation and Semantic \nCompletion via Logical Perception. 2024. \nhttps://ui.adsabs.harvard.edu/abs/2024arXiv241012788Z (accessed October 01, 2024). \n18. Günther M, Mohr I, Williams DJ, Wang B, Xiao H. Late Chunking: Contextual Chunk \nEmbeddings Using Long-Context Embedding Models. 2024. \nhttps://ui.adsabs.harvard.edu/abs/2024arXiv240904701G (accessed September 01, 2024). \n"}, {"page": 26, "text": "19. Amugongo LM, Mascheroni P, Brooks S, Doering S, Seidel J. Retrieval augmented \ngeneration for large language models in healthcare: A systematic review. PLOS Digital \nHealth 2025;4(6):e0000877 doi: 10.1371/journal.pdig.0000877. \n20. Precise zero-shot dense retrieval without relevance labels. Proceedings of the 61st Annual \nMeeting of the Association for Computational Linguistics (Volume 1: Long Papers); \n2023. \n21. Anthropic. Introducing Contextual Retrieval, 2024. \n22. Zhang X, Talukdar N, Vemulapalli S, et al. Comparison of Prompt Engineering and Fine-\nTuning Strategies in Large Language Models in the Classification of Clinical Notes. \nAMIA Jt Summits Transl Sci Proc 2024;2024:478-87 [published Online First: 20240531]. \n23. Piya FL, Beheshti R. ConTextual: Improving Clinical Text Summarization in LLMs with \nContext-preserving Token Filtering and Knowledge Graphs. 2025. \nhttps://ui.adsabs.harvard.edu/abs/2025arXiv250416394P (accessed April 01, 2025). \n24. Riley J. Understanding metadata. Washington DC, United States: National Information \nStandards Organization (http://www.niso.org/publications/press/UnderstandingMetadata. \npdf) 2017;23:7-10. \n25. LOINC Document Ontology. Secondary LOINC Document Ontology. \nhttps://loinc.org/document-ontology/. \n26. Munn Z, Peters MDJ, Stern C, Tufanaru C, McArthur A, Aromataris E. Systematic review or \nscoping review? Guidance for authors when choosing between a systematic or scoping \nreview approach. BMC Medical Research Methodology 2018;18(1):143 doi: \n10.1186/s12874-018-0611-x. \n27. Moher D, Liberati A, Tetzlaff J, Altman DG, The PG. Preferred Reporting Items for \nSystematic Reviews and Meta-Analyses: The PRISMA Statement. PLOS Medicine \n2009;6(7):e1000097 doi: 10.1371/journal.pmed.1000097. \n28. Tricco AC, Lillie E, Zarin W, et al. PRISMA Extension for Scoping Reviews (PRISMA-\nScR): Checklist and Explanation. Ann Intern Med 2018;169(7):467-73 doi: 10.7326/m18-\n0850 [published Online First: 20180904]. \n29. Mowery D, Wiebe J, Visweswaran S, Harkema H, Chapman WW. Building an automated \nSOAP classifier for emergency department reports. Journal of Biomedical Informatics \n2012;45(1):71-81 doi: https://doi.org/10.1016/j.jbi.2011.08.020. \n30. Mehrabi S, Krishnan A, Roch AM, et al. Identification of Patients with Family History of \nPancreatic Cancer--Investigation of an NLP System Portability. Stud Health Technol \nInform 2015;216:604-8. \n31. Tran LT, Divita G, Redd A, Carter ME, Samore M, Gundlapalli AV. Scaling Out and \nEvaluation of OBSecAn, an Automated Section Annotator for Semi-Structured Clinical \nDocuments, on a Large VA Clinical Corpus. AMIA Annu Symp Proc 2015;2015:1204-13 \n[published Online First: 20151105]. \n32. Rush EN, Danciu I, Ostrouchov G, et al. JSONize: A Scalable Machine Learning Pipeline to \nModel Medical Notes as Semi-structured Documents. AMIA Jt Summits Transl Sci Proc \n2020;2020:533-41 [published Online First: 20200530]. \n33. Tepper M, Capurro D, Xia F, Vanderwende L, Yetisgen M. Statistical Section Segmentation \nin Free-Text Clinical Records. LREC 2012. \n34. Explicit and Implicit Section Identification from Clinical Discharge Summaries. 2022 16th \nInternational Conference on Ubiquitous Information Management and Communication \n(IMCOM); 2022 3-5 Jan. 2022. \n"}, {"page": 27, "text": "35. Zhou W, Yetisgen M, Afshar M, Gao Y, Savova G, Miller TA. Improving model \ntransferability for clinical note section classification models using continued pretraining. \nJournal of the American Medical Informatics Association 2023;31(1):89-97 doi: \n10.1093/jamia/ocad190. \n36. Zhou W, Dligach D, Afshar M, Gao Y, Miller TA. Improving the Transferability of Clinical \nNote Section Classification Models with BERT and Large Language Model Ensembles. \nProc Conf Assoc Comput Linguist Meet 2023;2023:125-30. \n37. Zhou W, Miller TA. Generalizable Clinical Note Section Identification with Large Language \nModels. medRxiv 2024:2024.02.18.24303014 doi: 10.1101/2024.02.18.24303014. \n38. Stubbs A, Kotfila C, Xu H, Uzuner Ö. Identifying risk factors for heart disease over time: \nOverview of 2014 i2b2/UTHealth shared task Track 2. J Biomed Inform 2015;58 \nSuppl(Suppl):S67-s77 doi: 10.1016/j.jbi.2015.07.001 [published Online First: \n20150722]. \n39. Chang N-W, Dai H-J, Jonnagaddala J, Chen C-W, Tsai RT-H, Hsu W-L. A context-aware \napproach for progression tracking of medical concepts in electronic medical records. \nJournal of Biomedical Informatics 2015;58:S150-S57 doi: \nhttps://doi.org/10.1016/j.jbi.2015.09.013. \n40. Styler WFt, Bethard S, Finan S, et al. Temporal Annotation in the Clinical Domain. Trans \nAssoc Comput Linguist 2014;2:143-54. \n41. Johnson AEW, Pollard TJ, Shen L, et al. MIMIC-III, a freely accessible critical care database. \nScientific Data 2016;3(1):160035 doi: 10.1038/sdata.2016.35. \n42. Automated clinical diagnosis: The role of content in various sections of a clinical document. \n2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM); 2017 \n13-16 Nov. 2017. \n43. Wang J, Yu S, Davoudi A, Mowery DL. A Preliminary Characterization of Canonicalized and \nNon-Canonicalized Section Headers Across Variable Clinical Note Types. AMIA Annu \nSymp Proc 2020;2020:1268-76 [published Online First: 20210125]. \n44. Saleh M, Baghdadi S, Paquelet S. TocBERT: Medical Document Structure Extraction Using \nBidirectional Transformers. 2024. \nhttps://ui.adsabs.harvard.edu/abs/2024arXiv240619526S (accessed June 01, 2024). \n45. A New Public Corpus for Clinical Section Identification: MedSecId; 2022 October; \nGyeongju, Republic of Korea. International Committee on Computational Linguistics. \n46. Gao Y, Dligach D, Miller T, et al. Hierarchical Annotation for Building A Suite of Clinical \nNatural Language Processing Tasks: Progress Note Understanding. LREC Int Conf Lang \nResour Eval 2022;2022:5484-93 [published Online First: 2022/08/09]. \n47. Gao Y CJ, Miller T, Sharma B, Churpek M, Dligach D, Afshar M. . Tasks 1 and 3 from \nProgress Note Understanding Suite of Tasks: SOAP Note Tagging and Problem List \nSummarization (version 1.0.0). 1.0.0 ed: PhysioNet. \n48. Miller K, Bedrick S, Lu Q, et al. Dynamic few-shot prompting for clinical note section \nclassification using lightweight, open-source large language models. Journal of the \nAmerican Medical Informatics Association 2025;32(7):1164-73 doi: \n10.1093/jamia/ocaf084. \n49. MTSamples. Secondary MTSamples. https://mtsamples.com/. \n50. Kenei JK, Opiyo E. Using classification and visualization to support clinical texts review in \nelectronic clinical documentation. Proceedings of the 6th International Conference on \n"}, {"page": 28, "text": "Medical and Health Informatics. Virtual Event, Japan: Association for Computing \nMachinery, 2022:78–84. \n51. de la Iglesia I, Atutxa A, Gojenola K, Vivó Pascual M, Chocron P, de Maeztu G. ClinAIS \nCorpus: Automatic Identification of Sections in Spanish Clinical Documents - IberLEF \n2023: Zenodo, 2023. \n52. de la Iglesia I, Vivó M, Chocrón P, Maeztu G, Gojenola K, Atutxa A. An open source corpus \nand automatic tool for section identification in Spanish health records. J Biomed Inform \n2023;145:104461 doi: 10.1016/j.jbi.2023.104461 [published Online First: 20230802]. \n53. Miranda-Escalada A, Gonzalez-Agirre A, Armengol-Estapé J, Krallinger M. Overview of \nautomatic clinical coding: annotations, guidelines, and solutions for non-English clinical \ncases at CodiEsp track of CLEF eHealth 2020, 2020. \n54. Automatic Segmentation of Clinical Narratives in Sections with Pre-Trained Clinical \nTransformer Models. CEUR Workshop Proceedings; 2023. CEUR-WS. \n55. Mowery DL, South BR, Christensen L, et al. Normalizing acronyms and abbreviations to aid \npatient understanding of clinical texts: ShARe/CLEF eHealth Challenge 2013, Task 2. J \nBiomed Semantics 2016;7:43 doi: 10.1186/s13326-016-0084-y [published Online First: \n20160701]. \n56. A Supervised Abbreviation Resolution System for Medical Text. Conference and Labs of the \nEvaluation Forum; 2013. \n57. Stewart R, Soremekun M, Perera G, et al. The South London and Maudsley NHS Foundation \nTrust Biomedical Research Centre (SLAM BRC) case register: development and \ndescriptive data. BMC Psychiatry 2009;9:51 doi: 10.1186/1471-244x-9-51 [published \nOnline First: 20090812]. \n58. Wu H, Toti G, Morley KI, et al. SemEHR: A general-purpose semantic search system to \nsurface semantic data from clinical notes for tailored care, trial recruitment, and clinical \nresearch*. Journal of the American Medical Informatics Association 2018;25(5):530-37 \ndoi: 10.1093/jamia/ocx160. \n59. Ohno-Machado L, Bafna V, Boxwala AA, et al. iDASH: integrating data for analysis, \nanonymization, and sharing. J Am Med Inform Assoc 2012;19(2):196-201 doi: \n10.1136/amiajnl-2011-000538 [published Online First: 20111110]. \n60. Weng W-H, Wagholikar KB, McCray AT, Szolovits P, Chueh HC. Medical subdomain \nclassification of clinical notes using a machine learning-based natural language \nprocessing approach. BMC Medical Informatics and Decision Making 2017;17(1):155 \ndoi: 10.1186/s12911-017-0556-8. \n61. Almuhana HA-J, Abbas HH. Classification of medical specialty for text medical report based \non natural language processing and deep learning. International journal of health sciences \n2022;6(S7):3362-85 doi: 10.53730/ijhs.v6nS7.12476. \n62. CMS. Research, statistics, data, and systems. \n63. Medical Provider Specialty Predictions for the Detection of Anomalous Medicare Insurance \nClaims. 2017 IEEE International Conference on Information Reuse and Integration (IRI); \n2017 4-6 Aug. 2017. \n64. Tanya. Medical Specialty Classification, 2022. https://kaggle.com/competitions/medical-\nspecialty-classification  \n65. Zhang H, Zhu D, Tan H, Shafiq M, Gu Z. Medical Specialty Classification Based on \nSemiadversarial Data Augmentation. Computational Intelligence and Neuroscience \n2023;2023(1):4919371 doi: https://doi.org/10.1155/2023/4919371. \n"}, {"page": 29, "text": "66. Medical Specialty Classification from A Bangla Dataset: A Token Level Approach Using \nSeveral Machine And Deep Learning Algorithms. 2021 5th International Conference on \nElectrical Engineering and Information Communication Technology (ICEEICT); 2021 \n18-20 Nov. 2021. \n67. Kathirvel S, Mookiah L. Medical Specialty Classification Using Large Language Models \n(LLMs). The International FLAIRS Conference Proceedings 2025;38 doi: \n10.32473/flairs.38.1.138953. \n68. Xu Y, Liu J, Wu J, et al. A classification approach to coreference in discharge summaries: \n2011 i2b2 challenge. J Am Med Inform Assoc 2012;19(5):897-905 doi: 10.1136/amiajnl-\n2011-000734 [published Online First: 20120413]. \n69. Chinese patient record triage NLP dataset on HuggingFace. Secondary Chinese patient \nrecord triage NLP dataset on HuggingFace. \nhttps://huggingface.co/datasets/zeng981/nlpdataset. \n70. Ihnaini B, Zeng X, Yan H, Fang F, Sangi AR. Leveraging Large Language Models for \nDepartmental Classification of Medical Records. Applied Sciences 2025; 15(12). \n71. Pomares-Quimbaya A, Kreuzthaler M, Schulz S. Current approaches to identify sections \nwithin clinical narratives from electronic health records: a systematic review. BMC \nMedical Research Methodology 2019;19(1):155 doi: 10.1186/s12874-019-0792-y. \n72. Yang Y, Wang X, Huang Y, Chen N, Shi J, Chen T. Ontology-based venous \nthromboembolism risk assessment model developing from medical records. BMC \nMedical Informatics and Decision Making 2019;19(4):151 doi: 10.1186/s12911-019-\n0856-2. \n73. Socrates V, Gilson A, Lopez K, Chi L, Taylor RA, Chartash D. Predicting relations between \nSOAP note sections: The value of incorporating a clinical information model. J Biomed \nInform 2023;141:104360 doi: 10.1016/j.jbi.2023.104360 [published Online First: \n20230414]. \n74. A general supervised approach to segmentation of clinical texts. Proceedings - 2014 IEEE \nInternational Conference on Big Data, IEEE Big Data 2014; 2014. \n75. Lohr C, Luther S, Matthies F, et al. CDA-Compliant Section Annotation of German-\nLanguage Discharge Summaries: Guideline Development, Annotation Campaign, Section \nClassification. AMIA Annu Symp Proc 2018;2018:770-79 [published Online First: \n2019/03/01]. \n76. Goodrum H, Roberts K, Bernstam EV. Automatic classification of scanned electronic health \nrecord documents. Int J Med Inform 2020;144:104302 doi: \n10.1016/j.ijmedinf.2020.104302 [published Online First: 20201017]. \n77. Hsu E, Malagaris I, Kuo Y-F, Sultana R, Roberts K. Deep learning-based NLP data pipeline \nfor EHR-scanned document information extraction. JAMIA Open 2022;5(2):ooac045 doi: \n10.1093/jamiaopen/ooac045. \n78. Moon S, Liu S, Kshatriya BSA, et al. Assessing document section heterogeneity across \nmultiple electronic health record systems for computational phenotyping: A case study of \nheart-failure phenotyping algorithm. PLOS ONE 2023;18(3):e0283800 doi: \n10.1371/journal.pone.0283800. \n79. Landolsi MY, Hlaoua L, Romdhane LB. Hybrid method to automatically extract medical \ndocument tree structure. Engineering Applications of Artificial Intelligence \n2023;120:105922 doi: https://doi.org/10.1016/j.engappai.2023.105922. \n"}, {"page": 30, "text": "80. Dai HJ, Syed-Abdul S, Chen CW, Wu CC. Recognition and Evaluation of Clinical Section \nHeadings in Clinical Documents Using Token-Based Formulation with Conditional \nRandom Fields. Biomed Res Int 2015;2015:873012 doi: 10.1155/2015/873012 [published \nOnline First: 20150826]. \n81. Zuo X, Li J, Zhao B, et al. Normalizing Clinical Document Titles to LOINC Document \nOntology: an Initial Study. AMIA Annu Symp Proc 2020;2020:1441-50 [published \nOnline First: 20210125]. \n82. Ni J, Delaney B, Florian R. Fast Model Adaptation for Automated Section Classification in \nElectronic Medical Records. Stud Health Technol Inform 2015;216:35-9. \n83. Khan H, Mosa ASM, Paka V, et al. Mapping Clinical Documents to the Logical Observation \nIdentifiers, Names and Codes (LOINC) Document Ontology using Electronic Health \nRecord Systems Structured Metadata. AMIA Annu Symp Proc 2023;2023:1017-26 \n[published Online First: 20240111]. \n84. Subramanian A, Suresh PK, Santhiappan S. A robust section identification method for \nscanned electronic health records. Proceedings of the 6th Joint International Conference \non Data Science & Management of Data (10th ACM IKDD CODS and 28th COMAD). \nMumbai, India: Association for Computing Machinery, 2023:213–17. \n85. Mao C, Zhu Q, Chen R, Su W. Automatic medical specialty classification based on patients’ \ndescription of their symptoms. BMC Medical Informatics and Decision Making \n2023;23(1):15 doi: 10.1186/s12911-023-02105-7. \n86. Lee S, Han YJ, Park HJ, et al. Entity-enhanced BERT for medical specialty prediction based \non clinical questionnaire data. PLOS ONE 2025;20(1):e0317795 doi: \n10.1371/journal.pone.0317795. \n87. Afzal M, Hussain J, Abbas A, Hussain M, Attique M, Lee S. Transformer-based active \nlearning for multi-class text annotation and classification. Digit Health \n2024;10:20552076241287357 doi: 10.1177/20552076241287357 [published Online First: \n20241017]. \n88. Goenaga I, Lahuerta X, Atutxa A, Gojenola K. A section identification tool: Towards HL7 \nCDA/CCR standardization in Spanish discharge summaries. Journal of Biomedical \nInformatics 2021;121:103875 doi: https://doi.org/10.1016/j.jbi.2021.103875. \n89. Wang G, Lou X, Guo F, Kwok D, Cao C. EHR-HGCN: An Enhanced Hybrid Approach for \nText Classification Using Heterogeneous Graph Convolutional Networks in Electronic \nHealth Records. IEEE J Biomed Health Inform 2024;28(3):1668-79 doi: \n10.1109/jbhi.2023.3346210 [published Online First: 20240306]. \n90. Leveraging Medical Literature for Section Prediction in Electronic Health Records; 2019 \nNovember; Hong Kong, China. Association for Computational Linguistics. \n91. A Joint Model of Clinical Domain Classification and Slot Filling Based on RCNN and \nBiGRU-CRF. 2019 IEEE International Conference on Big Data (Big Data); 2019 9-12 \nDec. 2019. \n92. Leveraging Task Transferability to Meta-learning for Clinical Section Classification with \nLimited Data; 2022 May; Dublin, Ireland. Association for Computational Linguistics. \n93. de Oliveira JM, Antunes RS, da Costa CA. SOAP classifier for free-text clinical notes with \ndomain-specific pre-trained language models. Expert Systems with Applications \n2024;245:123046 doi: https://doi.org/10.1016/j.eswa.2023.123046. \n94. Richter-Pechanski P, Wiesenbach P, Schwab DM, et al. Clinical information extraction for \nLow-resource languages with Few-shot learning using Pre-trained language models and \n"}, {"page": 31, "text": "Prompting. 2024. https://ui.adsabs.harvard.edu/abs/2024arXiv240313369R (accessed \nMarch 01, 2024). \n95. Kugic A, Schulz S, Kreuzthaler M. Disambiguation of acronyms in clinical narratives with \nlarge language models. J Am Med Inform Assoc 2024;31(9):2040-46 doi: \n10.1093/jamia/ocae157. \n96. Oliveira JD, Santos HDP, Ulbrich AHDPS, et al. Development and evaluation of a clinical \nnote summarization system using large language models. Communications Medicine \n2025;5(1):376 doi: 10.1038/s43856-025-01091-3. \n97. Peng Y, Bathelt F, Gebler R, et al. Use of Metadata-Driven Approaches for Data \nHarmonization in the Medical Domain: Scoping Review. JMIR Med Inform \n2024;12:e52967 doi: 10.2196/52967 [published Online First: 20240214]. \n98. Ulrich H, Kock-Schoppenhauer A-K, Deppenwiese N, et al. Understanding the Nature of \nMetadata: Systematic Review. J Med Internet Res 2022;24(1):e25440 doi: \n10.2196/25440. \n99. Grewe J, Wachtler T, Benda J. A Bottom-up Approach to Data Annotation in \nNeurophysiology. Frontiers in Neuroinformatics 2011;Volume 5 - 2011 doi: \n10.3389/fninf.2011.00016. \n100. Zozus MN, Bonner J. Towards Data Value-Level Metadata for Clinical Studies. Stud Health \nTechnol Inform 2017;234:418-23. \n101. Chu Y-C, Kuo W-T, Cheng Y-R, et al. A Survival Metadata Analysis Responsive Tool \n(SMART) for web-based analysis of patient survival and risk. Scientific Reports \n2018;8(1):12880 doi: 10.1038/s41598-018-31290-z. \n102. Kim HH, Park YR, Lee KH, Song YS, Kim JH. Clinical MetaData ontology: a simple \nclassification scheme for data elements of clinical data based on semantics. BMC \nMedical Informatics and Decision Making 2019;19(1):166 doi: 10.1186/s12911-019-\n0877-x. \n103. Caufield JH, Liem DA, Garlid AO, et al. A Metadata Extraction Approach for Clinical Case \nReports to Enable Advanced Understanding of Biomedical Concepts. J Vis Exp \n2018(139) doi: 10.3791/58392 [published Online First: 20180920]. \n104. Automated Clinical Note Section Identification Using Transfer Learning and Contextual \nEmbeddings. 2023 Global Conference on Information Technologies and Communications \n(GCITC); 2023 1-3 Dec. 2023. \n105. Nassar A, Marafioti A, Omenetti M, et al. SmolDocling: An ultra-compact vision-language \nmodel for end-to-end multi-modal document conversion. 2025. \nhttps://ui.adsabs.harvard.edu/abs/2025arXiv250311576N (accessed March 01, 2025). \n \n"}]}