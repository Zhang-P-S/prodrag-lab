{"doc_id": "arxiv:2602.12015", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2602.12015.pdf", "meta": {"doc_id": "arxiv:2602.12015", "source": "arxiv", "arxiv_id": "2602.12015", "title": "Disentangling Ambiguity from Instability in Large Language Models: A Clinical Text-to-SQL Case Study", "authors": ["Angelo Ziletti", "Leonardo D'Ambrosi"], "published": "2026-02-12T14:46:20Z", "updated": "2026-02-12T14:46:20Z", "summary": "Deploying large language models for clinical Text-to-SQL requires distinguishing two qualitatively different causes of output diversity: (i) input ambiguity that should trigger clarification, and (ii) model instability that should trigger human review. We propose CLUES, a framework that models Text-to-SQL as a two-stage process (interpretations --> answers) and decomposes semantic uncertainty into an ambiguity score and an instability score. The instability score is computed via the Schur complement of a bipartite semantic graph matrix. Across AmbigQA/SituatedQA (gold interpretations) and a clinical Text-to-SQL benchmark (known interpretations), CLUES improves failure prediction over state-of-the-art Kernel Language Entropy. In deployment settings, it remains competitive while providing a diagnostic decomposition unavailable from a single score. The resulting uncertainty regimes map to targeted interventions - query refinement for ambiguity, model improvement for instability. The high-ambiguity/high-instability regime contains 51% of errors while covering 25% of queries, enabling efficient triage.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2602.12015v1", "url_pdf": "https://arxiv.org/pdf/2602.12015.pdf", "meta_path": "data/raw/arxiv/meta/2602.12015.json", "sha256": "652c4e7e670632e3997f109f4cd7e41c1c002a33de0f2390e24a9007928603d2", "status": "ok", "fetched_at": "2026-02-18T02:19:20.994827+00:00"}, "pages": [{"page": 1, "text": "Disentangling Ambiguity from Instability in Large Language Models: A\nClinical Text-to-SQL Case Study\nAngelo Ziletti*\nLeonardo D’Ambrosi\nBayer AG, Berlin, Germany\nangelo.ziletti@bayer.com\nAbstract\nDeploying large language models for clinical\nText-to-SQL requires distinguishing two quali-\ntatively different causes of output diversity: (i)\ninput ambiguity that should trigger clarification,\nand (ii) model instability that should trigger hu-\nman review. We propose CLUES, a framework\nthat models Text-to-SQL as a two-stage process\n(interpretations →answers) and decomposes\nsemantic uncertainty into an ambiguity score\nand an instability score. The instability score\nis computed via the Schur complement of a\nbipartite semantic graph matrix. Across Am-\nbigQA/SituatedQA (gold interpretations) and\na clinical Text-to-SQL benchmark (known in-\nterpretations), CLUES improves failure predic-\ntion over state-of-the-art Kernel Language En-\ntropy. In deployment settings, it remains com-\npetitive while providing a diagnostic decom-\nposition unavailable from a single score. The\nresulting uncertainty regimes map to targeted\ninterventions - query refinement for ambiguity,\nmodel improvement for instability. The high-\nambiguity/high-instability regime contains 51%\nof errors while covering 25% of queries, en-\nabling efficient triage.\n1\nIntroduction\nText-to-SQL systems powered by Large Language\nModels (LLMs) promise to democratize access\nto Electronic Health Records (EHRs) and claims\ndatabases, enabling epidemiologists to query com-\nplex data using natural language (Lee et al., 2023;\nZiletti and DAmbrosi, 2024; Koretsky et al., 2025).\nWhile retrieval-augmented approaches (RAG) have\nshown promising results (Ziletti and DAmbrosi,\n2024), deployment faces a critical barrier: the risk\nof syntactically correct but semantically erroneous\nqueries that return plausible yet incorrect results.\nA key challenge is latent ambiguity: ambiguity\nthat is not evident to the user but significantly af-\nfects results (Elazar et al., 2024; Gupta et al., 2025).\nConsider “How many patients over 18 have atopic\ndermatitis?”: does “over 18” refer to age at diag-\nnosis or current age? First diagnosis or any? Each\ninterpretation yields a different SQL query and po-\ntentially different results. Left unresolved, such\nambiguities undermine reproducibility of epidemi-\nological research (Hemkens et al., 2016; Herrett\net al., 2017).\nLatent ambiguity also complicates uncertainty\nestimation. When a model produces diverse out-\nputs, is this diversity a legitimate reflection of query\nambiguity, or a sign of model instability? Existing\nmethods provide a single score that conflates two\nfundamentally distinct sources: uncertainty aris-\ning from inherent ambiguity in the input (akin to\naleatoric uncertainty), and uncertainty stemming\nfrom the model’s internal instability or lack of\nknowledge (akin to epistemic uncertainty). This\ndistinction enables targeted diagnosis of system\nfailures for model improvement. For a deployed\nsystem, it is also operationally critical: high ambi-\nguity should trigger a clarification dialogue, while\nhigh instability should flag the query for human\nreview.\nContributions.\n(1) CLUES, a framework that\ndecomposes semantic uncertainty into ambiguity\n(HI) and conditional instability (HR|I) via the\nSchur complement of a bipartite similarity matrix,\nenabling different interventions (clarification vs. re-\nview) and applicable to any black-box LLM. (2) An\ninterpretation-generation procedure for epidemio-\nlogical questions and a clinical Text-to-SQL dataset\nwith multiple interpretations.1 (3) Empirical evi-\ndence across open-domain QA and clinical Text-to-\nSQL that CLUES improves failure prediction and\nyields regime-based error concentration useful for\ntargeted routing.\nPaper Organization. Sec. 3 formalizes our two-\nstage generative framework and introduces the\nSchur complement construction. We validate the\n1Code and dataset will be released upon acceptance.\narXiv:2602.12015v1  [cs.CL]  12 Feb 2026\n"}, {"page": 2, "text": "decomposition across three settings of increasing\ncomplexity: open-domain QA with gold interpre-\ntations (Sec. 4), a real-world clinical Text-to-SQL\ndataset (Sec. 5), and production deployment with\non-the-fly interpretation generation (Sec. 6).\n2\nRelated Work\nSemantic entropy and kernel-based uncertainty.\nSemantic entropy clusters generations into equiv-\nalence classes for hallucination detection(Kuhn\net al., 2023; Farquhar et al., 2024); Kernel Lan-\nguage Entropy (KLE) generalizes this by encod-\ning pairwise semantic similarities.(Nikitin et al.,\n2024) Recent work derives kernel entropy via bias-\nvariance-covariance decomposition,(Kamkari et al.,\n2024) combines semantic signals with token-level\nuncertainty,(Huang et al., 2025) and exploits ge-\nometric measures such as semantic density and\nvolume.(Sun et al., 2025; Kumar et al., 2025; Lee\net al., 2024a) However, these methods operate on\na single pool of outputs and do not model multi-\nstage generative processes or distinguish uncer-\ntainty sources.(Nikitin et al., 2024; Kamkari et al.,\n2024)\nDecomposing aleatoric and epistemic uncer-\ntainty. This distinction is fundamental in prob-\nabilistic machine learning and critical for deploy-\nment in safety-critical domains.(Kendall and Gal,\n2017; Hüllermeier and Waegeman, 2021) Recent\nLLM work trains meta-models or uses temperature\nsensitivity to identify epistemic uncertainty, but\nthese approaches require additional supervision or\npipeline changes.(Desai and Durrett, 2024; Mozes\net al., 2025; Zhang et al., 2025) In the EHR-QA\ndomain, Kim et al. (2022) decompose uncertainty\nto detect ambiguous questions, but operate at the\ntoken level without modeling multi-stage genera-\ntion.\nText-to-SQL and clinical uncertainty.\nText-\nto-SQL has evolved from cross-domain bench-\nmarks (Yu et al., 2018) to clinical applications for\nEHR access and clinical trial recruitment (Ziletti\nand D’Ambrosi, 2025; Ghosh et al., 2025; Deng\net al., 2022).\nBenchmarks like EHRSQL (Lee\net al., 2023) and BiomedSQL (Koretsky et al.,\n2025) evaluate clinical Text-to-SQL, while multi-\nturn approaches improve robustness (Park et al.,\n2024). Existing systems prioritize execution ac-\ncuracy but provide limited uncertainty quantifica-\ntion (Park et al., 2022; Kim et al., 2024; Ziletti\nand DAmbrosi, 2024). Reliability work focuses\non unanswerable detection, ensemble methods, or\ntoken entropy thresholds (Kim et al., 2024; Lee\net al., 2024b), but does not decompose uncertainty\nby source or model semantic equivalence.\n3\nMethodology: A Decomposition\nFramework for Semantic Uncertainty\nOur methodology extends the geometric view of\nuncertainty from KLE to a multi-stage generative\nprocess. We construct a bipartite semantic graph\nrepresenting the entire system and use tools from\nlinear algebra and spectral graph theory to decom-\npose its structural complexity.\n3.1\nInterpretation-Augmented Generation\nWe formalize the Text-to-SQL system as a two-\nstage generative process. Given an initial natural\nlanguage query q:\n1. Interpretation Stage: The system first gen-\nerates a set of N distinct semantic interpre-\ntations, I = {I1, I2, . . . , IN}. Each interpre-\ntation In is a natural language reformulation\nrepresenting one plausible reading of the orig-\ninal query q. This stage explicitly surfaces\nthe ambiguity (or lack thereof) inherent in the\ninput.\n2. Generation Stage: For each interpretation\nIn\n∈I, the system generates M candi-\ndate SQL queries, executes them against the\ndatabase, and verbalizes the retrieved data into\nnatural language answers. This yields a set of\nanswers Rn = {Rn,1, Rn,2, . . . , Rn,M} per\ninterpretation. The complete answer set is\nR = {R1,1, . . . , RN,M}, containing N × M\ntotal answers.\nThis one-to-many (N →N × M) structure al-\nlows us to distinguish diversity across interpreta-\ntions (ambiguity) from instability within the gener-\nation process for a single interpretation.\n3.2\nConstructing the Bipartite Semantic\nGraph\nWe define a similarity function k(·, ·) ∈[0, 1] mea-\nsuring semantic similarity between text strings.\nThe full system matrix W serves as the graph’s\nweighted adjacency matrix and has a natural bipar-\ntite block structure:\nW =\n\u0012WII\nWIR\nWRI\nWRR\n\u0013\n∈R(N+NM)×(N+NM)\n(1)\n"}, {"page": 3, "text": "Figure 1: Examples of uncertainty regimes in CLUES. (Left) Regime II, Ambiguity: Interpretations (brown) are\nsemantically distinct (low WII off-diagonal), but results (green) cluster tightly within each interpretation (high\nintra-cluster WRR), yielding high HI, low HR|I. (Right) Regime III, Instability: Interpretations are similar (high\nWII off-diagonal), yet results vary substantially within interpretations, yielding low HI, high HR|I. Red dashed\nedges: interpretation-result assignments (WIR). Bottom: corresponding system matrices W.\nwhere:\n• WII ∈RN×N: The interpretation similarity\nmatrix, with (WII)ij = k(Ii, Ij). This block\nencodes the semantic relationships among in-\nterpretations.\n• WRR ∈RNM×NM: The answer similar-\nity matrix (flattening (n, m) 7→j), with\n(WRR)ij = k(Ri, Rj). This block encodes\nthe semantic relationships among all gener-\nated answers.\n• WIR ∈RN×NM and WRI = W⊤\nIR: The\nassignment matrices, with (WIR)ij = 1 if\nanswer Rj was generated from interpretation\nIi, and 0 otherwise.\nThe diagonal blocks WII and WRR encode\ngraded semantic similarity, interpreted as weighted\nedge connectivity in the graph. The off-diagonal\nblocks WIR and WRI encode the generative\nprovenance between interpretations and their an-\nswers. We represent this provenance as binary con-\nnectivity, since each answer traces to exactly one\ninterpretation. This mixed representation is con-\nsistent with the graph-theoretic framework: edge\nweights encode connection strength, whether de-\nrived from continuous similarity scores or binary\nstructural links. The KLE framework (Nikitin et al.,\n2024) constructs graphs from natural-language-\ninference-based similarity scores; our extension\nintroduces a second node type (answers) connected\nto the first (interpretations) via known generative\nlinks rather than inferred similarity.\nPrompt-Based Similarity. The similarity func-\ntion k(·, ·) is implemented via an LLM with a\ntask-specific prompt that defines the relevant no-\ntion of equivalence. For Text-to-SQL, the prompt\nassesses whether two interpretations would yield\nlogically equivalent SQL queries; for QA bench-\nmarks, whether they would yield the same factual\n"}, {"page": 4, "text": "answer. This ensures that WII and WRR encode\ntask-relevant semantics rather than generic lexical\nsimilarity.\nHeat\nKernel\nRegularization.\nFollowing\nKLE (Nikitin et al., 2024), we apply a heat\ndiffusion kernel Kτ = e−τL, where L = D −W\nis the graph Laplacian and D is the degree matrix.\nThis transforms raw pairwise similarities into a\nsmoothed representation where the hyperparam-\neter τ controls granularity: small τ preserves\nfine-grained distinctions, while large τ diffuses\nsimilarity across the graph,\nmerging nearby\nnodes into coarse clusters. To select τ without a\nvalidation set, we calibrate against an idealized\nbaseline: WRR of perfectly identical items (all\nones) should yield near-zero entropy (<0.001\nbits). This yields τ = 10 for our experiments.\nSensitivity analysis (Table 4) confirms robustness\nacross τ ∈[2, 20].\n3.3\nDecomposing Uncertainty with the Schur\nComplement\nOur central goal is to decompose the total uncer-\ntainty of the system into interpretable components:\ninput ambiguity and system instability. The result-\ning scores HI and HR|I are not intended to replace\naggregate measures like HR for failure prediction;\nrather, they provide complementary information\nabout the source of uncertainty, enabling differen-\ntial interventions (input refinement vs. generation\nreview) that a single score cannot support.\n3.3.1\nBaseline: Result Entropy HR\nThe state-of-the-art KLE approach (Nikitin et al.,\n2024) computes entropy over generated outputs\nwithout modeling their provenance. In our frame-\nwork, this yields HR from WRR alone. High HR\nindicates diverse outputs but does not distinguish\nthe source of uncertainty: input ambiguity or sys-\ntem instability. This is the baseline we aim to im-\nprove upon.\n3.3.2\nJoint Uncertainty H(R, I)\nWe define total system uncertainty as the joint en-\ntropy over the full bipartite graph, computed from\nthe complete similarity matrix W (Eq. 1). This cap-\ntures uncertainty across both interpretations and\nresults, along with their generative relationships\nencoded in WIR.\n3.3.3\nAmbiguity Score HI\nWe define the ambiguity score as the entropy over\nthe set of interpretations, estimating ambiguity in\nthe user’s query. We compute HI by applying the\nKLE framework to WII:\nKI = e−τLI,\nρI = KI/Tr(KI),\nHI = −Tr(ρI log ρI)\n(2)\n3.3.4\nInstability Score HR|I\nWe define the instability score as the conditional\nentropy of results given interpretations: “Given a\nclear interpretation, how much does the answer still\nvary?”\nThe Naive Subtraction Approach. A natural ap-\nproach is to estimate conditional entropy via sub-\ntraction: HR|I = HR,I −HI. However, this relies\non the Shannon entropy chain rule, which does\nnot generally hold for von Neumann entropy on\nheat-kernel density matrices(Nikitin et al., 2024).\nThe joint and marginal kernels have different sizes\n(see Eq. 1) and undergo independent diffusion pro-\ncesses, so ˜HR|I is not guaranteed to be positive.\nIndeed, ˜H yields negative values in 37–60% of\ncases (Tables 1 and 3).\nThe Schur Complement Approach. We lever-\nage the block structure of W (Eq. 1) to construct\nthe conditional similarity structure directly via the\nSchur complement (Schur, 1917; Zhang, 2005):\nS = WRR −WRI(WII + ϵI)−1WIR\n(3)\nwhere ϵ = 10−3 ensures invertibility. The Schur\ncomplement provides a principled way to “condi-\ntion on” the interpretation structure. The projection\nterm WRIW−1\nII WIR captures the portion of re-\nsult similarity explained by interpretations. The\nresidual S retains only the similarity structure that\ninput ambiguity cannot account for. This mirrors\nthe Gaussian case, where the Schur complement\nyields conditional covariance Cov(R|I) (Boyd and\nVandenberghe, 2004). The entropy HR|I computed\nfrom S therefore quantifies the system’s internal\ninconsistency. Since S is not guaranteed to be\npositive semidefinite (PSD), we project onto the\nPSD cone via eigendecomposition, clipping nega-\ntive eigenvalues to zero (Higham, 2002), then ap-\nply the KLE recipe (Eq. 2). Unlike the subtrac-\ntion approach above, this guarantees HR|I ≥0.\nWe term this decomposition framework CLUES\n(Conditional Language Uncertainty via Entropy\nand Schur). Crucially, CLUES distinguishes uncer-\ntainty from query ambiguity (potentially address-\nable via clarification) from system instability (re-\nquiring model-level intervention).\n"}, {"page": 5, "text": "3.3.5\nUncertainty regimes and recommended\ninterventions\nWe define four regimes by thresholding HI (ambi-\nguity) and HR|I (instability):\n• Regime I: Confident (low HI, low HR|I):\nauto-answer.\n• Regime II: Ambiguity (high HI, low HR|I):\ninput refinement (clarification).\n• Regime III: Instability (low HI, high HR|I):\ngeneration review.\n• Regime IV: Compound (high/high): clarifica-\ntion + generation review.\nIn experiments we use median thresholds unless\notherwise stated. We evaluate both failure predic-\ntion and regime-based routing in Sec. 4.2, 5.3, and\n6.3.\n4\nExperiments on Open Answer Datasets\nWe first validate our decomposition on two open-\ndomain QA benchmarks: AmbigQA (Min et al.,\n2020), where questions admit multiple valid in-\nterpretations due to semantic ambiguity, and Situ-\natedQA (Zhang and Choi, 2021), where answers\nvary based on temporal or geographical context.\nBoth datasets provide gold-standard interpretations\npaired with corresponding answers, allowing us to\ntest whether HR|I provides a more accurate failure\nsignal than HR.\n4.1\nExperimental Setup\nDataset and Protocol. From each dataset, we se-\nlect the first Nq = 300 questions with at least two\ngold interpretations, capping at three interpreta-\ntions per question to limit inference costs. Follow-\ning the two-stage framework in Sec. 3, the interpre-\ntation stage is given by the dataset’s gold interpreta-\ntions. For the generation stage, we sample M = 3\nanswers per interpretation, yielding N × M results\nper question (N ∈{2, 3}). We construct the bi-\npartite semantic graph W and compute HR, ˜HR|I,\nand HR|I.\nLarge Language Models.\nFor answer genera-\ntion, we evaluate five frontier LLMs: GPT-OSS-\n120B (hereafter GPT-OSS) (OpenAI et al., 2025),\nKimi K2 Thinking (KimiK2) (Team et al., 2025)\nand Qwen-3-VL-235B-A22B (Qwen3) (Team,\n2025) are open-weights; Gemini 3 Pro (Gem-\nini3Pro) (Gemini Team, 2023) and Claude Sonnet\n4.5 (Claude4.5S) (Anthropic AI, 2023) are propri-\netary. All models are sampled with temperature\nT = 1. Throughout this paper, we use Gemini\n2.5 Flash (T = 0) for semantic similarity (WII,\nWRR) and answer correctness evaluation (unless\notherwise noted).\nEvaluation Metric. We employ a strict path con-\nsistency strategy: a generated answer is correct\nonly if it matches the gold answer for the specific\ninterpretation that produced it, not any valid an-\nswer. Correctness is assessed via LLM-as-a-judge,\nprompting Gemini3Pro with the predicted and gold\nanswers. A question is labeled as failure if the\nproportion of correct answers falls below a thresh-\nold η (we use η = 0.8). This criterion requires\nthe system to respect the semantic constraints of\neach interpretation, penalizing both mode collapse\n(identical outputs across distinct interpretations)\nand context confusion (correct answer paired with\nwrong interpretation).\n4.2\nResults and Analysis\nResults are presented in Table 1.\nPredicting\nfailures on frontier LLMs is inherently challeng-\ning; the baseline HR achieves AUROC scores\nof 0.47–0.66 depending on model and dataset.\nOur proposed HR|I consistently outperforms HR,\nachieving pooled AUROC of 0.627 on AmbigQA\n(+0.077) and 0.641 on SituatedQA (+0.074). Per-\nmodel results show consistent improvements, with\nthe largest gains when HR itself carries predic-\ntive signal; for models where HR performs near\nchance (Claude4.5S, Qwen3), all entropy measures\nshow very limited discriminative power. The naive\nsubtraction approach ˜HR|I achieves near-chance\nAUROC, validating the need for the Schur comple-\nment construction (Eq.3).\nThe improvement over HR stems from CLUES’s\nability to account for input structure. By ignoring\ninterpretations, HR errs in both directions: diver-\nsity inflation, where legitimate variation across in-\nterpretations (WII ≈I, WRR ≈I) is flagged as\nuncertainty; and mode collapse, where identical\noutputs across distinct interpretations (WRR ≈1)\nyield false confidence. The Schur complement de-\ntects both failure modes.\nRegime Analysis.\nThe four-regime framework\n(Sec. 3.3.5) partitions by HI and HR|I to guide\ninterventions. Here, we test whether HR|I provides\ndiscriminative value beyond HR alone. We fo-\ncus on high-uncertainty queries where HR exceeds\n"}, {"page": 6, "text": "AmbigQA (Nq = 300)\nSituatedQA (Nq = 300)\nAUROC\nRegime Acc.\nAUROC\nRegime Acc.\nModel\nAcc.\nHR\n˜HR|I\nHR|I\nA\nB\n∆\nAcc.\nHR\n˜HR|I\nHR|I\nA\nB\n∆\nQwen3\n25.0\n.476\n.550\n.506\n29.8\n23.7\n+6.2\n20.7\n.494\n.521\n.561\n32.8\n16.3\n+16.5\nGPT-OSS\n27.0\n.641\n.524\n.702\n53.8\n8.1\n+45.7\n25.7\n.660\n.634\n.758\n44.4\n3.1\n+41.3\nKimiK2\n40.7\n.663\n.466\n.770\n76.1\n16.3\n+59.7\n37.3\n.631\n.590\n.752\n64.3\n13.8\n+50.5\nClaude4.5S\n35.7\n.501\n.475\n.533\n40.7\n35.7\n+5.0\n30.7\n.502\n.569\n.495\n44.4\n19.5\n+24.9\nGemini3Pro\n47.3\n.538\n.480\n.659\n73.8\n32.6\n+41.2\n44.6\n.584\n.594\n.685\n61.6\n12.7\n+48.9\nPooled\n35.1\n.550\n.498\n.627\n56.6\n21.1\n+35.5\n31.8\n.567\n.573\n.641\n46.8\n13.3\n+33.5\nTable 1: Multi-Model Validation on Open-Domain QA Benchmarks. We evaluate Nq = 300 questions per dataset\nacross 5 LLMs (pooled: Nq ×5 = 1500 question–model instances). We compare HR (baseline KLE result entropy),\nnaive subtraction ˜HR|I, and Schur-complement conditional entropy HR|I (CLUES) for failure prediction (AUROC).\n∆denotes the accuracy gap between Regime A (high HR, low HR|I) and Regime B (high HR, high HR|I), where\nhigh/low are defined by pooled median splits. The naive subtraction ˜HR|I yields negative values in 53%/37% of\ncases (AmbigQA/SituatedQA).\nInput Question\nDisambiguated Question\nHow many patients > 17 yo have atopic\ndermatitis (all codes). Breakdown by\ncode\nCalculate the count of unique patients who have a first diagnosis of Atopic\nDermatitis at any time in their patient history, where the patient’s age at the\ntime of this first diagnosis was greater than 17 years. Provide this count broken\ndown by the specific concept code of Atopic Dermatitis.\nHow many patients with chronic kidney\ndisease never took heparin before their\nchronic kidney disease diagnosis?\nCount the number of unique patients who have a first occurrence of Chronic\nKidney Disease and who have no record of Heparin administration at any time\nprior to their first Chronic Kidney Disease diagnosis.\nTable 2: Disambiguation examples resolving temporal, demographic, and event ordering ambiguities. Bold text\nindicates specifications that were implicit or absent in the original question.\nits median, then partition by median HR|I into\nRegime A (low HR|I) and Regime B (high HR|I).\nDespite identical HR profiles, accuracy differs sub-\nstantially: 56.6% vs. 21.1% for AmbigQA and\n46.8% vs. 13.3% for SituatedQA. These differences\nare highly significant (Chi-square p < 10−22), with\nodds ratios of 4.9 and 5.7: queries in Regime B are\n5–6× more likely to fail. This pattern holds across\nall five LLMs without model-specific calibration.\n5\nClinical Text-to-SQL with Known\nInterpretations\n5.1\nResolving Ambiguity in Epidemiological\nQuestions\nEpidemiological questions in natural language\nfrequently contain implicit ambiguities requiring\nexplicit specification for accurate analysis (Ta-\nble 2). While rule-based templates (e.g., OHDSI\nATLAS (OHDSI Community, 2024)) lack flexi-\nbility and interactive clarification introduces user\nfatigue, our iterative disambiguation approach au-\ntomatically infers the most plausible interpretation\nthrough successive refinement rounds, presenting\nusers with a transparent final specification they can\nverify or edit before SQL generation. The disam-\nbiguation pipeline operates iteratively until con-\nvergence. Given an input question, each round\nprompts the LLM to:\n1. Identify common epidemiological ambigui-\nties including patient count semantics (unique\npatients vs. all records), temporal relation-\nships (before/after, within timeframes), pop-\nulation definitions (inclusion/exclusion crite-\nria), event ordering (first vs. any occurrence),\nand demographic specifications (age at diag-\nnosis vs. current age).\n2. Assign an ambiguity score s ∈[0, 1] and\ngenerate multiple candidate interpretations or-\ndered by clinical plausibility.\n3. Select the most plausible interpretation for the\nnext round.\nThe prompt embeds domain conventions as defaults\nreflecting common practice in observational health\nresearch (e.g., standard age bands; defaulting to\n"}, {"page": 7, "text": "entire patient history when unspecified; unique pa-\ntient counts). The process terminates when ambi-\nguity falls below a threshold (s < 0.1); in practice,\nwithin 1–3 iterations. We use Gemini 2.5 Flash\nwith structured output schemas.\nThis iterative disambiguation offers three advan-\ntages: (1) transparency, as users can review and\nedit candidates before SQL generation; (2) edu-\ncational value, as outputs serve as templates for\nwell-formed questions; and (3) systematic appli-\ncation of epidemiological best practices without\nuser-specified routine parameters.\nIn qualitative evaluation, epidemiologists con-\nfirmed that disambiguated outputs accurately re-\nflect domain conventions and produce clinically\nappropriate disambiguations.\n5.2\nExperimental Setup\nSource Dataset and Interpretation Construction.\nWe build on EpiAskKB (Ziletti and D’Ambrosi,\n2025), which contains question-SQL pairs for epi-\ndemiological research on EHR. Questions may be\nambiguous, reflecting how epidemiologists natu-\nrally pose queries (Table 2). For each question,\nwe construct a multi-interpretation setup follow-\ning Sec. 4.1. From the question and gold SQL,\nwe generate a disambiguated question reflecting\nthe gold SQL, plus three alternative interpretations\n(Sec. 5.1). For each alternative, we generate SQL\nby prompting the LLM with the original question,\nalternative interpretation, and gold SQL to guide\nquery structure. This constrained context mini-\nmizes structural errors. We use Gemini3Pro for all\ngeneration.\nGeneration and Execution Pipeline. For each\nquestion, we sample M = 3 SQL queries per inter-\npretation, yielding 3 × 3 = 9 generated queries per\nmodel-temperature configuration. SQL generation,\nentity resolution, self-correction, and execution fol-\nlow Ziletti and DAmbrosi (2024). Queries are run\non Optum’s de-identified Clinformatics® Data Mart\nDatabase, and retrieved results are verbalized into\nnatural language answers, from which we compute\nHR, ˜HR|I, and HR|I as in Sec. 3. Evaluation fol-\nlows Sec. 4.1 with η = 0.6.\n5.3\nResults\nResults are presented in Table 3. HR|I outper-\nforms HR as a failure predictor in 17 of 20 model-\ntemperature configurations, achieving pooled AU-\nROC of 0.762 [95% CI: 0.737, 0.787] versus 0.600\n[0.575, 0.627] for HR. This difference is signif-\nicant (p < 10−10), demonstrating that condition-\ning on interpretation structure provides substantial\ndiscriminative value. The naive subtraction ˜HR|I\nachieves only 0.461 AUROC with 60% negative\nvalues, validating the theoretical necessity of the\nSchur complement (Sec. 3.3).\nAUROC\nModel (T)\nAcc.\nHR\n˜HR|I\nHR|I\n∆\nQwen3\nT=0.7\n53.3\n.605\n.544\n.764\n+54.3\nT=1.0\n54.2\n.617\n.531\n.748\n+42.6\nT=1.5\n55.0\n.618\n.505\n.818\n+59.2\nT=2.0\n54.1\n.630\n.498\n.786\n+65.8\nGPT-OSS\nT=0.7\n71.6\n.600\n.416\n.731\n+31.2\nT=1.0\n75.5\n.615\n.410\n.828\n+34.3\nT=1.5\n71.6\n.615\n.384\n.831\n+34.2\nT=2.0\n71.6\n.612\n.391\n.818\n+35.0\nKimiK2\nT=0.7\n76.1\n.632\n.446\n.815\n+41.7\nT=1.0\n74.3\n.548\n.417\n.817\n+40.5\nT=1.5\n75.2\n.635\n.444\n.791\n+44.7\nT=2.0\n78.9\n.599\n.418\n.853\n+27.8\nClaude4.5S\nT=0.7\n78.9\n.593\n.395\n.611\n+0.0\nT=1.0\n77.6\n.595\n.466\n.694\n+10.3\nT=1.5\n78.0\n.633\n.400\n.744\n+30.8\nT=2.0\n78.9\n.575\n.426\n.622\n+16.8\nGemini3Pro\nT=0.7\n93.3\n.708\n.623\n.604\n+3.8\nT=1.0\n93.3\n.620\n.532\n.715\n+20.6\nT=1.5\n88.8\n.642\n.578\n.593\n+5.9\nT=2.0\n88.8\n.635\n.542\n.595\n+10.7\nPooled\n74.4\n.600\n.461\n.762\n+33.6\nTable 3: Clinical Text-to-SQL benchmark results (N =\n2,180; 109 questions × 5 models × 4 temperatures). ∆\n= Regime A −Regime B accuracy gap. ˜HR|I produces\nnegative values in 60% of cases.\nRegime Analysis Confirms Discriminative Value.\nThe accuracy gap ∆between Regime A (high HR,\nlow HR|I) and Regime B (high HR, high HR|I),\nsplit at median values, is positive in 19 of 20 con-\nfigurations (pooled: +33.6 pp). This replicates the\nopen-domain QA pattern (Sec. 4.2): among queries\nwith equally high output diversity, those with low\nHR|I are substantially more likely to succeed.\nTemperature Modulates Uncertainty Signal. For\nmost models, moderate temperatures (T = 1.0–\n1.5) yield the strongest HR|I signal. Claude 4.5\nillustrates this pattern: regime separation increases\nfrom ∆= 0 at T=0.7 to ∆= +30.8 at T=1.5\n(0 →+30.8), suggesting higher sampling diversity\n"}, {"page": 8, "text": "exposes latent instability. Gemini 3 Pro is the ex-\nception: its errors appear to stem from consistent\nbut incorrect outputs rather than instability.\nSensitivity to Diffusion Parameter τ. Table 4\nshows HR|I is robust for τ ≥2 (AUROC 0.75–\n0.76), while HR degrades at high τ (0.74 →0.58)\nas diffusion blurs pairwise similarities toward uni-\nformity. The Schur complement resists this ef-\nfect: both raw similarities and the projection term\nsmooth proportionally, preserving residual signal.\nτ\n1\n2\n3\n5\n10\n15\n20\nHI\n.571 .574 .576 .578 .572 .569 .567\nHR\n.669 .742 .738 .676 .601 .586 .582\nHR|I\n.675 .746 .764 .765 .762 .761 .760\nTable 4: Pooled AUROC sensitivity to heat kernel pa-\nrameter τ. HR|I remains stable across τ ∈[2, 20] while\nHR degrades at high diffusion.\n6\nClinical Text-to-SQL in Deployment\nSettings\n6.1\nExperimental Setup\nHaving established that HR|I outperforms HR with\nknown interpretations, we now test whether these\ngains extend to production deployment. This set-\nting differs from previous experiments in three key\nways.\nInterpretations are generated, not given. Inter-\npretations are produced on the fly via our disam-\nbiguation procedure (Sec. 5.1) and may imperfectly\ncapture the true ambiguity structure, unlike the val-\nidated gold/silver labels used previously.\nUncertainty serves as a proxy signal. We eval-\nuate final-answer correctness only, meaning HR|I\ncomputed over interpretations serves as a proxy\nfor reliability rather than directly measuring per-\ninterpretation accuracy.\nLimited statistical power. Evaluation is coarser\n(one label per question rather than per interpreta-\ntion), and models achieve high accuracy (Table 5),\nyielding sparse errors that challenge statistical esti-\nmation.\nWe use the same pipeline as Sec. 5.2, testing\nwith and without disambiguation and RAG. RAG\nfollows the methodology in Ziletti and DAmbrosi\n(2024).\n6.2\nResults\nTable 5 summarizes performance in the deployment\nsetting. All models achieve 84–100% accuracy,\nhigher than Sec. 5.3. This reflects the evaluation\nsetup: strict path consistency requires correctness\nacross multiple interpretations including less nat-\nural ones, while here we evaluate a single answer\nagainst the original query, which typically matches\nthe model’s default interpretation.\nQwen3\nGPT-OSS\nKimiK2\nClaude4.5S\nGemini3Pro\nPooled\nDis RAG\n×\n×\n85.3 93.6 99.1 95.4 100 94.7\n✓\n×\n88.1 98.2 99.1 94.5 97.2 95.4\n×\n✓\n90.8 99.1 97.2 97.2 100 96.9\n✓\n✓\n94.5 92.7 94.5 96.3 100 95.6\nPooled\n89.7 95.9 97.5 95.9 99.3 95.6\nTable 5: Model Accuracy by Configuration. Dis. =\ndisambiguated input. All values in %.\nUncertainty Separates Correct from Incorrect.\nDespite sparse errors, median uncertainty values\nare systematically higher for incorrect predictions.\nPooled across all configurations (N = 2,180), in-\ncorrect predictions show median HI of 0.189 vs.\n0.069 for correct, HR of 0.442 vs. 0.301, and HR|I\nof 0.072 vs. 0.003.\nRAG Stabilizes Output. RAG substantially re-\nduces HR|I for correct predictions: GPT-OSS\ndrops from 0.113 to 0.030, Qwen3 from 0.046 to\n0.006, and KimiK2 from 0.062 to 0.025. How-\never, RAG also reduces HR|I for incorrect predic-\ntions (pooled median: 0.104 →0.052), which may\nsuppress the uncertainty signal that would other-\nwise flag errors (e.g., GPT-OSS: 0.296 →0.025).\nClaude4.5S and Gemini3Pro show minimal HR|I\n(0.002) with or without RAG, suggesting sufficient\ninternalized domain knowledge.\nAUROC and regime-based diagnostics. In this\nsetting (Sec. 6.1), pooled AUROC is 0.687 [0.629,\n0.740] for HR versus 0.648 [0.600, 0.701] for HR|I\n(not significant, p = 0.20). Crucially, HR cannot\ndistinguish whether a high-uncertainty query needs\nclarification, model review, or both. CLUES is de-\nsigned to decompose uncertainty rather than maxi-\nmize single-score prediction, providing diagnostic\n"}, {"page": 9, "text": "resolution unavailable from HR alone (Sec. 6.3).\n6.3\nUncertainty Regime Analysis\nGiven sparse per-condition errors, we pool all data\nfor regime analysis. We partition queries using\npooled median thresholds for HI and HR|I, yield-\ning a 2×2 structure (Table 6).\nRegime\nHI\nHR|I\nC/I\nErr\nI: Confident\nLow\nLow\n534/8\n1.5%\nII: Ambiguity\nHigh\nLow\n530/18\n3.3%\nIII: Instability\nLow\nHigh\n529/21\n3.8%\nIV: Compound High High\n492/48\n8.9%\nTotal\n2085/95\n4.4%\nTable 6: Uncertainty Regime Analysis. 2×2 decom-\nposition by HI and HR|I median thresholds. C/I =\nCorrect/Incorrect.\nError Gradient and Routing Implications. Error\nrates increase from Regime I (1.5%) to Regime IV\n(8.9%). Each regime contains ∼25% of queries, yet\nRegime IV concentrates 51% of all errors (48/95).\nA routing strategy sending only Regime IV to hu-\nman review would examine one quarter of queries\nwhile catching half of all failures. Within-regime\nAUROC in Regime IV (≈0.52 for all metrics) indi-\ncates that continuous entropy values provide lim-\nited additional signal once the regime is determined.\nThe decomposition’s value is further demonstrated\namong high-uncertainty queries where both HI\nand HR are above median (N = 712): these ap-\npear identical under conventional metrics, yet HR|I\nseparates them into Regime A (4.3% error) and\nRegime B (9.2% error). This difference is signif-\nicant (odds ratio OR = 2.24, p < 0.02) and holds\nacross all five models using a single global thresh-\nold.\n7\nSummary\nWe introduced CLUES, a framework that decom-\nposes semantic uncertainty into ambiguity (HI)\nand conditional instability (HR|I) via a Schur-\ncomplement construction over an interpretation–\nresult bipartite graph. Across open-domain QA\nand clinical Text-to-SQL, HR|I is competitive with,\nand often improves upon, state-of-the-art Kernel\nLanguage Entropy (Nikitin et al., 2024) for failure\nprediction, while providing diagnostic resolution\nunavailable from a single score. Regime analy-\nsis based on (HI, HR|I) surfaces distinct failure\npatterns and maps them to targeted interventions:\nclarification for high ambiguity, human review for\nhigh instability. CLUES is model-agnostic and\nrequires only output sampling; future work will ex-\nplore adaptive routing and uncertainty propagation\nin agentic pipelines.\n8\nLimitations\nComputational Cost. CLUES requires multiple\nLLM calls per query (interpretations × samples; 9\nin our setup). Calls can be parallelized, though cost\nremains a consideration for large-scale deployment.\nInterpretation Quality. CLUES assumes gener-\nated interpretations meaningfully capture query am-\nbiguity. If the disambiguation procedure produces\ntrivial or redundant interpretations, HI may un-\nderestimate true input ambiguity, and the Schur\ncomplement may not isolate instability effectively.\nWe observed strong results with frontier LLMs, but\ninterpretation quality likely degrades with weaker\nmodels.\nRouting Efficiency in Sparse Error Regimes.\nIn high-accuracy settings (95.6% in deployment),\nregime-based routing catches 51% of errors by re-\nviewing 25% of queries, twice the efficiency of ran-\ndom selection, though not yet sufficient for fully\nautomated triage. The fundamental challenge is\nsparse errors: with only 95 failures (∼4% error\nrate), fine-grained uncertainty signals have limited\ndiscriminative power. Applications with higher\nbase error rates may benefit more substantially\nfrom regime-based routing.\nReferences\nAnthropic AI. 2023. Model card and evaluations for\nclaude models. https://www-files.anthropic.com/\nproduction/images/Model-Card-Claude-2.pdf. Ac-\ncessed: February 15, 2024.\nStephen Boyd and Lieven Vandenberghe. 2004. Convex\nOptimization. Cambridge University Press, Cam-\nbridge, England.\nNaihao Deng, Yuwei Chen, and Yue Zhang. 2022. Re-\ncent advances in text-to-SQL: A survey of what\nwe have and what we expect.\narXiv preprint\narXiv:2208.10099.\nShreshth Desai and Greg Durrett. 2024. Distinguishing\nthe knowable from the unknowable with language\nmodels. arXiv preprint arXiv:2402.03563.\nIzhak Elazar, Roee Aharoni, Jonathan Berant, and Reut\nTsarfaty. 2024. AMBROSIA: A benchmark for pars-\ning ambiguous questions into database queries. In\n"}, {"page": 10, "text": "Proceedings of the 62nd Annual Meeting of the Asso-\nciation for Computational Linguistics (ACL), pages\n11875–11893.\nSebastian Farquhar, Jannik Kossen, Lorenz Kuhn, and\nYarin Gal. 2024. Detecting hallucinations in large\nlanguage models using semantic entropy. Nature,\n630(8017):625–630.\nGemini Team. 2023. Gemini: A family of highly ca-\npable multimodal models. Technical report, Google.\nAccessed: February 15, 2024.\nShrestha Ghosh, Moritz Schneider, Carina Reinicke, and\nCarsten Eickhoff. 2025. A survey on LLM-assisted\nclinical trial recruitment. In Proceedings of the 14th\nInternational Joint Conference on Natural Language\nProcessing and the 4th Conference of the Asia-Pacific\nChapter of the Association for Computational Lin-\nguistics, pages 625–646, Mumbai, India. The Asian\nFederation of Natural Language Processing and The\nAssociation for Computational Linguistics.\nVivek Gupta, Rui Zhang, and Yue Zhao. 2025. Disam-\nbiguate first parse later: Generating interpretations\nfor ambiguity resolution in semantic parsing. In Pro-\nceedings of the Conference on Empirical Methods in\nNatural Language Processing (EMNLP).\nLars G Hemkens, Despina G Contopoulos-Ioannidis,\nand John PA Ioannidis. 2016. Research reproducibil-\nity in longitudinal multi-center studies using data\nfrom electronic health records. EGEMS (Generating\nEvidence & Methods to improve patient outcomes),\n4(2).\nEmily\nHerrett,\nArlene\nM\nGallagher,\nKrishnan\nBhaskaran, Harriet Forbes, Rohini Mathur, Tjeerd\nvan Staa, and Liam Smeeth. 2017. Methods for en-\nhancing the reproducibility of biomedical research\nfindings using electronic health records. BioData\nMining, 10(1):1–8.\nNicholas J. Higham. 2002. Computing the nearest corre-\nlation matrix—a problem from finance. IMA Journal\nof Numerical Analysis, 22(3):329–343.\nJiuding Huang, Dianzhi Yang, Kit Lau, Yuxuan Liu,\nYu Zhang, Chen Lyu, and Jifeng Chen. 2025. Inte-\ngrating token-level uncertainty, bidirectional nli, and\nsemantic entropy for robust hallucination detection in\nlarge language models. In IEEE International Con-\nference on Big Data (BigData), pages 2945–2954.\nIEEE.\nEyke Hüllermeier and Willem Waegeman. 2021.\nAleatoric and epistemic uncertainty in machine learn-\ning: An introduction to concepts and methods. Ma-\nchine Learning, 110(3):457–506.\nPriyank Jaini Kamkari, Aitor Lewkowycz, and David\nDuvenaud. 2024. A bias-variance-covariance decom-\nposition of kernel scores for generative models. arXiv\npreprint arXiv:2310.05833.\nAlex Kendall and Yarin Gal. 2017. What uncertainties\ndo we need in Bayesian deep learning for computer\nvision? In Advances in Neural Information Process-\ning Systems (NeurIPS), pages 5574–5584.\nDaeyoung Kim, Seongsu Bae, Seungho Kim, and Ed-\nward Choi. 2022. Uncertainty-aware text-to-program\nfor question answering on structured electronic health\nrecords. In Proceedings of the Conference on Health,\nInference, and Learning, pages 138–151. PMLR.\nYongrae Kim, Hyeonseok Park, Seongsu Seo, Gyubok\nLee, and Edward Choi. 2024. LG AI Research &\nKAIST at EHRSQL 2024: Self-training large lan-\nguage models with pseudo-labeled unanswerable\nquestions for a reliable text-to-SQL system on EHRs.\nIn Proceedings of the Clinical NLP Workshop.\nMathew J Koretsky, Maya Willey, and 1 others. 2025.\nBiomedSQL: Text-to-SQL for scientific reasoning\non biomedical knowledge bases.\narXiv preprint\narXiv:2505.20321.\nLorenz Kuhn, Yarin Gal, and Sebastian Farquhar. 2023.\nSemantic uncertainty: Linguistic invariances for un-\ncertainty estimation in natural language generation.\nInternational Conference on Learning Representa-\ntions (ICLR).\nAditya Kumar, Yuxin Zhang, and Jiahao Chen. 2025.\nSemantic volume: Quantifying and detecting both\nexternal and internal uncertainty in LLMs. arXiv\npreprint arXiv:2502.21239.\nGyubok Lee, Hyeonji Hwang, Seongsu Bae, Yeonsu\nKwon, Woncheol Shin, Seongjun Yang, Minjoon\nSeo, Jong C Lee, and Edward Choi. 2023. EHRSQL:\nA practical text-to-SQL benchmark for electronic\nhealth records. In Advances in Neural Information\nProcessing Systems (NeurIPS) Datasets and Bench-\nmarks Track.\nJoonho Lee, Seonghyeon Kim, Seoyoung Park, and\nJinwoo Shin. 2024a. Improving uncertainty quantifi-\ncation in large language models via semantic embed-\ndings. arXiv preprint arXiv:2410.22685.\nSangryul Lee, Jiyoun Kim, and Seoyeon Park. 2024b.\nProbGate at EHRSQL 2024: Enhancing SQL query\ngeneration accuracy through probabilistic threshold\nfiltering and error handling. In Proceedings of the\nClinical NLP Workshop.\nSewon Min, Julian Michael, Hannaneh Hajishirzi, and\nLuke Zettlemoyer. 2020. AmbigQA: Answering am-\nbiguous open-domain questions. In Proceedings of\nthe 2020 Conference on Empirical Methods in Nat-\nural Language Processing (EMNLP), pages 5783–\n5797, Online. Association for Computational Lin-\nguistics.\nMaximilian Mozes, Robert Bamler, and José Miguel\nHernández-Lobato. 2025.\nSemantic uncertainty\nin advanced decoding methods for llm generation.\narXiv preprint arXiv:2506.17296.\n"}, {"page": 11, "text": "Alexander Nikitin, Jannik Kossen, Yarin Gal, and Pekka\nMarttinen. 2024.\nKernel language entropy: fine-\ngrained uncertainty quantification for llms from se-\nmantic similarities. In Proceedings of the 38th Inter-\nnational Conference on Neural Information Process-\ning Systems, NIPS ’24, Red Hook, NY, USA. Curran\nAssociates Inc.\nOHDSI Community. 2024. Atlas: Open source software\nfor observational data analysis.\nhttps://github.\ncom/OHDSI/Atlas. Accessed: 2026-01-28.\nOpenAI, :, Sandhini Agarwal, Lama Ahmad, Jason\nAi, Sam Altman, Andy Applebaum, Edwin Arbus,\nRahul K. Arora, Yu Bai, Bowen Baker, Haiming Bao,\nBoaz Barak, Ally Bennett, Tyler Bertao, Nivedita\nBrett, Eugene Brevdo, Greg Brockman, Sebastien\nBubeck, and 108 others. 2025. gpt-oss-120b and gpt-\noss-20b model card. Preprint, arXiv:2508.10925.\nDaeyoung Park, Suji Choi, Sunjae Kim, Jongwuk Lee,\nand Jaegul Choo. 2022. Uncertainty-aware text-to-\nprogram for question answering on structured elec-\ntronic health records. In Proceedings of the Annual\nMeeting of the Association for Computational Lin-\nguistics (ACL), pages 1914–1929.\nJaehee Park, Nan Zhang, Xiaohui Xiao, and 1 oth-\ners. 2024. EHR-SeqSQL: A sequential text-to-SQL\ndataset for interactively exploring electronic health\nrecords. In Proceedings of the Annual Meeting of the\nAssociation for Computational Linguistics (ACL).\nJ Schur. 1917. Über potenzreihen, die im innern des ein-\nheitskreises beschränkt sind. J. Reine Angew. Math.,\n1917(147):205–232.\nYixuan Sun, Yichi Wang, and Yang Liu. 2025. Enhanc-\ning uncertainty quantification in large language mod-\nels through semantic graph density. arXiv preprint.\nKimi Team, Yifan Bai, Yiping Bao, Guanduo Chen,\nJiahao Chen, Ningxin Chen, Ruijue Chen, Yanru\nChen, Yuankun Chen, Yutian Chen, Zhuofu Chen,\nJialei Cui, Hao Ding, Mengnan Dong, Angang Du,\nChenzhuang Du, Dikang Du, Yulun Du, Yu Fan, and\n150 others. 2025. Kimi k2: Open agentic intelligence.\nPreprint, arXiv:2507.20534.\nQwen Team. 2025. Qwen3 technical report. Preprint,\narXiv:2505.09388.\nTao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga,\nDongxu Wang, Zifan Li, James Ma, Irene Li, Qingn-\ning Yao, Shanelle Roman, Zilin Zhang, and Dragomir\nRadev. 2018. Spider: A large-scale human-labeled\ndataset for complex and cross-domain semantic pars-\ning and text-to-SQL task. In Proceedings of the Con-\nference on Empirical Methods in Natural Language\nProcessing (EMNLP), pages 3911–3921.\nFuzhen Zhang, editor. 2005. The schur complement and\nits applications, 2005 edition. Numerical Methods\nand Algorithms. Springer, New York, NY.\nMichael Zhang and Eunsol Choi. 2021. SituatedQA: In-\ncorporating extra-linguistic contexts into QA. In Pro-\nceedings of the 2021 Conference on Empirical Meth-\nods in Natural Language Processing, pages 7371–\n7387, Online and Punta Cana, Dominican Republic.\nAssociation for Computational Linguistics.\nYuxin Zhang, Zinan Gao, Zhiming Xu, and Peng Cui.\n2025. Inv-entropy: A fully probabilistic framework\nfor uncertainty quantification in language models.\narXiv preprint arXiv:2506.09684.\nAngelo Ziletti and Leonardo DAmbrosi. 2024.\nRe-\ntrieval augmented text-to-SQL generation for epi-\ndemiological question answering using electronic\nhealth records. In Proceedings of the 6th Clinical\nNatural Language Processing Workshop, pages 47–\n53, Mexico City, Mexico. Association for Computa-\ntional Linguistics.\nAngelo Ziletti and Leonardo D’Ambrosi. 2025. Gener-\nating patient cohorts from electronic health records\nusing two-step retrieval-augmented text-to-sql gener-\nation. Preprint, arXiv:2502.21107.\n"}]}