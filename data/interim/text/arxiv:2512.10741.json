{"doc_id": "arxiv:2512.10741", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2512.10741.pdf", "meta": {"doc_id": "arxiv:2512.10741", "source": "arxiv", "arxiv_id": "2512.10741", "title": "TRIDENT: A Redundant Architecture for Caribbean-Accented Emergency Speech Triage", "authors": ["Elroy Galbraith", "Chadwick Sutherland", "Donahue Morgan"], "published": "2025-12-11T15:29:33Z", "updated": "2025-12-11T15:29:33Z", "summary": "Emergency speech recognition systems exhibit systematic performance degradation on non-standard English varieties, creating a critical gap in services for Caribbean populations. We present TRIDENT (Transcription and Routing Intelligence for Dispatcher-Empowered National Triage), a three-layer dispatcher-support architecture designed to structure emergency call inputs for human application of established triage protocols (the ESI for routine operations and START for mass casualty events), even when automatic speech recognition fails.   The system combines Caribbean-accent-tuned ASR, local entity extraction via large language models, and bio-acoustic distress detection to provide dispatchers with three complementary signals: transcription confidence, structured clinical entities, and vocal stress indicators. Our key insight is that low ASR confidence, rather than representing system failure, serves as a valuable queue prioritization signal -- particularly when combined with elevated vocal distress markers indicating a caller in crisis whose speech may have shifted toward basilectal registers. A complementary insight drives the entity extraction layer: trained responders and composed bystanders may report life-threatening emergencies without elevated vocal stress, requiring semantic analysis to capture clinical indicators that paralinguistic features miss.   We describe the architectural design, theoretical grounding in psycholinguistic research on stress-induced code-switching, and deployment considerations for offline operation during disaster scenarios. This work establishes a framework for accent-resilient emergency AI that ensures Caribbean voices receive equitable access to established national triage protocols. Empirical validation on Caribbean emergency calls remains future work.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2512.10741v1", "url_pdf": "https://arxiv.org/pdf/2512.10741.pdf", "meta_path": "data/raw/arxiv/meta/2512.10741.json", "sha256": "bc6d956cab77ebc063e6ce8cb46d73c7f44eed4496150e514921015c6bf8202f", "status": "ok", "fetched_at": "2026-02-18T02:24:25.996912+00:00"}, "pages": [{"page": 1, "text": "TRIDENT: A Redundant Architecture for Caribbean-Accented\nEmergency Speech Triage\nGalbraith, E., Sutherland, C., and Morgan, D.\nSMG Labs Research Group\nDecember 12, 2025\nAbstract\nEmergency speech recognition systems exhibit systematic performance degradation on\nnon-standard English varieties, creating a critical gap in services for Caribbean populations.\nWe present TRIDENT (Transcription and Routing Intelligence for Dispatcher-Empowered\nNational Triage), a three-layer dispatcher-support architecture designed to structure emer-\ngency call inputs for human application of established triage protocols (the ESI for routine\noperations and START for mass casualty events), even when automatic speech recognition\nfails.\nThe system combines Caribbean-accent-tuned ASR, local entity extraction via large\nlanguage models, and bio-acoustic distress detection to provide dispatchers with three com-\nplementary signals: transcription confidence, structured clinical entities, and vocal stress\nindicators. Our key insight is that low ASR confidence, rather than represent-\ning system failure, serves as a valuable queue prioritization signal—particularly\nwhen combined with elevated vocal distress markers indicating a caller in crisis\nwhose speech may have shifted toward basilectal registers. A complementary in-\nsight drives the entity extraction layer: trained responders and composed bystanders may\nreport life-threatening emergencies without elevated vocal stress, requiring semantic analysis\nto capture clinical indicators that paralinguistic features miss.\nWe describe the architectural design, theoretical grounding in psycholinguistic research\non stress-induced code-switching, and deployment considerations for offline operation during\ndisaster scenarios. This work establishes a framework for accent-resilient emergency AI that\nensures Caribbean voices receive equitable access to established national triage protocols.\nEmpirical validation on Caribbean emergency calls remains future work.\nKeywords: speech recognition, Caribbean English, emergency dispatch, vocal stress, triage\n1\nIntroduction\nWhen a caller dials emergency services during a crisis, modern automatic speech recognition\n(ASR) systems exhibit well-documented performance disparities across demographic groups [10].\nFor Caribbean English speakers—a population of over 40 million—these disparities compound\nwith a linguistic phenomenon: under acute stress, speakers tend to shift toward basilectal (more\ncreole-heavy) speech registers, precisely the varieties on which ASR systems perform worst.\nCaribbean health ministries have adopted internationally-validated triage protocols: the\nEmergency Severity Index (ESI) for routine operations and START (Simple Triage and Rapid\nTreatment) for mass casualty events. These protocols assume dispatchers can accurately capture\ncaller information—an assumption that fails systematically when ASR systems cannot reliably\ntranscribe Caribbean speech.\n1\narXiv:2512.10741v1  [cs.CL]  11 Dec 2025\n"}, {"page": 2, "text": "1.1\nTRIDENT: Dispatcher-Empowered Architecture\nThis paper presents TRIDENT (Transcription and Routing Intelligence for Dispatcher-\nEmpowered National Triage), designed to ensure Caribbean-accented callers receive equi-\ntable access to established triage protocols. Rather than attempting to eliminate ASR errors—an\nunrealistic goal—we build a dispatcher-support system that remains functional when tran-\nscription fails.\nOur central contribution is a three-layer framework providing dispatchers with struc-\ntured inputs for protocol application:\n1. Transcription confidence: Flags unreliable transcripts so dispatchers know to listen\ndirectly to audio\n2. Structured entity extraction:\nExtracts clinical indicators (location, mechanism,\nbreathing status, vulnerable populations) even from degraded transcriptions\n3. Bio-acoustic distress detection: Provides physiological stress markers independent of\ntranscript content\n1.2\nKey Insights\nTwo complementary insights motivate this design:\n1. Content beyond voice: Trained responders and composed bystanders may report life-\nthreatening emergencies without elevated vocal stress. Semantic extraction captures infor-\nmation that paralinguistic features miss—ensuring “children trapped in burning building,”\nspoken calmly, provides dispatchers with structured data for appropriate triage classifica-\ntion.\n2. Uncertainty as prioritization signal: Low ASR confidence, rather than represent-\ning failure, serves as a queue prioritization indicator—particularly when combined with\nelevated vocal distress marking a caller in crisis whose speech may have shifted toward\nbasilectal registers. This reframes accent-induced transcription errors from bugs into fea-\ntures correlating with genuine distress.\nTRIDENT addresses critical gaps in existing emergency AI—cloud dependency with accent-\nagnostic ASR, text-only analysis ignoring paralinguistic signals, dialect blindness to stress-\ninduced register shifting, and infrastructure fragility during disasters—while respecting the\nclinical authority of established protocols. The system structures inputs and prioritizes\nqueues, but triage decisions remain with trained professionals applying Ministry of Health-\nmandated frameworks.\n2\nRelated Work\nTRIDENT’s dispatcher-support architecture draws on research across five domains: ASR for\nCaribbean varieties, AI in emergency dispatch, vocal stress detection, dialect reversion under\ncognitive load, and edge computing for disaster resilience.\n2.1\nThe Accent Gap in Automatic Speech Recognition\nModern ASR systems exhibit systematic performance degradation on non-standard English va-\nrieties. Koenecke et al. [10] evaluated five commercial ASR systems, finding word error rates\naveraged 0.35 for Black speakers compared to 0.19 for White speakers, with performance gaps\ntraced to acoustic model limitations rather than language models.\n2\n"}, {"page": 3, "text": "Caribbean English remains especially underserved. Madden et al. [11] developed the first\nsubstantial Jamaican Patois corpus (42.58 hours) and derived scaling laws for Whisper perfor-\nmance. Pre-trained Whisper Large achieved 89% WER on Patois, while fine-tuned Whisper\nMedium reduced this to 30% WER. Critically, their scaling law (WER = 158.06 × M−0.255 ×\nD−0.269) demonstrates that dataset increases yield greater gains than model scaling for underrep-\nresented varieties, informing our choice of Whisper Medium with Caribbean-specific fine-tuning.\n2.2\nAI-Assisted Emergency Dispatch and Clinical Protocols\nEmergency services worldwide are exploring AI to improve call handling, but these systems must\nsupport established clinical triage protocols rather than replace human judgment.\nClinical Triage Protocols.\nThe Emergency Severity Index (ESI) is a five-level acuity\nscale (Level 1: immediate lifesaving intervention to Level 5: no resources needed) widely used\nin the United States and internationally [6]. Jamaica’s Ministry of Health implemented ESI\nacross all 19 public hospital emergency departments in 2016 [7]. For mass casualty events such\nas hurricanes, the START (Simple Triage and Rapid Treatment) protocol provides rapid four-\ncategory sorting: BLACK (deceased/expectant), RED (immediate), YELLOW (delayed), and\nGREEN (walking wounded). The ESI handbook explicitly notes that ESI should not be used\nduring mass casualty incidents [6].\nCurrent AI Systems. Existing emergency AI systems (e.g., ECA [1], Corti [2]) achieve\npromising classification accuracy but rely on cloud-dependent, accent-agnostic ASR and process\nonly transcribed text, ignoring paralinguistic signals. A scoping review of 106 AI studies in\nprehospital care identified underutilization of multimodal inputs and absence of infrastructure-\nindependent systems as key gaps [4].\nGaps for Caribbean Deployment. Three limitations motivate TRIDENT’s design: (1) no\naccent adaptation for Caribbean varieties or stress-induced register shifting, (2) no integration\nof vocal stress detection with text classification, and (3) cloud dependency that fails during\ndisasters when emergency services are most needed.\nTRIDENT addresses these gaps while\nmaintaining the principle that AI should empower dispatchers to apply ESI/START protocols\nmore effectively, not replace clinical judgment.\n2.3\nVocal Stress Detection\nThe bio-acoustic layer builds on research establishing acoustic correlates of psychological stress.\nA systematic review of 38 studies found fundamental frequency (F0) as the most consistent\nstress marker, with 15 of 19 studies reporting significant mean F0 increases under stress [15].\nResearch on emergency communications provides direct validation.\nVan Puyvelde et al.\n[18] analyzed real-life emergency recordings including cockpit voice recorders and 911 calls,\ndocumenting F0 increases from 123.9 Hz to 200.1 Hz during life-threatening emergencies—a\n62% increase. However, Deschamps-Berger et al. [5] found that while benchmark IEMOCAP\ndata yielded 63% emotion recognition accuracy, real emergency calls achieved only 45.6%—a\nsubstantial domain shift. This finding reinforces our design decision to use bio-acoustic analysis\nas a triage signal routing high-distress calls to human dispatchers, rather than attempting fully\nautomated classification.\n2.4\nDialect Reversion Under Cognitive Load\nPsycholinguistic research establishes that for Caribbean speakers navigating the creole continuum—\nfrom basilect (most creole features) through mesolect to acrolect (Standard English)—maintaining\nacrolectal speech requires sustained executive function. The inhibitory control model establishes\nthat non-target languages remain continuously active and must be suppressed through cognitive\n3\n"}, {"page": 4, "text": "effort [9]. Under high cognitive load, this inhibition fails, causing speakers to revert toward their\ndominant variety.\nPatrick’s [12] sociolinguistic analysis of the Jamaican Creole continuum establishes that stress\nlevels influence speakers’ positioning on this spectrum, with most speakers being mesolectal un-\nder normal conditions but capable of shifting toward either pole. The implications for emergency\nservices are significant: a professional who speaks Standard English at work may revert toward\nbasilectal Patois when their house is flooding. Standard ASR systems will exhibit precisely the\nperformance degradation documented in the accent gap literature at the moment when accurate\nrecognition is most critical.\n2.5\nEdge Computing for Disaster Resilience\nInfrastructure failure during disasters makes the case for offline-capable emergency AI. Hurricane\nMaria’s impact on Puerto Rico saw 95% of cell towers fail, with the entire island losing power [14].\nCommunication infrastructure failure contributed to a disputed death toll ultimately estimated\nat approximately 3,000, with recovery requiring over 200 days for full power restoration.\nRecent model compression advances make edge deployment feasible. Pre-positioned edge\ncomputing resources at hospitals, shelters, and emergency coordination centers, loaded with\nCaribbean-tuned models, could maintain triage capability even during complete grid and network\nfailure.\n2.6\nSummary: Positioning Our Contribution\nTRIDENT addresses four critical gaps in existing emergency dispatch AI for Caribbean deploy-\nment:\n• Caribbean-adapted ASR: Fine-tuned Whisper models (informed by Madden et al.’s\nscaling laws) provide transcription accuracy for Caribbean speech varieties, enabling viable\ndownstream entity extraction.\n• Multimodal distress detection: Parallel bio-acoustic analysis provides a signal pathway\nthat functions even when ASR fails, transforming low transcription confidence from a\nlimitation into a queue prioritization feature.\n• Stress-aware design:\nAccounts for stress-induced register shifting along the creole\ncontinuum—routing calls with elevated vocal distress and low ASR confidence to immedi-\nate human attention.\n• Offline operation: Complete system deployment on edge hardware (Raspberry Pi 5)\nenables function during infrastructure failures when emergency services are most critical.\nThe result is the first dispatcher-support system designed specifically for Caribbean emer-\ngency services—not to make triage decisions, but to ensure Caribbean-accented callers receive\nequitable access to the ESI and START protocols that their health ministries have adopted.\nTRIDENT empowers dispatchers with better information and intelligent queue prioritization;\nclinical judgment remains with trained human professionals.\n3\nTheoretical Foundations\nFine-tuning Whisper on Caribbean speech improves transcription but cannot eliminate the ac-\ncent gap. Madden et al. [11] achieved 30% WER on Jamaican Patois—dramatic improvement\nfrom 89% baseline, but still far above the <5% WER typical for standard English. Moreover,\n4\n"}, {"page": 5, "text": "fine-tuning on broadcast speech cannot capture emergency acoustics: elevated noise, emotional\nqualities, and stress-induced basilectal reversion. ASR alone will fail when needed most.\nConversely, bio-acoustic distress detection cannot provide semantic information needed for\ndispatch. A caller may exhibit extreme vocal stress while saying “my house is on fire” or “I lost my\nkeys”—identical distress signals but dramatically different responses. Furthermore, Deschamps-\nBerger et al. [5] found laboratory emotion recognition accuracy (63%) drops substantially in\nreal emergency calls (45.6%). Bio-acoustic features provide gradient information about caller\nstate but cannot substitute for semantic content.\n3.1\nThe Integration Thesis\nOur architecture integrates these complementary information sources based on the following\nthesis: In emergency contexts, the correlation between ASR failure and genuine\ndistress creates an opportunity to use recognition uncertainty as a routing signal\nrather than an error to be minimized.\nLinguistic Continuum\n0.0 (Failure)\n0.5\n0.7 (Threshold)\n1.0 (Perfect)\nASR Transcription Confidence\nACROLECT\n(Standard English)\nMESOLECT\n(Caribbean Variation)\nBASILECT\n(Deep Creole)\nSTRESS / COGNITIVE LOAD\n(Inhibitory Control Failure)\nTRIDENT INTERVENTION ZONE\n(Low Confidence + High Distress)\nConfidence Threshold (0.7)\nTheoretical Model: Stress-Induced Dialect Shift vs. ASR Performance\nFigure 1: The TRIDENT Integration Thesis: Stress-Induced Dialect Shift vs. ASR Performance.\nThe model illustrates the system’s theoretical foundation. Under acute stress (red arrow), speak-\ners experience inhibitory control failure, shifting along the continuum from acrolectal (standard)\nto basilectal (creole) registers. As speech becomes more basilectal, ASR confidence (blue line)\ndegrades below the usable threshold of 0.7. The “Intervention Zone” highlights TRIDENT’s\nnovel contribution: identifying calls where low transcription confidence coincides with high bio-\nacoustic distress, thereby converting a technical failure into a high-priority (Q1) routing signal.\nThis thesis rests on the psycholinguistic literature establishing that:\n1. Stress triggers cognitive load effects that impair executive function [8]\n2. Impaired executive function leads to reduced inhibition of dominant language varieties [9]\n3. For Caribbean speakers, dominant varieties include basilectal forms underrepresented in\nASR training [12, 11]\n4. Stress simultaneously elevates bio-acoustic markers (F0, intensity) that can be detected\nindependently of speech content [18]\nThe logical conclusion: when ASR confidence drops and bio-acoustic distress rises, the system\nhas detected a caller in genuine crisis whose speech has shifted beyond standard recognition\ncapabilities. This combination should trigger immediate human review—not because the system\nhas failed, but because it has successfully identified a caller who needs human attention most.\n5\n"}, {"page": 6, "text": "4\nSystem Architecture\nTRIDENT implements a three-layer dispatcher-support architecture where each component pro-\nvides independent value while contributing to intelligent queue prioritization. The system does\nnot make clinical triage decisions—those remain with trained dispatchers applying ESI or START\nprotocols—but ensures dispatchers receive the highest-priority calls first along with structured\ninformation to support protocol application. Figure 2 illustrates the system flow.\nParallel Processing Layers\nQueue Priority Levels\nIncoming Emergency Call\n(Raw Audio)\nLayer 1: ASR\n(Caribbean-Tuned Whisper Medium)\n[Fine-tuned w/ LoRA]\n Audio Stream\nLayer 3: Bio-Acoustic Analysis\n(pYIN F0, RMS Energy, Pitch CV, Jitter)\n[No Transcription Required]\n Audio Stream\nLayer 2: NLP Entity Extraction\n(Llama 3 8B - 4bit Quantized)\n[Local Inference]\n Transcript +\nConfidence Score\nQueue Prioritization Engine\n(3D Decision Matrix:\nConfidence × Distress × Content)\n Confidence\nScore\n Extracted Entities +\nContent Indicator Score\n Distress Score\n(0-1)\nQ1-IMMEDIATE\n(Highest Priority)\n Low Conf +\nHigh Distress\nQ2-ELEVATED\n(High Priority)\n High Content\nIndicators\nQ3-MONITOR\n(Moderate Priority)\n High Distress +\nLow Content\nQ5-ROUTINE\n(Standard Queue)\n Routine\nIndicators\nHuman Dispatcher\nReceives: Queue-ordered calls +\nStructured entities + Confidence flags\nDispatcher Applies\nESI (routine) or START (MCI)\nClinical Triage Decision\n Applies clinical\nprotocol\nFigure 2: The TRIDENT architecture. The system processes raw audio through two parallel\nstreams: (Left) A Caribbean-adapted ASR and NLP pipeline for entity extraction and content\nanalysis, and (Right) a bio-acoustic analysis layer for detecting physiological distress mark-\ners. The Queue Prioritization Engine integrates three independent signals—transcription\nconfidence, extracted clinical indicators, and vocal distress—to determine queue position for dis-\npatcher attention. This ensures that (1) calls with low transcription confidence but high vocal\ndistress receive immediate human review, and (2) semantically urgent calls from calm reporters\nare not delayed due to absent vocal stress markers. The dispatcher then applies established\ntriage protocols (ESI for routine operations, START for mass casualty events) using both TRI-\nDENT’s extracted entities and direct audio review.\n6\n"}, {"page": 7, "text": "4.1\nDesign Philosophy: Enabling Protocol Application\nTRIDENT’s architecture reflects a core principle: AI should empower dispatchers to apply\nestablished protocols more effectively, not replace clinical judgment. Caribbean health\nministries have adopted validated triage frameworks, ESI for emergency departments, START\nfor mass casualty incidents, that represent decades of clinical refinement. TRIDENT’s role is to\nsolve the input problem: ensuring these protocols can be applied equitably to Caribbean-accented\ncallers whose speech current ASR systems fail to transcribe accurately.\nEach architectural layer addresses a specific input challenge:\n• Layer 1 (ASR): Produces transcripts and confidence scores, enabling dispatchers to know\nwhen to trust text versus listen directly to audio.\n• Layer 2 (NLP): Extracts structured clinical entities—location, mechanism of injury,\nbreathing status, vulnerable populations—that map directly to ESI/START decision\npoints.\n• Layer 3 (Bio-Acoustic): Detects physiological distress markers that indicate caller crisis\nstate, providing a signal not currently captured by standard protocols but valuable for\nqueue prioritization.\nThe following subsections detail each layer’s implementation.\n4.2\nLayer 1: Caribbean-Tuned ASR\nThe ASR layer employs OpenAI’s Whisper Medium fine-tuned with Low-Rank Adaptation\n(LoRA) on Caribbean broadcast speech. We selected Whisper Medium over Large based on\nMadden et al.’s [11] scaling law, which demonstrates that domain-specific data yields greater\ngains than model size for Caribbean varieties. Whisper Medium is also more efficient for Rasp-\nberry Pi 5 edge deployment.\nFine-tuning Configuration:\n• Base model: openai/whisper-medium\n• Adaptation: LoRA (rank=16, alpha=32)\n• Training data: BBC Caribbean broadcast corpus (∼28,000 clips)\n• Trainable parameters: ∼0.5% of total model\nConfidence Scoring: The system computes utterance-level confidence as the mean log-\nprobability across all decoded tokens, normalized to 0-1:\nconfidence = exp\n \n1\nN\nN\nX\ni=1\nlog P(ti|t1 . . . ti−1, audio)\n!\n(1)\nWe use utterance-level rather than token-level confidence because emergency triage requires\nholistic assessment of transcription reliability. The low confidence threshold is set at 0.7 based\non initial calibration.\n4.3\nLayer 2: Local NLP Entity Extraction\nWhen ASR produces usable transcription (confidence ≥0.7), the NLP layer extracts structured\nemergency information using Llama 3 8B running locally via Ollama. The extraction schema\ntargets entity types that map directly to ESI and START triage protocol decision points.\n7\n"}, {"page": 8, "text": "4.3.1\nEntity Extraction Schema\nThe schema targets four entity categories:\n• LOCATION: Street addresses, landmarks, geographic references\n• MECHANISM/HAZARD: Emergency type (fire, flood, medical, violence, traffic)\n• CLINICAL INDICATORS: Breathing status, consciousness, bleeding, mobility\n• SCALE: Number of people involved, vulnerable populations\n4.3.2\nMapping to Triage Protocols\nTRIDENT entities support ESI and START protocol application. For ESI, extracted entities\ninform the four decision points: Point A (lifesaving intervention) captures \"not breathing,\"\n\"choking,\" \"unresponsive\"; Point B (high-risk situation) captures mechanism of injury and al-\ntered status; Point C (resource needs) uses hazard type and complexity; Point D (vital signs)\nuses reported vitals and distress indicators [6].\nFor mass casualty events using START, entities support rapid sorting: GREEN captures\n\"walking,\" \"minor injuries\"; YELLOW captures \"injured but stable,\" \"conscious\"; RED cap-\ntures \"trapped,\" \"not breathing,\" \"heavy bleeding\"; BLACK captures cessation indicators.\nProtocol\nDecision Point\nExample Extraction Target\nESI Level 1\nImmediate lifesaving in-\ntervention?\n“not breathing,” “choking,” “heavy\nbleeding,” “unresponsive”\nSTART RED\nNot walking, breathing is-\nsues\n“trapped,” “not breathing,” “unre-\nsponsive,” “heavy bleeding”\nTable 1: Example entity extraction targets supporting ESI and START protocols. Full protocol\nmappings detailed in extended version.\n4.3.3\nHandling Garbled Input\nThe NLP layer handles low-quality transcriptions through confidence-aware prompting. When\nASR confidence is below 0.7, the system instructs the LLM to mark uncertain extractions, avoid\nhallucination, prioritize location extraction, and note phonetically similar alternatives. When\nconfidence is very low (<0.4), minimal structured output is produced and the call is flagged for\nimmediate human review.\n4.3.4\nContent Indicator Scoring\nThe NLP layer computes a Content Indicator Score (Sc ∈[0, 100]) quantifying urgency\nimplied by semantic content, independent of how the caller sounds. This addresses a critical\ngap: a trained first responder may report a mass casualty event calmly, producing low bio-\nacoustic distress despite extremely urgent content. Without content analysis, such calls would\nbe deprioritized.\nRather than keyword matching, we leverage the LLM’s semantic understanding to classify\ntranscript content.\nThis approach handles Caribbean creole variants (“mi granmodda drop\ndung an she nah move” conveys the same urgency as “my grandmother collapsed and she’s not\nmoving”), negation, and indirect references.\nThe LLM outputs structured classifications:\n8\n"}, {"page": 9, "text": "{\n\"hazard_category\": \"violent_crime\" | \"medical\" | \"fire\" |\n\"flood\" | \"traffic\" | \"infrastructure\" | \"other\",\n\"life_threat_level\": \"imminent\" | \"potential\" | \"none\",\n\"vulnerable_population\": true | false,\n\"situation_status\": \"escalating\" | \"stable\" | \"resolved\",\n\"persons_affected\": <integer>\n}\nA deterministic function maps classifications to the score:\nSc = min (100, Shazard + Sthreat + Svuln + Sscale)\n(2)\nScoring components: Hazard category weights range from 30 (violent crime) to 5 (other).\nLife-threat level contributes +30 (imminent), +15 (potential), or +0 (none). Vulnerable popula-\ntion adds +15. Scale combines persons affected (+5 per person, capped at +20) and escalation\nstatus (+10 if escalating).\nExample calculations:\nTranscript\nClassification\nSc\n“Pothole on Nelson Street”\ninfrastructure, none, false, stable, 0\n10\n“House fire, spreading to neighbor’s yard”\nfire, potential, false, escalating, 0\n50\n“Pickney dem trap inna di fire”\nfire, imminent, true, stable, 2+\n80\nTable 2: Content indicator scoring via LLM classification. Semantic understanding captures ur-\ngency from Caribbean creole variants. High scores elevate queue priority; clinical triage remains\nwith dispatchers.\nThe Content Indicator Score feeds into queue prioritization (Section 4.6), ensuring seman-\ntically urgent calls reach dispatchers promptly even when vocal distress markers are absent.\nWeights are tunable parameters that should be calibrated with local emergency services to re-\nflect institutional priorities and regional hazard profiles.\n4.4\nLayer 3: Bio-Acoustic Distress Detection\nThe bio-acoustic layer operates on raw audio, independent of ASR success, extracting features\ncorrelated with psychological distress. Based on the vocal stress literature [15, 18, 19], we focus\non features that capture physiological arousal through vocal production changes.\n4.4.1\nFeature Extraction\nUsing librosa, we extract the following acoustic features:\n1. Fundamental Frequency (F0): Mean pitch extracted via autocorrelation method\n• Typical baseline: 85–180 Hz (male), 165–255 Hz (female) [16]\n• Stress indicator: Elevation above speaker baseline\n2. F0 Coefficient of Variation (CV): Pitch instability measure\n• Computed as CV = σF0/µF0\n• Normalizes for baseline differences across speakers\n• Stress indicator: CV > 0.3 suggests vocal instability\n9\n"}, {"page": 10, "text": "3. Energy (RMS amplitude): Mean intensity across utterance\n• Normalized to 0–1 scale relative to recording gain\n• Stress indicator: Elevated intensity during distress vocalizations\n4. Jitter: Cycle-to-cycle variation in F0 period\n• Relatively independent of prosodic patterns [18]\n• Pathology threshold: >1.04% [3]\n4.4.2\nDistress Score Calculation\nThe distress score combines multiple acoustic indicators into a composite metric. We weight\nfeatures according to their documented reliability and sex-independence:\nD = wpitch · P + wvar · V + wenergy · E + wjitter · J\n(3)\nwhere:\nThe pitch elevation component now uses sex-adaptive parameters:\nP = min\n\u0012\n1.0, max\n\u0012\n0,\n¯F0 −B\nR\n\u0013\u0013\n(pitch elevation)\n(4)\nwhere (B, R) adapts based on estimated speaker sex:\n(B, R) =\n(\n(120, 80)\nif ¯F0\n(init) < 165 Hz (estimated male)\n(200, 100)\notherwise (estimated female)\n(5)\nThe baseline B and range R parameters adapt based on a heuristic sex estimation from\nthe initial 3 seconds of speech.\nA male speaker at 170 Hz (stressed) now contributes P =\n(170 −120)/80 = 0.625 rather than the previous formulation’s 0.0, addressing the male pitch\npenalty.\nThe remaining components are:\nV = min\n\u0012\n1.0, CVF0\n0.5\n\u0013\n(pitch instability)\n(6)\nE = min\n\u0012\n1.0,\n¯E\n0.1\n\u0013\n(energy)\n(7)\nJ = min\n\u0012\n1.0, jitter\n0.02\n\u0013\n(perturbation)\n(8)\nThe weights reflect relative reliability from the literature:\n• wpitch = 0.30 — F0 elevation is the most consistent stress marker but is sex-dependent\n• wvar = 0.35 — F0 coefficient of variation is sex-normalized and robust\n• wenergy = 0.20 — intensity elevation accompanies distress\n• wjitter = 0.15 — perturbation measures are prosody-independent\n10\n"}, {"page": 11, "text": "4.4.3\nThreshold Classification\n• High Distress: D > 0.5\n• Low Distress: D ≤0.5\nThese thresholds are calibrated against Van Puyvelde et al.’s [18] findings on vocal markers\nin emergency versus baseline speech.\nNote on sex differences: The distress score prioritizes sex-normalized features (CV, jitter)\nover absolute F0 elevation to mitigate the substantial baseline differences between male (85–175\nHz) and female (165–270 Hz) speakers. See Section 6.1 for detailed discussion of remaining bias\nrisks.\n4.5\nThe Complementarity Principle\nThe theoretical foundation for our multi-layer design rests on what we term the Comple-\nmentarity Principle: the three signal dimensions capture distinct failure modes and urgency\nindicators that compensate for each other’s blind spots, ensuring dispatchers receive the most\ncritical calls first regardless of which individual signal might fail.\nDimension 1: Transcription Confidence. The conditions that degrade ASR perfor-\nmance (high stress, code-switching to basilect, environmental noise) are precisely the conditions\nthat often accompany genuine emergencies. Low confidence is not merely a technical limitation\nto be hidden—it correlates with caller distress and should elevate queue priority while flagging\nthe call for direct audio review.\nDimension 2:\nContent Indicators.\nSemantic analysis of transcript content captures\nurgency that vocal characteristics may miss. Trained professionals, repeat callers, and composed\nbystanders often report critical emergencies without elevated vocal stress—their calm delivery\nmasks the urgency that only content analysis reveals. When transcription confidence is high,\nextracted entities map directly to ESI/START decision points.\nDimension 3: Bio-Acoustic Distress. Vocal stress markers (elevated pitch, intensity,\ninstability) provide a parallel assessment channel that operates on raw audio, independent of\ntranscription success. A caller whose speech is entirely unintelligible to ASR will still produce\ndetectable distress signals. This dimension captures information not currently used by ESI or\nSTART protocols, representing TRIDENT’s novel contribution to dispatcher awareness.\nThis creates a robust prioritization space with complementary coverage:\nDimensional ordering. The three dimensions are evaluated in deliberate sequence: Con-\nfidence, Content, Concern. This ordering reflects operational logic: (1) Can we understand the\ncaller?—ASR confidence determines whether transcription is reliable enough for downstream\nanalysis; (2) What is being reported?—semantic content establishes the substance of the emer-\ngency; (3) How distressed does the caller sound?—bio-acoustic indicators validate and can ele-\nvate priority, but do not override content. This sequence ensures that a composed professional\nreporting a mass casualty event receives appropriate priority based on content, while a highly\ndistressed caller reporting a minor issue is not over-prioritized based on vocal expression alone.\n• High Confidence + Low Content + Low Concern: Routine call; dispatcher applies\nESI using extracted entities at normal pace\n• High Confidence + High Content + Low Concern: The composed reporter—urgent\ncontent from a calm caller requires elevated queue position; dispatcher reviews entities and\napplies ESI, likely assigning ESI-2 or ESI-3\n• High Confidence + Low Content + High Concern: Anxious caller, possibly minor\nissue—dispatcher assesses whether distress reflects emergency or anxiety\n11\n"}, {"page": 12, "text": "• High Confidence + High Content + High Concern: All signals aligned; immediate\nqueue position for rapid ESI/START application\n• Low Confidence + Low Content + Low Concern: Likely technical issue; dispatcher\nreviews audio quality before processing\n• Low Confidence + High Content + Low Concern: Garbled but fragments suggest\nurgency—elevated priority; dispatcher listens directly\n• Low Confidence + Low Content + High Concern: Distressed caller with unintelli-\ngible speech—immediate priority; dispatcher listens and applies protocol based on direct\nassessment\n• Low Confidence + High Content + High Concern: Maximum queue priority—all\nindicators suggest crisis; immediate dispatcher attention\nTwo cells represent our key insights. The High Confidence + High Content + Low\nConcern cell captures callers whose semantic content demands urgent attention despite calm\ndelivery: the trained first responder, medical professional, or composed bystander whose mea-\nsured voice belies the severity of their report. The Low Confidence + Low Content + High\nConcern cases capture the complementary pattern—callers in crisis whose speech has shifted\ntoward basilectal registers, where ASR failure combined with vocal stress becomes valuable\nprioritization information rather than system failure.\nTogether, these insights ensure that neither semantic nor paralinguistic signals alone deter-\nmine queue position—and that clinical triage decisions remain with trained dispatchers who can\nassess the full context of each call.\n4.6\nQueue Prioritization Engine\nThe Queue Prioritization Engine integrates three independent signals to determine the order\nin which calls receive dispatcher attention. Critically, this system determines queue po-\nsition, not clinical triage category. Clinical triage—assigning ESI levels 1–5 or START\ncolors (RED/YELLOW/GREEN/BLACK)—remains the responsibility of trained dispatchers\napplying Ministry of Health protocols.\nThe prioritization logic ensures that:\n1. Callers most likely to need immediate intervention reach dispatchers first\n2. Dispatchers receive structured information to support rapid protocol application\n3. Calls with unreliable transcriptions are flagged for direct audio review\n4.6.1\nThree-Dimensional Prioritization Space\nEach call is mapped to a point in prioritization space defined by:\n• Transcription Confidence (C): High (≥0.7) or Low (< 0.7)\n• Content Indicators (Sc): High (≥50) or Low (< 50)\n• Bio-Acoustic Distress (D): High (> 0.5) or Low (≤0.5)\nThe 2 × 2 × 2 combination yields eight queue priority cells, shown in Table 3.\n12\n"}, {"page": 13, "text": "Confidence\nContent\nConcern\nQueue\nDispatcher Action\nHigh\nLow\nLow\nQ5-ROUTINE\nApply ESI using extracted en-\ntities\nHigh\nHigh\nLow\nQ2-ELEVATED\nPriority review; calm reporter,\nurgent content∗\nHigh\nLow\nHigh\nQ3-MONITOR\nReview for anxiety vs.\nemer-\ngency\nHigh\nHigh\nHigh\nQ1-IMMEDIATE\nImmediate attention; apply ES-\nI/START\nLow\nLow\nLow\nQ5-REVIEW\nCheck audio quality; possible\ntechnical issue\nLow\nHigh\nLow\nQ2-ELEVATED\nListen to audio; fragments sug-\ngest urgency\nLow\nLow\nHigh\nQ1-IMMEDIATE\nPriority audio review; possible\ndialect shift†\nLow\nHigh\nHigh\nQ1-IMMEDIATE\nHighest priority; all indicators\nelevated\nTable 3: Three-dimensional queue prioritization matrix.\n∗Addresses trained responder/com-\nposed bystander scenario.\n†Preserves core insight: low ASR confidence + high vocal concern\nmay indicate stress-induced basilectal shift requiring human ears.\n4.6.2\nQueue Priority Levels\nQ1-IMMEDIATE: Top of queue. Dispatcher reviews within seconds. System flags call for\npotential crisis requiring direct audio assessment.\nQ2-ELEVATED: High priority queue. Dispatcher attention within 1–2 minutes. Extracted\nentities displayed prominently to support rapid ESI/START application.\nQ3-MONITOR: Moderate priority. May indicate anxious caller with non-urgent situation.\nDispatcher assesses and de-escalates if appropriate.\nQ5-ROUTINE: Standard queue. Extracted entities available; dispatcher applies ESI at nor-\nmal pace.\nQ5-REVIEW: Standard queue but flagged for audio quality check. May indicate technical\nissues rather than emergency content.\nNote on Q4: The current matrix does not produce a Q4 outcome.\nFuture refinement\nwith real operational data may identify scenarios warranting an intermediate priority level. A\ntheoretical case: High Confidence + Low Content + Moderate Concern (anxious caller, minor\nissue).\n4.6.3\nRelationship to Clinical Triage Protocols\nTable 4 illustrates how TRIDENT’s queue prioritization relates to—but does not replace—\nclinical triage protocols.\n4.6.4\nDispatcher Interface\nFigure 3 illustrates the dispatcher interface for a high-priority scenario. The interface presents:\n• Queue priority level with visual urgency coding\n• Transcription confidence (with recommendation to review audio if low)\n13\n"}, {"page": 14, "text": "TRIDENT\nOutput\nDispatcher Action\nProtocol Application\nQ1-\nIMMEDIATE\nImmediate audio review; assess\ncaller state\nDispatcher determines ESI-1/2\nor START-RED based on clini-\ncal assessment\nQ2-ELEVATED\nReview extracted entities; listen\nif uncertain\nDispatcher\napplies\nESI\nusing\nstructured data; may be ESI-2\nthrough ESI-4\nQ3-MONITOR\nAssess\ndistress\nsource;\nde-\nescalate if needed\nOften ESI-4/5 after dispatcher\ndetermines no emergency\nQ5-\nROUTINE/REVIEW\nProcess normally using extracted\nmetadata\nFull ESI protocol application;\ntypically ESI-3 through ESI-5\nTable 4: TRIDENT queue priority does not determine clinical triage level. Dispatchers apply\nESI or START protocols after reviewing TRIDENT’s structured outputs and/or call audio.\n• Extracted clinical entities mapped to ESI/START decision points\n• Bio-acoustic distress indicators\n• One-click access to call audio for direct assessment\nFigure 3: Dispatcher interface for a high-priority scenario (Q1-IMMEDIATE). Elevated distress\nmarkers combined with low transcription confidence trigger immediate queue placement. The\ninterface prominently recommends audio review and displays partial entity extraction with un-\ncertainty markers. The dispatcher will listen directly and apply ESI or START protocol based\non their clinical assessment.\n5\nDeployment Considerations\n5.1\nOperational Context: Supporting Protocol Application\nTRIDENT integrates with existing emergency dispatch workflows to support standardized triage\nprotocols—ESI for routine operations, START for mass casualty incidents. Day-to-day (ESI\ncontext): TRIDENT processes incoming calls to extract structured entities (location, mecha-\nnism, clinical indicators) and assigns queue priority. Dispatchers apply ESI to determine clinical\nacuity level (1–5) and appropriate response.\nMass casualty events (START context):\n14\n"}, {"page": 15, "text": "During hurricanes or earthquakes, TRIDENT’s queue prioritization manages call surges when\nvolume exceeds dispatcher capacity, enabling rapid caller sorting even when transcription qual-\nity degrades. Key principle: TRIDENT determines which calls dispatchers see first and what\nstructured information they receive; clinical triage decisions remain with trained professionals\napplying Ministry of Health protocols.\n5.2\nPrimary Deployment: Surge Queue Prioritization\nTRIDENT’s greatest value emerges during disaster surge conditions—hurricanes, earth-\nquakes, floods—when call volume exceeds dispatcher capacity and callers must wait in queue.\nTRIDENT’s processing latency (45–60 seconds on edge hardware) precludes real-time transcrip-\ntion, but surge queues provide ideal operational context.\nOperational flow:\n1. Caller dials emergency services; all dispatchers engaged\n2. Caller enters queue and hears automated message requesting description\n3. Caller provides initial statement (15–30 seconds)\n4. TRIDENT processes audio while caller waits (45–60 seconds)\n5. Queue reordered by priority (Q1-IMMEDIATE through Q5-ROUTINE)\n6. Highest-priority call routes first when dispatcher becomes available\n7. Dispatcher receives transcription, extracted entities, and distress indicators to support\nESI/START application\nWhy this context maximizes value: Calls are waiting regardless—TRIDENT uses wait\ntime productively.\nQueue prioritization ensures most critical callers reach dispatchers first.\nExtracted entities enable faster protocol application. Low ASR confidence flags alert dispatchers\nto potential dialect shift or audio quality issues before engagement.\nThis deployment model represents TRIDENT’s primary design target. Caribbean emergency\nservices face predictable annual surge events (hurricane season, June–November) where this\ncapability would directly impact response effectiveness.\n5.3\nEarly Exit for Critical Cases\nTo provide faster routing for clearly distressed callers, the system implements early exit when:\n1. High Distress + Low Confidence: If D > 0.8 and C < 0.4, route immediately to\nQ1-IMMEDIATE. This captures callers exhibiting extreme vocal stress whose speech has\nlikely shifted to basilectal registers.\n2. Extreme Distress: If D > 0.9 regardless of confidence, route to Q1-IMMEDIATE.\nUnder early exit, ASR and bio-acoustics complete in approximately 12 seconds (with bio-\nacoustic extraction parallel to transcription), reducing Time-to-Q1 from 55 seconds to 12 seconds\nfor clearly distressed callers—a critical improvement for surge queue scenarios.\n5.4\nOffline Operation\nAll components operate without internet connectivity: Whisper model weights and Llama 3\nstored locally, bio-acoustic analysis uses standard signal processing libraries, and queue logic im-\nplemented in local Python. This enables deployment at emergency coordination centers that may\nlose connectivity during disasters while maintaining local power (generator/battery backup). Of-\nfline capability ensures TRIDENT can support ESI/START protocol application precisely when\ninfrastructure degradation makes accurate call processing most difficult.\n15\n"}, {"page": 16, "text": "5.5\nIntegration with Existing Dispatch Systems\nTRIDENT operates as a pre-processing layer integrating with existing Computer-Aided Dis-\npatch (CAD) systems. The system accepts audio streams, processes them through the three-\nlayer architecture, and outputs structured data packages (queue priority, transcription with\nconfidence, extracted entities, distress indicators) to CAD systems. Dispatchers receive calls in\npriority order and apply ESI or START protocols using TRIDENT’s structured data and/or\ndirect audio review. This requires no changes to clinical protocols—only familiarization with\nTRIDENT’s output format.\n5.6\nHardware Requirements\nThe complete system deploys on Raspberry Pi 5 (8GB RAM) or equivalent edge hardware:\nComponent\nModel\nSize\nInference Speed\nASR\nWhisper Medium (INT4)\n∼400MB\n∼10s per 30s audio\nNLP\nLlama 3 8B (4-bit)\n∼4GB\n2-5 tokens/sec\nBio-acoustic\nlibrosa + numpy\n<50MB\nReal-time\nTable 5: Hardware requirements for edge deployment\nTotal system footprint: ∼4.5GB, well within Raspberry Pi 5 8GB capacity.\n6\nLimitations and Future Work\n6.1\nCurrent Limitations\nValidation gap (most critical). This paper presents an architectural framework with theo-\nretical grounding but limited empirical validation on real emergency calls. Performance claims\nare based on component evaluations and related literature rather than end-to-end system test-\ning. The three-dimensional queue prioritization matrix has not been validated against expert\ndispatcher judgments.\nProtocol integration. While TRIDENT is framed as supporting ESI and START proto-\ncols, the entity extraction schema and queue prioritization logic were developed independently of\nclinical stakeholder input. Full Ministry of Health integration requires validation that extracted\nentities map correctly to ESI decision points and that queue priorities align with operational\nworkflows.\nTraining data constraints. Caribbean emergency speech corpora do not exist. ASR fine-\ntuning was performed on broadcast speech, which differs from emergency call acoustics in noise\nprofiles, emotional content, and register distribution.\nSex differences in F0 baseline. Fundamental frequency is sexually dimorphic: male voices\ntypically range 85–175 Hz while female voices range 165–270 Hz [16, 17]. We mitigate this by\nprioritizing sex-normalized features (F0 coefficient of variation, jitter) over absolute F0 elevation\nin distress score calculation. Research confirms that stress manifests with “striking parallels\nin men and women” [13]—both sexes show increased pitch mean and variation under acute\nstress. However, residual bias risks remain: relaxed female speakers near upper baseline may\ncontribute to elevated distress scores, while stressed male speakers with naturally low F0 may not\ncontribute sufficiently. A validation study with sex-stratified analysis on Caribbean emergency\ncalls is essential to calibrate population-appropriate thresholds and confirm normalized measures\nmaintain sensitivity across demographics.\nContent indicator classification. The Content Indicator Score depends on LLM clas-\nsification quality. Caribbean creole expressions not well-represented in training data may be\n16\n"}, {"page": 17, "text": "misclassified. Empirical evaluation of classification accuracy on Caribbean transcripts is needed,\nparticularly for false negatives that could delay critical calls.\nSingle-speaker assumption. Multi-party calls are not handled. Speaker changes mid-call\ncould confuse bio-acoustic analysis and entity extraction.\nThreshold sensitivity. Multiple thresholds (ASR confidence 0.7, distress 0.5, content indi-\ncators 50) were selected based on literature but have not been rigorously optimized. Sensitivity\nanalysis examining precision-recall tradeoffs is needed.\n6.2\nFuture Work\nClinical stakeholder collaboration. Partnership with Caribbean emergency services to val-\nidate TRIDENT’s utility in real dispatch workflows, including observation studies of current\nESI/START challenges, dispatcher feedback on extracted entity usefulness, and iterative schema\nrefinement based on clinical input.\nCaribbean Emergency Speech Corpus.\nA dedicated corpus combining Caribbean-\naccented speech with emergency domain content and stress annotations is critical. We are ex-\nploring VoicefallJA, a gamified speech elicitation platform designed to collect stressed Caribbean\nspeech through game-induced cognitive load rather than acted performance. The Progressive\nWeb App targets 100–300 speakers via church network distribution, with Q2–Q3 2026 data col-\nlection. However, game-induced stress differs fundamentally from genuine emergency distress;\nthis approach should be viewed as a stepping stone toward real-call annotation under appropriate\nethical frameworks, not a replacement.\nEmpirical validation. End-to-end evaluation with emergency dispatch professionals as-\nsessing whether TRIDENT’s queue prioritization aligns with expert judgment, including sex-\nstratified analysis of bio-acoustic accuracy and entity extraction accuracy on Caribbean creole\ntranscripts.\nAblation studies. Quantifying the marginal contribution of each architectural component\n(bio-acoustic analysis, content indicators, Caribbean-tuned ASR).\nSex-adaptive distress detection. Implementing within-call F0 change detection rather\nthan absolute thresholds, and ensemble approaches combining multiple normalization strategies.\n7\nConclusion\nTRIDENT presents a dispatcher-support architecture that ensures Caribbean-accented emer-\ngency callers receive equitable access to ESI and START triage protocols. By combining accent-\nadapted speech recognition, local NLP entity extraction, and bio-acoustic distress detection, the\nsystem empowers dispatchers to apply established protocols even when automated transcription\nfails.\nThe architecture operationalizes two complementary insights established in Section 1.2: that\nASR uncertainty combined with vocal distress signals priority callers requiring human attention,\nand that calm delivery of urgent content must not delay dispatcher response. These insights\ndrive the three-dimensional queue prioritization matrix that routes calls based on confidence,\ncontent, and concern signals.\nCritically, TRIDENT respects the clinical authority of established protocols. The system\ndetermines which calls dispatchers see first and provides structured information to support\nrapid protocol application—but triage decisions remain with trained human professionals. This\ndesign philosophy reflects a broader principle for emergency AI: technology should empower\nhuman expertise, not attempt to replace it.\nWe hope this architectural framework contributes to more equitable emergency services—not\njust for Caribbean populations, but for the billions of speakers worldwide whose accents and\n17\n"}, {"page": 18, "text": "dialects remain underserved by current speech technology. When a caller dials for help, the\nsystem that answers should understand them. TRIDENT is a step toward that goal.\nReferences\n[1] Afraa Attiah and Manal Kalkatawi. AI-powered smart emergency services support for 9-1-1\ncall handlers using textual features and svm model for digital health optimization. Frontiers\nin Big Data, 8:1594062, 2025.\n[2] Stig Nikolaj Blomberg et al. Machine learning as a supportive tool to recognize cardiac\narrest in emergency calls. Resuscitation, 138:322–329, 2019.\n[3] Paul Boersma and David Weenink. Praat: doing phonetics by computer, 2013. Version\n5.3.51.\n[4] Marcel Lucas Chee, Mark Leonard Chee, Haotian Huang, Katelyn Mazzochi, Kieran Taylor,\nHan Wang, Mengling Feng, Andrew Fu Wah Ho, Fahad Javaid Siddiqui, Marcus Eng Hock\nOng, Nan Liu, et al. Artificial intelligence and machine learning in prehospital emergency\ncare: A scoping review. iScience, 26(8):107407, 2023.\n[5] Théo Deschamps-Berger, Lori Lamel, and Laurence Devillers. End-to-end speech emotion\nrecognition: Challenges of real-life emergency call centers data recordings. In Proceedings of\nthe 9th International Conference on Affective Computing and Intelligent Interaction (ACII),\npages 1–8, 2021.\n[6] Emergency Nurses Association. Emergency Severity Index (ESI): A Triage Tool for Emer-\ngency Departments, Version 5.\nEmergency Nurses Association, Schaumburg, IL, 2020.\nAvailable at https://www.ena.org/practice-resources/resource-library/esi.\n[7] Simone French, Georgiana Gordon-Strachan, Kevon Kerr, Jacquiline Bisasor-McKenzie,\nLambert Innis, and Paula Tanabe. Assessment of interrater reliability of the emergency\nseverity index after implementation in emergency departments in jamaica using a learning\ncollaborative approach. Journal of Emergency Nursing, 46(6):875–882, 2020.\n[8] Tamar H. Gollan and Victor S. Ferreira. Should I stay or should I switch? A cost-benefit\nanalysis of voluntary language switching in young and aging bilinguals. Journal of Experi-\nmental Psychology: Learning, Memory, and Cognition, 35(3):640–665, 2009.\n[9] David W. Green. Mental control of the bilingual lexico-semantic system. Bilingualism:\nLanguage and Cognition, 1(2):67–81, 1998.\n[10] Allison Koenecke et al. Racial disparities in automated speech recognition. Proceedings of\nthe National Academy of Sciences, 117(14):7684–7689, 2020.\n[11] Jordan Madden, Matthew Stone, Dimitri Johnson, and Daniel Geddez.\nTowards\nrobust speech recognition for Jamaican Patois music transcription.\narXiv preprint\narXiv:2507.16834, 2025.\n[12] Peter L. Patrick.\nUrban Jamaican Creole: Variation in the Mesolect.\nJohn Benjamins\nPublishing, Amsterdam, 1999.\n[13] Katarzyna Pisanski, Joanna Nowak, and Piotr Sorokowski. Multimodal stress detection:\nTesting for covariation in vocal, hormonal and physiological responses to Trier Social Stress\nTest. Hormones and Behavior, 106:52–61, 2018.\n18\n"}, {"page": 19, "text": "[14] Carlos Santos-Burgoa, John Sandberg, Erick Suárez, Ann Goldman-Hawes, Scott Zeger,\nAlejandra Garcia-Meza, Cynthia M. Pérez, Kenneth Rivera, Adriana Colón Ramos, Jose\nFigueroa, et al. Differential and persistent risk of excess mortality from hurricane maria in\npuerto rico: A time-series analysis. The Lancet Planetary Health, 2(11):e478–e488, 2018.\n[15] Lilien Schewski, Mathew Magimai Doss, Guido Beldi, and Sandra Keller. Measuring nega-\ntive emotions and stress through acoustic correlates in speech: A systematic review. PLOS\nONE, 20(7):e0328833, 2025.\n[16] Ingo R. Titze. Physiologic and acoustic differences between male and female voices. Journal\nof the Acoustical Society of America, 85(4):1699–1707, 1989.\n[17] Hartmut Traunmüller and Anders Eriksson. The frequency range of the voice fundamental\nin the speech of male and female adults. Journal of the Acoustical Society of America,\n97(4):2634–2639, 1995.\n[18] Martine Van Puyvelde, Xavier Neyt, Francis McGlone, and Nathalie Pattyn. Voice stress\nanalysis: A new framework for voice and effort in human performance. Frontiers in Psy-\nchology, 9:1994, 2018.\n[19] André Veiga et al. The fundamental frequency of voice as a potential stress biomarker: A\nsystematic review and meta-analysis. Stress and Health, 2025.\nA\nImplementation Details\nRepository: https://github.com/smg-labs/project-filter (to be made public upon\nacceptance)\nDependencies:\n• Python 3.11+\n• openai-whisper\n• transformers, peft (LoRA fine-tuning)\n• ollama (Llama 3 serving)\n• librosa (audio feature extraction)\n• jiwer (WER evaluation)\nHardware requirements:\n• Training: NVIDIA GPU with 16GB+ VRAM recommended\n• Inference: CPU-only operation supported; 8GB RAM minimum\nB\nAcknowledgments\nThis work emerged from the Caribbean Voices AI Hackathon, organized by the UWI AI In-\nnovation Centre and hosted on Zindi. We thank sponsors CIBC, Infolytics, and DataAxis for\ntheir support. The competition’s BBC Caribbean speech corpus motivated this architectural\nframework. We also thank Dr. Sikopo Nyambe-Galbraith for feedback on the research.\nWe also acknowledge the use of Google’s Gemini 3.0 Pro when brainstorming the ideas for\nthe paper, conducting deep research, and the generation of the figures in this paper. Anthropic’s\nClaude Opus 4.5 was used for the editing and proofreading of the paper.\n19\n"}]}