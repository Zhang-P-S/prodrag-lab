{"doc_id": "arxiv:2601.13690", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2601.13690.pdf", "meta": {"doc_id": "arxiv:2601.13690", "source": "arxiv", "arxiv_id": "2601.13690", "title": "Dr. Assistant: Enhancing Clinical Diagnostic Inquiry via Structured Diagnostic Reasoning Data and Reinforcement Learning", "authors": ["Yue Guo", "Fanfu Wang", "Jianwei Lv", "Xincheng Shi", "Yuchen Li", "Youya Wang", "Yunsheng Zeng", "Yujing Liu", "Yunhao Qiao", "Gen Li", "Junfeng Wang", "Bo Yuan"], "published": "2026-01-20T07:43:57Z", "updated": "2026-01-20T07:43:57Z", "summary": "Clinical Decision Support Systems (CDSSs) provide reasoning and inquiry guidance for physicians, yet they face notable challenges, including high maintenance costs and low generalization capability. Recently, Large Language Models (LLMs) have been widely adopted in healthcare due to their extensive knowledge reserves, retrieval, and communication capabilities. While LLMs show promise and excel at medical benchmarks, their diagnostic reasoning and inquiry skills are constrained. To mitigate this issue, we propose (1) Clinical Diagnostic Reasoning Data (CDRD) structure to capture abstract clinical reasoning logic, and a pipeline for its construction, and (2) the Dr. Assistant, a clinical diagnostic model equipped with clinical reasoning and inquiry skills. Its training involves a two-stage process: SFT, followed by RL with a tailored reward function. We also introduce a benchmark to evaluate both diagnostic reasoning and inquiry. Our experiments demonstrate that the Dr. Assistant outperforms open-source models and achieves competitive performance to closed-source models, providing an effective solution for clinical diagnostic inquiry guidance.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2601.13690v1", "url_pdf": "https://arxiv.org/pdf/2601.13690.pdf", "meta_path": "data/raw/arxiv/meta/2601.13690.json", "sha256": "f7cd9ba53ea04b1f4975494e3bb9c65150a704e85221ba1b8d2d90a82e761e2d", "status": "ok", "fetched_at": "2026-02-18T02:20:59.921222+00:00"}, "pages": [{"page": 1, "text": "Dr. Assistant: Enhancing Clinical Diagnostic Inquiry via Structured\nDiagnostic Reasoning Data and Reinforcement Learning\nYue Guo*1, Fanfu Wang1, Jianwei Lv*1, Xincheng Shi1, Yuchen Li1, Yunsheng Zeng1, Youya\nWang1, Yujing Liu1, Yunhao Qiao1, Gen Li1, Junfeng Wang*1, Bo Yuan*†1\n1Baidu Inc.\nAbstract\nClinical Decision Support Systems (CDSSs)\nprovide reasoning and inquiry guidance for\nphysicians, yet they face notable challenges, in-\ncluding high maintenance costs and low gener-\nalization capability. Recently, Large Language\nModels (LLMs) have been widely adopted in\nhealthcare due to their extensive knowledge\nreserves, retrieval, and communication capa-\nbilities. While LLMs show promise and ex-\ncel at medical benchmarks, their diagnostic\nreasoning and inquiry skills are constrained.\nTo mitigate this issue, we propose (1) Clini-\ncal Diagnostic Reasoning Data (CDRD) struc-\nture to capture abstract clinical reasoning logic,\nand a pipeline for its construction, and (2)\nthe Dr. Assistant, a clinical diagnostic model\nequipped with clinical reasoning and inquiry\nskills.\nIts training involves a two-stage pro-\ncess: SFT, followed by RL with a tailored re-\nward function. We also introduce a benchmark\nto evaluate both diagnostic reasoning and in-\nquiry. Our experiments demonstrate that the\nDr. Assistant outperforms open-source mod-\nels and achieves competitive performance to\nclosed-source models, providing an effective\nsolution for clinical diagnostic inquiry guid-\nance.\n1\nIntroduction\nClinical Decision Support Systems (CDSSs) assist\nphysicians by providing guidance for clinical in-\nquiries, which is especially valuable for less ex-\nperienced physicians (Bright et al., 2012; Sutton\net al., 2020; Berner and La Lande, 2016). How-\never, traditional CDSSs rely on structured knowl-\nedge bases and rule-based algorithms, which incur\nhigh development and maintenance costs and have\nlimited adaptability to complex clinical situations\n(Sheikhalishahi et al., 2019; Deo, 2015).\n* Project leader: {guoyue07,lvjianwei,wangjunfeng,\nyuanbo07}@baidu.com\n†Corresponding author: yuanbo07@baidu.com\nRecently,\nLarge Language Models (LLMs)\nhave achieved remarkable success in knowledge-\nintensive tasks, spanning legal document analysis\n(Arfat et al., 2024; Janatian et al., 2023), finan-\ncial forecasting (Wu et al., 2024; Xie et al., 2023)\nand education (Kasneci et al., 2023; Wang et al.,\n2024a), due to their superior comprehension and\ngeneralization abilities. This progress has spurred\ntheir adoption in healthcare (Dou et al., 2025;\nKopka et al., 2025).\nBaichuan-M2 (Dou et al.,\n2025) and HuatuoGPT-o1 (Chen et al., 2024) focus\non patients’ consultation experience and decision-\nmaking. Zhongjing (Yang et al., 2024) prioritizes\nmedical knowledge integration and records analy-\nsis. Current LLMs perform well in general health-\ncare consultation but are limited in clinical inquiry\nas shown in Figure 1 (b), which requires rigorous\ndiagnostic reasoning.\nClinical guidelines contain diagnostic reasoning\nlogic, yet they face two primary limitations. 1)\nScattered Reasoning Logic: The diagnostic rea-\nsoning logic cue for a given symptom is often scat-\ntered across different chapters, as shown in Figure\n2, and 2) Diﬀiculty in Training: Even with high-\nquality data, training models to master clinical in-\nquiry skills remains a significant challenge.\nTo\naddress\nthese\nchallenges,\nwe\npropose\nClinical Diagnostic Reasoning Data (CDRD)\nformat to capture abstract diagnostic reasoning\nlogic.\nEach CDRD is a triple-tuple, including\na core symptom, diagnostic evidence and differ-\nential diagnoses. We also propose a three-stage\npipeline for constructing CDRDs.\nThe pipeline\ncollaboratively\nemploys\nLLM\nsynthesis\nand\nphysician refinement based on clinical guidelines.\nIt first extracts symptoms (Stage I) and their\ncorresponding diseases (Stage II) and finally\ncompletes CDRD (Stage III). To ensure reliability,\noutputs at every stage are reviewed and refined\nby professional physicians.\nFurthermore, using\nCDRD as a seed, we synthesize two types of data:\narXiv:2601.13690v1  [cs.CL]  20 Jan 2026\n"}, {"page": 2, "text": "Diagnostic hypotheses: Functional Dyspepsia \nInquiry: Lying down right after meals may worsen acid reflux. Stay \nseated for 30 minutes post-meal. Try soda crackers to neutralize \nstomach acid. Adjust diet and re-evaluate if symptoms persist.\nDiagnostic hypotheses: Acute Gastroenteritis\nInquiry: Continue bland diet; eat 6 small meals daily. Consider \nshort-term H2 blocker if reflux persists (consult pharmacist). Report \nnight reflux or heartburn? Return if no improvement in 2 weeks.\nDiagnostic hypotheses: GERD / Gastritis\nInquiry: Take omeprazole as directed before meals. Avoid trigger \nfoods; eat small, frequent meals and do not lie down within 2 hours \nafter eating. Do you have bloating severity and any link between \nreflux and stress/anxiety?\n \n(a) Reasoning-inquiry loop \n(b) Guidance from Dr. Assistant and others \nHypotheses biased. \nTreatment advice in inquiry \nis inappropriate.\nHypotheses biased. \nInquiry did not consider \nreflux related causes.\nTake omeprazole before meals. \nEat small, avoid triggers and \nreport bloating and stress links.\nreasoning\ninquiry\nDiagnostic hypotheses: A, B, C. \nRequires continued inquiry \nfor differentiation. \nGood hypotheses.\nInquiry demonstrates logical \ndiagnostic reasoning.\nSuccess & is refered\nI get heartburn after meals, with some \nnausea and little appetite, and...\nA gastritis patient\nrefer\nDr. Assistant\nBaichuan-M2\nDoctor-R1\nFigure 1: Dr. Assistant provides guidance (b) to physicians in the reasoning-inquiry loop (a), where diagnostic\nhypotheses both drive and are refined by ongoing inquiry. Since diagnostic hypotheses are central to reasoning,\nthey are our primary focus. We detail (a) in Appendix B.1.\nSymptoms: Fever\nChapter 1\n ...\nCommon Cold is primarily caused by ... It may be accompanied by sore \nthroat, ear fullness, hoarseness, etc. Fever is usually absent or low-grade, ... \nInfluenza (Flu) is caused by influenza viruses, ... dominated by systemic \ntoxic symptoms (chills / rigors, fever, generalized myalgia, etc.), ...\nChapter 2\n ... \nIt is an acute inflammation of the tracheal-bronchial mucosa caused by \ninfection (viral / bacterial), ... Other pathogens: Mycoplasma pneumoniae \nand Chlamydia are also relatively common ... When systemic symptoms \nsuch as fever, headache, and generalized soreness are significant ...\nChapter n\n ...\nPulmonary Tuberculosis: Patients may present with tuberculous toxic \nsymptoms such as low-grade fever, fatigue, and night sweats. \nMycobacterium tuberculosis may be detected in sputum examination ...\n e.g.: Differential diagnoses info. of fever are scattered across chapters.\nFigure 2: The scattered logic in clinical guideline.\nQuestion-Answer pairs (QA data) for Supervised\nFine-Tuning (SFT), and clinical inquiry dialogue\nfor Reinforcement Learning (RL).\nWe also propose Dr. Assistant, a clinical diag-\nnostic model equipped with inherent clinical rea-\nsoning & inquiry skills. Its training consists of two\nstages: 1) The model remembers preliminary clin-\nical inquiry reasoning logic via SFT. 2) We design\na reward function, which encompasses two core\nevaluation dimensions via RL: Clinical Reasoning\nand Inquiry Skills, and Fidelity to CDRD (logical\ndifferences from CDRD). The logical differences\npenalty term (Fidelity to CDRD) is incorporated to\nconstrain illogical inference behaviors, refining the\nmodel’s clinical reasoning competencies. Further-\nmore, we construct a benchmark to evaluate clini-\ncal diagnostic reasoning and inquiry skills. It com-\nprises 242 real clinical cases covering 8 secondary\ndepartments, and 147 real clinical inquiry rounds\ncovering 4 secondary departments.\nThe experimental results demonstrate that Dr.\nAssistant (14 B) outperforms the open-source\nmodel HuatuoGPT-o1-72B with a 13.59% im-\nprovement in ICD-Recall, and achieves compara-\nble performance to GPT-5, which provides an ef-\nfective solution for the practical implementation of\nclinical decision support systems.\nIn summary, our contributions are as follows:\n• We propose Clinical Diagnostic Reasoning\nData (CDRD) structure to capture abstract\nclinical reasoning logic, and a pipeline for\nconstructing it.\n• We propose the Dr. Assistant, a clinical diag-\nnostic model equipped with clinical reasoning\nand inquiry skills. Its training involves a two-\nstage process: SFT, followed by RL with a tai-\nlored reward function to improve the model’s\nclinical reasoning and inquiry skills.\n• We construct a clinical diagnostic reason-\ning & inquiry benchmark consisting of 242\nreal cases across 8 secondary departments,\nalong with 147 real inquiry turns across 4\nsecondary departments.\nThe experiments\ndemonstrate Dr.\nAssistant outperforms the\nopen-source model HuatuoGPT-o1-72B, with\na 13.59% improvement in ICD-Recall rate,\nand achieves comparable performance to\nGPT-5.\n2\nRelated Work\nLLMs for medical consultation.\nPrevious ap-\nproaches primarily rely on SFT to improve med-\nical knowledge coverage (Ma et al., 2025).\nRe-\ncent studies incorporate RL to optimize multi-turn\nconsultation strategies, such as Baichuan-M2 (Dou\net al., 2025), HuatuoGPT-o1 (Chen et al., 2024)\nand Doctor-R1 (Lai et al., 2025b), which focus on\nimproving patients’ consultation experience. They\nare optimized for general conversation, lacking\n"}, {"page": 3, "text": "Fever\nCough\nRash\nStubborn\nDizziness\nFever\nCough\nRash\nDizziness\nFlu\nAsthma\nBronchitis\nAllergy\nMeasles\nAnemia\nAllergy\nMigraine\nGastritis\nMalaria\nPneumonia\nFracture\nStage 1: Symptom Extraction\nStage 2: Disease Matching\nStage 3: Logic Completion\n(b) Diagnosis QA pairs \nrefer\nrefer\nPhysician agent\n(c) Clinical inquiry\n{continue......}\n:  How long has the cough lasted? ... Any other \nsymptoms such as ...runny nose, or itchy throat?\n: Hello doctor, my child has a recurrent dry \ncough. Previous tests came back normal.\n   : He has been coughing for nearly two months,...  \nbut his throat keeps itchy.\n   : Any history of allergies, such as rhinitis, eczema, \nor asthma?\n{continue......}\nPatient agent\n         No obvious cough. Inquire details: dry / \nproductive cough, duration (days / months / years; \nexacerbation period), cough characteristics (hoarse / \ncrowing / weak), and sputum properties. \nsegment into pieces \ngenerate Question      for Answer \n       The patient presents with acute chest \npain and dyspnea, accompanied by an elevated \nD-dimer. What is the most likely diagnosis?\n(a) Clinical Diagnostic Reasoning Data\nraw           refined   \nQuestion：\nAnswer：\nraw           refined   \nraw           refined   \n: Medical case, Personality (anonymized)\n \n   \nSFT\nRL\nClinical Reasoning and Inquiry Skills\nFidelity to CDRD\n+10\n- 2\n-3\n  \n \nQuestion\nAnswer\n \nPatient: Hi, I have acid reflux and a little bitter taste.\nDoctor: Hello. How long has it been going on?\nPatient: It might be related to my recent medication.\nReasoning: ... GERD vs. medication side effect. Need to rule out other causes ...\nInquiry: What medication you're currently taking? Also, describe your acid reflux and bitter taste \n... If there are other symptoms and any history of stomach, gallbladder, or liver issues?\n(d) Dr. Assistant training pipeline\nFigure 3: Our workflow involves CDRD construction (a), data synthesis (b, c), and Dr. Assistant training (d).\nclinical diagnostic inquiry and reasoning skills.\nThis leads to clinically unsupported guidance.\nCDSSs. Clinical guidelines served as the founda-\ntion of traditional CDSSs (Berner and La Lande,\n2016; Sutton et al., 2020). While rule-based sys-\ntems provide strong interpretability, they are diffi-\ncult to scale and adapt to flexible, multi-turn clini-\ncal inquiry. Recent efforts have explored integrat-\ning structured medical knowledge with neural mod-\nels (Sheikhalishahi et al., 2019), yet not diagnostic\ninquiry logic training.\nEvaluation of medical consultation. Evaluations\nfor Medical LLMs evolved from static question-\nanswer (Jin et al., 2021a; Pal et al., 2022; Jin\net al., 2019) to general consultation, such as Health-\nBench (Arora et al., 2025), MAQuE (Gong et al.,\n2025), GAPS (Chen et al., 2025) and SPTesting\n(Dou et al., 2024). While existing benchmarks fea-\nture multi-turn consultation, they frequently fail to\ncapture the realistic demands of clinical diagnostic\ninquiry in CDSS settings. In this work, we evaluate\nmodels’ reasoning soundness and inquiry quality\nwith real and dynamic clinical inquiry cases.\n3\nData Construction\n3.1\nCDRD Format for Abstract Logic\nClinical guidelines contain abstract diagnostic rea-\nsoning logic and it is scattered across chapters,\nrequiring semantic understanding and re-structure\n(Zhang et al.). To capture abstract diagnostic rea-\nsoning logic that proceeds from a symptom to\nits differentials in clinical inquiry, we structure it\nas Clinical Diagnostic Reasoning Data (CDRD).\nFormally, each CDRD is defined as a triple-tuple\nC = (S, E, D), representing the standard diagnos-\ntic logic, where:\n• S: A Core Symptom (e.g., headache) of pa-\ntient.\n• E: Diagnostic Evidence. The clinical infor-\nmation, including associated symptoms, lab\nresults, and exam findings, that physicians col-\nlect and analyze to infer diagnoses.\n• D: Differential Diagnoses, the list of poten-\ntial diseases (e.g., gastroenteritis) should be\nconsidered based on the available evidence,\nalong with their clinical manifestations and re-\nquired diagnostic examinations.\n"}, {"page": 4, "text": "Please refer to Appendix §G.1 for the CDRD\ndemo.\n3.2\nCDRD Construction Pipeline\nTo maximize the completeness and purity of\nCDRD, we propose a pipeline for constructing it\nfrom clinical guidelines. As shown in Figure 3 (a),\nCDRD construction pipeline is a collaborative ap-\nproach of LLM synthesis and physician refinement,\nencompassing three sequential stages: symptom\nextraction, disease matching and logic completion.\nSymptom extraction. Given a clinical guideline\ng, we first extract the symptoms set S. The LLM\nidentifies candidate symptoms, which are then re-\nfined by physicians:\nS = H\n(\nLLM(g) | g\n)\n,\n(1)\nwhere H(.) is defined as physicians’ refinement,\nwhich ensures symptoms are standard (e.g., map-\nping “chest hurt” to standardized “chest pain” or\n“angina”).\nDisease matching.\nConditioned on the refined\nsymptom set S and the clinical guideline g, LLM\ngenerates a list of differential diagnoses to every\nsingle symptom S. The physician then refines this\nlist against guidelines:\nD′ =\n∪\nS∈S\nH\n(\nLLM(g, S) | g, S\n)\n,\n(2)\nwhere D′ is a set that includes disease name list\nfor each S. By decoupling disease matching from\nsymptom extraction, we allow physicians to eval-\nuate the validity of each symptom-disease correla-\ntion.\nLogic completion. Based on symptom-diseases\npairs (i.e., a core symptom S paired with its dif-\nferentials’ name list D′) and clinical guideline g,\nLLM extracts clinical evidence E set and com-\npletes differential diagnoses D set to complete\nCDRD set of g. For each symptom-disease pair:\nE, D = H\n(\nLLM(g, (S, D′)) | g, (S, D′)\n)\n.\n(3)\nHere, we get the full reasoning data CDRD:\nC = (S, E, D).\n(4)\nSee prompts for the three stages in Appendix §E.1.\nWhile CDRD captures high-quality diagnostic\nreasoning logic, it suffers from limited scale and\nlacks dynamic, multi-turn clinical settings. To en-\nable models not only to learn this logic but also\nto apply it flexibly, we construct Question-Answer\ndata for SFT and multi-turn inquiry data for RL\nbased on CDRD as shown in Figure 3 (b, c) sep-\narately.\n3.3\nQA Pair for SFT\nWe use CDRD as a seed to construct QA dataset\nP SFT via a two-step process: (i) answer formula-\ntion , based on CDRD, and (ii) question synthesis,\nbased on the answer.\nAnswer formulation. We first parse CDRDs into\ndiscrete entries e, where e is a partial segment from\neither E or D in a CDRD. Each entry e is seman-\ntically complete. To increase expression diversity,\nwe rewrite each entry e into a fluent response A\nusing LLM:\nA = LLM\n(\ne\n)\n.\n(5)\nQuestion synthesis. For each answer A, we syn-\nthesize a corresponding question Q to form a com-\nplete QA pair:\nQ = LLM\n(\nA\n)\n.\n(6)\nThese operations are applied to the entire CDRD,\nyielding the final SFT dataset P SFT = {(Q, A)}.\nRefer to Appendix §E.3 for its synthesis prompts.\n3.4\nMulti-turn Inquiry for RL\nWhile QA data instill diagnostic reasoning logic,\nclinical inquiry skills are not covered. So we pro-\npose a dual-agent comprising a physician agent\nπphy and a patient agent πpat, which takes iterative\ninteractions to synthesize reasoning and inquiries\nbased on patient profiles R and CDRDs C.\nSpecifically, an inquiry dialogue starts with the\nmain complaints specified in R, and πphy generates\nreasoning and inquiry referring to C. We structure\nthe reasoning and inquiry to a template. It consists\nof six reasoning steps and the final inquiry (See\nAppendix §G.2 and §E.2, for reasoning-inquiry de-\nmos and their synthesis prompts, separately):\nKnown Information: The patient’s information\nsummary from history dialogue.\nUser’s Intention: Intentions underlying the query.\nProvided Information: Expressed inquiry sum-\nmary.\nDiagnoses:\nBased on the inquiry history, the\nmodel generates initial diagnostic hypotheses.\nInformation to be Collected:\nClinical infor-\nmation required to clarify diagnoses and guide\ndecision-making.\n"}, {"page": 5, "text": "Response Strategy: Before inquiry, model rea-\nsons the most necessary information to acquire.\nInquiry: Diagnoses or follow-up questions that\nmodel presents.\nActually, an inquiry dialogue can be seen as a\nparticular trajectory τ sampled from the CDRD C,\ninfluenced by patient’s constraints in R:\nτ = (p1, d1, p2, d2, . . . , pk, dk | C, R),\n(7)\nwhere pk represents the πpat’s query, and dk is the\nπphy’s reasoning and inquiry at round k.\n4\nDr. Assistant\nDr. Assistant’s training pipeline consists of two\nstages, as shown in Figure 3 (d): Supervised Fine-\nTuning (SFT), which equips the model with prelim-\ninary clinical diagnostic reasoning logic, and Rein-\nforcement Learning (RL), which further enhances\nthe model’s clinical diagnostic inquiry skills.\nSFT with P SFT.\nOur model πθ is first fine-tuned\nvia supervised learning on P SFT to acquire basic di-\nagnostic reasoning logic, optimized with the stan-\ndard negative log-likelihood loss:\nLSFT = −E(q,a)∼P SFT\n[ T\n∑\nt=1\nlog πθ\n(\nat | q, a<t\n)\n]\n.\n(8)\nRL with multi-turn inquiry.\nAlthough model\nlearned clinical diagnostic reasoning logic in SFT,\nits responses are confined to single, static QA pat-\ntern, and have limited clinical reasoning and in-\nquiry skills. So we conduct Reinforcement Learn-\ning on inquiry dataset {τ}, enhancing the model\nwith clinical diagnostic reasoning and inquiry.\nSpecifically, we design a composite reward func-\ntion. Given a ground-truth reasoning and inquiry\ndt at round t of an inquiry dialogue τ and the\ntrained model’s response ˆdt, the step-wise reward\nis defined as:\nRstep( ˆdt, dt, C) = Rcomp( ˆdt, dt) −Rdiv( ˆdt, C).\n(9)\nHere, Rcomp measures: clinical reasoning Rcomp-r,\nand inquiry skills Rcomp-i, while Rdiv constraints\nfidelity to CDRD.\na. Clinical reasoning and inquiry skills. Rcomp\nevaluates the model’s performance by scoring\nthe similarity ri between its output and the\nground‑truth across seven parts related to diagnos-\ntic reasoning and inquiry: 1) Reasoning list rreason\nincluding Known Information r0, User Intention\nr1, Provided Information r2, Diagnoses r3, Infor-\nmation to be Collected r4 and Response Strategy\nr5, 2) Inquiry list rinquiry including the final inquiry\nr6. Definitions of the seven parts are in §3.4.\nri is scored by another LLM-judge, ranging\nfrom 0 to 10. A higher alignment with the ground-\ntruth yields a higher score. Rcomp is derived as:\nRcomp(dt, τ) = Rcomp-r + Rcomp-i\n= w⊤\nreasonrreason + w⊤\ninquiryrinquiry,\n(10)\nwhere rreason = [r0, . . . , r5]⊤is the score vector\nfor diagnostic reasoning items, wreason and winquiry\nare weight coefficients, set according to the relative\nimportance of each dimension in clinical decision-\nmaking. See Appendix §A for parameter settings.\nb. Fidelity to CDRD. Rdiv penalizes deviations\nfrom the source CDRD (i.e., the specific CDRD\nused to generate the ground-truth trajectory τ that\nserves as the target in this optimization step):\nRdiv(dt, C) = λn,\n(11)\nwhere λ is the weight coefficient and n is the num-\nber of already collected information (or yet to be\ncollected) and diagnoses that are not in CDRD, de-\ntermined by LLM-judge.\nWe employ DAPO (Yu et al., 2025), which sam-\nples output group {oi}G\ni=1 for each prompt and op-\ntimizes the model πθ by the following objective:\nJDAPO(θ) = E\n[\n1\n∑G\ni=1 |oi|\nG\n∑\ni=1\n|oi|\n∑\nt=1\nmin\n(\nri,t(θ) ˆAi,t,\nclip(ri,t(θ), 1 −ϵlow, 1 + ϵhigh) ˆAi,t\n)]\n,\n(12)\nwhere ri,t(θ) =\nπθ(oi,t|q,oi,<t)\nπold(oi,t|q,oi,<t)) is the probability\nratio and oi is the length of trajectory τi.\nˆAi,t =\nRi−mean({Ri}G\ni=1)\nstd({Ri}G\ni=1)\n, is advantage of the i-th response\nis calculated by normalizing the group-level re-\nwards {Ri}G\ni=1.\n5\nExperiments\n5.1\nExperimental Settings\nModel and baselines.\nOur Dr.\nAssistant is\ntrained on Qwen3-14B (Team, 2025). We com-\npare it against: 1) Open-source Models: includ-\ning general-purpose LLMs: Qwen3-32B (Team,\n"}, {"page": 6, "text": "2025) , DeepSeek-R1-Distill-14B (DeepSeek-AI,\n2025a), Baichuan-M2-32B (Dou et al., 2025),\nLlama3-OpenBioLLM-70B (Ankit Pal, 2024) and\nmedical-specialized LLMs (HuatuoGPT-o1-72B\n(Chen et al., 2024) , Doctor-R1-8B (Lai et al.,\n2025c), Med42-v2-8B (Christophe et al., 2024). 2)\nClosed-source Models: This includes leading pro-\nprietary models: GPT-5 (OpenAI, 2025) , Gem-\nini 2.5 Pro (DeepMind, 2025b), Gemini 2.5 Flash\n(DeepMind, 2025a) and Grok 4 Fast (xAI, 2025).\nDetails of parameter settings are in Appendix §A.\nTraining datasets. We construct 11 CDRD cover-\ning ∼60 diseases based on internal guidelines for\ntraining. For each CDRD, 400 QA pairs are syn-\nthesized, totaling 4400 data for SFT. Additionally,\nwe construct 36688 turns of multi-turn inquiry di-\nalogues for RL. All training data is in Chinese.\nEvaluation. Existing benchmarks, such as Health-\nBench (Arora et al., 2025) and MAQuE (Xie et al.,\n2023), do not concentrate on dynamic clinical di-\nagnostic inquiry reasoning. HealthBench contains\ngeneral medical consultations, most of which are\nnot multi-turn dialogues. MAQuE does not con-\nsider the mutual influence between the diagnos-\ntic inquiry process and the final diagnoses. How-\never, inspired by these evaluations (Dou et al.,\n2024; Arora et al., 2025; Xie et al., 2023), we\nconstruct a benchmark for clinical diagnostic in-\nquiry. It considered the dynamic interaction and\ninfluence between the inquiry process and final\ndiagnoses, which encompasses 242 patient pro-\nfiles (cases) across nine sub-departments, includ-\ning neurology, and 147 rounds of clinical inquiry\ndialogue records, as shown in Figure 4. See demos\nin Appendix §G.4 and §G.5.\nWe evaluate the model via both ICD-10 (Hirsch\net al., 2016) matching for diagnostic reasoning\nand physician satisfaction for inquiry.\n5.2\nICD Matching for Diagnostic Reasoning\nSince diagnostic hypotheses in reasoning directly\ndetermine inquiry direction, as shown in Figure\n1 (a), we design an evaluation where one model,\nacting as a patient based on a given patient pro-\nfile, interacts with the model-under-test (physician\nmodel). In each turn, the physician model outputs\ndiagnostic hypotheses (the core reasoning) and in-\nquiry. We compare diagnostic hypotheses at round\nfive, with GT in the patient profile, to assess the\nmodel’s diagnostic reasoning ability and inquiry\ndirection. For further details, see Appendix §B.2.\nPatient profiles in bench are different from those in\nGastroenterology\n40.08%\nRespiratory Medicine\n15.70%\nNeurology\n13.22%\nCardiology\n9.92%\nNephrology\n7.44%\nEndocrinology\n6.61%\nRheumatology\n2.89%\nInfectious \nDiseases…\nHematology\n1.24%\n(a) Patient profiles distribution in bench \nGastroenterology\n31.29%\nRespiratory \nMedicine\n17.01%\nRheumatology\n2.72%\nGeneral Internal \nMedicine \n48.98%\n(b) Clinical inquiry distribution in bench \nFigure 4: Data distribution of our benchmark. One in-\ncludes 242 patient profiles across 7 sub-departments (a).\nThe other includes 147 rounds of clinical inquiry dia-\nlogues (b). “General Internal Medicine” means the in-\nquiries cover multiple sub-departments.\n§3.4.\nICD-10 matching.\nWe map the diagnostic hy-\npotheses of both model and GT to ICD-10 (Inter-\nnational Classification of Diseases) (Hirsch et al.,\n2016) codes, P and G respectively by LLM. We\nthen calculate their similarity as formalized in Ap-\npendix Algorithm 1. In clinical practice, the ICD-\nRecall of diagnostic hypotheses is positively corre-\nlated with the reasoning and its whole inquiry strat-\negy, which is our main target. But we still include\nprecision for reference.\nICD-Recall (RICD). This is our primary metric,\nmeasuring the coverage of ground truth diagnoses.\nRICD = 1\n|G|\n∑\ng∈G\nmax\np∈P SimICD(p, g).\n(13)\nICD-Precision (PICD). It reflects diseases requir-\ning exclusion via further inquiry in diagnostic hy-\npotheses, while not in GT:\nPICD =\n1\n|P|\n∑\np∈P\nmax\ng∈G SimICD(p, g).\n(14)\nAs shown in Table 1: (1) Overall, Dr. Assis-\ntant achieves an advance in ICD-Recall, improving\nby 6.70% relative to the best closed-source model,\nGemini-3-Pro-Preview (0.5066 v.s. 0.4748). This\ndemonstrates its effectiveness. (2) Compared to\nopen-source general-purpose models, Dr. Assis-\ntant outperforms Qwen3-32B by 16.30 % relatively\n(0.5066 v.s.\n0.4356).\nThis is because Dr.\nAs-\nsistant learned diagnostic reasoning logic and in-\nquiry skills to infer patient’s disease from a core\nsymptom. (3) Compared to open-source medical\nmodels, Dr. Assistant achieves state-of-the-art in\nICD-Recall, even surpassing HuatuoGPT-o1-72B\nby 13.59% relatively (0.5066 v.s. 0.4460). It is be-\ncause previous medical models focus on domain\n"}, {"page": 7, "text": "Model\nRecall† ↑\nPrec. ↑\nOpen-source (Medical)\nHuatuoGPT-o1-72B\n0.4460\n0.5211\nBaichuan-M2-32B\n0.3687\n0.4517\nDoctor-R1-8B\n0.3873\n0.4800\nLlama3-OpenBioLLM-70B\n0.2216\n0.2755\nMed42-v2-8B\n0.2787\n0.3081\nOpen-source (Non-medical)\nQwen3-14B\n0.4298\n0.4600\nQwen3-32B\n0.4356\n0.4660\nDeepSeek-R1-Distill-14B\n0.3913\n0.4267\nClosed-source\nGPT-5\n0.4651\n0.4842\nGemini-2.5-Flash\n0.4288\n0.4497\nGemini-3-Pro-Preview\n0.4748\n0.5333\nGrok 4 Fast\n0.4284\n0.5159\nDr. Assistant\n0.5066\n0.4717\nTable 1: Average ICD-Recall & Precision, sorted by\nICD-Recall†. ICD-Recall (denoted by †) is the primary\ncriterion for assessing a model’s diagnostic reasoning\ncorrection. Model performance across secondary de-\npartments is detailed in Appendix Table 5.\nFigure 5: Physician’s satisfaction. For a clearer display\nof comparison, tie cases are excluded from this figure.\nknowledge but lack clinical diagnostic reasoning\nand inquiry skills. In the RL stage, Dr. Assistant\ninternalized reasoning and inquiry skills, thereby\ndriving the inquiry dialogue to an optimal trajec-\ntory.\n5.3\nPhysician Satisfaction\nTo evaluate model inquiries in real CDSS settings,\nwe had the model produce inquiries based on real\nclinical inquiry records (147 rounds), submitted\nthem to physicians for evaluation. We invite 11\nphysicians, each with about 6 years of clinical expe-\nrience. The evaluation criteria consist of two parts:\nrelevance and expertise, where relevance serves as\nthe prerequisite for winner. Physicians must deter-\nmine a winner of inquiry-couple (ours, baseline),\nor declare a tie. Each evaluation is independently\nreviewed by three physicians to ensure reliability.\nFor further details, see Appendix §B.3.\nAs shown in Figure 5: (1) Dr. Assistant gets\nhigher physician satisfaction compared to open-\nsource models. It shows improvements of 35.83%\nand 26.78% over the medical model Med42-v2-8B\nand HuatuoGPT-o1-72B, respectively. Dr. Assis-\ntant maintains focus on the diagnostic target. It\nstems from its clear diagnostic reasoning logic,\nwhich enables it to deliver more valuable inquiries\nthroughout the clinical process. See case study in\nAppendix §C. (2) Dr. Assistant advances GPT-5\nby 15.19% (36.96 v.s. 21.77). This highlights that\ncomplex clinical inquiry requires precise diagnos-\ntic reasoning. Dr. Assistant integrates diagnos-\ntic reasoning logic during RL, achieving superior\nphysician satisfaction.\nBenchmark\nQwen3-\n14B\nDr.\nAssistant\nRetention\nCMMLU (Medical, Chinese)\nAnatomy\n0.8649\n0.8784\n101.56%\nProfessional Medicine\n0.7952\n0.8032\n101.01%\nNutrition\n0.8207\n0.8276\n100.84%\nClinical Knowledge\n0.7890\n0.7932\n100.53%\nTCM\n0.8324\n0.8324\n100.00%\nCollege Medicine\n0.8828\n0.8791\n99.58%\nGenetics\n0.7727\n0.7670\n99.26%\nVirology\n0.8639\n0.8580\n99.32%\nMMLU-Pro (English)\nZero-shot\n0.6710\n0.6799\n101.33%\nFive-shot\n0.6724\n0.6686\n99.43%\nMedQA (English)\nZero-shot\n0.7021\n0.6897\n98.23%\nFive-shot\n0.6960\n0.6952\n99.89%\nAverage (Overall)\n0.7803\n0.7810\n100.10%\nTable 2: Performance on general benchmarks.\nThe\nRetention reflects model’s ability to maintain original\nknowledge after our post-training.\n5.4\nGeneral Medical Knowledge Retention\nTo assess the general knowledge retention of Dr.\nAssistant, we conduct a comparative analysis of\nits performance against Qwen3-14B on the gen-\neral knowledge benchmarks CMMLU(0/5-shot)\n(Li et al., 2024), MMLU-Pro (0/5-shot) (Wang\net al., 2024b), and MedQA (Jin et al., 2021b). For\nCMMLU, we select eight medical-related subsets\nfor evaluation. Results are in Table 2.\n"}, {"page": 8, "text": "Overall, Dr.\nAssistant maintains close per-\nformance to Qwen3-14B (0.7810 v.s.\n0.7803),\ndemonstrating no significant knowledge forgetting.\nNotably, on the eight Chinese medical subsets of\nCMMLU (Li et al., 2024), Dr. Assistant achieves\nequal or superior performance to Qwen3-14B in\nfive of them, further validating the effectiveness of\nour training method.\nMethod\nSatisfaction\nRecall† ↑\nPrec. ↑\nDr. Assistant\n-0.00%\n0.5066\n0.4717\nw/o SFT\n-18.82%\n0.5024\n0.4475\nw/o RL\n-6.80%\n0.3927\n0.5144\nw/o Rdiv\n-8.62%\n0.4856\n0.5192\nw/o Rcomp-r\n-5.50%\n0.4893\n0.4830\nTable 3: Ablation study on Dr. Assistant. Satisfac-\ntion is calculated as the difference in winning percent-\nage compared to Dr. Assistant.\n5.5\nAblation Study\nWe evaluate the contributions of SFT, RL, and the\nreward function to Dr. Assistant on our benchmark,\nwith results summarized in Table 3.\nThe removal of SFT and RL leads to perfor-\nmance drops of 0.84% and 29.00% relative to the\nfull on ICD-Recall separately, and drops of 18.82%\nand 6.80% on satisfaction separately.\nSFT im-\nproves the model’s clinical diagnostic logic, while\nRL further reinforces reasoning and inquiry skills.\nNotably, performance degrades less when SFT is\nomitted than when RL is. This suggests SFT tends\nto solidify the model’s response patterns around\nthe tuning data, which may constrain its adaptabil-\nity to prior tasks.\nAnd RL not only guides the\nmodel beyond these fixed patterns but also further\nrefines and expands its learned capabilities. (Lai\net al., 2025a).\nFurthermore, we individually removed the Rdiv\nand Rcomp-r reward. This leads to performance de-\nclines of 4.32% and 3.54% on ICD-Recall, respec-\ntively, and 8.62% and 5.50% on satisfaction, re-\nspectively, demonstrating their effectiveness. The\nRdiv component serves to penalize the generation\nof incorrect diagnostic information, improving out-\nput quality.\nThe Rcomp-r function rewards the\nmodel’s clinical reasoning, which is similar to GT.\n5.6\nEasy and Hard Diagnostic Inquiry\nWe stratified patient profiles by diagnosed dis-\nease (1∼6) into single-disease (1, easy) and multi-\nModel\nDiag.=1\nDiag.>1\nOpen-source (medical)\nHuatuoGPT-o1-72B\n0.5248\n0.4461\nBaichuan-M2-32B\n0.4139\n0.3688\nDoctor-R1-8B\n0.4733\n0.3890\nMed42-v2-8B\n0.2938\n0.2788\nLlama3-OpenBioLLM-70B\n0.2240\n0.1867\nOpen-source (general)\nQwen3-14B\n0.5030\n0.4316\nQwen3-32B\n0.5307\n0.4356\nDeepSeek-R1-Distill-14B\n0.4198\n0.3913\nClosed-source\nGPT-5\n0.5287\n0.4652\nGemini 2.5 Flash\n0.5192\n0.4289\nGrok 4 Fast\n0.4821\n0.4092\nGemini-3-Pro-Preview\n0.5455\n0.4749\nDr. Assistant\n0.5426\n0.5067\nTable 4: Model performance (ICD-Recall) stratified by\ndiagnostic complexity: single-disease cases (Diag.=1,\neasy) vs. multi-disease cases (Diag.>1, hard). We pro-\nvide detailed Diag.=1∼6 in Appendix Table 6.\ndisease (2∼6, hard) cases to evaluate model’s rea-\nsoning and inquiry skills across diagnostic com-\nplexity levels.\nAs shown in Table 4, compared\nto Baichuan-M2-32B and GPT-5, Dr.\nAssistant\nachieves disease-recall improvements of 31.09%\nand 2.80% (0.5426 v.s.\n0.4139 and 0.5426 v.s.\n0.5278) on single-disease tasks, and 37.39% and\n8.92% (0.5067 v.s. 0.3688 and 0.5067 v.s. 0.4652)\non multi-disease tasks, respectively.\nDr.\nAssis-\ntant not only achieves competitive performance on\nsingle-disease tasks but also demonstrates superior\ndiagnostic performance in hard (multi-disease) set-\ntings. It is because Dr. Assistant stays on the di-\nagnostic target. It stems from its clear diagnostic\nreasoning logic, which enables it to deliver more\nvaluable inquiries throughout the clinical process.\nWe also analyze the model’s performance across\ndifferent departments, as shown in Appendix §D.\n6\nConclusion\nTo address the limitations of traditional CDSSs\nand enhance the diagnostic reasoning capability\nof LLMs in clinical diagnostic inquiry, we pro-\npose (1) a structured Clinical Diagnostic Reason-\ning Data (CDRD) format along with a construc-\ntion pipeline to capture abstract clinical reasoning\nlogic, and (2) the Dr. Assistant model, which inte-\ngrates clinical reasoning and inquiry skills through\na two-stage training strategy of Supervised Fine-\n"}, {"page": 9, "text": "Tuning followed by Reinforcement Learning with\na tailored reward function. Evaluated on a dedi-\ncated diagnostic reasoning and inquiry benchmark,\nDr.\nAssistant outperforms open-source models\nand achieves competitive performance compared\nto closed-source models, offering a practical solu-\ntion for clinical diagnostic inquiry guidance.\n7\nLimitation\nOur study has several limitations. First, the con-\nstruction of Clinical Diagnostic Reasoning Data\n(CDRD) relies on physician refinement, which in-\ntroduces manual effort and may limit scalability.\nWhile we employed a three-stage pipeline to ensure\nquality, this process remains resource-intensive\nand could be subject to individual clinical judg-\nment biases. Second, our evaluation benchmark,\nthough constructed from real clinical cases and di-\nalogues, is moderate in scale and covers a limited\nnumber of secondary departments. This may af-\nfect the generalizability of our findings to broader\nor more specialized clinical settings. Third, the\nreward function used in reinforcement learning,\nwhile designed with clinical dimensions in mind,\nis inherently heuristic and may not fully capture\nall nuances of real diagnostic reasoning. Future\nwork could explore more automated, data-driven\nreward modeling or incorporate direct clinical out-\ncome feedback. Lastly, our experiments primarily\nfocus on diagnostic inquiry within a controlled di-\nalogue framework. The model’s performance in\nfully open-ended clinical conversations or integra-\ntion with live electronic health record systems re-\nmains to be tested.\n8\nAcknowledgments\nWe are grateful to Junfeng Wang and Bo Yuan for\ntheir leadership and support on this project. We\nextend our special thanks to Jianwei Lv and other\ncolleagues for their helpful comments on earlier\ndrafts of the paper. We also sincerely appreciate\nthe strong support from our professional medical\nteam in both data acquisition and model evaluation.\nAll listed individuals are with Baidu Inc.\nReferences\nMalaikannan\nSankarasubbu\nAnkit\nPal.\n2024.\nOpenbiollms:\nAdvancing\nopen-source\nlarge\nlanguage\nmodels\nfor\nhealthcare\nand\nlife\nsci-\nences.\nhttps://huggingface.co/aaditya/\nOpenBioLLM-Llama3-70B.\nYasir Arfat, Marco Colella, and Enrico Marello. 2024.\nLegal text analysis using large language models. In\nInternational Conference on Applications of Natural\nLanguage to Information Systems, pages 258–268.\nSpringer.\nRahul K Arora, Jason Wei, Rebecca Soskin Hicks, Pre-\nston Bowman, Joaquin Quiñonero-Candela, Foivos\nTsimpourlas, Michael Sharman, Meghan Shah, An-\ndrea Vallone, Alex Beutel, and 1 others. 2025.\nHealthbench: Evaluating large language models to-\nwards improved human health.\narXiv preprint\narXiv:2505.08775.\nEta S Berner and Tonya J La Lande. 2016. Overview\nof clinical decision support systems. In Clinical de-\ncision support systems: Theory and practice, pages\n1–17. Springer.\nTiffani J Bright, Anthony Wong, Ravi Dhurjati, Erin\nBristow, Lori Bastian, Remy R Coeytaux, Gre-\ngory Samsa, Vic Hasselblad, John W Williams,\nMichael D Musty, and 1 others. 2012. Effect of clin-\nical decision-support systems: a systematic review.\nAnnals of internal medicine, 157(1):29–43.\nJunying Chen, Zhenyang Cai, Ke Ji, Xidong Wang,\nWanlong Liu, Rongsheng Wang, Jianye Hou, and\nBenyou Wang. 2024.\nHuatuogpt-o1, towards\nmedical complex reasoning with llms.\nPreprint,\narXiv:2412.18925.\nXiuyuan Chen, Tao Sun, Dexin Su, Ailing Yu, Jun-\nwei Liu, Zhe Chen, Gangzeng Jin, Xin Wang,\nJingnan Liu, Hansong Xiao, and 1 others. 2025.\nGaps:\nA clinically grounded, automated bench-\nmark for evaluating ai clinicians.\narXiv preprint\narXiv:2510.13734.\nClément Christophe, Praveen K Kanithi, Tathagata\nRaha, Shadab Khan, and Marco AF Pimentel. 2024.\nMed42-v2: A suite of clinical llms.\nGoogle DeepMind. 2025a. Gemini 2.5 flash.\nGoogle DeepMind. 2025b. Gemini 2.5 pro.\nDeepSeek-AI. 2025a. Deepseek-r1: Incentivizing rea-\nsoning capability in llms via reinforcement learning.\nPreprint, arXiv:2501.12948.\nDeepSeek-AI. 2025b.\nDeepseek-v3.2: Pushing the\nfrontier of open large language models.\nRahul C Deo. 2015. Machine learning in medicine. Cir-\nculation, 132(20):1920–1930.\nChengfeng Dou, Chong Liu, Fan Yang, Fei Li, Jiyuan\nJia, Mingyang Chen, Qiang Ju, Shuai Wang, Shunya\nDang, Tianpeng Li, and 1 others. 2025. Baichuan-\nm2: Scaling medical capability with large verifier\nsystem. arXiv preprint arXiv:2509.02208.\nChengfeng Dou, Ying Zhang, Zhi Jin, Wenpin Jiao,\nHaiyan Zhao, Yongqiang Zhao, and Zhengwei Tao.\n2024.\nIntegrating physician diagnostic logic into\n"}, {"page": 10, "text": "large language models: Preference learning from\nprocess feedback. In Findings of the Association for\nComputational Linguistics: ACL 2024, pages 2453–\n2473.\nLinlu Gong, Ante Wang, Yunghwei Lai, Weizhi Ma,\nand Yang Liu. 2025. The dialogue that heals: A com-\nprehensive evaluation of doctor agents’ inquiry capa-\nbility. arXiv preprint arXiv:2509.24958.\nJA Hirsch, G Nicola, G McGinty, RW Liu, RM Barr,\nMD Chittle, and L Manchikanti. 2016. Icd-10: his-\ntory and context. American Journal of Neuroradiol-\nogy, 37(4):596–599.\nSamyar Janatian, Hannes Westermann, Jinzhe Tan,\nJaromir Savelka, and Karim Benyekhlef. 2023.\nFrom text to structure: Using large language models\nto support the development of legal expert systems.\nIn Legal Knowledge and Information Systems, pages\n167–176. IOS Press.\nDi Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng,\nHanyi Fang, and Peter Szolovits. 2021a. What dis-\nease does this patient have? a large-scale open do-\nmain question answering dataset from medical ex-\nams. Applied Sciences, 11(14):6421.\nDi Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng,\nHanyi Fang, and Peter Szolovits. 2021b. What dis-\nease does this patient have? a large-scale open do-\nmain question answering dataset from medical ex-\nams. Applied Sciences, 11(14):6421.\nQiao Jin, Bhuwan Dhingra, Zhengping Liu, William\nCohen, and Xinghua Lu. 2019.\nPubmedqa:\nA\ndataset for biomedical research question answering.\nIn Proceedings of the 2019 conference on empirical\nmethods in natural language processing and the 9th\ninternational joint conference on natural language\nprocessing (EMNLP-IJCNLP), pages 2567–2577.\nEnkelejda Kasneci, Kathrin Seßler, Stefan Küchemann,\nMaria Bannert, Daryna Dementieva, Frank Fischer,\nUrs Gasser, Georg Groh, Stephan Günnemann, Eyke\nHüllermeier, and 1 others. 2023. Chatgpt for good?\non opportunities and challenges of large language\nmodels for education. Learning and individual dif-\nferences, 103:102274.\nMarvin Kopka, Niklas von Kalckreuth, and Markus A\nFeufel. 2025.\nAccuracy of online symptom as-\nsessment applications, large language models, and\nlaypeople for self–triage decisions.\nnpj Digital\nMedicine, 8(1):178.\nSong Lai, Haohan Zhao, Rong Feng, Changyi Ma, Wen-\nzhuo Liu, Hongbo Zhao, Xi Lin, Dong Yi, Min Xie,\nQingfu Zhang, Hongbin Liu, Gaofeng Meng, and\nFei Zhu. 2025a.\nReinforcement fine-tuning natu-\nrally mitigates forgetting in continual post-training.\nCoRR, abs/2507.05386.\nYunghwei Lai, Kaiming Liu, Ziyue Wang, Weizhi Ma,\nand Yang Liu. 2025b. Doctor-r1: Mastering clini-\ncal inquiry with experiential agentic reinforcement\nlearning. arXiv preprint arXiv:2510.04284.\nYunghwei Lai, Kaiming Liu, Ziyue Wang, Weizhi Ma,\nand Yang Liu. 2025c. Doctor-r1: Mastering clini-\ncal inquiry with experiential agentic reinforcement\nlearning. Preprint, arXiv:2510.04284.\nHaonan Li, Yixuan Zhang, Fajri Koto, Yifei Yang, Hai\nZhao, Yeyun Gong, Nan Duan, and Timothy Bald-\nwin. 2024. Cmmlu: Measuring massive multitask\nlanguage understanding in chinese. In Findings of\nthe Association for Computational Linguistics: ACL\n2024, pages 11260–11285.\nSuxue Ma, Zhicheng Yang, Ruei-Sung Lin, Youbao\nTang, Ning Zhang, Zhenjie Cao, Yuan Ni, Jing Xiao,\nJieke Hou, and Peng Chang. 2025. Prefix-enhanced\nlarge language models with reused training data in\nmulti-turn medical dialogue.\nIn Proceedings of\nthe Second Workshop on Patient-Oriented Language\nProcessing (CL4Health), pages 26–33.\nOpenAI. 2025. Gpt-5 system card.\nAnkit Pal, Logesh Kumar Umapathi, and Malaikan-\nnan Sankarasubbu. 2022. Medmcqa: A large-scale\nmulti-subject multi-choice dataset for medical do-\nmain question answering. In Conference on health,\ninference, and learning, pages 248–260. PMLR.\nSeyedmostafa Sheikhalishahi, Riccardo Miotto, Joel T\nDudley, Alberto Lavelli, Fabio Rinaldi, and Venet\nOsmani. 2019. Natural language processing of clin-\nical notes on chronic diseases: systematic review.\nJMIR medical informatics, 7(2):e12239.\nGuangming Sheng, Chi Zhang, Zilingfeng Ye, Xibin\nWu, Wang Zhang, Ru Zhang, Yanghua Peng, Haibin\nLin, and Chuan Wu. 2024. Hybridflow: A flexible\nand efficient rlhf framework. arXiv preprint arXiv:\n2409.19256.\nReed T Sutton, David Pincock, Daniel C Baumgart,\nDaniel C Sadowski, Richard N Fedorak, and Karen I\nKroeker. 2020. An overview of clinical decision sup-\nport systems: benefits, risks, and strategies for suc-\ncess. NPJ digital medicine, 3(1):17.\nQwen Team. 2025. Qwen3 technical report. Preprint,\narXiv:2505.09388.\nShen Wang, Tianlong Xu, Hang Li, Chaoli Zhang,\nJoleen Liang, Jiliang Tang, Philip S Yu, and Qing-\nsong Wen. 2024a.\nLarge language models for ed-\nucation:\nA survey and outlook.\narXiv preprint\narXiv:2403.18105.\nYubo Wang, Xueguang Ma, Ge Zhang, Yuansheng Ni,\nAbhranil Chandra, Shiguang Guo, Weiming Ren,\nAaran Arulraj, Xuan He, Ziyan Jiang, and 1 others.\n2024b. Mmlu-pro: A more robust and challenging\nmulti-task language understanding benchmark. Ad-\nvances in Neural Information Processing Systems,\n37:95266–95290.\nShijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravol-\nski,\nMark Dredze,\nSebastian Gehrmann,\nPrab-\nhanjan Kambadur, David Rosenberg, and Gideon\n"}, {"page": 11, "text": "Mann. 2024.\nBloomberggpt:\nA large language\nmodel for finance,\n2023.\nURL https://arxiv.\norg/abs/2303.17564.\nxAI. 2025. Grok 4 fast.\nQianqian Xie, Weiguang Han, Xiao Zhang, Yanzhao\nLai, Min Peng, Alejandro Lopez-Lira, and Jimin\nHuang. 2023. Pixiu: A comprehensive benchmark,\ninstruction dataset and large language model for fi-\nnance. Advances in Neural Information Processing\nSystems, 36:33469–33484.\nSonghua Yang, Hanjie Zhao, Senbin Zhu, Guangyu\nZhou, Hongfei Xu, Yuxiang Jia, and Hongying Zan.\n2024. Zhongjing: Enhancing the chinese medical\ncapabilities of large language model through expert\nfeedback and real-world multi-turn dialogue. In Pro-\nceedings of the AAAI conference on artificial intelli-\ngence, volume 38, pages 19368–19376.\nQiying Yu, Zheng Zhang, Ruofei Zhu, Yufeng Yuan,\nXiaochen Zuo, Yu Yue, Weinan Dai, Tiantian Fan,\nGaohong Liu, Lingjun Liu, Xin Liu, Haibin Lin,\nZhiqi Lin, Bole Ma, Guangming Sheng, Yuxuan\nTong, Chi Zhang, Mofan Zhang, Wang Zhang, and\n16 others. 2025.\nDapo: An open-source llm re-\ninforcement learning system at scale.\nPreprint,\narXiv:2503.14476.\nH Zhang, J Chen, F Jiang, F Yu, Z Chen, J Li, G Chen,\nX Wu, Z Zhang, Q Xiao, and 1 others. Huatuogpt,\ntowards taming language model to be a doctor. arxiv\n(2023). arXiv preprint arXiv:2305.15075.\n"}, {"page": 12, "text": "A\nParameter Setting\nData construction.\nWe use DeepSeek-V3.2\n(DeepSeek-AI, 2025b) for constructing CDRD\ndata.\nFor constructing QA pairs and multi-turn\ninquiry dialogue data, we employ Qwen3-235B-\nA22B (Team, 2025). The model selection is de-\ntermined through manual validation on a small set\nof test data.\nSFT. The training epoch is set to 4, and a cosine\nannealing strategy is adopted, with a maximum\nlearning rate of 5e-6. The warm-up ratio is set\nto 0.0,3 and the regularization coefficient is set\nto 0.01. SFT training process is conducted on 32\nA800 GPUs.\nRL. Our RL training is based on the VeRL frame-\nwork (Sheng et al., 2024) with Qwen3-32B (Team,\n2025) as the LLM-judge in our reward function.\nThe learning rate is set to (1 × 10−6), clipping\nparameters are (ϵlow = 0.2) and (ϵhigh = 0.28),\nthe rollout number is 4, and the training batch size\nis 512. The entire reinforcement learning process\nwas run for 185 steps. Rcomp’s (eq. (10)) weights\nare set to wreason = [0.1, 0.3] (0.1 is for r0 to r2,\nand 0.3 for others) and winquiry = [0.6]. Rdiv’s\n(eq. (11)) weight is set to λ = 5. The RL training\nprocess is conducted on 8 H800 GPUs, with an ad-\nditional 16 H800 GPUs used for the LLM-judge.\nEvaluation.\nTo evaluate the ICD-Recall, ICD-\nPrecision and Physician Satisfaction metrics, we\nset greedy decoding (with temperature = 0) for\nall models to ensure deterministic and comparable\ngeneration outputs. The prompts in §F.1 and §F.2\nare used to generate responses for metric computa-\ntion.\nB\nEvaluation\nDr. Assistant is for clinical diagnostic reasoning\nand inquiry guidance (internal-medicine in Chi-\nnese in experiment).\nHowever, existing bench-\nmarks are not fully aligned with it. HealthBench\n(Arora et al., 2025) covers general healthcare con-\nsultation instead of multi-turn diagnostic inquiry.\nMAQuE (Xie et al., 2023), while involving multi-\nturn diagnostic inquiry, separates inquiry and diag-\nnostic reasoning. Therefore, it does not align the\nreal-world interdependence between them.\nB.1\nReasoning-inquiry Loop\nIn practice, the reasoning leads to a different tra-\njectory of inquiry. Physician issues inquiry based\non their diagnostic hypotheses (the reasoning core).\nUpon receiving an inquiry, the patient responds\nwith new queries. The physician then updates the\ndiagnostic hypothesis based on this new query and\ncontinues the dialogue. We show this reasoning-\ninquiry loop in Figure 1 (a), which ultimately re-\nsults in different diagnostic conclusions for the\nsame patient.\nAlthough the reasoning before an inquiry con-\nsists of multiple steps as mentioned in §3.4, their\nultimate goal is to verify the diagnostic hypothesis.\nIncluding the correct diagnoses within this hypoth-\nesis is a prerequisite for proper inquiry.\nB.2\nICD-10 Matching of Clinical Diagnostic\nReasoning\nPhysicians form initial diagnostic hypothesis based\non available information and iteratively refine it\nthrough targeted inquiry as new information is\ngathered, ultimately arriving at diagnostic results.\nThe evolving diagnostic hypothesis drives the rea-\nsoning of inquiry.\nTherefore, we compare the\nmodel’s diagnostic hypothesis with the diagnosis\nGT. To simulate dynamic clinical inquiry, we use\nan LLM as a patient simulator, conditioned on real\npatient profiles (includes basic medical history,\ncommunication style and diagnosis, anonymized).\nEach inquiry starts from patient simulator’s main\ncomplaint. At each turn, the evaluated model out-\nputs two parts: a diagnostic hypothesis and an in-\nquiry to the patient. After five rounds, we compare\nthe model’s last diagnostic hypotheses with the di-\nagnoses in the patient profile. Average ICD-Recall\nand ICD-Precision of each baseline are reported in\nTable 1.\nICD-10 matching. ICD-10 (International Classifi-\ncation of Disease) (Hirsch et al., 2016) codes’ lead-\ning letter indicates major chapter and subsequent\ndigits specify granular categories. We map the di-\nagnosis results by LLM from both the model and\nthe ground truth to ICD-10 codes, P and G, respec-\ntively. We then calculate the similarity between\nthem using SimICD(p, g), as formalized in Algo-\nrithm 1. Based on this similarity, we compute two\nmetrics:\nICD-Recall (RICD). This is our primary metric,\nmeasuring the coverage of ground truth diagnoses.\nRICD = 1\n|G|\n∑\ng∈G\nmax\np∈P SimICD(p, g)\n(15)\nReason for ICD-Recall priority: In clinical diag-\nnostic reasoning, missing right diagnoses means\n"}, {"page": 13, "text": "Algorithm 1: Hierarchical ICD-10 Similarity\nScoring\nInput: Predicted Code p, Ground Truth Code g\nOutput: Similarity Score S ∈[0.0, 1.0]\n1 Function SimICD(p, g):\n// Level 1: Exact Match\n2\nif p = g then\n3\nreturn 1.0\n// Level 2: Sub-category (First 4 chars, e.g.,\nJ45.9)\n4\nelse if Prefix(p, 4) = Prefix(g, 4) then\n5\nreturn 0.8\n// Level 3: Category (First 3 chars, e.g., J45)\n6\nelse if Prefix(p, 3) = Prefix(g, 3) then\n7\nreturn 0.6\n// Level 4: Block Range (e.g., J40–J47)\n8\nelse if Block(p) = Block(g) then\n9\nreturn 0.4\n// Level 5: Chapter (First Letter, e.g., J)\n10\nelse if Prefix(p, 1) = Prefix(g, 1) then\n11\nreturn 0.2\n12\nelse\n13\nreturn 0.0\nthe model loses critical diagnostic clues, leading\nto skewed inquiry and results. More importantly,\nit poses a severe safety risk as the true condition re-\nmains unaddressed. Conversely, a false alarm can\nbe ruled out by a physician.\nICD-Precision (PICD). It reflects the number of\ndisease candidates (requiring exclusion via further\ninquiry) in the differential diagnoses set.\nPICD =\n1\n|P|\n∑\np∈P\nmax\ng∈G SimICD(p, g)\n(16)\nB.3\nPhysician Satisfaction: Inquiry Quality\nWe also involve physicians to assess response qual-\nity from a CDSS application perspective.\nFor evaluation, real clinical dialogue records are\nformatted into a historical context and the latest pa-\ntient message. The model is tasked with generating\nthe next response. Finally, we pair Dr Assistant’s\nresponse with a single baseline model’s output for\nphysician comparison. For each pair, the physician\nselects the better response or indicates a tie (se-\nlect 0 or 2 per pair). The evaluation is based on\ntwo criteria: Relevance. Response should appro-\npriately follow up on the patient’s statements, and\nnot deviate from the core inquiry topic. Expertise\n& standardization. The response should be clin-\nically accurate in diagnosis, adhere to medical ex-\npertise, display a logical inquiry progression, and\nprovide scientifically sound and appropriate rec-\nommendations. In practice, physicians first assess\nrelevance. Responses that lack sufficient relevance\nare directly rejected, regardless of other qualities.\nC\nCase Study\nWe show a clinical inquiry dialogue record in our\nbench, and the following inquiry guidance was gen-\nerated by Dr. Assistant and HuatuoGPT-o1-72B.\nThe results are shown in Figure 6.\nThis inquiry case reveals a notable divergence\nin clinical focus: HuatuoGPT-o1-72B did not ad-\nequately identify the potential cardiovascular risk\nunderlying the patient’s symptoms and directed\nthe inquiry toward orthopedics. But Dr. Assistant\nconsistently prioritized cardiovascular exam by an-\nchoring on key symptomatic clues throughout in-\nquiry process. The case demonstrates how Dr. As-\nsistant sustains correct diagnostic reasoning and in-\nquiry skills when faced with complicated symptom\npatterns.\nD\nPerformance on Different Secondary\nDepartments\nWe stratified the evaluation dataset by secondary\ndepartments to assess the performance of different\nmodels under real-world long-tail scenarios. Re-\nsults are presented in Table 5.\nOur benchmark reflects the long-tail distribution\nof real clinical departments. Consequently, mod-\nels underperform in tail categories like Rheuma-\ntology compared to head categories like Gastroen-\nterology.\nCompared to HuatuoGPT-o1-72B, Dr.\nAs-\nsistant achieves a performance improvement of\n22.71% (0.3857 v.s. 0.3143) in Rheumatology and\n17.17% (0.5424 v.s. 0.4629) in Gastroenterology.\nThese results further validate the effectiveness of\nDr. Assistant in integrating diagnostic reasoning\nlogic within clinical inquiry scenarios.\n"}, {"page": 14, "text": "Model\nMetric\nAvg.\nGastro.\nResp.\nNeuro.\nCard.\nNeph.\nEndo.\nInfec.\nRheum. Hema.\nOpen-source LLMs\nHuatuoGPT-o1-72B\nRecall\n0.4460\n0.4629\n0.5061\n0.3526\n0.3875 0.5278 0.5094 0.3178\n0.3143\n0.3444\nPrec.\n0.5211\n0.5265\n0.6000\n0.4260\n0.4064 0.6130 0.6375 0.5333\n0.3000\n0.6000\nQwen3-14B\nRecall\n0.4298\n0.5294\n0.3899\n0.2438\n0.3792 0.4722 0.5135 0.2571\n0.1714\n0.4111\nPrec.\n0.4600\n0.5442\n0.5053\n0.2583\n0.3672 0.4907 0.4771 0.3857\n0.2000\n0.5667\nQwen3-32B\nRecall\n0.4356\n0.5194\n0.4061\n0.3854\n0.3840 0.4000 0.4260 0.2486\n0.2429\n0.2000\nPrec.\n0.4660\n0.5540\n0.5149\n0.3875\n0.3558 0.3963 0.4250 0.4000\n0.1714\n0.2000\nDeepSeek-R1-Distill-14B\nRecall\n0.3913\n0.4526\n0.4285\n0.2354\n0.3645 0.4000 0.4844 0.2600\n0.1000\n0.2444\nPrec.\n0.4267\n0.4766\n0.4914\n0.2458\n0.3523 0.4111 0.5604 0.5238\n0.1071\n0.4000\nBaichuan-M2-32B\nRecall\n0.3687\n0.3844\n0.4031\n0.1969\n0.3826 0.4833 0.6094 0.2143\n0.1000\n0.1667\nPrec.\n0.4517\n0.4471\n0.5724\n0.2385\n0.4486 0.5519 0.6667 0.4000\n0.2000\n0.3333\nDoctor-R1-8B\nRecall\n0.3873\n0.4433\n0.4026\n0.2521\n0.3806 0.4778 0.3604 0.2771\n0.0571\n0.5111\nPrec.\n0.4800\n0.5237\n0.5368\n0.3359\n0.4222 0.6111 0.4000 0.4714\n0.0571\n1.0000\nMed42-v2-8B\nRecall\n0.2787\n0.1575\n0.4532\n0.1813\n0.4674 0.3056 0.5578 0.4111\n0.1000\n0.1333\nPrec.\n0.3081\n0.1857\n0.5435\n0.2396\n0.4638 0.2648 0.5311 0.4333\n0.1286\n0.1333\nLlama3-OpenBioLLM-70B Recall\n0.2216\n0.1227\n0.2412\n0.1563\n0.2708 0.2000 0.4042 0.2238\n0.0857\n0.1667\nPrec.\n0.2755\n0.1619\n0.3593\n0.2042\n0.3083 0.2167 0.4625 0.3714\n0.1143\n0.3333\nClosed-source Models\nGPT-5\nRecall\n0.4651\n0.4923\n0.4961\n0.3641\n0.4021 0.3944 0.6115 0.3610\n0.5571\n0.4556\nPrec.\n0.4842\n0.5068\n0.5816\n0.3869\n0.4426 0.3537 0.5896 0.4810\n0.3898\n0.3444\nGemini 2.5 Flash\nRecall\n0.4288\n0.5181\n0.4325\n0.2724\n0.3877 0.4278 0.4156 0.2771\n0.2286\n0.4111\nPrec.\n0.4487\n0.5222\n0.5114\n0.2833\n0.3783 0.3972 0.4958 0.4714\n0.1524\n0.3889\nGrok-4-fast-non-reasoning\nRecall\n0.4284\n0.4672\n0.4162\n0.3051\n0.5017 0.4500 0.6136 0.2722\n0.0857\n0.2444\nPrec.\n0.5159\n0.5316\n0.5886\n0.3615\n0.5352 0.5370 0.7636 0.4667\n0.1143\n0.3111\nGemini-3-Pro-Preview\nRecall\n0.4748\n0.4974\n0.4491\n0.4247\n0.4529 0.5111 0.5200 0.3514\n0.6000\n0.3444\nPrec.\n0.5333\n0.5391\n0.6036\n0.4667\n0.4964 0.5093 0.5422 0.5571\n0.5167\n0.5333\nRecall\n0.5066\n0.5424\n0.4368\n0.4370\n0.5313 0.4722 0.7219 0.3981\n0.3857\n0.3778\nDr. Assistant\nPrec.\n0.4717\n0.5146\n0.4882\n0.3938\n0.4124 0.4444 0.6113 0.3381\n0.2796\n0.3667\nTable 5: Comprehensive comparison of ICD-Recall and ICD-Precision across all 9 secondary departments.\n"}, {"page": 15, "text": "Model\nMetric\nNumber of Disease in Case’s Diagnosis\nDiag.=1 Diag.=2 Diag.=3 Diag.=4 Diag.=5 Diag.=6\nOpen-source LLMs\nHuatuoGPT-o1-72B\nRecall\n0.5248\n0.3949\n0.3920\n0.3286\n0.4400\n0.5667\nPrec.\n0.4807\n0.5259\n0.6040\n0.5619\n1.0000\n1.0000\nQwen3-14B\nRecall\n0.5030\n0.3960\n0.3387\n0.3679\n0.0000\n0.4000\nPrec.\n0.4475\n0.4675\n0.4853\n0.5036\n0.0000\n0.6667\nQwen3-32B\nRecall\n0.5307\n0.3810\n0.3360\n0.3321\n0.4400\n0.2333\nPrec.\n0.4621\n0.4647\n0.4360\n0.4952\n1.0000\n0.8000\nDeepSeek-R1-Distill-14B\nRecall\n0.4198\n0.3820\n0.3194\n0.3893\n0.1200\n0.4667\nPrec.\n0.3745\n0.4484\n0.4938\n0.5200\n0.4667\n0.6000\nBaichuan-M2-32B\nRecall\n0.4139\n0.3310\n0.3627\n0.3571\n0.0000\n0.2667\nPrec.\n0.4030\n0.4580\n0.5753\n0.5500\n0.0000\n0.7333\nDoctor-R1-8B\nRecall\n0.4733\n0.3434\n0.3227\n0.2286\n0.4400\n0.2333\nPrec.\n0.4521\n0.4939\n0.5287\n0.4786\n1.0000\n0.7000\nMed42-v2-8B\nRecall\n0.2938\n0.2639\n0.2806\n0.2821\n0.0000\n0.4667\nPrec.\n0.2656\n0.3131\n0.3583\n0.4571\n0.0000\n0.9333\nLlama3-OpenBioLLM-70B Recall\n0.2240\n0.1808\n0.1333\n0.0679\n0.0000\n0.2333\nPrec.\n0.2160\n0.2700\n0.2533\n0.1857\n0.0000\n1.0000\nClose-source Models\nGPT-5\nRecall\n0.5287\n0.4340\n0.4000\n0.3750\n0.3600\n0.1667\nPrec.\n0.4491\n0.5111\n0.5224\n0.4690\n0.6000\n0.5000\nGemini 2.5 Flash\nRecall\n0.5192\n0.3910\n0.2667\n0.3679\n0.4400\n0.1667\nPrec.\n0.4414\n0.4578\n0.4120\n0.5048\n0.5000\n0.6000\nGrok-4-fast-non-reasoning\nRecall\n0.4821\n0.4032\n0.3545\n0.3875\n0.0000\n0.2333\nPrec.\n0.4592\n0.5588\n0.5174\n0.6333\n0.0000\n1.0000\nGemini-3-Pro-Preview\nRecall\n0.5455\n0.4330\n0.3920\n0.4321\n0.3600\n0.3333\nPrec.\n0.5003\n0.5498\n0.5140\n0.6495\n0.6000\n1.0000\nGrok-3-Mini\nRecall\n0.4787\n0.3629\n0.3884\n0.2821\n0.4400\n0.2333\nPrec.\n0.4779\n0.5449\n0.6797\n0.5714\n1.0000\n1.0000\nRecall\n0.5426\n0.4750\n0.4613\n0.5500\n0.5200\n0.5667\nDr. Assistant\nPrec.\n0.4173\n0.4874\n0.5165\n0.6536\n0.4667\n0.7500\nTable 6: Performance comparison of ICD-Recall and ICD-Precision across different numbers of ground truth ICD-\n10 codes (Diag.=1 to Diag.=6).\n"}, {"page": 16, "text": "Pain in the left and right shoulders and upper back for one \nmonth, occasional chest pain, with a history of hypertension. \nNo ECG or cardiac-related tests have been performed. \nHow well is your hypertension controlled? Have you \nmonitored your blood pressure recently? Do you usually \nhave issues with obesity or high blood lipids?\nI am overweight, but I don’t know about blood lipids. But \nhaven’t checked, probably not high.\nNot necessarily.\nYou need to check your blood lipids and heart.\nUsually it’s around 120 systolic, diastolic 70–80. \nShould I check if my blood lipids are high?\nYes.\nBut my arms don’t hurt at night when sleeping; sometimes it feels \nlike pain in the gaps.\nThat could be periarthritis of the shoulder. It is related \nto orthopedics.\nWhat about the occasional chest pain? Sometimes it feels like \nsomething is coming up, but once I was checked and told I had \npharyngitis.\nAny acid reflux or heartburn?\nNo heartburn, no acid reflux. Just feels like something is coming \nup, very uncomfortable.\nYou could try omeprazole + domperidone to improve the symptoms.\nOkay. Sometimes there is pain around the collarbone.\nWhen high, blood pressure is around 150 systolic, \ndiastolic 90 or 100.\nYour symptoms do sound concerning, but please rest assured that we will work through this step by step. \nThe shoulder and back pain could be due to conditions like frozen shoulder or cervical spondylosis.\nI recommend that you consult an orthopedic specialist for further evaluation.\nThe collarbone pain, together with your previous shoulder and chest pain, requires evaluation for shoulder \nor heart concerns. Your blood pressure control remains suboptimal. Prompt reassessment of your \nlipid levels and an ECG are advised to exclude cardiac risks.\nClinical inquiry dialogue history:\n Inquiry guidance by assistants:\nHuatuoGPT-o1-72B:\nDr. Assistant:\nPatient’s query:\nFigure 6: Case study. Assistants generate final inquiry guidance based on the dialogue history and the latest query.\nPlease note that the data in our study is in Chinese. English is used here solely for illustrative purposes.\n"}, {"page": 17, "text": "E\nPrompt for Data Synthesis\nE.1\nPrompt for CDRD Construction\nStage I | Symptom Extraction Prompt\n以下是《临床诊疗指南》某一章的核心内容：\n» Below is the core content of a chapter in “Clinical Diagnosis and Treatment Guidelines”:\n{指南}\n» {Guideline}\n基于上述指南，请针对症状“{症状}” 筛选出与其相关的10 个【疾病】\n» Based on the above guidelines, please identify 10 [Diseases] related to the symptom “{Symptom}”.\n要求：提取的【疾病】需要是具体的疾病，不可是大类疾病。不可以捏造，只能提取！\n» Requirements: The extracted [Diseases] need to be specific diseases, not broad categories. Do not\nfabricate, only extract!\n输出为List 格式：\n» Output in List format:\n[“AAA”, “BBB”, “CCCC”]\nStage II | Disease Matching Prompt\n以下是《临床诊疗指南》某一章的核心内容：\n» Below is the core content of a chapter in “Clinical Diagnosis and Treatment Guidelines”:\n{指南}\n» {Guideline}\n已知症状“{症状}” 对应的疾病列表为：{疾病列表}\n» The disease list corresponding to the known symptom “{Symptom}” is: {Disease_List}\n请基于上述指南，补全诊断部分（疾病必须严格对应已知列表，不可新增或遗漏，内容严格\n依据指南提取）：\n» Based on the above guidelines, please complete the diagnosis section (diseases must strictly cor-\nrespond to the known list, no additions or omissions, with content strictly extracted from the guide-\nlines):\n要求：\n» Requirements:\n1. 每个疾病需包含“疾病特点” 和“辅助检查” 两部分\n» 1. Each disease must include two parts: “Disease Features” and “Auxiliary Examinations”.\n2. 疾病特点：突出该疾病与当前症状相关的核心特征，明确鉴别要点\n» 2. Disease Features: Highlight the core features of the disease related to the current symptom,\nclarifying differential points.\n3. 辅助检查：列出指南推荐的、用于明确诊断的检查项目\n» 3. Auxiliary Examinations: List the examination items recommended by the guidelines for con-\nfirming the diagnosis.\n4. 格式严格遵循示例：\n» 4. Strictly follow the example format:\n一、xxx 疾病\n"}, {"page": 18, "text": "» 1. xxx Disease\n疾病特点\n» Disease Features\n* 核心症状：xxxxxxx\n» * Core Symptoms: xxxxxxx\n* 伴随症状：xxxxxxx\n» * Accompanying Symptoms: xxxxxxx\n辅助检查\n» Auxiliary Examinations\n* 检查项目1：xxxxxxx\n» * Exam Item 1: xxxxxxx\n* 检查项目2：xxxxxxx\n» * Exam Item 2: xxxxxxx\n返回格式严格为JSON，仅包含诊断字段，不可添加额外内容：\n» Return format strictly as JSON, containing only the diagnosis field, no extra content:\n{“诊断（疾病特点+ 进一步检查）”: “上述格式的诊断内容”}\n» {“Diagnosis (Disease Features + Further Checks)”: “Diagnostic content in the above format”}\nStage III | Logic Completion Prompt\n以下是《临床诊疗指南》某一章的核心内容：\n» Below is the core content of a chapter in “Clinical Diagnosis and Treatment Guidelines”:\n{指南}\n» {Guideline}\n已知信息：\n» Known information:\n- 症状：{症状}\n» - Symptom: {Symptom}\n- 对应疾病列表：{疾病列表}\n» - Corresponding Disease List: {Disease_List}\n- 已补全的诊断内容：{诊断内容}\n» - Completed Diagnosis Content: {Diagnosis_Content}\n请基于上述指南和诊断内容，补全病情收集部分（需覆盖所有疾病的鉴别要点，具有临床实\n用性）：\n» Based on the above guidelines and diagnosis content, please complete the medical condition col-\nlection section (must cover differential points for all diseases, with clinical practicality):\n要求：\n» Requirements:\n1. 包含但不限于发作频率、诱发因素、伴随症状、发病程度、既往史、用药史、个人史等维\n度\n» 1. Including but not limited to dimensions such as attack frequency, inducing factors, accompanying\nsymptoms, severity, past history, medication history, personal history, etc.\n2. 每个维度需明确收集方向，需能支撑诊断中各疾病的鉴别\n» 2. Each dimension requires a clear collection direction to support the differentiation of diseases in\nthe diagnosis.\n3. 格式严格遵循示例：\n"}, {"page": 19, "text": "» 3. Strictly follow the example format:\n1. 发作频率：是否突发或反复发作，发作间隔时间，持续时长\n» 1. Attack Frequency: Sudden or recurrent, interval time, duration\n2. 发病程度：症状严重程度（如水肿范围、疼痛等级），是否影响视力或日常生活\n» 2. Severity: Severity of symptoms (e.g., range of edema, pain level), whether it affects\nvision or daily life\n3. 诱发因素：是否接触过敏原、外伤、感染史、劳累、情绪波动等\n» 3. Inducing Factors: Contact with allergens, trauma, infection history, fatigue, mood\nswings, etc.\n4. 伴随症状：是否有眼红、分泌物增多、发热、淋巴结肿大、视力下降等\n» 4. Accompanying Symptoms: Red eyes, increased secretions, fever, lymph node enlarge-\nment, vision loss, etc.\n5. 既往疾病史：是否有眼部疾病、皮肤病、传染病、慢性病等病史\n» 5. Past Medical History: Eye diseases, skin diseases, infectious diseases, chronic diseases,\netc.\n6. 用药史：是否使用过抗生素、激素类药物、抗过敏药物等，用药时间及疗效\n» 6. Medication History: Use of antibiotics, hormones, anti-allergy drugs, etc., duration\nand efficacy\n7. 个人史：是否有过敏史、职业暴露史、家族遗传病史等\n» 7. Personal History: Allergy history, occupational exposure, family genetic history, etc.\n返回格式严格为JSON，仅包含病情收集字段，不可添加额外内容：\n» Return format strictly as JSON, containing only the condition collection field, no extra content:\n{“病情收集”: “上述格式的病情收集内容”}\n» {“Condition Collection”: “Condition collection content in the above format”}\nE.2\nPrompt for Inquiry Dialogue Synthesis\n医生模拟器提示词(Doctor Simulator Prompt for Inquiry Dialogue Synthesis)\n你是一名医生。目标是：根据患者所述，在确认或高度怀疑特定疾病后，给出清晰、可执行\n的治疗建议与就医建议。\n» You are a doctor. The goal is: based on the patient’s statement, after confirming or highly suspecting\na specific disease, provide clear and actionable treatment advice and medical advice.\n### 重要规则###\n1. 严格按照模板格式输出\n» 1. Strictly output according to the template format\n2.【诊断】字段仅填写本模板对应的疾病名称，不添加额外前缀\n» 2. The [Diagnosis] field should only contain the disease name corresponding to this template,\nwithout adding extra prefixes\n3. 优先提供治疗方案、用药建议、生活方式与随访计划，并明确何时需要急诊/就医\n» 3. Prioritize providing treatment plans, medication advice, lifestyle and follow-up plans, and\nclearly state when emergency/medical attention is needed\n4. 若信息不足，先用1-2 个关键问题快速确认，再给出安全的过渡性建议\n» 4. If information is insufficient, first use 1-2 key questions to quickly confirm, then give safe\ninterim advice\n5. 每次回答只提问1-2 个关键问题\n» 5. Ask only 1-2 key questions per answer\n"}, {"page": 20, "text": "### 症状需要收集的病情###\n» ### Symptom Conditions to Collect ###\n{症状收集清单}\n» {Symptom_Checklist}\n### 症状的鉴别诊断（疾病特点+ 进一步检查）###\n» ### Differential Diagnosis of Symptoms (Disease Features + Further Tests) ###\n{鉴别诊断}\n» {Differential_Diagnosis}\n### 示例格式（严格遵循此格式）###\n» ### Example Format (Strictly Follow This Format) ###\n【】包裹每个字段的符号必须完全相同\n» The symbols [] wrapping each field must be exactly the same\n【已知信息】\n>> [Known Information]\n【待解决用户需求】\n>> [User Needs to Address]\n【已提供给用户信息】\n>> [Information Provided to User]\n【诊断】\n>> [Diagnosis]\n【待收集信息】\n>> [Information to Collect]\n【回复策略】\n>> [Response Strategy]\n【回复】\n>> [Response]\n例如：\n>> For example:\n【已知信息】\n>> [Known Information]\n小儿持续打喷嚏、流涕1个月，晨起及接触宠物后加重，家长疑过敏。\n>> Child continuously sneezing and runny nose for 1 month, worse in the morning and after contact with\npets, parents suspect allergy.\n【待解决用户需求】\n>> [User Needs to Address]\n了解可能病因、是否与过敏相关、是否需检查/用药。\n>> Understand possible causes, whether related to allergies, whether examination/medication is needed.\n【已提供给用户信息】\n>> [Information Provided to User]\n提及接触宠物后症状加重及过敏怀疑，无其他症状、病史。\n>> Mentioned symptoms worsening after pet contact and allergy suspicion, no other symptoms or medical\nhistory.\n【诊断】\n>> [Diagnosis]\n初步诊断：过敏性鼻炎。\n>> Preliminary diagnosis: Allergic rhinitis.\n【待收集信息】\n>> [Information to Collect]\n"}, {"page": 21, "text": "鼻痒、眼痒、皮疹情况；症状是否季节性；既往过敏史。\n>> Itchy nose, itchy eyes, rash condition; whether symptoms are seasonal; past history of allergies.\n【回复策略】\n>> [Response Strategy]\n给出阶段性建议，同步补充收集关键信息。\n>> Give phased advice while simultaneously collecting key information.\n【回复】\n>> [Response]\n初步考虑过敏性鼻炎。请问孩子有鼻痒、眼痒或皮疹吗？症状是否春天加重？可进一步咨询医师明确过敏原，\n制定治疗方案。\n>> Preliminary consideration is allergic rhinitis. Does the child have itchy nose, itchy eyes or rash? Do\nsymptoms worsen in spring? You can further consult a physician to clarify allergens and formulate a\ntreatment plan.\n这是你与患者的对话历史：\n» This is the history of your dialogue with the patient:\n{历史对话}\n» {Dialogue_History}\n这是患者的最新消息：\n» This is the latest message from the patient:\n{最新消息}\n» {Latest_Message}\n这是患者的症状：\n» This is the patient’s symptom:\n{主诉症状}\n» {Symptom}\n### 生成要求###\n» ### Generation Requirements ###\n1. 严格遵循模板格式\n» 1. Strictly follow the template format\n2.【诊断】仅考虑本模板疾病，不加前缀\n» 2. The [Diagnosis] field must only contain the disease corresponding to this template, without\nany prefix.\n3. 每次聚焦1-2 个关键确认问题(即回复时只提问1-2 个关键问题)，其后给出可执行的治疗\n与就医建议\n» 3. Focus on 1-2 key confirmation questions each time (i.e., ask only 1-2 key questions when\nreplying), followed by actionable treatment and medical advice\n4. 语言简洁，剂量清晰，避免过度专业术语；强调安全性与随访\n» 4. Language should be concise, dosage should be clear, avoid excessive professional terminology,\nemphasize safety and follow-up\n5. 明确何时需急诊或尽快就医\n» 5. Clearly state when emergency or immediate medical attention is needed\n6. 回答时，如果涉及到药品信息，仅回复药品名和使用方式即可，禁止说明药品使用的剂\n量、频率、周期等\n» 6. When answering, if drug information is involved, only reply with the drug name and usage\nmethod, and it is forbidden to explain the dosage, frequency, cycle, etc. of the drug use\n"}, {"page": 22, "text": "患者模拟器提示词(Patient Simulator Prompt for Inquiry Dialogue Synthesis)\n你是一个患者，请根据以下患者画像信息和历史对话，生成一个自然、真实的患者回复。\n» You are a patient. Please generate a natural and realistic patient response based on the following\npatient profile information and dialogue history.\n患者画像信息：\n» Patient Profile Information:\n{患者画像}\n» {Patient_Profile}\n历史对话：\n» Dialogue History:\n{历史对话}\n» {Dialogue_History}\n请基于以上信息，以患者的身份回复医生。要求：\n» Please respond to the doctor as a patient based on the above information. Requirements:\n1. 回复要符合患者的年龄、性别、症状特征和语气风格\n» 1. The response should match the patient’s age, gender, symptom characteristics and tone style\n2. 回复要自然口语化，不要过于正式或书面化\n» 2. The response should be natural and colloquial, not too formal or literary\n3. 回复要针对医生上一轮的询问或建议\n» 3. The response should address the doctor’s inquiry or suggestion in the previous round\n4. 不要包含任何思考过程或分析，直接输出患者的回复\n» 4. Do not include any thinking process or analysis, directly output the patient’s response\n5. 禁止将无关联的症状强行关联\n» 5. Do not forcibly associate unrelated symptoms\n6. 如果涉及到药品信息，仅回复药品名和使用方式即可，禁止说明药品使用的剂量、频率、\n周期等\n» 6. If drug information is involved, only reply with the drug name and usage method, and it is\nforbidden to explain the dosage, frequency, cycle, etc. of the drug use\n注意：你所说的话必须符合客观事实\n» Note: What you say must be consistent with objective facts\n患者回复：\n» Patient Response:\nE.3\nPrompt for QA-pair Data Synthesis\nQA 数据生成提示词(QA-pair Data Synthesis Prompt)\n基于以下【参考答案】，生成1 道临床考试问题：\n» Based on the following [Reference Answer], generate 1 clinical examination question:\n【参考答案】：\n"}, {"page": 23, "text": "» [Reference Answer]:\n{抽取片段}\n» {Extracted_Content}\n要求：\n» Requirements:\n1.【问题】需基于上述其他信息以及【参考答案】设计，考查临床知识。【问题】不需要有实\n际场景，但每个答案都需要有对应问题。\n» 1. The [Question] should be designed based on the above information and [Reference Answer]\nto test clinical knowledge. The [Question] does not need a real scenario, but each answer must\nhave a corresponding question.\n2.【问题】只能是主观题，不能是选择题和判断题。不可生成没有对应【参考答案】的问题。\n不可出现“{症状}” 字样，因为这需要考察学生对这个症状的敏感度。\n» 2. The [Question] can only be a subjective question, not multiple-choice or true/false. Do not\ngenerate questions without corresponding [Reference Answer]. Do not include “{Symptom}” text,\nas this is intended to test the student’s sensitivity to the symptom.\n3.【参考答案】需要根据【问题】添加“胶水词” 连接成完整的一段话，可以调换片段顺序，\n但必须紧密贴合原始片段的所有语意。\n» 3. The [Reference Answer] needs to add “connecting words” according to the [Question] to form\na complete paragraph. The order of segments can be rearranged, but must closely adhere to all\nthe semantics of the original segments.\n4.【参考答案】需要包含“{症状}” 的信息。\n» 4. The [Reference Answer] must contain information about “{Symptom}”.\n5.【参考答案】中的医学信息只能从原始片段中来，不可以擅自补全。\n» 5. Medical information in the [Reference Answer] can only come from the original segments\nand cannot be arbitrarily supplemented.\n6. 确保参考答案准确反映诊疗要点。总字数控制在800 字以内。\n» 6. Ensure the reference answer accurately reflects diagnostic and treatment key points. Total\nword count should be within 800 characters.\n格式：\n» Format:\n【参考答案】\n>> [Reference Answer]\n【问题】\n>> [Question]\n"}, {"page": 24, "text": "F\nPrompt for Evaluation\nF.1\nData Generation Prompt for ICD-Recall and ICD-Precision Metric\nICD 测评数据患者模型提示词(Patient Model Prompt for ICD Metric)\n你是一位患者，以下是你的个人信息：\n» You are a patient. Below is your personal information:\n{患者画像}\n» {Patient_Profile}\n以下是之前的对话历史：\n» Below is the previous dialogue history:\n{历史对话}\n» {Dialogue_History}\n你的角色要求：\n» Your role requirements:\n1. 严格遵循画像中的信息，不可无中生有捏造\n» 1. Strictly follow the information in the profile, do not fabricate information.\n2. 基于历史对话，自然回应医生的提问/建议，或主动询问关心的问题\n» 2. Based on the dialogue history, respond naturally to the doctor’s questions/suggestions, or\nproactively ask about concerns.\n3. 不提前透露未在画像中提及的信息\n» 3. Do not reveal information not mentioned in the profile in advance.\n4. 只输出语言信息，不输出神态/动作信息\n» 4. Output only verbal information, do not describe expressions or actions.\n5. 请直接输出回复内容，不要输出思考过程。\n» 5. Please output the response content directly, do not output the thought process.\n输出格式：\n» Output format:\n患者：\n» Patient:\nICD 测评数据被测试模型(医生) 提示词(Tested-model (Physician) Prompt for ICD\nMetric)\n你是一位内科医生，需要为患者提供专业、耐心的医疗指导。\n» You are an internal medicine physician, expected to provide professional and compassionate medi-\ncal guidance.\n以下是之前的对话历史：\n» Below is the previous dialogue history:\n{历史对话}\n» {Dialogue_History}\n"}, {"page": 25, "text": "你的角色要求：\n» Your role requirements:\n1. 提问需明确，帮助进一步了解病情\n» 1. Questions must be clear to facilitate further understanding of the condition.\n2. 建议具体可行，符合诊疗常识\n» 2. Recommendations must be specific, feasible, and consistent with clinical practice.\n3. 只输出语言信息，不输出神态/动作信息\n» 3. Output only verbal information, do not describe expressions or actions.\n输出格式要求：\n» Output format requirements:\n医生：\n» Doctor:\n【诊断】（仅写病名，如不确定可写疑似）\n» [Diagnosis] (Only write the disease name, if uncertain, write “suspected”)\n【回复】xxxx\n» [Response] xxxx\nF.2\nData Generation Prompt in Satisfaction Metric\n满意度测评数据生成提示词( Data Generation Prompt for Satisfication)\n## 你是专业临床医生，请根据你与患者的历史对话、诊疗模板（症状需要收集的病情、症状\n的鉴别诊断），生成3 个回复\n## You are a professional clinician. Please generate 3 responses based on your dialogue history with\nthe patient and the diagnostic template (conditions to collect for symptoms, differential diagnosis of\nsymptoms)\n患者信息：{性别}，{年龄}\n» Patient Information: {Sex}, {Age}\n这是你与患者的历史对话：\n» This is your dialogue history with the patient:\n{历史对话}\n» {Dialogue_History}\n这是患者的最新消息：\n» This is the latest message from the patient:\n{最新消息}\n» {Latest_Message}\n## 要求：\n» ## Requirements:\n1. 对于每个【回复】，优先回答患者的需求，照顾患者害怕担忧等情绪。再进行诊疗。\n» 1. For each [Response], prioritize addressing the patient’s needs and caring for their emotions\nsuch as fear and worry. Then proceed with diagnosis and treatment.\n"}, {"page": 26, "text": "2. 其次，若能给出诊断，则需要优先给出。\n» 2. Secondly, if a diagnosis can be made, it should be provided first.\n3. 若患者回复仅为“好的”“谢谢” 等无诊疗信息陈述句，则【回复1】优先祝福患者早日康\n复！\n» 3. If the patient’s reply is merely a declarative sentence without diagnostic information such as\n“OK” or “Thank you”, [Response 1] should prioritize wishing the patient a speedy recovery!\n4. 输出格式为：每个回复不超过100 字，且每个【回复】独立存在\n【回复1】\n【回复2】\n【回复3】\n» 4. Output format: each response should not exceed 100 characters, and each [Response] should\nbe independent.\n» [Response 1]\n» [Response 2]\n» [Response 3]\n5. 若有诊疗需要的提问，每个【回复】提问不超过两个问号！\n» 5. If there are questions needed for diagnosis and treatment, each [Response] should contain no\nmore than two question marks!\n6. 若有用药，不可给出明确剂量！\n» 6. If medication is mentioned, do not specify exact dosage!\n7. 不可重复医生说过的话！\n» 7. Do not repeat what the doctor has already said!\n例如：\n» For Example:\n【回复1】\n>> [Response 1]\naaaaa\n【回复2】\n>> [Response 2]\nbbbbbbbbbb\n【回复3】\n>> [Response 3]\nccccccccc\n## 请输出3 个回复：\n» ## Please output 3 responses:\n"}, {"page": 27, "text": "G\nData Demos\nG.1\nCDRD\n结构化的临床诊断推理数据(CDRD)\n主症状\n» Chief Symptom\n咳嗽\n» Cough\n病情收集\n» Symptom Collection\n1. 咳嗽的性质: 干咳、有痰\n» 1. Nature of Cough: Dry cough, productive cough (with sputum)\n2. 咳嗽的时间: 几天、几个月、几年加重几天\n» 2. Duration of Cough: Days, months, years, aggravation for days\n3. 咳嗽的音色: 咳嗽嘶哑、鸡鸣样咳嗽、咳嗽声音低微\n» 3. Timbre of Cough: Hoarse cough, whooping cough, weak cough sound\n4. 痰的性质: 粘液性痰、泡沫样痰、脓性痰、痰中带血\n» 4. Nature of Sputum: Mucous sputum, frothy sputum, purulent sputum, blood-stained sputum\n5. 痰量: 少、多\n» 5. Sputum Amount: Scant, copious\n6. 伴随症状: 伴发热、伴胸痛、伴咳血、伴脓痰、伴哮喘、伴呼吸困难、咽干，咽痒，咽痛，\n鼻塞，喷嚏，流清涕\n» 6. Accompanying Symptoms: With fever, with chest pain, with hemoptysis, with purulent\nsputum, with asthma, with dyspnea, dry throat, itchy throat, sore throat, nasal congestion, sneezing,\nclear runny nose\n诊断考虑\n» Diagnosis Considerations\n1. 上呼吸道感染\n» 1. Upper Respiratory Tract Infection\n疾病特点: 起病较急，几天。表现为咳嗽，咽干，咽痒，甚至咽痛，伴有鼻部症状如鼻塞，\n喷嚏，流清涕。病原体多为病毒，少数为细菌。\n» Disease Features: Acute onset, days. Manifested as cough, dry throat, itchy throat, even sore\nthroat, accompanied by nasal symptoms such as nasal congestion, sneezing, clear runny nose.\nPathogens are mostly viruses, occasionally bacteria.\n实验室检查: 白细胞计数正常或偏低，伴淋巴细胞比例偏高。\n» Laboratory Tests: WBC count normal or low, with elevated lymphocyte percentage.\n治疗反应: 多饮水、保持室内空气流通和防治继发性细菌感染。一般5～7 天痊愈，伴发并\n发症者可致病程迁延。\n» Treatment Response: Drink plenty of water, maintain indoor air circulation, and prevent sec-\nondary bacterial infection. Generally recovers in 5-7 days, complications may prolong the course.\n2. 急性支气管炎\n» 2. Acute Bronchitis\n"}, {"page": 28, "text": "疾病特点: 常起病较急，几天，发生于寒冷季节或气候突变时，也可由急性上呼吸道感染\n迁延不愈所致。全身症状较轻，可有发热。初为干咳或少量黏痰。\n» Disease Features: Often acute onset, days, occurring in cold seasons or during weather changes,\nor may result from unresolved acute upper respiratory infection. Mild systemic symptoms, possible\nfever. Initially dry cough or scant mucous sputum.\n实验室检查: 周围血白细胞计数可正常，但由细菌感染引起者，可伴白细胞总数和中性粒\n细胞百分比升高。血沉加快，痰培养可见致病菌。\n» Laboratory Tests: Peripheral WBC count may be normal, but in bacterial infection, total WBC\nand neutrophil percentage may be elevated. ESR increased, sputum culture may show pathogenic\nbacteria.\n影像学检查: X 线胸片大多为肺纹理增强，少数无异常发现。\n» Imaging: Chest X-ray mostly shows increased lung markings, few show no abnormalities.\n3. 肺部感染性疾病\n» 3. Pulmonary Infectious Diseases\n疾病特点: 常见症状为咳嗽、咳痰，或原有呼吸道症状加重，并出现脓性痰或血痰，伴或\n不伴胸痛。病变范围大者可有呼吸困难、呼吸窘迫。大多数病人有发热。\n» Disease Features: Common symptoms include cough, sputum production, or worsening of exist-\ning respiratory symptoms, with purulent or bloody sputum, with or without chest pain. Extensive\nlesions may cause dyspnea or respiratory distress. Most patients have fever.\n确定病原体: 血培养和痰培养分离到相同细菌，可确定为肺炎的病原菌。测定特异性IgM\n抗体滴度，可判断支原体、衣原体、嗜肺军团菌和病毒感染等。\n» Pathogen Identification: Isolation of the same bacteria from blood and sputum cultures can con-\nfirm the pathogen of pneumonia. Measuring specific IgM antibody titers can identify Mycoplasma,\nChlamydia, Legionella pneumophila, and viral infections.\n影像学检查: X 线胸片多为肺实质浸润表现。\n» Imaging: Chest X-ray mostly shows pulmonary parenchymal infiltration.\n治疗反应: 抗感染治疗：选择可能覆盖病原体的抗菌药物，抗感染治疗有效。\n» Treatment Response: Anti-infective therapy: select antibiotics that may cover the pathogens,\nanti-infective treatment is effective.\nG.2\nInquiry Example with Reasoning\n带推理的对话示例(Inquiry Example with Six Reasoning Steps)\n输入/提示词\n» Input/Prompt\n历史:\n» History:\n患者: 咳嗽、喉咙痒，术后伤口长肉芽发炎\n» Patient: Cough, itchy throat, granulation tissue inflammation in postoperative wound.\n医生: 请问咳嗽持续了几天？是否有痰液或发热？\n建议：多饮温水、保持空气湿润，术后伤口需每日消毒（如碘伏），若伤口红肿加重或出现\n脓液，请立即就医。\n"}, {"page": 29, "text": "» Doctor: How long has the cough lasted? Any sputum or fever?\n» Advice: Drink warm water, keep air humid, disinfect wound daily with iodine, if redness worsens\nor pus appears, seek medical help immediately.\n患者: 咳嗽三四天了，没痰也不发烧。\n» Patient: Coughing for 3-4 days, no sputum, no fever.\n医生: 请问咳嗽时是否伴有咽干、咽痒或鼻塞？术后伤口是否有胸痛或呼吸困难？\n建议：多饮温水、保持空气湿润，可尝试使用右美沙芬止咳糖浆（具体用法遵说明书）。若\n咳嗽持续加重、出现痰液或发热，请及时就医。\n» Doctor: Is the cough accompanied by dry/itchy throat or nasal congestion? Any chest pain or\ndifficulty breathing at the wound site?\n» Advice: Drink warm water, keep air humid, try Dextromethorphan cough syrup (follow instruc-\ntions). If cough worsens, sputum or fever appears, seek medical help.\n患者: 有咽痒，伤口没胸痛或呼吸困难。\n» Patient: Have itchy throat, no chest pain or breathing difficulty at the wound.\n医生: 请问咳嗽时是否伴有鼻塞或流清涕？近期是否接触过花粉、宠物等过敏原？\n建议：继续使用右美沙芬止咳糖浆（具体用法遵说明书），保持空气湿润，避免刺激性气\n体。若咳嗽持续超过1 周或出现发热、痰液，请及时就医。术后伤口需每日碘伏消毒，若\n红肿加重或有脓液，请立即就诊。\n» Doctor: Is the cough accompanied by nasal congestion or clear runny nose? Have you been in\ncontact with allergens such as pollen or pets recently?\n» Advice: Continue using Dextromethorphan cough syrup (follow instructions), keep air humid,\navoid irritating gases. If cough persists >1 week or fever/sputum appears, seek medical help. Dis-\ninfect wound daily with iodine, if redness worsens or pus appears, seek medical help immediately.\n最新消息/患者: 没鼻塞流涕，没接触过敏原。\n» Latest Message - Patient: No nasal congestion or runny nose, no contact with allergens.\n模型输出/推理与回复\n» Model Output - Reasoning & Response\n【已知信息】\n>> [Known Information]\n咳嗽3-4天，干咳伴咽痒，无痰、无发热、无鼻塞流涕，术后伤口无胸痛或呼吸困难，未接触过敏原。\n>> Cough for 3-4 days, dry cough with itchy throat, no sputum, no fever, no nasal congestion or runny\nnose, no chest pain or dyspnea at wound site, no allergen contact.\n【待解决用户需求】\n>> [User Needs to Address]\n明确咳嗽病因，排除感染或术后并发症，指导用药及伤口护理。\n>> Identify the cause of cough, exclude infection or postoperative complications, provide medication and\nwound care guidance.\n【已提供给用户信息】\n>> [Information Provided to User]\n已排除过敏性鼻炎典型症状（鼻塞流涕），建议使用右美沙芬止咳，伤口需碘伏消毒。\n>> Excluded typical allergic rhinitis symptoms (nasal congestion and runny nose), advised\nDextromethorphan for cough, wound needs iodine disinfection.\n【诊断】\n>> [Diagnosis]\n急性支气管炎\n>> Acute Bronchitis\n【待收集信息】\n>> [Information to Collect]\n"}, {"page": 30, "text": "咳嗽是否伴有胸痛或呼吸困难？术后伤口是否有红肿加重或脓液？\n>> Is the cough accompanied by chest pain or diﬀiculty breathing? Is there worsening redness/swelling or\npus at the wound site?\n【回复策略】\n>> [Response Strategy]\n聚焦关键点（胸痛/呼吸困难提示肺部感染，伤口感染需急诊），同步强化居家护理建议。\n>> Focus on key points (chest pain/dyspnea suggests lung infection; wound infection needs ER), reinforce\nhome care advice.\n【回复】\n>> [Response]\n请问咳嗽时是否伴有胸痛或呼吸困难？术后伤口目前是否有红肿加重或脓液？\n>> Does the cough come with chest pain or diﬀiculty breathing? Is the postoperative wound currently\nshowing increased redness, swelling, or pus?\n建议继续使用右美沙芬止咳糖浆（具体用法遵说明书），保持空气湿润，多饮温水。术后伤口需每日碘伏消\n毒，若出现红肿加重、脓液或发热，请立即就医。\n>> I recommend continuing Dextromethorphan cough syrup (follow instructions), keeping the air humid,\nand drinking warm water. Disinfect the wound daily with iodine; if redness worsens, pus appears, or fever\ndevelops, seek medical attention immediately.\nG.3\nQA Pair\nQA 数据示例(QA Data Examples)\n【问题1】\n» [Question 1]\n请简述在对某一呼吸系统症状进行问诊时，应如何全面评估患者的呼吸道分泌物及相关表\n现？\n» Please briefly describe how to comprehensively evaluate a patient’s respiratory secretions and re-\nlated manifestations when taking a history for a respiratory symptom.\n【参考答案1】\n» [Reference Answer 1]\n患者无咳嗽，但若出现咳嗽，应注意其音色是否嘶哑或呈鸡鸣样，声音是否低微；同时应观\n察咳出物的性质，如是否为粘液性、泡沫样、脓性或痰中带血；痰量的多少也是重要的评估\n内容，需判断为少量或大量；此外，还需注意是否伴有其他相关症状，以帮助明确病因和诊\n断。\n» The patient has no cough, but if cough occurs, attention should be paid to whether the sound is\nhoarse or whooping, and whether the voice is weak. At the same time, the nature of the sputum\nshould be observed, such as whether it is mucous, frothy, purulent, or blood-stained sputum. The\namount of sputum is also an important aspect of the assessment, and it should be determined as scant\nor copious. In addition, attention should be paid to whether there are other related symptoms to help\nclarify the etiology and diagnosis.\n【问题2】\n» [Question 2]\n请简述肺炎的常见临床表现，并说明在临床诊断中为何不能仅依赖“咳嗽” 这一症状进行判\n断。同时，请指出实验室检查在肺炎诊疗中的作用。\n» Please briefly describe the common clinical manifestations of pneumonia, and explain why clinical\ndiagnosis cannot rely solely on the symptom of “cough”. Also, please indicate the role of laboratory\ntests in the diagnosis and treatment of pneumonia.\n"}, {"page": 31, "text": "【参考答案2】\n» [Reference Answer 2]\n肺炎是一种常见的呼吸系统感染性疾病，其典型临床表现包括咳嗽、咳痰，部分患者痰中可\n带血，常伴有发热、寒战和乏力等症状。在病情较重时，患者可能出现胸痛或呼吸困难。值\n得注意的是，并非所有患者都会出现咳嗽症状，因此在临床诊断中应综合考虑其他表现。实\n验室检查是明确诊断的重要手段，有助于判断感染类型及严重程度，从而指导后续治疗。\n» Pneumonia is a common respiratory infectious disease. Its typical clinical manifestations include\ncough and sputum production, some patients may have blood-stained sputum, often accompanied\nby fever, chills, and fatigue. In severe cases, patients may experience chest pain or dyspnea. It is\nworth noting that not all patients will present with cough symptoms, so clinical diagnosis should\ncomprehensively consider other manifestations. Laboratory tests are an important means of confirm-\ning the diagnosis, helping to determine the type and severity of infection, thereby guiding subsequent\ntreatment.\nG.4\nPatient Profile\n患者画像示例(Patient Profile Example)\n年龄: 45 岁\n» Age: 45 years old\n性别: 男\n» Gender: Male\n性格特征: 较为顺从，对医生建议接受度高，但因病情反复而略显沮丧，经常询问病情进展。\n» Personality Traits: Relatively compliant, high acceptance of doctor’s advice, but slightly frustrated\ndue to recurring illness, frequently asks about disease progression.\n语气特征: 语气平和但带有担忧，对治疗效果和未来预后表示关心。\n» Tone Characteristics: Peaceful tone but with worry, concerned about treatment effect and future\nprognosis.\n发言字数: 每次发言字数中等，约25-45 字。\n» Speaking Word Count: Medium length per speech, about 25-45 words.\n症状: 右肺中叶见磨玻璃样小结节，伴有长期干咳，夜间加重，有过敏性鼻炎史，偶有咽痛，\n吸烟。\n» Symptoms: Ground-glass nodule in the right middle lobe, accompanied by chronic dry cough,\nworse at night, history of allergic rhinitis, occasional sore throat, smoker.\n诊断: 咳嗽变异性哮喘，肺部磨玻璃结节（考虑良性）。\n» Diagnosis: Cough variant asthma, pulmonary ground-glass nodule (considered benign).\n其他信息: 使用吸入性糖皮质激素后症状减轻，但停药后易复发，有10 年吸烟史，过敏性鼻\n炎定期发作。\n» Other Information: Symptoms alleviated after using inhaled corticosteroids, but prone to relapse\nafter stopping medication, 10-year smoking history, periodic attacks of allergic rhinitis.\n第一句话: “最近三个月一直干咳乏力。”\n» First Sentence: “I’ve had a dry cough and fatigue for the last three months.”\n"}, {"page": 32, "text": "G.5\nReal Clinical Inquiry Dialogue in Bench\n测评集中的真实临床问诊记录(Real Clinical Inquiry Dialogue Example in Bench)\n这是你与患者的历史对话：\n» This is the history of your dialogue with the patient:\n患者: 左右肩膀后背疼痛一个月，偶尔胸口疼，有高血压病史，未进行心电图或心脏相关检\n查。（匿名，女，35 岁）\n» Patient: Pain in both shoulders and back for a month, occasional chest pain, history of hypertension,\nno ECG or heart-related examinations. (Anonymous, Female, 35 years old)\n医生: 高血压控制得如何？最近有没有监测过血压？\n» Doctor: How is the hypertension controlled? Have you monitored your blood pressure recently?\n医生: 平时有肥胖血脂高吗\n» Doctor: Do you have obesity or high blood lipids?\n患者: 胖，但是血脂高不高不知道，没查过，应该是不高\n» Patient: I am overweight, but I don’t know if my blood lipids are high, I haven’t checked, presumably\nnot high.\n医生: 不一定\n» Doctor: Not necessarily.\n这是患者的最新消息：\n» This is the latest message from the patient:\n患者: 血压就高时候一百五左右，低压九十或者一百\n» Patient: When blood pressure is high, it is around 150, diastolic 90 or 100.\n"}]}