{"doc_id": "arxiv:2511.06000", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2511.06000.pdf", "meta": {"doc_id": "arxiv:2511.06000", "source": "arxiv", "arxiv_id": "2511.06000", "title": "LLMs Do Not See Age: Assessing Demographic Bias in Automated Systematic Review Synthesis", "authors": ["Favour Yahdii Aghaebe", "Tanefa Apekey", "Elizabeth Williams", "Nafise Sadat Moosavi"], "published": "2025-11-08T13:12:36Z", "updated": "2025-12-19T02:07:06Z", "summary": "Clinical interventions often hinge on age: medications and procedures safe for adults may be harmful to children or ineffective for older adults. However, as language models are increasingly integrated into biomedical evidence synthesis workflows, it remains uncertain whether these systems preserve such crucial demographic distinctions. To address this gap, we evaluate how well state-of-the-art language models retain age-related information when generating abstractive summaries of biomedical studies. We construct DemogSummary, a novel age-stratified dataset of systematic review primary studies, covering child, adult, and older adult populations. We evaluate three prominent summarisation-capable LLMs, Qwen (open-source), Longformer (open-source) and GPT-4.1 Nano (proprietary), using both standard metrics and a newly proposed Demographic Salience Score (DSS), which quantifies age-related entity retention and hallucination. Our results reveal systematic disparities across models and age groups: demographic fidelity is lowest for adult-focused summaries, and under-represented populations are more prone to hallucinations. These findings highlight the limitations of current LLMs in faithful and bias-free summarisation and point to the need for fairness-aware evaluation frameworks and summarisation pipelines in biomedical NLP.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2511.06000v2", "url_pdf": "https://arxiv.org/pdf/2511.06000.pdf", "meta_path": "data/raw/arxiv/meta/2511.06000.json", "sha256": "b24e14533b45f3669cacdc07ff6455a766e162e502e9de75ac73ccb3d48052e1", "status": "ok", "fetched_at": "2026-02-18T02:28:08.265654+00:00"}, "pages": [{"page": 1, "text": "LLMs Do Not See Age: Assessing Demographic Bias in Automated\nSystematic Review Synthesis\nFavour Yahdii Aghaebe*†, Tanefa Apekey‡, Elizabeth Williams§†, Nafise Sadat Moosavi*\nUniversity of Sheffield, UK\n{fyaghaebe1, t.apekey, e.a.williams, n.s.moosavi}@sheffield.ac.uk\nAbstract\nClinical interventions often hinge on age: med-\nications and procedures safe for adults may\nbe harmful to children or ineffective for older\nadults.\nHowever, as language models are\nincreasingly integrated into biomedical evi-\ndence synthesis workflows, it remains uncertain\nwhether these systems preserve such crucial de-\nmographic distinctions. To address this gap,\nwe evaluate how well state-of-the-art language\nmodels retain age-related information when\ngenerating abstractive summaries of biomed-\nical studies. We construct DemogSummary, a\nnovel age-stratified dataset of systematic review\nprimary studies, covering child, adult, and older\nadult populations. We evaluate three prominent\nsummarisation-capable LLMs, Qwen (open-\nsource), Longformer (open-source) and GPT-\n4.1 Nano (proprietary), using both standard\nmetrics and a newly proposed Demographic\nSalience Score (DSS), which quantifies age-\nrelated entity retention and hallucination. Our\nresults reveal systematic disparities across mod-\nels and age groups: demographic fidelity is\nlowest for adult-focused summaries, and under-\nrepresented populations are more prone to hal-\nlucinations. These findings highlight the lim-\nitations of current LLMs in faithful and bias-\nfree summarisation and point to the need for\nfairness-aware evaluation frameworks and sum-\nmarisation pipelines in biomedical NLP.\n1\nIntroduction\nThe use of large language models (LLMs) to en-\nhance the efficiency of scientific research and clini-\ncal practice has become increasingly common. In\nparticular, LLMs have shown promise in accelerat-\ning labour-intensive processes such as systematic\nreviews. These models are now being explored\n*School of Computer Science\n†Healthy Lifespan Institute\n‡Sheffield Centre for Health and Related Research\n§Department of Oncology and Metabolism\nat various stages of the review pipeline, includ-\ning abstract identification and screening (Delgado-\nChaves et al., 2025), offering the potential to reduce\ntime and cost in evidence synthesis.\nDespite these advances, concerns are emerging\nabout the potential biases introduced by LLMs\nwhen applied to domains involving sensitive or\nunderrepresented populations. Recent studies sug-\ngest that LLMs may exhibit demographic bias in\ntheir outputs (Kamruzzaman et al., 2024). In the\ncontext of systematic reviews, which often inform\nhigh-stakes decisions in medicine and policy, such\nbiases pose serious risks. The process by which\nLLMs synthesise and preserve critical demographic\ninformation, specifically with narrative synthesis,\nwhere findings from individual studies are sum-\nmarised, remains largely unexamined.\nThis presents a critical gap: while LLMs are\nincreasingly used in summarising biomedical lit-\nerature, little is known about their ability to retain\ndemographic and population information, partic-\nularly age-related descriptors which are integral\naspects of the systematic review. Misrepresenta-\ntion or omission of such details can compromise\nboth clinical relevance and health equity, reinforc-\ning the very disparities such systematic reviews are\ndesigned to reduce.\nBuilding on existing work that treats narrative\nsynthesis as a form of multi-document summarisa-\ntion (DeYoung et al., 2024; Wallace et al., 2021),\nwe investigate how well LLMs preserve demo-\ngraphic integrity, specifically age-related descrip-\ntors, when approximating a systematic review ab-\nstract from the abstracts of included primary stud-\nies. To support this investigation, we construct\nDemogSummary, an age-stratified dataset of sys-\ntematic reviews and primary studies grouped by\npopulation, and propose the Demographic Salience\nScore (DSS), a composite metric that quantifies\nentity-level retention, omission, and hallucination\nof age-related information. Using this framework,\narXiv:2511.06000v2  [cs.CL]  19 Dec 2025\n"}, {"page": 2, "text": "we assess the summarisation performance of three\nstate-of-the-art LLMs across child, adult, and older\nadult populations. Our results reveal that fidelity\nto demographic information is not uniform. Sum-\nmaries concerning adult populations show the low-\nest retention of age-related content and the high-\nest incidence of hallucinated descriptors, while\nthose focused on children and older adults show\ngreater accuracy. Across models, GPT-4.1 Nano\n(OpenAI, 2023) and Longformer (Beltagy et al.,\n2020) demonstrate stronger demographic preserva-\ntion than Qwen-2.5 (Yang et al., 2025), though all\nexhibit limitations in faithfully synthesising age-\nspecific biomedical content. These findings high-\nlight the need to move beyond generic evaluation\nmetrics and toward assessments capturing demo-\ngraphic fidelity in biomedical summarisation. Our\ncontributions are threefold:\n• Presenting a novel age-stratified dataset\nof\nsystematic\nreview\nprimary\nstudies\n(DemogSummary), grouped by population\n(children, adults, older adults), designed to\nsupport\ndemographic-specific\nevaluation\nof summarisation models in biomedical\ndomains.\n• Identifying systematic disparities in how\nLLMs preserve age-related information dur-\ning multi-document summarisation, highlight-\ning representational gaps that are obscured by\nconventional evaluation metrics.\n• Introducing the Demographic Salience Score,\na targeted metric that quantifies the retention,\nomission, and hallucination of demographic\nentities, enabling a fairness-aware assessment\nof summarisation fidelity.\n2\nRelated Work\n2.1\nAutomatic Systematic Reviews\nData extraction and synthesis represent the most\nresource-intensive and error-prone phases within\nthe systematic review workflow, often requiring\nsignificant manual effort and rigour. Surveys of\nprofessionals involved in systematic reviews rein-\nforce this notion; 45% of respondents in one study\nof 194 professionals identified data extraction as\nthe most time-consuming stage (Scott et al., 2021).\nConsequently, there has been an increased focus on\nautomating these steps, particularly using LLMs\n(Ge et al., 2024; Schmidt et al., 2023). While LLMs\nhave shown promise in biomedical information ex-\ntraction, their accuracy remains inconsistent across\ntasks and domains. More broadly, concerns have\nemerged about their tendency to amplify societal bi-\nases, especially in high-stakes fields like medicine.\nBiases in training data, model design, and linguis-\ntic priors can lead to unequal treatment of groups\nbased on attributes such as race (Yang et al., 2024)\nand gender (Bajaj et al., 2024; Tang et al., 2024),\nresulting in harms like stereotyping and misasso-\nciation (Gallegos et al., 2024). Yet demographic\nattributes like age remain underexplored in bias\nevaluations, particularly in biomedical synthesis.\nAutomatic summarisation selects and integrates key\ncontent from one or more documents to produce\na concise, informative output (Nenkova and McK-\neown, 2011). This task is increasingly important\nin the biomedical domain, where the exponential\ngrowth of publications makes manual synthesis dif-\nficult to scale (Pawar et al., 2023). In particular,\nmulti-document summarisation offers a promising\nway to approximate the narrative synthesis found\nin systematic reviews. As LLMs are increasingly\nadopted for this purpose, it becomes essential to\nexamine not only their efficiency, but also how reli-\nably and equitably they preserve critical population-\nspecific information.\n2.2\nBias in Automated Synthesis and\nSummarisation\nDespite the promise of LLMs for multi-document\nbiomedical summarisation, their outputs often re-\nflect biases that can distort or omit critical demo-\ngraphic information. This is especially concerning\nin systematic reviews, where under-representation\nor misrepresentation of population groups may\nhave direct clinical and policy implications. Prior\nwork has examined bias in summarisation across\ndomains such as news (Steen and Markert, 2024a),\nopinion generation (Huang et al., 2023, 2024), and\nradiology reports (Seyyed-Kalantari et al., 2021;\nNguyen et al., 2024). However, biomedicine has re-\nceived little attention, particularly in narrative syn-\nthesis of systematic reviews, where omissions or\nhallucinations of population-specific information\ncan compromise the validity of clinical evidence.\nFairness and bias have been long-standing con-\ncerns in NLP (Bolukbasi et al., 2016; Bender and\nFriedman, 2018; Blodgett et al., 2020; Tang et al.,\n2024), though their definitions are often inconsis-\ntent across tasks and domains. We draw on the\nframework posited by Crawford (2017), which dis-\n"}, {"page": 3, "text": "Figure 1: Age-stratified primary study abstracts are summarised by LLMs, and the outputs are compared to\nsystematic review abstracts. Summaries are evaluated by age group for demographic fidelity using retention,\nomission, and hallucination metrics.\ntinguishes between two forms of algorithmic bias:\nallocative bias, which affects access to resources,\nand representational bias, which misrepresents or\nexcludes certain groups (Sun et al., 2019; Suresh\nand Guttag, 2021). This study focuses on repre-\nsentational bias, particularly the loss or distortion\nof age-related information in generated summaries.\nWe adopt the definition of an unbiased summariser\nproposed by Steen and Markert (2024b), which\nemphasises faithful and complete representation of\nrelevant input content.\nEvaluating bias in summarisation presents sev-\neral challenges. In certain domains, researchers\ncan generate synthetic or controlled input texts to\nisolate the effects of bias in model outputs. In\nbiomedical summarisation, however, such input\nmanipulation is impractical, as real clinical stud-\nies must be used to reflect the actual conditions\nand constraints of systematic reviews. To address\nthis, we curate DemogSummary, a real-world, age-\nstratified dataset that allows for population-specific\nevaluation without altering the original inputs. This\ndesign lets us examine representational bias as it\noccurs naturally, while controlling for demographic\nfocus through corpus structure and targeted evalua-\ntion. Another challenge lies in how summaries\nare evaluated: standard automatic metrics such\nas BLEU (Papineni et al., 2002) and BERTScore\n(Zhang et al., 2019) measure surface or semantic\nsimilarity but fail to capture representational distor-\ntions or omissions (Deutsch et al., 2022; Gao and\nWan, 2022). To address this limitation, we com-\nplement existing metrics with a novel evaluation\nmethod: the Demographic Salience Score, which\nquantifies how well age-related demographic enti-\nties are preserved in generated summaries. This al-\nlows us to assess summarisation fidelity through the\nlens of demographic representation, which is an es-\nsential but often overlooked dimension in biomedi-\ncal NLP.\n3\nThe DEMOGSUMMARY Dataset\nExisting systematic review datasets, such as Syn-\nergy (De Bruin et al., 2023), do not support stratifi-\ncation by population age group, which is essential\nfor our analysis. We therefore construct a new\ndataset that enables explicit categorisation of pri-\nmary studies and reviews into child, adult, and\nolder adult populations.\n3.1\nDataset Construction\nSystematic reviews were selected based on the pres-\nence of demographic terms (e.g., ‘Aged‘, ‘Older\nAdult‘, ‘Adult‘, ‘Child‘) in titles or Medical Subject\nHeadings (MeSH) annotations. Searches were con-\nducted in three open-access biomedical databases:\nPubMed (National Center for Biotechnology In-\nformation (NCBI), 1988), Cochrane (Cochrane\nDatabase of Systematic Reviews, 1992), and Web\nof Science (Clarivate, 2025), using combinations\nof ‘systematic review‘ and demographic keywords.\nThis yielded reviews across medical domains, cat-\negorised into three population groups: children\n(aged <18 years), adults (aged 28-59 years), and\nolder adults (60+ years). Inclusion required that\nreviews (i) focus on a single, well-defined demo-\ngraphic group and (ii) cite at least three primary\nstudies with accessible abstracts. Any reviews that\n"}, {"page": 4, "text": "did not comply with (i) and (ii) were excluded. For\neach included review, cited primary studies were\nretrieved via PubMed and PubMed Central iden-\ntifiers (PMIDs/PMCIDs); if unavailable, in-text\nhyperlinks were used. The final dataset qualifies\nunder the UK Parliament (2014) exemption for non-\ncommercial text and data analysis1.\n3.2\nDemographic Annotation\nWe identified demographic information using a\ncombination of rule-based methods and LLM-\nbased named entity recognition; details are in-\ncluded in Appendix B. The resulting dataset in\nAge Group\nReviews\nAvg. Studies per Review\nAdults\n14\n23\nChildren\n15\n32\nOlder Adults\n15\n25\nTable 1: Overview of the DemogSummary Dataset.\nMedical Domain\nNumber of Reviews\nPublic Health\n14\nFrailty\n2\nMental Health\n8\nNutrition and Digestive Health\n9\nCognitive Health\n1\nCardiovascular Health\n5\nPain\n2\nDental and Gut Health\n2\nRespiratory Health\n1\nTotal\n44\nTable 2: Breakdown of the DEMOGSUMMARY Dataset\nby Medical Domain.\nTable 1 includes 14 adult, 15 child, and 15 older\nadult systematic reviews, each comprising primary\nstudies spanning multiple medical domains as de-\nscribed in Table 2. In total, these reviews en-\ncompass approximately 1,200 primary studies. Al-\nthough the dataset consists of 44 systematic re-\nviews, this scale is appropriate given the nature of\nsystematic reviews, which are intended to synthe-\nsise large bodies of evidence and typically include\nmany primary studies each.\n1We\nrelease\nthe\nPubMed\nIDs\nfor\nsystematic\nre-\nviews\nin\nDEMOGSUMMARY\nalongside\nthe\ncode\nat:\nhttps://github.com/Favour-Yahdii/lllms_dont_see_age to sup-\nport transparency, reproducibility, and future research.\n4\nExperimental Design\n4.1\nModel Selection\nWe selected three large language models that reflect\na range of architectures, context-handling capabili-\nties, and access modalities:\nQWEN\n(Qwen/Qwen2.5-14B-Instruct-1M)\n(Yang et al., 2025): a state-of-the-art open-source\nautoregressive transformer model with extended\ncontext length support. QWEN was selected due\nto its ability to process long sequences (up to 1M\ntokens), which is critical for working with multiple\nprimary study abstracts without truncation.\nGPT\n(OpenAI/gpt-4.1-nano) (OpenAI, 2023): a\nproprietary model accessed via the OpenAI API.\nWe included this model as a strong commercial\nbaseline, selected for its favourable trade-off be-\ntween speed and performance in general-purpose\nlanguage understanding tasks.\nLongformer\n(allenai/led-large-16384-arxiv)\n(Beltagy et al., 2020):\na transformer-based\nencoder-decoder model pretrained on scientific\npapers from ArXiv and designed specifically for\nscientific long-document processing, making it\nparticularly suitable for tasks involving structured\nacademic language and domain-specific content.\n4.2\nTask Setup\nEach model is tasked with generating an abstractive\nnarrative synthesis based on the full set of primary\nstudy abstracts from a systematic review. The tar-\nget output is a concise summary approximating the\npublished systematic review abstract. We evaluated\ntwo prompt conditions: a regular prompt, which\ndid not refer to patient demographics, and an age-\naware prompt, which explicitly informed the model\nof the population group involved. Both prompts\nare outlined in (Table 3). This setup enabled as-\nsessment of whether demographic cues influence\nsummarisation behaviour.\n4.3\nImplementation Details\nAll experiments were conducted over approxi-\nmately 90 GPU hours on a single NVIDIA L4.\nInference with GPT-4.1-nano via the OpenAI API\ncost approximately $5 for all reviews, while the\nopen-source models (QWEN and Longformer)\nwere accessed via Hugging Face. More details,\nincluding runtime environment, inference cost, and\nhyperparameters, are provided in Appendix A.\n"}, {"page": 5, "text": "You are an experienced and objective biomedical sys-\ntematic reviewer. Your task is to draft a concise, struc-\ntured abstract that approximates a systematic review ab-\nstract, using the set of provided biomedical research\nabstracts.The provided research abstracts involve\nstudies conducted specifically in {POPULATION\nGROUP} populations. Keep this in mind as you com-\nplete the task. Ensure to produce your summary abstract\nbased only on the provided abstracts. Do not include any\nexternal information or personal opinions. Your sum-\nmary should be a synthesis of the provided abstracts, not\na critique or evaluation of them.\nTable 3: Prompt used for summary generation. The text\nin bold was included only in the age-aware prompt.\n5\nEvaluation Metrics\nWe conducted a supervised evaluation using the\npublished systematic review abstracts as gold stan-\ndards. In addition to standard summarisation met-\nrics, we introduced the Demographic Salience\nScore to assess retention of demographic content.\n5.1\nStandardised Metrics\nWe employed a suite of complementary evaluation\nmetrics to capture different aspects of summarisa-\ntion quality. BLEU (Papineni et al., 2002) mea-\nsures surface-level n-gram overlap with the gold-\nstandard abstract, while BERTScore (Zhang et al.,\n2019) evaluates semantic similarity using contex-\ntual embeddings from a pre-trained transformer.\nTo assess fluency, informativeness, and alignment\nwith expert-authored content, we used BARTScore\n(Yuan et al., 2021) in a supervised setup, where\nthe model computes the likelihood of the generated\nsummary given the gold standard. Lastly, FactCC\n(Kryscinski et al., 2020) was used to assess factual\nconsistency. It classifies each sentence in the gen-\nerated summary by whether it is supported by the\ngold summary or not.\n5.2\nDemographic Salience Score (DSS)\nTo evaluate how effectively demographic informa-\ntion is preserved and conveyed in multi-document\nsummarisation, we introduce the Demographic\nSalience Score (DSS). While this study focuses\non age-related demographic content, the metric\nis generalisable to other demographic dimensions\n(e.g., gender, ethnicity). DSS captures two key\naspects of demographic fidelity: (1) inclusion of\nsalient demographic entities, and (2) penalisation\nof unsupported (hallucinated) content.\nEntity Extraction.\nWe construct a gold-standard\nset of demographic entities by parsing each system-\natic review. Entities related to age are extracted\nusing a combination of rule-based patterns and\nLLM-assisted methods2. These extracted entities\nform the reference set Entgold, which serve as the\nevaluation target.\nTo evaluate the reliability of the demographic\nannotation process, we manually reviewed a strati-\nfied random sample of 60 annotated abstracts, 20\nfrom each age group (children, adults, older adults),\nrepresenting approximately 5% of the total dataset.\nIn this subset, 59 out of 60 annotations (98%)\nwere accurate. Based on this high accuracy rate\nand the diversity of the sample, we considered the\nannotation pipeline to be sufficiently reliable for\ndownstream analysis.\nEach primary study was subsequently cate-\ngorised into one of the following age groups; Child:\n<18 years, Adult: 18–59 years, Older Adult: 60+\nyears.\nFigure 2: Subset of Gold standard Demographic Entities\nfrom Reviews\nScoring Components.\nThe DSS has two main\ncomponents, the Entity Retention Score (ERS) and\nthe Hallucination Penalty (HP). Components such\nas the omission rate are derivatives of these main\ncomponents. We establish Entsummary as the set\nof demographic entities in the generated summary.\nEntity Retention Score (ERS):\nThe proportion\nof gold entities preserved in the generated sum-\nmary. This score reflects how comprehensively\nthe summary captures the reference demographic\ncontent.\nERS = |Entsummary ∩Entgold|\n|Entgold|\n(1)\nOmission Rate. As the complement of ERS, we\ndefine omission as the proportion of gold entities\nmissing from the summary:\nOmission = 1 −ERS\n(2)\nAlthough not part of the DSS formulation, we\nreport omission rates in our results to provide an\nadditional perspective on demographic coverage.\n2Details of these techniques are provided in Appendix B.\n"}, {"page": 6, "text": "Hallucination Penalty (HP):\nThe proportion of\nentities in Entsummary that do not match any en-\ntity in Entgold. A generated entity is considered a\nmatch if it either exactly matches a gold entity or\nexceeds a specified cosine similarity threshold3.\nHP = |Entsummary \\ Match(Entgold)|\n|Entsummary|\n(3)\nOver-length Penalty (OP): In multi-document\nsummarisation, excessively long outputs can artifi-\ncially deflate the hallucination penalty by increas-\ning the total number of extracted entities—thereby\nreducing the proportion of hallucinated content.\nTo account for this, we introduce an over-length\npenalty (OP) that activates when the number of gen-\nerated tokens exceeds a predefined threshold. This\nadjustment ensures that the hallucination penalty\nremains sensitive to unsupported content, regard-\nless of summary length:\nOP = max(0, Tgen −Tmax)\nTmax\n(4)\nwhere Tgen is the number of generated tokens,\nand Tmax is a predefined token limit. The adjusted\nhallucination penalty is then defined as:\nHPadj = HP + OP\n(5)\nDSS:\nThe Demographic Salience Score is com-\nputed as a weighted combination of retention and\npenalty terms:\nDSS = α × ERS −γ × HPadj\n(6)\nWhere α, and γ are non-negative weighting co-\nefficients. To normalise the score to the [0, 1] range,\nwe divide by the maximum achievable score α · N\n(i.e., a perfect score with full retention and no hal-\nlucination penalty), and clip negative values, where\nN is the number of systematic reviews:\nDSSnormalised = max\n\u0012\n0, α × ERS −γ × HPadj\nα × N\n\u0013\n(7)\nThis normalisation ensures interpretability while\nbounding the score, rewarding summaries that re-\ntain salient demographic content and penalising\nunsupported or excessive additions.\n3see Section 5.2 for details\nImplementation Details.\nWe identified matched\ndemographic entities using cosine-based seman-\ntic similarity, applying a threshold of 0.7 to de-\ntermine matches4. The same similarity threshold\nwas applied inversely to identify hallucinations,i.e.,\nentities with similarity below the threshold were\nconsidered unsupported. Weighting parameters\nα = γ = 2 were used in Equations 6 and 7, balanc-\ning the contribution of entity retention and hallu-\ncination penalties. These settings were chosen to\nprioritise demographic salience while discouraging\nunsupported content 5.\nMetric Comparison and Interpretation.\nTo\ncontextualise the behaviour of DSS, we examined\nits relationship with the standard evaluation metrics\nintroduced in Section 5.1. Pearson correlation anal-\nysis showed strong positive correlations between\nDSS and BLEU (0.970), BERTScore (0.923), and\nBARTScore (0.892), indicating that summaries\nwith higher demographic fidelity often also exhibit\nstrong lexical and semantic alignment with refer-\nence abstracts. However, despite this alignment,\nDSS remains conceptually distinct. Unlike stan-\ndard metrics, which assess surface-level similarity,\nDSS explicitly measures the retention of demo-\ngraphic entities and penalises unsupported or omit-\nted demographic information. In contrast, metrics\nsuch as BERTScore do not distinguish between\nwhich information is preserved or hallucinated, nor\ndo they prioritise content relevance tied to specific\npopulation groups.\nDSS also showed a negative correlation with\nFactCC (-0.99), a factual consistency metric, sug-\ngesting that DSS captures a complementary dimen-\nsion of quality, namely, demographic salience and\ninclusion, that is not the primary focus of factuality-\noriented metrics. Taken together, these compar-\nisons indicate that DSS aligns with general mea-\nsures of summary quality but contributes a focused,\ndomain-relevant perspective that standard metrics\ndo not directly capture.\n5.3\nModel-Level Performance Analysis\nTo assess differences in model performance across\nthe three age groups, we used the Kruskal–Wallis\ntest (Daniel, 2008), a non-parametric method ap-\npropriate for comparing three or more independent\n4We also explored prompting an LLM for entity matching\nbut found it inconsistent and less reproducible.\n5We performed sensitivity analysis tests for these parame-\nters; details can be found in Appendix C.\n"}, {"page": 7, "text": "groups without assuming normality. When sig-\nnificant effects were found, Dunn’s post-hoc tests\n(Sedgwick, 2012) with Bonferroni correction were\napplied to adjust for multiple comparisons. Effect\nsizes were calculated using epsilon-squared (ε2).\n6\nResults and Discussions\nSurface Metrics Are Demographically Insensi-\ntive; FactCC Shows Partial Sensitivity.\nBased\non the results in Table 4, BLEU, BERTScore, and\nBARTScore exhibit minimal variation across mod-\nels and age groups, indicating a lack of sensitiv-\nity to population-specific fidelity and limits their\nutility in demographic evaluation. While limited,\nFactCC reveals greater differentiation. GPT consis-\ntently scores higher, with age-aware prompts im-\nproving performance in the child group. However,\nscores remain low for older adults across QWEN\nand Longformer, despite similar gains, indicating\nongoing challenges in summarising this group. The\ndivergence between high FactCC scores and poor\ndemographic fidelity underscores the need for met-\nrics that capture representational accuracy.\nDSS\nHighlights\nModel-Specific\nTradeoffs.\nDSS, designed to assess demographic fidelity,\nreveals clearer distinctions between models. Under\nregular prompting, GPT achieves high DSS across\nall groups by balancing entity retention with low\nhallucination and length penalties.\nIn contrast,\nQWEN, despite strong ERS, suffers from high\nhallucination and overly verbose summaries,\nresulting in sharply reduced DSS, especially in\nadults and children. Longformer exhibits fewer\nhallucinations overall but is notably uneven across\nage groups: it performs relatively well for older\nadults and children, where omission rates are\nlower, but struggles with the adult group, where\nretention is markedly weaker. Overall, in the older\nadult group, DSS is consistently higher.\nSimple Fixes Are Non-Trivial:\nAge-Aware\nPrompting Yields Mixed Effects on Fidelity and\nStability.\nThe impact of age-aware prompting\nvaries considerably across models and age groups.\nFor GPT, it leads to modest gains in factual con-\nsistency (FactCC) but slightly reduces DSS due to\nlower entity coverage. QWEN shows high sensitiv-\nity to age aware prompting, achieving near-perfect\nERS in some settings, but at the cost of increased\nhallucination and verbosity, leading to substantial\ndrops in DSS. Longformer’s behaviour is more con-\nsistent: It shows limited improvement overall but\nperforms relatively well in the older adult group,\nwhere DSS increases without major penalty trade-\noffs. These results suggest that while demographic\nspecific age-aware prompting can shift model be-\nhaviour, it does not consistently enhance demo-\ngraphic fidelity and often introduces new sources\nof instability, thereby highlighting the non-triviality\nof improving model’s retention of salient demo-\ngraphic entities.\n6.1\nRetention and Hallucination Patterns\nAcross LLMs.\nWhile Table 4 summarises model-level averages, it\nobscures instance-level variability that can affect\nthe reliability of summarisation in practice. Fig-\nure 3 shows the distribution of Entity Retention\nScore (Figure 3a) and Hallucination Score (Figure\n3b) for the adult group under the regular prompt.\nThe ERS distribution highlights GPT’s consistently\nstrong demographic coverage, with minimal vari-\nation across reviews. In contrast, Longformer dis-\nplays a wide spread and lower median, suggesting\ninconsistent retention of key population informa-\ntion. QWEN achieves comparable retention but\nat the cost of highly variable hallucination scores,\nincluding extreme outliers, indicating instability in\ncontent faithfulness. These patterns suggest that\neven when models appear comparable on average,\ntheir behaviour can diverge substantially across in-\nstances, a risk especially critical in biomedical set-\ntings. Additional distributions for other age groups\nand prompt conditions are provided in Appendix F,\nalong with a token-level qualitative analysis in Sec-\ntion 6.3.\n6.2\nStatistical Analysis of Inter-Model\nDifferences\nWe assessed whether model-level differences\nacross age groups and evaluation metrics were sta-\ntistically significant using the Kruskal–Wallis and\nDunn’s tests. Results below summarise key find-\nings for each prompt condition.\nRegular Prompt.\nUnder the regular prompt, sig-\nnificant differences appeared mainly in the adult\ngroup. ERS and omission scores differed across\nmodels (H = 10.30, p = 0.0058, ε2 = 0.20),\nwith Longformer underperforming relative to GPT\n(p = 0.013) and QWEN (p = 0.021); differ-\nences between GPT and QWEN were not signif-\nicant (p = 1.00). Hallucination scores also var-\n"}, {"page": 8, "text": "Group\nModel\nBERT ↑\nBART ↑\nBLEU ↑\nFactCC ↑\nERS ↑\nHP ↓\nOmission ↓\nOP ↓\nDSS ↑\nRegular Prompt\nChild\nGPT\n0.84\n-2.26\n2.40\n0.76\n0.84\n0.12\n0.16\n0.00\n0.72\nQWEN\n0.82\n-2.26\n1.68\n0.52\n0.97\n0.58\n0.02\n0.95\n0 (-0.55)\nLongformer\n0.81\n-2.30\n2.46\n0.44\n0.91\n0.33\n0.09\n0\n0.63\nAdult\nGPT\n0.83\n-2.31\n2.05\n0.82\n0.81\n0.12\n0.19\n0\n0.69\nQWEN\n0.81\n-2.30\n1.76\n0.51\n0.78\n0.74\n0.22\n1.02\n0 (-0.98)\nLongformer\n0.80\n-2.37\n2.16\n0.60\n0.45\n0.18\n0.50\n0.00\n0.27\nOlder Adult\nGPT\n0.83\n-2.00\n3.75\n0.71\n0.92\n0.14\n0.08\n0\n0.78\nQWEN\n0.82\n-1.99\n2.25\n0.43\n0.98\n0.11\n0.02\n0\n0.79\nLongformer\n0.81\n-2.03\n2.81\n0.41\n0.95\n0.07\n0.05\n0\n0.78\nAge-Aware Prompt\nChild\nGPT\n0.84\n-2.25\n3.04\n0.83\n0.87\n0.17\n0.13\n0\n0.69\nQWEN\n0.81\n-2.31\n0.72\n0.63\n0.89\n2.06\n0.11\n1.32\n0( -2.49)\nLongformer\n0.82\n-2.31\n2.04\n0.59\n0.91\n0.33\n0.09\n0\n0.58\nAdult\nGPT\n0.83\n-2.31\n2.60\n0.82\n0.62\n0.12\n0.38\n0\n0.5\nQWEN\n0.83\n-2.27\n1.62\n0.59\n0.93\n1.14\n0.07\n1.57\n0(-1.78)\nLongformer\n0.81\n-2.35\n2.18\n0.63\n0.45\n0.18\n0.55\n0\n0.27\nOlder Adult\nGPT\n0.84\n-2.00\n3.70\n0.67\n0.85\n0.04\n0.15\n0\n0.81\nQWEN\n0.83\n-1.98\n2.27\n0.42\n0.98\n0.11\n0.02\n1.33\n0(-0.46)\nLongformer\n0.81\n-2.04\n1.93\n0.50\n0.95\n0.07\n0.05\n0\n0.88\nTable 4: Comprehensive automatic evaluation results across demographic groups and summarisation models. The\ntop section reports scores under the regular prompt, and the bottom under the age-aware prompt. ERS, HP, Omission\nand OP are reported as averages across reviews. DSS is reported as the normalised value, with negative unnormalised\nscores in parentheses.\nied (H = 7.23, p = 0.0269, ε2 = 0.12), with\nQWEN exceeding GPT (p = 0.042). In the child\ngroup, only hallucination differences were signif-\nicant (H = 6.14, p = 0.046, ε2 = 0.10), with\nQWEN hallucinating more than GPT (p = 0.040).\nNo significant differences were found in the older\nadult group (p > 0.90).\nAge-Aware Prompt.\nWith the age-aware prompt,\ninter-model differences became more pronounced\nfor adults. ERS and omission scores again differed\nsignificantly (H = 11.40, p = 0.0034, ε2 = 0.22),\nwith Longformer performing worse than QWEN\n(p = 0.0027); GPT and QWEN did not differ\nsignificantly (p = 0.088). Hallucination scores\nalso varied (H = 13.10, p = 0.0014, ε2 = 0.26),\nwith QWEN exceeding both GPT (p = 0.0023)\nand Longformer (p = 0.013). Among children,\nhallucination scores showed strong differences\n(H = 19.27, p = 6.54 × 10−5, ε2 = 0.41), with\nQWEN again exceeding GPT (p = 0.00012) and\nLongformer (p = 0.0020); ERS and omission were\nnot significant. Older adults showed no significant\ndifferences on any metric (p > 0.10).\nOverall, model variability was most pronounced\nin adults, particularly for ERS and hallucinations.\nQWEN consistently hallucinated more than GPT\nand Longformer, while Longformer’s lower ERS\nand higher omission were concentrated in the adult\ngroup.\n6.3\nQualitative Evaluation and Token\nAnalysis\nEntity-level behaviour was examined across three\ndimensions: entities retained, hallucinations, and\nomissions. These were evaluated across demo-\ngraphic groups and under both regular and age-\naware prompts.\nEntity Retention.\nRetained entities spanned a\nmix of canonical age-group labels (e.g., adults, chil-\ndren, older adults) and more granular descriptors\nsuch as young adults, adults aged 18–35, early\nchildhood, and community-dwelling older adults.\nThe age-aware prompt tended to elicit more spe-\ncific and contextually rich terms, including detailed\ndemographic subgroups (e.g., healthy elderly men\nand women, Midwestern young adults, adult car-\ndiac patients). These findings suggest that models\nwere generally sensitive to age-related cues and\ncapable of surfacing relevant synonyms and de-\nscriptive variants, especially when the prompt was\nexplicitly age-conditioned.\nHallucinations and Omissions.\nHallucinated en-\ntities, while less frequent overall, often involved\ntangential or demographically unrelated popula-\n"}, {"page": 9, "text": "(a) Entity Retention Across Models (Adult Group) - Reg-\nular Prompt\n(b) Hallucinations Across Models (Adult Group) - Regular\nPrompt\nFigure 3: Comparison of Entity Retention and hallucinations across Models for the Adult Group - Regular Prompt.\ntions not mentioned in the gold document. Exam-\nples include the inclusion of prisoners in the popu-\nlation group of a review on smoking cessation inter-\nventions for young adults. Hallucination frequency\nwas higher for QWEN and more prominent un-\nder the age-aware prompt, reflecting a tendency to\novergenerate plausible but unsupported population\ndescriptors. These patterns mirror the quantitative\nhallucination scores and indicate model-specific\nsusceptibility to fabrication and generation of un-\nsupported content, particularly when prompted to\nfocus on demographic detail. Omissions included\nboth general and highly specific age-related terms\nthat were present in the gold documents but not\ncaptured in the generated outputs. These, sim-\nilar to retained entities, ranged from descriptive\nphrases (e.g., mean age 73.66 ± 14.67 years, res-\nidents in aged care settings) to developmental or\nlife stage terms such as infancy, childhood, and\nyoung adulthood. Across prompts, omissions were\nmost pronounced for Longformer, consistent with\nits lower quantitative entity retention scores. The\nomission of precise subgroups may reflect limita-\ntions in entity grounding, particularly for complex\nor compound descriptors. There seemed to be no\nobvious pattern in the models decision on which\nentities to retain and which to exclude.\n6.4\nEffect of Prompt Design\nThe age-aware prompt systematically increased the\nspecificity and range of demographic terms pro-\nduced, particularly for adults and older populations.\nHowever, this increase in granularity was accompa-\nnied by greater lexical variability and, for QWEN\nin particular, more hallucinations and unsupported\nentities. GPT retained a better balance between fi-\ndelity and specificity, while Longformer exhibited\nlower entity coverage across conditions.\nOverall, the age-aware prompt improved cover-\nage of fine-grained descriptors but also amplified\nmodel-specific failure modes, such as hallucina-\ntions or omissions, highlighting the non-triviality of\nimproving demographic entity retention in LLMs.\nThese qualitative observations support the quan-\ntitative findings, particularly regarding QWEN’s\nhallucination rate and Longformer’s lower entity\nretention performance.\n7\nConclusion\nOur study shows that current LLMs exhibit system-\natic disparities in age-related information retention\nin biomedical summaries. Using DemogSummary\nand the Demographic Salience Score (DSS), we\nquantify these biases, finding adult summaries par-\nticularly error-prone and underrepresented popula-\ntions more likely to be hallucinated. These results\nhighlight the need for demographic-aware evalua-\ntion and fair summarisation pipelines, paving the\nway for more equitable and transparent biomedical\nNLP systems.\n"}, {"page": 10, "text": "Limitations\nThis study offers a focused evaluation of age-\nrelated fairness in LLM-based summarisation but\nhas several limitations. First, the dataset covers a\nlimited set of medical domains, which may con-\nstrain generalisability. Second, the causes of ob-\nserved disparities remain under explored. Lastly,\nthe study does not investigate bias mitigation meth-\nods, limiting its prescriptive value for fairness-\noriented applications.\nAcknowledgements\nThis work was supported by the University of\nSheffield’s Healthy Lifespan Institute Research\nScholarship. We also acknowledge the University\nof Sheffield IT Services for providing access to\nHigh Performance Computing resources. We are\ngrateful to the reviewers and area chairs for their\nthoughtful feedback and constructive discussions,\nand especially to Jasivan Sivakumar and Joe Stacey\nfor their invaluable insights and guidance.\nReferences\nDivij Bajaj, Yuanyuan Lei, Jonathan Tong, and Ruihong\nHuang. 2024. Evaluating gender bias of LLMs in\nmaking morality judgements. In Findings of the As-\nsociation for Computational Linguistics: EMNLP\n2024, pages 15804–15818, Miami, Florida, USA.\nAssociation for Computational Linguistics.\nIz Beltagy, Matthew E. Peters, and Arman Cohan.\n2020. Longformer: The long-document transformer.\nPreprint, arXiv:2004.05150.\nEmily M. Bender and Batya Friedman. 2018. Data\nStatements for Natural Language Processing: To-\nward Mitigating System Bias and Enabling Better\nScience. Transactions of the Association for Compu-\ntational Linguistics, 6:587–604. Place: Cambridge,\nMA Publisher: MIT Press.\nSu Lin Blodgett, Solon Barocas, Hal Daumé III, and\nHanna Wallach. 2020.\nLanguage (technology) is\npower: A critical survey of “bias” in NLP. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 5454–\n5476, Online. Association for Computational Lin-\nguistics.\nTolga Bolukbasi, Kai-Wei Chang, James Y Zou,\nVenkatesh Saligrama, and Adam T Kalai. 2016.\nMan is to Computer Programmer as Woman is to\nHomemaker? Debiasing Word Embeddings. In Ad-\nvances in Neural Information Processing Systems,\nvolume 29. Curran Associates, Inc.\nClarivate. 2025. Web of Science [Internet]. https:\n//www.webofscience.com. Certain data included\nherein are derived from Clarivate™(Web of Sci-\nence™). © Clarivate 2025. All rights reserved. [cited\n2025 May 19].\nCochrane Database of Systematic Reviews. 1992.\nCochrane Database of Systematic Reviews [Inter-\nnet]. https://www.cochranelibrary.com/cdsr/\nabout-cdsr. [cited 2025 May 19].\nKate Crawford. 2017. The trouble with Bias.\nWayne W. Daniel. 2008. Kruskal-Wallis Test, pages\n288–290. Springer New York, New York, NY.\nJonathan De Bruin, Yongchao Ma, Gerbrich Ferdinands,\nJelle Teijema, and Rens Van de Schoot. 2023. SYN-\nERGY - Open machine learning dataset on study\nselection in systematic reviews.\nFernando M. Delgado-Chaves, Matthew J. Jennings, An-\ntonio Atalaia, Justus Wolff, Rita Horvath, Zeinab M.\nMamdouh, Jan Baumbach, and Linda Baumbach.\n2025. Transforming literature screening: The emerg-\ning role of large language models in systematic re-\nviews. Proceedings of the National Academy of Sci-\nences, 122(2):e2411962122.\nDaniel Deutsch, Rotem Dror, and Dan Roth. 2022. Re-\nexamining system-level correlations of automatic\nsummarization evaluation metrics. In Proceedings of\nthe 2022 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, pages 6038–6052,\nSeattle, United States. Association for Computational\nLinguistics.\nJay DeYoung, Stephanie C. Martinez, Iain J. Marshall,\nand Byron C. Wallace. 2024. Do multi-document\nsummarization models synthesize?\nTransactions\nof the Association for Computational Linguistics,\n12:1043–1062.\nIsabel O. Gallegos, Ryan A. Rossi, Joe Barrow,\nMd Mehrab Tanjim, Sungchul Kim, Franck Dernon-\ncourt, Tong Yu, Ruiyi Zhang, and Nesreen K. Ahmed.\n2024. Bias and Fairness in Large Language Models:\nA Survey. Computational Linguistics, 50(3):1097–\n1179.\nMingqi Gao and Xiaojun Wan. 2022. DialSummEval:\nRevisiting summarization evaluation for dialogues.\nIn Proceedings of the 2022 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\npages 5693–5709, Seattle, United States. Association\nfor Computational Linguistics.\nLixia Ge, Rupesh Agrawal, Maxwell Singer, Palvan-\nnan Kannapiran, Joseph Antonio De Castro Molina,\nKiok Liang Teow, Chun Wei Yap, and John Arputhan\nAbisheganaden. 2024. Leveraging artificial intelli-\ngence to enhance systematic reviews in health re-\nsearch: advanced tools and challenges. Systematic\nReviews, 13(1):269.\n"}, {"page": 11, "text": "Nannan Huang, Haytham Fayek, and Xiuzhen Zhang.\n2024.\nBias in opinion summarisation from pre-\ntraining to adaptation: A case study in political bias.\nIn Proceedings of the 18th Conference of the Euro-\npean Chapter of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 1041–\n1055, St. Julian’s, Malta. Association for Computa-\ntional Linguistics.\nNannan Huang, Lin Tian, Haytham Fayek, and Xiuzhen\nZhang. 2023. Examining bias in opinion summarisa-\ntion through the perspective of opinion diversity. In\nProceedings of the 13th Workshop on Computational\nApproaches to Subjectivity, Sentiment, & Social Me-\ndia Analysis, pages 149–161, Toronto, Canada. Asso-\nciation for Computational Linguistics.\nMahammed Kamruzzaman, Md. Shovon, and Gene\nKim. 2024. Investigating subtler biases in LLMs:\nAgeism, beauty, institutional, and nationality bias in\ngenerative models. In Findings of the Association for\nComputational Linguistics: ACL 2024, pages 8940–\n8965, Bangkok, Thailand. Association for Computa-\ntional Linguistics.\nWojciech Kryscinski, Bryan McCann, Caiming Xiong,\nand Richard Socher. 2020. Evaluating the factual\nconsistency of abstractive text summarization. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 9332–9346, Online. Association for Computa-\ntional Linguistics.\nNational Center for Biotechnology Information (NCBI).\n1988. National Center for Biotechnology Informa-\ntion (NCBI) [Internet].\nhttps://www.ncbi.nlm.\nnih.gov/. [cited 2025 May 19].\nAni Nenkova and Kathleen McKeown. 2011. Automatic\nSummarization, volume 5. Now Publishers. Journal\nAbbreviation: Foundations and Trends in Information\nRetrieval Publication Title: Foundations and Trends\nin Information Retrieval.\nDerek L. Nguyen, Yinhao Ren, Tyler M. Jones, Saman-\ntha M. Thomas, Joseph Y. Lo, and Lars J. Grimm.\n2024. Patient characteristics impact performance\nof ai algorithm in interpreting negative screening\ndigital breast tomosynthesis studies.\nRadiology,\n311(2):e232286. PMID: 38771177.\nOpenAI. 2023.\nGpt-4 technical report.\nhttps://\narxiv.org/abs/2303.08774. ArXiv:2303.08774.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic evalu-\nation of machine translation. In Proceedings of the\n40th Annual Meeting of the Association for Compu-\ntational Linguistics, pages 311–318, Philadelphia,\nPennsylvania, USA. Association for Computational\nLinguistics.\nDipti Pawar, Shraddha Phansalkar, Abhishek Sharma,\nGouri K. Sahu, Chun K. Ang, and Wei H. Lim. 2023.\nSurvey on the Biomedical Text Summarization Tech-\nniques with an Emphasis on Databases, Techniques,\nSemantic Approaches, Classification Techniques, and\nSimilarity Measures. Sustainability, 15(5).\nLena Schmidt, Ailbhe N. Finnerty Mutlu, Rebecca El-\nmore, Babatunde K. Olorisade, James Thomas, and\nJulian P. T. Higgins. 2023. Data extraction methods\nfor systematic review (semi)automation: Update of a\nliving systematic review.\nAnna M Scott, Caitlin Forbes, Jasmine Clark, Matt\nCarter, Paul Glasziou, and Zachary Munn. 2021. Sys-\ntematic review automation tools improve efficiency\nbut lack of knowledge impedes their adoption: a sur-\nvey. Journal of Clinical Epidemiology, 138:80–94.\nEpub 2021 Jul 7.\nPhilip Sedgwick. 2012. Multiple significance tests: the\nbonferroni correction. BMJ (online), 344:e509–e509.\nLaleh Seyyed-Kalantari, Haoran Zhang, Matthew B. A.\nMcDermott, Irene Y. Chen, and Marzyeh Ghassemi.\n2021. Underdiagnosis bias of artificial intelligence al-\ngorithms applied to chest radiographs in under-served\npatient populations. Nature Medicine, 27(12):2176–\n2182.\nJulius Steen and Katja Markert. 2024a. Bias in news\nsummarization: Measures, pitfalls and corpora. In\nFindings of the Association for Computational Lin-\nguistics: ACL 2024, pages 5962–5983, Bangkok,\nThailand. Association for Computational Linguistics.\nJulius Steen and Katja Markert. 2024b. Bias in News\nSummarization: Measures, Pitfalls and Corpora. In\nFindings of the Association for Computational Lin-\nguistics: ACL 2024, pages 5962–5983, Bangkok,\nThailand. Association for Computational Linguistics.\nTony Sun, Andrew Gaut, Shirlyn Tang, Yuxin Huang,\nMai ElSherief, Jieyu Zhao, Diba Mirza, Elizabeth\nBelding, Kai-Wei Chang, and William Yang Wang.\n2019. Mitigating Gender Bias in Natural Language\nProcessing: Literature Review. In Proceedings of the\n57th Annual Meeting of the Association for Computa-\ntional Linguistics, pages 1630–1640, Florence, Italy.\nAssociation for Computational Linguistics.\nHarini Suresh and John Guttag. 2021. A Framework\nfor Understanding Sources of Harm throughout the\nMachine Learning Life Cycle. In Equity and Access\nin Algorithms, Mechanisms, and Optimization, pages\n1–9, – NY USA. ACM.\nKunsheng Tang, Wenbo Zhou, Jie Zhang, Aishan Liu,\nGelei Deng, Shuai Li, Peigui Qi, Weiming Zhang,\nTianwei Zhang, and NengHai Yu. 2024. Gender-\nCARE: A Comprehensive Framework for Assessing\nand Reducing Gender Bias in Large Language Mod-\nels. In Proceedings of the 2024 on ACM SIGSAC\nConference on Computer and Communications Se-\ncurity, CCS ’24, pages 1196–1210, New York, NY,\nUSA. Association for Computing Machinery. Event-\nplace: Salt Lake City, UT, USA.\nUK\nParliament.\n2014.\nCopyright,\nDe-\nsigns\nand\nPatents\nAct\n1988,\nSection\n29A.\n"}, {"page": 12, "text": "https://www.legislation.gov.uk/ukpga/\n1988/48/section/29A?\nSection 29A inserted\n(1 June 2014) by The Copyright and Rights in\nPerformances (Research, Education, Libraries and\nArchives) Regulations 2014 (S.I. 2014/1372), regs. 1,\n3(2). [cited 2025 May 19].\nByron C. Wallace, Shibam Saha, Frank Soboczen-\nski, and Ian J. Marshall. 2021.\nGenerating (fac-\ntual?)\nnarrative summaries of rcts: Experiments\nwith neural multi-document summarization. AMIA\nJoint Summits on Translational Science Proceedings,\n2021:605–614.\nAn Yang, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei\nHuang, Haoyan Huang, Jiandong Jiang, Jianhong Tu,\nJianwei Zhang, Jingren Zhou, Junyang Lin, Kai Dang,\nKexin Yang, Le Yu, Mei Li, Minmin Sun, Qin Zhu,\nRui Men, Tao He, and 9 others. 2025. Qwen2.5-1m\ntechnical report. Preprint, arXiv:2501.15383.\nYifan Yang, Xiaoyu Liu, Qiao Jin, Furong Huang, and\nZhiyong Lu. 2024. Unmasking and quantifying racial\nbias of large language models in medical report gen-\neration. Communications Medicine, 4(1):176.\nWeizhe Yuan, Graham Neubig, and Pengfei Liu. 2021.\nBartscore: Evaluating generated text as text genera-\ntion. In Advances in Neural Information Processing\nSystems, volume 34, pages 27263–27277. Curran As-\nsociates, Inc.\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.\nWeinberger, and Yoav Artzi. 2019.\nBertscore:\nEvaluating text generation with BERT.\nCoRR,\nabs/1904.09675.\nA\nHyperparameters\nThe hyperparameters in Table 5 were selected to\nencourage highly deterministic, concise outputs\n(temperature = 0) and to reduce redundancy. The\nmaximum output token limit (750) was chosen both\nto provide sufficient token space for generating de-\ntailed summaries that approximate the length and\ncontent of gold-standard review abstracts, as well\nas a guide for penalising overly lengthy synthe-\nses that provide weak and shallow aggregations of\nbiomedical systematic review abstracts.\nModel\nTemperature\nMax Tokens\nFP\nGPT-4.1 Mini\n0\n750\nNA\nGPT-4.1 Nano\n0\n750\nNA\nQwen\n0\n750\n1.1\nLongformer\nNA\n750\n1.1\nTable 5: Hyperparameters used for different models in\nthe experiment. FP = Frequency Penalty\nB\nDemographic Annotation Procedure\nB.1\nRule-Based Age Entity Extraction\nListing 1: Pseudocode for rule-based age extraction\ndef extract_demographics(text):\ndemographics = {}\n# Define regular expression patterns\nto identify age -related\nexpressions\nage_patterns = [\n# Matches \"45 years old\", \"30 -50\nyears\"\nr'(?<!\\d)(\\d{1 ,3})\\s*(?:(?: -|to)\n\\s*(\\d{1 ,3}))?\\s*(?: years ?|\nyrs?)\\s*(?: old|of age)?',\n# Matches \"aged 40 to 65\", \"aged\n70\"\nr'aged?\\s*(\\d{1 ,3}) (?:\\s*(?:to\n|-|-)s*(\\d{1 ,3}))?',\n# Matches \"6 month -old\", \"12 mo\nold\"\nr'(\\d{1 ,2})\\s*(?: month[- ]old|mo\nold)',\n# Matches \"age of 20 to 40\", \"\naged 60 -85\"\nr'(?: age|aged)\\s*(?:of\\s*)?(\\d\n{1 ,3})\\s*(?:to|-|-)|s*(\\d\n{1 ,3})'\n]\ndef find_matches(patterns):\nreturn [match.group ().strip ()\nfor p in patterns for match\nin re.finditer(p, text , re.\nIGNORECASE)]\ndemographics[\"age\"] = find_matches(\nage_patterns)\nreturn demographics\nB.2\nLLM-Based Named Entity Recognition\nPrompt\nListing 2: LLM prompt for structured demographic\nextraction\nYou are an intelligent assistant tasked\nwith extracting structured\ninformation from academic PDF\ndocuments.\nStep 1: Extract the following fields:\n- \"title\"\n- \"firstauthor\"\n- \"year\"\n- \"abstract\" (until the \"Keywords\"\nsection)\n- \"systematicreviewpmid\"\n- \"stype\"\n- \"populationdemographics\"\nStep 2: Return a JSON object in the\nfollowing format:\n"}, {"page": 13, "text": "{\n\"title\": \"...\",\n\"firstauthor\": \"...\",\n\"year\": \"...\",\n\"abstract\": \"...\",\n\"systematicreviewpmid\": \"...\",\n\"stype\": \"...\",\n\"populationdemographics\": [...]\n}\nNotes:\n- Read the full abstract across chunks\nif needed.\n- Do not stop early or include extra\ncommentary.\nC\nSensitivity Analysis of DSS Parameters\nTo evaluate the robustness of the Demographic\nSalience Score (DSS), we conducted a sensitivity\nanalysis on key hyperparameters: (i) the seman-\ntic similarity and hallucination thresholds, and (ii)\nthe weighting parameters α (ERS weight) and γ\n(hallucination penalty).\nThreshold analysis showed a consistent trend:\nDSS scores were highest at lower, more permissive\nthresholds and declined gradually as thresholds in-\ncreased, reflecting stricter evaluation. We selected\n0.7 for both thresholds, yielding a normalized DSS\nof 0.64—a balance between semantic precision and\npenalization of unsupported content. DSS varied\nminimally in the surrounding parameter space, in-\ndicating local stability.\nFor α and γ, we tested values between 1 and\n2. We avoided assigning 0 to any of the param-\neters to avoid cancelling the contribution of the\ncorresponding component, which is undesirable.\nIn our tests, increasing α slightly improved DSS,\nwhereas higher γ values reduced it due to stronger\nhallucination penalties. For experimentation, re-\nsearchers may adjust these weights depending on\nwhich aspect they wish to emphasise, assigning\nhigher weight to γ to prioritise hallucination con-\ntrol, or to α to strengthen DSS. The final config-\nuration (α = 2.0, γ = 2.0) achieved a DSS of\n0.66, one of the highest observed, and exhibited\nrobustness to parameter variation.\nFigure 5 displays normalised DSS scores over a\ngrid of semantic similarity and hallucination thresh-\nolds, while figure 5 shows DSS values as a function\nof α and γ, varied from 1.0 to 2.0.\nD\nSource-Level Demographic Entity\nExtraction\nListing 3: Pseudocode for Demographic Extraction\nFunction\nFunction extract_demographics(text):\nInitialise an empty dictionary:\ndemographics\nDefine regex patterns for:\n- Age (e.g., \"45 years old\", \"\naged 40 to 65\", \"6 month -old\n\")\nDefine helper function find_matches(\npatterns):\nFor each pattern in patterns:\nUse case -insensitive regex\nsearch on text\nCollect all matching\nsubstrings\nReturn list of matches\ndemographics[\"age\"] = find_matches(\nage_patterns)\nReturn demographics\nListing 4: Pseudocode for Age Entity Extraction\nFunction extract_entities(text):\nDefine system prompt:\n\"You are a helpful assistant.\nGiven the abstract , extract\nall age related demographic\nentities.\nYou should extract entities\nrelated to age.\nYour job is to extract these\nentities only , do not add to\nor subtract from the\nprovided text.\"\nSend prompt and input text to\nlanguage model (e.g., GPT):\n- Model: \"gpt -4.1- nano\"\n- Instructions: system prompt\n- Input: \"Here is the abstract\nset: \\n{text}\"\nReceive response from model\nReturn the output text as extracted\nentities\nE\nDemographic Salience and Entity\nRetention\nListing 5: Pseudocode for Entity Retention Evaluation\nand DSS Computation\nFunction\ncompute_semantic_similarity_and_ers(\nrecords , threshold =0.7,\nhallucination_threshold =0.7,\nalpha=2, gamma=2, overlength_penalty\n=None):\nInitialise:\nexact_matches := empty dict\n"}, {"page": 14, "text": "Figure 4: Semantic Similarity Threshold\nsimilar_matches := empty dict\nhallucinations := empty dict\nomissions := empty dict\nomission_scores := empty dict\ners_scores := empty dict\nhallucination_scores := empty\ndict\nFor each record in records:\nreference_entities := list of\ngold entities\ngenerated_entities := list of\npredicted entities\nID := record identifier\nCompute:\nexact := intersection of\nreference and generated\nentities\nembeddings_ref := embeddings\nfor reference_entities\nembeddings_gen := embeddings\nfor generated_entities\nFor each reference entity not in\nexact:\nIf cosine similarity with\nany generated entity >=\nthreshold:\nAppend to\nsimilar_matches\nCount as similar match\nFor each generated entity not in\nreference_entities:\nIf cosine similarity with\nall reference entities <\nhallucination_threshold\n:\nAdd to hallucinations\nFor each reference entity not\nmatched:\nIf cosine similarity with\nall generated entities <\nthreshold:\nAdd to omissions\nCompute:\nomission_score := omitted /\nreference_entities\ners := 1 - omission_score\nhallucination_score :=\nhallucinations /\nreference_entities\nStore scores for ID\nCompute group -level metrics:\ners_sum := sum of all ERS scores\nhall_sum := sum of all\nhallucination scores\nIf overlength_penalty is\nprovided:\nAdd penalties to hall_sum\nDSS := alpha x ers_sum - gamma x\n"}, {"page": 15, "text": "Figure 5: Alpha-Gamma Grid\nhall_sum\nDSS_normalised := max(0, DSS / (\nalpha x number of records))\nReturn:\nexact_matches , similar_matches ,\nhallucinations ,\nhallucination_scores ,\nomissions , omission_scores ,\ners_scores , DSS ,\nDSS_normalised ,\n[overlength_penalty if provided]\n"}, {"page": 16, "text": "F\nEntity Retention, Hallucinations and Omissions\nHere we present the full set of results across both prompt regimes and demographic groups tested.\nFigure 6: Entity Omissions Across Models (Adult\nGroup) - Regular Prompt\nFigure 7:\nEntity Retention Across Models (Adult\nGroup) - Age Aware Prompt\nFigure 8: Entity Omissions Across Models (Adult\nGroup) - Age Aware Prompt\nFigure 9: Hallucinations Across Models (Adult Group)\n- Age Aware Prompt\n"}, {"page": 17, "text": "Figure 10: Entity Retention Across Models (Child\nGroup) - Regular Prompt\nFigure 11: Entity Omissions Across Models (Child\nGroup) - Regular Prompt\nFigure 12: Hallucinations Across Models (Child Group)\n- Regular Prompt\nFigure 13: Entity Retention Across Models (Child\nGroup) - Age Aware Prompt\n"}, {"page": 18, "text": "Figure 14: Entity Omissions Across Models (Child\nGroup) - Age Awaare Prompt\nFigure 15: Hallucinations Across Models (Child Group)\n- Age Aware Prompt\nFigure 16: Entity Retention Across Models (Older Adult\nGroup) - Regular Prompt\nFigure 17: Entity Omissions Across Models (Older\nAdult Group) - Regular Prompt\n"}, {"page": 19, "text": "Figure 18: Hallucinations Across Models (Older Adult\nGroup) - Regular Prompt\nFigure 19: Entity Retention Across Models (Older Adult\nGroup) - Age Aware Prompt\nFigure 20: Entity Omissions Across Models (Older\nAdult Group) - Age Aware Prompt\nFigure 21: Hallucinations Across Models (Older Adult\nGroup) - Age Aware Prompt\n"}]}