{"doc_id": "arxiv:2511.22858", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2511.22858.pdf", "meta": {"doc_id": "arxiv:2511.22858", "source": "arxiv", "arxiv_id": "2511.22858", "title": "RAG System for Supporting Japanese Litigation Procedures: Faithful Response Generation Complying with Legal Norms", "authors": ["Yuya Ishihara", "Atsushi Keyaki", "Hiroaki Yamada", "Ryutaro Ohara", "Mihoko Sumida"], "published": "2025-11-28T03:28:27Z", "updated": "2025-11-28T03:28:27Z", "summary": "This study discusses the essential components that a Retrieval-Augmented Generation (RAG)-based LLM system should possess in order to support Japanese medical litigation procedures complying with legal norms. In litigation, expert commissioners, such as physicians, architects, accountants, and engineers, provide specialized knowledge to help judges clarify points of dispute. When considering the substitution of these expert roles with a RAG-based LLM system, the constraint of strict adherence to legal norms is imposed. Specifically, three requirements arise: (1) the retrieval module must retrieve appropriate external knowledge relevant to the disputed issues in accordance with the principle prohibiting the use of private knowledge, (2) the responses generated must originate from the context provided by the RAG and remain faithful to that context, and (3) the retrieval module must reference external knowledge with appropriate timestamps corresponding to the issues at hand. This paper discusses the design of a RAG-based LLM system that satisfies these requirements.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2511.22858v1", "url_pdf": "https://arxiv.org/pdf/2511.22858.pdf", "meta_path": "data/raw/arxiv/meta/2511.22858.json", "sha256": "076cabef7e73a7608d32154141d3a9649c9d07d8d35aeaed4b68d4078c43b675", "status": "ok", "fetched_at": "2026-02-18T02:25:53.525172+00:00"}, "pages": [{"page": 1, "text": "RAG System for Supporting Japanese Litigation\nProcedures: Faithful Response Generation Complying\nwith Legal Norms\nYuya Ishihara1,*, Atsushi Keyaki1,*, Hiroaki Yamada2, Ryutaro Ohara1,3 and Mihoko Sumida1\n1Hitotsubashi University, Japan\n2Institute of Science Tokyo, Japan\n3Nakamura, Tsunoda & Matsumoto, Japan\nAbstract\nThis study discusses the essential components that a Retrieval-Augmented Generation (RAG)-based LLM system\nshould possess in order to support Japanese medical litigation procedures complying with legal norms. In\nlitigation, expert commissioners, such as physicians, architects, accountants, and engineers, provide specialized\nknowledge to help judges clarify points of dispute. When considering the substitution of these expert roles\nwith a RAG-based LLM system, the constraint of strict adherence to legal norms is imposed. Specifically, three\nrequirements arise: (1) the retrieval module must retrieve appropriate external knowledge relevant to the disputed\nissues in accordance with the principle prohibiting the use of private knowledge, (2) the responses generated\nmust originate from the context provided by the RAG and remain faithful to that context, and (3) the retrieval\nmodule must reference external knowledge with appropriate timestamps corresponding to the issues at hand.\nThis paper discusses the design of a RAG-based LLM system that satisfies these requirements.\nKeywords\nRetrieval–Augmented Generation, Litigation Procedures, Legal Norms, Expert Knowledge, Information Retrieval\n1. Introduction\nIn recent years, large language models (LLMs) have demonstrated remarkable advancements in their\ncapabilities, leading to a growing movement toward their implementations into professional domains\nsuch as medicine and law. Since they are trained on extensive large text corpora, LLMs acquire a broad\ncollection of knowledge throughout the training process [1, 2]. However, LLMs do not retain up-to-date\ninformation about events that occurred after their training period, and their knowledge of highly\nspecialized or less common domains is not necessarily adequate. For these reasons, in professional\ndomains such as legal[3] and medicine[4] , recent research has increasingly explored the use of Retrieval-\nAugmented Generation (RAG) approaches, which exploits external knowledge to generate high-quality\nresponses.\nOur research group is studying a RAG-based LLM system to support medical litigation procedures\nin Japan. Normally, litigation process goes as follows, (i)arranging issues, (ii)fact finding, (iii)legal\nevaluation, (iv)writing reasons of outcome and (v)writing sentences1. In the process of (i)arrange\nissues, each claim submitted by the plaintiff and the defendant is examined to distinguish the points\nof agreement from those in dispute, thereby extracting points that should be the focus points of the\nlitigation. In medical litigation, this process involves technical advisors who are medical professionals.\nThese experts provide technical explanations regarding matters that may require witness examination\nor expert testimony during (ii)fact finding, attend sessions involving the discovery of evidence or\nThis is a preprint version of a paper reviewed and accepted at BREV-RAG 2025: Beyond Relevance-based EValuation of RAG\nSystems, a SIGIR-AP 2025 workshop.\n*Corresponding author.\n*Corresponding author.\n$ yuya.ishihara@r.hit-u.ac.jp (Y. Ishihara); a.keyaki@r.hit-u.ac.jp (A. Keyaki); yamada@comp.isct.ac.jp (H. Yamada);\nr.ohara@ntmlo.com (R. Ohara); m.sumida@r.hit-u.ac.jp (M. Sumida)\n\u001a 0009-0003-8033-9927 (Y. Ishihara); 0000-0001-6495-117X (A. Keyaki); 0000-0002-1963-958X (H. Yamada);\n0009-0000-8018-3895 (R. Ohara); 0000-0002-8531-2964 (M. Sumida)\n© 2025 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).\n"}, {"page": 2, "text": "i. Arrange issues\nii. Fact Finding\nArrange Evidences\nArrange Claims\nConsideration of issues, \nclaims evidences and facts\niii. Legal Evaluations, application \nof law\niv. write reasons of outcome\nv. write sentences\nConsideration of reliance\nIf other issue\nFigure 1: process of civil litigation\nwitnesses, and offer explanations to judges to aid in assessing the reliability of evidence and witness\ntestimonies presented by the parties. Particularly, because fact-finding by judges in medical litigation\nrequires domain-specific medical expertise, identifying the matters that should be subject to expert\ntestimony demands extensive referencing and analysis of a large volume of legal and medical claims\nand related documents. Consequently, the workload in this process is extremely high. According to\nProfessor Murata Wataru (Chuo University), a former judge, Japanese courts prepare internal reference\nmaterials summarizing the case overview and the issues for expert testimony and opinion to facilitate\njudicial deliberation. Thus, support by computers, especially by the application of LLMs and RAG, is\nexpected to significantly enhance the efficiency of these processes. Furthermore, in a RAG-based LLM\nsystem designed to support medical litigation procedures, it is essential not only to provide accurate\ninformation but also to ensure compliance with the judicial system’s norms. Based on this premise,\nwe propose a set of requirements that a legal RAG framework should satisfy in order to fulfill those\nnormative principles.\n2. Requirements in medical litigations\nAs a preliminary requirement, it is essential to retrieve external knowledge that is appropriate and\nrelevant to the issues of dispute. Although the accuracy of the retrieval module is one of the established\nevaluation points in RAG systems, conducting appropriate expert testimony in the context of medical\nlitigation further requires to comply with the norms of civil procedure and consideration of the domain-\nspecific characteristics within the medical litigations.\n2.1. Procedural Requirements for Use of Expert Knowledge\nIn Japan’s civil litigation procedure, regardless of whether a case involves a specialized domain, the\nadversarial principle is adopted. Judges make decisions from a neutral point based solely on the claims\n"}, {"page": 3, "text": "and evidence submitted by both parties. Consequently, judges are restricted from relying on issues not\nsubmitted or raised by any of the parties or on knowledge not contained within the submitted evidence,\nas doing so would infringe upon the procedural rights of the parties. This adversarial principle, has a\ntension with the expectation of the litigation system that judges continually update their understanding\nof precedents, statutes, and social norms. The extent to which judges should be permitted to conduct\njudicial investigation and use privately acquired knowledge has thus become a subject of debate,\nparticularly in the context of the ongoing digital transformation of society. This requirement applies\nnot only to medical litigations but also to other types of litigation, particularly those that are highly\nspecialized and involve expert advisory systems, such as intellectual property, construction and system\ndevelopment litigations.\nCurrently, it is recognized that when judges rely on specialized knowledge, domain-specific expert\nknowledge can be invoked without the presentation of evidence only if it has undergone critical\nverification by the relevant expert community, and the parties must be guranteed an opportunity to\ncontest the use of such knowledge[5]. Furthermore, in the civil procedure systems of the United States,\nthe United Kingdom, and Germany, the use of privately acquired expert knowledge is considered to be\npermitted under certain requirements, such as it is being commonly shared within the relevant expert\ncommunity, or the implementation of procedural requirements including disclosure to both parties\nand the provision of an opportunity for comment[6]. Accordingly, in the context of RAG systems, the\nexternal knowledge sources should be limited to those that have been critically validated by expert\ncommunities, and access to such information must be controlled to ensure that it remains equally\navailable to both parties involved in the proceedings.\n2.2. Reliance of Expert Knowledge and Frequent Updates\nJudges, by their professional responsibilities, are required to continually update their understanding\nof statutes, judicial precedents, and social norms. In the medical litigation, moreover, judges are\nadditionally expected not only to address the specialized nature of the cases in charge but also to ensure\nthe reliability of the data and evidence upon which their judgments rely. Furthermore, doctors who\nserve as technical advisors in medical domains provide technical explanations grounded in their medical\nexpertise, and also update them. Due to continuous advances in medicine, even authoritative data\nsources such as well-established medical textbooks, peer-reviewed papers, and clinical guidelines issued\nby professional communities gradually lose their validity over time. According to Professor Shigeto\nYonemura (The University of Tokyo), a leading authority in Japanese medical law and also a doctor,\napproximately twenty percent of such data becomes outdated within five years. While the knowledge\nacquired through pretraining inevitably becomes obsolete, continuously retraining LLMs to update\ndomain-specific knowledge would be an inefficient approach. Therefore, it is essential that generated\nresponses explicitly derive from and be faithful to the context provided through retrievals.\n2.3. Issue-specific Reference Time\nOne of the reasons why expert testimony in arranging issues can become a complex procedure is that\nthe applicable standard of expert knowledge differs depending on the issue in dispute. For example,\nwhen the issue concerns whether a physician was negligent or not, the judgment must be based on\nthe medical knowledge, standard of care, and medical law valid at the time the incident happened. In\ncontrast, when the issue concerns the causal relationship between a medical treatment and its outcome,\nthe judgment should rely on the most up-to-date knowledge available at the close of oral proceedings[7].\nTherefore, it is necessary to reference external knowledge corresponding to the appropriate time period\nrelevant to the issue in focus.\nAlthough authoritative data gradually lose their validity over time, the transition to new authorized\nknowledge does not occur abruptly at once. During the transitional period, multiple streams of\nexpert knowledge that contradict each other may coexist until new data or precedents become widely\nacknowledged. Therefore, when retrieving appropriate sources in a RAG framework, it is necessary to\n"}, {"page": 4, "text": "Query\nGenerated\nanswer\nLLM\nPrompt:\nContext:\nrelevant doc 1\nrelevant doc 2\nrelevant doc 3\nQuery\nInput\nOutput\nDB\ndoc\nRetrieval Module\nMaintenance \nof timestamp\nIdentifying \nreference time\nFigure 2: Overview of the a RAG-based LLM System\nconsider the expert knowledge that was valid at the relevant point in time.\nBased on the above, this study addresses the realization of a “norm-compliant RAG” system, focusing\non: (1)controlling knowledge sources in compliance with procedural requirements concerning the use\nof expert knowledge, (2)attribution and faithfulness of generated responses to their information sources;\nand (3)appropriateness of the published time of referenced sources.\n3. Related Work\n3.1. Retrieval-Augmented Generation (RAG)\nSince large language models (LLMs) are trained on extensive corpora, they acquire various forms of\nknowledge during the learning process [1, 2]. However, they do not retain up-to-date information, such\nas current events that occur after model training, and their coverage of specialized or less common\nknowledge is often insufficient. As a result, LLMs are known to generate responses containing misinfor-\nmation, commonly referred to as hallucinations. Because the training corpora used in constructing LLMs\nmay not adequately include domain-specific expertise, the presence of hallucinations is particularly\nlikely when applying such models to specialized domains.\nSeveral approaches have been proposed to mitigate hallucinations, including improving the quality of\ntraining data [8], adjusting decoding strategies [9], enabling self-verification by the model [10, 11], and\nregenerating responses based on factual verification results [12]. Among these, Retrieval-Augmented\nGeneration (RAG) [13, 14] has emerged as one of the most prominent and widely studied approaches.\nAn overview of the RAG framework is presented in Figure 2. First, the user’s input to the LLM is\nused as a query to retrieve relevant documents through a retrieval module. The retrieved documents\nare then provided to the LLM as contextual information, together with the user’s input. The LLM\ngenerates a response while referring to these relevant documents. By leveraging high-quality external\ninformation through RAG, previous studies have reported improvements in task performance [13, 14]\nand reductions in hallucination occurrence [15, 16, 17, 3, 4].\nHowever, completely suppressing hallucinations remains challenging even when using RAG. For\nexample, a study on the application of RAG in the legal domain [3] reported that, although hallucinations\ncan be mitigated through RAG, they cannot be entirely eliminated. Consequently, the study emphasizes\nthe importance of expert responsibility in verifying the texts generated by LLMs when applying AI\nwithin the legal field.\nIn addition, [3] conducted an evaluation of hallucinations based on accuracy and factuality. Therefore,\nto the best of our knowledge, no prior research has focused on compliance with legal norms or on the\nappropriateness of the knowledge sources that substantiate such compliance, which constitutes the\n"}, {"page": 5, "text": "central challenge addressed in this study.\n3.2. Analysis of the Correspondence Between Information Sources and Responses\nTo verify whether the responses are faithfully generated based on the context provided by the RAG\nsystem, possible approaches include analysis using Data Attribution (DA) and evaluation methods\nrelated to response faithfulness.\nIn existing studies on Data Attribution (DA) [18, 19], the focus of analysis has been on the pre-training\ndata of LLMs, known as Training Data Attribution (TDA). In contrast, in the RAG-based LLM system\nexamined in this study, knowledge derived from the RAG component and that originating from the\nLLM’s pre-training data may exist in a competitive relationship, thereby requiring a more complex\nanalytical approach.\nAdditionally, within the RAG framework, mechanisms have been proposed to evaluate the faithfulness\nof responses with respect to the provided context. For example, Ragas1 enables the computation of a\nFaithfulness Score, which assesses the degree of consistency between the context and the generated\nresponse. The Faithfulness Score determines, through natural language inference, whether the content\nof the generated response is supported by the information contained in the given context. Specifically,\nthe Faithfulness Score is calculated through the following procedure:\n1. Identify all the claims in the response.\n2. Check each claim to see if it can be inferred from the retrieved context.\n3. Compute the faithfulness score using the formula:\nFaithfulness Score = Number of claims in the response supported by the retrieved context\nTotal number of claims in the response\n(1)\n4. Norm-compliant RAG\nIn this section, we discuss: (1) controlling knowledge sources in compliance with procedural require-\nments concerning the use of expert knowledge; (2) attribution and faithfulness of generated responses\nto their information sources; and (3) appropriateness of the published time of referenced sources, to\nrealize a norm-compliant RAG.\n4.1. Controlling Knowledge Sources in Compliance with Procedural Requirements\nWe restrict the use of external knowledge to sources that are acceptable according to civil litigation\nnorms. We can achieve this control by controlling the scope of documents targeted by RAG retrieval\nand filtering the results. In assessing this aspect, we could simply label outputs derived from sources\nthat deviate from the predefined scope as inappropriate.\n4.2. Attribution and Faithfulness of Generated Responses to Information Sources\nExpert knowledge is continuously updated over time. Thus, responses generated by relying solely on\nthe model’s knowledge acquired during its pre-training period can become easily outdated. RAG is the\nsolution for this issue. To reinforce the effect of RAG, it is necessary to devise methods that generate\nresponses faithful to the context (or documents) retrieved in the pipeline of the RAG approach. Possible\napproaches include explicit constraints through prompting and the introduction of chain-of-verification\nsteps that check whether candidate sentences for generation are contained in the context.\nTo assess this aspect, we need to identify the data source or authority via DA analysis. We check\nwhether the information contained in the outputs originates from RAG-derived knowledge or from\npre-training. If it originates from pre-training, it is regarded as an inappropriate answer. Even if the\n1https://docs.ragas.io/en/stable/\n"}, {"page": 6, "text": "generated output is based on RAG-derived knowledge, if it contradicts the knowledge in the source, it\nshould be considered inappropriate. Thus, it is also necessary to assess the faithfulness of the outputs\nagainst the source.\n4.3. Valid Time Period of Referenced Sources\nThe older documents can be outdated if they are overruled due to new discoveries and updates. A naive\nsolution to this issue might be keeping the knowledge always updated to the latest version; however,\nthis solution would not work in our legal RAG setting.\nThe valid time periods of information sources vary depending on the types of issues raised in trials.\nFor instance, if the issue of interest in a trial is a physician’s negligence, the medical knowledge valid at\nthe time of the physician’s act can differ from that which is valid at the time of the trial, which is based\non newer sources. If a system generates responses only according to the newest sources, it makes up an\nunrealistic conclusion based on knowledge unavailable at the time of the act in question. Moreover,\nthe validity of time periods for sources matters not only in medical expert knowledge but also in legal\nexpert knowledge, such as precedents and statutes.\nThus, a legal RAG system should be able to recognize and manage the validity of time periods\nfor sources correctly. Managing the time metadata of information sources is important, especially\nconcerning when information is published and when it becomes invalid. We could achieve this by\nutilizing timestamps and citation networks.\nWhen assessing this aspect, if a generated response is based on information with inappropriate\ntimestamps that do not align with the input query, it is considered unsuitable.\n5. Conclusion\nWe are developing a RAG-based LLM system to support medical litigation proceedings in Japan. Such\na system must not just present accurate information, but also provide legally compliant responses to\nsupport expert testimony. To accommodate the requirements, we propose aspects of “conformance\nto the norm” that a legal RAG system should satisfy. Specifically, we propose three aspects: (1)\ncontrolling knowledge sources in compliance with procedural requirements concerning the use of\nexpert knowledge; (2) attribution and faithfulness of generated responses to their information sources;\nand (3) appropriateness of the published time of referenced sources.\nOur future work includes proposing methods that satisfy each requirement, refining evaluation\nmetrics, implementing them, and conducting experiments.\nAcknowledgments\nWe appreciate Prof. Shigeto Yonemura (The University of Tokyo), Prof. Wataru Murata (Chuo Uni-\nversity), Prof. Shozo Ota (Meiji University), Prof. Simon Deakin (University of Cambridge), and Prof.\nFelix Steffek (University of Cambridge) for their helpful comments. This work was partially supported\nby Minji-Funsou-Shori-Kenkyukikin, the Japanese Society for the Promotion of Science Grantin-Aid\nfor Scientific Research (B) (#23H03686, #25K03178) and Scientific Research (C) (#24K15066), and JST\nPRESTO (#JPMJPR236B).\nDeclaration on Generative AI\nDuring the preparation of this work, the authors used GPT-5 and Grammarly for grammar and style\nsuggestions. After using this tool, the authors reviewed and edited the content and take full responsibility\nfor the publication’s content.\n"}, {"page": 7, "text": "References\n[1] F. Petroni, T. Rocktäschel, S. Riedel, P. Lewis, A. Bakhtin, Y. Wu, A. Miller, Language Models as\nKnowledge Bases?, in: Proc. of the EMNLP-IJCNLP 2019, 2019.\n[2] J. Wei, Y. Tay, R. Bommasani, C. Raffel, B. Zoph, S. Borgeaud, D. Yogatama, M. Bosma, D. Zhou,\nD. Metzler, E. H. Chi, T. Hashimoto, O. Vinyals, P. Liang, J. Dean, W. Fedus, Emergent abilities of\nlarge language models, Transactions on Machine Learning Research (TMLR) (2022) 2835–8856.\n[3] V. Magesh, F. Surani, M. Dahl, M. Suzgun, C. D. Manning, D. E. Ho, Hallucination-Free? Assessing\nthe Reliability of Leading AI Legal Research Tools, Journal of Empirical Legal Studies 22 (2025)\n216–242.\n[4] Y.-W. Chu, K. Zhang, C. Malon, M. R. Min, Reducing Hallucinations of Medical Multimodal Large\nLanguage Models with Visual Retrieval-Augmented Generation , in: Proc. of the AAAI 2025, 2025.\n[5] G. Okanari, Saibankan no shichi riyou no kinshi (the prohibition of judge’s use of private\nknowledge), Hougaku Zasshi :(Journal of Law) of Osaka City University 68 (2021) 1 – 66.\n[6] E. Sugiyama, Saibankan niyoru senmonchishiki no shushu to riyou (collection and use of expert\nknowledge by the judge, symposium: The discipline of civil judges in the exercise of their powers),\nMinso Zasshi (Journal of Civil Procedure) 69 (2023) 103 – 114.\n[7] Y. Shirai, Mijukuji Moumakusyou to Ishi no Kashitu (Misdiagnosis of retinopathy of prematurity\nand Doctor’s Negligence), Hanrei kara Manabu Minji-Jijitsu Nintei: Jurisuto Zoukan (Special\nEdition of Journal: Jurist: Learning from Case Law: Civil Fact-Finding) (2006) 252–256.\n[8] A. Albalak, Y. Elazar, S. M. Xie, S. Longpre, N. Lambert, X. Wang, N. Muennighoff, B. Hou, L. Pan,\nH. Jeong, C. Raffel, S. Chang, T. Hashimoto, W. Y. Wang, A Survey on Data Selection for Language\nModels, arXiv:2402.16827, 2024.\n[9] K. Li, O. Patel, F. Viégas, H. Pfister, M. Wattenberg, Inference-Time Intervention: Eliciting Truthful\nAnswers from a Language Model, in: Proc. of the NeurIPS 2023, 2023.\n[10] P. Manakul, A. Liusie, M. Gales, SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection\nfor Generative Large Language Models, in: Proc. of the EMNLP 2023, 2023.\n[11] X. Zhang, B. Peng, Y. Tian, J. Zhou, L. Jin, L. Song, H. Mi, H. Meng, Self-Alignment for Factuality:\nMitigating Hallucinations in LLMs via Self-Evaluation, in: Proc. of the ACL 2024, 2024.\n[12] Y. Wang, R. G. Reddy, Z. M. Mujahid, A. Arora, A. Rubashevskii, J. Geng, O. M. Afzal, L. Pan,\nN. Borenstein, A. Pillai, I. Augenstein, I. Gurevych, P. Nakov, Factcheck-Bench: Fine-Grained\nEvaluation Benchmark for Automatic Fact-checkers, in: Proc. of the Findings of the EMNLP 2024,\n2024.\n[13] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Lewis, W. tau Yih,\nT. Rocktäschel, S. Riedel, D. Kiela, Retrieval-Augmented Generation for Knowledge-Intensive NLP\nTasks, in: Proc. of the NIPS 2020, 2020.\n[14] Y. Gao, Y. Xiong, X. Gao, K. Jia, J. Pan, Y. Bi, Y. Dai, J. Sun, M. Wang, H. Wang, Retrieval-Augmented\nGeneration for Large Language Models: A Survey, arXiv:2312.10997, 2023.\n[15] S. T. I. Tonmoy, S. M. M. Zaman, V. Jain, A. Rani, V. Rawte, A. Chadha, A. Das, A Comprehensive\nSurvey of Hallucination Mitigation Techniques in Large Language Models, arXiv:2401.01313, 2024.\n[16] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Lewis, W. tau Yih,\nT. Rocktäschel, S. Riedel, D. Kiela, Reducing Hallucination in Structured Outputs via Retrieval-\nAugmented Generation, in: Proc. of the NAACL 2024, 2024.\n[17] W. Zhang, J. Zhang, Hallucination Mitigation for Retrieval-Augmented Large Language Models: A\nReview, Mathematics 13 (2025).\n[18] G. Pruthi, F. Liu, S. Kale, M. Sundararajan, Estimating Training Data Influence by Tracing Gradient\nDescent, in: Proc. of the NeurIPS 2020, 2020.\n[19] T. A. Chang, D. Rajagopal, T. Bolukbasi, L. Dixon, I. Tenney, Scalable Influence and Fact Tracing\nfor Large Language Model Pretraining, in: Proc. of the ICLR 2025, 2025.\n"}]}