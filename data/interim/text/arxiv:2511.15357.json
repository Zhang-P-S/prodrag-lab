{"doc_id": "arxiv:2511.15357", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2511.15357.pdf", "meta": {"doc_id": "arxiv:2511.15357", "source": "arxiv", "arxiv_id": "2511.15357", "title": "Cost-Aware Prediction (CAP): An LLM-Enhanced Machine Learning Pipeline and Decision Support System for Heart Failure Mortality Prediction", "authors": ["Yinan Yu", "Falk Dippel", "Christina E. Lundberg", "Martin Lindgren", "Annika Rosengren", "Martin Adiels", "Helen Sjöland"], "published": "2025-11-19T11:34:47Z", "updated": "2025-11-19T11:34:47Z", "summary": "Objective: Machine learning (ML) predictive models are often developed without considering downstream value trade-offs and clinical interpretability. This paper introduces a cost-aware prediction (CAP) framework that combines cost-benefit analysis assisted by large language model (LLM) agents to communicate the trade-offs involved in applying ML predictions. Materials and Methods: We developed an ML model predicting 1-year mortality in patients with heart failure (N = 30,021, 22% mortality) to identify those eligible for home care. We then introduced clinical impact projection (CIP) curves to visualize important cost dimensions - quality of life and healthcare provider expenses, further divided into treatment and error costs, to assess the clinical consequences of predictions. Finally, we used four LLM agents to generate patient-specific descriptions. The system was evaluated by clinicians for its decision support value. Results: The eXtreme gradient boosting (XGB) model achieved the best performance, with an area under the receiver operating characteristic curve (AUROC) of 0.804 (95% confidence interval (CI) 0.792-0.816), area under the precision-recall curve (AUPRC) of 0.529 (95% CI 0.502-0.558) and a Brier score of 0.135 (95% CI 0.130-0.140). Discussion: The CIP cost curves provided a population-level overview of cost composition across decision thresholds, whereas LLM-generated cost-benefit analysis at individual patient-levels. The system was well received according to the evaluation by clinicians. However, feedback emphasizes the need to strengthen the technical accuracy for speculative tasks. Conclusion: CAP utilizes LLM agents to integrate ML classifier outcomes and cost-benefit analysis for more transparent and interpretable decision support.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2511.15357v1", "url_pdf": "https://arxiv.org/pdf/2511.15357.pdf", "meta_path": "data/raw/arxiv/meta/2511.15357.json", "sha256": "9d1e70f7389ba139444e217d8e888fa1dbd9a22051c0cfcbb1cedd67cb1a9b51", "status": "ok", "fetched_at": "2026-02-18T02:26:35.964155+00:00"}, "pages": [{"page": 1, "text": "Cost-Aware Prediction (CAP): An LLM-Enhanced Machine Learning Pipeline\nand Decision Support System for Heart Failure Mortality Prediction\nYinan Yu1∗, Falk Dippel2, Christina E. Lundberg3,5, Martin Lindgren3,4,\nAnnika Rosengren3,4, Martin Adiels6, Helen Sjöland3,4\n1Department of Computer Science and Engineering, Chalmers University of Technology and University of Gothenburg, Gothenburg, Sweden\n2Sahlgrenska University Hospital, Gothenburg, Sweden\n3Department of Molecular and Clinical Medicine, Sahlgrenska Academy, University of Gothenburg, Gothenburg, Sweden\n4Department of Medicine, Geriatrics and Emergency Medicine, Sahlgrenska University Hospital, Gothenburg, Sweden\n5Department of Food and Nutrition, and Sport Science, Faculty of Education, University of Gothenburg, Gothenburg, Sweden\n6School of Public Health and Community Medicine, Institute of Medicine, University of Gothenburg, Gothenburg, Sweden\nAbstract\nObjective\nMachine learning (ML) predictive models are often developed without considering downstream value\ntrade-offs and clinical interpretability. This paper introduces a cost-aware prediction (CAP) framework that com-\nbines cost–benefit analysis assisted by large language model (LLM) agents to communicate the trade-offs involved in\napplying ML predictions.\nMaterials and Methods\nWe developed an ML model predicting 1-year mortality in patients with heart failure (N =\n30, 021, 22% mortality) to identify those eligible for home care. We then introduced clinical impact projection (CIP)\ncurves to visualize important cost dimensions – quality of life and healthcare provider expenses, further divided into\ntreatment and error costs, to assess the clinical consequences of predictions. Finally, we used four LLM agents to\ngenerate patient-specific descriptions. The system was evaluated by clinicians for its decision support value.\nResults\nThe eXtreme gradient boosting (XGB) model achieved the best performance, with an area under the re-\nceiver operating characteristic curve (AUROC) of 0.804 (95% confidence interval (CI) 0.792–0.816), area under the\nprecision-recall curve (AUPRC) of 0.529 (95% CI 0.502–0.558) and a Brier score of 0.135 (95% CI 0.130–0.140).\nDiscussion\nThe CIP cost curves provided a population-level overview of cost composition across decision thresh-\nolds, whereas LLM-generated cost-benefit analysis at individual patient-levels. The system was well received accord-\ning to the evaluation by clinicians. However, feedback emphasizes the need to strengthen the technical accuracy for\nspeculative tasks.\nConclusion\nCAP utilizes LLM agents to integrate ML classifier outcomes and cost-benefit analysis for more trans-\nparent and interpretable decision support.\nKeywords: Cost-Benefit Analysis; Clinical Decision Support Systems; Large Language Models; Heart Failure;\nPredictive Learning Model\nIntroduction\nThe use of clinical prediction models based on artificial intelligence (AI) holds high promise in medicine, but transition\nto clinical practice remains challenging. Clinical decision-making seeks to balance available patient information to\noptimise favourable outcomes and minimise harm. Likewise, clinical decision support systems (CDSSs) typically rest\n∗Corresponding author: Yinan Yu, yinan@chalmers.se\nUnder review.\narXiv:2511.15357v1  [cs.LG]  19 Nov 2025\n"}, {"page": 2, "text": "on multi-objective optimisations as clinical information is computationally combined and translated to finding a local\nminimum of risk based on the variables included.\nImplementation of CDSS ultimately depends on satisfying regulatory requirements and earning clinicians´ trust by\npresenting interpretable AI outputs, communicating the relation between competing objectives, for example, minimis-\ning cost while maximising performance and safety1.\nOne method for achieving understandable AI is to present the predicted outcome to the clinician using a decision\ncurve to illustrate benefit relative to risk2. A decision curve will describe the theoretical risk prediction for an unde-\nsirable outcome in an individual patient in the presence or absence of an intervention recommended by the CDSS and\nat various levels of probability.\nHeart failure is a prevalent condition among older individuals3, that drives substantial healthcare costs through\nrecurrent hospitalisations, despite the fact that the condition can often successfully be treated at home4–6. Here, we\nreport the design of a machine learning (ML) prediction model for mortality in patients with severe heart failure, aimed\nat supporting care-level recommendations – either customised home care as an intervention or hospital readmission\nas standard care – during periods of worsening health. Beyond predicting 1-year all-cause mortality, we proceed\nto address downstream consequences such as patient’s quality of life (QoL) and healthcare resource use through the\ndevelopment of an interpretable and cost-aware predictive framework, called cost-aware prediction (CAP). A semi-\nquantitative measure is employed to estimate patient-centred costs (e.g. patient outcomes and QoL) and costs for the\nhealthcare provider (e.g. resource allocation and monetary expenses) as examples. The CAP framework illustrates\nhow outcomes can be optimised under varying conditions by balancing these cost dimensions, while delivering high-\naccuracy predictions and interpretable decision curves. Finally, we attempt to explain the underlying calculations by\nuser-targeted natural language explanations to facilitate interpretation and to support informed clinical decisions.\nMethods\nWe introduce a decision-support framework, cost-aware prediction (CAP) that integrates three components into an\ninterpretable system to support informed decision-making in clinical practice.\nDataset and prediction outcome\nThis study includes patients (N = 34, 139), 18 years and older, with a first in-hospital heart failure diagnosis between\nJanuary 1, 2017 and December 31, 2023. Diagnoses were registered by codes I110, I130, I132, any I42 or any\nI50 in any position, according to the International Classification of Diseases (10th revision) (ICD-10). Patient data\nwas collected from a comprehensive database of electronic health records (EHRs) covering all hospital-admissions at\nemergency care providers in the Region Västra Götaland (VGR) of Sweden between January 1st 2014 and December\n31th 2023 to allow for 3 years of prior history. Sweden has universal healthcare providing low-cost hospital care to all\nresidents. After exclusion of patients with missing information (N = 735), and patients who died during the initial\nhospitalisation (N = 3, 383), the final cohort consisted of N = 30, 021 patients (Fig. 1).\nFirst in-hospital heart\nfailure diagnosis since\nJanuary 1st 2017:\nN = 34, 139\nFinal cohort:\nN = 30, 021\nN = 735: Incomplete data\nN = 3, 383: Death during\ninitial hospitalisation\nFigure 1: Cohort flow chart indicating selection process\nClinical variables from patient data included: age, sex, body mass index, length of stay, comorbidities along with\nprevious surgeries or interventions within the last 3 years, prescribed drugs within the last year prior to hospitalisation,\nvital signs and laboratory tests during hospitalisation, and physical mobility extracted from health records within the\nlast 30 days before diagnostic date. For multiple measurements of the same vital sign or laboratory test, the average\n2\n"}, {"page": 3, "text": "value was used for the respective hospitalisation. In total, 75 clinical variables were extracted from EHRs with variable-\nspecific information, such as ICD-10 codes used for comorbidities and Anatomical Therapeutic Chemical (ATC) codes\nfor medications, provided in Supplementary Table S1.\nThe prediction outcome of the ML model was all-cause mortality within 1 year after discharge after receiving a first\nheart failure diagnosis during hospitalisation.\nComponent 1: Supervised ML model\nThe first component is a supervised ML predictive model that produces a risk score between 0 and 1 for every patient.\nThis score represents the likelihood that an event will occur. To turn this score into a yes-or-no decision, a threshold\nmust be chosen (for example, a decision may be made that patients with a score above 0.7 will be classified as high\nrisk).\nComponent 2: Visualisation of clinical impact factors\nIn ML, a classification result can be true positive (TP) (a patient correctly predicted to have a high probability of\nmortality within one year, and who in fact does die within that time), a false positive (FP) (a patient predicted to have\na high probability of mortality within one year, but who actually survives beyond that time), a true negative (TN)\n(a patient correctly predicted to have a low probability of mortality, and who indeed survives beyond the year), or\na false negative (FN) (a patient predicted to have a low probability of mortality, but who dies within the year). It\nis commonly assumed that improved predictive accuracy automatically translates into greater clinical benefits, often\nwithout explicitly accounting for the associated clinical impact. This assumption implicitly categorises FPs and FNs\nas universally “bad”, while treating TPs and TNs as inherently “good”. This view overlooks that in clinical practice,\nrisks can arise even from accurate predictions. Such risks may be influenced by clinical actions triggered by the\nmodel’s outputs. Thus, while predictive accuracy remains critical, understanding the downstream impact of ML-based\npredictions is essential for improving interpretability.\nTo address this, we introduce the clinical impact projection (CIP) curve, where the term cost represents the clinical\nand organisational impact of decisions made based on model predictions. Our design of CIP considers two clinically\nrelevant dimensions:\n• QoL cost: typically captures the patient’s lived experience, including aspects relevant to their well-being during\ncare. Lower values indicate better QoL, such as when a patient receives care that is appropriate and minimally\nintrusive in a familiar environment. A negative QoL cost indicates increased QoL compared to the baseline.\n• Healthcare system cost: Reflects the impact on healthcare resources, including hospital bed occupancy, staff\nworkload, and financial expenditures. Lower values indicate more efficient resource utilisation and reduced\nstrain on healthcare systems.\nFurthermore, for each dimension, CIP considers two types of costs: clinical treatment cost and classification error\ncost, reflecting the clinical consequences and classification impact, respectively. More detailed definition and calcu-\nlation of CIP can be found in Supplementary Section CIP implementation details. Note that users of CIP can define\nadditional cost dimensions and types specific for their context, and that our application represents an example of\nprioritised costs.\nComponent 3: Cost-benefit analysis using large language model\nClinicians often find ML model outputs difficult to interpret, particularly when clinical trade-offs must be consid-\nered7–9. Language models can complement ML decision support by explaining uncertainty and contextualising risks\nbased on patient data and clinical priorities. To address this, the final component of the framework integrates four\nlarge language model (LLM) agents to support interpretation of model outputs and associated cost–benefit trade-offs.\nEach agent addresses a key clinical question. The agents operate in a prompt-only mode, prioritising simplicity and\ntraceability over integration with external tools.\nAgent I. How certain is the risk prediction? Summarises prediction reliability for an individual patient, based on\ntheir risk score, decision threshold, and local model performance.\nAgent II. How do I interpret the CIP cost curves? Explains key contributors to patient-level cost, using treatment\nand error costs across QoL and healthcare system dimensions.\nAgent III. How can prediction uncertainty be reduced? Suggests actions (e.g. additional tests, record review) that\nmay improve prediction certainty.\n3\n"}, {"page": 4, "text": "Agent IV. How can future risks be mitigated? Provides forward-looking guidance based on predicted outcomes and\npotential care pathways.\nTo evaluate the system, we conducted two complementary expert reviews. One clinician, involved in methods de-\nvelopment, performed a structured assessment of the outputs for each agent (clinical development review), focusing on\naccuracy and relevance. In addition, two external clinicians (experienced practising specialists in emergency medicine\nand cardiology, respectively) conducted a clinical user review, evaluating interpretability, reliability, and usability of\nthe agents’ outputs through structured questions and open-ended feedback (Supplementary Section LLM-agent evalu-\nation details and Supplementary Table S6-S8).\nImplementation of the CAP framework\nHere, we will illustrate how to implement this pipeline applying our use case of eligibility for home care programs\nthrough 1-year mortality prediction.\nStep 1: ML classification model development\nThe first step is to develop and select the best performing model based on the ML metric; area under the precision-recall\ncurve and decision threshold based on the best F1 score (Supplementary Section Machine learning model metrics and\nMachine learning implementation details).\nStep 2: Population-level clinical impact visualisation\nBefore generating the visualisation (i.e., the CIP cost curves), clinicians must first define the cost structure. Costs need\nto be specified separately for each type, clinical dimension, and prediction outcome scenario (TP, FP, TN, and FN). In\nour case study, the costs (ranging from −1 to 1), were defined based on the following assumptions, which represent a\nclinical example to illustrate the CIP/CAP framework:\n• Treatment costs: When a patient (either TP or FP) is included in a home care programme, their QoL is expected\nto improve due to increased comfort, reduced hospitalisations, and greater autonomy. Thus, a negative QoL\ncost of −1.0 is assigned, which indicates maximum benefits. Simultaneously, healthcare costs decrease due to\nreduced hospital resource usage, represented as −0.5 in this example. For patients who remain in standard care\n(TN, FN), both costs are set to 0, as this reflects the default baseline.\n• Errors incur additional burden. In our study, a patient incorrectly classified as at high risk of mortality (FP) will\nreceive home care but eventually be rehospitalised, potentially delaying necessary treatment. This results in a\nmoderate QoL penalty of 0.5 and healthcare cost of 0.25. In the case of FN, a high-risk patient is not assigned\nto home care, potentially leading to a poor end-of-life experience and avoidable strain on the healthcare system.\nHence, this is assigned the highest penalty: QoL cost of 1.0 and healthcare cost of 1.0. Correct predictions (TP,\nTN) incur no error cost.\nGiven this baseline definition, the full cost matrix (determined by the consensus of clinicians involved in this project)\nis summarised in Table 1.\nTable 1: Assigned quality of life and healthcare costs per outcome scenario\nType\nScenario\nQoL cost\nHealthcare cost\nTreatment\nTP\n−1.0\n−0.5\nTreatment\nFP\n−1.0\n−0.5\nTreatment\nTN\n0.0\n0.0\nTreatment\nFN\n0.0\n0.0\nError\nTP\n0.0\n0.0\nError\nFP\n0.5\n0.25\nError\nTN\n0.0\n0.0\nError\nFN\n1.0\n1.0\nFN=false negative. FP=false positive. QoL=quality of life.\nTP=true positive. TN=true negative.\nWith the definitions of the cost dimensions in place, we compute expected costs at the population level by combining\nthe model’s prediction outputs (TP, FP, TN, FN) across a range of decision thresholds from 0 to 1. The CIP cost curves\n4\n"}, {"page": 5, "text": "are then calculated according to Supplementary Section CIP implementation details, which aggregates treatment and\nerror costs across the QoL and healthcare dimensions.\nTo visualise these components, we introduce a baseline, referred to as the zero cost curve, that separates costs\n(plotted above the baseline) from benefits (plotted below the baseline). Each cost is presented as distinct, colour-coded\nstacked areas above and below this reference line, respectively, providing an overview of cost composition. The upper\nboundary of the stacked areas (the silhouette of the curve) represents the net effect, calculated as total cost minus total\nbenefit at each threshold.\nStep 3: Patient-level cost-benefit analysis using four LLM agents\nIn this step, the system generates a structured clinical cost-benefit analysis tailored to an individual patient. The core\nprompt components are detailed in Table 2. Detailed prompts are provided in Supplementary Listing S1- S5. We used\nthe state-of-the-art LLM model gpt-4.1-2025-04-14 to implement the agent responses for the prompt queries.\nTable 2: Structure of prompts and input dependencies used to construct the four CAP decision support agents\nEach column (I–IV) represents a distinct decision support agent. Rows specify the contextual inputs and response dependencies required for each\nagent.\nType\nPrompt\nI\nII\nIII\nIV\nContext\nPatient clinical profile\n✓\n✓\n✓\n✓\nContext\nClassifier description\n✓\nContext\nClassifier decision threshold r\n✓\nContext\nClassifier performance summary near r\n✓\nContext\nPredicted risk score s\n✓\n✓\nContext\nClassifier performance summary near s\n✓\nContext\nCIP cost description\n✓\nContext\nCIP cost coefficients\n✓\nContext\nComposition of CIP cost curves near s\n✓\nContext\nResponse from I\n✓\n✓\nContext\nResponse from II\n✓\nQuery\nClassification risk analysis\n✓\nQuery\nClinical cost-benefit analysis\n✓\nQuery\nClassification risk mitigation\n✓\nQuery\nIntervention risk prediction and intervention\n✓\nCAP=cost-aware prediction. CIP=clinical impact projection. I=How certain is the risk prediction? II=How\ndo I interpret the CIP cost curves? III=How can prediction uncertainty be reduced? IV=How can future\nrisks be mitigated?\nEthics\nEthical approval of study was granted by the Swedish Ethical Review Authority, through the Ethics Committee of the\nUmeå University (EPN Reference: DNR 2021-02786).\nResults\nPatient baseline characteristics\nThe cohort had a median age of 79 years, 45% women and median hospital-admittance 6.1 days at baseline, with a\n1-year mortality of 22%. Patients who died were older, more often female and with longer hospital stays (85 years,\n48% women, 7.9 days, as compared with 78 years, 44% women and 5.8 days in survivors) as presented in Table 3.\nStatistical analysis was performed as in Supplementary Section Statistical testing.\nMachine learning performance\nWe developed various candidate models for the ML classifier, and implementation details are outlined in Supple-\nmentary Section Machine learning implementation details and Supplementary Table S2. Figure 2 visualises the re-\nceiver operating characteristic (ROC) curve, precision-recall curve (PRC) and calibration curve for all model candi-\ndates. Table 4 reports the bootstrapped estimates of area under the receiver operating characteristic curve (AUROC),\n5\n"}, {"page": 6, "text": "Table 3: Baseline characteristics of heart failure cohort - Table continues next page.\nVariable\nTotal\nSurvived\nDeceased within 1 year\np-value\nNumber of patients\n30021\n23499\n6522\n-\nAge and sex\nAge (years), median (IQR)\n79 (71, 86)\n78 (69, 85)\n85 (78, 90)\n<0.001\nSex\nWomen, n (%)\n13572 (45)\n10432 (44)\n3140 (48)\n<0.001\nBMI (kg/m2), median (IQR)\n26.5 (23.6, 30.4)\n26.8 (23.9, 30.7)\n24.7 (21.8, 28.6)\n<0.001\nVisit information\nICU stay, n (%)\n635 (2.1)\n523 (2.2)\n112 (1.7)\n0.01\nICU days, median (IQR)\n5.3 (2.1, 12.0)\n5.1 (2.1, 10.4)\n7.0 (2.1, 15.9)\n0.04\nIn-hospital days, median (IQR)\n6.1 (3.1, 10.9)\n5.8 (3.0, 10.0)\n7.9 (4.2, 13.7)\n<0.001\nComorbidities, n (%)\nCCI, median (IQR)\n3 (2, 4)\n2 (1, 4)\n4 (2, 6)\n<0.001\nMain heart failure diagnosis\n10993 (37)\n8565 (36)\n2428 (37)\n0.25\nAlcohol abuse\n895 (3.0)\n721 (3.1)\n174 (2.7)\n0.1\nAortic aneurysm\n1022 (3.4)\n795 (3.4)\n227 (3.5)\n0.73\nAortic stenosis\n2730 (9.1)\n1955 (8.3)\n775 (12)\n<0.001\nAsthma\n2808 (9.3)\n2244 (9.6)\n564 (8.6)\n0.03\nAtrial fibrillation\n15485 (52)\n11982 (51)\n3503 (54)\n<0.001\nCancer\n6352 (21)\n4349 (19)\n2003 (31)\n<0.001\nCardiomyopathy\n2346 (7.8)\n2156 (9.2)\n190 (2.9)\n<0.001\nChronic coronary syndrome\n5955 (20)\n4546 (19)\n1409 (22)\n<0.001\nChronic kidney disease\n4515 (15)\n3007 (13)\n1508 (23)\n<0.001\nCOPD\n4170 (14)\n3016 (13)\n1154 (18)\n<0.001\nDiabetes type 1\n1097 (3.6)\n861 (3.7)\n236 (3.6)\n0.89\nDiabetes type 2\n7598 (25)\n5833 (25)\n1765 (27)\n<0.001\nDyslipidemia\n9666 (32)\n7672 (33)\n1994 (31)\n<0.001\nGonarthrosis\n2505 (8.3)\n1965 (8.4)\n540 (8.3)\n0.85\nHeart failure ICD-10 code I50\n28174 (94)\n21870 (93)\n6304 (97)\n<0.001\nHypertension\n21130 (70)\n16213 (69)\n4917 (75)\n<0.001\nIschemic stroke\n2128 (7.1)\n1544 (6.6)\n584 (8.9)\n<0.001\nLeg fracture\n2038 (6.8)\n1400 (6.0)\n638 (9.8)\n<0.001\nMyocardial infarction\n4434 (15)\n3572 (15)\n862 (13)\n<0.001\nObesity\n3465 (12)\n2938 (12)\n527 (8.1)\n<0.001\nPulmonary embolism\n1140 (3.8)\n850 (3.6)\n290 (4.5)\n<0.001\nSubstance abuse\n1938 (6.5)\n1573 (6.7)\n365 (5.6)\n<0.001\nValvular disease\n2873 (9.6)\n2271 (9.7)\n602 (9.2)\n0.3\nPrevious surgery or interventions, n (%)\nCoronary angioplasty graft\n2371 (7.9)\n1943 (8.3)\n428 (6.6)\n<0.001\nCoronary artery bypass grafting\n1798 (6.0)\n1415 (6.0)\n383 (5.9)\n0.67\nHeart transplant\n27 (0.1)\n22 (0.1)\n5 (0.1)\n0.86\nPacemaker or defibrillator\n2539 (8.5)\n1949 (8.3)\n590 (9.0)\n0.06\nValve replacement\n1191 (4.0)\n957 (4.1)\n234 (3.6)\n0.08\nPrescribed drugs prior to diagnostic hospitalisation, n (%)\nACEi\n4875 (16)\n3977 (17)\n898 (14)\n<0.001\nAntiarrhythmics, class III\n789 (2.6)\n707 (3.0)\n82 (1.3)\n<0.001\nAngiotensin receptor blockers\n3207 (11)\n2526 (11)\n681 (10)\n0.49\nARNI\n330 (1.1)\n298 (1.3)\n32 (0.5)\n<0.001\nBeta blockers\n8947 (30)\n7121 (30)\n1826 (28)\n<0.001\nCardiac glycosides\n1893 (6.3)\n1486 (6.3)\n407 (6.2)\n0.83\nCardiac stimulants\n673 (2.2)\n560 (2.4)\n113 (1.7)\n<0.001\nLoop diuretics\n10854 (36)\n8003 (34)\n2851 (44)\n<0.001\nThiazide diuretics\n713 (2.4)\n547 (2.3)\n166 (2.5)\n0.33\nDiuretics, exclude thiazide\n483 (1.6)\n319 (1.4)\n164 (2.5)\n<0.001\nMRA\n4171 (14)\n3322 (14)\n849 (13)\n0.02\nSGLT2 inhibitors\n363 (1.2)\n311 (1.3)\n52 (0.8)\n<0.001\nACEi=angiotensin-converting enzyme inhibitors. ARNI=angiotensin receptor neprilysin inhibitors. BMI=body mass index. CCI=Charlson comor-\nbidity index.\nCOPD=chronic obstructive pulmonary disease.\nGFR=glomerular filtration rate.\nICU=intensive care unit.\nIQR=interquartile range.\nMRA=mineralocorticoid receptor antagonist. NT-proBNP=N-terminal pro b-type natriuretic peptide. SGLT2=sodium-glucose transport protein 2.\narea under the precision-recall curve (AUPRC) and Brier score (BS) for a more robust performance assessment.\nBoosting machines outperformed simpler models and were well calibrated according to the ideal calibration line.\nDue to the highest AUPRC out of all candidates, eXtreme gradient boosting (XGB) was chosen as the final model\n6\n"}, {"page": 7, "text": "Table 3: Baseline characteristics of heart failure cohort - continued.\nVariable\nTotal\nSurvived\nDeceased within 1 year\np-value\nVital signs, median (IQR)\nDiastolic blood pressure (mmHg)\n74 (69, 80)\n75 (69, 81)\n72 (67, 78)\n<0.001\nSystolic blood pressure (mmHg)\n132 (120, 145)\n132 (121, 145)\n129 (117, 142)\n<0.001\nBody temperature (°C)\n36.7 (36.4, 36.9)\n36.7 (36.5, 36.9)\n36.6 (36.4, 36.9)\n<0.001\nPulse rate (beats/min)\n78 (70, 88)\n78 (69, 88)\n80 (72, 89)\n<0.001\nRespiratory rate (breaths/min)\n19 (17, 22)\n19 (17, 21)\n20 (18, 23)\n<0.001\nOxygen saturation (%)\n96 (94, 97)\n96 (94, 97)\n95 (93, 96)\n<0.001\nLaboratories, median (IQR)\nAlbumin (34–45 g/L)\n33 (29, 36)\n33 (30, 36)\n31 (27, 34)\n<0.001\nBilirubin (5–25 µmol/L)\n12 (8, 17)\n12 (8, 17)\n12 (8, 17)\n0.02\nBlood urea nitrogen (F/M 8.7–22/9.8–23 mg/dL)\n21 (16, 26)\n20 (16, 25)\n24 (19, 28)\n<0.001\nC-reactive protein (0–5 mg/L)\n19 (5, 61)\n16 (5, 58)\n30 (10, 71)\n<0.001\nCreatinine (F/M 45–90/60–105 µmol/L)\n88 (72, 107)\n86 (71, 105)\n93 (73, 114)\n<0.001\nFerritin (F/M 5–105/27–400 µg/L)\n99 (44, 192)\n100 (44, 190)\n94 (46, 199)\n0.92\nFasting glucose (4–6.9 mmol/L)\n6.1 (5.4, 7.0)\n6.1 (5.4, 7.0)\n6.2 (5.5, 8.0)\n0.1\nPlasma glucose (4–6.3 mmol/L)\n6.8 (6.1, 7.6)\n6.8 (6.1, 7.5)\n6.9 (6.2, 7.6)\n<0.001\nHemoglobin (F/M 117–153/134–170 g/L)\n124 (109, 138)\n125 (111, 139)\n118 (104, 131)\n<0.001\nGlycated hemoglobin (31–46 mmol/mol)\n39 (35, 45)\n38 (35, 44)\n41 (36, 49)\n<0.001\nNT-proBNP (0–400 ng/L)\n4169 (1870, 8843)\n3634 (1641, 7570)\n6917 (3190, 14400)\n<0.001\nPotassium (3.5–4.6 mmol/L)\n4.0 (3.8, 4.3)\n4.0 (3.8, 4.3)\n4.1 (3.8, 4.4)\n0.27\nSodium (136–145 mmol/L)\n139 (137, 141)\n139 (137, 141)\n139 (137, 141)\n0.1\nAlanine transaminase (F/M 0.25–0.60/0.25–0.75 µkat/L)\n0.4 (0.3, 0.6)\n0.4 (0.3, 0.6)\n0.3 (0.2, 0.5)\n<0.001\nAspartate transaminase (F/M 0.25–0.75/0.25–1.1 µkat/L)\n0.4 (0.3, 0.6)\n0.4 (0.3, 0.6)\n0.4 (0.2, 0.6)\n<0.001\nTroponin I (F/M 0–16/0–35 ng/L)\n14 (6, 25)\n13 (6, 25)\n15 (7, 25)\n0.11\nTroponin T (0–14 ng/L)\n15 (11, 18)\n15 (11, 18)\n17 (12, 19)\n<0.001\nUric acid (F/M 155–400/230–480 µmol/L)\n416 (322, 513)\n413 (320, 510)\n424 (336, 524)\n0.31\nEstimated GFR (mL/min/1.73m2)\n57 (45, 70)\n59 (47, 71)\n50 (40, 63)\n<0.001\nPhysical mobility\nPhysical status, median (IQR)\n0 (0, 1)\n0 (0, 1)\n0 (0, 2)\n<0.001\nPressure wounds, n (%)\n3606 (12)\n2413 (10)\n1193 (18)\n<0.001\nACEi=angiotensin-converting enzyme inhibitors. ARNI=angiotensin receptor neprilysin inhibitors. BMI=body mass index. CCI=Charlson comor-\nbidity index.\nCOPD=chronic obstructive pulmonary disease.\nGFR=glomerular filtration rate.\nICU=intensive care unit.\nIQR=interquartile range.\nMRA=mineralocorticoid receptor antagonist. NT-proBNP=N-terminal pro b-type natriuretic peptide. SGLT2=sodium-glucose transport protein 2.\nfor clinical application. The discriminatory capability of XGB resulted in AUROC = 0.804 (95% CI 0.792–0.816)\nand AUPRC = 0.529 (95% CI 0.502–0.558) with a calibration of BS = 0.135 (95% CI 0.130–0.140). The decision\nthreshold td = 0.25 was identified at the maximal F1 score F1max = 0.543 (Supplementary Fig. S2).\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n1\nSpecificity\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nSensitivity\nA\nNo skill (AUROC=0.5)\nLR (AUROC=0.786)\nRF (AUROC=0.796)\nLGB (AUROC=0.805)\nXGB (AUROC=0.804)\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nRecall\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nPrecision\nB\nNo skill (AUPRC=0.217)\nLR (AUPRC=0.493)\nRF (AUPRC=0.509)\nLGB (AUPRC=0.524)\nXGB (AUPRC=0.529)\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nMean predicted probability\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nObserverd proportion\nC\nIdeal calibration\nLR (BS=0.139)\nRF (BS=0.139)\nLGB (BS=0.135)\nXGB (BS=0.135)\nFigure 2: Visual comparison of discriminative and calibration performance of model candidates\nReceiver operating characteristic curve (A), precision-recall curve (B) and calibration curve (C) demonstrate highest predictive performance for\ngradient boosting machines based on the test set. AUPRC= area under the precision-recall curve. AUROC=area under the receiver operating\ncharacteristic curve. BS=Brier score. LGB=light gradient boosting machine. LR=logistic regression. RF=random forest. XGB=eXtreme gradient\nboosting.\n7\n"}, {"page": 8, "text": "Table 4: Bootstrapped performance comparison of model candidates\nAUROC, AUPRC and BS are reported with 95% CIs. Best performances are highlighted in bold.\nModel\nAUROC\nAUPRC\nBS\nLR\n0.786\n0.494\n0.139\n(0.772-0.799)\n(0.466-0.524)\n(0.134-0.144)\nRF\n0.797\n0.510\n0.139\n(0.784-0.809)\n(0.481-0.539)\n(0.135-0.144)\nLGB\n0.806\n0.525\n0.135\n(0.793-0.818)\n(0.495-0.554)\n(0.130-0.140)\nXGB\n0.804\n0.529\n0.135\n(0.792-0.816)\n(0.502-0.558)\n(0.130-0.140)\nAUPRC= area under the precision-recall curve.\nAU-\nROC=area under the receiver operating characteristic curve.\nBS=Brier score.\nLGB=light gradient boosting machine.\nLR=logistic regression. RF=random forest. XGB=eXtreme\ngradient boosting.\nCIP cost curves\nFigure 3 presents the CIP cost curves at different thresholds with a shaded (coloured yellow) risk band, illustrating\nindividual risk, here exemplified for synthetic patient 1. The detailed synthesis process is described in Supplementary\nSection Synthetic patient generation for LLM prompts. The results from the CIP visualisations provide insights into\nthe clinical impact at the patient-specific predicted risk in comparison to the decision threshold. Moreover, the risk\nband highlights the relative change in competing costs.\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nThreshold\n3.0\n2.5\n2.0\n1.5\n1.0\n0.5\n0.0\n0.5\nCost\nDecision\nthreshold (0.24):\nQoL error: 20%\nHC error: 14%\nQoL treatment: 44%\nHC treatment: 22%\nPredicted risk (0.10):\nQoL error: 18%\nHC error: 9%\nQoL treatment: 49%\nHC treatment: 24%\nTotal cost curve\nZero cost curve\nQoL error\nHC error\nQoL treatment\nHC treatment\nFigure 3: CIP cost curves visualises different cost contributions\nCIP cost curves combine the cost curves for prediction error and treatment costs at varying decision thresholds taking different cost dimensions,\nnamely patient’s QoL and healthcare system, into account. At the population-level, the stacked cost contributions highlight the clinical impact\nbetween potentially competing factors. At the patient-level, CIP visualises the cost-benefit within a risk band (yellow shade) of the patient-specific\nrisk prediction in relation to the decision threshold. CIP=clinical impact projection. HC=health care. QoL=quality of life.\nEvaluation by clinicians\nThe outcome was evaluated by three clinicians (one clinician for development review and two for user review as in\nSupplementary Section LLM-agent evaluation details). The review is conducted on 10 synthetic patients (Supple-\nmentary Table S5). The clinical development review focused on two key aspects: reliability and clinical accuracy,\nand it included an inventory of common themes of insatisfactory quality in its outputs with respect to the specific\nLLM-agents. A prototype of the CAP framework used for clinical evaluation can be found in Supplementary Fig. S4.\nThe evaluation revealed clear differences in the perceived reliability and accuracy of the four agent outputs (Likert\nscale, 1–5). Agent I (\"How certain is the risk prediction?\") received the highest ratings, with a reliability score of 4.70\n8\n"}, {"page": 9, "text": "and accuracy score of 4.20 across all patients. While generally well-received, the reviewer noted occasional inappro-\npriate terminology and the inclusion of unsupported advice. Agent II (\"How do I interpret the CIP cost curves?\") was\nrated as reliable (4.00), but accuracy was lower (2.10), due to speculative statements regarding QoL and healthcare\ncost consequences. Agent III (\"How can prediction uncertainty be reduced?\") achieved moderate ratings (reliability\n3.60, accuracy 2.30), with qualitative feedback indicating that the advice was sometimes overconfident and partially\nunsubstantiated. Agent IV (\"How can future risks be mitigated?\") received the lowest scores (reliability 2.60, accuracy\n1.70), with the reviewer describing the guidance as unrealistic and frequently ungrounded.\nWe categorised the identified themes into 11 categories, which were annotated during the development review. The\nfive most common issues were: (1) incorrect or overreaching medical terminology; (2) overly confident and imperative\nadvice (e.g. use of \"shall\", \"must\"); (3) unrealistic, unfeasible, or idealistic recommendations; (4) unasked-for or\nunsolicited advice; and (5) overbearing or overly prescriptive advice concerning minor details.\nThe clinical user review was conducted across the same 10 patient cases, with clinicians providing both Likert-scale\nratings (1–5) and qualitative comments for each of the CAP components. For risk estimation, the users reported high\nconfidence when using the classifier’s risk estimate in combination with the tool, with consistent feedback that the\ntool enhanced their risk assessment process. The generated risk explanations were generally seen as clear and useful,\nthough in some cases they added little beyond what the risk score already conveyed. The CIP cost curves received\nmixed feedback. The users found the concept useful for illustrating trade-offs. The tool’s uncertainty handling was\nappreciated, particularly its suggestions for reducing uncertainty, though these were sometimes too generic or incom-\nplete for very complex cases. Importantly, the tool did not create a false sense of reassurance; the user consistently\nnoted it maintained appropriate caution.\nDiscussion\nOur work focuses on the development of interpretable predictive models for 1-year all-cause mortality in heart failure,\nstructured around three central questions. Q1: Why does the model make a positive or negative prediction? Q2: What\nare the consequences of acting on the model’s predictions in clinical care? Q3: How sensitive and robust are these\npredictions when used in practice?\nEuropean Union AI legal requirements\nImportantly, the European Union AI act poses legally binding requirements on transparency, safety, accountability\nand ethics for development of AI to be applied in health care (Artificial intelligence act1). In particular, the EU\nAI Act requires clear definition, assessment, and governance of risks arising from the output of AI models. CIP\naddresses this by categorising risks into patient- and healthcare system–related dimensions, thereby aligning with the\nAct’s requirements. Each cost dimension reflects a distinct risk, presented within a structured framework where risks\nare evaluated based on both technical performance and real-world clinical and economic impact. Notably, the risks\nhere should be read as an relevant example of important considerations in heart failure but may be tailored to the\nuser´s needs. Moreover, the evaluation of these costs facilitates effective and transparent communications of risks, as\nstakeholders can clearly see the trade-offs between different decisions. Thus, the cost evaluation framework will aid\nin initial risk assessment but also enable the long-term safety, effectiveness, and accountability of the AI system.\nClinical feedback on LLM-agents\nThe cost-aware decision guidance, communicated by the LLM-agents, was rated positively and was helpful for assess-\ning future risk. However, the integration of patient-level and population-level information had a steep learning curve\nfor the evaluating clinicians. The generated explanations were generally well-received. The users felt the explanations\ncaptured key decision factors and expressed confidence about applying them in practice. There was little concern\nabout content falling outside established guidelines or evidence-based practice, though in complex cases, explanations\nincluded unnecessary details or became overly lengthy.\nThe clinical user review shows that the system was generally well-received for its ability to support risk estima-\ntion and explanation, suggesting that the LLM agents are most effective (accurate and helpful) in descriptive and\nexplanatory tasks. However, speculative or forward-looking guidance was unsatisfactory and requires further devel-\nopment. Overall, the clinical user review results suggest the system’s strengths lie in supporting risk communication\nand generating structured clinical explanations.\n9\n"}, {"page": 10, "text": "Potential applications for policymakers and healthcare financiers\nNote that although this paper addresses clinicians as stakeholders, it may also be relevant to hospital administrators\nand policymakers, and can be adjusted according to the selection of included costs. For example, whereas the correctly\nclassified groups, TP and TN, are clinically uncomplicated, the FN illustrate delivery of care that does not contribute\nto patient value although a costly choice in our model. For comparable conditions, the framework may be useful for\npolicymakers when planning the distribution of hospital beds versus home care.\nRelated work\nPrevious research has successfully demonstrated the application of ML models for prediction of all-cause mortality\nwithin 1 year for hospitalised heart failure patients10–15. ML models outperformed conventional heart failure risk\nscore models10,12,13. Among the various types of AI models, supervised classification models are generally the most\naccurate and reliable for clinical prediction tasks. These ML models follow well-established methods for development,\nvalidation, and evaluation, which favour trust in their results in clinical settings. Models of increasing complexity,\nsuch as neural networks16–18 and transformer-based architectures19,20, show potential for further gains but typically\nrequire larger datasets, may be less robust (high variance), and present greater interpretability challenges. Given the\nimportance of interpretability (Q1) complex model architectures were not prioritised.\nDespite advances in model development, the clinical utility of ML models remains limited, and the evaluation of\ndownstream effects of decisions seldom addressed or evaluated (Q2). In clinical practice, risk thresholds for manage-\nment decisions are rarely well defined but rest on clinical judgement, and the consequences of acting on predictions\nare often unclear.\nFrameworks such as the misclassification cost term (MCT)21 and decision curve analysis (DCA)2 aim to bridge\nthis gap. MCT quantifies optimal thresholds by balancing sensitivity, specificity, prevalence, and predefined costs of\nFP and FN. However, MCT tightly couples model behaviour to fixed cost terms defined during development, limiting\nflexibility. DCA visualises net benefit across thresholds, comparing model-guided decisions to treat-none and treat-all\nstrategies14,22–24, yet does not break down the cost structure of individual predictions. In contrast, the CIP cost curve\nprovides patient-level cost composition and by illustrating how sensitive these costs are to threshold changes (Q3).\nDCAs constructed for all model candidates can be found in Supplementary Fig. S3.\nTo enhance interpretability, LLMs have shown promise in clinical decision support25–28, including summarising\nmedical records and assisting with diagnostic reasoning. However, their integration into clinical workflows remains at\nan early stage. Recent studies have highlighted limitations29,30, such as inflexible reasoning, overconfidence in outputs,\nand susceptibility to errors in complex clinical scenarios. Moreover, LLMs are not inherently reliable for speculative\ntasks or generating outcomes beyond grounded evidence, as they are prone to hallucinations25–28. Evaluations indicate\nthat LLMs may underperform compared with human clinicians, particularly when processing unstructured or nuanced\npatient data. Findings from our exploratory study are consistent with these observations. Nonetheless, LLM-based\napproaches hold considerable potential, and further development with rigorous evaluation is warranted.\nStrengths and limitations\nOur model is built on a large, comprehensive, and representative regional cohort, ensuring reliable risk mapping,\nCIP/CAP, and reflecting real-world expectations for healthcare services. It can also simulate outcomes with cost con-\nsiderations to support threshold-setting in healthcare planning. However, data drift over time necessitates regular up-\ndates and validation on contemporary cohorts in the evolving and changing clinical environments. While LLM–based\nexplanations were generally well received, their performance in speculative reasoning and complex patient scenarios\nremains limited. Further refinement is needed to ensure their safe and reliable clinical use.\nConclusions\nWith CAP we propose a three-stage framework:\nFirstly, we showed that ML models can effectively predict all-cause mortality within 1 year in a heart failure cohort\nwith a first in-hospital diagnosis, with XGB identified as the best model based on the highest AUPRC.\nSecondly, on population-level we theoretically outlined cost matrices including treatment and prediction error costs\nfor two relevant cost dimensions, related to the patient’s QoL and the healthcare provider. We then conceptualised CIP\nto reflect the cost contributions associated with the predictions of the XGB classifier across various risk thresholds\nexpanding traditional ML metrics by accounting for the clinical impact on patient’s QoL and healthcare costs.\n10\n"}, {"page": 11, "text": "Thirdly, we integrated LLM agents into the CAP framework to communicate four different aspects of output inter-\npretation, for patient-level decision support.\nSupplementary information\nSupplementary information is available in the appendix.\nContributors\nYY: Conceptualization, Data curation, Formal analysis, Funding acquisition, Investigation, Methodology, Project ad-\nministration, Resources, Software, Supervision, Validation, Visualization, Writing – original draft, Writing – critical\nreview, commentary & editing. FD: Conceptualization, Data curation, Formal analysis, Investigation, Methodology,\nProject administration, Software, Visualization, Writing – original draft, Writing – critical review, commentary &\nediting. MA: Conceptualization, Data curation, Formal analysis, Methodology, Software, Writing – critical review,\ncommentary & editing. HS: Conceptualization, Funding acquisition, Methodology, Project administration, Resources,\nSupervision, Validation, Writing – original draft, Writing – critical review, commentary & editing. CEL: Methodol-\nogy, Writing – critical review, commentary & editing. ML: Methodology, Writing – critical review, commentary &\nediting. AR: Resources, Writing – critical review, commentary & editing.\nDeclaration of interests\nAll authors declare no conflict of interest.\nData sharing\nThe data and source code are not publicly available but will be made available upon reasonable request after internal\nreview.\nAcknowledgments\nThis work was supported by grants from the Swedish state under an agreement concerning research and education of\ndoctors (ALFGBG-991470 [to H.S.], ALFGBG-971608 [to M.L.]), the Swedish Research Council (2023-06421 [to\nH.S.], 2023-02144 [to A.R.]), the Swedish Heart and Lung Foundation (2024-0678 [to A.R.]), and Vinnova Advanced\nDigitalization (DNR 2024-01446 [to Y.Y. and H.S.]).\nReferences\n1 Council of European Union. Council regulation (EU) no 2024/1689; 2024.\nhttps://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=OJ:L_202401689\nAc-\ncessed June 15, 2025.\n2 Vickers AJ, Elkin EB. Decision Curve Analysis: A Novel Method for Evaluating Prediction Models. Medical\nDecision Making. 2006 Nov;26(6):565-74. Available from: http://journals.sagepub.com/doi/10.\n1177/0272989X06295361.\n3 Wideqvist M, Rosengren A, Schaufelberger M, Pivodic A, Fu M.\nTen year age- and sex-specific tem-\nporal trends in incidence and prevalence of heart failure in Västra Götaland, Sweden.\nESC Heart Fail-\nure. 2022;9(6):3931-41.\n_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/ehf2.14103.\nAvailable from:\nhttps://onlinelibrary.wiley.com/doi/abs/10.1002/ehf2.14103.\n11\n"}, {"page": 12, "text": "4 Desai AS, Stevenson LW.\nRehospitalization for Heart Failure:\nPredict or Prevent?\nCircula-\ntion. 2012 Jul;126(4):501-6.\nAvailable from:\nhttps://www.ahajournals.org/doi/10.1161/\nCIRCULATIONAHA.112.125435.\n5 Le N, Rahman T, Kapralik JL, Ibrahim Q, Lear SA, Van Spall HGC. The Hospital at Home Model vs Routine Hos-\npitalization for Acute Heart Failure: A Survey of Patients’ Preferences. CJC Open. 2022 Mar;4(3):263-70. Avail-\nable from: https://www.sciencedirect.com/science/article/pii/S2589790X21002754.\n6 Geng F, McGarry BE, Rosenthal MB, Zubizarreta JR, Resch SC, Grabowski DC. Preferences for Postacute Care\nat Home vs Facilities. JAMA Health Forum. 2024 Apr;5(4):e240678. Available from: https://doi.org/\n10.1001/jamahealthforum.2024.0678.\n7 Sanchez-Martinez S, Camara O, Piella G, Cikes M, González-Ballester MÁ, Miron M, et al. Machine learning\nfor clinical decision-making: challenges and opportunities in cardiovascular imaging. Frontiers in cardiovascular\nmedicine. 2022;8:765693.\n8 Mlodzinski E, Wardi G, Viglione C, Nemati S, Crotty Alexander L, Malhotra A. Assessing barriers to implemen-\ntation of machine learning and artificial intelligence–based tools in critical care: web-based survey study. JMIR\nPerioperative Medicine. 2023;6:e41056.\n9 Hou J, Wang LL. Explainable AI for Clinical Outcome Prediction: A Survey of Clinician Perceptions and Prefer-\nences. arXiv preprint arXiv:250220478. 2025.\n10 Adler ED, Voors AA, Klein L, Macheret F, Braun OO, Urey MA, et al. Improving risk prediction in heart failure\nusing machine learning. European Journal of Heart Failure. 2020 Jan;22(1):139-47. Available from: https:\n//onlinelibrary.wiley.com/doi/10.1002/ejhf.1628.\n11 Angraal S, Mortazavi BJ, Gupta A, Khera R, Ahmad T, Desai NR, et al. Machine Learning Prediction of Mortality\nand Hospitalization in Heart Failure With Preserved Ejection Fraction. JACC: Heart Failure. 2020 Jan;8(1):12-21.\nAvailable from: https://linkinghub.elsevier.com/retrieve/pii/S2213177919305414.\n12 Tohyama T, Ide T, Ikeda M, Kaku H, Enzan N, Matsushima S, et al. Machine learning-based model for predicting\n1 year mortality of hospitalized patients with heart failure. ESC Heart Failure. 2021 Oct;8(5):4077-85. Available\nfrom: https://onlinelibrary.wiley.com/doi/10.1002/ehf2.13556.\n13 Takahama H, Nishimura K, Ahsan B, Hamatani Y, Makino Y, Nakagawa S, et al. Clinical application of artifi-\ncial intelligence algorithm for prediction of one-year mortality in heart failure patients. Heart and Vessels. 2023\nJun;38(6):785-92.\n14 Tian P, Liang L, Zhao X, Huang B, Feng J, Huang L, et al. Machine Learning for Mortality Prediction in Patients\nWith Heart Failure With Mildly Reduced Ejection Fraction. Journal of the American Heart Association. 2023\nJun;12(12):e029124. Available from: https://www.ahajournals.org/doi/10.1161/JAHA.122.\n029124.\n15 Ketabi M, Andishgar A, Fereidouni Z, Sani MM, Abdollahi A, Vali M, et al. Predicting the risk of mortality\nand rehospitalization in heart failure patients: A retrospective cohort study by machine learning approach. Clin-\nical Cardiology;47(2):e24239. Available from: https://onlinelibrary.wiley.com/doi/10.1002/\nclc.24239.\n16 Kwon Jm, Kim KH, Jeon KH, Lee SE, Lee HY, Cho HJ, et al. Artificial intelligence algorithm for predicting\nmortality of patients with acute heart failure. PLOS ONE. 2019 Jul;14(7):e0219302. Available from: https:\n//dx.plos.org/10.1371/journal.pone.0219302.\n17 Wang Z, Zhu Y, Li D, Yin Y, Zhang J. Feature rearrangement based deep learning system for predicting heart failure\nmortality. Computer Methods and Programs in Biomedicine. 2020 Jul;191:105383. Available from: https:\n//linkinghub.elsevier.com/retrieve/pii/S0169260719316712.\n18 Li D, Fu J, Zhao J, Qin J, Zhang L. A deep learning system for heart failure mortality prediction. PLOS ONE. 2023\nFeb;18(2):e0276835. Available from: https://dx.plos.org/10.1371/journal.pone.0276835.\n12\n"}, {"page": 13, "text": "19 Pang C, Jiang X, Kalluri KS, Spotnitz M, Chen R, Perotte A, et al. CEHR-BERT: Incorporating temporal infor-\nmation from structured EHR data to improve prediction tasks. In: Machine Learning for Health. PMLR; 2021. p.\n239-60.\n20 Antikainen E, Linnosmaa J, Umer A, Oksala N, Eskola M, Van Gils M, et al. Transformers for cardiac patient\nmortality risk prediction from heterogeneous electronic health records. Scientific Reports. 2023 Mar;13(1):3517.\nAvailable from: https://www.nature.com/articles/s41598-023-30657-1.\n21 Greiner M, Pfeiffer D, Smith RD. Principles and practical application of the receiver-operating characteristic\nanalysis for diagnostic tests. Preventive Veterinary Medicine. 2000 May;45(1-2):23-41. Available from: https:\n//linkinghub.elsevier.com/retrieve/pii/S016758770000115X.\n22 Li F, Xin H, Zhang J, Fu M, Zhou J, Lian Z. Prediction model of in-hospital mortality in intensive care unit\npatients with heart failure: machine learning-based, retrospective analysis of the MIMIC-III database.\nBMJ\nOpen. 2021 Jul;11(7):e044779. Available from: https://bmjopen.bmj.com/lookup/doi/10.1136/\nbmjopen-2020-044779.\n23 Li J, Liu S, Hu Y, Zhu L, Mao Y, Liu J. Predicting Mortality in Intensive Care Unit Patients With Heart Failure Us-\ning an Interpretable Machine Learning Model: Retrospective Cohort Study. Journal of Medical Internet Research.\n2022 Aug;24(8):e38082. Available from: https://www.jmir.org/2022/8/e38082.\n24 Chen Z, Li T, Guo S, Zeng D, Wang K. Machine learning-based in-hospital mortality risk prediction tool for inten-\nsive care unit patients with heart failure. Frontiers in Cardiovascular Medicine. 2023 Apr;10:1119699. Available\nfrom: https://www.frontiersin.org/articles/10.3389/fcvm.2023.1119699/full.\n25 Shool S, Adimi S, Saboori Amleshi R, Bitaraf E, Golpira R, Tara M. A systematic review of large language model\n(LLM) evaluations in clinical medicine. BMC Medical Informatics and Decision Making. 2025;25(1):117.\n26 Vrdoljak J, Boban Z, Vilovi´c M, Kumri´c M, Boži´c J. A review of large language models in medical education,\nclinical decision support, and healthcare administration. In: Healthcare. vol. 13. MDPI; 2025. p. 603.\n27 Zhang K, Meng X, Yan X, Ji J, Liu J, Xu H, et al. Revolutionizing health care: The transformative impact of large\nlanguage models in medicine. Journal of Medical Internet Research. 2025;27:e59069.\n28 Denecke K, May R, LLMHealthGroup, Rivera Romero O. Potential of large language models in health care:\nDelphi study. Journal of Medical Internet Research. 2024;26:e52399.\n29 Li J, Zhou Z, Lyu H, Wang Z. Large language models-powered clinical decision support: enhancing or replacing\nhuman expertise?\nIntelligent Medicine. 2025;5(1):1-4. Available from: https://www.sciencedirect.\ncom/science/article/pii/S2667102625000014.\n30 Liu F, Li Z, Zhou H, Yin Q, Yang J, Tang X, et al. Large Language Models Are Poor Clinical Decision-Makers: A\nComprehensive Benchmark. In: Al-Onaizan Y, Bansal M, Chen YN, editors. Proceedings of the 2024 Conference\non Empirical Methods in Natural Language Processing. Miami, Florida, USA: Association for Computational\nLinguistics; 2024. p. 13696-710. Available from: https://aclanthology.org/2024.emnlp-main.\n759/.\n13\n"}, {"page": 14, "text": "Supplementary information\nTable S1: Data collection with detailed information, consisting of outcome for categorical and units for numerical\nfeatures along with missing percentage, and codes for clinical variables. ACEi=angiotensin-converting enzyme inhibitors.\nARNI=angiotensin receptor neprilysin inhibitors. BMI=body mass index. CCI=Charlson comorbidity index. COPD=chronic\nobstructive pulmonary disease. GFR=glomerular filtration rate. ICU=intensive care unit. MRA=mineralocorticoid receptor\nantagonist. NT-proBNP=N-terminal pro b-type natriuretic peptide. SGLT2=sodium-glucose transport protein 2. Table\ncontinues next page.\nVariable\nOutcome/Unit\nDetails (e.g., codes for extraction)\nMissing ratio in %\nDemographics\nAge\nyears\n0\nSex\n0: male, 1: female\n0\nBMI\nkg/m2\n54.69\nVisit information\nICU stay\n0: no, 1: yes\n0\nICU days\ndays\n97.88\nIn-hospital days\ndays\n0\nComorbidities\nCCI\n1\nCCI was caluclated using the comorbidipy pack-\nage version 0.5.0 with mapping variant charlson\nand weightning variant se.\n0\nMain heart failure diagnosis\n0: no, 1: yes\nQualifying heart failure diagnosis at primary po-\nsition\n0\nAlcohol abuse\n0: no, 1: yes\nF10\n0\nAortic aneurysm\n0: no, 1: yes\nI71\n0\nAortic stenosis\n0: no, 1: yes\nI350, I352\n0\nAsthma\n0: no, 1: yes\nJ45\n0\nAtrial fibrillation\n0: no, 1: yes\nI48\n0\nCancer\n0: no, 1: yes\nC\n0\nCardiomyopathy\n0: no, 1: yes\nI42, I43\n0\nChronic coronary syndrome\n0: no, 1: yes\nI259\n0\nChronic kidney disease\n0: no, 1: yes\nN18\n0\nCOPD\n0: no, 1: yes\nJ44\n0\nDiabetes type 1\n0: no, 1: yes\nE10\n0\nDiabetes type 2\n0: no, 1: yes\nE11\n0\nDyslipidemia\n0: no, 1: yes\nE78\n0\nGonarthrosis\n0: no, 1: yes\nM179\n0\nHeart failure\n0: no, 1: yes\nI50\n0\nHypertension\n0: no, 1: yes\nI10, I11, I12, I13, I15\n0\nIschemic stroke\n0: no, 1: yes\nI63\n0\nLeg fracture\n0: no, 1: yes\nS72, S82, S92\n0\nMyocardial infarction\n0: no, 1: yes\nI21\n0\nObesity\n0: no, 1: yes\nE66\n0\nPulmonary embolism\n0: no, 1: yes\nI26\n0\nSubstance abuse\n0: no, 1: yes\nF11, F12, F13, F14, F15, F16, F17, F18, F19\n0\nValvular disease\n0: no, 1: yes\nI05, I06, I07, I08, I09, I33, I34, I351, I36, I37, I38,\nI39\n0\nPrevious surgery or interventions\nCoronary angioplasty graft\n0: no, 1: yes\nZ955\n0\nCoronary artery bypass grafting\n0: no, 1: yes\nZ951\n0\nHeart transplant\n0: no, 1: yes\nZ941\n0\nPacemaker or defibrillator\n0: no, 1: yes\nZ950\n0\nValve replacement\n0: no, 1: yes\nZ952, Z953, Z954\n0\nPrescribed drugs prior to diagnostic hospitalisation\nACEi\n0: no, 1: yes\nC09AA01,\nC09AA02,\nC09AA03,\nC09AA05,\nC09AA10\n0\nAntiarrhythmics, class III\n0: no, 1: yes\nC01BD\n0\nAngiotensin receptor blockers\n0: no, 1: yes\nC09CA01, C09CA03, C09CA06\n0\nARNI\n0: no, 1: yes\nC09DX04\n0\nBeta blockers\n0: no, 1: yes\nC07AB02, C07AB07, C07AG02, C07AB12\n0\nCardiac glycosides\n0: no, 1: yes\nC01A\n0\nCardiac stimulants\n0: no, 1: yes\nC01C\n0\nLoop diuretics\n0: no, 1: yes\nC03C\n0\nThiazide diuretics\n0: no, 1: yes\nC03A\n0\nDiuretics, exclude thiazide\n0: no, 1: yes\nC03B\n0\nMRA\n0: no, 1: yes\nC03DA\n0\n1\n"}, {"page": 15, "text": "Variable\nOutcome/Unit\nDetails (e.g., codes for extraction)\nMissing ratio in %\nSGLT2 inhibitors\n0: no, 1: yes\nA10BK\n0\nVital signs\nDiastolic blood pressure\nmmHg\n5.78\nSystolic blood pressure\nmmHg\n5.11\nBody temperature\n°C\n6.49\nPulse rate\nbeats/min\n5.73\nRespiratory rate\nbreaths/min\n15.41\nOxygen saturation\n%\n6.04\nLaboratories\nAlbumin\ng/L\n27.81\nBilirubin\nµmol/L\n40.82\nBlood urea nitrogen\nmg/dL\n74.06\nC-reactive protein\nmg/L\n8.90\nCreatinine\nµmol/L\n11.95\nFerritin\nµg/L\n87.42\nFasting glucose\nmmol/L\n95.93\nPlasma glucose\nmmol/L\n16.39\nHemoglobin\ng/L\n4.17\nGlycated hemoglobin\nmmol/mol\n86.81\nNT-proBNP\nng/L\n41.67\nPotassium\nmmol/L\n4.44\nSodium\nmmol/L\n4.34\nAlanine transaminase\nµkat/L\n44.73\nAspartate transaminase\nµkat/L\n45.88\nTroponin I\nng/L\n79.23\nTroponin T\nng/L\n95.62\nUric acid\nµmol/L\n97.02\nEstimated GFR\nmL/min/1.73m2\nEstimated GFR was calculated using the Lund-\nMalmö formula LMR18.\n11.95\nPhysical mobility\nPhysical status\n0: walking without aid,\n1: walking with aid, 2:\nwheelchair, 3:\nbedrid-\nden\n0\nPressure wounds\n0: no, 1: yes\n0\nClinical consequences and interpretations\nThis section details the clinical consequences of our application. The implications of misclassification require\ncareful consideration. A FP prediction of high mortality risk may lead to premature withdrawal of hospital-\nbased treatment. This risk, while serious, can be mitigated through open-ended treatment plans that allow\nclinicians to override model-based recommendations based on evolving clinical assessments. Importantly,\nsuch flexibility must be maintained, as AI-based models are subject to stricter regulatory requirements than\ntraditional heuristic tools, such as clinical risk scores. Conversely, FNs risk depriving patients of appropriate\nhome-based palliative care, leading to unnecessary aggressive treatment and increased healthcare costs. In this\ncontext, the structured explanations generated by the LLM agents can support clinicians in identifying when\nmodel outputs warrant closer scrutiny, potentially enhancing the transparency and safety of decision-making.\nFurthermore, explicit modelling of the costs associated with FPs and FNs provides valuable insight for\npolicymakers and healthcare managers concerned with both clinical outcomes and resource allocation.\nMachine learning model metrics\nDeveloping the ML model involves several technical design choices, including selecting the appropriate model\ntype and tuning its hyperparameters. Model performance is evaluated on a test cohort with real-world\nelectronic health record data, using standard ML metrics such as precision and recall. Precision is defined as\nthe proportion of positive identifications that are actually correct (e.g., the proportion of patients correctly\nidentified as likely to die within a year out of all patients identified as such). Recall is the proportion of\nactual positives that are correctly identified (e.g., the proportion of patients who died within a year and were\ncorrectly identified by the model). We adopted the commonly used ML metric to evaluate and compare the\nperformance of different models: the area under the precision-recall curve with varying thresholds. This\nmetric can be used to automatically select the best overall performing model. To define an operational point\nof the best classifier for decision-making, the decision threshold is selected as the one that maximises the F1\n2\n"}, {"page": 16, "text": "score across all thresholds, where the F1 score measures the relationship between precision and recall as a\nsingle metric calculated as harmonic mean.\nMachine learning implementation details\nTo predict mortality within 1 year using ML, patient data was divided into 24,016 samples for model training\nand 6,005 samples for model evaluation stratified for mortality outcome. Four frequently used ML models\nwere employed: logistic regression (LR), random forest (RF), light gradient boosting machine (LGB) and\neXtreme gradient boosting (XGB). ML code and models were implemented in Python 3.10.13 with package\nversions scikit-learn 1.4.0, lightgbm 4.3.0 and xgboost 2.0.0.\nFeatures with more than 80% missing data were removed (Table S1). To address the remaining missingness,\nfeatures were imputed by the median. As an alternative to median imputation, k-Nearest Neighbors imputation\nwas applied but yielded similar results and was not considered further due to its higher computational cost.\nNumerical and ordinal features were normalised to [0, 1] and categorical features label encoded.\nFor all model candidates, hyperparameters were optimised using grid search and stratified 5-fold cross-\nvalidation on the training set to ensure equal class distribution in all folds. Models were evaluated by\nmaximising the area under the precision-recall curve to address class imbalance. The optimised hyperparame-\nters for all models are reported in Table S2. The best models were then retrained on the complete training set\nand evaluated on the unseen test set.\nThe model’s discriminatory capability was assessed using receiver operating characteristic (ROC) curve\nand precision-recall curve (PRC) with area under ROC curve (AUROC) and area under the precision-recall\ncurve (AUPRC) as threshold-independent metrics to summarise each curve. For the reliability of predicted\nprobabilities, calibration curve and Brier score (BS) were evaluated. The 95% confidence intervals (CI) for\nAUROC, AUPRC and BS were calculated with bootstrapping (1000 iterations). The best model candidate was\nidentified based on the highest AUPRC over AUROC and the respective decision threshold was determined\nby the highest F1 score to account for class imbalance in the data.\nCIP implementation details\nThe purpose of the CIP curve is to visualise how costs are distributed across decision thresholds. Users need\nto define the relevant cost terms for each clinical dimension (QoL and healthcare provider cost) and cost type.\nIn particular, we consider two cost types in this work,\n• Treatment cost (CT): The inherent cost of delivering a given care pathway (for example, hospital-based\ncare or home-based care), independent of prediction accuracy. This is defined relative to a baseline of the\nstandard treatment (for example, hospital-based care).\n• Error cost (CE): The additional cost arising from false positive or false negative predictions. This cost is\ndefined relative to the ground truth label.\nLet py(t) denote the empirical proportion of patients classified into outcome y at threshold t. The expected\ncost for a given cost type τ and dimension k at threshold t is defined as:\nE(Cτ\nk ; t) =\n∑\ny∈{TP,FP,FN,TN}\npy(t) · Cτ\nk (y)\n(1)\nwhere\n• k ∈{1, 2} denotes the cost dimension: C1 for QoL cost and C2 for healthcare system cost;\n• τ ∈{T, E} denotes the cost type: Treatment (T) or Error (E);\n• y ∈{TP, FP, FN, TN} represents the prediction outcome;\n• t ∈[0, 1] is the decision threshold applied to the classifier.\nThe expected cost varies depending on the decision threshold. By systematically evaluating a range of\nthresholds, we obtain the CIP curve – a population-level overview of the clinical cost implications expressed\nthrough these costs.\n3\n"}, {"page": 17, "text": "Statistical testing\nTo determine statistical significance (p-value ≤0.05) between non-events and events (deceased within 1 year),\nChi-square test was utilised for categorical features (clinical variables), t-test for two independent samples\nfor normally distributed numerical features and Mann-Whitney U rank test for non normally distributed\nnumerical features.\nTable S2: Hyperparameter optimisation setup using grid search with 5-fold cross-validation. LGB=light gradient boosting\nmachine. LR=logistic regression. RF=random forest. XGB=eXtreme gradient boosting.\nModel\nParameter\nSearch space\nFinal value\nLR\nsolver\n[liblinear, saga]\nsaga\npenalty\n[l1, l2]\nl1\nC\n[0.1, 1, 10, 100]\n1\nRF\nmax_depth\n[4, 8, 12]\n12\nn_estimators\n[100, 300, 500]\n500\nmin_samples_split\n[2, 5, 10]\n10\nmin_samples_leaf\n[1, 2, 4]\n1\nLGB\nmax_depth\n[4, 8, 12]\n12\nn_estimators\n[100, 300, 500]\n500\nlearning_rate\n[0.01, 0.1, 0.3]\n0.01\nsubsample\n[0.5, 0.8, 1]\n0.5\ncolsample_bytree\n[0.5, 0.8, 1]\n0.5\nreg_alpha\n[0, 1, 5]\n0\nreg_lambda\n[0, 1, 5]\n5\nnum_leaves\n[25, 50]\n50\nXGB\nmax_depth\n[4, 8, 12]\n8\nn_estimators\n[100, 300, 500]\n500\nlearning_rate\n[0.01, 0.1, 0.3]\n0.01\nsubsample\n[0.5, 0.8, 1]\n0.5\ncolsample_bytree\n[0.5, 0.8, 1]\n0.8\nreg_alpha\n[0, 1, 5]\n0\nreg_lambda\n[0, 1, 5]\n0\nSynthetic patient generation for LLM prompts\nTo evaluate the large language model (LLM) agents, synthetic patients were generated to allow for the\nreproducibility of the prompts used in the cost-aware prediction (CAP) framework. The design of the synthetic\npatient is limited to 20 features as the synthesis of nearly real-world patients is non-trivial and beyond the scope\nof this work. Each synthetic patient was reviewed by the clinicians in the project. The 20 features, denoted\nas the core set Score, include a demographic triplet (age, sex, body mass index) and 17 non-demographic\nfeatures with the highest contribution to the decision-making by the best classifier. Independent of the\nassigned contribution, the demographic triplet was included to contextualise the synthetic patient profiles\n(e.g., sex-dependent laboratory measurements).\nThe contribution of each feature was evaluated by the SHapley Additive exPlanation (SHAP) method. SHAP\nvalues are commonly used to explain the decision process of an ML model by quantifying the average impact\nof each individual feature on predictions across all possible feature combinations. Figure S1 summarises the\nSHAP distribution for the top 20 predictive features using XGB which yields the highest AUPRC performance\n(best classifier). Meanwhile, Table S3 presents the mean SHAP values for all features. To evaluate the\ncompetitiveness of XGB when the real patient data was restricted to the core set Score, the classifier was\nretrained on Score following the previously established implementation pipeline. The hyperparameter tuning\nwas omitted by reusing the hyperparameter setup optimised for Scomplete (69 features after preprocessing).\nFigure S2 highlights the comparison of the F1 score across various risk thresholds, demonstrating that the core\nset Score is competitive with Scomplete while resulting in a similar decision threshold. Furthermore, Table S4\nindicates only a minor performance drop across AUROC, AUPRC and BS.\nSince the performance comparison has verified that the reduced classifier performs nearly equally well, 10\nsynthetic patients were generated using the features in Score to utilise their profiles as prompt input for the\nLLM agents. The 10 synthetic profiles and their respective risk predictions are outlined in Table S5.\n4\n"}, {"page": 18, "text": "Table S3: Feature importance of best model (XGB) calculated by mean SHAP values. ACEi=angiotensin-converting\nenzyme inhibitors. ARNI=angiotensin receptor neprilysin inhibitors. BMI=body mass index. CCI=Charlson comor-\nbidity index. COPD=chronic obstructive pulmonary disease. GFR=glomerular filtration rate. ICU=intensive care unit.\nMRA=mineralocorticoid receptor antagonist. NT-proBNP=N-terminal pro b-type natriuretic peptide. SGLT2=sodium-\nglucose transport protein 2. SHAP=SHapley Additive exPlanations. XGB=eXtreme gradient boosting.\nVariable\nSHAPmean\nVariable\nSHAPmean\nAge\n0.4912\nSubstance abuse\n0.0086\nCCI\n0.2756\nTroponin I\n0.0072\nOxygen saturation\n0.214\nChronic kidney disease\n0.0068\nAlbumin\n0.1795\nAlcohol abuse\n0.0067\nBody temperature\n0.1597\nObesity\n0.0061\nSystolic blood pressure\n0.1347\nMyocardial infarction\n0.0061\nNT-proBNP\n0.1309\nAntiarrhythmics, class III\n0.0053\nRespiratory rate\n0.0905\nLeg fracture\n0.0049\nPhysical status\n0.0889\nBeta blockers\n0.0046\nPulse rate\n0.0884\nIschemic stroke\n0.0045\nHemoglobin\n0.0829\nDiabetes type 2\n0.0044\nBMI\n0.0759\nHypertension\n0.0041\nIn-hospital days\n0.0694\nMain heart failure diagnosis\n0.004\nC-reactive protein\n0.0693\nACEi\n0.0036\nSodium\n0.0646\nChronic coronary syndrome\n0.0035\nCancer\n0.0617\nValve replacement\n0.0019\nEstimated GFR\n0.0525\nPacemaker or defibrillator\n0.0019\nLoop diuretics\n0.0498\nMRA\n0.0018\nPotassium\n0.0463\nCardiac glycosides\n0.0015\nBlood urea nitrogen\n0.0445\nAngiotensin receptor blockers\n0.0014\nSex\n0.0404\nAortic aneurysm\n0.0013\nDiastolic blood pressure\n0.0387\nDiuretics, exclude thiazide\n0.0013\nPressure wounds\n0.0341\nCoronary artery bypass grafting\n0.0012\nAlanine transaminase\n0.0312\nThiazide diuretics\n0.0011\nCreatinine\n0.0284\nValvular disease\n0.0011\nPlasma glucose\n0.0251\nDiabetes type 1\n0.0011\nAspartate transaminase\n0.024\nICU stay\n0.0009\nBilirubin\n0.0205\nHeart failure\n0.0009\nAortic stenosis\n0.0179\nCoronary angioplasty graft\n0.0009\nDyslipidemia\n0.0124\nPulmonary embolism\n0.0005\nCardiomyopathy\n0.0117\nSGLT2 inhibitors\n0.0005\nAsthma\n0.0115\nCardiac stimulants\n0.0003\nAtrial fibrillation\n0.0114\nARNI\n0.0002\nGonarthrosis\n0.0112\nHeart transplant\n0.0\nCOPD\n0.0112\n1.5\n1.0\n0.5\n0.0\n0.5\n1.0\nSHAP value\nBlood urea nitrogen\nPotassium\nLoop diuretics\nEstimated GFR\nCancer\nSodium\nC-reactive protein\nIn-hospital days\nBMI\nHemoglobin\nPulse rate\nPhysical status\nRespiratory rate\nNT-proBNP\nSystolic blood pressure\nBody temperature\nAlbumin\nOxygen saturation\nCCI\nAge\nLow\nHigh\nFeature value\nFigure S1: Top 20 clinical predictors of best model (XGB) visualised by the SHAP values of each sample and ranked by\nmean SHAP values. SHAP=SHapley Additive exPlanations. XGB=eXtreme gradient boosting.\n5\n"}, {"page": 19, "text": "0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nThreshold\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\nF1 score\nComplete feature set\nCore feature set\nDecision threshold\n(td=0.25, F1max=0.543)\nDecision threshold\n(td=0.24, F1max=0.543)\nFigure S2: Performance comparison of F1 score\nagainst various thresholds for the best model\n(XGB) trained on the original high-dimensional\nfeature space Scomplete (69 features) versus a core\nset Score (20 features). Evaluation was performed\non the same test set, where each instance was\nrepresented by either the complete set or core\nset of clinical variables. XGB=eXtreme gradient\nboosting.\nTable S4: Performance comparison of the XGB model trained and\nevaluated either on the complete set of clinical variables Scomplete\nor the core set of clinical variables Score. AUROC, AUPRC and BS\nare reported with 95% CI. AUPRC=area under the precision-recall\ncurve. AUROC=area under the receiver operating characteristic\ncurve. BS=Brier score. XGB=eXtreme gradient boosting.\nModel\nSet\nAUROC\nAUPRC\nBS\nXGB\nScomplete\n0.804\n0.529\n0.135\n(69 features)\n(0.792-0.816)\n(0.502-0.558)\n(0.130-0.140)\nXGB\nScore\n0.802\n0.520\n0.135\n(20 features)\n(0.789-0.815)\n(0.494-0.549)\n(0.131-0.140)\nTable S5: Overview of synthetic heart failure patients. The respective risks are predicted by the best classifier (XGB).\nValues highlighted in grey simulate missing values that are imputed. Alb=albumin. BMI=body mass index. C=cancer.\nCCI=Charlson comorbidity index. CRP=C-reactive protein. Days=in-hospital days. eGFR=estimated glomerular filtration\nrate. Hb=hemoglobin. HD=loop diuretics. Id=patient identifier. K=potassium. Na=sodium. NT-proBNP=N-terminal pro\nb-type natriuretic peptide. O2=oxygen saturation. PR=pulse rate. PS=physical status. RR=respiratory rate. SBP=systolic\nblood pressure. Temp=body temperature. XGB=eXtreme gradient boosting.\nId Age Sex BMI CCI O2\nAlb Temp SBP NT-proBNP RR PS PR Hb\nDays CRP Na\nC eGFR HD K\nRisk\n1\n86\n0\n26.5\n2\n85\n37\n37.2\n161\n2424\n17\n1\n75\n145 5.1\n20\n140 0\n52\n0\n4.1 0.010\n2\n70\n0\n26.5\n1\n95\n33\n36.5\n134\n252\n19\n1\n81\n144 2.1\n20\n141 0\n55\n0\n4.0 0.025\n3\n85\n0\n26.5\n2\n90\n33\n37.0\n146\n4142\n19\n1\n82\n151 6.5\n22\n140 0\n56\n0\n4.2 0.208\n4\n65\n1\n26.5\n7\n92\n30\n38.2\n154\n4142\n17\n0\n75\n170 5.2\n19\n141 1\n50\n1\n4.5 0.132\n5\n79\n0\n26.5\n5\n89\n33\n36.2\n145\n15241\n23\n2\n79\n125 7.1\n21\n150 1\n52\n0\n4.4 0.62\n6\n69\n1\n21.3\n1\n94\n35\n36.7\n125\n4142\n22\n0\n80\n156 1.9\n25\n131 0\n49\n0\n4.1 0.077\n7\n77\n1\n26.5\n5\n88\n42\n36.2\n140\n2000\n19\n1\n82\n121 6.7\n19\n135 0\n51\n0\n4.9 0.251\n8\n75\n1\n26.5\n5\n91\n38\n36.8\n147\n17450\n19\n2\n82\n135 1.6\n26\n141 0\n48\n1\n3.8 0.182\n9\n84\n1\n26.5\n4\n90\n34\n37.5\n153\n6123\n17\n1\n78\n154 2.4\n23\n138 1\n47\n0\n4.4 0.157\n10 72\n0\n25.2\n4\n92\n32\n37.1\n134\n1124\n17\n0\n79\n141 4.7\n27\n131 0\n58\n0\n4.1 0.144\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nThreshold\n0.15\n0.10\n0.05\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\nNet benefit\ntreat-none\ntreat-all\nLR\nRF\nLGB\nXGB\ntreat-none\ntreat-all\nLR\nRF\nLGB\nXGB\nFigure S3: Clinical applicability of all model candidates at different risk thresholds illustrated by decision curve analysis\nfrom the test set. LGB=light gradient boosting machine. LR=logistic regression. RF=random forest. XGB=eXtreme gradient\nboosting.\n6\n"}, {"page": 20, "text": "Listing S1 How certain is the risk prediction? (Agent I) for synthetic patient 1\n1## System\n2You are a highly precise medical AI assistant with expertise in clinical decision support.\n3Your primary role is to assist clinicians in **objectively conducting cost-benefit analysis of AI-based risk models** for patient care.\n4\n5Your responses must be:\n6- Clear and structured.\n7- Supported by patient condition and numerical reasoning.\n8- Informative and specific about the patient.\n9\n10Avoid:\n11- Subjective or vague recommendations.\n12- Stating obvious facts.\n13\n14 ==========\n15\n16## Patient profile (the most important consideration factors):\n17The patient is diagnosed with heart failure (ICD-10 I50) in-hospital for the first time.\n18This is the patient info: {\"age_at_index\": 86, \"sex\": 0, \"BMI\": 26.5, \"CCI\": 2, \"saturation\": 85, \"albumin\": 37, \"body_temperature\": 37.2, \"blood_pressure_systolic\": 161,\n\"nt_probnp\": 2424, \"respiratory_rate\": 17, \"physical_status\": 1, \"pulse_rate\": 75, \"hemoglobin\": 145, \"inhospital_days\": 5.1, \"c_reactive_protein\": 20, \"sodium\": 140,\n\"cancer\": 0, \"eGFR\": 52, \"HD\": 0, \"potassium\": 4.1}\n,→\n,→\n19This is the context info of the clinical variables:\n20\n- sex maps to (0: male, 1: female)\n21\n- physical_status maps to (0: walking without aid, 1: walking with aid, 2: wheelchair, 3: bedridden) within the last 30 days\n22\n- HD to a prescription of loop diuretics within the last year\n23\n- Mapping of ICD-10 codes (feature: code): (Cancer: C)\n24\n- Mapping of ATC code levels (feature: code): (HD: C03C)\n25\n26## Mortality prediction classifier:\n27You are provided with a machine learning classifier that predicts one-year mortality in heart failure patients.\n28The classifier assigns each patient a likelihood of mortality. A threshold determines the final classification:\n29- If the probability >= threshold, the patient is classified as high risk (positive).\n30- If the probability < threshold, the patient is classified as low risk (negative).\n31This classifier is evaluated at multiple thresholds, yielding different values for true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN).\n32The optimal threshold is 0.24.\n33The classifier demonstrates the following performance across decision thresholds around 0.24: {0.19: {'TP': 1044, 'FP': 1594, 'TN': 3106, 'FN': 261}, 0.2: {'TP': 1022, 'FP':\n1515, 'TN': 3185, 'FN': 283}, 0.21: {'TP': 1000, 'FP': 1445, 'TN': 3255, 'FN': 305}, 0.22: {'TP': 983, 'FP': 1382, 'TN': 3318, 'FN': 322}, 0.23: {'TP': 963, 'FP': 1302,\n'TN': 3398, 'FN': 342}, 0.24: {'TP': 940, 'FP': 1215, 'TN': 3485, 'FN': 365}, 0.25: {'TP': 917, 'FP': 1158, 'TN': 3542, 'FN': 388}, 0.26: {'TP': 886, 'FP': 1097, 'TN':\n3603, 'FN': 419}, 0.27: {'TP': 866, 'FP': 1042, 'TN': 3658, 'FN': 439}, 0.28: {'TP': 841, 'FP': 978, 'TN': 3722, 'FN': 464}, 0.29: {'TP': 815, 'FP': 926, 'TN': 3774,\n'FN': 490}}\n,→\n,→\n,→\n,→\n34The predicted score is 0.1.\n35The classifier demonstrates the following performance across decision thresholds around 0.1: {0.05: {'TP': 1279, 'FP': 3518, 'TN': 1182, 'FN': 26}, 0.06: {'TP': 1268, 'FP':\n3304, 'TN': 1396, 'FN': 37}, 0.07: {'TP': 1255, 'FP': 3121, 'TN': 1579, 'FN': 50}, 0.08: {'TP': 1243, 'FP': 2952, 'TN': 1748, 'FN': 62}, 0.09: {'TP': 1230, 'FP': 2779,\n'TN': 1921, 'FN': 75}, 0.1: {'TP': 1213, 'FP': 2631, 'TN': 2069, 'FN': 92}, 0.11: {'TP': 1202, 'FP': 2472, 'TN': 2228, 'FN': 103}, 0.12: {'TP': 1185, 'FP': 2329, 'TN':\n2371, 'FN': 120}, 0.13: {'TP': 1153, 'FP': 2208, 'TN': 2492, 'FN': 152}, 0.14: {'TP': 1136, 'FP': 2090, 'TN': 2610, 'FN': 169}, 0.15: {'TP': 1112, 'FP': 1967, 'TN': 2733,\n'FN': 193}}\n,→\n,→\n,→\n,→\n36\n37 ## Task\n38Analyze the patient's profile.\n39Given the classifier's decision threshold of 0.24 and that the predicted score for the patient is 0.1,\n40evaluate the reliability of the predicted classification for this specific patient, referencing the classifier's performance across neighboring thresholds.\n41\n42The output should be specific to the patient, excluding generic summaries of the classifier.\n43Make a comprehensive and supportive analysis for the clinician considering all factors.\n44Be critical. Do not speculate about potential downstream treatments.\n45\n46The output should be formatted as a JSON instance that conforms to the JSON schema below.\n47\n48As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n49the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n50\n51Here is the output schema:\n52```\n53{\"$defs\": {\"MisclassificationConsequence\": {\"properties\": {\"type\": {\"description\": \"The potential misclassification type relevant to the patient.\", \"enum\": [\"False Positive\",\n\"False Negative\"], \"title\": \"Type\", \"type\": \"string\"}, \"likelihood\": {\"description\": \"Likelihood of this misclassification for this patient at or near the threshold.\",\n\"enum\": [\"High\", \"Moderate\", \"Low\"], \"title\": \"Likelihood\", \"type\": \"string\"}, \"rationale\": {\"description\": \"Numerical and clinical reasoning behind this likelihood\nestimate.\", \"title\": \"Rationale\", \"type\": \"string\"}, \"concerns\": {\"description\": \"The concerns of the potential prediction error. Return No concerns if none. Be\ncritical.\", \"title\": \"Concerns\", \"type\": \"string\"}, \"patient_profile_analysis\": {\"description\": \"The analysis of patient clinical profile in terms of mortality within 1\nyear.\", \"title\": \"Patient Profile Analysis\", \"type\": \"string\"}}, \"required\": [\"type\", \"likelihood\", \"rationale\", \"concerns\", \"patient_profile_analysis\"], \"title\":\n\"MisclassificationConsequence\", \"type\": \"object\"}}, \"description\": \"Patient-specific predictive risk profiling\", \"properties\": {\"predicted_score\": {\"description\":\n\"Predicted mortality probability for the patient.\", \"title\": \"Predicted Score\", \"type\": \"number\"}, \"applied_threshold\": {\"description\": \"Threshold used for classification\ndecision.\", \"title\": \"Applied Threshold\", \"type\": \"number\"}, \"predicted_label_by_classifier\": {\"description\": \"Classifier outcome for the patient.\", \"enum\": [\"High Risk\",\n\"Low Risk\"], \"title\": \"Predicted Label By Classifier\", \"type\": \"string\"}, \"predicted_label_after_analysis\": {\"description\": \"Predicted outcome for the patient after risk\nanalysis.\", \"enum\": [\"High Risk\", \"Low Risk\"], \"title\": \"Predicted Label After Analysis\", \"type\": \"string\"}, \"misclassification_analysis\": {\"anyOf\": [{\"$ref\":\n\"#/$defs/MisclassificationConsequence\"}, {\"type\": \"null\"}], \"default\": null, \"description\": \"Analysis of the most likely misclassification risk and its consequence for\nthis patient.\"}, \"overall_assessment\": {\"description\": \"Objective interpretation of the classifier's decision in the patient's context.\", \"title\": \"Overall Assessment\",\n\"type\": \"string\"}}, \"required\": [\"predicted_score\", \"applied_threshold\", \"predicted_label_by_classifier\", \"predicted_label_after_analysis\", \"overall_assessment\"]}\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n54```\n7\n"}, {"page": 21, "text": "Listing S2 How do I interpret the CIP cost curves? (Agent II) for synthetic patient 1\n1## System\n2You are a highly precise medical AI assistant with expertise in clinical decision support.\n3Your primary role is to assist clinicians in **objectively conducting cost-benefit analysis of AI-based risk models** for patient care.\n4\n5Your responses must be:\n6- Clear and structured.\n7- Supported by patient condition and numerical reasoning.\n8- Informative and specific about the patient.\n9\n10Avoid:\n11- Subjective or vague recommendations.\n12- Stating obvious facts.\n13\n14==========\n15\n16## Patient profile (the most important consideration factors):\n17The patient is diagnosed with heart failure (ICD-10 I50) in-hospital for the first time.\n18This is the patient info: {\"age_at_index\": 86, \"sex\": 0, \"BMI\": 26.5, \"CCI\": 2, \"saturation\": 85, \"albumin\": 37, \"body_temperature\": 37.2, \"blood_pressure_systolic\": 161,\n\"nt_probnp\": 2424, \"respiratory_rate\": 17, \"physical_status\": 1, \"pulse_rate\": 75, \"hemoglobin\": 145, \"inhospital_days\": 5.1, \"c_reactive_protein\": 20, \"sodium\": 140,\n\"cancer\": 0, \"eGFR\": 52, \"HD\": 0, \"potassium\": 4.1}\n,→\n,→\n19This is the context info of the clinical variables:\n20\n- sex maps to (0: male, 1: female)\n21\n- physical_status maps to (0: walking without aid, 1: walking with aid, 2: wheelchair, 3: bedridden) within the last 30 days\n22\n- HD to a prescription of loop diuretics within the last year\n23\n- Mapping of ICD-10 codes (feature: code): (Cancer: C)\n24\n- Mapping of ATC code levels (feature: code): (HD: C03C)\n25\n26## Patient risk analysis\n27{\"predicted_score\":0.1,\"applied_threshold\":0.24,\"predicted_label_by_classifier\":\"Low Risk\",\"predicted_label_after_analysis\":\"Low\nRisk\",\"misclassification_analysis\":{\"type\":\"False Negative\",\"likelihood\":\"Low\",\"rationale\":\"The patient’s predicted score (0.1) is substantially below the applied\nthreshold (0.24). At the nearest evaluated threshold (0.1), the classifier demonstrates a sensitivity (TPR) of 92.9% (1213/1305) and a false negative rate of 7.1%\n(92/1305). As the threshold increases toward 0.24, the number of false negatives rises (from 92 at 0.1 to 365 at 0.24), but the predicted score is distinctly below both\nthresholds, making misclassification as false negative (wrongly classified as low risk) unlikely for this patient.\",\"concerns\":\"No concerns. The large separation between\nthe patient’s score and the threshold, coupled with strong sensitivity at and below this threshold, suggests very low probability of significant underestimation of risk\nfor this patient.\",\"patient_profile_analysis\":\"This 86-year-old male with systolic hypertension, low oxygen saturation (85%), moderately impaired kidney function (eGFR\n52), and an elevated NT-proBNP (2424) presents with a frail clinical profile (dependent on walking aids, CCI 2), all of which are adverse prognosticators for 1-year\nmortality in heart failure. However, based purely on the model’s output, he is classified as low risk. This suggests that despite clinical frailty, the input features\nweighted by the model yield a low predicted risk, possibly due to preserved albumin and hemodynamic stability.\"},\"overall_assessment\":\"The classifier’s decision to label\nthis patient as low risk is reliable given the substantial margin between the patient’s predicted score (0.1) and the operational threshold (0.24). The classifier’s\nsensitivity at and below this point is high, minimizing the risk of false negatives. Re-analysis in the context of the patient’s adverse risk factors supports heightened\nclinical vigilance, but the model’s output at this margin does not indicate likely misclassification.\"}\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n28\n29## Clinical costs:\n30If the classifier assigns a positive label, the patient will be enrolled in a home care program.\n31If the classifier assigns a negative label, the patient will continue with regular hospital-based care.\n321. **Treatment cost (treatment)** is the cost due to the home care program (positive treatment) associated with each outcome.\n332. **Prediction error costs (error)** is the additional cost when the classifier makes an incorrect prediction (a misclassification).\n34\n35Home care programs generally improve quality of life due to increased comfort and convenience, while also reducing healthcare costs.\n36For this patient, clinical outcomes are expected to remain similar to those achieved through regular hospital visits.\n37However, if the patient is a false positive (FP), they may initially be assigned to home care but require urgent hospital readmission, leading to increased costs for both\nquality of life and healthcare.\n,→\n38Conversely, if the patient is a false negative (FN), they will continue with standard hospital care, which may reduce their quality of life due to unnecessary hospital visits\nand impose higher costs on the healthcare system.\n,→\n39\n40To reflect these considerations, clinicians defined the cost weights to be: {'QoL Treatment': {'TP': -1.0, 'FP': -1.0, 'TN': 0.0, 'FN': 0.0}, 'QoL Prediction Error': {'TP':\n0.0, 'FP': 0.5, 'TN': 0.0, 'FN': 1.0}, 'Healthcare Treatment': {'TP': -0.5, 'FP': -0.5, 'TN': 0.0, 'FN': 0.0}, 'Healthcare Prediction Error': {'TP': 0.0, 'FP': 0.25,\n'TN': 0.0, 'FN': 1.0}}\n,→\n,→\n41\n42The total cost around the predicted score 0.1: {0.05: {'Cost Total': -0.75}, 0.06: {'Cost Total': -0.72}, 0.07: {'Cost Total': -0.69}, 0.08: {'Cost Total': -0.66}, 0.09:\n{'Cost Total': -0.63}, 0.1: {'Cost Total': -0.6}, 0.11: {'Cost Total': -0.57}, 0.12: {'Cost Total': -0.55}, 0.13: {'Cost Total': -0.51}, 0.14: {'Cost Total': -0.49}, 0.15:\n{'Cost Total': -0.46}}\n,→\n,→\n43Cost composition is calculated as: abs(cost)/sum(abs(all costs at this threshold)); sign is either positive cost (negative impact) or negative cost (benefit).\n44QoL treatment cost around the predicted score 0.1: {0.05: {'composition': 0.49, 'sign': 'neg.'}, 0.06: {'composition': 0.49, 'sign': 'neg.'}, 0.07: {'composition': 0.49,\n'sign': 'neg.'}, 0.08: {'composition': 0.49, 'sign': 'neg.'}, 0.09: {'composition': 0.49, 'sign': 'neg.'}, 0.1: {'composition': 0.49, 'sign': 'neg.'}, 0.11:\n{'composition': 0.49, 'sign': 'neg.'}, 0.12: {'composition': 0.48, 'sign': 'neg.'}, 0.13: {'composition': 0.48, 'sign': 'neg.'}, 0.14: {'composition': 0.48, 'sign':\n'neg.'}, 0.15: {'composition': 0.48, 'sign': 'neg.'}}\n,→\n,→\n,→\n45Healthcare treatment cost around the predicted score 0.1: {0.05: {'composition': 0.24, 'sign': 'neg.'}, 0.06: {'composition': 0.24, 'sign': 'neg.'}, 0.07: {'composition':\n0.24, 'sign': 'neg.'}, 0.08: {'composition': 0.24, 'sign': 'neg.'}, 0.09: {'composition': 0.24, 'sign': 'neg.'}, 0.1: {'composition': 0.24, 'sign': 'neg.'}, 0.11:\n{'composition': 0.24, 'sign': 'neg.'}, 0.12: {'composition': 0.24, 'sign': 'neg.'}, 0.13: {'composition': 0.24, 'sign': 'neg.'}, 0.14: {'composition': 0.24, 'sign':\n'neg.'}, 0.15: {'composition': 0.24, 'sign': 'neg.'}}\n,→\n,→\n,→\n46QoL error cost around the predicted score 0.1: {0.05: {'composition': 0.18, 'sign': 'pos.'}, 0.06: {'composition': 0.18, 'sign': 'pos.'}, 0.07: {'composition': 0.18, 'sign':\n'pos.'}, 0.08: {'composition': 0.18, 'sign': 'pos.'}, 0.09: {'composition': 0.18, 'sign': 'pos.'}, 0.1: {'composition': 0.18, 'sign': 'pos.'}, 0.11: {'composition': 0.18,\n'sign': 'pos.'}, 0.12: {'composition': 0.18, 'sign': 'pos.'}, 0.13: {'composition': 0.18, 'sign': 'pos.'}, 0.14: {'composition': 0.18, 'sign': 'pos.'}, 0.15:\n{'composition': 0.18, 'sign': 'pos.'}}\n,→\n,→\n,→\n47Healthcare error cost around the predicted score 0.1: {0.05: {'composition': 0.09, 'sign': 'pos.'}, 0.06: {'composition': 0.09, 'sign': 'pos.'}, 0.07: {'composition': 0.09,\n'sign': 'pos.'}, 0.08: {'composition': 0.09, 'sign': 'pos.'}, 0.09: {'composition': 0.09, 'sign': 'pos.'}, 0.1: {'composition': 0.09, 'sign': 'pos.'}, 0.11:\n{'composition': 0.1, 'sign': 'pos.'}, 0.12: {'composition': 0.1, 'sign': 'pos.'}, 0.13: {'composition': 0.1, 'sign': 'pos.'}, 0.14: {'composition': 0.1, 'sign': 'pos.'},\n0.15: {'composition': 0.11, 'sign': 'pos.'}}\n,→\n,→\n,→\n48\n49## Task\n50Analyze the patient's profile. Given the patient profile, conduct cost-benefit analysis for this specific patient, referencing different types of costs across neighboring\nthresholds.\n,→\n51\n52The output should be specific to the patient, excluding generic summaries of the cost.\n53Make a comprehensive and supportive analysis for the clinician considering all factors.\n54Be critical.\n55\n56The output should be formatted as a JSON instance that conforms to the JSON schema below.\n57\n58As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n59the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n60\n61Here is the output schema:\n62```\n63{\"$defs\": {\"CostSummary\": {\"properties\": {\"threshold\": {\"description\": \"Threshold being evaluated.\", \"title\": \"Threshold\", \"type\": \"number\"}, \"total_cost\": {\"description\":\n\"Combined cost across all categories.\", \"title\": \"Total Cost\", \"type\": \"number\"}, \"qol_treatment_cost\": {\"description\": \"QoL treatment cost. Include a single float only,\nno calculation.\", \"title\": \"Qol Treatment Cost\", \"type\": \"number\"}, \"healthcare_treatment_cost\": {\"description\": \"Healthcare treatment cost. Include a single float only,\nno calculation.\", \"title\": \"Healthcare Treatment Cost\", \"type\": \"number\"}, \"qol_error_cost\": {\"description\": \"QoL error cost. Include a single float only, no\ncalculation.\", \"title\": \"Qol Error Cost\", \"type\": \"number\"}, \"healthcare_error_cost\": {\"description\": \"Healthcare error cost. Include a single float only, no\ncalculation.\", \"title\": \"Healthcare Error Cost\", \"type\": \"number\"}}, \"required\": [\"threshold\", \"total_cost\", \"qol_treatment_cost\", \"healthcare_treatment_cost\",\n\"qol_error_cost\", \"healthcare_error_cost\"], \"title\": \"CostSummary\", \"type\": \"object\"}}, \"description\": \"Cost landscape interpretation\", \"properties\": {\"predicted_score\":\n{\"description\": \"Predicted risk score for the patient.\", \"title\": \"Predicted Score\", \"type\": \"number\"}, \"decision_label\": {\"description\": \"Classifier's decision label at\nthis score.\", \"enum\": [\"High Risk\", \"Low Risk\"], \"title\": \"Decision Label\", \"type\": \"string\"}, \"main_risk_factors\": {\"description\": \"Key clinical variables influencing\ncost.\", \"title\": \"Main Risk Factors\", \"type\": \"string\"}, \"cost_composition_at_predicted_score\": {\"$ref\": \"#/$defs/CostSummary\", \"description\": \"Cost breakdown at current\nscore threshold.\"}, \"lowest_cost_threshold\": {\"description\": \"Threshold with lowest total cost nearby.\", \"title\": \"Lowest Cost Threshold\", \"type\": \"number\"}, \"summary\":\n{\"description\": \"Concise plain-language interpretation of the cost-benefit tradeoff for this patient, closing with an actionable recommendation if applicable.Any cost\ncomposition should be reported in percentange.\", \"title\": \"Summary\", \"type\": \"string\"}}, \"required\": [\"predicted_score\", \"decision_label\", \"main_risk_factors\",\n\"cost_composition_at_predicted_score\", \"lowest_cost_threshold\", \"summary\"]}\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n64```\n8\n"}, {"page": 22, "text": "Listing S3 How can prediction uncertainty be reduced? (Agent III) for synthetic patient 1\n1## System\n2You are a highly precise medical AI assistant with expertise in clinical decision support.\n3Your primary role is to assist clinicians in **objectively conducting cost-benefit analysis of AI-based risk models** for patient care.\n4\n5Your responses must be:\n6- Clear and structured.\n7- Supported by patient condition and numerical reasoning.\n8- Informative and specific about the patient.\n9\n10Avoid:\n11- Subjective or vague recommendations.\n12- Stating obvious facts.\n13\n14==========\n15\n16## Patient profile (the most important consideration factors):\n17The patient is diagnosed with heart failure (ICD-10 I50) in-hospital for the first time.\n18This is the patient info: {\"age_at_index\": 86, \"sex\": 0, \"BMI\": 26.5, \"CCI\": 2, \"saturation\": 85, \"albumin\": 37, \"body_temperature\": 37.2, \"blood_pressure_systolic\": 161,\n\"nt_probnp\": 2424, \"respiratory_rate\": 17, \"physical_status\": 1, \"pulse_rate\": 75, \"hemoglobin\": 145, \"inhospital_days\": 5.1, \"c_reactive_protein\": 20, \"sodium\": 140,\n\"cancer\": 0, \"eGFR\": 52, \"HD\": 0, \"potassium\": 4.1}\n,→\n,→\n19This is the context info of the clinical variables:\n20\n- sex maps to (0: male, 1: female)\n21\n- physical_status maps to (0: walking without aid, 1: walking with aid, 2: wheelchair, 3: bedridden) within the last 30 days\n22\n- HD to a prescription of loop diuretics within the last year\n23\n- Mapping of ICD-10 codes (feature: code): (Cancer: C)\n24\n- Mapping of ATC code levels (feature: code): (HD: C03C)\n25\n26## Patient risk analysis\n27{\"predicted_score\":0.1,\"applied_threshold\":0.24,\"predicted_label_by_classifier\":\"Low Risk\",\"predicted_label_after_analysis\":\"Low\nRisk\",\"misclassification_analysis\":{\"type\":\"False Negative\",\"likelihood\":\"Low\",\"rationale\":\"The patient’s predicted score (0.1) is substantially below the applied\nthreshold (0.24). At the nearest evaluated threshold (0.1), the classifier demonstrates a sensitivity (TPR) of 92.9% (1213/1305) and a false negative rate of 7.1%\n(92/1305). As the threshold increases toward 0.24, the number of false negatives rises (from 92 at 0.1 to 365 at 0.24), but the predicted score is distinctly below both\nthresholds, making misclassification as false negative (wrongly classified as low risk) unlikely for this patient.\",\"concerns\":\"No concerns. The large separation between\nthe patient’s score and the threshold, coupled with strong sensitivity at and below this threshold, suggests very low probability of significant underestimation of risk\nfor this patient.\",\"patient_profile_analysis\":\"This 86-year-old male with systolic hypertension, low oxygen saturation (85%), moderately impaired kidney function (eGFR\n52), and an elevated NT-proBNP (2424) presents with a frail clinical profile (dependent on walking aids, CCI 2), all of which are adverse prognosticators for 1-year\nmortality in heart failure. However, based purely on the model’s output, he is classified as low risk. This suggests that despite clinical frailty, the input features\nweighted by the model yield a low predicted risk, possibly due to preserved albumin and hemodynamic stability.\"},\"overall_assessment\":\"The classifier’s decision to label\nthis patient as low risk is reliable given the substantial margin between the patient’s predicted score (0.1) and the operational threshold (0.24). The classifier’s\nsensitivity at and below this point is high, minimizing the risk of false negatives. Re-analysis in the context of the patient’s adverse risk factors supports heightened\nclinical vigilance, but the model’s output at this margin does not indicate likely misclassification.\"}\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n28\n29## Task\n30Analyze the patient's profile and the risk analysis of the classifier.\n31Suggest action points for the clinicians in order to make more confident predictions of this patient.\n32\n33The output should be specific to the patient, excluding generic summaries of the classifier.\n34Be critical.\n35\n36The output should be formatted as a JSON instance that conforms to the JSON schema below.\n37\n38As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n39the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n40\n41Here is the output schema:\n42```\n43{\"$defs\": {\"ActionPointC\": {\"properties\": {\"action\": {\"description\": \"Concise title describing the recommended clinical action.\", \"title\": \"Action\", \"type\": \"string\"},\n\"rationale\": {\"description\": \"Justification for the recommendation, grounded in the patient's data and clinical reasoning.\", \"title\": \"Rationale\", \"type\": \"string\"},\n\"suggested_tests_or_data\": {\"anyOf\": [{\"items\": {\"type\": \"string\"}, \"type\": \"array\"}, {\"type\": \"null\"}], \"description\": \"Specific measurements, labs, or assessments that\nwould increase confidence in the risk estimate.\", \"title\": \"Suggested Tests Or Data\"}, \"expected_clinical_value\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}],\n\"default\": null, \"description\": \"Explanation of how the new data would contribute to the clinical interpretation or next steps.\", \"title\": \"Expected Clinical Value\"}},\n\"required\": [\"action\", \"rationale\"], \"title\": \"ActionPointC\", \"type\": \"object\"}}, \"description\": \"Uncertainty reduction strategy\", \"properties\": {\"patient_id\": {\"anyOf\":\n[{\"type\": \"string\"}, {\"type\": \"null\"}], \"default\": null, \"description\": \"Unique patient identifier; optional if anonymized.\", \"title\": \"Patient Id\"}, \"predicted_score\":\n{\"description\": \"Probability score output from the AI-based risk model for the patient.\", \"title\": \"Predicted Score\", \"type\": \"number\"}, \"threshold\": {\"description\":\n\"Risk threshold applied to convert the predicted score into a binary risk classification.\", \"title\": \"Threshold\", \"type\": \"number\"}, \"predicted_label\": {\"description\":\n\"Final binary risk label for the patient after classifier analysis (e.g., 'High Risk').\", \"title\": \"Predicted Label\", \"type\": \"string\"}, \"misclassification_risk\":\n{\"description\": \"Characterization of the risk that the model output is a false positive or false negative.\", \"title\": \"Misclassification Risk\", \"type\": \"string\"},\n\"action_points\": {\"description\": \"A list of patient-specific, clinically actionable steps to improve risk stratification confidence in decreasing order of priority.\",\n\"items\": {\"$ref\": \"#/$defs/ActionPointC\"}, \"title\": \"Action Points\", \"type\": \"array\"}, \"final_recommendations\": {\"description\": \"A concise, action-oriented summary of the\nrecommended steps to mitigate risk. Avoid over-generalization as the summarized actions should be pratical to follow. Use a considerate, not a commanding tone.\", \"title\":\n\"Final Recommendations\", \"type\": \"string\"}}, \"required\": [\"predicted_score\", \"threshold\", \"predicted_label\", \"misclassification_risk\", \"action_points\",\n\"final_recommendations\"]}\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n44```\n9\n"}, {"page": 23, "text": "Listing S4 How can future risks be mitigated? (Agent IV) for synthetic patient 1\n1## System\n2You are a highly precise medical AI assistant with expertise in clinical decision support.\n3Your primary role is to assist clinicians in **objectively conducting cost-benefit analysis of AI-based risk models** for patient care.\n4\n5Your responses must be:\n6- Clear and structured.\n7- Supported by patient condition and numerical reasoning.\n8- Informative and specific about the patient.\n9\n10Avoid:\n11- Subjective or vague recommendations.\n12- Stating obvious facts.\n13\n14==========\n15\n16## Patient profile (the most important consideration factors):\n17The patient is diagnosed with heart failure (ICD-10 I50) in-hospital for the first time.\n18This is the patient info: {\"age_at_index\": 86, \"sex\": 0, \"BMI\": 26.5, \"CCI\": 2, \"saturation\": 85, \"albumin\": 37, \"body_temperature\": 37.2, \"blood_pressure_systolic\": 161,\n\"nt_probnp\": 2424, \"respiratory_rate\": 17, \"physical_status\": 1, \"pulse_rate\": 75, \"hemoglobin\": 145, \"inhospital_days\": 5.1, \"c_reactive_protein\": 20, \"sodium\": 140,\n\"cancer\": 0, \"eGFR\": 52, \"HD\": 0, \"potassium\": 4.1}\n,→\n,→\n19This is the context info of the clinical variables:\n20\n- sex maps to (0: male, 1: female)\n21\n- physical_status maps to (0: walking without aid, 1: walking with aid, 2: wheelchair, 3: bedridden) within the last 30 days\n22\n- HD to a prescription of loop diuretics within the last year\n23\n- Mapping of ICD-10 codes (feature: code): (Cancer: C)\n24\n- Mapping of ATC code levels (feature: code): (HD: C03C)\n25\n26## Patient cost-benefit analysis\n27{\"predicted_score\":0.1,\"decision_label\":\"Low Risk\",\"main_risk_factors\":\"Advanced age (86), male sex, first heart failure admission, marked hypoxemia (saturation 85%),\nmoderate renal impairment (eGFR 52), elevated NT-proBNP (2424), markedly elevated systolic blood pressure (161), CCI 2, requirement for walking aids. These factors raise\nbaseline risk, but preserved albumin, stable vital signs, and no malignancy or dialysis moderate this\nassessment.\",\"cost_composition_at_predicted_score\":{\"threshold\":0.1,\"total_cost\":-0.6,\"qol_treatment_cost\":-0.294,\"healthcare_treatment_cost\":-0.144,\"qol_error_cost\":0.108,\n\"healthcare_error_cost\":0.054},\"lowest_cost_threshold\":0.05,\"summary\":\"At the patient’s predicted score of 0.1, total cost is -0.6, indicating moderate net benefit. The\nlargest contribution (49%) is quality-of-life (QoL) benefit from avoided unnecessary treatment, followed by a 24% healthcare cost saving. Positive costs from potential\nquality-of-life (18%) and healthcare (9%) prediction errors persist, reflecting some risk of reduced patient QoL and increased system cost if risk is underestimated. The\nlowest total cost (-0.75) is just above the prediction (threshold 0.05), driven similarly by treatment-related benefits. Given the substantial margin between score and\nthe decision threshold, the classifier is unlikely to misclassify this patient as low risk despite significant clinical frailty. Actionable recommendation: The model\noutput for this patient offers a cost-favorable, low-risk decision, but clinical vigilance is advised due to the patient’s frailty. If risk margin narrows or health\nstatus changes, consider sensitivity analysis at marginally lower thresholds.\"}\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n28\n29## Task\n30Analyze the patientâ€™s clinical profile in conjunction with the model-based cost-benefit assessment of treatment deployment.\n31Based on this analysis, and assuming treatment is initiated, identify targeted action points to mitigate patient-specific risks.\n32The goal is not to reduce mortality risks, but to warn the clinicians about treatment-specific risks.\n33\n34Recommendations must be tailored to this individual patient's clinical context. Avoid any generic or model-wide summaries.\n35\n36The output should be formatted as a JSON instance that conforms to the JSON schema below.\n37\n38As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n39the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n40\n41Here is the output schema:\n42```\n43{\"$defs\": {\"ActionPointD\": {\"properties\": {\"action\": {\"description\": \"Concise description of the proposed action.\", \"title\": \"Action\", \"type\": \"string\"}, \"rationale\":\n{\"description\": \"Justification based on treatment-specific clinical profile and treatment context.\", \"title\": \"Rationale\", \"type\": \"string\"}, \"monitoring_or_tests\":\n{\"anyOf\": [{\"items\": {\"type\": \"string\"}, \"type\": \"array\"}, {\"type\": \"null\"}], \"description\": \"Tests or assessments required for this action.\", \"title\": \"Monitoring Or\nTests\"}, \"mitigation_goal\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"default\": null, \"description\": \"What this action aims to reduce or prevent.\", \"title\":\n\"Mitigation Goal\"}}, \"required\": [\"action\", \"rationale\"], \"title\": \"ActionPointD\", \"type\": \"object\"}, \"CostComponent\": {\"properties\": {\"name\": {\"description\": \"Component\nof the cost model, e.g., 'quality of life', 'healthcare cost'.\", \"title\": \"Name\", \"type\": \"string\"}, \"value\": {\"description\": \"Relative contribution to total cost (range:\n0.0 to 1.0).\", \"title\": \"Value\", \"type\": \"number\"}, \"explanation\": {\"description\": \"Explanation of how this cost component is impacted for this patient.\", \"title\":\n\"Explanation\", \"type\": \"string\"}}, \"required\": [\"name\", \"value\", \"explanation\"], \"title\": \"CostComponent\", \"type\": \"object\"}, \"RiskFactor\": {\"properties\": {\"name\":\n{\"description\": \"Specific clinical variable contributing to risk.\", \"title\": \"Name\", \"type\": \"string\"}, \"value\": {\"description\": \"Observed value or category for the\npatient.\", \"title\": \"Value\", \"type\": \"string\"}, \"interpretation\": {\"description\": \"Patient-specific implication of the value.\", \"title\": \"Interpretation\", \"type\":\n\"string\"}}, \"required\": [\"name\", \"value\", \"interpretation\"], \"title\": \"RiskFactor\", \"type\": \"object\"}}, \"description\": \"Cost-aware decision guidance\", \"properties\":\n{\"patient_id\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"default\": null, \"description\": \"Optional identifier if used in patient record systems.\", \"title\":\n\"Patient Id\"}, \"predicted_score\": {\"description\": \"Predicted mortality or risk score from the AI model.\", \"title\": \"Predicted Score\", \"type\": \"number\"}, \"decision_label\":\n{\"description\": \"AI model's final decision label for the patient (e.g., 'High Risk').\", \"title\": \"Decision Label\", \"type\": \"string\"}, \"main_risk_factors\": {\"description\":\n\"Key clinical features contributing to risk classification.\", \"items\": {\"$ref\": \"#/$defs/RiskFactor\"}, \"title\": \"Main Risk Factors\", \"type\": \"array\"}, \"cost_summary\":\n{\"description\": \"Breakdown of cost components at the predicted score.\", \"items\": {\"$ref\": \"#/$defs/CostComponent\"}, \"title\": \"Cost Summary\", \"type\": \"array\"},\n\"treatment_plan\": {\"description\": \"Treatment or care program being deployed based on decision (e.g., home care).\", \"title\": \"Treatment Plan\", \"type\": \"string\"},\n\"recommended_actions_post_treatment\": {\"description\": \"Targeted clinical actions to mitigate future risk ensuring beneficial post-treatment.\", \"items\": {\"$ref\":\n\"#/$defs/ActionPointD\"}, \"title\": \"Recommended Actions Post Treatment\", \"type\": \"array\"}, \"final_recommendations\": {\"description\": \"A concise, action-oriented summary of\nthe recommended steps to mitigate future risk with beneficial post-treatment .Use a considerate, not a commanding tone.\", \"title\": \"Final Recommendations\", \"type\":\n\"string\"}}, \"required\": [\"predicted_score\", \"decision_label\", \"main_risk_factors\", \"cost_summary\", \"treatment_plan\", \"recommended_actions_post_treatment\",\n\"final_recommendations\"]}\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n44```\n10\n"}, {"page": 24, "text": "Listing S5 Summary of the cost-benefit analysis for synthetic patient 1\n1## System\n2You are a highly precise medical AI assistant with expertise in clinical decision support.\n3Your primary role is to assist clinicians in **objectively conducting cost-benefit analysis of AI-based risk models** for patient care.\n4Your responses must be:\n5- Clear and structured.\n6- Supported by patient condition and numerical reasoning.\n7- Informative and specific about the patient.\n8Avoid:\n9- Subjective or vague recommendations.\n10- Stating obvious facts.\n11\n12==========\n13\n14## Task:\n15Summarize the following outcomes for patient to a clinician.\n16Focus on a cost benefit analysis.\n17Do not add or alter existing information or results. Be concise.\n18\n19## Outcome risk analysis:\n20{\"predicted_score\":0.1,\"applied_threshold\":0.24,\"predicted_label_by_classifier\":\"Low Risk\",\"predicted_label_after_analysis\":\"Low\nRisk\",\"misclassification_analysis\":{\"type\":\"False Negative\",\"likelihood\":\"Low\",\"rationale\":\"The patient’s predicted score (0.1) is substantially below the applied\nthreshold (0.24). At the nearest evaluated threshold (0.1), the classifier demonstrates a sensitivity (TPR) of 92.9% (1213/1305) and a false negative rate of 7.1%\n(92/1305). As the threshold increases toward 0.24, the number of false negatives rises (from 92 at 0.1 to 365 at 0.24), but the predicted score is distinctly below both\nthresholds, making misclassification as false negative (wrongly classified as low risk) unlikely for this patient.\",\"concerns\":\"No concerns. The large separation between\nthe patient’s score and the threshold, coupled with strong sensitivity at and below this threshold, suggests very low probability of significant underestimation of risk\nfor this patient.\",\"patient_profile_analysis\":\"This 86-year-old male with systolic hypertension, low oxygen saturation (85%), moderately impaired kidney function (eGFR\n52), and an elevated NT-proBNP (2424) presents with a frail clinical profile (dependent on walking aids, CCI 2), all of which are adverse prognosticators for 1-year\nmortality in heart failure. However, based purely on the model’s output, he is classified as low risk. This suggests that despite clinical frailty, the input features\nweighted by the model yield a low predicted risk, possibly due to preserved albumin and hemodynamic stability.\"},\"overall_assessment\":\"The classifier’s decision to label\nthis patient as low risk is reliable given the substantial margin between the patient’s predicted score (0.1) and the operational threshold (0.24). The classifier’s\nsensitivity at and below this point is high, minimizing the risk of false negatives. Re-analysis in the context of the patient’s adverse risk factors supports heightened\nclinical vigilance, but the model’s output at this margin does not indicate likely misclassification.\"}\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n21\n22## Outcome cost interpretation:\n23{\"predicted_score\":0.1,\"decision_label\":\"Low Risk\",\"main_risk_factors\":\"Advanced age (86), male sex, first heart failure admission, marked hypoxemia (saturation 85%),\nmoderate renal impairment (eGFR 52), elevated NT-proBNP (2424), markedly elevated systolic blood pressure (161), CCI 2, requirement for walking aids. These factors raise\nbaseline risk, but preserved albumin, stable vital signs, and no malignancy or dialysis moderate this\nassessment.\",\"cost_composition_at_predicted_score\":{\"threshold\":0.1,\"total_cost\":-0.6,\"qol_treatment_cost\":-0.294,\"healthcare_treatment_cost\":-0.144,\"qol_error_cost\":0.108,\n\"healthcare_error_cost\":0.054},\"lowest_cost_threshold\":0.05,\"summary\":\"At the patient’s predicted score of 0.1, total cost is -0.6, indicating moderate net benefit. The\nlargest contribution (49%) is quality-of-life (QoL) benefit from avoided unnecessary treatment, followed by a 24% healthcare cost saving. Positive costs from potential\nquality-of-life (18%) and healthcare (9%) prediction errors persist, reflecting some risk of reduced patient QoL and increased system cost if risk is underestimated. The\nlowest total cost (-0.75) is just above the prediction (threshold 0.05), driven similarly by treatment-related benefits. Given the substantial margin between score and\nthe decision threshold, the classifier is unlikely to misclassify this patient as low risk despite significant clinical frailty. Actionable recommendation: The model\noutput for this patient offers a cost-favorable, low-risk decision, but clinical vigilance is advised due to the patient’s frailty. If risk margin narrows or health\nstatus changes, consider sensitivity analysis at marginally lower thresholds.\"}\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n24\n25## Outcome risk mitigation:\n26{\"patient_id\":null,\"predicted_score\":0.1,\"threshold\":0.24,\"predicted_label\":\"Low Risk\",\"misclassification_risk\":\"Low likelihood of false negative; model sensitivity at or\nbelow threshold is high, but clinical profile carries adverse prognosticators (age, chronic kidney disease, frailty, hypoxemia), creating a potential disconnect between\nmodel estimation and bedside judgment.\",\"action_points\":[{\"action\":\"Reassess and trend oxygenation status\",\"rationale\":\"Patient's oxygen saturation is critically low at\n85%, which is an independent predictor of mortality in heart failure and may not be fully weighted in the current model. Confirming the accuracy and trend of oxygenation\n(including consideration for arterial blood gases) would help to clarify acute severity and residual risk.\",\"suggested_tests_or_data\":[\"Repeat pulse oximetry at\nintervals\",\"Arterial blood gas (ABG) analysis\",\"Assessment for supplemental oxygen requirement\"],\"expected_clinical_value\":\"Better characterization of hypoxemic burden\nand response to therapies could identify evolving decompensation risk not fully captured by the AI model.\"},{\"action\":\"Review for acute or subacute decompensation not\ncaptured in model inputs\",\"rationale\":\"Low albumin, high NT-proBNP, and moderate eGFR reduction suggest systemic stress and possible subacute organ\ndecompensation—features that may prompt under-recognition of short-term risk by the model.\",\"suggested_tests_or_data\":[\"Repeat NT-proBNP after diuresis\",\"Daily weight\ntrend\",\"Input/output balance analysis\",\"Assess for new symptoms (e.g., confusion, increasing fatigue, reduced urine output)\"],\"expected_clinical_value\":\"Detection of\nworsening congestion or evolving multi-organ dysfunction, which may necessitate reclassification of risk and timely intervention.\"},{\"action\":\"Obtain frailty and\nfunctional status reassessment\",\"rationale\":\"Current classification reflects 'walking with aids', but frailty scores (e.g., Clinical Frailty Scale, handgrip strength)\nprovide nuanced prognostic information in elderly heart failure patients and may be missed by structured data-fed models.\",\"suggested_tests_or_data\":[\"Clinical Frailty\nScale evaluation\",\"Timed Up-and-Go test\"],\"expected_clinical_value\":\"Improved individual mortality risk stratification and more accurate tailoring of follow-up\nintensity.\"},{\"action\":\"Request external validation of PI (prediction index) or cross-model consensus in this subgroup\",\"rationale\":\"Given advanced age and frail clinical\ncharacteristics, models trained on broader populations may exhibit calibration drift. Benchmarking this patient’s risk by applying a second validated model (e.g., MAGGIC,\nSeattle HF Model) could confirm or refine the risk estimate.\",\"suggested_tests_or_data\":[\"Calculate MAGGIC score\",\"Re-run risk with a heart failure-specific external\ntool\"],\"expected_clinical_value\":\"Mitigates single-model bias and boosts confidence in the classification, especially in a high-variability clinical\nsubgroup.\"}],\"final_recommendations\":\"Although AI model output suggests low risk, key adverse clinical features warrant caution. Trend the patient’s oxygenation and early\ndecompensation markers, reassess frailty using standardized tools, and consider second-model risk estimation. These targeted steps will strengthen individualized\nprognostication beyond the current classifier.\"}\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n27\n28## Outcome cost benefit recommendation:\n29{\"patient_id\":null,\"predicted_score\":0.1,\"decision_label\":\"Low Risk\",\"main_risk_factors\":[{\"name\":\"Age\",\"value\":\"86\",\"interpretation\":\"Advanced age increases frailty and\nsusceptibility to treatment side effects.\"},{\"name\":\"Oxygen Saturation\",\"value\":\"85%\",\"interpretation\":\"Marked hypoxemia may complicate diuretic therapy or exacerbate\nunderlying respiratory limitations.\"},{\"name\":\"Systolic Blood Pressure\",\"value\":\"161 mmHg\",\"interpretation\":\"Elevated blood pressure could increase risk of hypotension\nwith heart failure therapies.\"},{\"name\":\"NT-proBNP\",\"value\":\"2424\",\"interpretation\":\"Significant cardiac strain/volume overload, necessitating cautious fluid\nmanagement.\"},{\"name\":\"eGFR\",\"value\":\"52\",\"interpretation\":\"Stage 3 chronic kidney disease; increased risk for electrolyte disturbances and drug accumulation with heart\nfailure treatment.\"},{\"name\":\"Physical Status\",\"value\":\"Walking with aids\",\"interpretation\":\"Functional limitation, increasing fall risk especially if overt diuresis or\nhypotension occurs.\"}],\"cost_summary\":[{\"name\":\"QoL Treatment Benefit\",\"value\":0.49,\"explanation\":\"Major gain from avoiding unnecessary or overly aggressive interventions\nin a frail, elderly patient.\"},{\"name\":\"Healthcare Treatment Cost\",\"value\":0.24,\"explanation\":\"Reduced direct cost due to optimized, likely less intensive therapy in a\npatient categorized as low risk.\"},{\"name\":\"QoL Prediction Error Cost\",\"value\":0.18,\"explanation\":\"Residual risk to quality of life if risk is underestimated and expected\nrecovery is not achieved or subclinical decompensation occurs.\"},{\"name\":\"Healthcare Prediction Error Cost\",\"value\":0.09,\"explanation\":\"Potential for unexpected\nhealthcare utilization if disease trajectory does not follow predicted low-risk path.\"}],\"treatment_plan\":\"Initiation of standard evidence-based heart failure therapy\n(likely including diuretics, afterload reduction, and monitoring in step-down or outpatient setting).\",\"recommended_actions_post_treatment\":[{\"action\":\"Monitor for\nhypovolemia and electrolyte disturbances within 48 hours post-treatment initiation.\",\"rationale\":\"Elderly patient with moderate renal impairment is at increased risk of\nover-diuresis, hyponatremia, and hypokalemia after initiation of diuretics.\",\"monitoring_or_tests\":[\"Daily weights\",\"Serum sodium, potassium, creatinine\",\"Assessment for\northostatic symptoms\"],\"mitigation_goal\":\"Minimize risk of acute kidney injury, metabolic disturbances, and iatrogenic falls.\"},{\"action\":\"Assess for symptomatic\nhypotension at least daily during medication titration.\",\"rationale\":\"Markedly elevated systolic blood pressure at baseline alongside frailty may lead to overshooting\ntarget blood pressures with antihypertensives or up-titration of heart failure medications.\",\"monitoring_or_tests\":[\"Vital signs (standing and supine blood\npressure)\",\"Review of medication adjustments\"],\"mitigation_goal\":\"Prevent syncope, falls, and related injuries due to sudden blood pressure drops.\"},{\"action\":\"Implement\nfall risk mitigation strategies tailored to mobility status.\",\"rationale\":\"Patient requires walking aids and may experience transient instability after treatment\nchanges.\",\"monitoring_or_tests\":[\"Environmental safety check\",\"Fall risk assessment by nursing staff\"],\"mitigation_goal\":\"Reduce risk of physical injury due to postural\ninstability and weakness.\"},{\"action\":\"Schedule close outpatient follow-up within 7 days post-discharge.\",\"rationale\":\"Early reassessment is required given first-ever\nheart failure admission, frailty, and dynamic clinical variables.\",\"monitoring_or_tests\":[\"Clinic visit for symptoms review and lab\nreassessment\"],\"mitigation_goal\":\"Ensure early detection of adverse events or clinical deterioration.\"},{\"action\":\"Optimize oxygen support as\ntolerated.\",\"rationale\":\"Baseline hypoxemia (saturation 85%) may worsen with fluid shifts or treatment-induced changes.\",\"monitoring_or_tests\":[\"Frequent oxygen\nsaturation checks\"],\"mitigation_goal\":\"Maintain adequate tissue oxygenation and avoid respiratory distress.\"}],\"final_recommendations\":\"Given this patient’s advanced age,\nmoderate renal impairment, mobility limitation, and low oxygen saturation, it would be prudent to intensively monitor fluid and electrolyte status, blood pressure, and\nfall risk immediately after starting treatment. Ensuring early outpatient follow-up and carefully titrating therapies can help avert preventable complications.\"}\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n,→\n30\n31The output should be formatted as a JSON instance that conforms to the JSON schema below.\n32\n33As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n34the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n35Here is the output schema:\n36```\n37{\"properties\": {\"summary\": {\"description\": \"A concise, action-oriented summarization of the outcomes from different clinical analyses.\", \"title\": \"Summary\", \"type\":\n\"string\"}, \"decision\": {\"description\": \"A final decision if the patient is recommended for a home care programme or continues with stand care.\", \"title\": \"Decision\",\n\"type\": \"string\"}}, \"required\": [\"summary\", \"decision\"]}\n,→\n,→\n38```\n11\n"}, {"page": 25, "text": "Figure S4: CAPboard of synthetic patient 1\n(A) Patient-specific information\nVariable\nValue\nVariable\nValue\nAge\n86\nSodium\n140\nSex\n0\nPotassium\n4.1\nBMI\n26.5\nHemoglobin\n145\nCCI\n2\nAlbumin\n37\nCancer\n0\nC-reactive protein\n20\nOxygen saturation\n85\nNT-proBNP\n2424\nBody temperature\n37.2\nEstimated GFR\n52\nSBP\n161\nLoop diuretics\n0\nPulse rate\n75\nPhysical status\n1\nRespiratory rate\n17\nIn-hospital days\n5.1\n(B) ML performance (population-level)\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nThreshold\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\nF1 score\nDecision threshold (0.24)\nPredicted risk (0.10)\nPatient band\n(C) CIP cost curves (population-level)\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nThreshold\n3.0\n2.5\n2.0\n1.5\n1.0\n0.5\n0.0\n0.5\nCost\nDecision\nthreshold (0.24):\nQoL error: 20%\nHC error: 14%\nQoL treatment: 44%\nHC treatment: 22%\nPredicted risk (0.10):\nQoL error: 18%\nHC error: 9%\nQoL treatment: 49%\nHC treatment: 24%\nTotal cost curve\nZero cost curve\nQoL error\nHC error\nQoL treatment\nHC treatment\n(D) Summary of the cost-benefit analysis\nThe AI model assigns this 86-year-old heart failure patient a low one-year mortality\nrisk (score 0.1, well below the 0.24 threshold), with a robustly low false negative\nrate at this score and reassuring clinical profile despite moderate renal impairment,\nelevated NT-proBNP, and reduced mobility.\nCost-benefit analysis indicates a\nclear net benefit at the current threshold (total cost = -0.6), driven by reduced\nquality-of-life and healthcare expenditures from avoiding unnecessary home care,\nwith only minor residual error costs due to ongoing hospital-based management.\nRisk mitigation should focus on active surveillance for occult respiratory or\ndecompensation risks, given unexplained low oxygen saturation, and on targeted\nfrailty and functional assessments due to advanced age and mobility limitations.\nTreatment planning must prioritize renal-adjusted diuretic use, fall prevention, close\nmonitoring for fluid and medication-related adverse events, and comprehensive\ndischarge arrangements to minimize readmission risk and optimize recovery.\nEnhanced short-term hospital monitoring and reassessment will further reduce the\nrisk of missed complications while maintaining the net cost benefit of in-hospital\ncare for this low-risk profile.\nDecision: Continue standard hospital-based care; home care programme is not\nrecommended based on current risk and cost-benefit assessment.\n(E) How certain is the risk prediction? (Agent I)\nFor this patient, whose score is considerably below the threshold, the classifier is highly reliable in its assignment\nof low one-year mortality risk. Based on both performance metrics (low false negative rate at and below this score)\nand clinical profile considerations, the decision is well supported and the likelihood of underestimating risk in this\nspecific case is low.\n(F) How do I interpret the CIP cost curves? (Agent II)\nAt the predicted score of 0.1, the classifier assigns a ’Low Risk’ label, aligned with the relatively reassuring clinical\nprofile despite advanced age and chronic heart failure. Cost analysis at this threshold shows a total cost of -0.6,\nindicating a net benefit but not the maximal achievable benefit in the local range. The cost composition at this\nthreshold is: 49% QoL treatment benefit (negative), 24% healthcare treatment benefit (negative), 18% QoL error\ncost (positive), and 9% healthcare error cost (positive). The costs are dominated by the treatment-related QoL and\nhealthcare cost savings from avoiding unnecessary home care assignment in a low-risk patient, though some error\npenalty remains due to ongoing standard hospital care and missed opportunity for home-based comfort. The lowest\ntotal cost in the neighborhood is at threshold 0.05 (total = -0.75), but the difference with 0.1 is modest, suggesting\nlimited additional opportunity for cost optimization in this patient. Given the classifier’s very low false negative\nrisk in this score range, adherence to the current ’Low Risk’ assignment is objectively supported. Recommendation:\nContinue standard hospital-based follow-up for this patient, as further lowering the risk threshold yields minimal\nadditional cost benefit and the current decision accurately captures both clinical status and economic considerations.\n(G) How can prediction uncertainty be reduced? (Agent III)\nGiven the low model-predicted risk but concerning hypoxemia and advanced age, a short-term period of enhanced\nmonitoring and targeted reassessment (including repeat oxygen measurements, frailty/screening, and trending\nbiomarkers) is advised. These steps will provide a more comprehensive risk picture and allow timely intervention\nif currently occult hazards emerge. If all are reassuring, confidence in the algorithm’s low-risk assignment is\nstrengthened.\n(H) How can future risks be mitigated? (Agent IV)\nGiven this patient’s advanced age, moderate renal impairment, and modest functional limitations, the main priorities\nare careful diuretic titration, proactive monitoring for mobility decline, and vigilant assessment of fluid and medication-\nrelated risks throughout the hospital stay. Ensuring coordinated discharge planning and timely follow-up will help\nmitigate future complications specific to the patient’s frailty and comorbidity profile.\nLLM-agent evaluation details\nUser review (two clinicians) Two experienced clinicians, practising specialists in emergency medicine and\ncardiology and not involved in the development of the tool, were recruited to evaluate user performance. Each\nclinician interacted with the tool across ten synthetic patient cases. The tool implemented the LLM-agents using\nthe OpenAI GPT-4.1 model (version gpt-4.1-2025-04-14). After completing each case, the clinicians responded\nto a standardized set of evaluation questions focused on risk estimation, decision support, explanation quality,\nand clinical integration aspects. These questions are summarized in Table S6.\nDevelopment review (one clinician)\nA clinician from the development team conducted a structured internal\nevaluation of the tool by reviewing the same set of synthetic patients (H.S.). For each patient, two evaluation\n12\n"}, {"page": 26, "text": "Table S6: CAP component evaluation questionnaire (questions and comments). CAP=cost-aware prediction.\nCAP Component\nClinical process\nID\nQuestion/Comment\nA, B (only predicted\nrisk)\nRisk estimation\nQ1\nThe classifier’s risk estimate made me more confident in assessing\nthis patient’s risk.\nA, B, E\nRisk estimation\nQ2\nThe classifier’s risk estimate and tool made me more confident in\nassessing this patient’s risk.\nD, E\nRisk estimation\nQ3\nTo make a risk estimate, I relied on the classifier and tool rather than\nmy clinical judgement.\nE\nRisk estimation\nC1\nComment about generated risk explanation.\nD, F\nWeighing clinical cost trade-\noffs\nQ4\nThe CIP cost curves made the trade-offs between clinical costs clearer.\nD, F\nWeighing clinical cost trade-\noffs\nC2\nComment about CIP cost curves:\n- What is beneficial about the CIP cost curves?\n- What is unclear or overwhelming about the about the CIP cost\ncurves (e.g., cost information)?\nG\nHandling uncertainty\nQ5\nThe tool suggested supportive and actionable steps to reduce uncer-\ntainty of the patient’s risk.\nG\nHandling uncertainty\nQ6\nThe tool made me feel falsely reassured about uncertainties I would\nnormally question.\nG\nHandling uncertainty\nC3\nComment about uncertainty handling.\nH\nCost-aware decision guidance\nQ7\nThe cost-aware guidance provides an informative recommendation\nregarding future risk.\nAll\nIntegration of patient-level and\nsystem-level reasoning\nQ8\nThe combination of patient-level and population-level information is\nhelpful.\nAll\nIntegration of patient-level and\nsystem-level reasoning\nC4\nDescribe how the tool helped or hindered balancing individual vs.\npopulation-level thinking.\nAll\nGenerating explanation\nQ9\nThe tool’s explanation captured the key factors I considered when\nmaking a decision.\nAll\nGenerating explanation\nQ10\nI would use the explanation to communicate my decision to others\n(colleagues, patient, patient’s family, health provider admin).\nAll\nGenerating explanation\nQ11\nThe tool described things I already know or already had considered,\nsuperfluous information.\nAll\nGenerating explanation\nQ12\nThe tool made suggestions outside established guidelines or\nevidence-based medicine.\nAll\nGenerating explanation\nC5\nComment about generated explanation.\ntables were completed. The first table (cf. Table S7) focused on the perceived usefulness and factual accuracy\nof the information generated by the tool. The second table (cf. Table S8) cataloged specific types of issues\nencountered, such as hallucinations, unclear language, or unrealistic suggestions. This internal review aimed\nto systematically document known failure modes and assess the alignment between the tool’s outputs and\nclinical reasoning expectations.\nTable S7: CAP component evaluation. CAP=cost-aware prediction.\nCAP Component\nGeneral comments on useful-\nness of information\nComments on truthfulness, re-\nliability and language\nUsefulness\nAccuracy\nInsert value\nInsert value\nInsert value\nInsert value\nInsert value\nTable S8: Categories of feedback issues in tool-generated suggestions.\n#\nCategory\n1\nSuperfluous/obvious\n2\nUnasked for/unsolicited\n3\nRepetitive\n4\nIncorrect terminology/use of expressions\n5\nIncorrect (overreaching) medical terminology\n6\nHallucination (unfounded, unsubstantiated advice)\n7\nOverbearing, imperative advice for details, minor issues\n8\nOverly confident imperative advice (shall, must)\n9\nUnrealistic, unfeasible, idealistic advice\n10\nAdvice to distrust/overrule classifier/reclassify\n11\nUnclear meaning/implication for clinician\n13\n"}]}