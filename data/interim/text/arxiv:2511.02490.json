{"doc_id": "arxiv:2511.02490", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2511.02490.pdf", "meta": {"doc_id": "arxiv:2511.02490", "source": "arxiv", "arxiv_id": "2511.02490", "title": "BRAINS: A Retrieval-Augmented System for Alzheimer's Detection and Monitoring", "authors": ["Rajan Das Gupta", "Md Kishor Morol", "Nafiz Fahad", "Md Tanzib Hosain", "Sumaya Binte Zilani Choya", "Md Jakir Hossen"], "published": "2025-11-04T11:27:03Z", "updated": "2025-11-04T11:27:03Z", "summary": "As the global burden of Alzheimer's disease (AD) continues to grow, early and accurate detection has become increasingly critical, especially in regions with limited access to advanced diagnostic tools. We propose BRAINS (Biomedical Retrieval-Augmented Intelligence for Neurodegeneration Screening) to address this challenge. This novel system harnesses the powerful reasoning capabilities of Large Language Models (LLMs) for Alzheimer's detection and monitoring. BRAINS features a dual-module architecture: a cognitive diagnostic module and a case-retrieval module. The Diagnostic Module utilizes LLMs fine-tuned on cognitive and neuroimaging datasets -- including MMSE, CDR scores, and brain volume metrics -- to perform structured assessments of Alzheimer's risk. Meanwhile, the Case Retrieval Module encodes patient profiles into latent representations and retrieves similar cases from a curated knowledge base. These auxiliary cases are fused with the input profile via a Case Fusion Layer to enhance contextual understanding. The combined representation is then processed with clinical prompts for inference. Evaluations on real-world datasets demonstrate BRAINS effectiveness in classifying disease severity and identifying early signs of cognitive decline. This system not only shows strong potential as an assistive tool for scalable, explainable, and early-stage Alzheimer's disease detection, but also offers hope for future applications in the field.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2511.02490v1", "url_pdf": "https://arxiv.org/pdf/2511.02490.pdf", "meta_path": "data/raw/arxiv/meta/2511.02490.json", "sha256": "8a65224ade7b87887b766c02116a876100406d83bc1c7a9bf84849a50f139d67", "status": "ok", "fetched_at": "2026-02-18T02:28:33.203337+00:00"}, "pages": [{"page": 1, "text": "BRAINS: A Retrieval-Augmented System\nfor Alzheimer’s Detection and Monitoring\nRajan Das Gupta1,4\nMd Kishor Morol4,†\nNafiz Fahad2,4\nMd Tanzib Hosain1,4\nSumaya Binte Zilani Choya4,4\nMd Jakir Hossen2,4,†\n1American International University-Bangladesh\n2Multimedia University\n3George Mason University\n4ELITE Research Lab\n18-36304-1@student.aiub.edu, kishormorol@ieee.org\nnafiz.fahad@student.mmu.edu.my, 20-42737-1@student.aiub.edu\nschoya@gmu.edu, jakir.hossen@mmu.edu.my\nAbstract—As the global burden of Alzheimer’s disease (AD)\ncontinues to grow, early and accurate detection has become\nincreasingly critical, especially in regions with limited access\nto advanced diagnostic tools. We propose BRAINS (Biomedical\nRetrieval-Augmented Intelligence for Neurodegeneration Screen-\ning) to address this challenge. This novel system harnesses\nthe powerful reasoning capabilities of Large Language Models\n(LLMs) for Alzheimer’s detection and monitoring. BRAINS\nfeatures a dual-module architecture: a cognitive diagnostic\nmodule and a case-retrieval module. The Diagnostic Mod-\nule utilises LLMs fine-tuned on cognitive and neuroimaging\ndatasets—including MMSE, CDR scores, and brain volume\nmetrics—to perform structured assessments of Alzheimer’s risk.\nMeanwhile, the Case Retrieval Module encodes patient profiles\ninto latent representations and retrieves similar cases from a\ncurated knowledge base. These auxiliary cases are fused with\nthe input profile via a Case Fusion Layer to enhance contextual\nunderstanding. The combined representation is then processed\nwith clinical prompts for inference. Evaluations on real-world\ndatasets demonstrate BRAINS effectiveness in classifying disease\nseverity and identifying early signs of cognitive decline. This\nsystem not only shows strong potential as an assistive tool\nfor scalable, explainable, and early-stage Alzheimer’s disease\ndetection, but also offers hope for future applications in the field.\nIndex Terms—Alzheimer’s Disease, Retrieval Augmented Gen-\neration (RAG), Cognitive Decline Detection, Clinical Decision\nSupport\nI. INTRODUCTION\nAlzheimer’s disease (AD), the most common form of de-\nmentia, represents a complex and progressive neurodegenera-\ntive disorder that significantly impairs memory, cognition, and\nbehaviour [1]. According to the World Health Organization\n(WHO), over 55 million people worldwide are currently living\nwith dementia, with Alzheimer’s disease accounting for up\nto 70% of these cases. Alarmingly, this number is projected\nto rise to 139 million by 2050, driven primarily by ageing\npopulations and delayed diagnoses [2]. As noted by the\nNational Institute on Aging (NIA), Alzheimer’s is currently\namong the leading causes of disability and dependency among\nolder adults. However, it remains vastly underdiagnosed, par-\n† Corresponding author\nticularly in low-resource settings where access to specialized\nneurological assessment is limited [3].\nDespite decades of research, early and reliable detection\nof Alzheimer’s disease remains a critical challenge. Tradi-\ntional diagnostic methods, including neuropsychological test-\ning, MRI-based brain volume analysis [4], and clinical rating\nscales such as the Mini-Mental State Examination (MMSE)\nand Clinical Dementia Rating (CDR) [5], are resource-\nintensive and require domain expertise [6]. Moreover, access\nto neuroimaging and specialized interpretation remains scarce\nin economically disadvantaged regions, leading to disparities\nin early diagnosis and care delivery [7], [8].\nDiagnosing and managing Alzheimer’s disease is further\ncomplicated by the brain’s structural complexity and the het-\nerogeneity of cognitive decline patterns. Small morphological\nchanges, such as cortical thinning or hippocampal atrophy,\nare often difficult to quantify and interpret, even for experi-\nenced clinicians [9]. Additionally, real-world assessment data,\nsuch as brain volume estimates (eTIV, nWBV), MMSE/CDR\nscores, and demographic information (Table I), are inherently\nvariable and incomplete across populations [10]–[12]. These\nchallenges underscore the need for intelligent systems inte-\ngrating heterogeneous, multimodal data to aid early detection\nand disease monitoring [13]–[15].\nRecent advances in artificial intelligence (AI) particularly\nlarge language models (LLMs) offer transformative potential\nfor assisting clinicians in synthesizing such complex data.\nWhile previous AI systems in neurology have relied on rigid\nfeature engineering or domain-specific heuristics, LLMs [16]–\n[20] provide a generalizable, prompt-driven framework for\nreasoning over structured clinical input. However, most current\nsystems lack case-based contextual reasoning, interpretability,\nand robustness to real-world data variability.\nTo\naddress\nthese\nlimitations,\nwe\nintroduce\nBRAINS\n(Biomedical Retrieval-Augmented Intelligence for Neurode-\ngeneration Screening)—a novel, retrieval-augmented diagnos-\ntic framework that leverages the reasoning capabilities of\nLLMs alongside case-based retrieval and neurocognitive data\nfusion. BRAINS adopts a dual-phase architecture: the Diag-\narXiv:2511.02490v1  [cs.LG]  4 Nov 2025\n"}, {"page": 2, "text": "TABLE I: Key Features for Alzheimer’s Disease Diagnosis\nFeature\nClinical Relevance\nMMSE\nGlobal cognitive function\nCDR\nDementia severity rating\neTIV\nIntracranial volume normalization\nnWBV\nBrain atrophy indicator\nHippocampal Volume\nMemory-related region atrophy\nAmygdala Volume\nEmotion processing region\nVentricular Volume\nEnlarged in AD progression\nTemporal Thickness\nCortical atrophy biomarker\nWMH\nMarker for vascular pathology\nAge\nPrimary risk factor\nEducation Level\nReflects cognitive reserve\nGender\nInfluences disease manifestation\nAPOE Genotype\nGenetic predisposition (ϵ4 allele)\nMoCA Score\nMCI screening alternative\nGDS Score\nScreens comorbid depression\nnostic Module is pre-trained with neurocognitive assessment\nrecords to encode foundational knowledge of Alzheimer’s\nprogression. In contrast, the Case Retrieval Module encodes\ninput features to retrieve semantically relevant historical cases\nfrom a clinical knowledge base. These auxiliary cases are\nintegrated through a Case Fusion Layer, enabling context-\naware reasoning that enhances interpretability and prediction\naccuracy.\nWe construct and validate BRAINS on a real-world dataset\ncomprising MMSE, CDR, brain volumetric measures (eTIV,\nnWBV), and demographic variables to evaluate the sys-\ntem’s practical utility. Our experiments demonstrate that\nBRAINS achieves superior performance in detecting and\nstaging Alzheimer’s disease compared to baseline models,\nwhile also providing explainable outputs aligned with clinical\ninsights. We argue that BRAINS not only contributes a robust\ntechnical advancement but also represents a scalable solution\nfor dementia screening in both high-resource hospitals and\nunderserved settings where early intervention is most critical.\nII. METHODOLOGY\nIn\nthis\nsection,\nwe\nintroduce\nBRAINS\n(Biomedi-\ncal Retrieval-Augmented Intelligence for Neurodegeneration\nScreening), a system designed to support Alzheimer’s disease\ndiagnosis by leveraging clinical guidelines in neurocognitive\nassessment and brain imaging. We begin by describing our\ndataset, which includes demographic, cognitive, and neu-\nroanatomical features such as MMSE, CDR, eTIV, and nWBV.\nWe then present the architecture of BRAINS, which combines\na Diagnostic Module for cognitive evaluation with a Case\nRetrieval Module that integrates relevant patient histories.\nThese components are fused via a Case Fusion Layer, enabling\ncontext-aware, explainable predictions aligned with real-world\nclinical workflows.\nA. Data Preparing\nThe objective of pre-training is to equip the foundational\nmodel with prior domain knowledge by exposing it to a broad\ncorpus of relevant information. This stage involves training on\na large volume of unlabeled text to help the model internalize\ndomain-specific concepts before fine-tuning on structured di-\nagnostic tasks. In our case, we aim for the BRAINS model to\nacquire baseline understanding of Alzheimer’s-related termi-\nnology, cognitive scoring systems, and clinical reasoning prior\nto task-specific adaptation.\nTo support this, we curated a pre-training dataset consist-\ning of textual reports and summaries derived from relevant\nAlzheimer’s disease report [4], [7], [21], neurocognitive eval-\nuations (e.g., MMSE, CDR) [22], and structured annotations\nfrom clinical databases such as NACC and ADNI [23], [24].\nSince the model is not designed to process images directly, we\napplied regularization by removing sentences that referenced\nvisual elements. Specifically, we filtered out any sentences\ncontaining terms like “Figure” or “see image” to ensure\nconsistency in textual input. This pre-training phase enhances\nthe model’s ability to reason over structured brain health data\nin subsequent diagnostic tasks.\nB. Alzheimer’s Disease Dataset\nTo support the diagnosis and staging of Alzheimer’s dis-\nease, we curated a further clinical dataset with 1105 patient\nrecords collected from medical institutions. Each subject is\ncategorized as 1. Early-Onset Alzheimer’s Disease, 2. Late-\nOnset Alzheimer’s Disease, 3. Familial Alzheimer’s Disease,\n4. Sporadic Alzheimer’s Disease, 5. Atypical Alzheimer’s\nDisease based on MMSE, CDR, and neuroimaging-derived\nmetrics.\nThe dataset includes features: MMSE, CDR, eTIV, nWBV,\nage, gender, handedness, education, and socioeconomic status.\nAll entries were pre-processed by normalization, encoding,\nand outlier removal to ensure quality and consistency for\ndownstream modeling with BRAINS.\nC. Model Architecture\nAs illustrated in Figure 1, the proposed BRAINS framework\nconsists of two core components: the Diagnostic Module and\nthe Case Retrieval Module. Upon receiving a new patient\ncase—comprising neurocognitive scores (e.g., MMSE, CDR),\ndemographic data, and structural brain metrics (e.g., nWBV,\neTIV)—the Case Retrieval Module first encodes the input and\n"}, {"page": 3, "text": "Text Encoder\nAge: 69 years old \nMMSE: 27 (Normal: 24–30) \nCDR: 0.5 (Normal: 0.0) \neTIV (mL): 1485 (Normal: 1350–1600) \nnWBV: 0.73 (Normal: >0.75) \nEducation: 16 years \nSES: 4 \n… \nDiagnostic Outcomes: Very Mild Alzheimer’s \nDisease\nAge: 76 years old \nMMSE: 22 (Normal: 24–30) \nCDR: 1.0 (Normal: 0.0) \neTIV (mL): 1450 (Normal: 1350–1600) \nnWBV: 0.68 (Normal: >0.75) \nEducation: 12 years \nSES: 3 \n… \nDiagnostic Outcomes: Mild Alzheimer’s \nDisease, Moderate Alzheimer’s Disease\nCase Fusion Layer\nAge: 82 years old \nMMSE: 17 (Normal: 24–30) \nCDR: 2.0 (Normal: 0.0) \neTIV (mL): 1402 (Normal: 1350–1600) \nnWBV: 0.61 (Normal: >0.75) \nEducation: 8 years \nSES: 2 \n… \nDiagnostic Outcomes: Severe Alzheimer’s\nDisease\nInference\nDiagnostic Outcomes: [i] [iii] [iv]\nWn\n<s>You are now a professional neurologist specializing in Alzheimer’s disease.\nBased on the patient's neurocognitive and brain volume data—such as MMSE,\nCDR, eTIV, nWBV, age, education, and SES—please make a clinical judgment.\nThe values in parentheses represent the typical clinical range where relevant.\nSelect the appropriate diagnosis from the following options (multiple selections\nallowed): (i) No Cognitive Impairment, (ii) Very Mild Alzheimer’s Disease, (iii)\nMild Alzheimer’s Disease, (iv) Moderate Alzheimer’s Disease, (v) Severe\nAlzheimer’s Disease .</s>\n<s> Patient Data: Age: 76 years, MMSE: 22, CDR: 1.0, eTIV: 1450, nWBV:\n0.68, Education: 12 years, SES: 3 Below are reference neurocognitive records\nand diagnostic outcomes for similar patients:<RAG><RAGHere></RAG>\n<S>\n_System\nCase Retruval Module\n:\n_You\n_are\n_now\n_a\n<RAG>\n<RAGHere>\n</RAG>\n</s>\nWcls\nWn-1 \nWn\nW1\n_professional \nWcls\nWn-1 \nWn\nW1\nWcls\nWn-1 \nW1\nReplace\nToken\nDatabase\nFig. 1: BRAINS architecture for Alzheimer’s diagnosis. The input case is encoded and used to retrieve similar neurocognitive\nrecords. Retrieved cases are fused with the input via the Case Fusion Layer, replacing the <RAGHere> token in the prompt.\nThe fused representation is then passed to the LLM for inference and explanation.\nretrieves the top-KKK most clinically relevant auxiliary cases\nfrom a curated knowledge base. These retrieved cases are\nthen paired with the input as (T, R)(T, R)(T, R), where TTT\nrepresents the target case and RRR denotes the reference cases.\nThis case pair is subsequently passed to the Diagnostic Mod-\nule, which performs reasoning over the joint representation to\nassess the likelihood and stage of Alzheimer’s disease. By in-\ntegrating contextual information from similar historical cases,\nBRAINS enhances interpretability and diagnostic robustness.\nThe following sections detail each module’s architecture and\noperational flow.\nD. Case Retrieval Module\nTo enhance the precision and contextual awareness of\nAlzheimer’s disease diagnosis, the proposed BRAINS sys-\ntem integrates retrieval-augmented inference by leveraging a\nstructured memory of historical neurocognitive cases. Rather\nthan relying solely on generalizable reasoning from pre-trained\nknowledge, BRAINS employs a Case Retrieval Module to\ndynamically fetch semantically similar patient profiles from\na vectorized clinical case database. This augmentation facili-\ntates nuanced decision-making, especially in the presence of\nheterogeneous or borderline cognitive features.\nThe Case Retrieval Module comprises two core com-\nponents: a curated neurocognitive case database and a\nhigh-dimensional text encoder. Each entry in the training\ndataset—including features such as MMSE, CDR, age, eTIV,\nnWBV, and education—is first tokenized and encoded using\na clinical-domain-adapted text encoder. The resulting hidden\nrepresentation w[CLS], which summarizes the input case, is\nstored in a FAISS-based vector database [25].\nDuring training and inference, the input case T is encoded\ninto its hidden representation and queried against the FAISS\nvector store using cosine similarity. The top 1K most similar\nhistorical cases are retrieved, followed by a reranking module\nthat reorders them based on a fine-tuned scoring mechanism.\nThe highest scoring K auxiliary cases R = {r0, r1, . . . , rK−1}\nare then selected to form a case pair (T, R), where the target\ncase T is jointly reasoned over with the retrieved support\ncases R. This approach allows BRAINS to directly incor-\nporate population-level cognitive trends and structural brain\nbiomarkers into its diagnostic inference, ultimately improving\nrobustness and explainability in clinical settings.\nE. Diagnostic Module\nUpon retrieval, the BRAINS framework forms a case pair\n(T, R), where T represents the input patient profile and R =\n{r0, r1, ..., rK−1} denotes the top-K semantically relevant\nneurocognitive cases retrieved from the clinical memory. The\nDiagnostic Module consists of two key components: the Case\nFusion Layer and the Inference LLM.\nTo overcome the context-length limitations of large lan-\nguage models, the Case Fusion Layer aggregates representa-\ntions of the retrieved cases. Each auxiliary case ri is encoded\n"}, {"page": 4, "text": "TABLE II: Performance comparison of LLaMA2-13B, RAG variants, and the proposed BRAINS system across all, single,\ndouble, and triple case types.\nModel\nAll\nSingle\nDouble\nTriple\nCorrect\nF1\nPrec.\nRecall\nF1\nPrec.\nRecall\nF1\nPrec.\nRecall\nF1\nLLaMA2-13B\nFive-shot\n0.335\n0.339\n0.000\n0.000\n0.000\n0.299\n0.719\n0.423\n0.421\n0.980\n0.591\nFine-tuning\n0.600\n0.538\n0.657\n0.728\n0.692\n0.468\n0.474\n0.471\n0.643\n0.281\n0.391\nw/o standard\n0.454\n0.376\n0.645\n0.513\n0.571\n0.290\n0.500\n0.361\n0.250\n0.063\n0.100\nRAG\nRAG-1\n0.712\n0.731\n0.766\n0.540\n0.619\n0.703\n0.824\n0.802\n0.774\n0.981\n0.863\nRAG-2\n0.727\n0.755\n0.790\n0.572\n0.664\n0.660\n0.921\n0.769\n0.727\n0.975\n0.842\nBRAINS\n0.773\n0.819\n0.784\n0.731\n0.740\n0.711\n0.875\n0.810\n0.931\n0.911\n0.929\ninto hidden vectors wi = {w[CLS]i, w1i, . . . , wni}, and the\ninput case is encoded as t = {t[CLS], t1, . . . , tn}. A cross-\nattention mechanism, based on the standard Transformer for-\nmulation [26], is employed to align and integrate contextual\ninformation across the retrieved examples:\nAttn(Q, K, V ) = softmax\n\u0012QK⊤\n√dk\n\u0013\nV\n(1)\nwhere Q = WQt[CLS], K = WKA, V = WKA, and A denotes\nthe concatenated matrix of retrieved case vectors:\nA = [w[CLS]0, w10, . . . , wn0, w[CLS]1, . . . , wn(K−1)]\nThe resulting case fusion vector replaces the special\n<RAGHere> token within the prompt embedding sequence\nP = {p<s>, pSystem, . . . , p<RAGHere>, . . . , p</s>}. The fused\nsequence is then passed to the Inference LLM for prediction.\nDuring pre-training, we adopt a next-token prediction strat-\negy to enable the model to acquire foundational neurocog-\nnitive knowledge. Fine-tuning is conducted with supervised\nobjectives, where the loss is computed solely on the assis-\ntant’s response, refining the model’s focus and performance in\nAlzheimer’s disease prediction tasks.\nIII. EXPERIMENTS\nIn this section, we present the experimental framework\nemployed to evaluate the efficacy of our proposed system. This\nframework is grounded in clinically relevant neurocognitive\ndatasets, with a focus on early-stage Alzheimer’s disease\ndetection and multi-faceted cognitive impairment classifica-\ntion. The experimental design is meticulously structured to\nprobe retrieval-augmented reasoning performance and gener-\nalization across single-clue, dual-clue, and complex multi-clue\ndiagnostic cases. Implementation details, data preprocessing\nstrategies, and evaluation protocols are aligned with estab-\nlished neuroscience benchmarks [27] to ensure reproducibility\nand relevance. The results provide quantitative insight into\nthe system’s diagnostic accuracy and interpretability under\nvariable cognitive load conditions.\nA. Pre-training Setting\nWe adopt the LLaMA2-13B [20] model as our foundational\nlarge language model, further fine-tuned on clinically curated\nneurocognitive corpora involving Alzheimer’s disease, mild\ncognitive impairment (MCI), and related neurodegenerative\nconditions. Training is conducted over 10 epochs with a\nbatch size of 64, using the AdamW optimizer [28] and a\nlearning rate set to 1 × 10−4. To ensure stable convergence,\nwe apply 1,000 warm-up steps. The token block size is\nfixed at 2048 to accommodate high-resolution case narratives\nthat integrate structured cognitive assessments (e.g., MMSE,\nCDR), neuroimaging-derived biomarkers (e.g., hippocampal\natrophy, cortical thinning), and demographic variables (e.g.,\nage, gender, education). This fine-tuning strategy equips the\nmodel with domain-specific reasoning capabilities necessary\nfor downstream neurodiagnostic inference.\nB. Fine-tuning Setting\nBuilding upon prior foundational training, we repurpose the\npretrained neurodiagnostic language model as the backbone\nfor inference. To ensure alignment between retrieval and\nreasoning, the same model architecture is deployed as the text\nencoder within the Case Retrieval Module, thereby preserving\nrepresentational consistency. For reranking retrieved support\ncases, we integrate the bge-reranker-large [29] to\nrefine case relevance via dense semantic scoring. At inference\ntime, we retrieve the top-K = 5 neurocognitive profiles from\nthe vector database, grounded in prior subjects exhibiting\ncomparable biomarker and cognitive test signatures.\nTo promote positional robustness and mitigate overfitting to\nfixed retrieval slots, we introduce a dynamic masking strategy\nduring training, where m ∈[0, 4] auxiliary cases are randomly\nmasked in each training iteration. The model is trained for 15\nepochs with a batch size of 4 using the AdamW optimizer [28]\nand a learning rate of 1×10−5. To improve training efficiency\nand parameter efficiency, we adopt Low-Rank Adaptation\n(LoRA) [30], configured with α = 32 and r = 8, enabling\nscalable fine-tuning within computational constraints while\nretaining high domain-specific fidelity.\nIV. RESULTS\nAs presented in Table II, the efficacy of the proposed\nBRAINS model is validated through rigorous empirical eval-\n"}, {"page": 5, "text": "uation within the domain of neurocognitive disorder inference.\nIn the baseline setting using LLaMA2-13B, the Five-shot\nprompting paradigm can generate plausible outputs, yet it fails\nto yield reliable diagnostic accuracy in complex multi-label\nneurocognitive cases.\nUpon fine-tuning the model on structured clinical texts—\nenriched with cognitive metrics such as MMSE, CDR, and\nvolumetric MRI-derived features—a substantial improvement\nof 26.50% in accuracy is observed. The absence of these\nstandardized neuro-biomarkers during input leads to a pro-\nnounced degradation in model performance, especially in\ncomplex classification settings involving co-occurring condi-\ntions. Further gains are achieved by incorporating retrieval-\naugmented generation (RAG), where one or more relevant\ncases are retrieved to assist inference. With a single retrieved\ncase (RAG-1), accuracy increases from 60.00% to 71.20%,\nand additional retrieved profiles provide incremental benefits.\nHowever, retrieving more than two cases leads to token\nlength constraints that inhibit reasoning due to limited context\nwindow sizes. This bottleneck is effectively overcome by the\nBRAINS model’s case fusion mechanism, which supports the\nintegration of up to five auxiliary cases, achieving an accuracy\nof 77.30%.\nUnder the Five-shot configuration, the model achieves high\nrecall (98.00%) in multi-pathology scenarios but suffers from\nlow F1 (59.10%) due to poor precision. In contrast, single-\nlabel prediction tasks reveal a complete breakdown (F1 =\n0.00%), suggesting an overly conservative decision boundary.\nThis highlights the limitations of zero- or Five-shot gen-\neralization for complex neurological inference. Fine-tuning\nimproves this imbalance, while the BRAINS model surpasses\nboth token and reasoning limitations, delivering robust and\ninterpretable predictions across varying levels of diagnostic\ncomplexity.\nV. CONCLUSION\nThis study introduces BRAINS, a novel foundation model\narchitected specifically for early-stage alzheimer’s disorder\nscreening. Tailored for the analysis of core neurological report\ndata—such as cognitive assessments (e.g., MMSE, CDR),\nspeech and behaviour logs, and structural brain imaging sum-\nmaries—BRAINS is designed to support clinical reasoning,\nparticularly for less experienced practitioners in neurology and\ngeriatric medicine. By integrating retrieval-augmented gen-\neration (RAG) mechanisms, BRAINS substantially improves\ndiagnostic precision for multi-morbidity inference tasks. In\nour benchmark evaluation on mild cognitive impairment and\nAlzheimer-type dementia classification, BRAINS achieves an\naccuracy of 77.30%, significantly outperforming the baseline\nlarge language model, which attains only 45.40%. We posit\nthat BRAINS represents a foundational shift in scalable, in-\nterpretable, and data-efficient brain health modelling, with the\npotential to generalise across a broad spectrum of neurological\ndiagnostic domains.\nREFERENCES\n[1] B. P. Imbimbo, S. Ippati, M. Watling, and C. Balducci, “Accelerating\nalzheimer’s disease drug discovery and development: What’s the way\nforward?,” Expert Opinion on Drug Discovery, 2021.\n[2] S. Miller, “Astrocyte heterogeneity in the adult central nervous system,”\nFrontiers in Cellular Neuroscience, vol. 12, p. n/a, 2018.\n[3] R. C. Petersen et al., “Alzheimer’s disease neuroimaging initiative (adni):\nClinical characterization,” Neurology, vol. 74, no. 3, pp. 201–209, 2010.\n[4] D. S. Marcus, T. H. Wang, J. Parker, et al., “Open access series\nof imaging studies (oasis): Cross-sectional mri data in young, middle\naged, nondemented, and demented older adults,” Journal of Cognitive\nNeuroscience, vol. 19, no. 9, pp. 1498–1507, 2007.\n[5] J. C. Morris, “The clinical dementia rating (cdr): Current version and\nscoring rules,” Neurology, vol. 43, no. 11, pp. 2412–2414, 1993.\n[6] C. R. Jack, D. A. Bennett, K. Blennow, et al., “Nia-aa research frame-\nwork: Toward a biological definition of alzheimer’s disease,” Alzheimer’s\n& Dementia, vol. 14, no. 4, pp. 535–562, 2018.\n[7] M. W. Weiner, D. P. Veitch, P. S. Aisen, et al., “2014 update of\nthe alzheimer’s disease neuroimaging initiative: A review of papers\npublished since its inception,” Alzheimer’s & Dementia, vol. 11, no. 6,\npp. e1–e120, 2015.\n[8] M. F. Folstein, S. E. Folstein, and P. R. McHugh, “Mini-mental state:\nA practical method for grading the cognitive state of patients for the\nclinician,” Journal of Psychiatric Research, vol. 12, no. 3, pp. 189–198,\n1975.\n[9] A. Reuben, A. Caspi, H. Harrington, et al., “Predicting dementia from\nstructured health records using machine learning,” JAMA Network Open,\nvol. 4, no. 7, p. e2118854, 2021.\n[10] Z. Yang, X. Lin, et al., “Knowledge-enhanced language models in\nmedical domains,” Briefings in Bioinformatics, 2023.\n[11] K. Singhal, S. Azizi, et al., “Towards expert-level medical question\nanswering with prompt-augmented llms,” Nature, 2023.\n[12] R. Luo, Y. Zhang, et al., “Clinicalt5: Retrieval-enhanced clinical sum-\nmarization with task-adaptive pretraining,” Findings of ACL, 2024.\n[13] A. Zeng, X. Ma, and K. Yu, “Long-context modeling for medical report\nunderstanding using sparse transformers,” Proceedings of ACL, 2024.\n[14] C. Gao, L. Zhang, et al., “Reta: Retrieval-augmented transformer for\nclinical note understanding,” arXiv preprint arXiv:2303.02252, 2023.\n[15] Y. Zhang, K. Sun, et al., “Cogagent: A generalist foundation model for\nmultimodal tasks,” arXiv preprint arXiv:2403.11295, 2024.\n[16] M. Chen, R. Zhou, et al., “Pmc-llama: Towards open-source medical\nllms,” arXiv preprint arXiv:2401.05509, 2024.\n[17] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts,\nP. Barham, H. W. Chung, C. Sutton, S. Gehrmann, et al., “Palm: Scal-\ning language modeling with pathways,” Journal of Machine Learning\nResearch, vol. 24, no. 240, pp. 1–113, 2023.\n[18] J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman,\nD. Almeida, J. Altenschmidt, S. Altman, S. Anadkat, et al., “Gpt-4\ntechnical report,” arXiv preprint arXiv:2303.08774, 2023.\n[19] S. Li, K. Singhal, et al., “Med-palm: Large language models for\nmedicine,” arXiv preprint arXiv:2305.09617, 2023.\n[20] H. Touvron, T. Lavril, G. Izacard, et al., “Llama: Open and efficient\nfoundation language models,” arXiv preprint arXiv:2302.13971, 2023.\n[21] G. B. Frisoni, N. C. Fox, C. R. Jack Jr, P. Scheltens, and P. M.\nThompson, “The clinical use of structural mri in alzheimer disease,”\nNature reviews neurology, vol. 6, no. 2, pp. 67–77, 2010.\n[22] J. C. Morris, “The clinical dementia rating (cdr) current version and\nscoring rules,” Neurology, vol. 43, no. 11, pp. 2412–2412, 1993.\n[23] N. A. C. C. (NACC), “National alzheimer’s coordinating center (nacc)\ndata.” https://www.alz.washington.edu/, 2023. Accessed: 2025-07-28.\n[24] A. D. N. I. (ADNI), “Alzheimer’s disease neuroimaging initiative (adni).”\nhttps://adni.loni.usc.edu/, 2023. Accessed: 2025-07-28.\n[25] M. Douze, A. Guzhva, C. Deng, J. Johnson, G. Szilvasy, P.-E. Mazar´e,\nM. Lomeli, L. Hosseini, and H. J´egou, “The faiss library,” 2025.\n[26] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nŁ. Kaiser, and I. Polosukhin, “Attention is all you need,” Advances in\nneural information processing systems, vol. 30, 2017.\n[27] J. Guo, X. Shan, G. Wang, D. Chen, R. Lu, and S. Tang, “Heart:\nHeart expert assistant with retrieval-augmented,” in AAAI 2024 Spring\nSymposium on Clinical Foundation Models, 2024.\n[28] I. Loshchilov and F. Hutter, “Decoupled weight decay regularization,”\narXiv preprint arXiv:1711.05101, 2017.\n"}, {"page": 6, "text": "[29] H. Xiao, R. Ren, et al., “Bge-reranker: A strong baseline for passage\nreranking,” arXiv preprint arXiv:2309.11664, 2023.\n[30] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang,\nW. Chen, et al., “Lora: Low-rank adaptation of large language models.,”\nICLR, vol. 1, no. 2, p. 3, 2022.\n"}]}