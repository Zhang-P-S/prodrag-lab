{"doc_id": "arxiv:2512.05537", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2512.05537.pdf", "meta": {"doc_id": "arxiv:2512.05537", "source": "arxiv", "arxiv_id": "2512.05537", "title": "Automated Identification of Incidentalomas Requiring Follow-Up: A Multi-Anatomy Evaluation of LLM-Based and Supervised Approaches", "authors": ["Namu Park", "Farzad Ahmed", "Zhaoyi Sun", "Kevin Lybarger", "Ethan Breinhorst", "Julie Hu", "Ozlem Uzuner", "Martin Gunn", "Meliha Yetisgen"], "published": "2025-12-05T08:49:57Z", "updated": "2025-12-05T08:49:57Z", "summary": "Objective: To evaluate large language models (LLMs) against supervised baselines for fine-grained, lesion-level detection of incidentalomas requiring follow-up, addressing the limitations of current document-level classification systems.   Methods: We utilized a dataset of 400 annotated radiology reports containing 1,623 verified lesion findings. We compared three supervised transformer-based encoders (BioClinicalModernBERT, ModernBERT, Clinical Longformer) against four generative LLM configurations (Llama 3.1-8B, GPT-4o, GPT-OSS-20b). We introduced a novel inference strategy using lesion-tagged inputs and anatomy-aware prompting to ground model reasoning. Performance was evaluated using class-specific F1-scores.   Results: The anatomy-informed GPT-OSS-20b model achieved the highest performance, yielding an incidentaloma-positive macro-F1 of 0.79. This surpassed all supervised baselines (maximum macro-F1: 0.70) and closely matched the inter-annotator agreement of 0.76. Explicit anatomical grounding yielded statistically significant performance gains across GPT-based models (p < 0.05), while a majority-vote ensemble of the top systems further improved the macro-F1 to 0.90. Error analysis revealed that anatomy-aware LLMs demonstrated superior contextual reasoning in distinguishing actionable findings from benign lesions.   Conclusion: Generative LLMs, when enhanced with structured lesion tagging and anatomical context, significantly outperform traditional supervised encoders and achieve performance comparable to human experts. This approach offers a reliable, interpretable pathway for automated incidental finding surveillance in radiology workflows.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2512.05537v1", "url_pdf": "https://arxiv.org/pdf/2512.05537.pdf", "meta_path": "data/raw/arxiv/meta/2512.05537.json", "sha256": "e29cf5af01a0182b86daafc6140e4c1736e1744ab38a7aeb4bd54ab028c50c85", "status": "ok", "fetched_at": "2026-02-18T02:25:17.794485+00:00"}, "pages": [{"page": 1, "text": "Automated Identification of Incidentalomas Requiring Follow-Up: A\nMulti-Anatomy Evaluation of LLM-Based and Supervised Approaches\nNamu Park1, Farzad Ahmed2, Zhaoyi Sun1, Kevin Lybarger2, Ethan Breinhorst3, Julie Hu3,\nÖzlem Uzuner2, Martin Gunn4, Meliha Yetisgen1\n1Department of Biomedical Informatics and Medical Education, University of Washington, Seattle, WA, USA\n2Department of Information Sciences and Technology, George Mason University, Fairfax, VA, USA\n3Department of Radiology, Te Whatu Ora Health New Zealand, Te Toka Tumai Auckland, Auckland, New Zealand\n4Department of Radiology, School of Medicine, University of Washington, Seattle, WA, USA\nAbstract\nObjective: To evaluate large language models (LLMs) against supervised baselines for fine-grained,\nlesion-level detection of incidentalomas requiring follow-up, addressing the limitations of current\ndocument-level classification systems.\nMethods: We utilized a dataset of 400 annotated radiology reports containing 1,623 verified lesion\nfindings.\nWe compared three supervised transformer-based encoders (BioClinicalModernBERT,\nModernBERT, Clinical Longformer) against four generative LLM configurations (Llama 3.1-8B,\nGPT-4o, GPT-OSS-20b). We introduced a novel inference strategy using lesion-tagged inputs and\nanatomy-aware prompting to ground model reasoning.\nPerformance was evaluated using class-\nspecific F1-scores.\nResults: The anatomy-informed GPT-OSS-20b model achieved the highest performance, yielding\nan incidentaloma-positive macro-F1 of 0.79. This surpassed all supervised baselines (maximum\nmacro-F1: 0.70) and closely matched the inter-annotator agreement of 0.76. Explicit anatomical\ngrounding yielded statistically significant performance gains across GPT-based models (p < 0.05),\nwhile a majority-vote ensemble of the top systems further improved the macro-F1 to 0.90. Error\nanalysis revealed that anatomy-aware LLMs demonstrated superior contextual reasoning in distin-\nguishing actionable findings from benign lesions.\nConclusion: Generative LLMs, when enhanced with structured lesion tagging and anatomical con-\ntext, significantly outperform traditional supervised encoders and achieve performance comparable\nto human experts. This approach offers a reliable, interpretable pathway for automated incidental\nfinding surveillance in radiology workflows.\nKeywords:\nIncidental Findings; Large Language Models; Natural Language Processing;\nRadiology; Clinical Decision Support\n1. Introduction\nIncidental findings, or incidentalomas, refer to unexpected abnormalities discovered during imag-\ning studies performed for unrelated reasons [1]. Their detection has increased as imaging utilization\nhas grown across healthcare. A systematic review estimated that incidental findings appear in up\narXiv:2512.05537v1  [cs.CL]  5 Dec 2025\n"}, {"page": 2, "text": "to one-third of computed tomography (CT) and positron emission tomography CT (PET-CT) ex-\naminations [2]. These findings create a clinical dilemma, since most are benign while some represent\nearly-stage disease that requires intervention. Balancing overdiagnosis and missed pathology has\nbecome an important concern in medical practice.\nTo support clinicians, the American College of Radiology (ACR) and other professional groups\nprovide standardized decision rules for managing incidental findings [1]. These guidelines outline\nfollow-up pathways based on organ type, lesion size, and imaging features. Ensuring adherence\nremains difficult in real-world settings. Radiology reports are unstructured narratives that often\ninclude multiple findings and subtle recommendations, so significant incidental findings may be\noverlooked or receive no follow-up, which contributes to patient risk and healthcare inefficiency.\nDecision rules also contain little clinical context about comorbidities, although this information is\nrelevant for determining the appropriate timing and type of follow-up.\nIn large hospital systems, millions of radiology reports are generated each year, so manual review\nis infeasible. Automated systems that identify incidental findings and follow-up recommendations\ncould improve care coordination. Early natural language processing (NLP) work demonstrated that\nextracting such information is possible [3, 4, 5], but earlier systems were limited by linguistic vari-\nability, contextual ambiguity, and the lack of lesion-level supervision. Distinguishing an incidental\nlesion from the primary diagnostic concern often requires nuanced understanding that rule-based\nor shallow learning approaches cannot provide.\nRecent advances in clinical NLP offer new opportunities.\nDomain-specific encoders such as\nBioClinicalBERT [6] and ClinicalBERT [7] introduced contextual representations tailored to clinical\ntext.\nGenerative models such as GPT-4 [8] and Med-PaLM [9] show strong reasoning abilities\nand can interpret subtle contextual cues, recognize implicit recommendations, and integrate cross-\nsentence information that is essential for identifying incidentalomas accurately.\nThis study uses improved reasoning and text-understanding capabilities of modern NLP systems\nto develop LLM-based methods for anatomy-aware identification of incidentalomas. By integrating\nlesion-tagged inputs and prompting strategies grounded in anatomical structure, our approach aligns\ncomputational predictions with how radiologists interpret imaging findings. We compare LLM-\nbased systems with strong supervised baselines to evaluate their accuracy and clinical consistency.\nWe find that anatomical grounding improves performance and interpretability.\nThe best LLM\nconfiguration achieves an incidentaloma-positive macro-F1 of 0.79, which closely matches the inter-\nannotator agreement macro-F1 of 0.76.\n2. Related Work\n2.1. Clinical NLP using Supervised Models\nTransformer-based language models [10] have transformed clinical NLP by leveraging contextual\nembeddings from large-scale biomedical and clinical corpora.\nBioClinicalBERT [6], trained on\nMIMIC-III [11] and PubMed texts, has demonstrated strong performance on concept extraction and\nrelation detection tasks. Variants such as ClinicalBERT [7] and other transfer learning approaches\nhave further improved robustness across multiple clinical domains [12]. To handle longer clinical\ndocuments, architectures such as Clinical Longformer and Clinical BigBird extend transformers\nwith sparse attention, enabling efficient modeling of radiology reports and other long sequences\n[13]. More recently, domain-extended models like ModernBERT [14], BioClinicalModernBERT [15]\nincorporate long-context adaptations specifically designed for biomedical applications.\n2\n"}, {"page": 3, "text": "Statement of significance\nProblem\nRadiology reports frequently contain incidental findings, yet many are\nunder-recognized or lack appropriate follow-up, leading to missed or\ndelayed diagnoses. Manual review is infeasible at scale, and existing\nautomated systems often fail to distinguish incidentalomas from clin-\nically indicated findings.\nWhat\nis\nAlready\nKnown\nPrevious NLP and machine learning methods have demonstrated the\nfeasibility of extracting incidental findings from radiology text but\nmostly rely on document-level classification. These systems struggle\nwith contextual ambiguity and lack lesion-level interpretability.\nWhat\nthis\nPaper\nAdds\nThis paper presents a lesion-tagged, anatomy-aware framework for au-\ntomated identification of incidentalomas requiring follow-up across six\nanatomies. By integrating structured lesion information with LLMs\nand supervised encoders, the study shows that anatomy-informed\nprompting substantially improves detection accuracy, interpretability,\nand clinical reliability. It also introduces the first lesion-level bench-\nmark and error analysis for incidentaloma classification.\nWho Would Bene-\nfit\nfrom\nthe\nNew\nKnowledge in this\nPaper\nRadiologists, clinical informaticians, and health systems developing\nscalable AI tools for incidental finding surveillance and data-driven\nquality improvement in imaging workflows.\nIn radiology, these models have been applied to tasks such as report classification, lesion entity\nextraction, and malignancy detection [16, 17]. Comparative evaluations highlight their strengths\nfor document-level prediction but also reveal challenges in multi-class classification tasks where\nfalse negatives are especially costly [18, 19]. Our work contributes to this body of research by\nsystematically benchmarking BioClinicalModernBERT, ModernBERT, and Clinical Longformer for\nincidentaloma detection, providing evaluation across multiple anatomies.\n2.2. Clinical NLP using Generative Large Language Models\nGenerative LLMs have recently emerged as powerful tools for clinical NLP, capable of zero-shot\nand few-shot generalization across diverse medical tasks. GPT-4 [20] and GPT-4o [21] both have\nshown considerable performance on medical reasoning benchmarks, demonstrating competency in\nboth multiple-choice exams and free-text reasoning tasks [8, 21, 22].\nSimilarly, Med-PaLM [9],\nan instruction-tuned variant of PaLM [23], has exhibited strong performance on clinically-oriented\nquestion answering and reasoning tasks.\nOpen-source foundation models such as LLaMA [24]\nhave also been widely adopted in clinical NLP research as the backbone for lightweight adapta-\ntions. Methods like low-rank adaptation (LoRA) [25] have enabled efficient fine-tuning of LLMs for\ndomain-specific tasks without retraining full models.\nWithin radiology domain, LLMs have been explored for report summarization [26], clinical rea-\nsoning [27], and structured entity extraction from imaging reports [28]. Instruction-tuned medical\nLLMs such as MedAlpaca [29] have further demonstrated the feasibility of adapting general-purpose\nmodels to healthcare through domain-specific instruction datasets. Despite these advances, few\n3\n"}, {"page": 4, "text": "studies have explored lesion-level classification tasks that explicitly leverage lesion and anatomy\ninformation. Our work addresses this gap by 1) marking candidate lesions with structured tags in\nthe report text and 2) providing LLMs with explicit lesion-anatomy associations during inference.\nThese structured inputs enhance classification and interpretability by ensuring models attend to\nspecific findings within their correct anatomical context.\n2.3. Identification of Incidentalomas in Radiology Reports\nLarge-scale analyses have highlighted the frequency of incidental findings in abdominal and\npelvic CT exams and their downstream clinical implications [2]. Organ-specific investigations have\ncharacterized incidentalomas of the adrenal glands, thyroid, and lungs, providing prevalence es-\ntimates and evidence-based follow-up recommendations [30, 31, 19]. Traditional approaches have\nrelied on structured radiology databases and manual chart reviews, which ensure accuracy but limit\nscalability across large health systems [32, 18].\nEarlier NLP systems established the foundation for automated detection of incidental findings in\nradiology reports. Dutta et al. [33] and Trivedi et al. [34] implemented rule-based and interactive\nNLP frameworks for identifying incidental observations in narrative imaging text, while Kang et\nal. [35] focused on incidental pulmonary nodules. These early studies demonstrated the feasibility\nof text mining for large-scale retrospective identification of incidental findings but were limited by\nhand-engineered features and domain-specific lexicons. Building on these foundations, more recent\nNLP pipelines have leveraged machine learning and transformer-based architectures to automati-\ncally extract incidental findings from unstructured radiology reports [3, 28]. However, most prior\nNLP efforts have emphasized document-level classification of reports containing incidental findings\nrather than fine-grained lesion-level annotation. Closely related to incidentaloma identification,\nrecent studies have advanced the extraction of follow-up imaging recommendations from radiology\nreports using NLP approaches [4, 36, 5].\nSubsequent advances in deep learning enabled more robust classification and extraction pipelines.\nCanton et al. [37] proposed a multi-modal system that combined imaging metadata and report text\nto automatically detect adrenal and thyroid incidentalomas. Schumm et al. [38] automated adrenal\nnodule extraction from electronic health records, and Bala et al. [39] developed a web-based appli-\ncation for incidentaloma tracking and management, illustrating the integration of AI systems into\nclinical follow-up workflows.\nRecent work has highlighted the growing role of LLMs in incidental finding interpretation and\ncommunication. Woo et al. [40] evaluated a HIPAA-compliant instance of GPT-4 [20] for identify-\ning actionable incidental findings and generating patient-facing summaries from radiology reports,\nachieving high factual alignment with expert reviews. Bhayana et al. [41] similarly demonstrated\nthat single-shot prompting with GPT-4 could identify incidental findings across multiple report\ntypes with minimal supervision. Aksu et al. [42] compared ChatGPT [20], Gemini [43], and Claude\n[44] for adrenal incidentaloma management, showing that GPT-based reasoning systems can ap-\nproximate endocrinologist-level decision-making.\nThese developments highlight the potential of\nmultimodal and text-based LLM systems to enhance incidentaloma triage and follow-up workflows.\nOur study extends this line of work by introducing lesion-specific annotations across six anatomies\nand explicitly modeling both incidentaloma presence and follow-up requirements, while exploring\nhow LLM-based prompting can improve lesion-level interpretability and clinical decision support.\n4\n"}, {"page": 5, "text": "Table 1: Lesion identification performance using multiple approaches on annotated radiology reports (Park et al.,\n2024).\nMethod\nOverlap Match\nExact Match\nPrecision\nRecall\nF1-score\nPrecision\nRecall\nF1-score\nPL-Marker ++\n0.880\n0.888\n0.884\n0.740\n0.712\n0.726\nLlama 3.1-8B (0-shot)\n0.377\n0.322\n0.348\n0.014\n0.012\n0.013\nLlama 3.1-8B (1-shot)\n0.449\n0.387\n0.415\n0.064\n0.055\n0.059\nGPT-4o (0-shot)\n0.599\n0.374\n0.460\n0.170\n0.106\n0.131\nGPT-4o (1-shot)\n0.576\n0.489\n0.529\n0.192\n0.163\n0.177\n3. Methods\n3.1. Dataset\n3.1.1. Preprocessing\nWe utilized an existing clinical database comprising 6,668,323 radiology reports from 2007 to\n2020, representing the general patient population across four hospitals within the UW Medicine\nsystem. All reports were automatically de-identified and processed with PL-Marker++, a radiology-\nspecific BERT-based model for lesion-level entity and relation extraction [45, 28]. PL-Marker++\nwas trained on a manually annotated corpus of 609 radiology reports labeled by medical residents\nand board-certified radiologists, achieving inter-annotator agreement F1 = 0.762 and macro-F1 =\n0.88 for lesion finding extraction.\nPL-Marker++ extracts three main categories of information: clinical indications, lesion findings,\nand medical problems, each accompanied by finding-specific arguments such as anatomy and size\ntrend attributes. Clinical indications describe the reason for the imaging study (e.g., “evaluation of\nlung nodule”, “follow-up for prior mass”, or “abdominal pain”) and are automatically categorized into\nfour subtypes: neoplastic diagnosis, non-neoplastic diagnosis, symptom, and trauma. Lesion find-\nings represent mass-forming pathologic structures (e.g., “hepatic lesion”, “adrenal nodule”), whereas\nmedical problems represent non mass-forming pathologic processes. Anatomical and descriptive\nattributes capture details such as size, count, and temporal size trend with five possible values: in-\ncreasing, decreasing, no change, disappeared, and new. Anatomy information associated with each\nlesion, medical problem, and clinical indication is extracted using entity–relation extraction and\nmapped to predefined anatomy categories such as lung, liver, and kidney.\nTable 1 presents token-level lesion identification performance on the annotated dataset described\nby Park et al. [28]. On the test set, PL-Marker++, a BERT-based model trained on annotated\nradiology reports, outperformed n-shot approaches using Llama 3.1-8B and GPT-4o. This is con-\nsistent with recent work [46, 47] showing that LLMs often struggle with token-level clinical named\nentity recognition tasks, likely due to limitations of decoder-based architectures.\nThese structured outputs, particularly the integration of categorized clinical indications and\nlesion-level findings with anatomical and size trend attributes, formed the basis for this study. They\nenabled the identification of reports describing new or potentially actionable lesions and provided\nclinical context to improve LLM inference performance described in the following sections. The\nstudy protocol was reviewed and approved by the University of Washington Institutional Review\nBoard (IRB).\n5\n"}, {"page": 6, "text": "3.1.2. Sampling Process\nThe low prevalence of incidentaloma-containing reports (e.g. 9.9% for adrenal incidentalomas\n[39] and less than 5% for chest computed tomography for incidental pulmonary embolism [48]) and\nthe substantial linguistic variability with which radiologists describe these findings make identifying\nsuch cases challenging. Directly searching for terms such as “incidental” or “incidentaloma” would\nintroduce bias and miss many true incidentalomas, since radiologists often describe them without\nusing these terms. To avoid this limitation, we used a broader sampling strategy that leveraged\nPL-Marker++ outputs and SVM-based recommendation sentence identification, aiming for more\ncomprehensive coverage of incidentaloma cases. After discussions with a board-certified radiologist,\nwe developed a sampling strategy designed to achieve a high positivity rate for reports likely to\ncontain incidentalomas. Although this approach may introduce some sampling bias, it increased\nthe proportion of incidentaloma-positive reports, which was important for constructing a robust\ngold standard. Our sampling strategy applied four sequential filters:\n(1) Target relevant anatomies: Using structured clinical findings extracted with PL-Marker++,\nwe analyzed all radiology reports and identified findings mapped to six anatomical regions:\nkidney, liver, lung, pancreas, adrenal gland, and thyroid. These regions were selected because\nthey are more likely to contain incidentalomas. Among all reports, 24.7 % (n = 1,767,623)\ncontained at least one finding (clinical indication, medical problem, or lesion) from these\nanatomies, yielding 7,519,138 findings. We then selected reports across all imaging modali-\nties that included lesion findings in these regions with assertion values labeled as “present”\nor “possible”. In total, 6.3 % of all reports (n = 112,100) satisfied these criteria and were\nretained.\n(2) Exclude previously identified lesions: Using size trend data, we excluded reports with\nsize trend values of “increasing”, “decreasing”, “disappeared”, or “no change”, which indicate\ncomparison with prior imaging and therefore previously identified lesions. Accordingly, 5.7%\nof reports identified in step (1) were excluded, leaving 105,729 reports.\n(3) Filter surveillance cases: PL-Marker++ was used to extract clinical indication types\n(trauma, symptom, neoplastic diagnosis, and non-neoplastic diagnosis). Reports with a neo-\nplastic diagnosis in the clinical indication were excluded to minimize inclusion of expected\nfindings rather than incidental ones. After this step, 39.6% of reports (n = 41,833) were\nretained.\n(4) Select reports with follow-up recommendations: Among the 41,833 reports retained, we\nfurther selected those containing follow-up recommendation sentences, as incidentalomas are\nfrequently accompanied by such recommendations. Recommendation sentences were identified\nusing a support vector machine (SVM)–based classifier [36]. This step yielded 19,690 reports\nwith the highest probability of containing a clinically important incidentaloma.\nTo ensure accurate anatomical assignment for each lesion and facilitate lesion-level and document-\nlevel analyses, we implemented a double-verification process for anatomy extraction. PL-Marker++\ninitially provided sentence-level lesion–anatomy mappings, but its inference was sometimes limited\nwhen relevant anatomy mentions appeared outside the immediate sentence. To address this, we\nused an additional LLM (Llama 3.1-8B-Instruct) [49] trained to infer anatomical associations from\nfull report context, which achieved a micro-F1 score of 0.895 on the annotated dataset from the\nPL-Marker++ study. Discrepancies between systems were manually reviewed, and a final verified\n6\n"}, {"page": 7, "text": "anatomy label was assigned to each annotated lesion. This dual-level verification ensured robust\nand consistent anatomical categorization across six target anatomies: kidney, liver, lung, pancreas,\nadrenal gland, and thyroid.\n3.1.3. Data Annotation\nOf the 19,690 radiology reports that met the selection criteria, 400 reports were randomly\nselected and annotated.\nAnnotation guidelines were refined through multiple iterations by two\nboard-certified radiologists to ensure both precision and clinical relevance. Rather than relying\nsolely on document-level labels, the guidelines were designed to leverage lesion-level findings. Each\nlesion was annotated as No Incidentaloma, Incidentaloma–No Risk, or Incidentaloma–Follow-up\nRequired, with the distinction based on clinical severity (e.g. “Benign simple cysts” were considered\nas not requiring follow-up). To expedite annotation and minimize missed lesion mentions, lesion\nfindings extracted using PL-Marker++ [28] were pre-annotated in the BRAT annotation tool [50].\nDifferential diagnoses were excluded.\nTwo medical residents participated in the annotation process. Initially, we conducted double-\nannotation training rounds in which both annotators independently labeled the same reports, fol-\nlowed by weekly feedback sessions supervised by a board-certified radiologist. Discrepancies were\nreviewed and resolved through consensus, and remaining disagreements were adjudicated by the\nradiologist who developed the guidelines. Once a document-level inter-annotator agreement (IAA)\nof 0.896 F1 for incidentaloma status was achieved, we transitioned to single-annotation rounds,\nwhere each annotator was assigned distinct reports.\nAs a result, 160 double-annotated reports contained 1,623 pre-identified lesion findings, averag-\ning 10.15 lesions per report. Of these reports, 117 (73.1%) contained at least one incidentaloma,\ndemonstrating an enriched sample. Annotators reached agreement on 1,498 incidentaloma labels,\nresulting in an agreement rate of 92.3% (0.838 F1). Common incidentaloma terms included “lesion”,\n“nodule”, “cyst”, and “mass”. Annotator 1 identified an average of 2.538 incidentalomas per report,\nslightly higher than Annotator 2’s average of 2.294. We then moved to single annotation for the\nremaining reports. The overall dataset distribution at the document level is summarized in Table\n2, while Table 3 presents the anatomy-specific distribution of all annotated lesion findings.\nTable 2: Distribution of annotated reports with and without incidentalomas.\nTotal (n)\nW/ Incidentaloma\nW/O Incidentaloma\nDouble-annotated\n160\n117 (73.1%)\n43 (26.9%)\nSingle-annotated\n240\n158 (65.8%)\n82 (34.2%)\nTotal\n400\n275 (69.25%)\n125 (30.75%)\n3.2. Incidentaloma Classification\nUsing the annotated reports, we defined the incidentaloma classification task to support both\nlesion-level and document-level analyses. Leveraging anatomy information from Section 3.1.2 to-\ngether with the annotated lesion findings, we framed incidentaloma identification as seven anatomy-\nspecific, three-way classifications per report. For each anatomy (Lung, Liver, Kidney, Adrenal,\nPancreas, Thyroid, Other), the model generated one label from {0 = No Incidentaloma, 1 =\nIncidentaloma–No Risk, 2 = Incidentaloma–Follow-up Required}.\n7\n"}, {"page": 8, "text": "Table 3: Number of incidentalomas across six target anatomies in our dataset of 400 radiology reports. A single\nreport may include multiple incidentalomas in different anatomical sites. Percentages in parentheses indicate the\nproportion of low-risk incidentalomas and those requiring follow-up within each anatomy.\nNo Incidentaloma\nIncidentaloma\nNo Risk\nFollow-up Required\nLung\n324\n18 (4.5%)\n58 (14.5%)\nLiver\n302\n78 (19.5%)\n20 (5.0%)\nKidney\n238\n128 (32.0%)\n34 (8.5%)\nAdrenal\n379\n6 (1.5%)\n15 (3.8%)\nPancreas\n384\n5 (1.2%)\n11 (2.8%)\nThyroid\n378\n14 (3.5%)\n8 (2.0%)\nOthers\n341\n25 (6.3%)\n34 (8.5%)\nTotal\n2346\n274\n180\nDuring inference, all models first generated lesion-level predictions for each anatomy and then\naggregated these predictions into a single anatomy-level label using a severity precedence rule.\nFormally, for a given anatomy a with lesion labels {l1, l2, . . . , ln}, the aggregated label La was\ndefined as:\nLa = max{l1, l2, . . . , ln},\nli ∈{0, 1, 2},\nwhere 0 = No Incidentaloma, 1 = Incidentaloma–No Risk, and 2 = Incidentaloma–Follow-up\nRequired. For example, if three lung lesions were labeled {0, 0, 2}, the aggregated anatomy label\nfor lung would be Llung = 2. These class indices (0, 1, and 2) are used throughout the paper to\nrefer to their corresponding labels.\nEach radiology report was represented as a structured vector of seven anatomy-specific inciden-\ntaloma labels:\nR = (Llung, Lliver, Lkidney, Ladrenal, Lpancreas, Lthyroid, Lother),\nLa ∈{0, 1, 2}.\nInter-annotator agreement (IAA) for the document-level annotations, calculated without con-\nsidering anatomy-specific labels, was 0.93 F1 for No Incidentaloma, 0.81 F1 for Incidentaloma–No\nRisk, and 0.70 F1 for Incidentaloma–Follow-up Required, resulting in a macro-average F1 of 0.81.\nThis schema provided consistent, anatomy-specific labeling and served as the foundation for subse-\nquent model training and evaluation. Summary statistics are presented in Table 3.\n3.2.1. Supervised Learning Approach\nWe fine-tuned three transformer-based encoders on the annotated dataset: BioClinicalModern-\nBERT, ModernBERT, and Clinical Longformer. BioClinicalModernBERT [15] is a recent BERT-\nbased model for bioclinical applications pre-trained on large-scale biomedical and clinical corpora,\noptimized for domain-specific terminology and extended context modeling. ModernBERT [14] com-\nbines general-domain and clinical text during pre-training, providing a balanced representation that\nenables comparison with a less domain-specialized encoder. Clinical Longformer [13] uses a sparse\nattention mechanism to efficiently process lengthy radiology reports that often exceed the input\ncapacity of standard BERT-like models. All models were trained according to the classification\ntask described in Section 3.2, to extract lesion-level incidentaloma labels.\n8\n"}, {"page": 9, "text": "Model hyperparameters were tuned on the validation set. We explored learning rates in {1 ×\n10−5, 2 × 10−5, 3 × 10−5, 5 × 10−5}, batch sizes of {8, 16, 32}, and up to 15 training epochs, with\nweight decay {0.01, 0.05} and dropout {0.1, 0.2}. The final configuration, selected according to the\nhighest validation macro-F1 for incidentaloma classes, used a batch size of 16, learning rate 2×10−5,\nlinear warmup over 10% of total steps, weight decay 0.01, and dropout 0.1. The maximum sequence\nlength was 512 tokens for BioClinicalModernBERT and ModernBERT, and 2,048 tokens for Clinical\nLongformer. Models were trained for up to 10 epochs with early stopping (patience = 3), using the\nAdamW optimizer [51], gradient clipping [52] (maximum norm = 1.0), and mixed-precision (FP16)\ntraining on NVIDIA A100 GPUs.\nThe input features comprised a structured textual representation derived from the prepro-\ncessed radiology reports rather than the full report narrative. For each report, we generated seven\nanatomy-specific input strings, one for each anatomy category. Each input took the form Anatomy:\n<organ> | Lesion:\n<lesion description> | Context:\n<neighboring text>, allowing the\nmodel to reason separately about potential incidental findings in each anatomical region. Anatom-\nical information was obtained from the verified anatomy labels generated during preprocessing\n(Section 3.1.1) and inserted directly into the input as plain text. Lesion descriptions were obtained\nfrom the lesion spans identified during the same stage, and a maximum of 100 characters of sur-\nrounding report text were included to capture relevant local context. This window size was selected\nthrough validation-set analysis to balance lesion specificity with contextual information.\nEach sequence was tokenized and padded to the maximum input length supported by the encoder\nmodel, using the model-specific tokenizer. This yielded a unified text representation capturing three\ncomponents, the anatomy of interest, the lesion description, and the immediate local context, while\nensuring consistent formatting across models with different sequence capacities. During inference,\nthe supervised models first generated lesion-level predictions for each anatomy and then aggregated\nthese into final document-level labels, as described in Section 3.2.\nSince the gold standard labels were substantially imbalanced (Table 3), with relatively few\ninstances labeled Incidentaloma–Follow-up Required, we implemented cost-sensitive learning strate-\ngies to enhance performance on underrepresented yet clinically important classes. Three approaches\nwere evaluated. First, class-weighted cross-entropy was applied, assigning weights inversely propor-\ntional to class frequencies. Second, focal loss was employed with γ = 2 and class-specific weighting\nα = wc, emphasizing hard-to-classify and minority examples. Finally, an expected-cost objective\nwas tested using a 3 × 3 asymmetric cost matrix C designed to penalize clinically consequential\nmisclassifications:\nLEC = 1\nN\nN\nX\ni=1\n2\nX\nk=0\nCyi,k pθ(k | xi),\nwhere pθ denotes the softmax output probabilities. At inference time, we also used cost-aware\ndecision making by selecting the label that minimized expected misclassification cost under the\npredicted distribution.\n3.2.2. LLM-based Approach\nSimilar to supervised learning methods, the LLM-based approach first extracts lesion-level in-\ncidentaloma labels and then aggregates these predictions into document-level labels, as described\nin Section 3.2. For LLMs, prior to inference, candidate lesion entity spans in the original report\nwere enclosed with XML-format tags using lesion information extracted by PL-Marker++, while\nthe surrounding text remained intact. Numbered lesion tags support detailed error analysis and\n9\n"}, {"page": 10, "text": "help reduce noise. Without tags, it can be difficult to identify the lesion of interest, particularly\nwhen terms like “nodule” appear in multiple contexts within the same report. By highlighting le-\nsions directly, tags disambiguate such cases, expedite manual review by clinicians, and minimize the\ninfluence of irrelevant or distracting text, which improves interpretability and clinical reliability.\nOur ablation study using the Llama 3.1-8B Instruct model showed that the inclusion of lesion\ntags substantially improved performance compared with untagged inputs. In the 0-shot setting,\ninputs with lesion tags achieved higher macro F1-score than all 0-shot, 1-shot and 5-shot settings\nwithout tags, indicating that structural cues can be more beneficial than additional examples. The\nimprovement was primarily driven by higher precision with comparable recall, suggesting that the\ntags helped models focus on the correct lesion spans. Accordingly, we used lesion-tagged inputs\nthroughout all LLM experiments. Generation was performed with settings intended to minimize\nstochastic variation (temperature = 0, top-p = 1).\nUsing these lesion-tagged radiology reports, we evaluated two prompt settings:\n1. Base Prompt: The lesion-tagged report is passed as-is.\n2. With-anatomy Prompt: The lesion-tagged report is supplemented with a concise map-\nping that pins each tag to previously extracted anatomy information described in 3.1.1; the\nmapping is a single line such as LESION1=Thyroid; LESION2=Pancreas; LESION3=Adrenal;\n.... This pinning removes residual ambiguity about anatomy assignment while keeping all\nevidence in situ.\nAn example of the With-anatomy prompt is shown in Figure 2. Both prompting approaches\nuse the same instruction described in Figure 1 and the same report content, where lesions are\ntagged using numbered XML-format tags. In the With-anatomy approach, additional anatomical\ninformation is included. As illustrated in the LLM reasoning trace in Figure 2, the model correctly\nattends to the target lesions by leveraging the numbered tags during inference.\nWe evaluated four generative LLM-based approaches under identical settings using the two\nprompts described above. The first was a LoRA (Low-Rank Adaptation) [25] fine-tuned Llama\n3.1-8B model, adapted on our annotated radiology reports to generate incidentaloma labels in a\ndomain-specific manner while keeping parameter updates lightweight. The second approach was a\nprompt-engineered version of Llama 3.1-8B, applied in a zero-shot fashion without gradient updates\nand evaluated in both prompt settings. The third approach employed GPT-4o, a proprietary state-\nof-the-art model, to benchmark performance against open-source alternatives. Finally, we evaluated\nGPT-OSS [53], an open-source GPT-style model that has demonstrated competitive performance\nacross multiple public benchmarks. For computational feasibility, we used GPT-OSS-20B rather\nthan GPT-OSS-120B, balancing inference time and resource requirements while maintaining strong\nperformance. All experiments were conducted on our HIPAA-compliant secure server environment.\nFine-tuning GPT-OSS-20B was not feasible because the model relies on generating explicit reasoning\ntraces, which were not available for our clinical dataset. Fine-tuning GPT-4o was not performed to\nmaintain consistency across proprietary models and to ensure a fair comparison within a prompt-\nonly evaluation framework.\n3.3. Evaluation\nThe held-out test set contains 80 double-annotated reports, yielding 560 anatomy-specific labels\nin total (seven anatomies per report). Of these labels, 50 are Incidentaloma–No Risk (1) and 29 are\nIncidentaloma–Follow-up Required (2); the remainder are No Incidentaloma (0). The training set\n10\n"}, {"page": 11, "text": "Prompt for Incidentaloma Identification\nRole: You are a board-certified radiologist.\nTask: Analyze each report to verify incidentaloma status in target anatomies.\nThe list of lesions to consider is provided in the input using <LESION> </LESION> tags.\nExclusions:\nDo not classify a lesion as an incidentaloma if:\n- It is suspected or potential metastasis when the scan indication includes a known\nprimary malignancy.\n- It is found on surveillance scans (e.g., cirrhosis patients undergoing repeated liver\nimaging for HCC\nor patients with known malignancy undergoing routine scans for metastases).\n- It has been previously identified in a prior study.\n- Its size change is mentioned (\"stable\", \"decreased\", \"increased\", \"unchanged\", etc.)\n- Its clinical indication is related to the target lesion\nExample output:\n{\n’Lung Inci’: {},\n’Liver Inci’: {\"LESION2\":1},\n’Kidney Inci’: {},\n’Adrenal Inci’: {},\n’Pancreas Inci’: {},\n’Thyroid Inci’: {\"LESION4\":2},\n’Other Inci’: {}\n}\nEmpty dict: No incidentalomas\nCategory 1: Incidentalomas not requiring follow-up.\nCategory 2: Incidentalomas requiring follow-up.\nProvide brief reasoning (<5 sentences) after JSON output.\nFigure 1: Prompt used for verifying incidentaloma status across target anatomies. Exclusion criteria and examples\nare derived from the annotation guidelines.\n(n = 280) and validation set (n = 40) were used exclusively for prompt refinement in the LLM-based\napproaches and for model optimization in the supervised learning experiments.\nModel performance was primarily evaluated using the F1-score, which balances sensitivity and\nprecision. F1-scores were calculated for all three classes. To better capture performance on clinically\nmeaningful cases, we additionally report an incidentaloma macro-F1, defined as the mean of the F1\nvalues for the two incidentaloma classes (1 and 2). Because the No Incidentaloma class comprised\nthe majority of samples and consistently yielded high performance across models, the incidentaloma\nmacro-F1 offers a more balanced assessment focused on cases where incidentalomas are present.\n11\n"}, {"page": 12, "text": "Figure 2: Example of input and output used for LLM-based incidentaloma identification using GPT-OSS-20B. Lesions\nthat are not returned in the JSON output are treated as No Incidentaloma (Class 0). Reasoning traces are available\nonly in GPT-OSS-20B inferences, as GPT-4o does not provide reasoning trace outputs.\n4. Results\n4.1. Performance Comparison\nAs shown in Table 4, the best overall performance was achieved by the GPT-OSS-20b (With\nAnatomy) model, which obtained the highest F1-scores across all labels and an incidentaloma-\npositive macro-F1 of 0.79. GPT-4o (With Anatomy) was the second-best performer, with F1 scores\nof 0.82 and 0.71 for the incidentaloma-positive classes.\nThese two anatomy-informed methods\nconsistently outperformed all other systems, indicating that explicit anatomy context substantially\nimproves incidentaloma classification.\nAmong supervised encoders, BioClinicalModernBERT (w/o CS) and ModernBERT (CS) both\nreached an incidentaloma macro-F1 of 0.70, with BioClinicalModernBERT performing better for\nClass 1 (0.79 F1) and ModernBERT slightly stronger for Class 2 (0.63 F1). Cost-sensitive (CS)\nlearning produced only modest gains and mainly increased recall for minority classes.\nComparing model families, LLMs showed clear gains over supervised encoders. Only Llama\n3.1-8B was fine-tuned using LoRA; all other LLMs, including GPT-4o and GPT-OSS-20B, were\nevaluated in a prompt-only configuration. GPT-4o (Base) already matched the strongest non-LLM\nbaselines, and adding anatomical context further improved performance, yielding up to a ∆+0.08\nincrease in macro-F1 (classes 1–2) and clearly surpassing all non-LLM methods. The consistent\n12\n"}, {"page": 13, "text": "benefit of anatomy-aware prompting across both Llama and GPT-based architectures highlights the\nvalue of anatomy-aware contextualization of lesion findings in improving incidentaloma detection.\nTable 4: Performance comparison of supervised encoders (with and without cost-sensitive learning (CS)) and LLM-\nbased approaches on incidentaloma classification. F1 values are reported for each class (0: No Incidentaloma, 1:\nIncidentaloma–No Risk, 2: Incidentaloma–Follow-up Required).\nOverall Accuracy and Incidentaloma Macro-F1\n(computed on Class 1 and 2 only) are also reported to show each model’s overall correctness and ability to detect\nand correctly classify incidentaloma-positive cases. Best values for each category are in bold.\nModel\nClass 0\nClass 1\nClass 2\nAccuracy\nIncidentaloma Macro-F1\nInter-annotator Agreement (IAA)\n0.93\n0.81\n0.70\n0.89\n0.76\nSupervised Encoder-based Models\nBioClinicalModernBERT (w/o CS)\n0.99\n0.79\n0.61\n0.95\n0.70\nBioClinicalModernBERT (CS)\n0.99\n0.72\n0.60\n0.95\n0.66\nModernBERT (w/o CS)\n0.99\n0.76\n0.60\n0.95\n0.68\nModernBERT (CS)\n0.99\n0.77\n0.63\n0.95\n0.70\nLarge Language Models\nFine-tuned Llama 3.1-8B\n0.96\n0.62\n0.46\n0.91\n0.54\nLlama 3.1-8B (Base)\n0.89\n0.59\n0.46\n0.81\n0.52\nLlama 3.1-8B (With Anatomy)\n0.90\n0.61\n0.64\n0.82\n0.63\nGPT-4o (Base)\n0.96\n0.76\n0.62\n0.92\n0.69\nGPT-4o (With Anatomy)\n0.97\n0.82\n0.71\n0.94\n0.77\nGPT-OSS-20b (Base)\n0.96\n0.81\n0.71\n0.93\n0.76\nGPT-OSS-20b (With Anatomy)\n0.97\n0.84\n0.73\n0.94\n0.79\n4.2. Pairwise Statistical Significance Testing of Models on Incidentaloma-Positive Lesions\nTo evaluate statistical significance in model performance, we conducted a lesion-level bootstrap\nanalysis restricted to lesions annotated as incidentalomas. This approach quantifies variability at\nthe lesion level and focuses on clinically meaningful cases. Figure 3 summarizes these comparisons,\nwith each horizontal line representing the estimated CI for ∆Macro-F1. Llama-based models were\nexcluded because of their consistently lower performance across all metrics.\nOverall, both GPT-OSS (Base) and GPT-OSS (Anatomy) achieved higher Macro-F1 values than\nthe supervised baselines (ModernBERT, BioclinicalModernBERT). GPT-OSS (Anatomy) provided\nthe best overall performance, with confidence intervals lying entirely above zero when contrasted\nwith all supervised encoders (p < 0.01).\nAll GPT-based models outperformed the supervised\nmethods by a statistically significant margin, underscoring the advantage of LLMs for lesion-level\nclassification.\nConsistent with the previous section, both GPT-OSS and GPT-4o showed significant gains when\nanatomical context was incorporated through anatomy-aware prompting. GPT-4o (Anatomy) sig-\nnificantly outperformed its base version (p = 0.012), and GPT-OSS (Anatomy) also improved over\nGPT-OSS (Base). These results demonstrate that anatomy-aware prompting improves robustness\nand clinical reliability of LLM-based systems for incidentaloma classification and is a generalizable\nstrategy for radiology-specific information extraction.\n4.3. Error Analysis\n4.3.1. Errors in Supervised Models\nWe examined error patterns for BioClinicalModernBERT and ModernBERT, both with and\nwithout cost-sensitive (CS) training, to understand the limitations of supervised encoders. Clinical\n13\n"}, {"page": 14, "text": "Figure 3: Pairwise non-parametric bootstrap comparison of model performance on incidentaloma-positive lesions.\nEach point represents the mean difference in Macro-F1 (A–B) across 1,000 lesion-level bootstrap samples, with hori-\nzontal bars showing 95% confidence intervals. Comparisons to the right of zero indicate that Model A outperformed\nModel B.\nLongformer was excluded from detailed analysis because of its poor recall for follow-up-required\ncases and inconsistent error behavior.\nBioClinicalModernBERT showed the most balanced performance among the supervised models\nbut still underestimated lesion severity, frequently labeling follow-up-required incidentalomas as low-\nrisk. Cost-sensitive training reduced some of these misses but increased false positives for benign\nlesions. ModernBERT showed a similar trend with generally lower recall and precision, often missing\nfollow-up recommendations that appeared only in impression sections or in abbreviated form (e.g.,\n“f/u CT advised”).\nQualitative inspection indicated that both models struggled with hedged phrasing (e.g., “likely\nbenign,” “probably cystic”), complex size descriptions, and multi-lesion narratives mixing benign\nand higher-risk lesions. ModernBERT particularly struggled when follow-up recommendations were\nexpressed indirectly or outside the main lesion description. LIME-based interpretability analyses\n[54] supported these findings, showing that token-level attributions were dominated by explicit\nlesion descriptors and common modifiers (e.g., “subcentimeter,” “stable,” “mass”), while contextual\n14\n"}, {"page": 15, "text": "indicators of clinical intent were underweighted.\n4.3.2. Errors in Generative LLMs\nThe most critical errors involved missed incidentalomas, which represent potentially high-risk\nfindings. GPT-4o (Base) missed 10 of 29 (34.5%) such cases, GPT-4o (Anatomy) reduced this to 7\nof 29 (24.1%), GPT-OSS (Base) to 6 of 29 (20.7%), and GPT-OSS (Anatomy) to 5 of 29 (17.2%).\nThese trends indicate that anatomy-aware prompting improves focus on lesion-specific information\nand reduces clinically important misses.\nFalse positives, where normal lesions were misclassified as incidentalomas (Class 0 →Class\n1 or 2), were uncommon (3–6%).\nAnatomy inclusion slightly reduced these rates for GPT-4o\n(4.8% →3.5%) and GPT-OSS (5.6% →5.4%). None of the models predicted no-risk incidentalomas\nas requiring follow-up. Across all models, a recurring pattern was underestimation of severity, where\nfollow-up-required lesions were misclassified as no-risk (Class 2 →Class 1). GPT-4o showed such\nunderestimation in 13.8% of error cases, while GPT-OSS reduced this to 10.3%. These errors often\nappeared in reports with equivocal language or indirectly expressed follow-up intent. GPT-OSS\n(Anatomy) achieved the best balance, minimizing hazardous misses while keeping false positives\nlow.\nTo further characterize GPT-OSS (Anatomy), we reviewed its 33 errors among 560 evaluated\nlesions. Errors occurred across multiple anatomical sites (lung, liver, kidney, thyroid), indicating\nbroader reasoning challenges rather than anatomy-specific effects. Three dominant mismatch types\nwere identified:\nFollow-Up Required vs. No-Risk (Gold = Class 2 →Model = Class 1, n=3)\nGPT-OSS (Anatomy) correctly identified the lesion but underestimated its clinical significance.\nThese cases involved conditional language such as “tiny sub-6 mm lung nodule, follow-up if high\nrisk” or “indeterminate hypodensity on unenhanced liver CT”, where reassuring phrases were overem-\nphasized and qualifiers related to higher-risk populations or incomplete characterization were un-\nderweighted.\nIncidentaloma Missed (Gold = Class 1 or 2 →Model = Class 0, n = 4)\nFour lesions labeled as incidentalomas were classified as non-incidentalomas because annotators had\noverlooked contextual cues such as “stable” or “compared to prior exam,” indicating prior evaluation.\nThese were annotation errors rather than model failures. GPT-OSS (Anatomy) correctly identi-\nfied all four as non-incidental, suggesting sensitivity to subtle contextual indicators that human\nannotators sometimes miss.\nFalse Incidentaloma Detection (Gold = 0 →Model = 1 or 2, n = 26)\nFalse positives were the largest error category. GPT-OSS (Anatomy) misclassified 26 non-incidental\ncases as incidentalomas, split between no-risk (13) and follow-up-required (13). Most arose from\ndifferences in interpreting the relationship between the clinical indication and the lesion. For ex-\nample, with clinical indication “previous CXR abnormal” and “small opacity in the left lower lung”,\nannotators linked the opacity to the prior abnormal CXR and labeled it non-incidental, whereas the\nmodel treated it as a separate finding requiring follow-up. In another case with indication “restag-\ning”, human annotators considered a lesion in a different anatomical region incidental, while the\nmodel interpreted the context as evidence of existing malignancy and classified it as non-incidental.\nThese examples highlight how divergent interpretations of clinical intent and anatomical context\ncan lead to disagreement between human experts and LLMs.\n15\n"}, {"page": 16, "text": "5. Discussion\n5.1. Ensemble Effects and Majority-Vote Performance\nTwelve lesions were correctly classified by all GPT-based models but misclassified by both\nBERT-based models, whereas the opposite occurred only five times. Most of the GPT-correct and\nBERT-incorrect cases contained nodule management guideline templates that are automatically\ninserted into reports by the radiology information system (RIS) macros (e.g., “follow-up per Fleis-\nchner Society guidelines”). These standardized template insertions often appear without explicit\ncontextual linkage to an active finding, which likely caused confusion for the supervised models\nthat rely heavily on local lexical cues rather than broader semantic context. In contrast, GPT\nmodels demonstrated stronger contextual reasoning, correctly linking each recommendation to its\ncorresponding lesion finding. While these results highlight the contextual adaptability of LLMs,\nthe BERT-based models showed a more conservative bias that often missed positive incidentaloma\ncases but produced fewer false positives, reflecting a precision-oriented decision boundary.\nTo integrate the complementary strengths of different modeling approaches, a simple majority-\nvote ensemble approach was constructed across six strong systems: GPT-4o (Base and Anatomy),\nGPT-OSS (Base and Anatomy), ModernBERT with cost-sensitive (CS) training, and BioClini-\ncalModernBERT without CS. Each lesion’s final label was determined by the most frequent pre-\ndiction across models. In case of ties during majority voting, the lowest numerical label was cho-\nsen (e.g., 0 < 1 < 2), providing a conservative bias toward non-incidentaloma predictions. This\nparameter-free ensemble achieved the highest overall performance, yielding a Macro-F1 of 0.902\nand surpassing all individual models. The resulting lesion-level F1 scores were well balanced across\nall classes (No Incidentaloma = 0.988, No Risk = 0.889, Follow-up Required = 0.830), representing\nconsistent gains over the best individual model, GPT-OSS (With Anatomy), which achieved 0.968,\n0.842, and 0.727 for the same categories, respectively. The ensemble therefore improved each class\nby a notable margin, particularly for identifying incidentalomas requiring follow-up, where the F1\nvalue increased by more than 0.10. This indicates that combining the contextual reasoning of LLMs\nwith the structured precision of supervised encoders may enhance reliability in clinical information\nextraction from radiology reports, particularly in cases involving ambiguous or uncertain phrasing.\nWhile the ensemble achieved clear gains in robustness and overall accuracy, this approach also\nintroduces practical trade-offs. Deploying multiple large-scale models in parallel increases compu-\ntational overhead, inference latency, and system complexity, which may limit real-world scalability.\nFurthermore, ensembling can obscure the interpretability of individual model decisions, complicat-\ning clinical validation and downstream error analysis. Future implementations should therefore\nbalance the benefits of ensemble stability against operational efficiency and transparency, particu-\nlarly when integrating LLM-based systems into clinical workflows.\n5.2. Clinical Implications and Potential Applications\nThe proposed incidentaloma identification approach has several potential applications for clinical\ndecision support (CDS), workflow optimization, and follow-up tracking in radiology practice. It\ncould be integrated at the point of order entry within CDS systems to automatically identify\npatients with a prior incidentaloma and recommend the most appropriate follow-up imaging study.\nWhen incorporated into radiology reporting software, the model could provide real-time guidance\nbased on lesion size, imaging characteristics, and patient demographics, suggesting the most relevant\nclinical practice guideline for follow-up. In addition, the structured lesion-level outputs could be\nused to populate follow-up tracking systems, enabling longitudinal monitoring of incidental findings\n16\n"}, {"page": 17, "text": "and improving adherence to recommended follow-up intervals. Moreover, it forms a foundation for\nevaluation about the downstream clinical and economic impact of imaging incidentalomas in the\nsetting of patient co-morbidities and other lesions.\nOur study also offers opportunities for improved explainability and transparency in clinical AI\nsystems. Lesion-level analyses and LLM-generated explanations could be integrated into interactive\ndashboards, enabling radiologists to visualize model reasoning and validate follow-up recommenda-\ntions. Such interpretability features would enhance clinician trust and support safe integration of\nAI-assisted tools into routine radiology workflows.\nCollectively, these applications illustrate how automated incidentaloma detection can extend\nbeyond research evaluation to support safer, more consistent, and guideline-concordant imaging\ncare.\n5.3. Limitations\nDespite these findings, several limitations warrant consideration. First, the annotated dataset,\nwhile carefully curated and reviewed by radiologists, remains limited in size due to the intensive\nnature of manual lesion-level annotation. This constraint may limit the generalizability of results\nto less common anatomies or atypical phrasing styles.\nSecond, radiology reporting conventions\nand imaging modalities vary widely across institutions, which could reduce the transferability of\nmodel performance to other health systems without additional adaptation or domain-specific tuning.\nThird, the evaluation primarily focused on text-based single-report analysis and did not incorporate\ntemporal context from prior studies or longitudinal patient histories that could refine incidentaloma\ncharacterization and follow-up reasoning.\nIn addition, annotation subjectivity may have introduced minor inconsistencies, particularly in\nborderline cases where incidentaloma status or follow-up need was open to interpretation. While\nannotation review and consensus procedures were employed, subtle differences in annotator judg-\nment could influence ground-truth labels. Furthermore, although model explainability was partially\nexamined through token-level attribution and qualitative inspection, deeper interpretability analy-\nses involving radiology experts are needed to fully understand the decision-making behavior of llms\nin complex radiology narratives.\nFuture work should therefore explore the integration of longitudinal patient data, cross-institutional\nvalidation, and more scalable annotation strategies, alongside improved interpretability frameworks,\nto enhance both the reliability and clinical trustworthiness of AI-assisted incidentaloma detection\nsystems.\n6. Conclusions\nThis study presents a comprehensive evaluation of supervised transformer-based encoders and\ngenerative LLMs for automated identification and classification of incidentalomas in radiology re-\nports. By introducing lesion-tagged inputs and anatomy-aware prompting, we demonstrate that\ngenerative LLMs, particularly GPT-OSS (With Anatomy), achieve substantially stronger and more\nbalanced performance than conventional supervised encoders. These gains were most pronounced\nin incidentaloma-positive cases, where explicit lesion and anatomical context enabled more precise\nreasoning about clinical relevance and follow-up necessity.\nBeyond quantitative performance, this study emphasizes a detailed lesion-level error analysis.\nIncorporating structured lesion cues, such as lesion tags and anatomical information, promoted more\nconsistent lesion-level inference in LLMs, while transformer-based supervised models produced fewer\n17\n"}, {"page": 18, "text": "false positives, reflecting a precision-oriented bias. Ensemble analysis further demonstrated that\ncombining generative and encoder-based systems through majority voting stabilized predictions\nacross clinically meaningful categories.\nAlthough this work was conducted on data from a single institution and limited to individual\nreports without longitudinal context, the results provide clear evidence that structured lesion con-\ntext and anatomical grounding are key to reliable and transparent LLM-based clinical reasoning in\nradiology. Future research should extend these findings through multi-institutional validation, tem-\nporal modeling, and incorporation of human-in-the-loop frameworks to ensure clinical robustness\nand generalizability.\nOverall, this work advances the development of clinically aligned, anatomy-aware LLM frame-\nworks for radiology report understanding, bridging the gap between automated text classification\nand clinical decision support in real-world radiology workflows.\nAcknowledgments\nThis work was supported in part by the National Institutes of Health and the National Cancer\nInstitute (NCI) (Grant Nr. 1R01CA248422-01A1)). The content is solely the responsibility of the\nauthors and does not necessarily represent the official views of the National Institutes of Health.\nReferences\n[1] Berland LL, Silverman SG, Gore RM, Mayo-Smith WW, Megibow AJ, Yee J, et al. Man-\naging Incidental Findings on Abdominal CT: White Paper of the ACR Incidental Findings\nCommittee. Journal of the American College of Radiology. 2010;7(10):754-73.\n[2] Lumbreras B, Donat L, Hernández-Aguado I. Incidental Findings in Imaging Diagnostic Tests:\nA Systematic Review. The British Journal of Radiology. 2010;83(988):276-89.\n[3] Cai T, Giannopoulos AA, Yu S, Kelil T, Ripley B, Kumamaru KK, et al. Natural Language\nProcessing Technologies in Radiology Research and Clinical Applications.\nRadioGraphics.\n2016;36(3):738-53.\n[4] Mabotuwana T, Hall CS, Tieder J, Gunn ML. Improving Quality of Follow-Up Imaging Rec-\nommendations in Radiology. In: AMIA Annual Symposium Proceedings. vol. 2017; 2018. p.\n1196-204.\n[5] Dalal S, Hombal V, Weng WH, Mankovich G, Mabotuwana T, Hall CS, et al.\nDetermin-\ning Follow-Up Imaging Study Using Radiology Reports.\nJournal of Digital Imaging. 2020\nFeb;33(1):121-30.\n[6] Alsentzer E, Murphy J, Boag W, Weng WH, Jindi D, Naumann T, et al. Publicly Available\nClinical BERT Embeddings. In: Proceedings of the 2nd Clinical Natural Language Processing\nWorkshop. Minneapolis, Minnesota, USA: ACL; 2019. p. 72-8.\n[7] Huang K, Altosaar J, Ranganath R. ClinicalBERT: Modeling Clinical Notes and Predicting\nHospital Readmission. arXiv Preprint arXiv:190405342. 2019.\n[8] Nori H, King N, McKinney SM, Carignan D, Horvitz E. Capabilities of GPT-4 on Medical\nChallenge Problems. arXiv Preprint arXiv:230313375. 2023.\n18\n"}, {"page": 19, "text": "[9] Singhal K, Azizi S, Tu T, Mahdavi SS, Wei J, Chung HW, et al. Large Language Models\nEncode Clinical Knowledge. Nature. 2023;620(7972):172-80.\n[10] Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, et al. Attention is All\nYou Need. Advances in Neural Information Processing Systems. 2017;30.\n[11] Johnson AE, Pollard TJ, Shen L, Lehman LwH, Feng M, Ghassemi M, et al. MIMIC-III, A\nFreely Accessible Critical Care Database. Sci Data. 2016;3(1):1-9.\n[12] Peng Y, Yan S, Lu Z. Transfer Learning in Biomedical Natural Language Processing: An\nEvaluation of BERT and ELMo on Ten Benchmarking Datasets. In: Proceedings of the 18th\nBioNLP Workshop and Shared Task; 2019. p. 58-65.\n[13] Li Y, Wehbe RM, Ahmad FS, Wang H, Luo Y. Clinical-Longformer and Clinical-BigBird:\nTransformers for Long Clinical Sequences. arXiv Preprint arXiv:220111838. 2022.\n[14] Warner B, Chaffin A, Clavié B, Weller O, Hallström O, Taghadouini S, et al. Smarter, Better,\nFaster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context\nFinetuning and Inference. arXiv Preprint arXiv:241213663. 2024.\n[15] Sounack T, Davis J, Durieux B, Chaffin A, Pollard TJ, Lehman E, et al. BioClinical Mod-\nernBERT: A State-of-the-Art Long-Context Encoder for Biomedical and Clinical NLP. arXiv\nPreprint arXiv:250610896. 2025.\n[16] Irvin J, Rajpurkar P, Ko M, Yu Y, Ciurea-Ilcus S, Chute C, et al. Chexpert: A large chest\nradiograph dataset with uncertainty labels and expert comparison. In: Proceedings of the\nAAAI conference on artificial intelligence. vol. 33; 2019. p. 590-7.\n[17] Gerevini AE, Lavelli A, Maffi A, Maroldi R, Minard AL, Serina I, et al. Automatic Classification\nof Radiological Reports for Clinical Care. Artificial Intelligence in Medicine. 2018;91:72-81.\n[18] Welch HG, Black WC. Overdiagnosis in Cancer. Journal of the National Cancer Institute.\n2010;102(9):605-13.\n[19] MacMahon H, Naidich DP, Goo JM, Lee KS, Leung AN, Mayo JR, et al.\nGuidelines for\nManagement of Incidental Pulmonary Nodules Detected on CT Images: From the Fleischner\nSociety 2017. Radiology. 2017;284(1):228-43.\n[20] Achiam, et al. GPT-4 Technical Report. arXiv Preprint arXiv:230308774. 2023.\n[21] Hurst A, Lerer A, Goucher AP, Perelman A, Ramesh A, Clark A, et al. GPT-4o System Card.\narXiv Preprint arXiv:241021276. 2024.\n[22] Park N, Ramachandran GK, Lybarger K, Xia F, Uzuner O, Yetisgen M, et al. Identifying\nImaging Follow-Up in Radiology Reports: A Comparative Analysis of Traditional ML and\nLLM Approaches. arXiv preprint arXiv:251111867. 2025.\n[23] Chowdhery A, Narang S, Devlin J, Bosma M, Mishra G, Roberts A, et al. Palm: Scaling\nLanguage Modeling with Pathways. Journal of Machine Learning Research. 2023;24(240):1-\n113.\n19\n"}, {"page": 20, "text": "[24] Touvron H, Lavril T, Izacard G, Martinet X, Lachaux MA, Lacroix T, et al. Llama: Open\nand efficient foundation language models. arXiv preprint arXiv:230213971. 2023.\n[25] Hu EJ, Shen Y, Wallis P, Allen-Zhu Z, Li Y, Wang S, et al. LoRA: Low-Rank Adaptation of\nLarge Language Models. ICLR. 2022;1(2):3.\n[26] Liu Z, Li Y, Shu P, Zhong A, Jiang H, Pan Y, et al. Radiology-GPT: A Large Language Model\nfor Radiology. Meta-Radiology. 2025:100153.\n[27] Wang G, Yang G, Du Z, Fan L, Li X. ClinicalGPT: large language models finetuned with\ndiverse medical data and comprehensive evaluation. arXiv preprint arXiv:230609968. 2023.\n[28] Park N, Lybarger K, Ramachandran GK, Lewis S, Damani A, Uzuner O, et al. A novel corpus\nof annotated medical imaging reports and information extraction results using BERT-based\nlanguage models. In: Proceedings of the 2024 Joint International Conference on Computational\nLinguistics, Language Resources and Evaluation (LREC-COLING 2024); 2024. p. 1280-92.\n[29] Han T, Adams LC, Papaioannou JM, Grundmann P, Oberhauser T, Löser A, et al. MedAl-\npaca—An Open-Source Collection of Medical Conversational AI Models and Training Data.\narXiv Preprint arXiv:230408247. 2023.\n[30] Maher DI, Williams E, Grodski S, Serpell JW, Lee JC. Adrenal Incidentaloma Follow-Up\nis Influenced by Patient, Radiologic, and Medical Provider Factors: A Review of 804 Cases.\nSurgery. 2018;164(6):1360-5.\n[31] Song Z, Wu C, Kasmirski J, Gillis A, Fazendin J, Lindeman B, et al. Incidental Thyroid Nodules\non Computed Tomography: A Systematic Review and Meta-Analysis Examining Prevalence,\nFollow-Up, and Risk of Malignancy. Thyroid. 2024;34(11):1389-400.\n[32] Reiner BI. Radiology Reporting Past, Present, and Future: The Radiologist’s Perspective.\nJournal of the American College of Radiology. 2007;4(5):313-9.\n[33] Dutta S, Long WJ, Brown DF, Reisner AT. Automated Detection Using Natural Language\nProcessing of Radiologists Recommendations for Additional Imaging of Incidental Findings.\nAnnals of Emergency Medicine. 2013;62(2):162-9.\n[34] Trivedi G, Dadashzadeh ER, Handzel RM, Chapman WW, Visweswaran S, Hochheiser H. In-\nteractive NLP in Clinical Care: Identifying Incidental Findings in Radiology Reports. Applied\nClinical Informatics. 2019;10(04):655-69.\n[35] Kang SK, Garry K, Chung R, Moore WH, Iturrate E, Swartz JL, et al. Natural Language\nProcessing for Identification of Incidental Pulmonary Nodules in Radiology Reports. Journal\nof the American College of Radiology. 2019;16(11):1587-94.\n[36] Lau W, Payne TH, Uzuner O, Yetisgen M. Extraction and Analysis of Clinically Important\nFollow-Up Recommendations in a Large Radiology Dataset. AMIA Summits on Translational\nScience Proceedings. 2020;2020:335.\n[37] Canton SP, Dadashzadeh E, Yip L, Forsythe R, Handzel R. Automatic Detection of Thyroid\nand Adrenal Incidentals Using Radiology Reports and Deep Learning. Journal of Surgical\nResearch. 2021;266:192-200.\n20\n"}, {"page": 21, "text": "[38] Schumm M, Hu MY, Sant V, Kim J, Tseng CH, Sanz J, et al.\nAutomated Extraction of\nIncidental Adrenal Nodules from Electronic Health Records. Surgery. 2023;173(1):52-8.\n[39] Bala W, Steinkamp J, Feeney T, Gupta A, Sharma A, Kantrowitz J, et al. A web application\nfor adrenal incidentaloma identification, tracking, and management using machine learning.\nApplied Clinical Informatics. 2020;11(04):606-16.\n[40] Woo KmC, Simon GW, Akindutire O, Aphinyanaphongs Y, Austrian JS, Kim JG, et al.\nEvaluation of GPT-4 Ability to Identify and Generate Patient Instructions for Actionable\nIncidental Radiology Findings.\nJournal of the American Medical Informatics Association.\n2024;31(9):1983-93.\n[41] Bhayana R, Elias G, Datta D, Bhambra N, Deng Y, Krishna S. Use of GPT-4 with Single-\nShot Learning to Identify Incidental Findings in Radiology Reports.\nAmerican Journal of\nRoentgenology. 2024;222(2):e2330651.\n[42] Baş Aksu Ö, Aydın RF, Gökçay Canpolat A, Demir Ö, Şahin M, Emral R, et al.\nArtifi-\ncial intelligence in endocrine practice: comparing ChatGPT, Gemini, and Claude for adrenal\nincidentaloma care. Journal of Endocrinological Investigation. 2025:1-11.\n[43] Team G, Anil R, Borgeaud S, Alayrac JB, Yu J, Soricut R, et al. Gemini: a family of highly\ncapable multimodal models. arXiv preprint arXiv:231211805. 2023.\n[44] Anthropic. Claude; 2024. Accessed: 08/2025. Available from: https://www.anthropic.com/\nclaude/sonnet.\n[45] Lee K, Dobbins NJ, McInnes B, Yetisgen M, Uzuner Ö. Transferability of Neural Network\nClinical Deidentification Systems. Journal of the American Medical Informatics Association.\n2021 09;28(12):2661-9. Available from: https://doi.org/10.1093/jamia/ocab207.\n[46] Hu Y, Chen Q, Du J, Peng X, Keloth VK, Zuo X, et al. Improving Large Language Models for\nClinical Named Entity Recognition via Prompt Engineering. Journal of the American Medical\nInformatics Association. 2024;31(9):1812-20.\n[47] Lu Q, Li R, Wen A, Wang J, Wang L, Liu H. Large Language Models Struggle in Token-Level\nClinical Named Entity Recognition. In: AMIA Annual Symposium Proceedings. vol. 2024;\n2025. p. 748.\n[48] O’Sullivan JW, Muntinga T, Grigg S, Ioannidis JP. Prevalence and Outcomes of Incidental\nImaging Findings: Umbrella Review. BMJ. 2018;361.\n[49] Grattafiori A, Dubey A, Jauhri A, Pandey A, Kadian A, Al-Dahle A, et al. The Llama 3 Herd\nof Models. arXiv Preprint arXiv:240721783. 2024.\n[50] Stenetorp P, Pyysalo S, Topić G, et al. BRAT: A Web-Based Tool for NLP-Assisted Text\nAnnotation. In: Proceedings of the Demonstrations at the Conference of the European Chapter\nof the Association for Computational Linguistics. Avignon, France; 2012. p. 102-7. Available\nfrom: https://aclanthology.org/E12-2021.\n[51] Loshchilov I, Hutter F.\nDecoupled Weight Decay Regularization.\narXiv Preprint\narXiv:171105101. 2017.\n21\n"}, {"page": 22, "text": "[52] Zhang J, He T, Sra S, Jadbabaie A. Why Gradient Clipping Accelerates Training: A Theoret-\nical Justification for Adaptivity. arXiv Preprint arXiv:190511881. 2019.\n[53] Agarwal S, Ahmad L, Ai J, Altman S, Applebaum A, Arbus E, et al. gpt-oss-120b & gpt-oss-\n20b model card. arXiv Preprint arXiv:250810925. 2025.\n[54] Ribeiro MT, Singh S, Guestrin C. \" Why should i trust you?\" Explaining the predictions of any\nclassifier. In: Proceedings of the 22nd ACM SIGKDD international conference on knowledge\ndiscovery and data mining; 2016. p. 1135-44.\n22\n"}]}