{"doc_id": "arxiv:2602.06449", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2602.06449.pdf", "meta": {"doc_id": "arxiv:2602.06449", "source": "arxiv", "arxiv_id": "2602.06449", "title": "Evaluating an evidence-guided reinforcement learning framework in aligning light-parameter large language models with decision-making cognition in psychiatric clinical reasoning", "authors": ["Xinxin Lin", "Guangxin Dai", "Yi Zhong", "Xiang Li", "Xue Xiao", "Yixin Zhang", "Zhengdong Wu", "Yongbo Zheng", "Runchuan Zhu", "Ming Zhao", "Huizi Yu", "Shuo Wu", "Jun Zhao", "Lingming Hu", "Yumei Wang", "Ping Yin", "Joey W. Y. Chan", "Ngan Yin Chan", "Sijing Chen", "Yun Kwok Wing", "Lin Lu", "Xin Ma", "Lizhou Fan"], "published": "2026-02-06T07:21:08Z", "updated": "2026-02-06T07:21:08Z", "summary": "Large language models (LLMs) hold transformative potential for medical decision support yet their application in psychiatry remains constrained by hallucinations and superficial reasoning. This limitation is particularly acute in light-parameter LLMs which are essential for privacy-preserving and efficient clinical deployment. Existing training paradigms prioritize linguistic fluency over structured clinical logic and result in a fundamental misalignment with professional diagnostic cognition. Here we introduce ClinMPO, a reinforcement learning framework designed to align the internal reasoning of LLMs with professional psychiatric practice. The framework employs a specialized reward model trained independently on a dataset derived from 4,474 psychiatry journal articles and structured according to evidence-based medicine principles. We evaluated ClinMPO on a unseen subset of the benchmark designed to isolate reasoning capabilities from rote memorization. This test set comprises items where leading large-parameter LLMs consistently fail. We compared the ClinMPO-aligned light LLM performance against a cohort of 300 medical students. The ClinMPO-tuned Qwen3-8B model achieved a diagnostic accuracy of 31.4% and surpassed the human benchmark of 30.8% on these complex cases. These results demonstrate that medical evidence-guided optimization enables light-parameter LLMs to master complex reasoning tasks. Our findings suggest that explicit cognitive alignment offers a scalable pathway to reliable and safe psychiatric decision support.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2602.06449v1", "url_pdf": "https://arxiv.org/pdf/2602.06449.pdf", "meta_path": "data/raw/arxiv/meta/2602.06449.json", "sha256": "7818b624a8a95598b98c8202eeaf8ecdf9150d5cfae6b16f8ca6958987e0ba1b", "status": "ok", "fetched_at": "2026-02-18T02:19:34.482084+00:00"}, "pages": [{"page": 1, "text": "Evaluating an evidence-guided reinforcement\nlearning framework in aligning light-parameter\nlarge language models with decision-making\ncognition in psychiatric clinical reasoning\nXinxin Lin1,∗, Guangxin Dai2,∗, Yi Zhong3,∗, Xiang Li2, Xue Xiao4, Yixin Zhang5,\nZhengdong Wu1, Yongbo Zheng6, Runchuan Zhu1,†, Ming Zhao1,7,†, Huizi Yu1, Shuo\nWu2, Jun Zhao2, Lingming Hu6, Yumei Wang6, Ping Yin8, Joey W.Y. Chan1, Ngan\nYin Chan1, Sijing Chen1, Yun Kwok Wing1, Lin Lu3,9,#, Xin Ma2,#, Lizhou Fan1,#\n1The Chinese University of Hong Kong, Shatin, N.T., Hong Kong SAR, China,\n2Shandong University, Jinan, China,\n3Peking University Sixth Hospital, Beijing, China,\n4Inspur Cloud Information Technology Co., Ltd., Jinan, China,\n5Fudan University, Shanghai, China,\n6Shandong Provincial Hospital Afﬁliated to Shandong First Medical University, Jinan, China,\n7Jilin University, Changchun, China,\n8Hong Kong ICI Cloud Service Limited, Hong Kong SAR, China,\n9Shandong First Medical University, Jinan, China\n∗These authors contributed equally to this work.\n†This work is done during an internship at The Chinese University of Hong Kong\n#Corresponding authors: Lizhou Fan (leofan@cuhk.edu.hk), Xin Ma (maxin@sdu.edu.cn), Lin Lu (linlu@bjmu.edu.cn)\nABSTRACT\nLarge language models (LLMs) hold transformative potential for medical decision support yet their application in psychiatry\nremains constrained by hallucinations and superﬁcial reasoning. This limitation is particularly acute in light-parameter\nLLMs which are essential for privacy-preserving and eﬃcient clinical deployment. Existing training paradigms prioritize\nlinguistic ﬂuency over structured clinical logic and result in a fundamental misalignment with professional diagnostic\ncognition. Here we introduce ClinMPO, a reinforcement learning framework designed to align the internal reasoning of\nLLMs with professional psychiatric practice. The framework employs a specialized reward model trained independently on a\ndataset derived from 4,474 psychiatry journal articles and structured according to evidence-based medicine principles. We\nevaluated ClinMPO on a unseen subset of the benchmark designed to isolate reasoning capabilities from rote memorization.\nThis test set comprises items where leading large-parameter LLMs consistently fail. We compared the ClinMPO-aligned\nlight LLM performance against a cohort of 300 medical students. The ClinMPO-tuned Qwen3-8B model achieved a\ndiagnostic accuracy of 31.4% and surpassed the human benchmark of 30.8% on these complex cases. These results\ndemonstrate that medical evidence-guided optimization enables light-parameter LLMs to master complex reasoning tasks.\nOur ﬁndings suggest that explicit cognitive alignment oﬀers a scalable pathway to reliable and safe psychiatric decision\nsupport.\n1 Introduction\nLarge language models (LLMs) oﬀer signiﬁcant potential for medical decision support and have attracted\nincreasing interest in psychiatry research1–5. Yet their deployment in clinical settings is restricted by the risk\nof hallucinations and the lack of a reasoning paradigm that aligns with clinical thought6–8. This limitation\ncompromises reliability and patient safety9–13. Recent evaluations indicate that high benchmark scores do\nnot guarantee safe performance in autonomous roles14–16. This disconnect is particularly acute in psychiatry\nbecause clinical practice requires the integration of diverse evidence and longitudinal context7,17–20. Current\narXiv:2602.06449v1  [cs.CL]  6 Feb 2026\n"}, {"page": 2, "text": "Figure 1. Overview of the ClinMPO framework. a Data construction pipeline for Public Dataset and\nEvidence Dataset. b Illustration of the ClinMPO algorithm. Candidate responses are scored by a reward\nmodel (ClinM) trained on the Evidence dataset to mimic psychiatrist ratings. Group-based reward and\nadvantage calculations are then used to optimize the policy. c Model performance is evaluated using a\ntwo-level clinical classiﬁcation scheme and compared with human performance, using outputs from multiple\nmodels and medical students on a held-out test set.\n2/21\n"}, {"page": 3, "text": "training paradigms fail to reproduce the evidence-based reasoning essential to medicine21–23.\nPractical clinical applications often necessitate smaller and locally hosted models due to privacy and\ncomputational constraints. These systems oﬀer security beneﬁts but typically struggle with the multi-step\nreasoning and error detection required for psychiatric care. Such deﬁcits impair diagnostic accuracy and risk\nassessment. Enhancing the reasoning capabilities of compact models is therefore critical for the delivery of\nreliable AI-augmented mental health services24,25.\nSpecialized systems have attempted to address these gaps by tailoring training pipelines to psychiatry.\nApproaches such as Psyche-R1 and MentraSuite employ hybrid supervised ﬁne-tuning (SFT) and reinforce-\nment learning (RL) to improve performance26,27. However, these methods often focus on correcting factual\nerrors rather than improving the reasoning process itself. Other frameworks prioritize general mental-state\ninference over structured clinical workﬂows like diﬀerential diagnosis28. Moreover, existing reward signals\nfrequently optimize for linguistic ﬂuency rather than clinical logic14,15,29. This can result in models that\ngenerate plausible but analytically ﬂawed outputs7,25.\nHere we present ClinMPO. This is a reinforcement learning framework designed to align light LLMs\nwith professional psychiatric cognition. We introduce an independent reward model called ClinRM. This\nmodel guides policy optimization using a proprietary Evidence Dataset. The dataset contains 18,569 entries\nderived from 4,474 psychiatry journal articles. We structure the data according to the Oxford Centre for\nEvidence-Based Medicine hierarchy. Expert review of a data subset allows the reward model to approximate\nclinician-level evaluation. ClinMPO explicitly rewards evidence-based logic and penalizes incoherent chains\nof thought.\nWe conducted our evaluation within a rigorous scenario-based framework14–16,24.\nWe constructed a\nbenchmark of 8,849 questions from publicly available medical datasets.\nWe identiﬁed a hard subset of\nitems where most large models fail. This approach minimizes memorization and emphasizes reasoning under\nuncertainty. We annotated items with ICD-11 diagnostic categories and Psychiatric Practice Competencies\nto enable ﬁne-grained performance analysis.\nWe applied ClinMPO to a series of light LLMs and compared its eﬃcacy against established baselines.\nWe also administered the test set to 300 psychiatry students. This comparison allows us to benchmark\nmodel performance against human trainees. Our results show that ClinMPO enhances psychiatric reasoning\nin light LLMs and reduces the gap between model and human performance. These ﬁndings highlight the\nimportance of aligning LLMs with clinical reasoning processes for eﬀective application in psychiatry.\n2 Results\n2.1 ClinMPO aligns model reasoning with clinical evidence\nThe ClinMPO framework functions as a cohesive system that integrates three distinct yet synergistic modules\nto align light-parameter models with professional clinical standards. Figure 1 illustrates this architecture.\nThe system comprises a policy model responsible for response generation, a clinically grounded reward model\nfor rigorous evaluation, and a multi-group policy optimization module that drives iterative reﬁnement. This\nmodular design explicitly prioritizes scientiﬁc validity and diagnostic soundness over mere linguistic ﬂuency\nor surface-level probability.\nThe process initiates with the policy model. We initialize this component using supervised ﬁne-tuning\n(SFT) on a curated dataset of psychiatry-relevant materials. The model generates multiple diverse reasoning\ntrajectories for any given clinical query. These candidate responses serve as the input for the clinical reward\nmodel (ClinRM). We train ClinRM independently using a high-quality, proprietary Evidence Dataset. This\ndataset contains 18,569 entries derived from 4,474 psychiatry journal articles and is rigorously structured\naccording to the hierarchy of the Oxford Centre for Evidence-Based Medicine. ClinRM evaluates each set of\ngenerated responses by assigning higher scalar scores to reasoning chains that demonstrate scientiﬁc sound-\nness and semantic coherence. It speciﬁcally rewards the appropriate integration of symptoms, longitudinal\ndisease course, and complex contextual factors. Conversely, the model imposes penalties on critical errors\nsuch as symptom misidentiﬁcation, incorrect pathogenesis, ﬂawed diﬀerential diagnosis, and inappropriate\ntreatment planning.\nThe multi-group policy optimization module processes these reward signals to update the model.\nIt\ncomputes the relative advantages among candidates within each response group rather than relying on\nabsolute reward values.\nThis relative optimization approach updates the policy to preferentially select\n3/21\n"}, {"page": 4, "text": "Figure 2. Performance of medical students, base models, and ﬁnetuned models trained with\ndiﬀerent pipelines on test set, stratiﬁed by Two-tiered Clinical Categorization. Dots in diﬀerent\ncolors represent the accuracy of diﬀerent models for each category, while the red diamond denotes the\naccuracy of human medical students on the corresponding category set. a Results stratiﬁed by the ICD11\ndiagnostic taxonomy, b Results stratiﬁed by psychiatric practice competencies.\ntrajectories with higher comparative clinical quality. Consequently, the system encourages the emergence of\nreasoning patterns that mirror expert psychiatric judgment while it simultaneously suppresses optimization\ntoward verbosity, stylistic imitation, or shortcut strategies. Through repeated cycles of generation, evaluation,\nand optimization, ClinMPO progressively reshapes the internal decision-making pathways of the policy model.\nThis alignment enables the model to navigate realistic and high-stakes psychiatric scenarios with greater\nﬁdelity. These components collectively demonstrate how a clinically informed optimization paradigm steers\nlight LLMs toward reliable and evidence-based psychiatric reasoning.\n2.2 Models reach parity with medical student benchmarks\nWe benchmark the performance of ClinMPO against a reference cohort of 300 medical students to contextual-\nize model capabilities within human expert trajectories. The data indicates that our framework substantially\nreduces the performance gap between LLMs and human trainees. Notably, the framework reverses this gap\nin the largest model scale tested. As Figure 3b displays, the Qwen3-8B-ClinMPO model achieves an overall\naccuracy of 31.43%. This ﬁgure exceeds the human reference performance of 30.84%. It represents a 3.17\npercentage-point absolute gain over the corresponding base model (28.27%) and a 0.74 percentage-point\n4/21\n"}, {"page": 5, "text": "Figure 3. Model accuracy and reasoning transition analysis across scales. a Net reasoning\ntransitions (false-to-true minus true-to-false, FT - TF) for each model scale and training strategy. b\nHuman(medical students) performance and Overall diagnostic accuracy of Qwen3 models at four\nparameter scales (0.6B, 1.7B, 4B, and 8B) under Base, SFT, GRPO, and ClinMPO training strategies.\nadvantage over the strongest non-ClinMPO baseline (GRPO at 30.80%).\nThis convergence toward human-level performance extends beyond aggregate accuracy metrics and per-\nmeates speciﬁc clinical domains. We analyze performance across 26 ICD-11 psychiatric diagnostic groups\nas shown in Figure 2a. ClinMPO-tuned models achieve leading performance in the majority of clinically\ncentral domains. In the category of \"Mental, behavioural or neurodevelopmental disorders,\" the 4B scale\nmodel achieves 50.00% accuracy. This substantially exceeds the human benchmark of 27.27%. We observe\nsimilar trends in \"Impulse control disorders.\" Here the top ClinMPO model reaches 50.00% and more than\ndoubles the human performance of 20.90%. In the category of \"Factitious disorders,\" the best ClinMPO\nmodel matches the top GRPO model at 57.14%. This score substantially surpasses the human score of\n25.74%.\nWe observe particularly pronounced gains in the domain of Psychiatric Practice Competencies (Figure 2b).\nIn the category of \"Monitoring, Follow-up & Measurement-Based Care,\" ClinMPO achieves its highest accu-\nracy of 42.86% at the 8B scale. This surpasses the human benchmark of 30.38% as well as both SFT and\nGRPO baselines. Similarly, in the category of \"Comorbidity & Complexity Management,\" ClinMPO reaches\n44.74% at the 8B scale. This exceeds the human performance of 27.24% and outperforms both GRPO and\nSFT models. These domains typically challenge rule-based approaches due to the need for nuanced judgment.\nThe results highlight the ability of ClinMPO to approximate and essentially exceed clinician-level diagnostic\njudgment rather than relying on shallow recognition cues or memorization.\n2.3 Optimization corrects reasoning in light-parameter models\nClinMPO yields consistent and scalable improvements in reasoning accuracy across all evaluated model sizes\n(Figure 3a). Relative to base models, the framework improves overall accuracy by 0.23% at the 0.6B scale,\n1.84% at 1.7B, 5.64% at 4B, and 3.17% at 8B. When we average across all scales, ClinMPO produces a\nmean absolute improvement of 2.72 percentage points. This exceeds the gains observed with both SFT (1.64\npoints) and GRPO (1.80 points). These statistics suggest that the beneﬁts of evidence-guided reinforcement\nlearning scale eﬀectively even with limited parameter counts.\nWe analyze error transitions to distinguish genuine reasoning improvements from random variability or\nlucky guesses. We examine the net changes in \"false-to-true\" versus \"true-to-false\" transitions between the\n5/21\n"}, {"page": 6, "text": "Figure 4. Overall accuracy distribution across the Two-tiered Clinical Categorization. This\nchart compares the distribution of human(medicine students) accuracy (in red) against the performance of\nmodels trained under diﬀerent paradigms (shown in other colors).\nbase and post-trained models. ClinMPO produces the largest net improvements across all non-trivial model\nsizes. Speciﬁcally, we observe net gains of +32 for the 1.7B model, +98 for the 4B model, and +55 for the\n8B model. In contrast, GRPO achieves smaller net gains while SFT shows negative or modest net changes at\nsmaller scales. At the 4B scale, ClinMPO corrects 22.6% of previously incorrect predictions. This compares\nfavorably with 21.4% under GRPO and 13.9% under SFT. This data conﬁrms that the framework actively\nrepairs ﬂawed reasoning chains.\nThe reasoning gains of ClinMPO are further evident in clinically oriented competencies (Figure 3b).\nThe framework achieves top model performance and closely approaches human benchmarks in complex\ndomains that require synthesis of multiple data points.\nIn tasks requiring multi-step causal reasoning,\nsuch as \"Comorbidity & Complexity Management,\" ClinMPO peaks at 44.74% with the 8B model. This\nsubstantially outperforms the human benchmark of 27.24%. Furthermore, in the category of \"Symptom\nElicitation & Mental Status Examination,\" ClinMPO reaches 42.31% at the 8B scale. This score far surpasses\nthe human score of 26.91%.\nThese ﬁndings demonstrate that ClinMPO improves reasoning depth and\ndiagnostic accuracy in clinically nuanced tasks rather than merely enforcing stylistic compliance or output\nformatting.\n2.4 ClinMPO improves robustness across psychiatry diagnostic domains\nWe examine the distributional patterns of model performance to assess robustness and consistency (Figure 4).\nThis analysis includes 38 heterogeneous categories comprising 12 psychiatric practice competencies and 26\nICD-11 diagnostic groups. The visualization allows for a direct comparison of central tendency, dispersion,\nand tail behavior across diﬀerent training paradigms.\nClinMPO consistently exhibits higher medians and upper quartiles across all model scales compared to the\nbase, SFT, and GRPO variants. It also maintains comparatively compact interquartile ranges. At the 4B and\n8B scales, ClinMPO shows a clear upward shift in median accuracy relative to SFT and GRPO. The 4B model\nreaches a median of 30.59% and the 8B model reaches 31.98%. This shift accompanies a concentration of\ndata points around the central range. In contrast, SFT and GRPO display wider distributions and elongated\nlower whiskers. This indicates substantial variability and a higher incidence of low-performing categories\nwhere the models fail to generalize.\nThe distributional stability of ClinMPO improves monotonically with scale. We observe a progressive\nupward movement of both the median and the overall accuracy marker from the 0.6B to the 8B model.\nConversely, SFT and GRPO exhibit less regular scaling behavior. Gains in overall accuracy for these baselines\n6/21\n"}, {"page": 7, "text": "often accompany increased dispersion or heavier lower tails. This pattern suggests that the improvements\ndriven by ClinMPO are broadly distributed across categories rather than being driven by a small number of\nhigh-performing domains.\nThe robustness advantage of ClinMPO is particularly evident in the suppression of extreme failures.\nSFT and GRPO frequently span from near zero to high accuracy across categories. This is reﬂected by long\nwhiskers and diﬀuse proﬁles in the visualization. ClinMPO avoids such extremes in most settings. Instead,\nit maintains mid-range to high performance across the majority of competencies and diagnostic groups. This\nindicates more reliable generalization across clinically diverse and imbalanced categories. These distribution-\nlevel properties are critical for clinical reasoning tasks where reliability across diverse scenarios is as important\nas peak accuracy.\n3 Discussion\nThe integration of Large Language Models (LLMs) into psychiatric workﬂows faces barriers that extend\nbeyond simple hallucinations.\nThe fundamental challenge is structural.\nGeneral-purpose models lack a\ncognitive framework that parallels the evidence-based and contextualized reasoning required in clinical psy-\nchiatry. Current optimization methods frequently prioritize linguistic plausibility or surface-level correctness.\nThis approach often fails to internalize essential cognitive processes such as diﬀerential diagnosis and error\nrecognition. The limitation is particularly acute for light-parameter LLMs. These models are essential for\nprivacy-sensitive and resource-constrained environments but typically lack the inherent capacity for complex\nreasoning.\nTheir safe deployment requires a robust alignment with clinical logic that standard training\nparadigms do not provide.\nWe introduce ClinMPO to resolve this misalignment.\nThis reinforcement learning framework aligns\nmodel reasoning with professional psychiatric cognition. The core innovation lies in the integration of two\ncomponents. First, the ClinRM reward model evaluates reasoning steps based on a proprietary evidence\ncorpus extracted from the psychiatric literature. It assesses logical coherence and evidence usage rather\nthan lexical overlap. Second, multi-group policy optimization guides the model toward robust reasoning\npatterns by emphasizing relative quality across diverse case groups. This approach anchors optimization\nin structured clinical evidence. It provides light LLMs with a necessary cognitive scaﬀold. This enables\ntheir development into reliable reasoning assistants without reliance on massive parameter scale or generic\npreference alignment.\nOur evaluation demonstrates that this approach successfully bridges the gap between artiﬁcial and human\nclinical cognition.\nClinMPO consistently enhances the performance of light LLMs on psychiatric tasks.\nNotably, the framework narrows and frequently reverses the performance disparity between models and\nmedical students. This convergence is most evident in complex tasks that require evidence synthesis and\ndiﬀerential diagnosis. These results suggest that eﬀective psychiatric AI depends less on raw computational\npower and more on the structural alignment of the model with domain-speciﬁc reasoning protocols.\nA critical ﬁnding of this study is the distinction between answer correctness and reasoning validity. Con-\nventional training paradigms like Supervised Fine-Tuning (SFT) often incentivize models to guess correct\nanswers based on superﬁcial heuristics. This phenomenon explains the superﬁcial reasoning frequently ob-\nserved in benchmarks30–32. ClinMPO addresses this core limitation by shifting the optimization target. The\nClinRM provides dense feedback based on evidence hierarchy and diagnostic principles. This forces the\nmodel to construct clinically valid reasoning chains rather than merely mimicking the statistical patterns of\ncorrect answers. This shift aligns the internal processing of the model with professional standards.\nThe study also has signiﬁcant implications for the deployment of eﬃcient AI in healthcare. Practical\napplications often demand lightweight models due to infrastructure and privacy constraints15,29,33. However,\nreduced parameter counts typically restrict multi-step reasoning capabilities. Previous attempts to transfer\ncapabilities from larger models often resulted in improved factual memory rather than enhanced reasoning\narchitecture.\nOur results indicate that reasoning capability is not solely a function of scale.\nClinMPO\nfosters robust generalization through multi-group optimization. This proves that compact models can achieve\nreliable clinical reasoning when their training objectives rigorously reﬂect cognitive tasks.\nWe acknowledge several limitations that deﬁne directions for future research.\nFirst, our evaluation\nrelies on controlled datasets. Future validation must occur within dynamic clinical workﬂows and involve\ndiverse patient populations to ensure socioeconomic and cultural equity. Second, our approach is currently\n7/21\n"}, {"page": 8, "text": "Figure 5. Pipeline for data construction pipeline. a Public QA Dataset construction b Evidence\nDataset construction\nconstrained to the post-training phase. This leaves the model susceptible to interference from non-medical\ndata distributions encountered during pre-training. Future methodologies should explore alignment strategies\nthat begin during the pre-training phase12. Finally, challenges regarding long-term fairness and robustness\nto adversarial inputs remain. Addressing these issues will likely require complementary techniques such as\nretrieval-augmented generation and rigorous post-deployment monitoring.\nIn summary, this study demonstrates a viable pathway to enhance psychiatric AI through explicit cog-\nnitive alignment. ClinMPO moves beyond paradigms dominated by model scaling or linguistic ﬂuency. We\nshow that light LLMs can acquire clinically grounded reasoning capabilities that rival those of human trainees.\nThis progress oﬀers a feasible route for health systems to deploy resource-eﬃcient AI systems that assist pro-\nfessional judgment. We provide our evidence dataset and evaluation framework to the research community\nto facilitate this transition. These resources aim to foster a shift from simple accuracy metrics toward deep\nassessments of reasoning ﬁdelity in high-stakes medical domains.\n4 Methods\n4.1 Dataset Collection from Medical Evidence\nWe construct two core datasets through a systematic pipeline as shown in Figure(5): the Public QA Dataset\nand the Evidence QA Dataset. The Public QA Dataset derives from six publicly available medical question-\nand-answer resources: Chinese Medical Benchmark (CMB), MedBullets/MedBulletsQA, Medical Multiple\nChoice Question Answering (MedMCQA), Medical Question Answering (MedQA), Medical Expert Question\nSet/MedXpertQA, and Massive Multitask Language Understanding–Professional Extension (MMLUPro).\nThe construction process involves three major stages. First, we employ GPT-5 to ﬁlter questions from all\nsources to ensure psychiatric relevance. The ﬁltering relies on the clinical topics, sub-specialties, and major\npsychiatric disorders in the Oxford Textbook of Psychiatry (7th edition).\nThis process produced 9,649\ncandidate questions.\nNext, we standardized all questions from their original formats including multiple-\n8/21\n"}, {"page": 9, "text": "choice items, expert question–answer pairs, and open-ended questions. Each question is converted into a\nuniﬁed multiple choice format: question, options, correct answer, and COT. Then, We removed redundant\nitems using a Clinical BERT–based semantic similarity algorithm with a 90% similarity threshold. Finally,\nﬁve clinical experts in psychiatry independently reviewed and annotated a randomly sampled 30% subset to\nfurther ensure data quality. After validation, the Public QA Dataset contains 8,849 curated questions.\nThe development of the Evidence QA Dataset adheres closely to the Oxford Centre for Evidence-Based\nMedicine grading framework, with a speciﬁc focus on three key appraisal perspectives: Critical Appraisal,\nExperimental Studies, and Observational Studies. First, we employed a MeSH term-based search strategy\nacross OpenAlex and Europe PMC, targeting high-quality psychiatry articles published between January\n2020 and October 2025. We then sampled articles in proportion to the evidence-level pyramid. This yields\n4,474 papers spanning practice guidelines, systematic reviews, controlled trials, and case reports. Second,\nwe introduced an Clinical-Psychiatry thinking criteria.\nFive clinical psychiatry experts designed this by\ngrounding in the Oxford Textbook of Psychiatry (7th edition), emphasizing key clinical reasoning dimensions.\nLet C denote the set of evaluation criteria, which is formally deﬁned as (Eq.(1)):\nC =\n\n\n\n\n\n\n\nC1 : Scientiﬁcity and Accuracy of Knowledge,\nC2 : Plainness and Conciseness of Language,\nC3 : Orderliness and Logicality of Structure.\n(1)\nFurthermore, for C1 we specify the sub-criteria as (Eq.(2)):\nC1 =\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nk1 :\nIncorrect Pathogenesis,\nk2 :\nMisidentiﬁcation of Symptoms,\nk3 :\nMisinterpretation of Examinations,\nk4 :\nErrors in Diﬀerential Diagnosis,\nk5 :\nIncorrect Treatment Plans.\n(2)\nThird, we used GPT-5 to analyze each article, extract core ﬁndings, and generate one multiple-choice\nquestion per paper.Subsequently, GPT-5 controlled modiﬁcations into a subset of questions, enriching data\ndiversity and capturing real-world error patterns. These modiﬁcations randomly added errors aligned with\nthe scoring categories, such as incorrect pathogenesis, linguistic issues, or structural ﬂaws. Finally, we used\nSimHash and the same expert review protocol as public QA datasets for de-duplication.\nAfter integrating the original and modiﬁed items, the ﬁnal Evidence QA Dataset contains 18,569 question–\nanswer pairs, each includes: question, options, correct answer, COT for answer, score sheet, and COT for\nscoring.\n4.2 Human Baseline Evaluation\nThe research protocol was reviewed and approved by the Institutional Research Ethics Committee (R202512150520).\nAll data were processed in accordance with applicable privacy and data protection standards, and no identi-\nﬁable personal information was collected or used. All participants provided informed consent and received a\nsmall monetary compensation for their participation. Participants were randomly assigned to experimental\nconditions and were blinded to the study design. No deception was used.\nThis study established a reliable human baseline to further compare and evaluate model reasoning capa-\nbilities. We recruited 300 medical students with coursework experience in psychiatry as participants. The\nevaluation is conducted using a pre-deﬁned Public QA test set. First, a dual-mode data collection protocol\nwas implemented, comprising both oﬄine paper-based tests and an online platform. All procedures strictly\nadhered to the Declaration of Helsinki, with full data anonymization. Question assignment was randomized\nsuch that each item received six independent responses, thereby balancing individual variability and item\ndiﬃculty. Second, participant responses were compared against ground-truth answers to derive overall accu-\nracy, which served as the primary baseline metric. Third, accuracy within each subcategory was computed\nusing ICD-11–guided classiﬁcations. Finally, the distribution of human baseline performance was visualized\nusing heatmaps.\"\n9/21\n"}, {"page": 10, "text": "4.3 Data Preprocessing for Two-Stage Training\nWe performed a ﬁne grained partition of the integrated set of the Public dataset. The goal is to ensure that\ntraining realistically reﬂects the model’s behavior under diﬀerent knowledge conditions. This approach aims\nto approximate a black box inference scenario as closely as possible. We employed thirteen advanced LLMs\nto independently reason over all items and treated their judgments as a form of cross system collective voting.\nThis panel included models recognized for their strong general capabilities (GPT-4o, GPT-5,Gemini-2.5-Pro),\neﬃcient smaller architectures (GPT-5-Mini, Llama-3.1-8B, Mistral-7B), recent iterations with advanced rea-\nsoning (Claude-Sonnet-4-20250514, Claude-Sonnet-4-20250514-thinking), and prominent open-source repre-\nsentatives (DeepSeek-V3, DeepSeek-R1, Qwen3-8B, Yi-1.5-9B). We categorized items answered correctly by\nmore than eight models into the “easy”set. This subset corresponds to medical knowledge that appears to\nbe well-exposed during pretraining on large-scale corpora. Conversely, we assigned items to the \"hard\" set if\nthe number of correct models did not exceed this threshold. The knowledge represented in this set typically\nexhibits insuﬃcient coverage in standard pretraining data or occurs in sparse forms, impeding the formation\nof stable internal representations within the model parameter space.\nFollowing this partitioning principle, we adopted same conﬁgurations in the subsequent two stage training\nprocess to investigate strategies for improving reasoning ability. Under this setup, we used the easy set as\nthe training set and the hard set as the test set across both stages. In total, the training set contains 7112\nitems and the test set contains 1737 items. Speciﬁcally, This setup intends to create a black-box environment\nwhere the model depends on structured reasoning to process unseen medical knowledge. Consequently, this\nallows us to assess how eﬀectively the training strategy fosters genuine reasoning ability.\n4.4 Data Categorization with ICD-11\nWe established a two-tiered clinical categorization framework for the Public QA dataset, anchored in the\nWorld Health Organization’s International Classiﬁcation of Diseases, 11th Revision (ICD-11) as Appendix\nA.\nThe ﬁrst tier is structured directly by the ICD-11 diagnostic taxonomy, encompassing 26 principal disease\ncategories and 168 associated sub-diagnoses to ensure global nosological alignment. To complement this di-\nagnostic structure, we introduced a second tier designed to capture the essential competencies of psychiatric\npractice. This dimension was derived through a systematic review of authoritative clinical, educational, and\nregulatory frameworks, including clinical practice guidelines (American Psychiatric Association; National\nInstitute for Health and Care Excellence Guideline NG225; WHO mhGAP Intervention Guide) and certi-\nﬁcation speciﬁcations (United States Medical Licensing Examination Content Outline; National Board of\nMedical Examiners Psychiatry Subject Examination Outline; American Board of Psychiatry and Neurology\nCertiﬁcation Content Speciﬁcations; Royal College of Psychiatrists Clinical Assessment of Skills and Com-\npetencies syllabus). By reconciling these sources with specialist input, we ultimately deﬁne 12 clinically\noriented question-type categories that represent the core knowledge and applied competencies expected of a\npracticing psychiatrist.\nData categorization is implemented through a semi-automated, two-stage workﬂow. First, we employed\nan initial screening rule-based keyword matching, customized to ICD-11 terminology. This coarse-grained\nﬁltration was followed by a reﬁned classiﬁcation step utilizing the large language model GPT-5 for nuanced,\nhierarchical medical knowledge categorization. Then, Five experts conducted a manual review on a randomly\nsampled 10% of the automatically categorized items to validate labeling accuracy. Supplementarily, We\nadjudicated discrepant cases through a multidisciplinary expert panel consensus discussion and systematically\napplied the ﬁnalized corrections to the dataset.\n4.5 Experimental Setup\nWe performed experiments on computing server equipped with eight NVIDIA A100 GPUs (80 GB memory\neach) running Ubuntu 24.04.1 LTS (Noble Numbat). To ensure reproducibility across training and deploy-\nment stages, we created three isolated Conda environments. For SFT, we employed Python 3.10, PyTorch\n2.2.2, and the LLaMA-Factory toolkit to initialize the model and conduct instruction tuning. For RL environ-\nment, we conﬁgured it with Python 3.10, PyTorch 2.7.1+cu126, and the Verl framework. For inference and\ndeployment, we used a dedicated comprising Python 3.10, PyTorch 2.7.1+cu126, and the vLLM framework.\n10/21\n"}, {"page": 11, "text": "4.6 Reward Model Development\nWe developed ClinRM, a reward model designed to simulate the Simulated Clinical Psychiatry Thinking\nStrategy (CPTS). To ensure consistency in model selection and optimization, we adopt the thinking-enabled\nQwen3-8B model as the base Model and used SFT train ClinRM on the Evidence QA dataset.\nFor each evaluated instance, the reward model receives an input tuple as (Eq.(3)):\nx = {q, A, a∗, r},\n(3)\nwhere q denotes the clinical question, A denotes the set of candidate answer options, a∗denotes the\ngold-standard answer, and r denotes a generated chain-of-thought that includes the model’s ﬁnal selection.\nBased on this input, ClinRM outputs a structured evaluation score in JSON format following a predeﬁned\ncriterion system C (Eq. (1)).\nScoring rules.\nFor each sub-criterion kj ∈K, the reward model assigns a discrete score as (Eq.(4)):\nsj ∈{−2, 0, +2},\n(4)\nwhere s j = −2 indicates that an error corresponding to kj is detected, sj = 0 indicates that the sub-criterion\nis not triggered, and s j = +2 indicates that the sub-criterion is correctly addressed.\nFor the remaining criteria C2 and C3, which non related to clinical Phsychiatry aspects, scalar scores are\nassigned as (Eq.(5)):\nsC2, sC3 ∈{−1, +1},\n(5)\nwhere a negative value indicates the presence of linguistic or structural issues (e.g., redundancy, incom-\npleteness, or illogical ordering), and a positive value indicates the absence of such issues.\nReward aggregation and normalization.\nThe unnormalized reward is computed by aggregating all criterion-\nlevel scores as (Eq.(6)):\nRraw = ∑\nj∈K\nsj +sC2 +sC3.\n(6)\nTo mitigate overly conservative optimization behavior and reduce the risk of gradient vanishing caused\nby predominantly negative rewards, we apply a non-negative normalization to the aggregated score. The\nﬁnal reward used for model optimization is deﬁned as (Eq.(7)):\nR = max\n(\n0, Rraw\n)\n.\n(7)\nHere, R denotes the ﬁnal scalar reward produced by ClinRM, while Rraw denotes the unnormalized sum\nof criterion-speciﬁc scores. This formulation preserves expert clinical preferences while ensuring numerical\nstability during reward model optimization.\n4.7 Cold-Start Supervised Fine-Tuning\nWe perform a cold-start SFT stage using on pre-deﬁned. To verify the generalizability of the method, We\nﬁntuned the Qwen series model by Low-Rank Adaptation (LoRA): Qwen3-0.6B, Qwen3-1.7B, Qwen3-4B,\nand Qwen3-8B. This stage provides a stable and eﬀective policy initialization for the next RL. Finally, we\ngot four ﬁntuned-models πθ0(Qwen3-0.6B, Qwen3-1.7B, Qwen3-4B, and Qwen3-8B), where θ0 represents the\noptimized model parameters at the end of this stage.\n4.8 Reinforcement Learning via GRPO\nIn the RL stage, we investigated policy optimization based on GRPO. We used the cold-start SFT models πθ0\nas the initial policy models and performed GRPO post-training on predeﬁned public QA training dataset.\n11/21\n"}, {"page": 12, "text": "Standard GRPO.\nFor each input prompt s, the policy πθ generates a group of K candidate responses\n{a1,...,aK}, each receiving a scalar reward {r1,...,rK}. Following the standard GRPO formulation, rewards\nare normalized within each group to compute the relative advantage as (Eq.(8)):\nˆAi = ri −µr\nσr +ε ,\nµr = 1\nK\nK\n∑\ni=1\nri,\nσr =\n√\n1\nK\nK\n∑\ni=1\n(\nri −µr\n)2.\n(8)\nwhere µr and σr denote the mean and standard deviation of rewards within the group, and ε is a small\nconstant for numerical stability.\nThe GRPO objective function is deﬁned as (Eq.(9)):\nLGRPO(θ) = E(s,a)\n[\nmin\n(\nρθ(s,a) ˆA,\nclip\n(\nρθ(s,a),1−ε,1+ε\n) ˆA\n)]\n−β DKL\n(\nπθ ∥πref\n)\n,\n(9)\nwhere ρθ(s,a) = πθ(a|s)/πref(a|s) is the importance sampling ratio, πref denotes the reference policy (ini-\ntialized as πθ0), β controls the strength of Kullback–Leibler regularization, and DKL(·∥·) denotes the KL\ndivergence.\nClinMPO.\nTo incorporate clinically grounded reasoning signals, we proposed ClinMPO, which preserves the\nGRPO optimization framework in (Eq. (9)) but replaces the scalar reward ri with a structured clinical reward\nRCPTS(s,a), generated by the ClinRM reward model. This reward integrates scientiﬁc accuracy, linguistic\nclarity, and structural coherence as deﬁned by the clinical criteria system.\nAs a result, ClinMPO introduces a clinical-consistency regularizer C(s,a), derived from ClinRM dimen-\nsions associated with diagnostic reasoning logic and structural coherence. Based on RCPTS(s,a), a clinically\nadjusted advantage ˆACPTS is computed using the same group-normalization scheme as in Eq. (8).\nThe resulting gradient update is deﬁned as (Eq.(10))\n∇θLCPTS(θ) = E(s,a)\n[\n∇θ min\n(\nρθ(s,a) ˆACPTS,\nclip\n(\nρθ(s,a),1−ε,1+ε\n) ˆACPTS\n)]\n−β ∇θDKL\n(\nπθ ∥πref\n)\n+λ ∇θC(s,a),\n(10)\nwhere λ controls the contribution of the clinical-consistency regularizer.\nBy injecting expert-derived, clinically grounded signals directly into the policy gradient update, ClinMPO\nexplicitly steers model optimization toward the rigor, logical structure, and domain-speciﬁc accuracy required\nfor psychiatric diagnostic reasoning.\n4.9 Model Evaluation Metrics\nWe employed a multi-dimensional and multi-layered evaluation framework to systematically assess 12 Qwen\nseries models across three post-training paradigms: SFT, Base GRPO, and ClinMPO. The evaluation was\nconducted on a pre-partitioned public medical question-answering test set. The entire evaluation is referenced\nagainst the pre-established human baseline, comprehensively measuring the gaps in reasoning ability both\namong the models and between the models and humans. The assessment integrates objective quantitative\ndata analysis with subjective expert clinical review to obtain a thorough and credible performance judgment.\nAt the quantitative level, we ﬁrst calculated the overall accuracy for each model. To further diagnose\nerror patterns, we further decomposed the accuracy into four categories: TT (true answer correct and\n12/21\n"}, {"page": 13, "text": "model output correct), TF (true answer correct but model output incorrect), FT (true answer incorrect but\nmodel output correct), and FF (both true answer and model output incorrect). Secondly, we computed\nsubcategory accuracies on the previously constructed ICD-11–Guided Data Categorization.\nFinally, We\ngenerated comparative heatmaps of model versus human performance across subcategories, which visually\nreveal the models’ diﬀerentiated capabilities in various subﬁelds within psychiatry.\nAt the expert level, we invited an independent panel of three senior clinical psychiatrists to perform a\nblinded review. We randomly sampled 10% of the model’s Chain-of-Thought outputs from the test set to\naddress the limitations of purely quantitative metrics and to assess reasoning quality. The review process\nstrictly follows the predeﬁned scoring criteria in equation(1). This evaluation provides a clinical perspective\non each model’s reasoning ability, oﬀering essential real-world context and interpretation for the quantitative\nﬁndings.\n5 Data Availability\nData will be available soon.\n6 Code Availability\nCode will be available soon.\n13/21\n"}, {"page": 14, "text": "References\n1. Rajpurkar, P., Chen, E., Banerjee, O. & Topol, E. J. Ai in health and medicine. Nat. medicine 28,\n31–38 (2022).\n2. Yu, H. et al. Large language models in biomedical and health informatics: a review with bibliometric\nanalysis. J. healthcare informatics research 8, 658–711 (2024).\n3. Xu, S. et al. Identifying psychiatric manifestations in outpatients with depression and anxiety: a large\nlanguage model-based approach. npj Mental Heal. Res. 4, 63 (2025).\n4. Liu, Z. et al. Large language models in psychiatry: Current applications, limitations, and future scope.\nBig Data Min. Anal. 7, 1148–1168 (2024).\n5. Tang, L. et al. Evaluating large language models on medical evidence summarization. NPJ digital\nmedicine 6, 158 (2023).\n6. Singhal, K. et al. Large language models encode clinical knowledge. Nature 620, 172–180 (2023).\n7. Obradovich, N. et al. Opportunities and risks of large language models in psychiatry. NPP—Digital\nPsychiatry Neurosci. 2, 8 (2024).\n8. Singhal, K. et al. Toward expert-level medical question answering with large language models. Nat.\nMedicine 31, 943–950 (2025).\n9. Hua, Y. et al. A scoping review of large language models for generative tasks in mental health care. npj\nDigit. Medicine 8, 230 (2025).\n10. Zhang, R., Meng, H., Neubronner, M. et al. Computational and ethical considerations for using large\nlanguage models in psychotherapy. Nat. Comput. Sci. 5, 854–862, DOI: 10.1038/s43588-025-00874-x\n(2025).\n11. Pichowicz, W., Kotas, M. & Piotrowski, P. Performance of mental health chatbot agents in detecting\nand managing suicidal ideation. Sci. Reports 15, 31652, DOI: 10.1038/s41598-025-17242-4 (2025).\n12. Kallstenius, T., Capusan, A., Andersson, G. et al. Comparing traditional natural language processing\nand large language models for mental health status classiﬁcation: a multi-model evaluation. Sci Rep\n15, 24102, DOI: 10.1038/s41598-025-08031-0 (2025).\n13. Hakim, J., Painter, J., Ramcharran, D. et al. The need for guardrails with large language models in\npharmacovigilance and other medical safety critical settings. Sci. Reports 15, 27886, DOI: 10.1038/\ns41598-025-09138-0 (2025).\n14. Tam, T. Y. C. et al. A framework for human evaluation of large language models in healthcare derived\nfrom literature review. NPJ digital medicine 7, 258 (2024).\n15. Agrawal, M., Chen, I. Y., Gulamali, F. & Joshi, S. The evaluation illusion of large language models in\nmedicine. npj Digit. Medicine 8, 600 (2025).\n16. Chen, X. et al. Evaluating large language models and agents in healthcare: key challenges in clinical\napplications. Intell. Medicine (2025).\n17. Thirunavukarasu, A. J. & O’Logbon, J. The potential and perils of generative artiﬁcial intelligence in\npsychiatry and psychology. Nat. Mental Heal. 2, 745–746 (2024).\n18. Mizuno, A., Erickson, Z., Jimenez, D. et al. Ai in geriatric psychiatry: precision meets human experience.\nNeuropsychopharmacology DOI: 10.1038/s41386-026-02328-y (2026).\n19. Ferrante, M. et al. Computational psychiatry: a report from the 2017 nimh workshop on opportunities\nand challenges. Mol. Psychiatry 24, 479–483, DOI: 10.1038/s41380-018-0063-z (2019).\n20. Menke, A. Precision pharmacotherapy: psychiatry’s future direction in preventing, diagnosing, and treat-\ning mental disorders. Pharmacogenomics Pers. Medicine 11, 211–222, DOI: 10.2147/PGPM.S146110\n(2018).\n21. Cook, D. J., Mulrow, C. D. & Haynes, R. B. Systematic reviews: synthesis of best evidence for clinical\ndecisions. Annals internal medicine 126, 376–380 (1997).\n14/21\n"}, {"page": 15, "text": "22. Davidson, M. & Iles, R. Research methods in health: Foundations for evidence-based practice. In\nLiamputtong, P. (ed.) Research Methods in Health: Foundations for Evidence-Based Practice, 285–300\n(Oxford University Press, 2010).\n23. Dukart, J., Weis, S., Genon, S. et al. Towards increasing the clinical applicability of machine learning\nbiomarkers in psychiatry. Nat. Hum. Behav. 5, 431–432, DOI: 10.1038/s41562-021-01085-w (2021).\n24. Templin, T. et al. Framework for bias evaluation in large language models in healthcare settings. npj\nDigit. Medicine 8, 414 (2025).\n25. Malgaroli, M. et al. Large language models for the mental health community: framework for translating\ncode to care. The Lancet Digit. Heal. 7, e282–e285 (2025).\n26. Dai, C. et al. Psyche-r1: Towards reliable psychological llms through uniﬁed empathy, expertise, and\nreasoning. arXiv preprint arXiv:2508.10848 (2025).\n27. Xiao, M. et al.\nMentrasuite: Post-training large language models for mental health reasoning and\nassessment. arXiv preprint arXiv:2512.09636 (2025).\n28. Feng, Y., Luo, H., Feng, L., Zhao, S. & Luu, A. T. From stimuli to minds: Enhancing psychological\nreasoning in llms via bilateral reinforcement learning. arXiv preprint arXiv:2508.02458 (2025).\n29. Benkirane, K., Kay, J. & Perez-Ortiz, M. How can we diagnose and treat bias in large language models\nfor clinical decision-making?\nIn Proceedings of the 2025 Conference of the Nations of the Americas\nChapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1:\nLong Papers), 2263–2288 (2025).\n30. Kim, J. et al.\nLarge language models outperform mental and medical health care professionals in\nidentifying obsessive-compulsive disorder. NPJ Digit. Medicine 7, 193 (2024).\n31. Bucher, A., Egger, S., Vashkite, I., Wu, W. & Schwabe, G.\n“it’s not only attention we need”:\nSystematic review of large language models in mental health care. JMIR mental health 12, e78410\n(2025).\n32. Wu, C. et al. Towards evaluating and building versatile large language models for medicine. npj Digit.\nMedicine 8, 58 (2025).\n33. Zhou, S. et al. Automating expert-level medical reasoning evaluation of large language models. npj\nDigit. Medicine (2025).\n15/21\n"}, {"page": 16, "text": "Appendix A: Two-tiered Clinical Categorization\nTier 1: ICD-11 Diagnostic Taxonomy\nItem\nCategory\nI\nMonitoring, Follow-up & Measurement-Based Care\nII\nCommunication, Consultation & Interprofessional Collaboration\nIII\nRisk Assessment & Safety Planning\nIV\nDiﬀerential Diagnosis (including Medical Mimics)\nV\nSystems-Based & Community Care (Public Health Perspective)\nVI\nTreatment Selection & Initiation\nVII\nSymptom Elicitation & Mental Status Examination (MSE)\nVIII\nLegal, Ethical & Capacity/Judgment\nIX\nComorbidity & Complexity Management\nX\nSpecial Populations & Lifespan Adaptation\nXI\nDiagnostic Formulation & Case Deﬁnition\nXII\nEvidence Appraisal, Data Interpretation & Scale Use\nTier 2: Psychiatric Practice Competencies\nMajor Category\nDisorders\nA\nOther speciﬁed mental, behavioural or neurodevelopmental disorders [6E8Y]\nB\nGender incongruence\nC\nCatatonia\nD\nFeeding or eating disorders\nE\nMental, behavioural or neurodevelopmental disorders, unspeciﬁed [6E8Z]\nF\nMood disorders\nG\nDisruptive behaviour or dissocial disorders\nH\nDisorders speciﬁcally associated with stress\nI\nParaphilic disorders\nJ\nNeurodevelopmental disorders\nK\nImpulse control disorders\nL\nDissociative disorders\nM\nPersonality disorders and related traits\nN\nDisorders due to substance use or addictive behaviours\nO\nAnxiety or fear-related disorders\nP\nSleep-wake disorders [07]\nQ\nObsessive-compulsive or related disorders\nR\nPsychological or behavioural factors aﬀecting disorders or diseases classiﬁed\nelsewhere [6E40]\nS\nSecondary mental or behavioural syndromes associated with disorders or dis-\neases classiﬁed elsewhere\nT\nNeurocognitive disorders\n16/21\n"}, {"page": 17, "text": "U\nSchizophrenia or other primary psychotic disorders\nV\nSexual dysfunctions\nW\nDisorders of bodily distress or bodily experience\nX\nFactitious disorders\nY\nElimination disorders\nZ\nMental or behavioural disorders associated with pregnancy, childbirth or the\npuerperium\n17/21\n"}, {"page": 18, "text": "Appendix B: Annotation platform settings\nFigure 6. Screenshot of annotation platform. The self-built Label Studio platform interface used by\nclinicians to perform the labeling tasks.\n18/21\n"}, {"page": 19, "text": "Appendix C: A Comparative Error Analysis of ClinMPO and baseline Model\nThis appendix presents a qualitative error analysis comparing ClinMPO with a baseline model (Qwen3-8B)\non a representative clinical reasoning task. The analysis focuses on diﬀerences in clinical reasoning structure,\ntext expression, and ethical decisionmaking.\nSample question\nAfter three sessions with a therapy client, Dr. Leonard Lykowski realizes that he’s feeling\nsomewhat hostile toward the client because she reminds him of his wife who he’s currently\ndivorcing.\nDr. Lykowski recognizes that his emotional reaction may interfere with eﬀective\ntherapy. What is the most appropriate professional action?\nOptions\nA. Consult with another psychologist to determine whether or not to continue seeing the\nclient in therapy.\nB. Seek personal therapy to manage his feelings and continue working with the client.\nC. Refer the client to another therapist after discussing the reason with her.\nD. Recognize that his feelings are the result of countertransference and continue to work\nwith the client.\nE. Express his hostility toward the client during the session.\nF. Terminate the therapy sessions without any explanation.\nG. Discuss his personal situation with the client to create transparency.\nH. Ignore his feelings and continue working with the client.\nI. Refer the client to another therapist without telling the client the reason for the referral.\nJ. Ask the client to ﬁnd another therapist without providing a reason.\nCorrect Answer: A\nHINT:The above test questions are selected from one of the test sets. Outputs generated by the two models\nare compared and analysed independently by clinicians with relevant clinical expertise.\n19/21\n"}, {"page": 20, "text": "Figure 7. Baseline Model (Qwen3-8B) Response. The left panel displays the model’s original\noutput. Segments highlighted in red denote portions ﬂagged by a clinician as clinically inappropriate or\nsuboptimal. The right panel presents aligned explanations clarifying the underlying reasoning errors or\ntext comprehension issues.\n20/21\n"}, {"page": 21, "text": "Figure 8. ClinMPO Response. The left panel shows the model’s original output text. Text highlighted\nin green denotes segments identiﬁed by a clinician as clinically appropriate and wellreasoned. The right\npanel provides corresponding explanations\n21/21\n"}]}