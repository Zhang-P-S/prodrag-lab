{"doc_id": "arxiv:2511.21075", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2511.21075.pdf", "meta": {"doc_id": "arxiv:2511.21075", "source": "arxiv", "arxiv_id": "2511.21075", "title": "Aligning LLMs with Biomedical Knowledge using Balanced Fine-Tuning", "authors": ["Zhenchao Tang", "Fang Wang", "Haohuai He", "Jiale Zhou", "Tianxu Lv", "Jun Zhu", "Shouzhi Chen", "Minghao Yang", "Yu Wang", "Jiayang Wu", "Yidong Song", "Jianhua Yao"], "published": "2025-11-26T05:34:26Z", "updated": "2025-11-26T05:34:26Z", "summary": "Effective post-training is essential to align Large Language Models (LLMs) with specialized biomedical knowledge to accelerate life science research. However, current approaches face significant limitations. First, biomedical reasoning involves intricate mechanisms often represented by sparse textual data. Standard Supervised Fine-Tuning (SFT) tends to overfit to surface-level instruction patterns without effectively internalizing this fragmented scientific knowledge. Second, Reinforcement Learning (RL) is impractical for this domain, as defining meaningful rewards often necessitates prohibitive experimental validation (e.g., wet-lab verification of drug responses), rendering real-time feedback unfeasible. We propose Balanced Fine-Tuning (BFT), an efficient post-training method designed to learn complex reasoning from sparse data without external reward signals. BFT operates through a two-layer weighting mechanism: 1. At the token level, it scales loss via prediction probabilities to stabilize gradients and prevent overfitting; 2. At the sample level, it uses \"minimum group confidence\" to adaptively enhance the learning of hard samples. Experiments demonstrate that BFT significantly outperforms SFT. In medical tasks, it enables LLMs to acquire knowledge that SFT misses. In biological tasks, BFT-based LLMs surpass GeneAgent (an accurate agent for biology analysis) in biological process reasoning. Moreover, the text embeddings generated by BFT can be directly applied to downstream tasks, such as gene interaction and single-cell perturbation response prediction. These results indicate that BFT facilitates broad applications of LLMs in biomedical research.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2511.21075v1", "url_pdf": "https://arxiv.org/pdf/2511.21075.pdf", "meta_path": "data/raw/arxiv/meta/2511.21075.json", "sha256": "f3061e2dae25e4ba4ce240a459de71f6a45088dd09b00233ae5a438836acb8f0", "status": "ok", "fetched_at": "2026-02-18T02:26:02.787434+00:00"}, "pages": [{"page": 1, "text": "Aligning LLMs with Biomedical Knowledge using\nBalanced Fine-Tuning\nZhenchao Tang1†, Fang Wang1†*, Haohuai He1, Jiale Zhou1, Tianxu Lv1, Jun Zhu1,\nShouzhi Chen1, Minghao Yang1, Yu Wang1, Jiayang Wu1, Yidong Song1, Jianhua Yao1∗\n1. Tencent AI for Life Sciences Lab, Shenzhen, China.\n†Equal contribution\n*Corresponding author\nAbstract\nEffective post-training is essential to align Large Language Models (LLMs) with\nspecialized biomedical knowledge to accelerate life science research. However,\ncurrent approaches face significant limitations. First, biomedical reasoning involves\nintricate mechanisms often represented by sparse textual data. Standard Supervised\nFine-Tuning (SFT) tends to overfit to surface-level instruction patterns without\neffectively internalizing this fragmented scientific knowledge. Second, Reinforce-\nment Learning (RL) is impractical for this domain, as defining meaningful rewards\noften necessitates prohibitive experimental validation (e.g., wet-lab verification of\ndrug responses), rendering real-time feedback unfeasible. We propose Balanced\nFine-Tuning (BFT), an efficient post-training method designed to learn complex\nreasoning from sparse data without external reward signals. BFT operates through\na two-layer weighting mechanism: 1. At the token level, it scales loss via prediction\nprobabilities to stabilize gradients and prevent overfitting; 2. At the sample level, it\nuses “minimum group confidence” to adaptively enhance the learning of hard sam-\nples. Experiments demonstrate that BFT significantly outperforms SFT. In medical\ntasks, it enables LLMs to acquire knowledge that SFT misses. In biological tasks,\nBFT-based LLMs surpass GeneAgent (an accurate agent for biology analysis) in\nbiological process reasoning. Moreover, the text embeddings generated by BFT can\nbe directly applied to downstream tasks, such as gene interaction and single-cell\nperturbation response prediction. These results indicate that BFT facilitates broad\napplications of LLMs in biomedical research.\n1\nIntroduction\nLarge language models (LLMs) have achieved remarkable success across general domains, with\nsupervised fine-tuning (SFT) and reinforcement learning (RL) becoming standard components of\nthe post-training pipeline [1]. However, biomedical science involves complex reasoning over sparse\nand fragmented knowledge. Developing effective post-training methods for aligning LLMs with\nbiomedical knowledge is therefore crucial—not only because LLMs can directly accelerate biomedical\ndiscovery, but also because they can inherit and extend the most recent advances in Artificial General\nIntelligence (AGI), paving the way for future intelligent agents in life sciences. Yet, the scarcity of\nhigh-quality biomedical data, the complexity of scientific reasoning, and the high cost of current\npost-training approaches have made it difficult for LLMs to generalize effectively to this domain [2].\n∗Corresponding author to: Fang Wang (avonwanghit@gmail.com), Jianhua Yao (jianhua.yao@gmail.com)\nPreprint. Under review.\narXiv:2511.21075v1  [cs.LG]  26 Nov 2025\n"}, {"page": 2, "text": "Although SFT is a simple and effective post-training method that performs well in general tasks, it\noften faces the risk of overfitting in complex biomedical reasoning. The gradients of SFT may become\nunstable, leading to degraded training performance [3, 4]. Biomedical reasoning involves highly\nintricate causal and regulatory mechanisms, yet the available textual data are extremely sparse—for\nexample, only a fraction of gene regulatory relationships are currently known. When SFT is applied to\nsuch sparse textual data, LLMs tend to overfit, losing their ability to generalize to unseen biomedical\ncontexts. In contrast, RL can explore multiple strategies through explicit reward signals, potentially\nimproving generalization. However, applying RL in the biomedical field is difficult because it requires\nprecisely defined reward functions [5, 6]. Designing such rewards incurs substantial experimental\nand computational cost—for instance, validating a drug’s response in a specific cell line demands\nextensive laboratory testing, making real-time or low-cost feedback nearly impossible to obtain.\nTherefore, a simple, generalizable post-training method capable of learning complex reasoning from\nsparse data is crucial for advancing LLMs in the biomedical domain.\nIn this paper, we propose a method called Balanced Fine-Tuning (BFT), which aims to align LLMs\nwith biomedical science. First, BFT limits the gradients on each token, ensuring stable parameter\nupdates and preventing overfitting. Second, BFT adjusts the model’s learning intensity for different\nsamples based on sample-level confidence, allowing the model to self-adaptively focus on difficult\nsamples during training. BFT is a simple improvement built upon SFT, with RL-like generalization\ncapabilities but without the significant training cost of RL.\nWe comprehensively evaluate the benefit of applying BFT on well-known LLMs such as DeepSeek-\nR1-Distill series [1]. In the medical domain, BFT enables LLMs to acquire knowledge that SFT\ncannot learn. More importantly, after BFT, LLMs exhibit less forgetting in general domains and\nthereby achieve overall improvement. In the biological domain, the BFT-based DeepSeek-R1-Distill\n(70B) outperforms GeneAgent (a self-verification language agent for biology analysis using domain\ndatabases) [7]. The BFT-based LLM does not require the complex scheduling process and external\ndatabase used in GeneAgent, indicating that BFT has injected biological knowledge into LLM.\nFurthermore, we demonstrate the advantages of BFT from the embedding perspective, where the text\nresponses generated by the BFT-based LLM can be converted into embeddings and widely applied\nin downstream tasks. Specifically, we obtain semantically rich gene entity embeddings from the\nBFT-based LLM, which can be directly used in biological research for gene interaction prediction,\nsingle-cell multimodal integration, single-cell perturbation response prediction. These results show\nthat BFT can effectively align LLMs with biomedical science.\n2\nResults\n2.1\nBFT overview\nBalanced Fine-Tuning (BFT) introduces adaptive weighting at both the token and sample levels to\nenhance training stability and learning efficiency. At the token level, BFT records the prediction\nprobability of each token—the likelihood assigned to it during generation. The loss for each token is\nrescaled according to its probability: tokens predicted with lower confidence receive smaller gradient\ncontributions, preventing overfitting. This mechanism stabilizes optimization while maintaining\nfine-grained control over token-level learning. At the sample level, BFT evaluates the overall\ndifficulty of each training sample based on its group confidence. Specifically, it computes the average\nprediction probability of tokens within a sliding window, representing the model’s local confidence\nacross short text spans. Among all such windows, the one with the minimum group confidence\nis selected to characterize the sample’s overall difficulty. Samples with lower minimum group\nconfidence are assigned higher weights, allowing the model to adaptively focus on challenging\nexamples. By integrating weighting mechanisms at both the token and sample levels, BFT achieves a\nbalance between gradient stability and adaptive difficulty learning, enabling large language models to\ngeneralize more effectively in complex biomedical reasoning tasks. For a detailed description of the\nmethod, please refer to the Methods section.\n2.2\nAblation study\nWe conducted ablation study in the mathematical reasoning domain, as it involves complex multi-step\ninference processes and produces concise and deterministic results at each step. Moreover, this\n2\n"}, {"page": 3, "text": "domain provides several public datasets for testing the generalization capability of post-training\nmethods.\nTo conveniently verify the effectiveness of BFT’s components, we fine-tuned a relatively small-scale\nmodel, DeepSeek-R1-Distill (1.5B), on the NuminaMath dataset [8]. The fine-tuned model was\nthen evaluated on multiple widely used mathematical reasoning benchmarks, including math_oai [9],\nminerva_math [10], and olympiadbench [11].\nExtended Data Figure 1a shows the test accuracy across different datasets. Two baselines are\nincluded: the red dashed line represents SFT, and the blue dashed line represents reinforcement\nlearning (represented by GRPO [1]). BFT is evaluated under three window length settings (BFT-\n128/256/512). In addition, two ablation variants are included: BFT w/o sample, which removes\nsample-level weighting, and BFT w/o token, which disables token-level weighting. Across all\ndatasets, BFT consistently outperforms SFT and achieves performance comparable to GRPO. When\ntoken-level weighting is applied (comparing BFT w/o sample with SFT), BFT exhibits significantly\nbetter generalization, indicating that stabilizing token-level gradients effectively enhances reasoning\nperformance. Adding sample-level weighting (comparing BFT-128/256/512 with BFT w/o sample)\nfurther improves performance by encouraging LLMs to focus on more challenging samples. However,\nremoving token-level weighting (BFT w/o token) leads to less improvement compared to SFT,\nsuggesting that gradient stabilization is a prerequisite for effective difficult-sample learning.\nExtended Data Figure 1b tracks the reasoning performance of BFT under different window lengths\nwithin a single training epoch. All configurations (BFT-128/256/512) exhibit stable optimization\ntrajectories and similar performance trends, demonstrating robustness to window size. Among them,\nBFT-256 achieves the highest overall accuracy, likely because shorter windows capture overly local\nconfidence, while longer windows may be influenced by unrelated noisy tokens within the window.\nTherefore, we adopt BFT-256 as the default configuration in subsequent experiments.\n2.3\nBFT enhances the outputs of LLMs\n2.3.1\nMedicine: BFT performs well on the OpenAI Health Bench\nWe evaluated our method in the medical domain using the OpenAI Health Bench [12], a compre-\nhensive benchmark for assessing LLMs on real-world clinical and biomedical reasoning tasks. The\nbenchmark provides two key subsets: the Consensus subset, which contains tasks where experts con-\nsistently agree on correct answers, and the Hard subset, which consists of more complex, ambiguous,\nor high-stakes questions designed to test the limits of LLM reasoning and factual grounding.\nWe employed the DeepSeek-R1-Distill series, specifically the 14B, 32B, and 70B versions. These\nmodels are distilled from the DeepSeek-R1, allowing them to inherit strong reasoning capabilities\nwhile maintaining computational efficiency. We fine-tuned these models on the Consensus subset and\nevaluated them on the Hard subset to assess generalization to challenging medical scenarios. Health\nBench adopts two complementary evaluation views: theme-wise evaluation, which categorizes\nresults by medical themes, including complex_response, health_data_task, communication, and\nclinical knowledge; and axis-wise evaluation, which measures model performance across key skill\ndimensions such as instruction following, factual accuracy, completeness, and reasoning depth. Each\nscore is computed based on OpenAI ChatGPT evaluations that assess the quality of model outputs\nalong multiple axes, normalized to a 0–1 range and averaged across all samples within each subset or\ntheme.\nBFT significantly improves the performance of LLMs on OpenAI Health Bench. In the theme-wise\nevaluation presented in Figure 1a, for certain themes like complex_response, health_data_task, and\ncommunication, BFT enables LLMs to master knowledge that is difficult for SFT to learn. As shown\nin Figure 1b, in the axis-wise evaluation, BFT greatly enhances metrics such as instruction following,\naccuracy, and completeness. Additionally, we compared the computational efficiency of BFT and\nSFT in Extended Data Figure 2. BFT achieves stable overall scores under different sliding window\nsettings (128, 256, 512), and its training runtime is close to that of SFT.\n2.3.2\nGeneral area: reducing forgetfulness\nSFT often causes LLMs to experience catastrophic forgetting, where knowledge acquired from\ngeneral domains is partially lost after domain-specific fine-tuning. To assess whether BFT mitigates\n3\n"}, {"page": 4, "text": "Figure 1: BFT enhances the outputs of DeepSeek-R1-Distill series (14B, 32B and 70B). a: In the\nmedical domain, theme-wise evaluation. b: In the medical domain, axis-wise evaluation. c: Forgetting\nevaluation in the general domain. We evaluated the general capabilities of LLMs previously fine-tuned\non the OpenAI Health Bench Consensus subset using the MMLU benchmark. d: Forgetting evaluation\nin the general domain. We evaluated the general capabilities of LLMs previously fine-tuned on the\nOpenAI Health Bench Consensus subset using the CMMLU benchmark. e: In the biology domain,\nwe applied BFT (blue) and SFT (orange) to fine-tune DeepSeek-R1-Distill series (14B, 32B and\n70B). We evaluated LLMs on three biological process reasoning benchmarks. We evaluate ROUGE\nscores (recall-oriented understudy for gisting evaluation) between the generated final pathway names\nand ground truths, specifically ROUGE-L (longest common subsequence), ROUGE-1 (1-gram) and\nROUGE-2 (2-gram) scores. f: We compared the BFT-based DeepSeek-R1-Distill (70B) against the\nlatest baselines for biological process reasoning.\n4\n"}, {"page": 5, "text": "this issue, we evaluated models fine-tuned on the OpenAI Health Bench Consensus subset using two\nwidely recognized general-domain benchmarks: MMLU [13] and CMMLU [14].\nMMLU (Massive Multitask Language Understanding) evaluates broad knowledge and reasoning\nability across 57 academic subjects, including STEM (Science, Technology, Engineering, and\nMathematics), social sciences, humanities, and other professional domains. It is one of the most\nwidely used indicators of general reasoning capability in LLMs. CMMLU (Chinese Massive Multitask\nLanguage Understanding) is its Chinese counterpart, covering 67 subjects across similar categories,\ndesigned to measure both general knowledge and domain transfer capability in Chinese-language\nreasoning. Evaluating on both MMLU and CMMLU enables a comprehensive understanding of how\npost-training affects multilingual generalization and forgetting.\nAs shown in Figures 1c and 1d, BFT consistently mitigates general-domain forgetting compared to\nSFT across all three models (14B, 32B and 70B). For example, on MMLU, BFT achieves higher or\ncomparable scores to the base model, outperforming SFT across most subject categories, particularly\nin the social sciences and humanities. On CMMLU, BFT also maintains or improves accuracy relative\nto the base model, demonstrating its robustness in multilingual reasoning. These results indicate\nthat BFT effectively stabilizes gradients and preserves general knowledge during domain-specific\nalignment, achieving the trade-off between specialization and generalization.\n2.3.3\nBiology: BFT improves reasoning about biological processes\nIn the biology domain, we fine-tuned LLMs using both SFT and BFT. The training data construction\nprocess is as follows: NCBI text provided by GenePT [15] is used as the knowledge base, and\nGPT-OSS-120B [16] is employed to generate a dataset in the share-gpt format. Extended Data Figure\n3 illustrates examples of the constructed samples.\nWe then evaluated the fine-tuned models on biological process reasoning tasks. As shown in Figure 1e,\nacross all models and test datasets, LLMs fine-tuned with BFT demonstrate more accurate inference\nof biological processes, indicating that BFT enhances the biological knowledge of LLMs.\nAmong the three models, we chose DeepSeek-R1-Distill 70B, which has the most accurate reasoning\nresults. We compared the BFT-based 70B LLM with two latest baselines. As shown in Figure 1f,\nthe BFT-based LLM outperforms GeneAgent in biological process reasoning tasks, demonstrating\nstronger reasoning ability in gene interactions and related processes. Unlike GeneAgent, the BFT-\nbased LLM does not rely on external API calls and database access (such as OpenAI and NCBI), nor\ndoes it require the design of an agent scheduling process. This indicates that BFT has enabled LLM\nto learn biological knowledge.\nIn Extended Data Figure 4 and Extended Data Figure 5, we present examples of the ability of\nSFT-based and BFT-based LLMs to master gene knowledge and infer biological processes. In the first\nexample, while SFT provides a generic overview, BFT demonstrates superior biological granularity\nby identifying specific mechanisms like MHC II presentation and SARS-CoV-2 spike activation. BFT\nalso captures critical clinical insights missed by SFT, such as CTSL’s regulation by cystatin and its\nstatus as a potential therapeutic target. For a more detailed comparison, please refer to Extended Data\nTable 1. In the second example, the answer of BFT is more accurate, as it considers the biological\nfunctions of the gene more comprehensively, especially in terms of genome stability and nuclear\nlamina organization. However, the answer of SFT is overly simplified in terms of tumor growth\ninhibition and ignores the key role of the gene in cell structure and genome stability. For a more\ndetailed comparison, please refer to Extended Data Table 2.\n2.4\nBFT learns representations with biological meaning\n2.4.1\nGene-level task evaluation\nConsidering that many downstream biological tasks can be accomplished through representation\nlearning, we further examined whether the embeddings generated by BFT-based LLM capture\nbiological knowledge. As shown in Extended Data Figure 6a, we obtained response texts from BFT-\nbased LLM and generated their embeddings using Youtu-Embedding [17]. The UMAP visualization\nin Figure 2a shows that genes with similar biological functions form distinct clusters, indicating that\nBFT-based representations reflect biological heterogeneity at the gene level. Compared with scGPT\n[18] and GenePT [15], BFT-based embeddings exhibit more compact and biologically meaningful\n5\n"}, {"page": 6, "text": "Figure 2: BFT learns representations with biological meaning. a: UMAP visualization of gene\nembeddings. From left to right are the gene embeddings of scGPT, the text embeddings of gene\ndescriptions output by OpenAI ChatGPT, and the text embeddings of gene descriptions output by\nBFT-based DeepSeek-R1-Distill 70B. b: Representation evaluation at the gene level, with the task\ntype being single-gene input. The classifier takes a single gene embedding as input and predicts\nits biological attributes, such as long-range and short-range transcription factors, dosage-sensitive\nand dosage-insensitive transcription factors, bivalent and Lys4-only methylated genes, and bivalent\nand non-methylated genes. c: Representation evaluation at the gene level, with the task type being\nmulti-gene input. The embeddings of two genes or two proteins are concatenated, and the classifier\npredicts their interaction type. d: Representation evaluation at the cell level. On single-cell data, cell\nembeddings are obtained by aggregating gene embeddings, and the evaluation includes phenotypes\nand cell types. e: Comparison of multimodal integration at the cell level, with the goal of integrating\nthe two modalities of RNA and ADT. The three main columns (Bio conservation, Batch correction,\nand Aggregate score) respectively represent biological heterogeneity, modality mixing degree, and\nthe overall metric. Each main column contains specific sub-metrics. For the first two columns, the\ncolor gradient from purple to green indicates scores from low to high. f: Comparison of single-cell\nperturbation response prediction results, with zero-shot prediction conducted on four perturbation\ndatasets respectively.\n6\n"}, {"page": 7, "text": "clustering. While scGPT relies on large-scale biological pretraining and GenePT adapts ChatGPT\nwith high computational cost, BFT-based embeddings achieve strong biological meaning without\nrequiring any domain-specific data management.\nFor quantitative evaluation, we followed the benchmark established by GenePT to test two gene-level\ntasks. The first task predicts biological properties from a single-gene embedding, and the second\npredicts the interaction type from a pair of gene embeddings. As shown in Figures 2b–c, BFT-based\nembeddings achieve the best performance on both tasks. For multi-gene input tasks, the UMAP\nvisualization of classifier embeddings (Extended Data Figure 7) further demonstrates that BFT-based\nembeddings capture clearer biological heterogeneity. These results indicate that BFT enhances the\nability of LLMs to represent biological knowledge.\n2.4.2\nCell-level task evaluation\nWe further evaluated the potential of BFT in cell-level embedding representation. As shown in\nExtended Data Figure 6b, we directly obtained cell embeddings by weighted aggregation of single-\ncell expression data and gene embeddings. In Figure 2d, we evaluated the heterogeneity of cell\nembeddings using phenotypic labels and cell type labels respectively, and found that BFT-based\nembeddings perform the best. This result also reveals an interesting phenomenon: BFT-based\nembeddings outperform scGPT, a single-cell foundation model pre-trained with large-scale single-\ncell datasets. This indicates that BFT indeed has the ability to align LLMs with biological knowledge.\nIn Extended Data Figure 8, we used UMAP to compare the PCA embeddings of raw data and\nBFT-based embeddings. We found that BFT-based embeddings eliminate batch effects across patients\nand distinguishes clusters of different cell types.\nWe also evaluated the single-cell multi-modal integration task [19]. We used BFT-based LLM to\nobtain protein texts, then used Youtu-Embedding to generate protein embeddings, and obtained cell\nembeddings under the protein modality in the same way. After mixing with cell embeddings under\nthe RNA modality, we found that BFT-based embeddings have multi-modal integration ability. We\ncompared this method with mainstream integration methods such as BBKNN [20], Harmony [21],\nand scMODAL [22]. The integration performance of BFT is second only to scMODAL and far\nexceeds that of Harmony and BBKNN (Figure 2e). This indicates that BFT-based embeddings not\nonly preserve biological heterogeneity but also accurately align the two modalities. For the UMAP\nvisualization of the integration results, please refer to Extended Data Figure 9.\nBFT-based embeddings demonstrate excellent biological knowledge in cell atlases and have the\npotential to serve as a unified representation in virtual cells [23]. We applied BFT-based embeddings\nto virtual cells, where its main task is perturbation response prediction. We obtained cell embeddings\nby weighting the gene embeddings of BFT-based LLM, and then used these cell embeddings as the\ninput for the STATE [24] decoder. The experiment involved zero-shot prediction of perturbation\nresponses on four perturbation datasets [25]. Assuming HepG2 as the test set, we used RPE1, Jurkat,\nand K562 to train the decoder of STATE. The comparison methods included STATE-SE (standard\nSTATE: SE + ST) and STATE-small (a lightweight version of STATE). We observed that BFT-based\nembeddings achieve the same performance as the current state-of-the-art model STATE (Figure 2f).\nNotably, BFT-based embeddings can achieve performance consistent with that of standard STATE\nwithout incurring biological data management costs, and are expected to serve as the cornerstone for\nfuture virtual cell research. A systematic overview of biomedical tasks is provided in Extended Data\nTable 3, which details the biological significance, specific domain knowledge required, and current\nstate-of-the-art (SOTA) baselines (such as GeneAgent, GenePT, and STATE) for each task presented\nin Figure 1 and Figure 2.\n3\nDiscussion\nBalanced Fine-Tuning (BFT) is a general yet effective post-training method that enhances the learning\nstability and generalizability of LLMs, particularly in domains characterized by sparse and complex\nreasoning such as biomedical science. Unlike reinforcement learning (RL), BFT does not rely on\nexplicit reward functions or costly feedback loops; instead, it dynamically reweights gradients at\nboth the token and sample levels. This design allows BFT to stabilize optimization while adaptively\nemphasizing challenging examples, enabling efficient learning from limited biomedical supervision.\n7\n"}, {"page": 8, "text": "Although BFT itself is a domain-agnostic method, biomedical knowledge becomes integrated into the\nLLMs through the training data and the adaptive learning process it induces. Specifically, when BFT\nis applied to biomedical data, the model’s parameters are gradually reshaped to capture the causal\nand functional regularities embedded in biomedical language. The token-level stabilization prevents\noverfitting to fragmented biomedical facts, while the sample-level weighting encourages the model\nto focus on more uncertain or complex biomedical scenarios. This mechanism implicitly transfers\nbiomedical knowledge into the model’s internal representation space.\nOur experiments demonstrate that BFT improves reasoning and factual grounding in biomedical\ntasks while preserving general-domain competence. For example, models fine-tuned with BFT on\nthe OpenAI Health Bench not only achieve higher accuracy in medical reasoning but also exhibit\nreduced forgetting on general benchmarks such as MMLU and CMMLU. In the biological domain,\npost-training with BFT can encode biologically meaningful representations—gene embeddings\nderived from BFT-based LLM naturally cluster by functional categories and align across modalities,\noutperforming specialized biological foundation models. These results suggest that BFT facilitates\nthe internal organization of biomedical knowledge within the LLM’s parameter space.\nIn conclusion, BFT provides a lightweight, stable, and domain-adaptive framework for post-training\nLLMs on scientific data. It offers a practical route to integrate complex biomedical knowledge without\nspecialized architecture or costly reinforcement signals. More broadly, BFT bridges general-domain\nintelligence with domain-specific reasoning, advancing the development of intelligent agents capable\nof scientific understanding and discovery. However, we recognize that BFT serves to maximize\nthe utilization of available data, distinct from pre-training which injects massive new knowledge.\nConsequently, if the base LLM is entirely void of relevant biological knowledge, or if the quality\nof the fine-tuning data is compromised, BFT cannot compensate for this absence of foundational\ninformation.\n4\nMethod\nBalanced Fine-Tuning (BFT) method is an improvement based on Supervised Fine-Tuning (SFT).\nWe first describe SFT, followed by BFT.\n4.1\nSupervised Fine-Tuning (SFT)\nSupervised fine-tuning (SFT) is the standard approach for aligning large language models (LLMs)\nwith human-annotated data. Given a dataset D = {(x, y∗)} of instruction–response pairs, SFT\nminimizes the token-level cross-entropy loss:\nLSFT(θ) = E(x,y∗)∼D\n\u0002\n−log πθ(y∗| x)\n\u0003\n,\n(1)\nwhere πθ(y∗| x) is the model likelihood of the reference response. The gradient is:\n∇θLSFT(θ) = E(x,y∗)∼D\n\u0002\n−∇θ log πθ(y∗| x)\n\u0003\n.\n(2)\nThe reinforcement learning objective maximizes the expected reward:\nJ(θ) = Ex∼Dx,y∼πθ(·|x) [r(x, y)] ,\n(3)\nwith the policy gradient theorem yielding:\n∇θJ(θ) = Ex∼Dx,y∼πθ(·|x) [∇θ log πθ(y|x) · r(x, y)] .\n(4)\nApplying importance sampling to the SFT gradient:\n∇θLSFT(θ) = Ex∼DxEy∼πθ(·|x)\n\u0014δ(y, y∗)\nπθ(y|x) (−∇θ log πθ(y|x))\n\u0015\n,\n(5)\nwhere δ(y, y∗) is the Kronecker Delta function (1 when y = y∗, 0 otherwise).\n8\n"}, {"page": 9, "text": "Defining implicit reward and importance weight functions:\nrSFT(x, y) = δ(y, y∗), w(y|x) = πθ(y|x)−1\n(6)\nyields the RL-equivalent form:\n∇θLSFT(θ) = −Ex∼Dx,y∼πθ(·|x) [w(y|x)rSFT(x, y)∇θ log πθ(y|x)]\n(7)\nThe importance weight w(y|x) = πθ(y∗|x)−1 introduces instability:\n• Gradient explosion when πθ(y∗|x) →0+.\n• High-variance updates during early training phases.\n• Degraded generalization due to overemphasis on low-likelihood labels.\n4.2\nDynamic Fine-Tuning (DFT)\nDynamic Fine-Tuning (DFT) [26] reinterprets SFT from a reinforcement learning (RL) perspective.\nIn SFT, each token’s gradient implicitly includes a factor πθ(y∗|x)−1, which amplifies gradients for\nlow-probability tokens, leading to instability. To correct this, DFT multiplies the loss by πθ(y∗|x)\n(detached from gradient flow), effectively canceling the amplification:\nLDFT(θ) = E(x,y∗)∼D\n\n−\n|y∗|\nX\nt=1\nsg\n\u0000πθ(y∗\nt | y∗\n<t, x)\n\u0001\nlog πθ(y∗\nt | y∗\n<t, x)\n\n,\n(8)\nwhere sg(·) denotes the stop-gradient operator. DFT thus reweights token losses according to\nmodel confidence, stabilizing optimization and preventing gradient explosion. However, it can\noveremphasize already-confident samples and under-train difficult ones.\n4.3\nBalanced Fine-Tuning (BFT)\nWe introduce Balanced Fine-Tuning (BFT), which incorporates a sample-level confidence weighting\nscheme. Inspired by the group confidence mechanism from DeepConf [27], BFT balances training\nby up-weighting uncertain examples while preserving the stability of DFT.\nPer-token confidence\nFor each token t of sample b, given logits zb,t ∈RV (V is the vocabulary\nsize) and target token yb,t, we define token confidence as:\ncb,t = πθ(yb,t | yb,<t, xb) = softmax(zb,t)[yb,t].\n(9)\nGroup confidence\nWe measure local reasoning reliability by averaging token confidences within a\nsliding window Gi of length g:\nCGi =\n1\n|Gi|\nX\nt∈Gi\ncb,t.\n(10)\nOverlapping windows (stride = 1) ensure smooth local sensitivity to difficult spans.\nLowest group confidence\nThe weakest region of each sequence is characterized by its lowest group\nconfidence:\npconf\nb\n= min\nGi∈Gb CGi,\n(11)\nwhere Gb denotes the set of all overlapping token groups of sample b, each group Gi contains g\nconsecutive tokens (stride = 1).\n9\n"}, {"page": 10, "text": "Sample-level reweighting\nWe define each sample’s balance coefficient as:\nsb = 1 −pconf\nb\n,\n(12)\nwhich scales per-sample loss inversely with model confidence. Thus, sb ≈0 for confident examples\nand sb ≈1 for difficult ones.\nLet ℓb,t = −log πθ(yb,t | yb,<t, xb) and wb,t = exp(−ℓb,t) denote token-level DFT weights. BFT\nintegrates token- and sample-level weighting:\nLBFT(θ) = 1\nB\nB\nX\nb=1\nsb\nP\nt mb,t wb,t ℓb,t\nP\nt mb,t + ε\n,\n(13)\nwhere mb,t is the loss mask and ε is a small constant for numerical stability. B denotes the number\nof samples in the current mini-batch, mb,t ∈{0, 1} is the validity mask, ℓb,t is the token-level\ncross-entropy loss, and wb,t = exp(−ℓb,t) represents the token confidence weight. The sample-level\nscaling factor sb is derived from the lowest group confidence pconf\nb\nof sample b.\nInterpretation\nBFT unifies SFT, DFT, and confidence-weighted learning under a single framework:\nSFT: sb = 1, wb,t = 1;\nDFT: sb = 1;\nBFT: sb = 1 −pconf\nb\n.\nThis formulation encourages the model to concentrate on underconfident samples, enhancing robust-\nness and generalization while preserving DFT’s gradient stability.\nBFT introduces negligible computational overhead: it adds one sliding-window mean per sequence\n(implemented via conv1d) and one per-sample scalar weighting, remaining fully compatible with\nLoRA, mixed precision, and distributed training. A comparison of the algorithmic procedures for\nSFT and BFT is provided in Algorithm 1 and Algorithm 2, respectively.\nAlgorithm 1 SFT Training\n1: function SFT(θ, D)\n2:\ntotal_loss ←0\n3:\nfor (x, y∗) ∼D do\n4:\nlogits ←πθ(y∗| x)\n5:\nprobs ←softmax(logits)\n6:\nloss ←−log(probs)\n7:\ntotal_loss ←total_loss + loss\n8:\nend for\n9:\nreturn ∇θ(total_loss)\n10: end function\nAlgorithm 2 BFT Training\n1: function BFT(θ, D, g)\n2:\ntotal_loss ←0\n3:\nfor (x, y∗) ∼D do\n4:\nlogits ←πθ(y∗| x)\n5:\nprobs ←softmax(logits)\n6:\ngroups ←Conv1d(probs, kernel_size = g, stride = 1)\n▷Additional step\n7:\npconf\nb\n←min(groups)\n▷Additional step\n8:\nloss ←(1 −pconf\nb\n) · (−probs · log(probs))\n▷Additional step\n9:\ntotal_loss ←total_loss + loss\n10:\nend for\n11:\nreturn ∇θ(total_loss)\n12: end function\n10\n"}, {"page": 11, "text": "Data availability and code availability\nAll datasets used in this study are already published and were obtained from public data repositories.\nMathematical datasets are available at [https://github.com/yongliang-wu/DFT]. Healthcare\ndatasets are available at [https://openai.com/index/healthbench/]. NCBI texts are available\nat [https://github.com/yiqunchen/GenePT]. Biological process reasoning Benchmark are\navailable at [https://github.com/ncbi-nlp/GeneAgent]. Single-cell perturbation response\nprediction datasets are available at [https://github.com/ArcInstitute/state]. The code\nof this study is available at https://github.com/TencentAILabHealthcare/BFT or https:\n//git.woa.com/gelseywang/BFT.\nCompeting interests\nThe authors declare no competing interests.\nReferences\n[1] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Peiyi Wang, Qihao Zhu, Runxin Xu,\nRuoyu Zhang, Shirong Ma, Xiao Bi, et al. Deepseek-r1 incentivizes reasoning in llms through\nreinforcement learning. Nature, 645(8081):633–638, 2025.\n[2] Fenglin Liu, Hongjian Zhou, Boyang Gu, Xinyu Zou, Jinfa Huang, Jinge Wu, Yiru Li, Sam S\nChen, Yining Hua, Peilin Zhou, et al. Application of large language models in medicine. Nature\nReviews Bioengineering, pages 1–20, 2025.\n[3] Gokul Swamy, Sanjiban Choudhury, Wen Sun, Zhiwei Steven Wu, and J Andrew Bagnell. All\nroads lead to likelihood: The value of reinforcement learning in fine-tuning. arXiv preprint\narXiv:2503.01067, 2025.\n[4] Hongling Zheng, Li Shen, Anke Tang, Yong Luo, Han Hu, Bo Du, Yonggang Wen, and Dacheng\nTao. Learning from models beyond fine-tuning. Nature Machine Intelligence, 7(1):6–17, 2025.\n[5] Guangming Sheng, Chi Zhang, Zilingfeng Ye, Xibin Wu, Wang Zhang, Ru Zhang, Yanghua\nPeng, Haibin Lin, and Chuan Wu. Hybridflow: A flexible and efficient rlhf framework. In\nProceedings of the Twentieth European Conference on Computer Systems, pages 1279–1297,\n2025.\n[6] Paul F Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario Amodei. Deep\nreinforcement learning from human preferences. Advances in neural information processing\nsystems, 30, 2017.\n[7] Zhizheng Wang, Qiao Jin, Chih-Hsuan Wei, Shubo Tian, Po-Ting Lai, Qingqing Zhu, Chi-Ping\nDay, Christina Ross, Robert Leaman, and Zhiyong Lu. Geneagent: self-verification language\nagent for gene-set analysis using domain databases. Nature Methods, pages 1–9, 2025.\n[8] Jia LI, Edward Beeching, Lewis Tunstall, Ben Lipkin, Roman Soletskyi, Shengyi Costa Huang,\nKashif Rasul, Longhui Yu, Albert Jiang, Ziju Shen, Zihan Qin, Bin Dong, Li Zhou, Yann\nFleureau, Guillaume Lample, and Stanislas Polu. Numinamath. Hugging Face repository, 2024.\n[9] Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn\nSong, and Jacob Steinhardt. Measuring mathematical problem solving with the math dataset.\narXiv preprint arXiv:2103.03874, 2021.\n[10] Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay\nRamasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, et al. Solving quan-\ntitative reasoning problems with language models. Advances in neural information processing\nsystems, 35:3843–3857, 2022.\n[11] XTX Investments. Ai mathematical olympiad - progress prize 1. 2024. Kaggle.\n11\n"}, {"page": 12, "text": "[12] Rahul K Arora, Jason Wei, Rebecca Soskin Hicks, Preston Bowman, Joaquin Quiñonero-\nCandela, Foivos Tsimpourlas, Michael Sharman, Meghan Shah, Andrea Vallone, Alex Beutel,\net al. Healthbench: Evaluating large language models towards improved human health. arXiv\npreprint arXiv:2505.08775, 2025.\n[13] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and\nJacob Steinhardt. Measuring massive multitask language understanding. Proceedings of the\nInternational Conference on Learning Representations (ICLR), 2021.\n[14] Haonan Li, Yixuan Zhang, Fajri Koto, Yifei Yang, Hai Zhao, Yeyun Gong, Nan Duan, and\nTimothy Baldwin. Cmmlu: Measuring massive multitask language understanding in chinese.\nIn Findings of the Association for Computational Linguistics: ACL 2024, pages 11260–11285,\n2024.\n[15] Yiqun Chen and James Zou. Simple and effective embedding model for single-cell biology\nbuilt from chatgpt. Nature biomedical engineering, 9(4):483–493, 2025.\n[16] Sandhini Agarwal, Lama Ahmad, Jason Ai, Sam Altman, Andy Applebaum, Edwin Arbus,\nRahul K Arora, Yu Bai, Bowen Baker, Haiming Bao, et al. gpt-oss-120b & gpt-oss-20b model\ncard. arXiv preprint arXiv:2508.10925, 2025.\n[17] Bowen Zhang, Zixin Song, Chunquan Chen, Qian-Wen Zhang, Di Yin, and Xing Sun. Codiemb:\nA collaborative yet distinct framework for unified representation learning in information retrieval\nand semantic textual similarity. arXiv preprint arXiv:2508.11442, 2025.\n[18] Haotian Cui, Chloe Wang, Hassaan Maan, Kuan Pang, Fengning Luo, Nan Duan, and Bo Wang.\nscgpt: toward building a foundation model for single-cell multi-omics using generative ai.\nNature methods, 21(8):1470–1480, 2024.\n[19] Zhenchao Tang, Guanxing Chen, Shouzhi Chen, Jianhua Yao, Linlin You, and Calvin Yu-Chian\nChen. Modal-nexus auto-encoder for multi-modality cellular data integration and imputation.\nNature Communications, 15(1):9021, 2024.\n[20] Krzysztof Pola´nski, Matthew D Young, Zhichao Miao, Kerstin B Meyer, Sarah A Teichmann,\nand Jong-Eun Park. Bbknn: fast batch alignment of single cell transcriptomes. Bioinformatics,\n36(3):964–965, 2020.\n[21] Ilya Korsunsky, Nghia Millard, Jean Fan, Kamil Slowikowski, Fan Zhang, Kevin Wei, Yuriy\nBaglaenko, Michael Brenner, Po-ru Loh, and Soumya Raychaudhuri. Fast, sensitive and\naccurate integration of single-cell data with harmony. Nature methods, 16(12):1289–1296,\n2019.\n[22] Gefei Wang, Jia Zhao, Yingxin Lin, Tianyu Liu, Yize Zhao, and Hongyu Zhao. scmodal: a\ngeneral deep learning framework for comprehensive single-cell multi-omics data alignment\nwith feature links. Nature Communications, 16(1):4994, 2025.\n[23] Charlotte Bunne, Yusuf Roohani, Yanay Rosen, Ankit Gupta, Xikun Zhang, Marcel Roed, Theo\nAlexandrov, Mohammed AlQuraishi, Patricia Brennan, Daniel B Burkhardt, et al. How to build\nthe virtual cell with artificial intelligence: Priorities and opportunities. Cell, 187(25):7045–7063,\n2024.\n[24] Abhinav K Adduri, Dhruv Gautam, Beatrice Bevilacqua, Alishba Imran, Rohan Shah, Mohsen\nNaghipourfar, Noam Teyssier, Rajesh Ilango, Sanjay Nagaraj, Mingze Dong, et al. Predicting\ncellular responses to perturbation across diverse contexts with state. bioRxiv, pages 2025–06,\n2025.\n[25] Yusuf H Roohani, Tony J Hua, Po-Yuan Tung, Lexi R Bounds, Feiqiao B Yu, Alexander Dobin,\nNoam Teyssier, Abhinav Adduri, Alden Woodrow, Brian S Plosky, et al. Virtual cell challenge:\nToward a turing test for the virtual cell. Cell, 188(13):3370–3374, 2025.\n[26] Yongliang Wu, Yizhou Zhou, Zhou Ziheng, Yingzhe Peng, Xinyu Ye, Xinting Hu, Wenbo Zhu,\nLu Qi, Ming-Hsuan Yang, and Xu Yang. On the generalization of sft: A reinforcement learning\nperspective with reward rectification. arXiv preprint arXiv:2508.05629, 2025.\n[27] Yichao Fu, Xuewei Wang, Yuandong Tian, and Jiawei Zhao. Deep think with confidence. arXiv\npreprint arXiv:2508.15260, 2025.\n12\n"}, {"page": 13, "text": "Extended data figure\nExtended Data Figure 1: Ablation study. a: Test results on different mathematical reasoning datasets.\nWe set two baselines: the red dashed line represents SFT, and the blue dashed line represents\nreinforcement learning (represented by GRPO). BFT includes three window length settings (BFT-128,\nBFT-256, and BFT-512). BFT w/o sample denotes removing the sample-level weighting mechanism\nfrom BFT (this setting does not require a sliding window). BFT w/o token denotes removing the\ntoken-level weighting mechanism from BFT (this setting requires a sliding window). b: Tracking the\nreasoning performance of BFT (with different window length settings) within 1 training epoch.\n13\n"}, {"page": 14, "text": "Extended Data Figure 2: The training runtime (unit: seconds) and evaluation scores of different\nmethods. BFT includes three window length settings (128, 256, and 512), and the comparison\nmethods include SFT and Focal loss. The training runtime of BFT is close to that of SFT, while its\nevaluation score is far higher than that of SFT.\n14\n"}, {"page": 15, "text": "Extended Data Figure 3: This case demonstrates how to generate biological training data from an\nNCBI gene summary. The black text represents the prompt template, the blue text corresponds to the\ninput text following the template (e.g., the gene summary of TP53), and the orange text shows the\nthree GPT-generated training samples in SFT format.\nExtended Data Figure 4: This case examines LLMs’ mastery of genetic knowledge. The black text is\nthe user prompt, the blue text is SFT response, and the orange text is BFT response.\n15\n"}, {"page": 16, "text": "Extended Data Figure 5: This case examines the reasoning ability of LLMs regarding biological\nprocesses. The black text is the user prompt, the blue text is SFT response, and the orange text is\nBFT response.\nExtended Data Figure 6: Workflow for extracting biological embeddings from LLM-BFT. a: LLM-\nBFT generates responses based on entities of interest (e.g., a specific gene). The textual description\nof the gene is input into Tencent Youtu-Embedding to obtain gene embeddings. b: For a single-cell\ndataset, gene embeddings are weighted by gene expression values to generate cell embeddings.\n16\n"}, {"page": 17, "text": "Extended Data Figure 7: UMAP visualization of the multi-gene input task. a: For GGI, the input\nembedding of the classifier is directly concatenated from the embeddings of two genes. b: For PPI,\nthe input embedding of the classifier is directly concatenated from the embeddings of two proteins.\nExtended Data Figure 8: UMAP visualization of cell-level embeddings. a: PCA embeddings of\nthe raw data, colored by cell type labels (cell type heterogeneity), patient labels (batch labels), and\nphenotype labels (disease heterogeneity), respectively. b: Cell embeddings derived from LLM-BFT,\ncolored by cell type labels (cell type heterogeneity), patient labels (batch labels), and phenotype\nlabels (disease heterogeneity), respectively.\n17\n"}, {"page": 18, "text": "Extended Data Figure 9: UMAP visualization of single-cell multimodal data integration results.\nRows 1 to 4 represent different integration methods, respectively. Columns 1 to 3 correspond to\ndifferent coloring labels (modality, cell type, and donor), respectively.\n18\n"}, {"page": 19, "text": "Extended data table\nExtended Data Table 1: Comparison of SFT and BFT Responses to the \"Tell me about gene CTSL\"\nPrompt.\nFeature\nSFT Response (Less\nAccurate)\nBFT\nResponse\n(More Accurate)\nSummary of Differ-\nences\nGene Classification\nLysosomal cysteine\nprotease.\nLysosomal cysteine\nprotease, belonging\nto the papain-like\nfamily.\nBFT\nprovides\nthe\nmore precise family\ninformation (Papain-\nlike family), which is\ndatabase-level detail.\nMaturation Process\nSynthesized as inac-\ntive precursor, acti-\nvated in acidic lyso-\nsomes.\nSynthesized as inac-\ntive preproenzyme,\nactivated\nin\nacidic\nlysosomes, and regu-\nlated by cystatin in-\nhibitors.\nBFT distinguishes be-\ntween precursor and\npreproenzyme, and\nadds the key regu-\nlatory factor (Cys-\ntatin).\nImmune Function\nInvolved in antigen\nprocessing.\nInvolved in antigen\nprocessing for MHC\nII presentation.\nBFT’s description is\nmore specific, clarify-\ning CTSL’s exact role\nin adaptive immunity.\nExtracellular Function\nInvolved\nin\nECM\nremodeling,\nbone\nresorption,\nand\nkeratinocyte differen-\ntiation.\nCan be secreted ex-\ntracellularly and has\nextracellular activity;\npromotes bone re-\nsorption.\nBFT explicitly men-\ntions the important\ncharacteristic of \"se-\ncretion\", while SFT\nonly lists extracellu-\nlar activities.\nDisease Association\nAssociated with can-\ncer progression, in-\nflammatory diseases,\nand some lysosomal\nstorage disorders.\nOverexpression pro-\nmotes cancer inva-\nsion and metastasis,\ncorrelates with poor\nprognosis, and is im-\nplicated in neurode-\ngeneration.\nBFT’s\ndisease\ndescription\nis\ndeeper, including the\nmechanism\n(inva-\nsion/metastasis) and\nclinical\nrelevance\n(poor\nprognosis),\nwhile excluding the\nvague\n\"lysosomal\nstorage disorders\".\nViral Infection Role\nAlso contributes to\nviral\nentry\nmech-\nanisms for certain\npathogens.\nActivates\nviral\nglycoproteins (e.g.,\nSARS-CoV-2 spike\nprotein), facilitating\nviral entry.\nBFT\nprovides\nthe\nspecific mechanism\n(glycoprotein activa-\ntion) and example\n(SARS-CoV-2 spike\nprotein),\nwhich is\nmuch more valuable\nthan SFT’s general\nstatement.\nTherapeutic Potential\nNot mentioned.\nIs a therapeutic tar-\nget; inhibitors are un-\nder development.\nBFT\nexplicitly\nde-\nfines its status as a\ndrug target, a key\npiece of information\nmissed by SFT.\n19\n"}, {"page": 20, "text": "Extended Data Table 2: Comparison between BFT, SFT, and Real Research on the biological process\nreasoning form gene set: ZMPSTE24, BANF1, WRN, LMNA.\nGene\nBFT (Correct)\nSFT (Incorrect)\nReal Research\nLMNA\nEncodes Lamin A/C,\nmajor structural com-\nponents of the nuclear\nlamina.\nA protein component\nof the \"ininklingia\ncomplex\" that medi-\nates RNAi.\nEncodes\nLamin\nA/C,\nthe\nprimary\nstructural proteins of\nthe nuclear lamina\n(the ’scaffold’ of the\nnucleus).\nZMPSTE24\nA zinc metallopro-\ntease that cleaves pre-\nlamin A to its mature\nform.\nA protein kinase that\nregulates cell growth\nvia the RAS-MAPK\npathway.\nA\nmetalloprotease\nwhose\nonly\nmajor\nknown\nrole\nis\nto\nperform\nthe\nfinal\nprocessing step on\npre-lamin\nA\n(the\nLMNA product).\nWRN\nA RecQ helicase (a\nprotein)\ninvolved\nin DNA repair and\ntelomere\nmainte-\nnance.\nA non-coding RNA\nscaffold for RNA in-\nterference (RNAi).\nA\nprotein-coding\ngene.\nThe WRN\nprotein is a DNA\nhelicase\nessential\nfor DNA repair and\ngenome stability.\nBANF1\nA DNA-binding pro-\ntein that bridges chro-\nmatin to the nuclear\nenvelope.\nA transcription factor\nthat activates genes\nlike cyclin D1/E2.\nA\nstructural\nDNA-\nbinding protein that is\nessential for nuclear\nenvelope reassembly\nafter mitosis and for\nanchoring chromatin\nto the inner nuclear\nmembrane.\nOverall Process\nNuclear lamina orga-\nnization and genome\nstability.\nSuppression of tumor\ngrowth via gene si-\nlencing.\nMaintenance\nof\nnuclear\nenvelope\nintegrity and genome\nstability (This path-\nway\nis\ncentral\nto\nhuman\npremature\naging syndromes).\n20\n"}, {"page": 21, "text": "Extended Data Table 3: Overview of biomedical tasks evaluated in this study, detailing their biological\nsignificance, required knowledge domains, and state-of-the-art (SOTA) baselines.\nTask\nName\n(Benchmark)\nBiological Significance\nKnowledge Required\nCurrent SOTA /\nBaseline\nMedical\nRea-\nsoning (OpenAI\nHealth\nBench\n[12])\nCritical for developing clini-\ncal decision support systems.\nEvaluating on ’Hard’ subsets\ntests reliability in real-world\nclinical scenarios.\nClinical guidelines, diagnos-\ntic logic, symptomatology,\nand ability to handle ambigu-\nous medical data.\nGPT 5 Pro.\nBiological\nPro-\ncess\nReasoning\n(GeneAgent [7])\nEssential for understanding\nmolecular mechanisms of\ndisease and identifying drug\ntargets. Requires inferring a\nspecific biological pathway\nfrom a set of genes.\nHigh-level biological reason-\ning, understanding of gene-\ngene relationships, and func-\ntional pathway organization.\nGeneAgent [7].\nGene Attribute\nPrediction\n(GenePT [15])\nPredicts intrinsic properties\nlike\ndosage\nsensitivity,\nmethylation\nstatus\n(biva-\nlency),\nand\ntranscription\nfactor range. Crucial for un-\nderstanding gene regulation\nand epigenetics.\nEpigenetic states, transcrip-\ntional regulatory logic, and\ngene dosage effects.\nGenePT [15].\nInteraction Pre-\ndiction (GenePT\n[15])\nPredicts Gene-Gene Inter-\nactions (GGI) and Protein-\nProtein Interactions (PPI).\nFundamental for mapping\ncellular signaling networks\nand protein complexes.\nPhysical\nand\nfunctional\nconnectivity\nbetween\nbiomolecules; co-expression\npatterns.\nGenePT [15].\nSingle-cell\nMulti-modal In-\ntegration (Monae\n[19])\nIntegrates\ntranscriptomic\n(RNA) and proteomic (ADT)\ndata.\nVital for resolving\ncellular heterogeneity and\ncreating unified cell atlases.\nCross-modal\ncorrelations\n(Central\nDogma:\nRNA\n→\nProtein)\nand\nnoise\ndistribution\nin\nsingle-cell\nsequencing.\nscMODAL [22].\nPerturbation\nResponse\nPre-\ndiction (STATE\n[24])\nPredicts how cells change\nafter\ngenetic\n(CRISPR)\nor chemical perturbations.\nServes as the cornerstone for\n\"Virtual Cell\" modeling and\nin silico drug screening.\nCausal gene regulatory net-\nworks;\ndynamic response\nmechanisms to external stim-\nuli.\nSTATE [24].\n21\n"}]}