{"doc_id": "arxiv:2511.10912", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2511.10912.pdf", "meta": {"doc_id": "arxiv:2511.10912", "source": "arxiv", "arxiv_id": "2511.10912", "title": "Evaluating Large Language Models on Rare Disease Diagnosis: A Case Study using House M.D", "authors": ["Arsh Gupta", "Ajay Narayanan Sridhar", "Bonam Mingole", "Amulya Yadav"], "published": "2025-11-14T02:54:58Z", "updated": "2025-11-14T02:54:58Z", "summary": "Large language models (LLMs) have demonstrated capabilities across diverse domains, yet their performance on rare disease diagnosis from narrative medical cases remains underexplored. We introduce a novel dataset of 176 symptom-diagnosis pairs extracted from House M.D., a medical television series validated for teaching rare disease recognition in medical education. We evaluate four state-of-the-art LLMs such as GPT 4o mini, GPT 5 mini, Gemini 2.5 Flash, and Gemini 2.5 Pro on narrative-based diagnostic reasoning tasks. Results show significant variation in performance, ranging from 16.48% to 38.64% accuracy, with newer model generations demonstrating a 2.3 times improvement. While all models face substantial challenges with rare disease diagnosis, the observed improvement across architectures suggests promising directions for future development. Our educationally validated benchmark establishes baseline performance metrics for narrative medical reasoning and provides a publicly accessible evaluation framework for advancing AI-assisted diagnosis research.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2511.10912v1", "url_pdf": "https://arxiv.org/pdf/2511.10912.pdf", "meta_path": "data/raw/arxiv/meta/2511.10912.json", "sha256": "26fcc9a27e443c7d066f140d10138a5585d11bfa16f73ec254a8d2e2ebd97935", "status": "ok", "fetched_at": "2026-02-18T02:27:06.608594+00:00"}, "pages": [{"page": 1, "text": "Evaluating Large Language Models on Rare Disease Diagnosis: A Case Study\nusing House M.D.\nArsh Gupta 1, Ajay Narayanan Sridhar 1, Bonam Mingole 1, Amulya Yadav 1\n1The Pennsylvania State University\nabg6210@psu.edu, afs6372@psu.edu, bjm6940@psu.edu, amulya@psu.edu\nAbstract\nLarge language models (LLMs) have demonstrated capabil-\nities across diverse domains, yet their performance on rare\ndisease diagnosis from narrative medical cases remains un-\nderexplored. We introduce a novel dataset of 176 symptom-\ndiagnosis pairs extracted from House M.D., a medical tele-\nvision series validated for teaching rare disease recognition\nin medical education. We evaluate four state-of-the-art LLMs\nsuch as GPT 4o mini, GPT 5 mini, Gemini 2.5 Flash, and\nGemini 2.5 Pro on narrative-based diagnostic reasoning tasks.\nResults show significant variation in performance, ranging\nfrom 16.48% to 38.64% accuracy, with newer model gener-\nations demonstrating a 2.3× improvement. While all models\nface substantial challenges with rare disease diagnosis, the\nobserved improvement across architectures suggests promis-\ning directions for future development. Our educationally val-\nidated benchmark establishes baseline performance metrics\nfor narrative medical reasoning and provides a publicly ac-\ncessible evaluation framework for advancing AI-assisted di-\nagnosis research.\nIntroduction\nThe rapid advancement of large language models (LLMs)\nhas opened new opportunities for applying natural lan-\nguage understanding to complex domains requiring reason-\ning under uncertainty (Jerrentrup et al. 2015; Mechler et al.\n2017; Sanges et al. 2018). In healthcare, accurate diagno-\nsis from patient-reported symptoms remains a critical chal-\nlenge where LLMs could provide value for clinical decision\nsupport and medical education. However, evaluating LLM\nperformance in medical diagnosis faces significant barriers\ndue to privacy constraints, limited dataset availability, and\nthe formalized nature of existing medical datasets.\nMedical television dramas, particularly House M.D., of-\nfer a unique solution by providing rich, case-based scenar-\nios where symptoms and diagnostic outcomes are clearly\ndescribed in narrative form (Jerrentrup et al. 2015; Mech-\nler et al. 2017; Cambra-Badii et al. 2020). The educational\nvalue of House M.D. has been well-established, with suc-\ncessful use in medical education to teach about rare dis-\neases and clinical reasoning (Jerrentrup et al. 2015; Mechler\net al. 2017). Research shows that 49.6% of health sciences\nCopyright © 2026, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\nstudents watch medical dramas regularly, and these shows\neffectively convey medical knowledge (Cambra-Badii et al.\n2020).\nIn this work, we evaluate LLM performance on symptom-\nto-diagnosis prediction using a novel dataset of 176 cases\nconstructed from House M.D. episodes. Each case pairs\nsymptom descriptions with corresponding disease diag-\nnoses, demanding that models identify medical clues within\nnarrative descriptions, closely mirroring clinical practice.\nOur dataset is publicly available on Kaggle1\nOur work addresses three challenges: (i) general-purpose\nLLMs lack specialization for narrative medical reasoning,\n(ii) available datasets rarely capture narrative-driven diag-\nnostic structure, and (iii) limited dataset sizes raise gen-\neralizability concerns. We evaluate multiple state-of-the-art\nLLMs like GPT 5 Mini (OpenAI 2025), GPT 4o Mini (Ope-\nnAI 2024), Gemini 2.5 Flash (DeepMind 2025a), and Gem-\nini 2.5 Pro (DeepMind 2025b) to assess diagnostic reasoning\ncapabilities across different architectures. Our experiments\nreveal modest performance on rare disease diagnostic tasks,\nhighlighting domain-specific challenges in medical reason-\ning from narrative cases.\nOur contributions are: (1) a novel dataset of symptom-\ndisease mappings from publicly available narrative cases\nreflecting clinical reasoning patterns, and (2) comprehen-\nsive baseline evaluation across multiple LLM architectures\ndemonstrating current limitations in narrative medical rea-\nsoning.\nResults establish clear performance baselines across dif-\nferent model families, indicating that narrative-based rare\ndisease diagnosis remains a significant challenge for cur-\nrent LLMs. These findings suggest that educationally vali-\ndated medical narratives can serve as valuable benchmarks\nfor measuring LLM diagnostic capabilities, establishing a\nfoundation for future research in AI-assisted medical diag-\nnosis and highlighting the need for domain-specific adapta-\ntions.\nRelated Work\nMedical television dramas have gained recognition as effec-\ntive educational tools with structured narrative formats suit-\nable for both human learning and machine learning applica-\n1https://bit.ly/4p9ltW8\narXiv:2511.10912v1  [cs.CL]  14 Nov 2025\n"}, {"page": 2, "text": "tions. Jerrentrup et al. (Jerrentrup et al. 2015) demonstrated\nthat House M.D. can be successfully integrated into medical\ncurricula for teaching rare diseases and complex diagnostic\nscenarios. Cambra-Badii et al. (Cambra-Badii et al. 2020)\nfound that 49.6% of health sciences students regularly watch\nmedical dramas, with House M.D. among the most popular,\nand that these shows effectively teach bioethical and profes-\nsional practice issues.\nSanges et al. (Sanges et al. 2018) and Sarrafpour et\nal. (Sarrafpour et al. 2019) validated case-based learning for\nrare disease education, showing significant improvements\nin students’ diagnostic recognition abilities. These findings\nsuggest that structured symptom-diagnosis relationships in\nnarrative medical content may provide valuable evaluation\ndata for AI systems reasoning through clinical presentations.\nBeyond educational validation, studies have highlighted\nthe unique coverage of rare diseases in medical television.\nMechler et al. (Mechler et al. 2017) analyzed orphan dis-\neases featured in House M.D., showing the series frequently\npresents rare diseases seldom encountered in training, mak-\ning it valuable for both medical students and AI diagnostic\nevaluation.\nSchaefer and von Hirschhausen (Schaefer and von\nHirschhausen 2016) demonstrated that medical television\nhelps viewers recognize symptoms and seek appropriate\nconsultation. Furman and Clayton (Furman and Clayton\n2015) analyzed genetic concepts in medical shows, high-\nlighting that narrative case presentations closely parallel di-\nagnostic reasoning challenges, suggesting clear utility for\nevaluating automated diagnostic systems.\nRecent advances emphasize simulation and case-based\nlearning approaches mirroring structured narratives in med-\nical television. Rattani et al. (Rattani et al. 2019) identified\nnarrative methods as particularly effective for complex sce-\nnarios, while Rasul et al. (Rasul et al. 2021) validated real-\nscenario approaches in medical education. These studies\ndemonstrate that well-structured narrative cases effectively\nbridge theoretical knowledge and practical application, in-\ndicating their potential for evaluating LLMs on diagnostic\nreasoning patterns.\nWhile existing literature supports the educational value of\nmedical television for human learners, limited research ex-\nplores its application to machine learning systems. Our work\naddresses this gap by systematically extracting symptom-\ndiagnosis pairs from House M.D. episodes and evaluating\nLLM diagnostic capabilities across multiple architectures,\nextending established educational value of medical narra-\ntives to AI evaluation.\nDataset Creation\nWe constructed our dataset from the publicly available\nHouse M.D. wiki (https://house.fandom.com), extracting\nnarrative content from all 176 episodes across eight seasons.\nThe data extraction involved three stages: (1) web scrap-\ning using BeautifulSoup (Richardson 2024), which\nallows for robust parsing of HTML content, (2) struc-\ntured prompt generation where each evaluated model (GPT-\n4o mini (OpenAI 2024), GPT-5 Mini (OpenAI 2025), Gem-\nini 2.5 Flash (DeepMind 2025a), Gemini 2.5 Pro (DeepMind\n2025b) independently transforms raw narrative episodes into\nstandardized medical case formats, and (3) quality filtering\nto ensure clinical detail, diagnostic clarity, and alignment\nwith real-world medical reasoning (Jerrentrup et al. 2015;\nCambra-Badii et al. 2020; Sanges et al. 2018).\nOur final dataset consists of 176 symptom-diagnosis pairs\nspanning diverse medical specialties, with emphasis on com-\nplex diagnostic scenarios requiring multi-step reasoning.\nThe complete dataset and model evaluation results are pub-\nlicly available on Kaggle and GitHub.2\nEducational Validation: Jerrentrup et al. (Jerrentrup\net al. 2015) demonstrated successful integration of House\nM.D. into medical curricula for teaching rare disease recog-\nnition.\nRare Disease Coverage: Mechler et al. (Mechler et al.\n2017) found the show frequently features orphan diseases\nunderrepresented in traditional medical datasets, addressing\na gap in medical AI evaluation benchmarks.\nClinical Realism: Despite dramatic elements, the show\nemploys medical consultants to ensure clinical accuracy and\nfollows a consistent diagnostic framework mirroring prac-\ntice.\nAccessibility: Unlike proprietary medical datasets, House\nM.D. content is publicly available, enabling reproducible re-\nsearch while avoiding ethical constraints of real patient data.\nNarrative Context: The narrative format preserves\ntemporal\nsymptom\nprogression,\ndemographics,\nand\nclinical\ndecision-making\nthat\nstructured\ndatasets\nof-\nten lose (Cambra-Badii et al. 2020; Schaefer and von\nHirschhausen 2016).\nWhile our dataset reflects limitations of fictional con-\ntent, including dramatic exaggeration and complex case fo-\ncus, these characteristics may benefit evaluation by pro-\nviding challenging edge cases that test model robustness.\nThe educational validation of House M.D. by medical\nprofessionals provides confidence that extracted scenarios\ncontain clinically meaningful information suitable for AI\nevaluation (Cambra-Badii et al. 2020; Schaefer and von\nHirschhausen 2016).\nMethodology\nWe designed a straightforward evaluation pipeline to as-\nsess LLM performance on symptom-to-diagnosis predic-\ntion tasks across multiple model architectures, consisting of\nprompt construction, model inference, and evaluation met-\nrics.\nStage\nProcess\nExample\nExact\nMatch\nPrediction\nin\nground truth\nLupus in Systemic Lu-\npus\nFuzzy\nMatch\nToken\nsimilarity\n(thresh. = 0.8)\nSarcoidosis ≈Sarcoid\n(0.89)\nClassif.\nBinary outcome\nCorrect / Incorrect\nTable 1: Fuzzy matching workflow\n2Code: https://bit.ly/481OSuD, https://bit.ly/4oCxqnj;\nDataset: https://bit.ly/4p9ltW8;\nResults: https://bit.ly/3JYGEeG, https://bit.ly/47FHXs1\n"}, {"page": 3, "text": "Input: House M.D. Episode Content\n↓\nExtract Symptoms & Create Prompt\n↓\nLLM Inference →Predicted Diagnosis\n↓\nFuzzy String Matching vs. Ground Truth\n↓\nOutput: Binary Accuracy Score (Correct/Incorrect)\nFigure 1: Evaluation pipeline for LLM-based diagnosis\nModel Selection and Configuration\nWe evaluated four state-of-the-art LLMs: GPT-4o Mini,\nGPT-5 Mini, Gemini 2.5 Flash, and Gemini 2.5 Pro. This se-\nlection spans different model families (OpenAI and Google)\nand capability levels, enabling assessment of diagnostic rea-\nsoning across various architectures and training approaches.\nThe model was configured with standard parameters: tem-\nperature set to 0.0 to ensure deterministic outputs, maximum\ntoken length of 1500 to accommodate detailed diagnostic\nreasoning, and no additional system prompts beyond the di-\nagnostic instruction to avoid introducing bias toward specific\nmedical frameworks.\nPrompt Design and Inference\nOur prompts follow a structured medical case presentation\nformat designed to simulate realistic clinical scenarios. Each\nprompt contains patient demographic information, symptom\ndescriptions with temporal progression, relevant medical\nhistory, and initial diagnostic workup results. The prompts\nexplicitly request a single primary diagnosis while encour-\naging the model to provide supporting reasoning.\nFor each case, models generate diagnostic responses in\na single-pass approach without iterative refinement. Model\nresponses were collected systematically across all 176 cases\nwith consistent experimental conditions.\nPrompt\nGround Truth Disease\n”A\n27-year-old\nmale\npresents to the ER after\nan\nepisode\nof\nacute\naphonia\nand\nsyncope\nduring\nhis\nwedding\nceremony. Initially, ma-\nlingering was suspected,\nbut\nhe\nsubsequently\ndeveloped a productive\ncough,\ncyanosis,\nand\nwas found to have a\npleural\neffusion.\nHis\nworkup revealed a posi-\ntive mononucleosis test,\nwhich is atypical for his\nage......”\nArnold-Chiari malforma-\ntion\nTable 2: Example evaluation case from Gemini 2.5 Pro\nshowing only a portion of the Prompt and Ground Truth Dis-\nease.\nEvaluation Metrics\nWe evaluated predictions using fuzzy string matching\nagainst ground truth diagnoses, addressing the challenge that\nmedical conditions have multiple valid names. Our algo-\nrithm employs Python’s SequenceMatcher with a 0.8\nsimilarity threshold, performing exact substring matching\nfirst, then token-wise fuzzy comparison. Final accuracy is\ncomputed as the proportion of correctly classified cases, pro-\nviding clear performance benchmarks while accommodat-\ning medical terminology ambiguity.\nLimitations\nOur methodology has acknowledged limitations. Fuzzy\nmatching may miss semantically equivalent diagnoses us-\ning substantially different terminology, and the binary met-\nric may not capture partial credit for related diagnoses.\nHowever, our approach provides a systematic and repro-\nducible framework for evaluating LLM diagnostic perfor-\nmance across multiple architectures.\nResults\nOverall Performance\nWe evaluated four state-of-the-art LLMs on our House M.D.\ndiagnostic dataset using fuzzy string matching. Table 3 sum-\nmarizes the accuracy across all models.\nModel\nCorrect\nAccuracy (%)\nGPT-4o-mini\n29/176\n16.48\nGemini 2.5 Flash\n58/176\n32.95\nGPT-5-mini\n65/176\n36.93\nGemini 2.5 Pro\n68/176\n38.64\nTable 3: Diagnostic accuracy across LLM models\nPerformance varied significantly across model architec-\ntures, with Gemini 2.5 Pro achieving the highest accuracy\nat 38.64%, followed by GPT-5 Mini at 36.93%, Gemini 2.5\nFlash at 32.95%, and GPT-4o Mini at 16.48%. Despite these\ndifferences, all models demonstrated substantial challenges\nwith rare disease diagnostic reasoning.\nPerformance Analysis\nPerformance varied not only across models but also across\nseasons, as shown in Table 4. Season 1 achieved the highest\naccuracy at 56.52%, while Season 5 showed the lowest at\n20.83%. This variation suggests that diagnostic complexity\nvaries throughout the series, with later seasons potentially\nfeaturing more challenging rare disease cases. However, the\nrelatively strong performance in Season 8 (52.38%) indi-\ncates that temporal progression alone does not fully explain\naccuracy differences rather case-specific diagnostic com-\nplexity appears to be the primary driver.\nAcross all models, performance was better on com-\nmon conditions with distinctive symptom presentations\n(meningitis, myocardial infarction, pulmonary embolism).\nAll models struggled with rare diseases (neurocysticercosis,\n"}, {"page": 4, "text": "Season\nEpisodes\nCorrect\nAccuracy (%)\nSeason 1\n23\n13\n56.52\nSeason 2\n24\n7\n29.17\nSeason 3\n24\n8\n33.33\nSeason 4\n16\n7\n43.75\nSeason 5\n24\n5\n20.83\nSeason 6\n21\n8\n38.10\nSeason 7\n23\n9\n39.13\nSeason 8\n21\n11\n52.38\nTable 4: Per-season diagnostic accuracy for Gemini 2.5 Pro\nErdheim-Chester disease), multi-system autoimmune disor-\nders (systemic lupus erythematosus, sarcoidosis), and tox-\nicological cases requiring integration of exposure history\nwith clinical presentation.\nThe performance gap between models suggests that\narchitectural differences and training approaches signifi-\ncantly impact diagnostic reasoning capabilities. GPT-5-mini\nand Gemini 2.5 Pro’s superior performance indicates that\nnewer model generations with enhanced reasoning capabil-\nities show meaningful improvements over earlier versions,\nthough substantial limitations remain.\nImplications\nThese results establish important baseline performance met-\nrics for narrative-based rare disease diagnosis and demon-\nstrate that current LLMs show promising capabilities in\nmedical reasoning tasks. The improvement from GPT-4o\nMini (16.48%) to Gemini 2.5 Pro (38.64%) indicates that the\nfield is making meaningful progress toward clinically useful\nAI diagnostic systems. While absolute accuracy levels in-\ndicate room for improvement, it is important to contextual-\nize these results: our benchmark exclusively features diag-\nnostically challenging cases that often puzzle expert physi-\ncians, representing a substantially harder evaluation task\nthan typical medical AI benchmarks. The ability to cor-\nrectly diagnose nearly 40% of these exceptionally difficult\ncases demonstrates meaningful medical reasoning capabil-\nities and establishes a solid foundation for future improve-\nments through domain-specific fine-tuning, integration with\nmedical knowledge bases, or hybrid reasoning approaches.\nDiscussion\nOur results demonstrate significant variation in LLM di-\nagnostic reasoning capabilities, with performance ranging\nfrom 16.48% (GPT-4o Mini) to 38.64% (Gemini 2.5 Pro).\nThis 2.3× improvement highlights rapid progress in medical\nreasoning, though rare disease diagnosis remains challeng-\ning for current general-purpose LLMs (Schaefer and von\nHirschhausen 2016; Mechler et al. 2017).\nOur House M.D. dataset addresses a gap in medical AI\nevaluation by providing narrative-based diagnostic scenar-\nios testing reasoning rather than factual recall which offers\na meaningful benchmark for evaluating AI diagnostic capa-\nbilities validated by the show’s documented use in medical\neducation (Jerrentrup et al. 2015).\nLimitations include potential bias from fictional narra-\ntives, lack of expert medical validation, and a binary ac-\ncuracy metric that does not capture clinical significance of\nerrors (Cambra-Badii et al. 2020). Models frequently pro-\nvided confident but incorrect explanations, raising concerns\nfor clinical deployment without specialized training and val-\nidation.\nDespite these limitations, the substantial improvement\nacross model generations is encouraging. Our benchmark\nestablishes baseline metrics for narrative-based rare disease\ndiagnosis and provides a foundation for future improve-\nments through domain-specific fine-tuning or hybrid ap-\nproaches combining LLMs with medical knowledge bases.\nFuture Directions and Research Opportunities\nSeveral promising directions emerge from our findings.\nFirst, expanding the dataset to include additional medical\ntelevision series (Grey’s Anatomy, The Good Doctor, ER)\nwould provide broader diagnostic scenario coverage and re-\nduce bias toward House M.D.’s rare disease focus. Second,\nexpert medical validation of extracted symptom-diagnosis\npairs would strengthen dataset reliability and enable com-\nparison with existing clinical benchmarks.\nThe 2.3× performance improvement from GPT-4o Mini\n(16.48%) to Gemini 2.5 Pro (38.64%) suggests substantial\nroom for further gains through domain-specific fine-tuning.\nIntegrating medical knowledge bases (UMLS, SNOMED-\nCT) with LLM reasoning may address rare disease recogni-\ntion limitations. Finally, hybrid approaches combining nar-\nrative understanding with structured medical knowledge and\nuncertainty quantification mechanisms could mitigate the\nconfident misdiagnosis problem observed across all models,\nmoving toward clinically useful diagnostic support systems.\nConclusion\nWe introduce a novel dataset of 176 diagnostically chal-\nlenging cases derived from House M.D. and establish base-\nline performance across four state-of-the-art LLMs. Results\nshow significant variation (16.48% to 38.64%), with the\n2.3× improvement across model generations demonstrating\nrapid progress in medical reasoning capabilities. However,\neven the best-performing models indicate that rare disease\ndiagnosis remains challenging for current LLMs.\nThis work contributes an educationally validated bench-\nmark for narrative-based medical reasoning and establishes\nclear performance baselines for future research. Our find-\nings highlight both the promise of LLMs in medical AI\nand the need for continued development through domain-\nspecific training, expert validation, and hybrid approaches\nto achieve clinically useful diagnostic systems.\nReferences\nCambra-Badii, L.; et al. 2020. Medical drama viewing habits\nand educational impact on health sciences students. BMC\nMedical Education, 20: 200–210.\nDeepMind, G. 2025a. Gemini 2.5 Flash: our cost-efficient\nthinking model. https://developers.googleblog.com/en/start-\nbuilding-with-gemini-2-5-flash/.\n"}, {"page": 5, "text": "DeepMind, G. 2025b. Gemini 2.5 Pro: our most advanced\nreasoning model.\nhttps://blog.google/technology/google-\ndeepmind/gemini-model-thinking-updates-march-2025/.\nFurman, R.; and Clayton, S. 2015. Teaching genetics con-\ncepts through medical television shows. Genetics Education\nReview, 8: 50–60.\nJerrentrup, A.; et al. 2015. Using House M.D. for teaching\nrare diseases in medical curricula. Medical Education Jour-\nnal, 49: 123–130.\nMechler, H.; et al. 2017. Orphan diseases and medical edu-\ncation in House M.D. Journal of Medical Media Studies, 5:\n23–34.\nOpenAI. 2024. GPT-4o mini: Advancing cost-efficient intel-\nligence.\nhttps://openai.com/index/gpt-4o-mini-advancing-\ncost-efficient-intelligence/.\nOpenAI. 2025. GPT-5 Mini: A streamlined version of GPT-\n5. https://platform.openai.com/docs/models/gpt-5-mini.\nRasul, F.; et al. 2021. Teaching professionalism using real-\nworld scenarios in undergraduate medical education. Medi-\ncal Education Journal, 55: 321–332.\nRattani, A.; et al. 2019. Narrative methods and simulation in\nmedical ethics and professionalism education. BMC Medi-\ncal Ethics, 20: 78–88.\nRichardson, L. 2024. Beautiful Soup 4: Pythonic HTML\nand XML parsing. https://pypi.org/project/beautifulsoup4/.\nAccessed: 2025-10-19.\nSanges, S.; et al. 2018. Role-play simulation and case-based\nlearning for rare disease education. Advances in Medical\nEducation, 12: 45–55.\nSarrafpour, M.; et al. 2019. Simulation and career-computer\nlearning for awareness of rare diseases. Medical Teacher,\n41: 1100–1110.\nSchaefer, K.; and von Hirschhausen, E. 2016. Entertainment\nmedia as a tool for rare disease awareness. Medical Educa-\ntion Online, 21: 1–9.\n"}]}