{"doc_id": "arxiv:2601.04209", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2601.04209.pdf", "meta": {"doc_id": "arxiv:2601.04209", "source": "arxiv", "arxiv_id": "2601.04209", "title": "Leveraging Language Models and RAG for Efficient Knowledge Discovery in Clinical Environments", "authors": ["Seokhwan Ko", "Donghyeon Lee", "Jaewoo Chun", "Hyungsoo Han", "Junghwan Cho"], "published": "2025-12-10T05:01:56Z", "updated": "2025-12-10T05:01:56Z", "summary": "Large language models (LLMs) are increasingly recognized as valuable tools across the medical environment, supporting clinical, research, and administrative workflows. However, strict privacy and network security regulations in hospital settings require that sensitive data be processed within fully local infrastructures. Within this context, we developed and evaluated a retrieval-augmented generation (RAG) system designed to recommend research collaborators based on PubMed publications authored by members of a medical institution. The system utilizes PubMedBERT for domain-specific embedding generation and a locally deployed LLaMA3 model for generative synthesis. This study demonstrates the feasibility and utility of integrating domain-specialized encoders with lightweight LLMs to support biomedical knowledge discovery under local deployment constraints.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2601.04209v1", "url_pdf": "https://arxiv.org/pdf/2601.04209.pdf", "meta_path": "data/raw/arxiv/meta/2601.04209.json", "sha256": "dcd089ddd0a2927fefb35dc03fc10b4fe7fb3c7f191b73b3b30b0f7f98e440e4", "status": "ok", "fetched_at": "2026-02-18T02:24:32.618174+00:00"}, "pages": [{"page": 1, "text": "Leveraging Language Models and RAG for\nEfficient Knowledge Discovery in Clinical\nEnvironments\nSeokhwan Ko1, Donghyeon Lee2, Jaewoo Chun2, Hyungsoo Han1,3,\nand Junghwan Cho1,*\n1Clinical Omics Institute, Kyungpook National University\n2Department of Biomedical Science, School of Medicine\nKyungpook National University\n3Department of Physiology, School of Medicine Kyungpook\nNational University\nAbstract\nLarge language models (LLMs) are increasingly recognized as valuable\ntools across the medical environment, supporting clinical, research, and\nadministrative workflows. However, strict privacy and network security\nregulations in hospital settings require that sensitive data be processed\nwithin fully local infrastructures. Within this context, we developed and\nevaluated a retrieval-augmented generation (RAG) system designed to rec-\nommend research collaborators based on PubMed publications authored\nAI Transformation Challenge and Symposium 2025\n* Corresponding author, joshua@knu.ac.kr\n1\narXiv:2601.04209v1  [cs.CL]  10 Dec 2025\n"}, {"page": 2, "text": "by members of a medical institution. The system utilizes PubMedBERT\nfor domain-specific embedding generation and a locally deployed LLaMA3\nmodel for generative synthesis. This study demonstrates the feasibility\nand utility of integrating domain-specialized encoders with lightweight\nLLMs to support biomedical knowledge discovery under local deployment\nconstraints.\n1\nIntroduction\nThe growing complexity of clinical and biomedical information has increased\nthe demand for tools that can support interpretation, reporting, and informa-\ntion retrieval across medical and academic environments. LLM-driven systems\nhave emerged as effective solutions, enabling automated document generation,\nstructured reporting, and administrative support [1, 2]. They further acceler-\nate literature review and facilitate collaboration discovery by synthesizing large\nvolumes of biomedical text [3, 4].\nHowever, in hospital environments, regulatory constraints require that patient-\nsensitive or institution-specific data remain within secure, isolated networks\n[5, 6, 7]. This limits the use of cloud-based AI services and motivates the de-\nvelopment of locally deployable LLM systems [8].\nIn this preliminary study, we present a research collaboration recommen-\ndation system designed for institutional deployment.\nThe system leverages\nPubMed publication metadata and generative modeling to identify potential\ncollaborators, summarize research topics, and facilitate interdisciplinary discov-\nery across the Kyungpook National University (KNU) School of Medicine.\n2\n"}, {"page": 3, "text": "Figure 1: Overall workflow of the collaboration recommendation system, based\non a Retrieval-Augmented Generation (RAG) architecture.\n2\nMaterials and Methods\nTo construct the institutional knowledge base, publication records authored\nby researchers affiliated with the KNU School of Medicine were collected from\nPubMed [9, 10]. For each entry, metadata such as titles, abstracts, author lists,\naffiliations, keywords, and publication years were extracted. All documents were\nstored locally within the hospital network to satisfy data security and privacy\nrequirements. This curated set of structured publication records served as the\nfoundation for subsequent embedding and retrieval processes. An overview of\nthe entire workflow is shown in Figure 1.\n3\n"}, {"page": 4, "text": "2.1\nEmbedding Representation\nWe represent the entire corpus of PubMed abstracts as D = {d1, d2, . . . , dN}.\nEach document is encoded into a dense biomedical semantic embedding using\nPubMedBERT [11]:\nhi = fPB(di) ∈Rm,\n(1)\nwhere fPB(·) denotes the domain-specific encoder and m is the embedding\ndimension. A user query q is processed in the same manner:\nhq = fPB(q).\n(2)\nAll embeddings {hi} were indexed in a local vector database to enable ef-\nficient semantic retrieval, following standard practices in approximate nearest-\nneighbor search [12].\n2.2\nSemantic Retrieval Using Cosine Similarity\nTo identify publications most relevant to a user query, we compute cosine sim-\nilarity between the query embedding and each document embedding, a widely\nused metric in vector-space retrieval [13, 14]:\nsim(hq, hi) =\nhq · hi\n∥hq∥∥hi∥.\n(3)\nDocuments are ranked according to their similarity scores, and the system\nselects the top-K results:\nRK(q) = TopKdi∈D sim(hq, hi).\n(4)\nThis retrieval step ensures that the generative model receives both the user’s\n4\n"}, {"page": 5, "text": "intent and a set of semantically aligned evidence from the literature.\n2.3\nPrompt Construction for RAG\nThe retrieved documents are incorporated into a retrieval-augmented prompt\nthat provides contextual grounding for the generative model, in line with stan-\ndard RAG approaches [15, 16]. This prompt is constructed by concatenating\nthe original query with the selected documents:\nP(q) = Concat\n\u0000q, d(1), d(2), . . . , d(K)\n\u0001\n,\n(5)\nwhere d(j) denotes the j-th highest-ranked retrieved document according\nto cosine similarity, ensuring that the prompt preserves the relevance-based\nordering of retrieved contexts.\n2.4\nGenerative Synthesis With LLaMA3.2\nTo comply with network security policies within the hospital environment,\nall generative inference is performed locally using LLaMA3.2, a 3B-parameter\nlightweight model [17]. Given the retrieval-augmented prompt P(q), the model\nsynthesizes summary information and produces a ranked recommendation of\npotential collaborators:\ny = gLLM(P(q)),\n(6)\nwhere gLLM denotes the generative model. The output combines information\ninferred from the query, retrieved publications, and patterns captured during\npretraining, resulting in interpretable recommendations and topic summaries\naligned with the institution’s research landscape.\n5\n"}, {"page": 6, "text": "3\nResults\nFigure 2: Example output for the query “deep learning prediction for medical\nimages.” Recommended researchers and topics are synthesized from retrieved\nPubMed publications.\nPilot evaluations showed that the system effectively retrieved contextually\nrelevant publications and synthesized informative collaboration suggestions. For\nthe query “deep learning prediction for medical images”, the system identified\nresearch groups specializing in thyroid pathology, deep learning, medical imag-\ning, and endocrine oncology, as shown in Figure 2.\nCompared with traditional keyword-based PubMed searches, PubMedBERT-\nbased embeddings improved contextual retrieval quality, and LLaMA3.2 pro-\nvided concise, interpretable summaries that highlighted research themes, method-\nologies, and potential interdisciplinary links.\nTo validate the correctness of the embedding and similarity computation, we\nexamined the cosine similarity scores for a representative query: “Deep Learning\nPrediction of TERT Promoter Mutation Status in Thyroid Cancer Using Histo-\nlogic Images.” As expected, the system returned the exact matching publication\nas the top-ranked result with a similarity score of 0.9964137. The subsequent\nretrieved documents showed cosine similarity scores of 0.9859726, 0.9858602,\n0.9848883, and 0.9842814 respectively. Figure 3 visualizes these similarity scores\nand confirms that the cosine similarity module operates as intended.\n6\n"}, {"page": 7, "text": "Figure 3: Cosine similarity scores for the top retrieved documents given the\nquery “Deep Learning Prediction of TERT Promoter Mutation Status in Thy-\nroid Cancer Using Histologic Images.” The exact matching publication is ranked\nfirst with the highest similarity score, confirming correct retrieval behavior.\n4\nConclusion\nWe present a locally deployable RAG system that integrates PubMedBERT for\nsemantic retrieval and LLaMA3.2 for generative analysis. The system enhances\nresearch networking efficiency while adhering to strict privacy and security con-\nstraints in hospital environments. This approach demonstrates the feasibility of\ndeploying lightweight yet domain-effective LLM systems for biomedical knowl-\nedge discovery.\n5\nDiscussion\nThis study demonstrates that integrating domain-specialized encoders [11] with\na lightweight locally deployed LLM can yield an effective and interpretable sys-\ntem for identifying potential research collaborations within a medical institution.\nBy leveraging PubMed-derived publication metadata and retrieval-augmented\ngeneration [15], the framework provides structured, context-aware recommen-\ndations while remaining compatible with strict security and deployment con-\nstraints in hospital environments.\n7\n"}, {"page": 8, "text": "The system also opens several avenues for further enhancement. One promis-\ning direction is the incorporation of agentic components capable of autonomously\nmonitoring newly published literature [18], thereby enabling continuous updates\nand real-time detection of emerging research themes [19]. Extending the frame-\nwork to support cross-institutional biomedical knowledge graph construction\n[20] would further enrich representations of collaborative networks and scien-\ntific domains. Moreover, connecting the system’s outputs to institutional grant\nmanagement pipelines and research workflow automation tools could facilitate\nmore seamless integration into operational research environments, ultimately\nsupporting strategic planning and interdisciplinary collaboration at scale.\n6\nAcknowlegment\nThis research was supported by the Brain Pool Program through the National\nResearch Foundation of Korea (NRF), funded by the Ministry of Science and\nICT (Grant No. 2022H1D3A2A01096490 & RS-2023-00283791) and the Min-\nistry of Education, Korea (Grant No. 2021R1I1A3056903 & RS-2024-00459836).\nSpecial thanks to Yu Ando, for his insightful comments and discussions.\nReferences\n[1] K. Singhal, S. Azizi, T. Tu, S. S. Mahdavi, J. Wei, H. W. Chung, N. Scales,\nA. Tanwani, H. Cole-Lewis, S. Pfohl, et al., “Large language models encode\nclinical knowledge,” Nature, vol. 620, no. 7972, pp. 172–180, 2023.\n[2] J. Zhou, H. Li, S. Chen, Z. Chen, Z. Han, and X. Gao, “Large language\nmodels in biomedicine and healthcare,” npj Artificial Intelligence, vol. 1,\nno. 1, p. 44, 2025.\n8\n"}, {"page": 9, "text": "[3] H. Nori, N. King, S. M. McKinney, D. Carignan, and E. Horvitz,\n“Capabilities of gpt-4 on medical challenge problems,” arXiv preprint\narXiv:2303.13375, 2023.\n[4] X. Tang, X. Duan, and Z. Cai, “Large language models for automated liter-\nature review: An evaluation of reference generation, abstract writing, and\nreview composition,” in Proceedings of the 2025 Conference on Empirical\nMethods in Natural Language Processing, pp. 1602–1617, 2025.\n[5] K. Y. Yigzaw, S. D. Olabarriaga, A. Michalas, L. Marco-Ruiz, C. Hillen,\nY. Verginadis, M. T. De Oliveira, D. Krefting, T. Penzel, J. Bowden, et al.,\n“Health data security and privacy: Challenges and solutions for the future,”\nRoadmap to successful digital health ecosystems, pp. 335–362, 2022.\n[6] N. Khalid, A. Qayyum, M. Bilal, A. Al-Fuqaha, and J. Qadir, “Privacy-\npreserving artificial intelligence in healthcare:\nTechniques and applica-\ntions,” Computers in Biology and Medicine, vol. 158, p. 106848, 2023.\n[7] B. S. Kelly, C. Quinn, N. Belton, A. Lawlor, R. P. Killeen, and J. Burrell,\n“Cybersecurity considerations for radiology departments involved with ar-\ntificial intelligence,” European radiology, vol. 33, no. 12, pp. 8833–8841,\n2023.\n[8] A. Basit, K. Hussain, M. A. Hanif, and M. Shafique, “Medaide: leveraging\nlarge language models for on-premise medical assistance on edge devices,”\narXiv preprint arXiv:2403.00830, 2024.\n[9] Z. Lu, “Pubmed and beyond: a survey of web tools for searching biomedical\nliterature,” Database, vol. 2011, p. baq036, 2011.\n9\n"}, {"page": 10, "text": "[10] C.-H. Wei, A. Allot, R. Leaman, and Z. Lu, “Pubtator central: automated\nconcept annotation for biomedical full text articles,” Nucleic acids research,\nvol. 47, no. W1, pp. W587–W593, 2019.\n[11] Y. Gu, R. Tinn, H. Cheng, M. Lucas, N. Usuyama, X. Liu, T. Naumann,\nJ. Gao, and H. Poon, “Domain-specific language model pretraining for\nbiomedical natural language processing,” ACM Transactions on Computing\nfor Healthcare (HEALTH), vol. 3, no. 1, pp. 1–23, 2021.\n[12] J. Johnson, M. Douze, and H. J´egou, “Billion-scale similarity search with\ngpus,” IEEE Transactions on Big Data, vol. 7, no. 3, pp. 535–547, 2019.\n[13] H. Sch¨utze, C. D. Manning, and P. Raghavan, Introduction to information\nretrieval, vol. 39. Cambridge University Press Cambridge, 2008.\n[14] N. Reimers and I. Gurevych, “Sentence-bert: Sentence embeddings using\nsiamese bert-networks,” arXiv preprint arXiv:1908.10084, 2019.\n[15] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal,\nH. K¨uttler, M. Lewis, W.-t. Yih, T. Rockt¨aschel, et al., “Retrieval-\naugmented generation for knowledge-intensive nlp tasks,” Advances in neu-\nral information processing systems, vol. 33, pp. 9459–9474, 2020.\n[16] G. Izacard and E. Grave, “Leveraging passage retrieval with generative\nmodels for open domain question answering,” in Proceedings of the 16th\nconference of the european chapter of the association for computational\nlinguistics: main volume, pp. 874–880, 2021.\n[17] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix,\nB. Rozi`ere, N. Goyal, E. Hambro, F. Azhar, et al., “Llama: Open and\nefficient foundation language models,” arXiv preprint arXiv:2302.13971,\n2023.\n10\n"}, {"page": 11, "text": "[18] L. Wang, C. Ma, X. Feng, Z. Zhang, H. Yang, J. Zhang, Z. Chen, J. Tang,\nX. Chen, Y. Lin, et al., “A survey on large language model based au-\ntonomous agents,” Frontiers of Computer Science, vol. 18, no. 6, p. 186345,\n2024.\n[19] J. Liu, C. Yu, J. Gao, Y. Xie, Q. Liao, Y. Wu, and Y. Wang, “Llm-\npowered hierarchical language agent for real-time human-ai coordination,”\narXiv preprint arXiv:2312.15224, 2023.\n[20] D. N. Nicholson and C. S. Greene, “Constructing knowledge graphs and\ntheir biomedical applications,” Computational and structural biotechnology\njournal, vol. 18, pp. 1414–1428, 2020.\n11\n"}]}