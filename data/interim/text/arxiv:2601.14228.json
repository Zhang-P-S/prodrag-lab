{"doc_id": "arxiv:2601.14228", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2601.14228.pdf", "meta": {"doc_id": "arxiv:2601.14228", "source": "arxiv", "arxiv_id": "2601.14228", "title": "Attention-Based Offline Reinforcement Learning and Clustering for Interpretable Sepsis Treatment", "authors": ["Punit Kumar", "Vaibhav Saran", "Divyesh Patel", "Nitin Kulkarni", "Alina Vereshchaka"], "published": "2026-01-20T18:41:44Z", "updated": "2026-01-20T18:41:44Z", "summary": "Sepsis remains one of the leading causes of mortality in intensive care units, where timely and accurate treatment decisions can significantly impact patient outcomes. In this work, we propose an interpretable decision support framework. Our system integrates four core components: (1) a clustering-based stratification module that categorizes patients into low, intermediate, and high-risk groups upon ICU admission, using clustering with statistical validation; (2) a synthetic data augmentation pipeline leveraging variational autoencoders (VAE) and diffusion models to enrich underrepresented trajectories such as fluid or vasopressor administration; (3) an offline reinforcement learning (RL) agent trained using Advantage Weighted Regression (AWR) with a lightweight attention encoder and supported by an ensemble models for conservative, safety-aware treatment recommendations; and (4) a rationale generation module powered by a multi-modal large language model (LLM), which produces natural-language justifications grounded in clinical context and retrieved expert knowledge. Evaluated on the MIMIC-III and eICU datasets, our approach achieves high treatment accuracy while providing clinicians with interpretable and robust policy recommendations.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2601.14228v1", "url_pdf": "https://arxiv.org/pdf/2601.14228.pdf", "meta_path": "data/raw/arxiv/meta/2601.14228.json", "sha256": "380d41201ae4f38b44761d0b5d8113cec11a6dc96e4045edea1db9dcbcb8c85b", "status": "ok", "fetched_at": "2026-02-18T02:20:57.080828+00:00"}, "pages": [{"page": 1, "text": "Attention-Based Offline Reinforcement Learning\nand Clustering for Interpretable Sepsis Treatment\nPunit Kumar, Vaibhav Saran, Divyesh Patel, Nitin Kulkarni, and Alina Vereshchaka\nDepartment of Computer Science and Engineering\nUniversity at Buffalo\nBuffalo, New York, USA\n{punitkum, vsaran, dpatel45, nitinvis, avereshc}@buffalo.edu\nAbstract—Sepsis remains one of the leading causes of mortality\nin intensive care units, where timely and accurate treatment\ndecisions can significantly impact patient outcomes. In this work,\nwe propose an interpretable decision support framework. Our\nsystem integrates four core components: (1) a clustering-based\nstratification module that categorizes patients into low, interme-\ndiate, and high-risk groups upon ICU admission, using clustering\nwith statistical validation; (2) a synthetic data augmentation\npipeline leveraging variational autoencoders (VAE) and diffusion\nmodels to enrich underrepresented trajectories such as fluid or\nvasopressor administration; (3) an offline reinforcement learning\n(RL) agent trained using Advantage Weighted Regression (AWR)\nwith a lightweight attention encoder and supported by an\nensemble models for conservative, safety-aware treatment rec-\nommendations; and (4) a rationale generation module powered\nby a multi-modal large language model (LLM), which produces\nnatural-language justifications grounded in clinical context and\nretrieved expert knowledge. Evaluated on the MIMIC-III and\neICU datasets, our approach achieves high treatment accuracy\nwhile providing clinicians with interpretable and robust policy\nrecommendations.\nIndex Terms—Reinforcement Learning, Sepsis Treatment,\nClustering, Offline RL, LLM, Synthetic Data Generation, Clinical\nDecision Support, Interpretable AI, Precision Medicine\nI. INTRODUCTION\nSepsis is a life-threatening medical emergency characterized\nby a dysregulated host response to infection, leading to acute\norgan dysfunction and high risk [1]. In-hospital risk rates\nrange from approximately 10 −30%, and can exceed 40%\nin cases of septic shock, underscoring the profound lethality\nof this condition [2]. In the United States, sepsis affects over\n1.7 million adults annually and accounts for more than a\nthird of hospital deaths, imposing a substantial human and\neconomic burden [3]. The rapid progression of sepsis and its\nheterogeneous presentation across diverse patient populations\nunderscore the urgent need for early detection, precise diagno-\nsis, and timely intervention to improve patient outcomes [4].\nRecent advances in large-scale critical care databases such\nas MIMIC-III [5] and eICU [6], combined with machine\nlearning (ML) and reinforcement learning (RL) methods, offer\npromising tools for personalized treatment planning. While\nsupervised models have shown success in tasks like risk strati-\nfication and mortality prediction, RL provides a framework for\nlearning sequential decision policies from historical data [7],\n[8]. Offline RL, in particular, is well-suited for clinical settings,\nwhere real-time exploration is neither feasible nor ethical.\nDespite increasing interest in applying RL to ICU settings,\nmost work remains focused on supervised risk scoring or\nbinary classification. Effective RL models must not only learn\noptimal policies from logged data but also support gener-\nalization to out-of-distribution states and produce reliable,\ninterpretable outputs for clinical use.\nIn this work we present a framework for personalized\ntreatment through RL, synthetic data generation, and language\nmodel-based rationale generation. Our main contributions in-\nclude:\n1) We developed an interpretable offline RL pipeline that\ncombines Advantage-Weighted Regression (AWR) with\na simplified attention mechanism. This output is then\ncombined with the ensemble predictions from XGBoost\nand TabNet to improve learning stability and treatment\naccuracy while maintaining interpretability.\n2) We utilize clustering-driven stratification to group pa-\ntients by risk using HDBSCAN [9], which allows us\nto handle the cold-start problem for the patients with\nlimited or no ICU history by assigning them to similar\nhistorical trajectories.\n3) To address class imbalance and data sparsity in criti-\ncal interventions (e.g., vasopressors), we augment the\ndataset with synthetic trajectories generated via a diffu-\nsion model and a conditional VAE.\n4) We integrate a multi-modal large language model\n(LLM) into the inference pipeline to generate contex-\ntual, patient-specific rationales for selected actions. The\nmodel combines current vitals, retrieved clinical knowl-\nedge, and RL outputs to support explainable decision-\nmaking.\nII. BACKGROUND AND LITERATURE REVIEW\n1) Sepsis as a Sequential Decision Problem: The diag-\nnostic and therapeutic challenges in sepsis, characterized by\nhidden disease states and incomplete observability of the\nunderlying pathophysiology, allow us to formulate it as a\nPartially Observable Markov Decision Process (POMDP). The\npatient’s physiological state evolves in response to adminis-\ntered treatments (e.g., vasopressors, fluids) and latent disease\nprogression. Clinical guidelines emphasize the need for timely\nintervention, where delays in antibiotic or fluid administration\nsubstantially increase risk [4], [10].\n© 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including\nreprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any\ncopyrighted component of this work in other works.\narXiv:2601.14228v1  [cs.LG]  20 Jan 2026\n"}, {"page": 2, "text": "Fig. 1: Overview of the interpretable sepsis treatment pipeline. (A) Patients without prior ICU history are stratified into low-,\nintermediate-, or high-risk groups using clustering. (B) To address data sparsity, synthetic transitions (s, a, r, s′, d) are generated\nusing a VAE and a diffusion model, then added to the RL training set. (C) For intermediate-risk or historical patients, a feature-\nattention encoder produces a latent state z = Attn(s), used by an AWR policy πϕ(a | z), a Q-network, and a value function.\nThe final recommendation a′ = arg maxa[blend(πϕ, πXGB)] combines outputs from AWR and a clinician-trained XGBoost\npolicy. (D) To enhance interpretability, a local LLM generates a natural-language rationale r = f(s, a′, context) using the\npatient state, selected action, and retrieved clinical context.\n2) Challenges in Modeling Sepsis from ICU Data: Training\nRL agents in healthcare is constrained by the absence of an\nonline environment and the inability to perform exploration.\nOffline RL algorithms address this by learning from historical\ndata while correcting for the distributional mismatch between\nthe behavior and the learned policy. However, the quality of\nthe learned policy is closely coupled with state representation\nand reward design.\nICU datasets such as MIMIC-III [5] and eICU [6] offer\ntime-stamped, high-resolution records of patient vitals, lab\ntests, interventions, and outcomes. Yet, they reflect evolving\nclinical standards, e.g., the definition of sepsis changed mid-\ndecade to emphasize organ dysfunction over simple infection\nmarkers [11]. This requires harmonization techniques, such\nas clustering-based cohort construction and dimensionality\nreduction (e.g., UMAP [12], HDBSCAN [9]), to ensure valid\ncross-temporal comparisons and consistent reward attribution.\n3) Integration of Language Models for Interpretability:\nFor AI systems to be useful in clinical practice, they need\nto explain their reasoning in a way that clinicians can trust.\nAttention mechanisms offer insights by highlighting which\nfeatures are important, but they often fall short of providing\nclear justifications. Recently, LLMs, especially those with\nmulti-modal inputs, have made it possible to generate natural-\nlanguage explanations grounded in both patient data and\nclinical knowledge [13], [14].\nIII. INTERPRETABLE SEPSIS TREATMENT METHODOLOGY\nOur\nmethodology\nintegrates\npatient\nrisk\nstratification\n(Sec. III-A), synthetic data augmentation (Sec. III-B), offline\nreinforcement learning (Sec. III-C), and LLM-based inter-\npretability (Sec. III-D) to develop a transparent and data-driven\nsepsis treatment policy. The full pipeline is illustrated in Fig. 1.\nA. Risk Stratification via Clustering\nNewly admitted patients often lack sufficient ICU history,\nmaking it challenging to apply downstream RL and LLM\nmodules that rely on longitudinal data. To address this, we\nuse unsupervised clustering to assess patient status upon\nadmission, grouping them into risk categories based on initial\nvitals and lab measurements. Clustering helps identify patients\naccording to their risk stratification. Prior to RL training, pa-\ntient states are clustered to identify distinct sepsis progression\npatterns, and recent advances in clustering efficiency, such as\nthe centroid update approach by Borlea et al. [15], demonstrate\nsignificant reductions in computational iterations while main-\ntaining clustering quality, a critical consideration for large-\nscale patient data preprocessing in clinical settings. We utilize\nHierarchical Density-Based Spatial Clustering of Applications\nwith Noise (HDBSCAN) [9] and Uniform Manifold Approxi-\nmation and Projection (UMAP) [12] as our core unsupervised\nclustering and visualization tools. This combination confers\nseveral key advantages over conventional clustering algorithms\nwithin the medical domain. Specifically, it accommodates\nvariable cluster densities, enables automatic cluster detection,\ndemonstrates robustness to noise and outliers, and is scalable\nfor real-time deployment.\nThis process broadly categorizes patients into the following:\n1) Low-risk [0%, 40%]: Patients with stable vitals and a\ngood recovery trajectory, thus no intervention is needed.\n2) Intermediate-risk (40%, 75%]: Patients suitable for our\nRL-based recommendations in conjunction with clinical\njudgment.\n"}, {"page": 3, "text": "3) High-risk (75%, 100%]: Patients requiring immediate\nclinical intervention.\nThe pipeline, shown in Fig. 2, performs temporal filtering,\nL2 normalization, and UMAP [12] dimensionality reduction,\nfollowed by HDBSCAN-based grouping. This procedure is\ndetailed in Algorithm 1.\nFig. 2: Clustering-based risk stratification pipeline. After pre-\nprocessing ICU data, including feature selection, temporal\nsequence construction, and UMAP Dimensionality reduction,\nHDBSCAN is used to group patients by similarity. The result-\ning clusters are validated using risk trends to ensure clinical\nrelevance.\nThis module provides interpretable early risk labels when\nclinical records are limited by using unsupervised clustering\nwith statistical validation.\nB. Synthetic Data Generation\nIn the medical domain, datasets are often limited and\ncostly to collect. To address this, we augment MIMIC-III and\neICU datasets with realistic synthetic patient trajectories using\ntwo complementary generative modeling methods: a diffusion\nmodel for continuous-time state transitions, and a Variational\nAutoencoder (VAE) for modeling discrete transitions condi-\ntioned on actions and rewards.\nDiffusion Model: We apply a lightweight diffusion process\nto each normalized observation window x0 to generate realistic\nsynthetic samples.\n1) Noise is added incrementally using a schedule {βt}T\nt=1,\nwhere βt gradually increases from near zero to a small\npositive value.\n2) At each step, the data is perturbed with Gaussian noise\nusing the forward kernel (Eq. 2), gradually increasing\nthe noise level in the sample.\nq(xt | xt−1) = N\n\u0000p\n1 −βt xt−1, βtI\n\u0001\n(2)\nAlgorithm 1 HDBSCAN-Based Clustering and Validation\nRequire: Dataset D, Feature set F, Max sequence length L =\n80,\nEnsure: Risk categories R ∈Low, Intermediate, High\n1: Filter D by temporal length; pad sequences to length L\n2: Apply L2 normalization and UMAP for dimensionality\nreduction; split data into training and test sets: D =\nDtrain ∪Dtest.\n3: Initialize\nHDBSCAN:\nmin cluster size\n=\nm,\nmin samples = s, ϵ = ϵ.\n4: Fit HDBSCAN on Dtrain to obtain clusters Ctrain and noise\nNtrain.\n5: Predict clusters on Dtest using trained model →Ctest, Ntest\n6: Evaluate mortality (M) variance: Var = PK\nk=1(Mk −\nMoverall)2/K, where k represents the kth cluster.\n7: Compute chi-square statistic: χ2 = P\ni(Oi −Ei)2/Ei,\nwhere Oi and Ei are observed and expected frequencies.\n8: p −value = P(χ2 >= χ2\nobserved)\n9: if p-value < 0.001 then\n10:\nAccept clusters as statistically significant.\n11: end if\n12: for each cluster c with mortality rate mc do\n13:\nif mc ≤0.40 then\n14:\nassign Low Risk\n15:\nelse if 0.40 < mc ≤0.75 then\n16:\nassign Intermediate Risk\n17:\nelse\n18:\nassign High Risk\n19:\nend if\n20: end for\n21: return Risk Categories R, Cluster Assignments, Valida-\ntion Metrics\n3) A neural network ϵθ(xt, t) is trained to estimate the\nadded noise. The model minimizes the objective rep-\nresented in Eq. 3:\nLdiff = Ex0,ϵ,t\n\u0002\n∥ϵ −ϵθ(xt, t)∥2\u0003\n(3)\n4) To generate a new sample, the process starts from pure\nnoise xT ∼N(0, I) and iteratively applies the denoiser\nfrom t = T down to t = 0, yielding a reconstructed\nwindow ˆx0.\n5) Finally, the output ˆx0 is unscaled, clipped to remove\nimplausible values, and added to the synthetic dataset\nused for training the RL agent.\nVariational\nAutoencoder\n(VAE):\nDiscrete,\naction-\nconditioned transitions are modeled using a conditional VAE.\nThe VAE captures complex dependencies between the current\nstate s, action a, reward r, terminal indicator d, and the next\nstate s′.\nThe encoder network fϕ maps the input pair (s, a) to a latent\ndistribution qϕ(z | s, a) = N(µ, σ2), where (µ, log σ2) =\nfϕ(s, a). Latent samples are drawn using the reparameteriza-\ntion trick: z = µ + σ ⊙ϵ, with ϵ ∼N(0, I). The decoder gψ\nthen reconstructs the next state ˆs′ conditioned on the latent\n"}, {"page": 4, "text": "variable along with the action, reward, and terminal indicator:\nˆs′ = gψ(z, a, r, d). Training minimizes a loss function that\ncombines reconstruction error and KL divergence:\nLVAE(ϕ, ψ) = Eqϕ(z|s,a)[∥s′−ˆs′∥2]+β DKL(qϕ(z|s, a) || p(z)),\nwhere p(z) = N(0, I) is the standard Gaussian prior and β\ncontrols the regularization strength. Prior to training, all states\nare normalized, and discrete actions are encoded as one-hot\nvectors to match the input requirements of the encoder.\nWe generate synthetic transitions to address a class-\nimbalance problem as follows:\n1) Sample latent variables z ∼N(0, I) from the prior\ndistribution.\n2) Select action a, reward r, and terminal flag d from\nempirical distributions.\n3) Decode using gψ(z, a, r, d) to obtain a synthetic next\nstate ˆs′.\n4) Apply post-processing to clip outliers and filter implau-\nsible transitions.\nThis combined approach of diffusion modeling and VAE\nhelps to generate realistic synthetic trajectories for underrep-\nresented interventions like vasopressors and fluids.\nFig.\n3:\nMinority-class\naugmentation\npipeline.\nCleaned\nMIMIC-III + eICU records are filtered to classes 1 & 2, then\ntwo parallel generators create new samples: (1) a VAE that\ndecodes latent draws, and (2) a conditional diffusion process\nthat iteratively denoises scaled states with a time-stepped loop.\nC. Ensemble RL-Based Treatment Agent\nWe apply offline RL to optimize sepsis treatment policies\nusing patient data from the MIMIC-III and e-ICU database.\nDue to data sparsity, especially in vasopressors and fluid\nintervention categories, we supplement training with syn-\nthetic trajectories generated via VAE and diffusion models\n(Sec. III-B).\nFeature Preparation: The following steps are used to\nprepare the dataset using Google BigQuery:\n1) Extract adult ICU stays with a sepsis diagnosis from\nMIMIC-III and eICU.\n2) Split each patient’s time series of vital signs and lab\nvalues into fixed-length windows of 4 hours.\n3) Fill any missing measurement by carrying the last ob-\nservation forward; if still missing, use the median value\nfor that feature.\n4) Scale each feature xj using its training-set mean µj and\nstandard deviation σj as ˜xj =\nxj−µj\nσj\n.\nFeature Importance Analysis via XGBoost: To validate\nour data preprocessing and imputation strategy, we conducted\na feature importance analysis using an XGBoost classifier.\nSpecifically, we augmented the state features with a synthetic\n“noise” feature, randomly generated from a uniform distribu-\ntion. The XGBoost model is trained to predict the discrete\naction classes (four actions in our RL environment) based on\nthe state features.\nRL Environment:\na) Observation Space:\nEach patient state st\n∈\nRd\ncaptures a snapshot of the patient’s condition at time step t,\nencoded as a vector of dimension d = 30. The feature set\nincludes vital signs (e.g., heart rate, mean arterial pressure\n[MAP], oxygen saturation [SpO2]), laboratory values (e.g.,\nlactate, creatinine, white blood cell count), and treatment\nindicators (e.g., prior administration of vasopressors or fluids).\nAll features are standardized using z-score normalization and\nmissing values are imputed using domain-aware techniques.\nb) Action Space: The agent selects from a discrete action\nspace with four treatment choices, representing common sepsis\ntreatment strategies:\nA = {No treatment, Fluids, Vasopressors, Combined treatments}\nc) Reward Function: The reward function is designed\nto align with key treatment goals: stabilizing vital signs and\nreducing short-term mortality. At each step, the agent receives\na composite reward:\nrt = −I{mortality within 48 h} + 0.3 I{MAPt > 65}\n+ 0.3 I{SpO2t > 94} + 0.2 I{lactatet < 2}\n(4)\nwhere I is the scaling factor [7]. The reward ranges from\n−1 (next 48−h mortality) to +0.8 when all three vitals\nare in safe ranges, including hemodynamic stability (MAP),\nadequate oxygenation (SpO2), and reduced metabolic stress\n(lactate). This reward function encourages the agent to prefer\ntreatments that stabilize the patient in the short-term, while\nstaying closely aligned with clinically meaningful goals.\nAWR\nwith\nFeature\nAttention:\nWe apply Advantage-\nWeighted Regression (AWR) [16] with a lightweight attention-\nbased encoder. The attention module transforms raw state\nvectors s into latent embeddings z = Attn(s) to capture the\nmost important features for the RL agent.\n1) We compute the next attended state z′ = Attn(s′) and\nform the one-step value target:\nyV = r + γ (1 −d) Vψ′(z′) ,\nδ = yV −Vψ(z)\n(5)\n"}, {"page": 5, "text": "Fig. 4: AWR with a custom feature attention pipeline. The 30-D state goes through a custom attention block and a shared\nencoder. Policy (π), Q, and V heads are trained together. We weight the policy loss using the advantage value and use a\ntarget-value network to smooth the learning updates.\n2) We train the value head with an expectile regression:\nLV = E\n\u0002\nw(δ) δ2\u0003\n,\nw(δ) =\n(\nτ,\nδ > 0,\n1 −τ,\nδ < 0\n(6)\nwhich pushes Vψ(z) toward the bootstrap target yV\nwhile weighting over- and under-estimates differently.\n3) We train the Q-head to match the same target:\nLQ = E\nh\u0000Qθ(z, a) −yV\n\u00012i\n(7)\n4) We form the advantage A = Qθ(z, a) −Vψ(z), convert\nit into a weight wA = exp\n\u0000A/β\n\u0001\nand train the policy\nby:\nLπ = −E\n\u0002\nwA log πϕ(a | z)\n\u0003\n(8)\nThe full training procedure is outlined in Algorithm 2,\nwhich details how each transition (s, a, r, s′, d) is used to\nupdate the policy, value, and Q-networks.\nEnsemble-Based Treatment Policy: Our final treatment de-\ncision is made by an ensemble of three models: an AWR-based\nRL agent, TabNet, and XGBoost. Because these decisions\ninvolve sensitive interventions like vasopressors and fluids,\nwe implement a conservative, safety-oriented rule: a treatment\nis recommended if any model in the ensemble predicts a\nprobability for it that exceeds a set threshold (ω).\nLet pfluid and pvaso be the maximum predicted probabilities\n(across TabNet and XGBoost) for fluid and vasopressor treat-\nments, and let aRL be the action suggested by the RL agent.\nThe final action a∗is computed as:\na∗=\n\n\n\n\n\nfluid,\nif pfluid > ω and pfluid > pvaso\nvasopressor,\nif pvaso > ω and pvaso > pfluid\naRL,\notherwise\n(9)\nThe recommendations from the two tabular models, TabNet\nand XGBoost, are evaluated first. If either model’s confidence\nAlgorithm 2 Advantage-Weighted Regression (AWR) with\nFeature Attention\nRequire: Batch of transitions (s, a, r, s′, d), discount factor γ,\nexpectile τ, temperature β, soft update rate α\nEnsure: Updated network parameters (ψ, θ, ϕ) for value, Q,\nand policy networks\n1: for all transition (s, a, r, s′, d) in batch do\n2:\nEncode current and next states with attention: z ←\nAttn(s), z′ ←Attn(s′)\n3:\nCompute target value:yV ←r + γ · (1 −d) · Vψ′(z′)\n4:\nCompute TD error: δ ←yV −Vψ(z)\n5:\nCompute value loss: LV ←E[w(δ) · δ2] where\nw(δ) =\n(\nτ,\nδ > 0\n1 −τ,\nδ < 0\n6:\nCompute Q-value estimate: Qθ(z, a)\n7:\nCompute Q loss:LQ ←E[(Qθ(z, a) −yV )2]\n8:\nCompute advantage: A ←Qθ(z, a) −Vψ(z)\n9:\nCompute weight: wA ←exp(A/β)/E[exp(A/β)]\n10:\nCompute policy loss: Lπ ←−E[wA · log πϕ(a | z)]\n11:\nCompute total loss: L ←LV + LQ + Lπ\n12:\nBackpropagate and update all networks using LAWR\n13:\nSoft update target: ψ′ ←(1 −α) · ψ′ + α · ψ\n14: end for\n15: return Updated parameters (ψ, θ, ϕ)\nfor a treatment exceeds a predefined threshold (ω), that action\nis taken, overriding the RL agent. Otherwise, the final decision\nis delegated to the learned RL policy. This hybrid approach\nensures a safety-aware framework that balances data-driven\ndecisions with clinical policies.\nTabNet: It is a deep learning model specifically designed\nfor structured tabular data. It uses sequential attention to focus\n"}, {"page": 6, "text": "on the most relevant features at each decision step. This makes\nit useful for interpretability and handling feature sparsity.\nGiven an input state vector x ∈Rd, TabNet applies a series\nof attention-based decision steps to produce feature masks\nand predictions. At each step t, a mask M (t) is generated to\nselect a subset of features: M (t) = Sparsemax(P (t)), where\nP (t) = Attn(x(t)).\nThe selected features are then passed through shared deci-\nsion layers to refine the output. The final treatment prediction\nis obtained after aggregating the outputs across all steps.\nXGBoost: It is a gradient-boosted decision tree model that\nis well-suited for our data. We use it as a secondary model\nto estimate the probability of recommending each treatment\naction based on patient state features.\nGiven a state input x ∈Rd, XGBoost builds an ensemble of\ndecision trees to learn the probability distribution over discrete\ntreatment classes:\nˆy =\nM\nX\nm=1\nfm(x),\nfm ∈F\n(10)\nwhere F is the space of regression trees, and each fm is a\ntree added at iteration m. The final prediction ˆy is interpreted\nas a softmax probability across the treatment classes.\nD. LLM-Based Rationale Generation\nTo improve the interpretability of clinical decision-making,\nwe integrate a multi-modal large language model into the\ninference pipeline. The goal is to generate natural-language\nrationales that explain why a particular treatment is selected;\nthis way, we aim to increase transparency and clinicians’ trust.\nWe construct a natural-language prompt (Fig. 5) from the\npatient’s clinical context as follows:\n1) The patient’s current state (s) is mapped to a point in\nthe learned patient clustering space. We merge this state\nwith the selected action a ∈A from the ensemble-based\nRL policy.\n2) The combined query is then used to search a Vector DB\nvia an Approximate Nearest Neighbor (ANN) search.\nThe search retrieves the top-k most relevant tokens from\nan expert-curated sepsis knowledge base that has been\npre-vectorized using a NOMIC encoder [17].\n3) The retrieved knowledge tokens are inserted into a\nprompt template. This prompt is passed to the LLM,\nwhich generates a clear, natural-language rationale ex-\nplaining the clinical reasoning for the recommended\naction (a) in the context of the patient’s state (s).\nIV. EVALUATION RESULTS & ANALYSIS\nA. Datasets\nLarge-scale, de-identified critical care databases such as\nMIMIC-III and the eICU Collaborative Research Database\nhave become foundational resources for sepsis research and\nclinical modeling. The Medical Information Mart for Intensive\nCare III (MIMIC-III) [5] contains detailed records from over\n53 000 ICU admissions at a single tertiary care hospital in\nFig. 5: Overview of the LLM-based rationale generation\nprocess. A query, combining the patient’s cluster state and the\nRL agent’s action, is used to retrieve relevant context from a\nvectorized sepsis knowledge base. The retrieved information\nis then passed to an LLM to generate a final, knowledge-\ngrounded explanation for the action.\nBoston, collected between 2001 and 2012. The patient popu-\nlation primarily consists of adults, with a median age of 66\nand an overall in-hospital mortality rate of approximately 11%.\nIn contrast, the eICU database includes more than 200 000\nICU stays across 208 U.S. hospitals from 2014 to 2015.\nBoth datasets provide high-resolution, time-stamped clinical\ninformation, including vital signs, lab results, interventions,\ndiagnostic codes, and outcomes.\nB. Latent Space Preparation\nIn order to identify clinically meaningful patient subgroups,\nwe performed unsupervised clustering over a merged dataset\ncombining MIMIC-III [5] and eICU [6]. After aligning on\nicustay_id, the merged dataset contained 874 108 time-\nstamped records across 27 799 ICU stays.\na) Temporal Filtering and Preprocessing: We restricted\nour analysis to patients with between 1 and 80 time points,\nwhich preserved approximately 75% of the original data.\nThis range was empirically chosen to exclude extremely long\nhospital stays (e.g., several months), which are atypical and\nprone to introducing temporal noise. The resulting dataset\nretained all 27 799 unique patients. Each patient’s temporal\ntrajectory was converted into a structured sequence with zero-\npadding to handle varying sequence lengths and create uni-\nform dimensions. After padding, the final feature matrix size\nwas 25 605 × 320, encompassing physiological variables and\n"}, {"page": 7, "text": "demographic attributes such as ‘spo2’, ‘platelets’, and ‘hours\nsince ICU admission’.\nb) Dimensionality Reduction and Clustering:\nTo en-\nable efficient clustering in a lower-dimensional latent space,\nwe applied Uniform Manifold Approximation and Projection\n(UMAP) [12], as it better preserves the global structure of\nthe data [18], [19], and this in turn helps with visualizing\nthe clusters and better understanding the patterns it has.\nWe then applied HDBSCAN [9], a density-based clustering\nalgorithm robust to noise and varying cluster densities. After\nhyperparameter tuning, we determined optimal clustering pa-\nrameters: minimum cluster size = 30; minimum samples = 30;\nepsilon = 0.01.\nThis yielded 124 distinct clusters during training. For inter-\npretability and downstream integration, we grouped them into\nthree clinical risk categories: low, intermediate, and high [20].\nNoisy data comprised 5.3% of training data and 11.3% of test\ndata, which is acceptable given the complexity and variability\ninherent in clinical data. Our approach is similar to methods\nused in behavioral health monitoring [21] and neuro-dynamics\nclustering [22].\nOverall clusters exhibited notable distinction in terms of\nmortality risk within 48 hours (Table I).\nTABLE I: Risk Stratification for Clusters\nCluster\nMortality\n(%)\nPatients\nRisk Category\n1, 86–123\n100.0\n31–211\nHigh Risk\n0, 2, 6, 43, 54,\n59–62, 65\n32.6–62.4\n62–220\nIntermediate Risk\n7, 12, 13, 15, 19,\n24, 27, 28, 40, 42,\n64, 75, 79, 80, 83,\n97, 108\n0.0–4.2\n31–836\nLow Risk\nC. Reinforcement Learning Experiments\nFeature Importance Analysis: Before evaluating RL mod-\nels, we performed feature importance analysis using XGBoost\nto validate our preprocessing and data imputation strategy.\nFeatures were ranked using the average gain metric across\ndecision trees. Clinically meaningful variables such as SpO2,\nplatelets, and MAP dominated the top rankings (Table II). In\ncontrast, a synthetic random noise feature received the lowest\nimportance score, confirming that the model appropriately\ndistinguishes signal from noise.\nAWR with Attention Mechanism: Our core RL method\nis Advantage-Weighted Regression (AWR), augmented with a\nlightweight attention mechanism. The attention module high-\nlights salient features in each patient state (s), producing an\nattended representation (z). The attention mechanism allows\nthe agent to dynamically prioritize key variables, such as MAP\nor lactate trends, when deciding treatment strategies. Fig. 6\nvisualizes one such trajectory, showing high attention on MAP\nand fluid-related features during hypotensive episodes.\nTABLE II: Top Features by XGBoost\nFeature\nGain Score\nSpO2\n910.93\nPlatelets\n732.08\nMAP\n239.74\nHours Since ICU Admission\n179.62\nGCS Total\n138.09\nEthnicity\n116.90\nSystolic BP\n104.86\nBicarbonate\n70.51\nRandom Noise\n0.93\nFig. 6: Attention plot for patient trajectory. Each line is a\nfeature over hours since ICU admission, and line thickness\nis proportional to the attention weight. The model places the\ngreatest emphasis on MAP (bold magenta) with secondary,\nthinner weights on other vitals/labs.\nTo evaluate model performance, we compared several vari-\nants of our pipeline:\n• BCQ (Behavior Cloning + Q-learning): A baseline\noffline RL method.\n• BCQ + Attention: Adds the attention mechanism to\nimprove state representation.\n• AWR + Attention: Our proposed interpretable offline RL\nagent.\n• Ensemble: Combines AWR, XGBoost, and TabNet to\nimprove robustness.\nOverall Performance: AWR + Attention outperforms BCQ in\nboth accuracy and average reward (Table III). The ensemble\nmodel achieves the best overall accuracy (83%) by integrating\ntabular and RL models.\nTABLE III: Combined Ablation Study\nModel\nAccuracy\n(%)\nAverage\nReward\nBCQ\n60\n-0.60\nBCQ + Attention\n74\n-0.47\nAWR + Attention\n80\n-0.33\nEnsemble (XGBoost + AWR +\nAttention + TabNet)\n83\nN/A\nPer-Class Treatment Performance: Table IV represents class-\nwise precision and recall for the four treatment actions (A0:\nno treatment, A1: fluids, A2: vasopressors, A3: combined).\nThe ensemble model consistently yields the best performance,\nespecially for minority actions (A1, A2), which are underrep-\nresented in the dataset but clinically critical.\n"}, {"page": 8, "text": "TABLE IV: Precision and Recall for Treatment Actions\nModel\nA0\nA1\nA2\nA3\nP\nR\nP\nR\nP\nR\nP\nR\nBCQ\n0.72 0.75 0.01 0.03 0.30 0.25 0.50 0.65\nBCQ + Attention\n0.82 0.84 0.03 0.10 0.45 0.40 0.60 0.72\nAWR + Attention 0.85 0.89 0.05 0.15 0.55 0.45 0.64 0.78\nXGBoost\n0.84 0.86 0.38 0.69 0.55 0.48 0.60 0.74\nTabNet\n0.85 0.81 0.48 0.54 0.62 0.56 0.50 0.80\nEnsemble\n0.93 0.92 0.50 0.60 0.65 0.60 0.81 0.70\nOur results show that integrating an attention mechanism\nwith offline RL improves treatment accuracy and action bal-\nance, particularly for underrepresented interventions.\nLLM-Based Rationale Generation: Clinical applications\ndemand secure and private deployments; thus, our primary\ncriterion was the ability to run the model locally. We evaluated\nseveral LLMs with a focus on offline installation and domain\nadaptability and selected the multi-modal LLaMA3.2-Vision\nmodel for its strong performance and compatibility with\noffline, healthcare-specific use cases.\nThe full prompt is passed to the model with top-K sampling\nset to 100, repeat penalty of 1.1, and temperature of 4.7.\nThe model produced clinically sound rationales. Two sam-\nple outputs include:\n“Vasopressor therapy was initiated due to persistent\nhypotension (MAP < 65 mmHg) and elevated lac-\ntate, suggesting ongoing hypoperfusion.”\nor, in a different scenario:\n“No immediate action was taken as vital signs are\nstable and lactate levels are normal.”\nThese responses showcase the model’s ability to generate\nclinically coherent treatment justifications.\nV. CONCLUSION\nIn this work, we tackled the complex challenge of optimiz-\ning sepsis treatment by combining offline reinforcement learn-\ning with attention mechanisms, risk-based patient clustering,\nand natural-language rationale generation using large language\nmodels. Overall our system achieved 83 % treatment accuracy.\nTo address data imbalance and limited coverage of rare but\ncritical treatments, we used synthetic data generated by diffu-\nsion models and VAEs. Our clustering-based risk stratification\nalso helps generalize recommendations to new patients, even\nwith minimal history. The system explains its actions in plain\nlanguage based on each patient’s condition. This helps build\nclinician trust and supports transparency for auditing.\nREFERENCES\n[1] M. Singer, C. S. Deutschman, C. W. Seymour, M. Shankar-Hari,\nD. Annane, and et al., “The third international consensus definitions for\nsepsis and septic shock (sepsis-3),” JAMA, vol. 315, no. 8, pp. 801–810,\n2016.\n[2] C. Rhee, R. Dantes, L. Epstein, D. J. Murphy, C. W. Seymour, T. J.\nIwashyna, and et al., “Incidence and trends of sepsis in us hospitals\nusing clinical vs claims data, 2009-2014,” JAMA, vol. 318, no. 13, pp.\n1241–1249, 2017.\n[3] V. Torres, L. Lacerda, R. Pontes, and et al., “Economic impact of sepsis\nin the intensive care unit: A systematic review,” Critical Care, vol. 27,\n2023.\n[4] L. Evans, A. Rhodes, W. Alhazzani, and et al., “Surviving sepsis\ncampaign: International guidelines for management of sepsis and septic\nshock 2021,” Intensive Care Medicine, vol. 47, pp. 1181–1247, 2021.\n[5] A. E. Johnson, T. J. Pollard, L. Shen, L.-w. H. Lehman, M. Feng,\nM. Ghassemi, B. Moody, P. Szolovits, L. Anthony Celi, and R. G. Mark,\n“Mimic-iii, a freely accessible critical care database,” Scientific data,\nvol. 3, no. 1, pp. 1–9, 2016.\n[6] T. J. Pollard, A. E. W. Johnson, J. D. Raffa, L. A. Celi, R. G.\nMark, and O. Badawi, “The eicu collaborative research database,\na freely available multi-center database for critical care research,”\nScientific Data, vol. 5, no. 1, p. 180178, 9 2018. [Online]. Available:\nhttps://doi.org/10.1038/sdata.2018.178\n[7] M. Komorowski, L. A. Celi, O. Badawi, A. C. Gordon, and A. A. Faisal,\n“The artificial intelligence clinician learns optimal treatment strategies\nfor sepsis in intensive care,” Nature Medicine, vol. 24, pp. 1716–1720,\n2018.\n[8] N. Kulkarni, C. Qiao, and A. Vereshchaka, “Optimizing pharmaceutical\nand non-pharmaceutical interventions during epidemics,” in Interna-\ntional Conference on Social Computing, Behavioral-Cultural Modeling\nand Prediction and Behavior Representation in Modeling and Simula-\ntion.\nSpringer, 2022, pp. 229–240.\n[9] L. McInnes, J. Healy, and S. Astels, “hdbscan: Hierarchical density\nbased clustering,” Journal of Open Source Software, vol. 2, no. 11, p.\n205, 2017. [Online]. Available: https://doi.org/10.21105/joss.00205\n[10] C. Rhee, R. B. Dantes, L. Epstein, and et al., “Impact of delayed\ntreatment on mortality in patients with sepsis,” JAMA Network Open,\nvol. 2, no. 5, 2019.\n[11] C. W. Seymour, V. X. Liu, T. J. Iwashyna, F. M. Brunkhorst, T. D.\nRea, and et al., “Assessment of clinical criteria for sepsis: For the third\ninternational consensus definitions for sepsis and septic shock (sepsis-\n3),” JAMA, vol. 315, no. 8, pp. 762–774, 2016.\n[12] L.\nMcInnes,\nJ.\nHealy,\nN.\nSaul,\nand\nL.\nGroßberger,\n“Umap:\nUniform manifold approximation and projection,” Journal of Open\nSource Software, vol. 3, no. 29, p. 861, 2018. [Online]. Available:\nhttps://doi.org/10.21105/joss.00861\n[13] K. Guo, A. Hu, J. Mu, Z. Shi, Z. Zhao, N. Vishwamitra, and H. Hu,\n“An investigation of large language models for real-world hate speech\ndetection,” in 2023 International Conference on Machine Learning and\nApplications (ICMLA).\nIEEE, 2023.\n[14] N. Kazi, I. Kahanda, S. I. Rupassara, and J. W. Kindt Jr., “Enhancing\ntransfer learning of llms through fine-tuning on task-related corpora for\nautomated short-answer grading,” in 2023 International Conference on\nMachine Learning and Applications (ICMLA).\nIEEE, 2023.\n[15] I.-D. Borlea, R.-E. Precup, F. DRAGAN, and A.-B. BORLEA, “Centroid\nupdate approach to k-means clustering,” Advances in Electrical and\nComputer Engineering, vol. 17, pp. 3–10, 11 2017.\n[16] X. B. Peng, A. Kumar, G. Zhang, and S. Levine, “Advantage-weighted\nregression: Simple and scalable off-policy reinforcement learning,” arXiv\npreprint arXiv:1910.00177, 2019.\n[17] M. W. U. Rahman, M. M. Abrar, H. G. Copening, S. Hariri, S. Shao,\nP. Satam, and S. Salehi, “Quantized transformer language model im-\nplementations on edge devices,” in 2023 International Conference on\nMachine Learning and Applications (ICMLA).\nIEEE, 2023.\n[18] N. L. Cavalcant and F. de Assis Ten´orio de Carvalho, “Novel l1-based\nneural gas clustering algorithms,” Pattern Recognition Letters, vol. 175,\npp. 1–10, 2024.\n[19] B. Li, “Diffusion equation based subspace extraction of image data for\nfast k-means,” in 2024 International Conference on Machine Learning\nand Applications (ICMLA), 2024, pp. 250–255.\n[20] S. Ahmad and A. Aral, “Hierarchical federated transfer learning: A\nmulti-cluster approach on the computing continuum,” in 2023 IEEE\nInternational Conference on Edge Computing (EDGE), 2023.\n[21] T. Radhakrishnan, E. Ingenito, U. Buy, S. M. P. Keller, and K. W.\nBoerke, “Detection of behavioral health challenges in high school stu-\ndents,” in 2024 International Conference on Health Informatics (ICHI),\n2024.\n[22] A. Khoshkhahtinat and H. Mohammadzadeh, “Dynamic changes of brain\nnetwork during epileptic seizure,” IEEE Journal of Biomedical and\nHealth Informatics, vol. 27, pp. 3950–3960, 2023.\n"}]}