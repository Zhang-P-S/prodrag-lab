{"doc_id": "arxiv:2601.21767", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2601.21767.pdf", "meta": {"doc_id": "arxiv:2601.21767", "source": "arxiv", "arxiv_id": "2601.21767", "title": "Evaluating ChatGPT on Medical Information Extraction Tasks: Performance, Explainability and Beyond", "authors": ["Liz Li", "Wei Zhu"], "published": "2026-01-29T14:16:51Z", "updated": "2026-02-11T03:42:26Z", "summary": "Large Language Models (LLMs) like ChatGPT have demonstrated amazing capabilities in comprehending user intents and generate reasonable and useful responses. Beside their ability to chat, their capabilities in various natural language processing (NLP) tasks are of interest to the research community. In this paper, we focus on assessing the overall ability of ChatGPT in 4 different medical information extraction (MedIE) tasks across 6 benchmark datasets. We present the systematically analysis by measuring ChatGPT's performance, explainability, confidence, faithfulness, and uncertainty. Our experiments reveal that: (a) ChatGPT's performance scores on MedIE tasks fall behind those of the fine-tuned baseline models. (b) ChatGPT can provide high-quality explanations for its decisions, however, ChatGPT is over-confident in its predcitions. (c) ChatGPT demonstrates a high level of faithfulness to the original text in the majority of cases. (d) The uncertainty in generation causes uncertainty in information extraction results, thus may hinder its applications in MedIE tasks.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2601.21767v2", "url_pdf": "https://arxiv.org/pdf/2601.21767.pdf", "meta_path": "data/raw/arxiv/meta/2601.21767.json", "sha256": "0f50dc97cc7882ac03424d67b5d6af0702f1a6883edeaaca9b197d0d9eb44ecd", "status": "ok", "fetched_at": "2026-02-18T02:20:10.219156+00:00"}, "pages": [{"page": 1, "text": "EVALUATING CHATGPT ON MEDICAL INFORMATION EXTRACTION TASKS:\nPERFORMANCE, EXPLAINABILITY AND BEYOND\nLiz Li\nDataSelect AI\nXuhui, Shanghai, China\nWei Zhu∗\nUniversity of Hong Kong\nHong Kong, HK, China\nABSTRACT\nLarge Language Models (LLMs) like ChatGPT have demon-\nstrated amazing capabilities in comprehending user intents\nand generate reasonable and useful responses. Beside their\nability to chat, their capabilities in various natural language\nprocessing (NLP) tasks are of interest to the research commu-\nnity. In this paper, we focus on assessing the overall ability of\nChatGPT in 4 different medical information extraction (Me-\ndIE) tasks across 6 benchmark datasets. We present the sys-\ntematically analysis by measuring ChatGPT’s performance,\nexplainability, confidence, faithfulness, and uncertainty. Our\nexperiments reveal that: (a) ChatGPT’s performance scores\non MedIE tasks fall behind those of the fine-tuned baseline\nmodels. (b) ChatGPT can provide high-quality explanations\nfor its decisions, however, ChatGPT is over-confident in its\npredcitions. (c) ChatGPT demonstrates a high level of faith-\nfulness to the original text in the majority of cases. (d) The\nuncertainty in generation causes uncertainty in information\nextraction results, thus may hinder its applications in MedIE\ntasks.\nIndex Terms— Large Language Models, medical infor-\nmation extraction, ChatGPT, natural language processing\n1. INTRODUCTION\nLarge Language Models (LLMs) (e.g., GPT-3 [1], LaMDA\n[2] and PaLM [3], GPT-4 [4]) are the main forces in revolu-\ntionizing and advancing the field of Natural Language Pro-\ncessing (NLP) [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n35, 36, 37, 38, 39, 40, 41, 42, 43, 44]. LLMs are known for its\namazing abilities: (a) instruction and demonstration learning.\nWith a proper instruction of the task at hand and a few demon-\nstrations [45, 46, 47, 48, 49], the LLMs can perform tasks they\nare yet trained for. (b) chain-of-thought (CoT) [50, 51, 52]\ncapabilities. LLMs have demonstrated great performances in\nsolving a wide range of reasoning tasks by reasoning step-\nby-step. This reasoning capability is not observed in smaller\nmodels, thus is referred as an emergent ability in the literature\n∗Email: michaelwzhu91@gmail.com\n[53, 54, 55, 56, 57, 58, 59, 12, 60, 61, 62, 63, 64, 65, 66, 67,\n68, 69, 70, 71, 42, 72, 73, 74, 75].\nChatGPT1 has became the most popular AI based prod-\nuct within a short time span after its launch [76]. As a LLM,\nChatGPT is known for its impressive ability to comprehend\nthe user intents in the queries and repond with human-like\ncontents. ChatGPT is built on the GPT-3 model series [1,\n77, 45] using reinforcement learning from human feed-back\n(RLHF) [78, 79] and high-quality human-annotated datasets\nof user queries and responses. Apart from its ability to chat\nwith humans, ChatGPT has many other aspects that are of\ninterest to NLP researchers. A series of research work have\nemerged, investigating the capabilities of ChatGPT for vari-\nous NLP tasks, like sentiment analysis [80, 81], natural lan-\nguage inference [82], machine reading comprehension [83].\nThe capabilities of ChatGPT as a general NLP task solver\nhave been preliminarily explored in the above research and\nvaluable insights are drawn. There are also work addressing\nthe potential impact of ChatGPT on the society and human\nevery-day life [84, 85, 86, 87].\nIn this work, we conduct a comprehensive analysis of\nChatGPT’s abilities in medical information extraction (Me-\ndIE) tasks. MedIE requires the model to have a deep under-\nstanding of the medical texts, and extract structured factual\nknowledge of diversified forms [88, 89, 90, 30, 91], thus it is\nan ideal test-bed for evaluating ChatGPT’s capabilities. We\nconduct our experiments and analysis based on 6 datasets\nbelonging to 4 fine-grained MedIE tasks. Through our exper-\niments, we find that with carefully designed task instructions\nand demonstrations, ChatGPT still has clear performance\ngaps compared with fine-tuned baseline models, as depicted\nin Figure 1. In addition to the performance evaluation, we\nalso assess the explainability, faithfulness, confidence and un-\ncertainty of the ChatGPT’s responses through both automatic\nevaluations and manual evaluations by domain experts.\nOur contributions are summarized as follows:\n• We comprehensively evaluate the overall performance\nof ChatGPT on various MedIE tasks and compare it\nwith other popular models.\n1https://chat.openai.com/\narXiv:2601.21767v2  [cs.CL]  11 Feb 2026\n"}, {"page": 2, "text": "• To assess the overall ability of ChatGPT, we conduct\na systematic evaluation from five dimensions: perfor-\nmance, explainability, faithfulness, confidence and un-\ncertainty. Our codes are publicly available for future\nresearch.\n2. RELATED WORK\n2.1. Pretrained Large Language Models\nRecently, both the research field and the industry has seen\nthe raise of large language models (LLMs). LLMs typically\ncontain more than ten billion or even a hundred billion param-\neters, such as GPT-4 [4], GPT-3 [1], Gopher [92], Chinchilla\n[93], PaLM [3], Megatron-turing-NLG [94], etc. Scaling up\nthe size of LLMs has resulted in a series of interesting ob-\nservations: (a) scaling up the model size brings impressive\nabilities in few-shot and zero-shot learning scenarios, such as\nproducing reasonable results with very few task demonstra-\ntions or task descriptions [1, 3]. (b) scaling up the number of\ntasks in fine-tuning LLMs with instruction tuning improves\nthe generalizability on unseen tasks [95]. (c) Emergent capa-\nbilities are unlocked when the model size is scaled up to hun-\ndreds of billions, which were not observed in smaller models\n[53]. Notably, the chain of thought capability is observed in\nLLMs [50, 51, 52, 96].\nWith its impressive ability to understand user in-tent and\ngenerate human-like responses, ChatGPT has become the\nmost popular language model within a short period of time\nafter its lanuch. It is trained on the GPT family [1, 77, 45]\nand high-quality conversational-style datasets using rein-\nforcement learning from human feedback (RLHF) [78, 79].\nBesides its dialogue ability, ChatGPT is being exten-\nsively studied by the researchers. Some literature focus on\nthe ethical or other risks brought by the powerful LLMs\nlike ChatGPT [84, 85, 97]. chatGPT has also revolutionized\nthe traditional fields like education [87, 98] and medicine\n[80, 99, 100], and what will these industries advance with\nChatGPT is analyzed. There are also research work inves-\ntigating how ChatGPT performs in various natural language\nprocessing tasks. There are work testing ChatGPT on a wide\nrange of NLP tasks, but usually a random test subset of the\noriginal benchmark tasks is tested [20, 101]. Other works\nfocus on a specific type of tasks.\nFor instance, [102, 80]\nwork on sentiment analysis, [103] works on commonsense\nreasoning. The ChatGPT’s ability of machine translation is\nexamined in [104]. [105] evaluates the mathematical capa-\nbilities of ChatGPT. Additionally, [106, 107] investigate the\ndifferences between human-written and ChatGPT-generated\ncontents in tasks like summarization and question answering,\nand the linguistic and grammatical features of ChatGPT’s\nresponses are analyzed.\n2.2. Information Extraction\nInformation Extraction (IE) is a research topic of long his-\ntory that aims to extract structured knowledge or factual in-\nformation from unstructured texts [108]. The field of IE in-\ncludes a wide range of tasks, such as named entity recogni-\ntion [109, 110], relation extraction (RE) [111, 112], event ex-\ntraction [113], aspect-level sentiment analysis [114]. Since\nthe raise of pre-trained models like BERT [115], the perfor-\nmances on IE tasks have advanced greatly [116]. But one has\nto have different model structures for different fine-grained IE\ntasks, for instance, the SOTA nested NER models [117] are\ndifferent from those of discontinuous NER tasks [118]. Re-\ncently, there is a trend that all the IE task should be solved by\na unified paradigm, that is, Seq2Seq generation. [119] pro-\nposes the framework of BartNER which solves all types of\nNER tasks with a BART model [120]. UIE [121] takes a step\nahead and proposes to use prompts and a unified structural\nlanguage to deal with many types of IE tasks with a single\nmodel checkpoint.\nWith the rise of LLMs, the research field of IE is also un-\nder revolution, and this work contributes to the literature by\nconducting a deep investigation into the ChatGPT’s capabili-\nties in MedIE tasks.\n2.3. Medical natural language processing\nThe developments in neural networks and natural language\nprocessing has advanced the field of medical natural language\nprocessing (MedNLP) [122, 88, 30]. In the pre-BERT era,\nfirstly, RNNs like LSTM/GRU are used for processing se-\nquential medical data such as text and speech [123]. Con-\nvolutional networks are also used for medical text classifi-\ncaiton [124]. The techniques of Graph neural networks are\nalso explored for diagnose recommendations [125]. In this\nperiod, many different model architectures are specially de-\nsigned for better performances on a specific MedNLP task\n[30, 91, 126]. Since BERT [115], the pretrained language\nmodels (PLMs) become the deafult solution for MedNLP. In\nthis stage, researcher becomes less interested in modifying\nthe model architecture, but instead trying to pretrain or further\npretrain a PLM from the open domain to the medical domain\n[127, 116, 128].\nWith the wide study of LLMs, the field of MedNLP is also\nbeing revolutionized. There are already works on adapting\nLLM backbones to the medical domain question answering\n[129]. And [130] propose PromptCBLUE, a prompt learning\nbased benchmark dataset for examing the LLMs’ ability in\nMedNLP tasks. This work investigates MedIE capabilities in\nChatGPT, and provide a deeper understanding of LLMs for\nfuture MedNLP research.\n"}, {"page": 3, "text": "Fig. 1. Performance comparisons of ChatGPT and the baseline models.\n3. CHATGPT FOR MEDIE\nIn this section, we first briefly introduce six fine-grained Me-\ndIE tasks, then we present how to evaluate ChatGPT’s perfor-\nmances on these tasks with five different metric dimensions.\nThe evaluation procedure involves annotations by the domain\nexperts.\n3.1. MedIE tasks\nMedIE involves a wide range of tasks which need to extract\nstructured factual information from unstructured medical\ntexts, such as entity, and relation, and event. In this research,\nwe conduct our analysis on the following 4 MedIE tasks:\nNamed entity recognition (NER)\nNER aims to first\nidentify the candidate medical entities, and then classify their\ntypes. Medical NER is known for its complexity, since it usu-\nally involves nested entities or discontinous entities [119].\nTriple extraction (TE)\nThis task identifies the target\nentities and the relations between each pair of entities jointly.\nThe medical knowledge is expressed not by entities, but their\nrelations. For example, a medicine can cure a diease, or a\nsymptom is caused by a disease. This task is generally more\ncomplex than merely identifying entities or classifying the re-\nlations of a given pair of entities.\nClinical Event Extraction (CEE)\nThis task is an exam-\nple of event detection tasks [131] in the medical field. Same as\nthe general event detection tasks, medical CEE task requires\na model to identify the event triggers, classify the event types\nand extracts different arguments and categorize their roles\nwith respect to the target events.\nICD encoding\nThis task aims to map the diagnosis\nterms (query terms) written by doctors to standardized dis-\nease terms (target terms) according to a certain standard\n[132].\nThe number of standardized terms may exceed 10\nthouand. Recently, this task is modeled by a system where\na small set of candidate terms are firstly retrieved and then a\nranking model scores and ranks the relevances of each query-\ntarget term pair [133]. The standard system adopted in this\ntask is usually the International Statistical Classification of\nDiseases and Related Health Problems 10th Revision (ICD-\n10)2. ICD-10 has more than 30 thousand disease terms, thus\nit is prohibitive to feed all the disease terms into ChatGPT.\nWe first retrieve candidate target terms for each query term\nusing BM25 [134], then ask ChatGPT to be a ranking model\nand choose the final target terms among the candidates. ICD-\n10 has different versions in different countries, and in this\nwork we adopt the ICD-10 Beijing Clinical Trial (version\nv601)3. We will refer to this Chinese version of ICD-10 as\nICD-10-Beijing.\nIn summary, every task needs LLMs’ unique ability to\nperform well. It is worth to explore the performances on these\nfine-grained MedIE tasks on ChatGPT.\n3.2. Composition of task prompts\nTo comprehensively evaluate the overall perfor-mance of\nChatGPT on IE tasks, we ask ChatGPT to generate the re-\nsponses under the closed MedIE setting. In the closed MedIE\nsetting [135], the labels of the entities/relations/events are\npre-defined and a model to extract information accordingly\nand no other information should be extracted. The closed\nMedIE paradigm is the most commomly used in previous\nworks, which uses the task-specific dataset with supervised\nlearn-ing paradigm to finetune a model like BERT [115].\n2https://www.who.int/standards/classifications/classification-of-diseases\n3http://www.cips-chip.org.cn/2021/eval3\n"}, {"page": 4, "text": "For ChatGPT, as we can not directly fine-tune the model\nparameters, we evaluate the ChatGPT’s ability to conduct Me-\ndIE with task prompts. Specifically, the task prompt consists\nof the following parts:\n• Task descriptions, describing the objective of the task,\nand the steps that should be taken to achieve the objec-\ntive.\n• label sets, containing all the candidate labels in this\ntask. This part also includes the explanations of the\nlabels.\n• Output formats, regulating the formats of the responses.\nSince MedIE tasks extract structured information from\nthe un-structured texts, what fields are in the output re-\nsults should be specified. And we need to specify the\noutput formats so that we can evaluate the performance\nof ChatGPT.\n• Demonstrations: with a few input-output examples of\nan unseen task, the LLMs can learn from the examples\nand perform the task without optimizing any parame-\nters [49].\n• The input text of the sample that we want the model to\nmake prediction on.\nThe prompts is in the same language as the MedIE\ntask.\nDue to limited length, we only present the prompt\nfor CMeEE-v2 [136], a Chinese NER task, in Table 1. The\nleft size is the prompt contents in Chinese, and the right size\nis their English translation.\n3.3. Evaluation protocols\nTo systemically and comprehensively evaluate the ChatGPT’s\ncapabilities on the MedIE tasks, we evalute ChatGPT’s re-\nsponses under the five dimensions:\n• Performance.\nOne import objective of this work is\nto comprehensively evaluate the overall performance\nof ChatGPT against the ground truth on various Me-\ndIE tasks and compare it with other popular fine-tuned\nmodels.\n• Explainability\nIn this work, we examine the ex-\nplainability of ChatGPT by asking it to provide detailed\nand accurate explainations of its reasoning processes\nfor conducting information extraction on a given task.\nWe collect the explainations from ChatGPT at two lev-\nels: (a) sample level (denoted as sample level explain),\nthat is, we ask ChatGPT to provide an overall explaina-\ntion of the whole input’s extraction results. (b) instance\nlevel, (denoted as instance level explain), that is, ex-\nplanation is provided for each extracted instance (for\nexample, each entity mention).\n• Faithfulness\nThe faithfulness of LLMs is important\nto ensure their trustworthiness [137].\nFor evaluat-\ning ChatGPT’s faithfulness, we examine two aspects:\n(a) whether the responses made by ChatGPT follows\nthe task instructions and extract information from the\ninput.\nThis aspect of faithfulness is denoted as In-\nstruct following (b) whether the explainations made by\nthe ChatGPT are faithful to the original sample input.\nThis aspect is denoted as faithful reasoning.\n• Confidence\nWe aim to examine whether ChatGPT\nhas over-confidence phenomenon.\n• Uncertainty\nSince ChatGPT generates responses us-\ning the top-p sampling [138] decoding algorithm, the\nprediction uncertainty of ChatGPT is an important as-\npect that should be considered when applying Chat-\nGPT to different applications. In this work, we measure\nthe prediction uncertainty of ChatGPT by querying the\nsame sample to ChatGPT API for 5 times and measure\nthe differences among different runs.\n4. PERFORMANCES\n4.1. Experimental Setups\nTo ensure a comprehensive evaluation of ChatGPT’s abili-\nties on the MedIE task, we conduct experiments on a diverse\nrange of MedIE tasks, including 4 different tasks spanning 6\ndatasets: (a) for medical NER tasks, we include three widely\nstudied benchmark datasets, ShARe13 [139], CADEC [140],\nCMeEE-V2 [136]. (b) for triple extraction task, we include\nthe CMeIE-v2 dataset [141]; (c) The CDEE dataset [142] is a\nbenchmark Chinese clinical event extraction task. (d) for the\nICD-coding task, the CHIP-CDN task [142] is adopted for\nevaluation.\nWe use the official OpenAI API (with the gpt-3.5-turbo\nengine) to obtain the ChatGPT responses. To prevent any\nbiases caused by historical chats, we cleared the conversa-\ntion after generating each response. For the ShaRE-2013 and\nCADEC datasets, we ask ChatGPT to evaluate on the test set.\nFor the rest tasks, the test set ground truths are not publicly\navailable, so we conduct evaluations on the development set.\nOtherwise specified, we choose the first two samples from the\ntraining set as demonstrations.\nFor comparison, we compare ChatGPT with a series of\npopular baselines: (1) BERT fine-tuning. For all the six task,\nwe adopt the bi-affine attention module as the prediction mod-\nule, following [143] (2) UIE [121]. (3) The state-of-the-art\n(SOTA) methods on each dataset, as reported in Table 2.\nFor each task, we report the instance level strict F1-\nscore. Here, an instance is a piece of structured informa-\ntion/knowledge from the un-structured text.\nFor example,\nthe entity mention and entity type constitutes an instance for\nthe NER tasks. For the ICD coding task, since a diagnosis\n"}, {"page": 5, "text": "Table 1. The task prompt for the medical NER task CMeEE-v2 [136]. The left is the prompt in Chinese, and the right size is\nits English translation\n任务名称：\nTask name\n医疗文本实体抽取\nNER for medical texts\n任务描述：\nTask description:\n对于给定的一组纯医学文本文档，任务的目标是识别并抽取出与医学临床相关的实体，\n并将他们归类到预先定义好的类别。\n实体类型含义解释：\nExplanations of the entity labels:\n1. 疾病：指导致病人处于非健康状态的原因或者医生对病人做出的诊断，并且是能够被治疗的。\n包括疾病或综合征、中毒或受伤、器官或细胞受损等\n2. 临床表现：疾病的表现，泛指患者不适感觉以及通过检查得知的异常表现。主要包括症状、体征\n3. 医疗程序：泛指为诊断或治疗所采取的措施、方法及过程。主要包括检查程序、治疗或预防程序等\n4. 医疗设备：泛指为诊断或治疗所使用的工具、器具、仪器等。主要包括检查设备、治疗设备\n5. 药物：指用来预防、治疗及诊断疾病的物质，包括临床药物、抗生素等\n6. 医学检验项目：指检查涉及到的体液检查项目、重要生理指标以及其他检查项目，主要针对人体而言，\n是能够通过设备或实验检测出的项目，并且是能够被量化，有其对应的测量值或指标值\n7. 身体解剖部位：泛指细胞、组织、及位于人体特定区域的由细小物质成分组合而成的结构、\n器官、系统、肢体，另外包括身体产生或解剖身体产生的物质等\n8. 科室：指医院或医疗机构所设有的科室\n9. 微生物类：包括细菌、病毒、真菌以及一些小型的原生生物、\n显微藻类等在内的一大类生物群体，另外包括微生物类产生的毒素、激素、酶等\n1. Disease: refers to the cause of the patient’s unhealthy state or the doctor’s diagnosis of the patient,\nand it can be treated. Including diseases or syndromes, poisoning or injury, organ or cell damage, etc.\n2. Clinical manifestations: manifestations of diseases, generally referring to the patient’s discomfort\nand abnormal manifestations learned through examination. It mainly includes symptoms and signs\n3. Medical procedure: generally refers to the measures, methods and processes adopted for diagnosis or\ntreatment. It mainly includes inspection procedures, treatment or prevention procedures, etc.\n4. Medical equipment: generally refers to tools, appliances, instruments, etc. used for diagnosis or treatment.\nMainly including inspection equipment, treatment equipment\n5. Drugs: refer to substances used to prevent, treat and diagnose diseases,\nincluding clinical drugs, antibiotics, etc.\n6. Medical inspection items: refer to body fluid inspection items, important physiological indicators\nand other inspection items involved in the inspection, mainly for the human body,\nand is an item that can be detected by equipment or experiments, and can be quantified,\nand has its corresponding measurement value or index value\n7. Body anatomical parts: generally refer to cells, tissues, and specific areas located in the human\nbody structures, organs, systems, and limbs composed of small material components, including\nsubstances produced by the body or dissected by the body, etc.\n8. Department: refers to the department set up by a hospital or medical institution\n9. Microorganisms: a large group of organisms including bacteria, viruses, fungi, some small protists,\nmicroscopic algae, etc., and toxins, hormones, enzymes, etc. produced by microorganisms\n示例：\n-\n示例1\ninput: 对儿童SARST细胞亚群的研究表明，与成人SARS相比，儿童细胞下降不明显，\n证明上述推测成立。\ntarget: [{’实体类型’: ’身体解剖部位’, ’实体名称’: ’SARST细胞亚群’},\n{’实体类型’: ’疾病’, ’实体名称’: ’成人SARS’},\n{’实体类型’: ’临床表现’, ’实体名称’: ’细胞下降’},\n{’实体类型’: ’身体解剖部位’, ’实体名称’: ’细胞’}]\nExample 1\ninput: The research on children’s SARST cell subsets shows that compared with adult SARS,\nthe children’s cells are not significantly reduced, proves that the above speculation is true.\ntarget: [{’Entity Type’: ’Body Anatomy’, ’Entity Name’: ’SARST Cell Subgroup’},\n{’Entity Type’: ’Disease’, ’ Entity name’: ’Adult SARS’},\n{’Entity type’: ’Clinical manifestation’, ’Entity name’: ’Cell decline’},\n{’Entity type’: ’Body Anatomy’, ’Entity Name’: ’Cell’}]\n输出格式规定：\nOutput format：\n1. 本任务的输出一个字典的列表，必须符合json格式。\n2. 每个字典代表一个医学实体，包含\\”实体类型\\”, \\”实体名称\\”字段，每个字段的取值都为字符串。\n3. 实体名称：即为医学实体在给定的文本中的出现形式，实体名称可以包含必要的标点符号，\n即可以是一个词、短语或句子。“临床表现”实体类别中允许嵌套，即该类型实体的名称内部可能\n包含其他八类实体。除了“临床表现”实体之外的医学实体，在抽取其实体名称时遵循“最大单位\n标注法”，即如果一个实体名称里包含其他的实体，只需要将最长的实体标注出来\n4. 注意：你需要一步步的思考，然后形成医学实体列表。\n1. The output of this task is a list of dictionaries, which must conform to the json format.\n2. Each dictionary represents a medical entity, including \\”entity type\\”, \\”entity name\\” fields,\nand the value of each field is a string .\n3. Entity name: It is the appearance form of the medical entity in the given text, the entity name can\ncontain necessary punctuation marks, and it can be a word, phrase or sentence. Nesting is allowed in\nthe ”clinical manifestation” entity category, that is, the name of this type of entity may contain other eight\ntypes of entities. Medical entities other than ”clinical manifestation” entities follow the ”maximum unit\nlabeling method” when extracting their entity names, that is, if an entity name contains other entities,\nonly the longest entity needs to be marked out\n4. Note: You need to think step by step, and then form a list of medical entities.\n输入:\nCurrent input text:\ninput:【发病率】自1952年Bruton报告首例先天性无丙种球蛋白血症（congenitalagammaglobulinemia）\n以来，全球报道的PID病例已愈万例，但其总发病率尚无确切资料。\ninput: [Incidence] Since Bruton reported the first case of congenital agammaglobulinemia\n(congenital agammaglobulinemia) in 1952, more than 10,000 cases of PID have been reported\nworldwide, but there is no definite information on the total incidence.\n"}, {"page": 6, "text": "term from the doctor may correspond to more than one ICD\nstandard terms, an instance in this task is defined as a ICD-10\nstandard disease term. The F1-score metric we adopt is strict,\nin the sense that the true positive number will add one only\nwhen all the keys in an ground-truth instance is correctly\npredicted.\nDue to the time-consuming nature of obtaining responses\nfrom domain experts, we randomly select 200 samples for\neach task for manual annotations.\nFor each sample, we\nask the human experts to annotate sample level explain, in-\nstance level explain and faithfull reasoning as boolean val-\nues.\n4.2. Performance of ChatGPT\nIn this subsection, we report the performances of different\nmodels including ChatGPT on the six benchmark MedIE\ntasks in Table 2.\nIt is clear from Table 2 that ChatGPT’s\nperformance is not comparable to that of the fully fine-tuned\nbaseline models or the SOTA methods in any of the MedIE\ntasks. This is not surprising given that ChatGPT does not\nfine-tune its parameters to adapt to the task, and asking it\nfor the prediction with only prompts is an extreme few-shot\nscenario.\nIn comparison, the other compared models are\nfully fine-tuned on task-specific datasets under a supervised\nlearning paradigm. Another reason may be that the meaning\nof some labels may not be easy to understand even though\nwe have provide explanations, thereby negatively impact the\nperformance. In addition, we can see that due to the top-p\nsampling strategy, the standard deviation (i.e., uncertainty) in\nperformance scores for ChatGPT is generally higher than the\nbaseline models.\nThe results in Table 2 indicate that ChatGPT performs\nslightly better on relatively simple MedIE tasks but have dif-\nficulty in dealing with complex and challenging tasks. For\nexample, the ICD coding task only involves matching the di-\nagnoses term from medical records to the candidate standard\nterms from the ICD-10 vocabulary, and no further contextual\nunderstanding are required. And since in the CMeEE task,\neven though there are nested entities, more than 90% of the\nentities are flat. Thus, ChatGPT can achieve F1-scores of\naround 30 in these two tasks. However, in the more com-\nplex tasks like CMeIE-v2, ChatGPT struggles as it needs to\nfirstly identify the entities that exist in the input and then iden-\ntify which entity pairs have meaningful relationships. In sum-\nmary, ChatGPT’s performance varies based on the complexity\nof the task.\nNote that in our results, the ChatGPT falls behind the fine-\ntuned baseline models. This conclusion is inconsistent with\nthe previous studies [82, 147, 148], which show that ChatGPT\ncan achieve desirable performance in a wide range of NLP\ntasks including IE tasks. One possible explanation for the\ndifference in conclusions is that we report the performance of\nthe entire dev or test set for each task in our study, while prior\nstudies reported on a very small set of test samples drawn at\nrandom, which may have substantial variance. In addition,\nthe MedIE tasks requires domain knowledges and are more\ncomplex and challenging than the tasks in the general domain\n[128].\n4.3. Other evaluation dimensions\nWhile it is important to obtain ChatGPT’s performance in\nevaluation, it is equally important to evaluate its capabilities\nfrom a wide range of dimensions that could offer important\ninsights for future research. In this subsection, we analyze\nthe explainability, faithfulness and confidence to give better\ninsights into the ChatGPT’s abilities.\n4.3.1. Explainability\nExplainability is an essential factor for the modern neu-\nral networks like LLMs, as it allows users to understand\nhow the model arrives at its predictions and be comfortable\nusing the applications supported by LLMs. To evaluate in-\nstance level explain, we only consider the correctly predicted\ninstances to ensure a valid evaluation of ChatGPT’s explain-\nability ability. The ratio of samples/instances with reasonable\nexplanations (denoted as R-score) for each task is reported in\nTable 3, and the following take-aways can be drawn. Firstly,\nhuman annotators approve the reasons given by ChatGPT,\nwith the majority of datasets achieving a R-score of over\n750%. The above results demonstrate that ChatGPT gives\nhigh-quality explanation for its prediction. Secondly, we find\nthat ChatGPT seems to be over-confident in its explanations,\nsince on the wrong predictions ChatGPT can also provide\nexplanations with confident tones and it can not reflect on its\nmistakes.\n4.3.2. Confidence\nIn this part, we investigate the level of confidence provided\nby ChatGPT for both the correctly and incorrectly predicted\ninstances. Our objective is to investigate whether ChatGPT\ncan provide reasonable prediction confidence scores for its\npredictions, thus reducing the risk of over-confidence or mis-\ninterpretation. In Table 4, we present the average confidence\nscores of correct and incorrect predictions from ChatGPT, re-\nferred to CC-score and IC-score, respectively. The results in\nTable 4 reveal that ChatGPT has high confidence levels in\ntheir correct and incorrect predictions. This is in line with the\nprevious literature reporting that large scale neural network\nmodels are over-confident [149]. This overconfidence may\npresent risk of misguidances to users.\nIn addition, we find two additional observations: (a) there\nare no significant gaps between the CC-score and IC-score,\nindicating the need for careful evaluation of ChatGPT’s out-\nputs since high confidence scores does not mean the predic-\ntions are more likely to be correct. (b) The confidence scores\n"}, {"page": 7, "text": "Table 2. The performances of ChatGPT and several baseline models on the six MedIE datasets. We report the average perfor-\nmance on the whole dev set over 5 different runs (with standard deviations reported in brackets). All the baseline models are\nre-implemented using official open-source codes.\nMedIE Tasks\nDataset\nBERT\nUIE\nSOTA\nChatGPT\nNamed Entity Recognition\nShARe13\n76.5 (±0.2)\n78.8 (±0.4)\n79.6 (±0.7) [118]\n23.5 (±1.2)\nCADEC\n70.3 (±0.4)\n70.6 (±0.6)\n71.6 (±0.4) [118]\n19.7 (±1.5)\nCMeEE-v2\n66.2 (±0.3)\n66.7 (±0.4)\n68.5 (±0.3) [144]\n39.8 (±2.1)\nTriple Extraction\nCMeIE-v2\n58.6 (±0.1)\n57.4 (±0.3)\n60.1 (±0.5) [145]\n9.9 (±0.8)\nEvent Extraction\nCHIP-CDEE\n62.4 (±0.5)\n64.1 (±0.5)\n65.8 (±0.4) [146]\n26.1 (±1.8)\nICD Coding\nCHIP-CDN\n78.9 (±0.3)\n82.3 (±0.2)\n84.9 (±0.3) [130]\n30.9 (±1.1)\nTable 3. The R-scores for the explanations provded by the\nChatGPT of its prediction both at the sample level and in-\nstance level.\nDataset\nsample-level R-score\ninstance-level R-score\nShARe13\n76%\n91%\nCADEC\n77%\n89%\nCMeEE-v2\n81%\n93%\nCMeIE-v2\n79%\n95%\nCHIP-CDEE\n76%\n92%\nCHIP-CDN\n77%\n88%\nTable 4. The average confidence scores estimated by Chat-\nGPT for its predicted instance. The standard devaitions of\nconfidence scores are reported in bracket.\nDataset\nCC-score\nIC-score\nShARe13\n81.4 (±1.2)\n81.1 (±0.9)\nCADEC\n79.8 (±1.0)\n80.1 (±1.7)\nCMeEE-v2\n82.2 (±0.8)\n81.9 (±1.1)\nCMeIE-v2\n79.6 (±1.3)\n78.9 (±1.1)\nCHIP-CDEE\n79.3 (±1.5)\n79.1 (±1.3)\nCHIP-CDN\n81.5 (±0.9)\n80.7 (±0.8)\nhave lower standard deviations. In fact, many of the samples\nhave the same confidence scores. The above two observations\nreveal the un-reliability of ChatGPT’s confidence scores.\n4.3.3. Faithfulness\nAssessing the faithfulness of ChatGPT is critical in develop-\ning a trustworthy information extraction model. Recent work\nargue that LLMs could provide hullucinated information to\nusers, which could potentially misguide the users’ decision\nmaking [150]. In this work, we measure the faithfulness of\nChatGPT on the MedIE tasks in the following two aspects:\n(a) Instruct following, that is, whether the responses made by\nChatGPT follows the task instructions and extract information\nstrictly following the inputs and the given label sets or candi-\ndate sets. (b) faithful reasoning, that is, whether the expla-\nnations given by ChatGPT are faithful to the original sample\ninputs.\nTable 5 reports the ratio of the annotated samples in\nTable 5. The ratio of the annotated samples in which the In-\nstruct following or faithful reasoning key is true\nDataset\nInstruct following\nfaithful reasoning\nShARe13\n86%\n96%\nCADEC\n87%\n93%\nCMeEE-v2\n89%\n94%\nCMeIE-v2\n83%\n91%\nCHIP-CDEE\n89%\n95%\nCHIP-CDN\n82%\n93%\nwhich the Instruct following or faithful reasoning key is\ntrue. We can see that on most of the MedIE tasks, the In-\nstruct following and faithful reasoning scores exceed 80%,\nshowing that ChatGPT can follow the task instructions and\nits explanations are regarded as reliable according to the in-\nputs. This result also demonstrate that the performance gap\nfrom ChatGPT to the fine-tuned baselines are not caused by\ngenerating labels that are not in the label sets.\n5. CONCLUSIONS\nIn this paper, we systematically analyze the ChatGPT’s per-\nformance, uncertainty, explainability, over-confidence and\nfaithfulness on medical information extraction (MedIE) tasks.\nWith carefully designed task prompts, we collect ChatGPT’s\nresponses via OpenAI APIs. Expert annotations are included\nfor reliable evaluation. On the 6 MedIE tasks, we find that:\n(a) ChatGPT’s performance is not satisfying compared to\nfully fine-tuned baseline models. (b) ChatGPT can provide\nvalid explanations for its predictions. (c) The over-confidence\nissue is observed in ChatGPT, indicating low calibration and\nrisk for application. (d) ChatGPT exhibits faithfulness to the\ninput texts and task prompts. (e) The uncertainty caused by\nthe randomness in response decoding results in high uncer-\ntainty in the predicted results. We hope that our work could be\nthe basis for future research on applying LLMs like ChatGPT\nfor information extraction.\n"}, {"page": 8, "text": "6. REFERENCES\n[1] Tom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al., “Language models are few-shot learn-\ners,” 2020, vol. 33, pp. 1877–1901.\n[2] Romal Thoppilan, Daniel De Freitas, Jamie Hall,\nNoam Shazeer,\nApoorv Kulshreshtha,\nHeng-Tze\nCheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du,\net al., “Lamda: Language models for dialog applica-\ntions,” arXiv preprint arXiv:2201.08239, 2022.\n[3] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts, Paul\nBarham, Hyung Won Chung, Charles Sutton, Sebas-\ntian Gehrmann, et al., “Palm: Scaling language model-\ning with pathways,” arXiv preprint arXiv:2204.02311,\n2022.\n[4] OpenAI, “GPT-4 Technical Report,” arXiv e-prints, p.\narXiv:2303.08774, Mar. 2023.\n[5] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama\nAhmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo\nAlmeida, Janko Altenschmidt, Sam Altman, Shyamal\nAnadkat, et al.,\n“Gpt-4 technical report,”\narXiv\npreprint arXiv:2303.08774, 2023.\n[6] Rohan Anil, Andrew M Dai, Orhan Firat, Melvin\nJohnson, Dmitry Lepikhin, Alexandre Passos, Siamak\nShakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen,\net al.,\n“Palm 2 technical report,”\narXiv preprint\narXiv:2305.10403, 2023.\n[7] Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mah-\ndavi, Jason Wei, Hyung Won Chung, Nathan Scales,\nAjay Tanwani, Heather Cole-Lewis, Stephen Pfohl,\net al., “Large language models encode clinical knowl-\nedge,” Nature, pp. 1–9, 2023.\n[8] Karan Singhal, Tao Tu, Juraj Gottweis, Rory Sayres,\nEllery Wulczyn, Le Hou, Kevin Clark, Stephen Pfohl,\nHeather Cole-Lewis, Darlene Neal, et al., “Towards\nexpert-level medical question answering with large\nlanguage models,” arXiv preprint arXiv:2305.09617,\n2023.\n[9] Harsha Nori, Nicholas King, Scott Mayer McKinney,\nDean Carignan, and Eric Horvitz,\n“Capabilities of\ngpt-4 on medical challenge problems,” arXiv preprint\narXiv:2303.13375, 2023.\n[10] Yuzhen Huang, Yuzhuo Bai, Zhihao Zhu, Junlei\nZhang, Jinghan Zhang, Tangjun Su, Junteng Liu,\nChuancheng Lv, Yikai Zhang, Jiayi Lei, et al.,\n“C-\neval: A multi-level multi-discipline chinese evalua-\ntion suite for foundation models,”\narXiv preprint\narXiv:2305.08322, 2023.\n[11] Haonan Li, Yixuan Zhang, Fajri Koto, Yifei Yang,\nHai Zhao, Yeyun Gong, Nan Duan, and Timothy\nBaldwin,\n“Cmmlu:\nMeasuring massive multitask\nlanguage understanding in chinese,”\narXiv preprint\narXiv:2306.09212, 2023.\n[12] Ganqu Cui, Lifan Yuan, Ning Ding, Guanming Yao,\nWei Zhu, Yuan Ni, Guotong Xie, Zhiyuan Liu, and\nMaosong Sun,\n“Ultrafeedback: Boosting language\nmodels with high-quality feedback,”\nArXiv, vol.\nabs/2310.01377, 2023.\n[13] Pengfei Wang, Huanran Zheng, Silong Dai, Wenjing\nYue, Wei Zhu, and Xiaoling Wang, “Ts-tcd: Triplet-\nlevel cross-modal distillation for time-series forecast-\ning using large language models,”\narXiv preprint\narXiv:2409.14978, 2024.\n[14] Wei Zhu Wenjing Yue and Xiaoling Wang, “Tcmeb:\nPerformance evaluation of large language models\nbased\non\ntraditional\nchinese\nmedicine\nbench-\nmarks,”\nhttps://github.com/ywjawmw/\nShenNong-TCM-Evaluation-BenchMark,\n2023.\n[15] Yuming Zhang, Peng Wang, Ming Tan, and Wei-Guo\nZhu, “Learned adapters are better than manually de-\nsigned adapters,” in Annual Meeting of the Association\nfor Computational Linguistics, 2023.\n[16] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,\nXiaolei Wang, Yupeng Hou, Yingqian Min, Beichen\nZhang, Junjie Zhang, Zican Dong, Yifan Du, Chen\nYang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang,\nRuiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu,\nPeiyu Liu, Jian-Yun Nie, and Ji-Rong Wen, “A Sur-\nvey of Large Language Models,”\narXiv e-prints, p.\narXiv:2303.18223, Mar. 2023.\n[17] Lingling Xu, Haoran Xie, Si-Zhao Joe Qin, Xiao-\nhui Tao, and Fu Lee Wang,\n“Parameter-efficient\nfine-tuning methods for pretrained language mod-\nels: A critical review and assessment,”\nArXiv, vol.\nabs/2312.12148, 2023.\n[18] Ning Ding, Yujia Qin, Guang Yang, Fu Wei, Zong-\nhan Yang, Yusheng Su, Shengding Hu, Yulin Chen,\nChi-Min Chan, Weize Chen, Jing Yi, Weilin Zhao, Xi-\naozhi Wang, Zhiyuan Liu, Haitao Zheng, Jianfei Chen,\nYang Liu, Jie Tang, Juan Li, and Maosong Sun, “Delta\ntuning: A comprehensive study of parameter efficient\nmethods for pre-trained language models,” ArXiv, vol.\nabs/2203.06904, 2022.\n"}, {"page": 9, "text": "[19] Yi Xin, Siqi Luo, Haodi Zhou, Junlong Du, Xiaohong\nLiu, Yue Fan, Qing Li, and Yuntao Du, “Parameter-\nefficient fine-tuning for pre-trained vision models: A\nsurvey,” ArXiv, vol. abs/2402.02242, 2024.\n[20] Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao\nChen, Michihiro Yasunaga, and Diyi Yang, “Is chat-\ngpt a general-purpose natural language processing task\nsolver?,” arXiv preprint arXiv:2302.06476, 2023.\n[21] Wei Zhu, Xiaoling Wang, Huanran Zheng, Mosha\nChen, and Buzhou Tang, “PromptCBLUE: A Chinese\nPrompt Tuning Benchmark for the Medical Domain,”\narXiv e-prints, p. arXiv:2310.14151, Oct. 2023.\n[22] Wei Zhu, Wenfeng Li, Xiaoling Wang, Wendi Ji,\nYuanbin Wu, Jin Chen, Liang Chen, and Buzhou\nTang, “Extracting decision trees from medical texts:\nAn overview of the text2dt track in chip2022,”\nin\nHealth Information Processing. Evaluation Track Pa-\npers, Buzhou Tang, Qingcai Chen, Hongfei Lin, Fei\nWu, Lei Liu, Tianyong Hao, Yanshan Wang, Haitian\nWang, Jianbo Lei, Zuofeng Li, and Hui Zong, Eds.,\nSingapore, 2023, pp. 89–102, Springer Nature Singa-\npore.\n[23] Wei Zhu, Wenfeng Li, Xiaoling Wang, Wendi Ji,\nYuanbin Wu, Jin Chen, Liang Chen, and Buzhou\nTang, “Extracting decision trees from medical texts:\nAn overview of the text2dt track in chip2022,”\nin\nHealth Information Processing. Evaluation Track Pa-\npers, Buzhou Tang, Qingcai Chen, Hongfei Lin, Fei\nWu, Lei Liu, Tianyong Hao, Yanshan Wang, Haitian\nWang, Jianbo Lei, Zuofeng Li, and Hui Zong, Eds.,\nSingapore, 2023, pp. 89–102, Springer Nature Singa-\npore.\n[24] Wei Zhu, Yilong He, Ling Chai, Yuanchun Fan, Yuan\nNi, Guo Tong Xie, and Xiaoling Wang,\n“paht nlp\n@ mediqa 2021: Multi-grained query focused multi-\nanswer summarization,” in Workshop on Biomedical\nNatural Language Processing, 2021.\n[25] Xiaonan Li, Kai Lv, Hang Yan, Tianya Lin, Wei Zhu,\nYuan Ni, Guo Tong Xie, Xiaoling Wang, and Xipeng\nQiu,\n“Unified demonstration retriever for in-context\nlearning,” ArXiv, vol. abs/2305.04320, 2023.\n[26] Wei Zhu, Peifeng Wang, Yuan Ni, Guo Tong Xie,\nand Xiaoling Wang,\n“Badge: Speeding up bert in-\nference after deployment via block-wise bypasses and\ndivergence-based early exiting,” in Annual Meeting of\nthe Association for Computational Linguistics, 2023.\n[27] Jingfang Zhang, Ming Tan, Pengyu Dai, and Wei-Guo\nZhu, “Leco: Improving early exiting via learned exits\nand comparison-based exiting mechanism,” in Annual\nMeeting of the Association for Computational Linguis-\ntics, 2023.\n[28] Wei Zhu, Xiaoling Wang, Mosha Chen, and Buzhou\nTang,\n“Overview of the promptcblue shared task in\nchip2023,” ArXiv, vol. abs/2312.17522, 2023.\n[29] Zhao Guo, Yuan Ni, Keqiang Wang, Wei Zhu, and\nGuotong Xie, “Global attention decoder for Chinese\nspelling error correction,”\nin Findings of the Asso-\nciation for Computational Linguistics: ACL-IJCNLP\n2021, Online, Aug. 2021, pp. 1419–1428, Association\nfor Computational Linguistics.\n[30] Wei Zhu, Yuan Ni, Xiaoling Wang, and Guotong Xie,\n“Discovering better model architectures for medical\nquery understanding,” in Proceedings of the 2021 Con-\nference of the North American Chapter of the Associa-\ntion for Computational Linguistics: Human Language\nTechnologies: Industry Papers, Online, June 2021, pp.\n230–237, Association for Computational Linguistics.\n[31] Huanran Zheng, Wei Zhu, Pengfei Wang, and Xiaoling\nWang, “Candidate soups: Fusing candidate results im-\nproves translation quality for non-autoregressive trans-\nlation,” ArXiv, vol. abs/2301.11503, 2023.\n[32] Haixia Sun, Jin Xiao, Wei Zhu, Yilong He, Sheng\nZhang, Xiaowei Xu, Li Hou, Jiao Li, Yuan Ni, and\nGuotong Xie, “Medical knowledge graph to enhance\nfraud, waste, and abuse detection on claim data: Model\ndevelopment and performance evaluation,” JMIR Med\nInform, vol. 8, no. 7, pp. e17653, Jul 2020.\n[33] Xinpeng Zhang, Ming Tan, Jingfan Zhang, and Wei\nZhu, “Nag-ner: a unified non-autoregressive genera-\ntion framework for various ner tasks,” in Annual Meet-\ning of the Association for Computational Linguistics,\n2023.\n[34] Yuming Zhang, Xiangxiang Gao, Wei Zhu, and Xiaol-\ning Wang, “Fastner: Speeding up inferences for named\nentity recognition tasks,” in International Conference\non Advanced Data Mining and Applications, 2023.\n[35] Xuwu Wang,\nLihan Chen,\nWei Zhu,\nYuan Ni,\nGuo Tong Xie, Deqing Yang, and Yanghua Xiao,\n“Multi-task entity linking with supervision from a tax-\nonomy,” Knowledge and Information Systems, vol. 65,\npp. 4335 – 4358, 2023.\n[36] Wei Zhu, Yuan Ni, Guo Tong Xie, Xiaofeng Zhou, and\nCai Chen, “The dr-kgqa system for automatically an-\nswering medication related questions in chinese,” 2019\nIEEE International Conference on Healthcare Infor-\nmatics (ICHI), pp. 1–6, 2019.\n"}, {"page": 10, "text": "[37] Wei Zhu,\n“Leebert:\nLearned early exit for bert\nwith cross-level optimization,” in Proceedings of the\n59th Annual Meeting of the Association for Compu-\ntational Linguistics and the 11th International Joint\nConference on Natural Language Processing (Volume\n1: Long Papers), 2021, pp. 2968–2980.\n[38] Zhexi Zhang, Wei Zhu, Junchi Yan, Peng Gao, and\nGuowang Xie,\n“Automatic student network search\nfor knowledge distillation,”\n2020 25th International\nConference on Pattern Recognition (ICPR), pp. 2446–\n2453, 2021.\n[39] Li Wang, Wei Zhu, Sihang Jiang, Sheng Zhang, Ke-\nqiang Wang, Yuan Ni, Guo Tong Xie, and Yanghua\nXiao, “Mining infrequent high-quality phrases from\ndomain-specific corpora,”\nProceedings of the 29th\nACM International Conference on Information &\nKnowledge Management, 2020.\n[40] Yuheng Li, Jiechao Gao, Wei Han, Wenwen Ouyang,\nWei Zhu, and Hui Yi Leong, “Ft-mdt: Extracting de-\ncision trees from medical texts via a novel low-rank\nadaptation method,” in Proceedings of the 2025 Con-\nference on Empirical Methods in Natural Language\nProcessing: Industry Track, 2025, pp. 65–76.\n[41] Hui Yi Leong, Yuheng Li, Yuqing Wu, Wenwen\nOuyang, Wei Zhu, Jiechao Gao, and Wei Han, “Amas:\nAdaptively determining communication topology for\nllm-based multi-agent system,” in Proceedings of the\n2025 Conference on Empirical Methods in Natural\nLanguage Processing: Industry Track, 2025, pp. 2061–\n2070.\n[42] Juyuan Zhang, Jiechao Gao, Wenwen Ouyang, Wei\nZhu, and Hui Yi Leong, “Time-llama: Adapting large\nlanguage models for time series modeling via dynamic\nlow-rank adaptation,” in Proceedings of the 63rd An-\nnual Meeting of the Association for Computational\nLinguistics (Volume 4: Student Research Workshop),\n2025, pp. 1145–1157.\n[43] Huiming Yin, Kun Wang, Ruyu Yang, Yanfang Tan,\nQiang Li, Wei Zhu, and Suzi Sung, “A machine learn-\ning model for predicting acute exacerbation of in-home\nchronic obstructive pulmonary disease patients,” Com-\nputer Methods and Programs in Biomedicine, vol. 246,\npp. 108005, 2024.\n[44] Wei Zhu, “Mrag: Benchmarking retrieval-augmented\ngeneration\nfor\nbio-medicine,”\narXiv\npreprint\narXiv:2601.16503, 2026.\n[45] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\nCarroll Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, et al.,\n“Training language models to follow instructions with\nhuman feedback,”\nAdvances in Neural Information\nProcessing Systems, vol. 35, pp. 27730–27744, 2022.\n[46] Hyung Won Chung, Le Hou, Shayne Longpre, Barret\nZoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang,\nMostafa Dehghani, Siddhartha Brahma, et al., “Scaling\ninstruction-finetuned language models,” arXiv preprint\narXiv:2210.11416, 2022.\n[47] Yizhong Wang, Swaroop Mishra, Pegah Alipoormo-\nlabashi, Yeganeh Kordi, Amirreza Mirzaei, Atharva\nNaik, Arjun Ashok, Arut Selvan Dhanasekaran, An-\njana Arunkumar,\nDavid Stap,\net al.,\n“Super-\nnaturalinstructions: Generalization via declarative in-\nstructions on 1600+ nlp tasks,”\nin Proceedings of\nthe 2022 Conference on Empirical Methods in Natu-\nral Language Processing, 2022, pp. 5085–5109.\n[48] Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe,\nMike Lewis, Hannaneh Hajishirzi, and Luke Zettle-\nmoyer, “Rethinking the role of demonstrations: What\nmakes in-context learning work?,”\narXiv preprint\narXiv:2202.12837, 2022.\n[49] Xiaonan Li, Kai Lv, Hang Yan, Tianyang Lin, Wei\nZhu, Yuan Ni, Guotong Xie, Xiaoling Wang, and\nXipeng Qiu, “Unified demonstration retriever for in-\ncontext learning,”\narXiv preprint arXiv:2305.04320,\n2023.\n[50] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Ed Chi, Quoc Le, and Denny Zhou, “Chain of\nthought prompting elicits reasoning in large language\nmodels,” arXiv preprint arXiv:2201.11903, 2022.\n[51] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le,\nEd Chi, and Denny Zhou, “Self-consistency improves\nchain of thought reasoning in language models,” arXiv\npreprint arXiv:2203.11171, 2022.\n[52] Takeshi Kojima, Shixiang Shane Gu, Machel Reid,\nYutaka Matsuo, and Yusuke Iwasawa,\n“Large lan-\nguage models are zero-shot reasoners,” arXiv preprint\narXiv:2205.11916, 2022.\n[53] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel,\nBarret Zoph, Sebastian Borgeaud, Dani Yogatama,\nMaarten Bosma, Denny Zhou, Donald Metzler, et al.,\n“Emergent abilities of large language models,” arXiv\npreprint arXiv:2206.07682, 2022.\n[54] Shubo Tian, Qiao Jin, Lana Yeganova, Po-Ting Lai,\nQingqing Zhu, Xiuying Chen, Yifan Yang, Qingyu\nChen, Won Kim, Donald C Comeau, et al., “Oppor-\ntunities and challenges for chatgpt and large language\nmodels in biomedicine and health,” Briefings in Bioin-\nformatics, vol. 25, no. 1, pp. bbad493, 2024.\n"}, {"page": 11, "text": "[55] William Hersh, “Search still matters: information re-\ntrieval in the era of generative ai,” Journal of the Amer-\nican Medical Informatics Association, p. ocae014,\n2024.\n[56] Wei Zhu, Aaron Xuxiang Tian, Congrui Yin, Yuan Ni,\nXiaoling Wang, and Guotong Xie, “Iapt: Instruction-\naware prompt tuning for large language models,” arXiv\npreprint arXiv:2405.18203, 2024.\n[57] Wei Zhu and Ming Tan, “SPT: Learning to selectively\ninsert prompts for better prompt tuning,” in Proceed-\nings of the 2023 Conference on Empirical Methods in\nNatural Language Processing, Houda Bouamor, Juan\nPino, and Kalika Bali, Eds., Singapore, Dec. 2023, pp.\n11862–11878, Association for Computational Linguis-\ntics.\n[58] Haokun Liu, Derek Tam, Mohammed Muqeeth, Jay\nMohta, Tenghao Huang, Mohit Bansal, and Colin A\nRaffel,\n“Few-shot parameter-efficient fine-tuning is\nbetter and cheaper than in-context learning,” Advances\nin Neural Information Processing Systems, vol. 35, pp.\n1950–1965, 2022.\n[59] Tianfang Xie, Tianjing Li, Wei Zhu, Wei Han, and\nYi Zhao, “Pedro: Parameter-efficient fine-tuning with\nprompt dependent representation modification,” arXiv\npreprint arXiv:2409.17834, 2024.\n[60] Huanran Zheng,\nWei Zhu,\nand Xiaoling Wang,\n“Nat4at: Using non-autoregressive translation makes\nautoregressive translation faster and better,”\nin Pro-\nceedings of the ACM on Web Conference 2024, 2024,\npp. 4181–4192.\n[61] Wei Zhu, Peng Wang, Xiaoling Wang, Yuan Ni, and\nGuotong Xie,\n“Acf: aligned contrastive finetuning\nfor language and vision tasks,” in ICASSP 2023-2023\nIEEE International Conference on Acoustics, Speech\nand Signal Processing (ICASSP). IEEE, 2023, pp. 1–\n5.\n[62] Xiangxiang Gao, Wei Zhu, Jiasheng Gao, and Con-\ngrui Yin, “F-pabee: Flexible-patience-based early ex-\niting for single-label and multi-label text classification\ntasks,” in ICASSP 2023-2023 IEEE International Con-\nference on Acoustics, Speech and Signal Processing\n(ICASSP). IEEE, 2023, pp. 1–5.\n[63] Yuhui Zuo, Wei Zhu, and Guoyong GUET Cai, “Con-\ntinually detection, rapidly react: Unseen rumors de-\ntection based on continual prompt-tuning,”\nin Pro-\nceedings of the 29th International Conference on Com-\nputational Linguistics, Gyeongju, Republic of Korea,\nOct. 2022, pp. 3029–3041, International Committee on\nComputational Linguistics.\n[64] Zhen Zhang, Wei Zhu, Jinfan Zhang, Peng Wang, Rize\nJin, and Tae-Sun Chung,\n“PCEE-BERT: Accelerat-\ning BERT inference via patient and confident early\nexiting,”\nin Findings of the Association for Com-\nputational Linguistics: NAACL 2022, Seattle, United\nStates, July 2022, pp. 327–338, Association for Com-\nputational Linguistics.\n[65] Tianxiang Sun, Xiangyang Liu, Wei Zhu, Zhichao\nGeng, Lingling Wu, Yilong He, Yuan Ni, Guotong Xie,\nXuanjing Huang, and Xipeng Qiu,\n“A simple hash-\nbased early exiting approach for language understand-\ning and generation,”\nin Findings of the Association\nfor Computational Linguistics: ACL 2022, Dublin, Ire-\nland, May 2022, pp. 2409–2421, Association for Com-\nputational Linguistics.\n[66] Wei Zhu, Xiaoling Wang, Yuan Ni, and Guotong Xie,\n“GAML-BERT: Improving BERT early exiting by gra-\ndient aligned mutual learning,”\nin Proceedings of\nthe 2021 Conference on Empirical Methods in Natu-\nral Language Processing, Online and Punta Cana, Do-\nminican Republic, Nov. 2021, pp. 3033–3044, Associ-\nation for Computational Linguistics.\n[67] Wei Zhu, “Mvp-bert: Multi-vocab pre-training for chi-\nnese bert,” in Annual Meeting of the Association for\nComputational Linguistics, 2021.\n[68] Xiepeng Li, Zhexi Zhang, Wei Zhu, Zheng Li, Yuan\nNi, Peng Gao, Junchi Yan, and Guotong Xie, “Pin-\ngan smart health and SJTU at COIN - shared task: uti-\nlizing pre-trained language models and common-sense\nknowledge in machine reading tasks,”\nin Proceed-\nings of the First Workshop on Commonsense Inference\nin Natural Language Processing, Hong Kong, China,\nNov. 2019, pp. 93–98, Association for Computational\nLinguistics.\n[69] Wei Zhu, Xiaofeng Zhou, Keqiang Wang, Xun Luo,\nXiepeng Li, Yuan Ni, and Guotong Xie,\n“Panlp at\nmediqa 2019: Pre-trained language models, transfer\nlearning and knowledge distillation,” in Proceedings\nof the 18th BioNLP Workshop and Shared Task, 2019,\npp. 380–388.\n[70] Wei Zhu, Yuan Ni, Guotong Xie, Xiaofeng Zhou, and\nCai Chen, “The dr-kgqa system for automatically an-\nswering medication related questions in chinese,” in\n2019 IEEE International Conference on Healthcare In-\nformatics (ICHI). IEEE, 2019, pp. 1–6.\n[71] Xiaofeng Zhou, Yuan Ni, Guotong Xie, Wei Zhu, Cai\nChen, Tianhao Wang, and Zhigang Pan, “Analysis of\nthe health information needs of diabetics in china,” in\nMEDINFO 2019: Health and Wellbeing e-Networks\nfor All, pp. 487–491. IOS Press, 2019.\n"}, {"page": 12, "text": "[72] Pengfei Wang, Huanran Zheng, Qi’ao Xu, Silong Dai,\nYiqiao Wang, Wenjing Yue, Wei Zhu, Tianwen Qian,\nand Liang Zhao, “Ts-htfa: Advancing time-series fore-\ncasting via hierarchical text-free alignment with large\nlanguage models,” Symmetry, vol. 17, no. 3, pp. 401,\n2025.\n[73] Zequan Liu, Yi Zhao, Ming Tan, Wei Zhu, and\nAaron Xuxiang Tian, “Para: Parameter-efficient fine-\ntuning with prompt aware representation adjustment,”\narXiv preprint arXiv:2502.01033, 2025.\n[74] Ellen Yi-Ge,\nJiechao Gao,\nWei Han,\nand Wei\nZhu,\n“Drum:\nLearning demonstration retriever\nfor large multi-modal models,”\narXiv preprint\narXiv:2412.07619, 2024.\n[75] Aaron Tian, Yi Zhao, Congrui Yin, Wei Zhu, Xing\nTian, and Yi Ge, “Fanlora: Fantastic loras and where to\nfind them in large language model fine-tuning,” in Pro-\nceedings of the 2024 Conference on Empirical Meth-\nods in Natural Language Processing: Industry Track,\n2024, pp. 515–528.\n[76] Christoph Leiter, Ran Zhang, Yanran Chen, Jonas Be-\nlouadi, Daniil Larionov, Vivian Fresen, and Steffen\nEger, “ChatGPT: A Meta-Analysis after 2.5 Months,”\narXiv e-prints, p. arXiv:2302.13795, Feb. 2023.\n[77] Nisan Stiennon, Long Ouyang, Jeff Wu, Daniel M.\nZiegler, Ryan Lowe, Chelsea Voss, Alec Radford,\nDario Amodei, and Paul Christiano,\n“Learning to\nsummarize from human feedback,” arXiv e-prints, p.\narXiv:2009.01325, Sept. 2020.\n[78] Paul F Christiano, Jan Leike, Tom Brown, Miljan Mar-\ntic, Shane Legg, and Dario Amodei, “Deep reinforce-\nment learning from human preferences,” Advances in\nneural information processing systems, vol. 30, 2017.\n[79] Guangliang Li, Randy Gomez, Keisuke Nakamura,\nand Bo He, “Human-centered reinforcement learning:\nA survey,”\nIEEE Transactions on Human-Machine\nSystems, vol. 49, no. 4, pp. 337–349, 2019.\n[80] Teo Susnjak, “Applying bert and chatgpt for sentiment\nanalysis of lyme disease in scientific literature,” arXiv\npreprint arXiv:2302.06474, 2023.\n[81] Zengzhi Wang, Qiming Xie, Zixiang Ding, Yi Feng,\nand Rui Xia, “Is chatgpt a good sentiment analyzer? a\npreliminary study,” arXiv preprint arXiv:2304.04339,\n2023.\n[82] Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao\nChen, Michihiro Yasunaga, and Diyi Yang, “Is Chat-\nGPT a General-Purpose Natural Language Processing\nTask Solver?,”\narXiv e-prints, p. arXiv:2302.06476,\nFeb. 2023.\n[83] Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian\nHan, Qizhang Feng, Haoming Jiang, Bing Yin, and\nXia Hu,\n“Harnessing the power of llms in practice:\nA survey on chatgpt and beyond,”\narXiv preprint\narXiv:2304.13712, 2023.\n[84] Mubin Ul Haque, Isuru Dharmadasa, Zarrin Tasnim\nSworna, Roshan Namal Rajapakse, and Hussain Ah-\nmad, “” i think this is the most disruptive technology”:\nExploring sentiments of chatgpt early adopters using\ntwitter data,” arXiv preprint arXiv:2212.05856, 2022.\n[85] Terry Yue Zhuo, Yujin Huang, Chunyang Chen, and\nZhenchang Xing, “Exploring ai ethics of chatgpt: A\ndiagnostic analysis,” arXiv preprint arXiv:2301.12867,\n2023.\n[86] Teo Susnjak, “Chatgpt: The end of online exam in-\ntegrity?,” arXiv preprint arXiv:2212.09292, 2022.\n[87] Zeljana Basic, Ana Banovac, Ivana Kruzic, and Ivan\nJerkovic, “Better by you, better than me, chatgpt3 as\nwriting assistance in students essays,” arXiv preprint\narXiv:2302.04536, 2023.\n[88] Udo Hahn and Michel Oleynik,\n“Medical informa-\ntion extraction in the age of deep learning,” Yearbook\nof medical informatics, vol. 29, no. 01, pp. 208–220,\n2020.\n[89] Yanshan Wang, Liwei Wang, Majid Rastegar-Mojarad,\nSungrim Moon, Feichen Shen, Naveed Afzal, Sijia\nLiu, Yuqun Zeng, Saeed Mehrabi, Sunghwan Sohn,\net al.,\n“Clinical information extraction applications:\na literature review,” Journal of biomedical informatics,\nvol. 77, pp. 34–49, 2018.\n[90] Giovanni Paolini, Ben Athiwaratkun, Jason Krone,\nJie Ma, Alessandro Achille, Rishita Anubhai, Ci-\ncero Nogueira dos Santos, Bing Xiang, and Ste-\nfano Soatto, “Structured prediction as translation be-\ntween augmented natural languages,” arXiv preprint\narXiv:2101.05779, 2021.\n[91] Wei Zhu, Xiaoling Wang, Yuan Ni, and Guotong Xie,\n“Autotrans: Automating transformer design via rein-\nforced architecture search,” in Natural Language Pro-\ncessing and Chinese Computing: 10th CCF Interna-\ntional Conference, NLPCC 2021, Qingdao, China, Oc-\ntober 13–17, 2021, Proceedings, Part I 10. Springer,\n2021, pp. 169–182.\n[92] Jack W Rae, Sebastian Borgeaud, Trevor Cai, Katie\nMillican,\nJordan Hoffmann,\nFrancis Song,\nJohn\nAslanides, Sarah Henderson, Roman Ring, Susannah\nYoung, et al.,\n“Scaling language models:\nMeth-\nods, analysis & insights from training gopher,” arXiv\npreprint arXiv:2112.11446, 2021.\n"}, {"page": 13, "text": "[93] Jordan Hoffmann, Sebastian Borgeaud, Arthur Men-\nsch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford,\nDiego de Las Casas, Lisa Anne Hendricks, Johannes\nWelbl, Aidan Clark, Tom Hennigan, Eric Noland,\nKatie Millican, George van den Driessche, Bogdan\nDamoc, Aurelia Guy, Simon Osindero, Karen Si-\nmonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals, and\nLaurent Sifre, “Training Compute-Optimal Large Lan-\nguage Models,” arXiv e-prints, p. arXiv:2203.15556,\nMar. 2022.\n[94] Shaden Smith, Mostofa Patwary, Brandon Norick,\nPatrick\nLeGresley,\nSamyam\nRajbhandari,\nJared\nCasper, Zhun Liu, Shrimai Prabhumoye, George\nZerveas, Vijay Korthikanti, Elton Zhang, Rewon\nChild, Reza Yazdani Aminabadi, Julie Bernauer, Xia\nSong, Mohammad Shoeybi, Yuxiong He, Michael\nHouston, Saurabh Tiwary, and Bryan Catanzaro, “Us-\ning DeepSpeed and Megatron to Train Megatron-\nTuring NLG 530B, A Large-Scale Generative Lan-\nguage Model,” arXiv e-prints, p. arXiv:2201.11990,\nJan. 2022.\n[95] Shayne Longpre, Le Hou, Tu Vu, Albert Webson,\nHyung Won Chung, Yi Tay, Denny Zhou, Quoc V Le,\nBarret Zoph, Jason Wei, et al., “The flan collection:\nDesigning data and methods for effective instruction\ntuning,” arXiv preprint arXiv:2301.13688, 2023.\n[96] Kyle Mahowald, Anna A Ivanova, Idan A Blank,\nNancy Kanwisher, Joshua B Tenenbaum, and Evelina\nFedorenko,\n“Dissociating language and thought in\nlarge language models: a cognitive perspective,” arXiv\npreprint arXiv:2301.06627, 2023.\n[97] Sebastian Kr¨ugel, Andreas Ostermaier, and Matthias\nUhl, “The moral authority of chatgpt,” arXiv preprint\narXiv:2301.07098, 2023.\n[98] Gerd Kortemeyer,\n“Could an artificial-intelligence\nagent pass an introductory physics course?,” Physical\nReview Physics Education Research, vol. 19, no. 1, pp.\n010132, 2023.\n[99] Ruibo Tu, Chao Ma, and Cheng Zhang,\n“Causal-\ndiscovery performance of chatgpt in the context\nof neuropathic pain diagnosis,”\narXiv preprint\narXiv:2301.13819, 2023.\n[100] Oded Nov, Nina Singh, and Devin M Mann, “Putting\nchatgpt’s medical advice to the (turing) test,” medRxiv,\npp. 2023–01, 2023.\n[101] Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wen-\nliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei\nJi, Tiezheng Yu, Willy Chung, et al.,\n“A multitask,\nmultilingual, multimodal evaluation of chatgpt on rea-\nsoning, hallucination, and interactivity,” arXiv preprint\narXiv:2302.04023, 2023.\n[102] Miguel Ortega-Mart´ın, ´Oscar Garc´ıa-Sierra, Alfonso\nArdoiz, Jorge ´Alvarez, Juan Carlos Armenteros, and\nAdri´an Alonso, “Linguistic ambiguity analysis in chat-\ngpt,” arXiv preprint arXiv:2302.06426, 2023.\n[103] Ning Bian, Xianpei Han, Le Sun, Hongyu Lin, Yaojie\nLu, and Ben He, “Chatgpt is a knowledgeable but in-\nexperienced solver: An investigation of commonsense\nproblem in large language models,”\narXiv preprint\narXiv:2303.16421, 2023.\n[104] Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Xing\nWang, and Zhaopeng Tu, “Is ChatGPT A Good Trans-\nlator? Yes With GPT-4 As The Engine,” arXiv e-prints,\np. arXiv:2301.08745, Jan. 2023.\n[105] Simon Frieder,\nLuca Pinchetti,\nRyan-Rhys Grif-\nfiths,\nTommaso\nSalvatori,\nThomas\nLukasiewicz,\nPhilipp Christian Petersen, Alexis Chevalier, and Julius\nBerner, “Mathematical capabilities of chatgpt,” arXiv\npreprint arXiv:2301.13867, 2023.\n[106] Sandra Mitrovi´c, Davide Andreoletti, and Omran Ay-\noub,\n“Chatgpt or human?\ndetect and explain. ex-\nplaining decisions of machine learning model for de-\ntecting short chatgpt-generated text,”\narXiv preprint\narXiv:2301.13852, 2023.\n[107] Biyang Guo, Xin Zhang, Ziyuan Wang, Minqi Jiang,\nJinran Nie, Yuxuan Ding, Jianwei Yue, and Yupeng\nWu, “How close is chatgpt to human experts? compar-\nison corpus, evaluation, and detection,” arXiv preprint\narXiv:2301.07597, 2023.\n[108] Yang Yang, Zhilei Wu, Yuexiang Yang, Shuangshuang\nLian, Fengjie Guo, and Zhiwei Wang, “A survey of in-\nformation extraction based on deep learning,” Applied\nSciences, vol. 12, no. 19, pp. 9691, 2022.\n[109] Sarkar Snigdha Sarathi Das, Arzoo Katiyar, Rebecca\nPassonneau, and Rui Zhang, “CONTaiNER: Few-shot\nnamed entity recognition via contrastive learning,” in\nProceedings of the 60th Annual Meeting of the Associ-\nation for Computational Linguistics (Volume 1: Long\nPapers), Dublin, Ireland, May 2022, pp. 6338–6353,\nAssociation for Computational Linguistics.\n[110] Mohamed Yassine Landolsi, Lobna Hlaoua, and Lotfi\nBen Romdhane,\n“Information extraction from elec-\ntronic medical documents: state of the art and future\nresearch directions,” Knowledge and Information Sys-\ntems, vol. 65, no. 2, pp. 463–516, 2023.\n"}, {"page": 14, "text": "[111] Wei Zhu, Xipeng Qiu, Yuan Ni, and Guotong Xie, “Au-\ntoRC: Improving BERT Based Relation Classification\nModels via Architecture Search,”\narXiv e-prints, p.\narXiv:2009.10680, Sept. 2020.\n[112] Bo Li, Dingyao Yu, Wei Ye, Jinglei Zhang, and\nShikun Zhang, “Sequence generation with label aug-\nmentation for relation extraction,”\narXiv preprint\narXiv:2212.14266, 2022.\n[113] I-Hung Hsu, Kuan-Hao Huang, Elizabeth Boschee,\nScott Miller, Prem Natarajan, Kai-Wei Chang, and\nNanyun Peng, “Degree: A data-efficient generation-\nbased event extraction model,” in Proceedings of the\n2022 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Human\nLanguage Technologies, 2022, pp. 1890–1908.\n[114] Yan-fen CHENG, Jia-jun WU, and Fan HE, “Aspect\nlevel sentiment analysis based on relation gated graph\nconvolutional network,” Journal of ZheJiang Univer-\nsity (Engineering Science), vol. 57, no. 3, pp. 437–445.\n[115] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova, “Bert: Pre-training of deep bidi-\nrectional transformers for language understanding,”\narXiv preprint arXiv:1810.04805, 2018.\n[116] Wei Zhu, “MVP-BERT: Multi-vocab pre-training for\nChinese BERT,” in Proceedings of the 59th Annual\nMeeting of the Association for Computational Lin-\nguistics and the 11th International Joint Conference\non Natural Language Processing: Student Research\nWorkshop, Online, Aug. 2021, pp. 260–269, Associ-\nation for Computational Linguistics.\n[117] Shuai Zhang, Yongliang Shen, Zeqi Tan, Yiquan Wu,\nand Weiming Lu, “De-bias for generative extraction in\nunified ner task,” in Annual Meeting of the Association\nfor Computational Linguistics, 2022.\n[118] Shuai Zhang, Yongliang Shen, Zeqi Tan, Yiquan Wu,\nand Weiming Lu, “De-bias for generative extraction\nin unified NER task,”\nin Proceedings of the 60th\nAnnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), Dublin, Ireland,\nMay 2022, pp. 808–818, Association for Computa-\ntional Linguistics.\n[119] Hang Yan, Tao Gui, Junqi Dai, Qipeng Guo, Zheng\nZhang, and Xipeng Qiu, “A Unified Generative Frame-\nwork for Various NER Subtasks,” arXiv e-prints, p.\narXiv:2106.01223, June 2021.\n[120] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer Levy,\nVeselin Stoyanov, and Luke Zettlemoyer, “Bart: De-\nnoising sequence-to-sequence pre-training for natural\nlanguage generation, translation, and comprehension,”\nin Annual Meeting of the Association for Computa-\ntional Linguistics, 2019.\n[121] Yaojie Lu, Qing Liu, Dai Dai, Xinyan Xiao, Hongyu\nLin, Xianpei Han, Le Sun, and Hua Wu,\n“Unified\nstructure generation for universal information extrac-\ntion,” in Proceedings of the 60th Annual Meeting of the\nAssociation for Computational Linguistics (Volume 1:\nLong Papers), Dublin, Ireland, May 2022, pp. 5755–\n5772, Association for Computational Linguistics.\n[122] Binggui Zhou, Guanghua Yang, Zheng Shi, and Shao-\ndan Ma,\n“Natural Language Processing for Smart\nHealthcare,” arXiv e-prints, p. arXiv:2110.15803, Oct.\n2021.\n[123] Merijn Beeksma, Suzan Verberne, Antal van den\nBosch, Enny Das, Iris Hendrickx, and Stef Groe-\nnewoud, “Predicting life expectancy with a long short-\nterm memory recurrent neural network using electronic\nmedical records,” BMC medical informatics and deci-\nsion making, vol. 19, no. 1, pp. 1–15, 2019.\n[124] Mark Hughes, Irene Li, Spyros Kotoulas, and Toy-\notaro Suzumura,\n“Medical text classification using\nconvolutional neural networks,”\nin Informatics for\nHealth: Connected Citizen-Led Wellness and Popula-\ntion Health, pp. 246–250. IOS Press, 2017.\n[125] Yang Li, Buyue Qian, Xianli Zhang, and Hui Liu,\n“Graph neural network-based diagnosis prediction,”\nBig Data, vol. 8, no. 5, pp. 379–390, 2020.\n[126] Zhexi Zhang, Wei Zhu, Junchi Yan, Peng Gao, and\nGuotong Xie, “Automatic student network search for\nknowledge distillation,”\nin 2020 25th International\nConference on Pattern Recognition (ICPR). IEEE,\n2021, pp. 2446–2453.\n[127] Zhao Guo, Yuan Ni, Keqiang Wang, Wei Zhu, and\nGuotong Xie, “Global attention decoder for chinese\nspelling error correction,”\nin Findings of the Asso-\nciation for Computational Linguistics: ACL-IJCNLP\n2021, 2021, pp. 1419–1428.\n[128] Yu Gu, Robert Tinn, Hao Cheng, Michael Lucas,\nNaoto Usuyama, Xiaodong Liu, Tristan Naumann,\nJianfeng Gao, and Hoifung Poon,\n“Domain-specific\nlanguage model pretraining for biomedical natural lan-\nguage processing,” 2020.\n[129] Wei Zhu and Xiaoling Wang, “Chatmed: A chinese\nmedical large language model,” https://github.\ncom/michael-wzhu/ChatMed, 2023.\n[130] Wei Zhu and Xiaoling Wang, “Promptcblue: a large-\nscale instruction-tuning dataset for multi-task and\n"}, {"page": 15, "text": "zero-shot learning in the medical domain in chinese,”\nhttps://github.com/michael-wzhu/\nPromptCBLUE, 2023.\n[131] Viet Dac Lai, “Event Extraction: A Survey,” arXiv\ne-prints, p. arXiv:2210.03419, Oct. 2022.\n[132] Chao-Wei Huang, Shang-Chi Tsai, and Yun-Nung\nChen, “PLM-ICD: Automatic ICD coding with pre-\ntrained language models,”\nin Proceedings of the\n4th Clinical Natural Language Processing Workshop,\nSeattle, WA, July 2022, pp. 10–20, Association for\nComputational Linguistics.\n[133] Rajvir Kaur, Jeewani Anupama Ginige, and Oliver\nObst,\n“A Systematic Literature Review of Auto-\nmated ICD Coding and Classification Systems us-\ning Discharge Summaries,”\narXiv e-prints,\np.\narXiv:2107.10652, July 2021.\n[134] Stephen Robertson, Hugo Zaragoza, et al., “The prob-\nabilistic relevance framework:\nBm25 and beyond,”\nFoundations and Trends® in Information Retrieval,\nvol. 3, no. 4, pp. 333–389, 2009.\n[135] Christina Niklaus, Matthias Cetto, Andr´e Freitas, and\nSiegfried Handschuh, “A survey on open information\nextraction,” arXiv preprint arXiv:1806.05599, 2018.\n[136] Zan Hongying, Li Wenxin, Zhang Kunli, Ye Yajuan,\nChang Baobao, and Sui Zhifang,\n“Building a pedi-\natric medical corpus: Word segmentation and named\nentity annotation,” in Chinese Lexical Semantics: 21st\nWorkshop, CLSW 2020, Hong Kong, China, May 28–\n30, 2020, Revised Selected Papers 21. Springer, 2021,\npp. 652–664.\n[137] Shen Zheng, Jie Huang, and Kevin Chen-Chuan\nChang,\n“Why Does ChatGPT Fall Short in An-\nswering Questions Faithfully?,”\narXiv e-prints, p.\narXiv:2304.10513, Apr. 2023.\n[138] Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and\nYejin Choi,\n“The Curious Case of Neural Text De-\ngeneration,” arXiv e-prints, p. arXiv:1904.09751, Apr.\n2019.\n[139] Danielle L. Mowery, Sumithra Velupillai, Brett R.\nSouth, Lee M. Christensen, David Mart´ınez, Liadh\nKelly, Lorraine Goeuriot, No´emie Elhadad, Sameer\nPradhan, Guergana K. Savova, and Wendy W. Chap-\nman, “Task 1: Share/clef ehealth evaluation lab 2013,”\nin Conference and Labs of the Evaluation Forum,\n2013.\n[140] Sarvnaz Karimi, Alejandro Metke-Jimenez, Madonna\nKemp, and Chen Wang, “Cadec: A corpus of adverse\ndrug event annotations,” Journal of biomedical infor-\nmatics, vol. 55, pp. 73–81, 2015.\n[141] T. Guan, H. Zan, X. Zhou, H. Xu, and K Zhang,\nCMeIE: Construction and Evaluation of Chinese Med-\nical Information Extraction Dataset, Natural Language\nProcessing and Chinese Computing, 9th CCF Interna-\ntional Conference, NLPCC 2020, Zhengzhou, China,\nOctober 14–18, 2020, Proceedings, Part I, 2020.\n[142] Ningyu Zhang, Mosha Chen, Zhen Bi, Xiaozhuan\nLiang, Lei Li, Xin Shang, Kangping Yin, Chuanqi Tan,\nJian Xu, Fei Huang, Luo Si, Yuan Ni, Guotong Xie,\nZhifang Sui, Baobao Chang, Hui Zong, Zheng Yuan,\nLinfeng Li, Jun Yan, Hongying Zan, Kunli Zhang,\nBuzhou Tang, and Qingcai Chen, “CBLUE: A Chinese\nbiomedical language understanding evaluation bench-\nmark,”\nin Proceedings of the 60th Annual Meeting\nof the Association for Computational Linguistics (Vol-\nume 1: Long Papers), Dublin, Ireland, May 2022, pp.\n7888–7915, Association for Computational Linguis-\ntics.\n[143] Timothy Dozat and Christopher D Manning, “Deep bi-\naffine attention for neural dependency parsing,” arXiv\npreprint arXiv:1611.01734, 2016.\n[144] Xiaojing Du, Jia Yuxiang, and Zan Hongying, “MRC-\nbased medical NER with multi-task learning and multi-\nstrategies,”\nin Proceedings of the 21st Chinese Na-\ntional Conference on Computational Linguistics, Nan-\nchang, China, Oct. 2022, pp. 836–847, Chinese Infor-\nmation Processing Society of China.\n[145] Quan Wang, Songtai Dai, Benfeng Xu, Yajuan Lyu,\nYong Zhu, Hua Wu, and Haifeng Wang,\n“Build-\ning Chinese Biomedical Language Models via Multi-\nLevel Text Discrimination,”\narXiv e-prints,\np.\narXiv:2110.07244, Oct. 2021.\n[146] I-Hung Hsu, Kuan-Hao Huang, Elizabeth Boschee,\nScott Miller, Prem Natarajan, Kai-Wei Chang, and\nNanyun Peng, “DEGREE: A data-efficient generation-\nbased event extraction model,” in Proceedings of the\n2022 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Human\nLanguage Technologies, Seattle, United States, July\n2022, pp. 1890–1908, Association for Computational\nLinguistics.\n[147] Jun Gao, Huan Zhao, Changlong Yu, and Ruifeng Xu,\n“Exploring the feasibility of chatgpt for event extrac-\ntion,” arXiv preprint arXiv:2303.03836, 2023.\n[148] Bo Li, Gexiang Fang, Yang Yang, Quansen Wang,\nWei Ye, Wen Zhao, and Shikun Zhang,\n“Eval-\nuating ChatGPT’s Information Extraction Capabili-\nties:\nAn Assessment of Performance, Explainabil-\nity, Calibration, and Faithfulness,” arXiv e-prints, p.\narXiv:2304.11633, Apr. 2023.\n"}, {"page": 16, "text": "[149] Deng-Bao Wang, Lei Feng, and Min-Ling Zhang, “Re-\nthinking calibration of deep neural networks: Do not\nbe afraid of overconfidence,”\nAdvances in Neural\nInformation Processing Systems, vol. 34, pp. 11809–\n11820, 2021.\n[150] Tianyi Zhang, Faisal Ladhak, Esin Durmus, Percy\nLiang,\nKathleen\nMcKeown,\nand\nTatsunori\nB\nHashimoto,\n“Benchmarking large language mod-\nels\nfor\nnews\nsummarization,”\narXiv\npreprint\narXiv:2301.13848, 2023.\n"}]}