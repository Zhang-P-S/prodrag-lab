{"doc_id": "arxiv:2602.12833", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2602.12833.pdf", "meta": {"doc_id": "arxiv:2602.12833", "source": "arxiv", "arxiv_id": "2602.12833", "title": "TRACE: Temporal Reasoning via Agentic Context Evolution for Streaming Electronic Health Records (EHRs)", "authors": ["Zhan Qu", "Michael Färber"], "published": "2026-02-13T11:39:19Z", "updated": "2026-02-13T11:39:19Z", "summary": "Large Language Models (LLMs) encode extensive medical knowledge but struggle to apply it reliably to longitudinal patient trajectories, where evolving clinical states, irregular timing, and heterogeneous events degrade performance over time. Existing adaptation strategies rely on fine-tuning or retrieval-based augmentation, which introduce computational overhead, privacy constraints, or instability under long contexts. We introduce TRACE (Temporal Reasoning via Agentic Context Evolution), a framework that enables temporal clinical reasoning with frozen LLMs by explicitly structuring and maintaining context rather than extending context windows or updating parameters. TRACE operates over a dual-memory architecture consisting of a static Global Protocol encoding institutional clinical rules and a dynamic Individual Protocol tracking patient-specific state. Four agentic components, Router, Reasoner, Auditor, and Steward, coordinate over this structured memory to support temporal inference and state evolution. The framework maintains bounded inference cost via structured state compression and selectively audits safety-critical clinical decisions. Evaluated on longitudinal clinical event streams from MIMIC-IV, TRACE significantly improves next-event prediction accuracy, protocol adherence, and clinical safety over long-context and retrieval-augmented baselines, while producing interpretable and auditable reasoning traces.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2602.12833v1", "url_pdf": "https://arxiv.org/pdf/2602.12833.pdf", "meta_path": "data/raw/arxiv/meta/2602.12833.json", "sha256": "72e6ee50868acf96000411173dbc4c5897b9a08f553a28abab825f001fd74a08", "status": "ok", "fetched_at": "2026-02-18T02:19:20.176855+00:00"}, "pages": [{"page": 1, "text": "TRACE: Temporal Reasoning via Agentic Context Evolution\nfor Streaming Electronic Health Records (EHRs)\nZhan Qu 1 2 Michael F¨arber 1 2\nAbstract\nLarge Language Models (LLMs) encode exten-\nsive medical knowledge but struggle to apply\nit reliably to longitudinal patient trajectories,\nwhere evolving clinical states, irregular timing,\nand heterogeneous events degrade performance\nover time.\nExisting adaptation strategies rely\non fine-tuning or retrieval-based augmentation,\nwhich introduce computational overhead, privacy\nconstraints, or instability under long contexts.\nWe introduce TRACE (Temporal Reasoning via\nAgentic Context Evolution), a framework that\nenables temporal clinical reasoning with frozen\nLLMs by explicitly structuring and maintaining\ncontext rather than extending context windows\nor updating parameters. TRACE operates over a\ndual-memory architecture consisting of a static\nGlobal Protocol encoding institutional clinical\nrules and a dynamic Individual Protocol tracking\npatient-specific state. Four agentic components,\nRouter, Reasoner, Auditor, and Steward, coordi-\nnate over this structured memory to support tem-\nporal inference and state evolution. The frame-\nwork maintains bounded inference cost via struc-\ntured state compression and selectively audits\nsafety-critical clinical decisions. Evaluated on\nlongitudinal clinical event streams from MIMIC-\nIV, TRACE significantly improves next-event pre-\ndiction accuracy, protocol adherence, and clinical\nsafety over long-context and retrieval-augmented\nbaselines, while producing interpretable and au-\nditable reasoning traces. TRACE is available at:\nTRACE-BD44\n1Department of Computer Science, TU Dresden, Dresden,\nGermany 2ScaDS.AI, Dresden, Germany. Correspondence to:\nZhan Qu <zhan.qu@tu-dresden.de>, Firstname2 Lastname2\n<first2.last2@www.uk>.\nPreprint. February 16, 2026.\n1. Introduction\nLarge Language Models (LLMs) have demonstrated strong\nperformance on static medical tasks, including diagnos-\ntic question answering, clinical summarization, and radio-\nlogical reporting (Singhal et al., 2023; Nori et al., 2023).\nHowever, deploying LLMs for longitudinal clinical reason-\ning remains a fundamental challenge. Real-world patient\ncare unfolds as a continuous, non-stationary event stream\ncharacterized by irregular temporal intervals, heterogeneous\nmodalities, and evolving physiological states (Wornow et al.,\n2024; Xu et al., 2024). In this setting, models must reason\nnot only over isolated observations, but over extended tra-\njectories in which early decisions, latent conditions, and\ninstitutional constraints remain clinically relevant over time.\nA core difficulty arises from the mismatch between how\nLLMs process context and how clinical reasoning operates\nin practice. Standard Transformers rely on a fixed context\nwindow and quadratic self-attention, making long-horizon\ninference computationally infeasible and brittle to context\ndilution. As trajectories grow, models increasingly exhibit\ncontext collapse and lost-in-the-middle behavior (Liu et al.,\n2024; Press et al., 2022), where critical early information\n(e.g., admission diagnoses or chronic contraindications) is\novershadowed by recent but less relevant events. Simply\nextending context length or increasing model size does not\nresolve this structural limitation.\nClinical reasoning further depends on conditional, context-\nsensitive heuristics that are rarely explicit in pretraining data\n(Qu & F¨arber, 2025). Examples include interpreting lab\ntrends relative to patient-specific baselines, enforcing con-\ntraindications, or adhering to institution-level formularies\nand protocols. Such heuristics are neither purely parametric\nnor reliably recoverable through semantic similarity alone;\nthey must be explicitly represented, selectively activated,\nand consistently applied as the patient trajectory evolves.\nExisting adaptation strategies exhibit complementary but\ninsufficient solutions. Fine-tuning can specialize a model to\na clinical domain, but incurs high computational cost, com-\nplicates deployment on privacy-sensitive data, and lacks\nrobustness to evolving protocols (Zhou et al., 2025; Zuo\net al., 2025; Griot et al., 2025). Retrieval-Augmented Gen-\n1\narXiv:2602.12833v1  [cs.LG]  13 Feb 2026\n"}, {"page": 2, "text": "TRACE: Temporal Reasoning via Agentic Context Evolution for Streaming EHRs\neration (RAG) avoids parameter updates but relies on vector\nsimilarity, which often retrieves clinically irrelevant or tem-\nporally inappropriate information (Cuconasu et al., 2024;\nXia et al., 2025; Xu et al., 2024). Long-context models\ncan ingest extensive histories, but suffer from severe effi-\nciency and reliability degradation in long-horizon settings\n(Liu et al., 2025; Li et al., 2024; Wornow et al., 2024). These\nlimitations suggest that robust clinical reasoning requires\nneither continual parameter updates nor unbounded context\nwindows, but a mechanism for structuring, maintaining, and\nupdating the right context over time.\nWe propose a different paradigm: treating longitudinal clin-\nical reasoning as a problem of continuous context opti-\nmization. We introduce TRACE (Temporal Reasoning via\nAgentic Context Evolution), a framework that transforms a\nfrozen LLM into a coordinated, multi-agent system operat-\ning over a compact, structured cognitive state. Rather than\nrelying on a monolithic context window or noisy retrieval,\nTRACE maintains a Dual-Memory Architecture consisting\nof: (i) a static Global Protocol encoding institution-level\nclinical guidelines, and (ii) a dynamic Individual Protocol\nthat tracks the evolving patient state in a structured, machine-\nreadable form.\nAt inference time, TRACE executes a lightweight agentic\nloop comprising four roles. A Router performs determinis-\ntic, trigger-based selection of relevant global rules. A Rea-\nsoner generates clinically grounded predictions conditioned\non the selected protocols and patient state. An Auditor se-\nlectively verifies safety-critical or high-uncertainty actions,\nenforcing contraindications without incurring constant over-\nhead. Finally, a Steward maintains a bounded context budget\nthrough a structured state compression mechanism (Mitosis),\nensuring that inference cost remains constant with respect\nto trajectory length.\nTo enable domain adaptation without test-time learning or\nparameter updates, TRACE employs a separate offline Re-\nflector agent. During an offline protocol induction phase,\nthe Reflector analyzes model failures on historical data and\nsynthesizes explicit, generalizable rules that are incorpo-\nrated into the Global Protocol. Once induced, the Global\nProtocol is frozen and reused across all downstream patient\ntrajectories, ensuring a clean separation between protocol\ninduction and deployment-time inference.\nWe evaluate TRACE on longitudinal event streams derived\nfrom MIMIC-IV (Johnson et al., 2023) using a prequen-\ntial evaluation protocol that strictly separates past learning\nfrom future prediction. Across multiple open-source LLMs,\nTRACE substantially improves predictive accuracy, proto-\ncol adherence, and clinical safety compared to long-context,\nretrieval-augmented, and monolithic agent baselines, while\nmaintaining bounded inference cost and fully transparent,\nhuman-readable reasoning traces. Our main contributions:\n• A context-centric view of longitudinal clinical rea-\nsoning. We formulate clinical decision-making over\npatient trajectories as a problem of continuous con-\ntext evolution, rather than static sequence modeling or\nunbounded context accumulation.\n• TRACE: a dual-memory, agentic framework for\nclinical streams. We propose TRACE, a multi-agent\nsystem that explicitly separates institutional clinical\nknowledge from patient-specific state, enabling scal-\nable, interpretable reasoning over long and irregular\nclinical trajectories without parameter updates.\n• Offline protocol induction via reflective rule synthe-\nsis. We introduce a Reflector agent that distills gener-\nalizable, institution-specific clinical rules from model\nfailures in an offline setting, avoiding fine-tuning and\ntest-time learning.\n• A safety-aware inference loop with bounded infer-\nence cost. TRACE integrates structured state updates\nand conditional safety auditing to maintain reliable\nclinical behavior while keeping inference cost indepen-\ndent of trajectory length.\n• Extensive empirical evaluation on longitudinal\nEHR data. We evaluate TRACE on event streams\nderived from MIMIC-IV and demonstrate consistent\nimprovements in predictive accuracy, protocol adher-\nence, and clinical safety over long-context and retrieval-\naugmented baselines.\n2. Related Work\nAdaptive Context and Prompt Evolution for Post-\nTraining LLM Improvement\nRecent work has explored\nimproving large language models (LLMs) without parame-\nter updates by iteratively modifying textual artifacts such\nas prompts, system instructions, or external memory. These\napproaches differ in whether adaptation occurs offline or\nat inference time, and in whether updates target short-lived\nprompts or persistent external memory. Reflection-based\nmethods show that LLMs can critique and revise their own\noutputs to improve performance, either within a single in-\nstance (Madaan et al., 2023) or across episodes in sequential\ndecision-making (Shinn et al., 2023). In parallel, prompt\noptimization methods treat prompts as optimizable objects\nand apply black-box or evolutionary search in prompt space,\nincluding Automatic Prompt Engineer (APE) (Zhou et al.,\n2022), OPRO (Yang et al., 2023), and PromptBreeder (Fer-\nnando et al., 2024). These approaches typically operate\noffline on fixed evaluation sets and do not address contin-\nual adaptation or long-horizon stability. Related systems\nsuch as MemGPT (Packer et al., 2023) focus on managing\nlong-context interactions via external memory, but primar-\n2\n"}, {"page": 3, "text": "TRACE: Temporal Reasoning via Agentic Context Evolution for Streaming EHRs\nFigure 1. Overview of TRACE. Phase I (Offline): On historical event streams E≤t, prediction errors between bYt and Y ∗\nt are analyzed\nby a Reflector agent, which induces generalizable clinical rules that are added to the Global Protocol PG. Phase II (Online): During\ndeployment, TRACE processes live event bundles Et using a bounded inference state St = (PG, PI,t, EI,t). A Router selects relevant\nrules, a Reasoner predicts the next action, an Auditor conditionally verifies safety-critical decisions, and a Steward updates the patient-\nspecific Individual Protocol PI,t+1. The Global Protocol remains frozen during online inference. All agents use the same LLM backbone.\nily address memory access and control rather than learning\ntransferable problem-solving knowledge.\nDynamic Cheatsheet (DC) (Suzgun et al., 2025) explicitly\nframes inference as a test-time learning process, in which\nan LLM maintains and curates a persistent external mem-\nory to improve future performance. GEPA (Agrawal et al.,\n2025) advances a complementary direction by optimizing\nprompts for compound LLM systems through reflective\nedits and Pareto-based evolutionary selection, positioning\nprompt evolution as an alternative to reinforcement learning\nfor system-level optimization. However, iterative prompts\nand memory rewriting may degrade over long horizons, par-\nticularly when updates are unstructured or overwrite earlier\ninformation, leading to context drift or loss of critical con-\nstraints. Agentic Context Engineering (ACE) (Zhang et al.,\n2025) addresses these limitations by evolving structured\ncontexts via incremental updates and deterministic merg-\ning, supporting both offline prompt optimization and online\ntest-time adaptation. Together, these methods form a coher-\nent research field on post-training LLM self-improvement\nvia evolving textual artifacts, differing primarily in their\noptimization targets and adaptation timescales.\nMedical Foundation Models and Longitudinal EHR Rea-\nsoning\nRecent medical foundation models have demon-\nstrated strong performance on static and short-horizon clini-\ncal tasks, including diagnostic reasoning and clinical ques-\ntion answering (Singhal et al., 2023; Nori et al., 2023;\nWornow et al., 2023). Domain-aligned variants such as\nMeditron further improves medical factuality and robustness\nthrough large-scale pretraining on curated clinical corpora\n(Chen et al., 2023). Beyond text-centric models, recent work\nhas explored foundation models trained directly on struc-\ntured medical events. COMET, for example, applies scaling\nlaws to heterogeneous EHR sequences and demonstrates\nstrong zero-shot performance across a range of clinical pre-\ndiction tasks (Waxler et al., 2025). To support longitudi-\nnal reasoning, a growing body of work models Electronic\nHealth Records (EHRs) as long temporal sequences of visits\nor events. Recent studies evaluate long-context architec-\ntures on full patient histories containing tens of thousands of\nevents (Wornow et al., 2024), while representation-focused\napproaches such as GT-BEHRT (Poulain & Beheshti, 2024)\nand AutoDP (Cui & Mitra, 2024) improve predictive perfor-\nmance by modeling temporal dependencies, task structure,\nor concept relations. In parallel, several works augment lon-\ngitudinal EHR models with retrieval mechanisms to incor-\nporate external or historical clinical knowledge, including\nRAM-EHR (Xu et al., 2024) and multimodal medical RAG\nsystems (Xia et al., 2025). Other efforts explore generative\nmodeling of longitudinal EHRs, including diffusion-based\napproaches for synthesizing realistic multimodal patient tra-\njectories (He et al., 2024; Zhong et al., 2024). Despite sub-\nstantial progress, existing approaches predominantly treat\npatient history as a flat or weakly structured sequence and\nrely on longer contexts, retrieval, or larger models to manage\ntemporal dependencies, leaving open the problem of how to\nsupport reliable, interpretable, and policy-aware clinical rea-\nsoning over unbounded event streams without continually\nexpanding context windows or retraining model parameters.\n3. Methodology\nWe formulate longitudinal clinical reasoning as a continuous\ncontext optimization problem over a potentially unbounded\n3\n"}, {"page": 4, "text": "TRACE: Temporal Reasoning via Agentic Context Evolution for Streaming EHRs\nevent stream. A patient trajectory is modeled as a sequence\nof event sets E = (E1, . . . , ET ), where each Et represents\na bundle of clinical observations, interventions, and mea-\nsurements at timestep t. At each timestep, the model must\nestimate P(Yt+1|E1:t) where Yt+1 denotes the next clinical\nintervention or patient state.\nStandard Transformer architectures scale poorly to long-\nhorizon clinical trajectories due to the quadratic O(t2) com-\nputational and memory complexity of self-attention and the\nfixed context window Lmax. Consequently, na¨ıvely extend-\ning the context length becomes computationally infeasible\nand empirically brittle, particularly when modeling long-\nterm temporal dependencies in irregular clinical data.\nTo address this limitation, TRACE reformulates longitudinal\nreasoning by maintaining a compact, high-density cognitive\nstate rather than relying on massive context windows or\nad hoc vector retrieval. Specifically, TRACE decouples\nclinical context into two complementary memory streams:\na static, institution-level Global Protocol encoding clinical\nguidelines and shared medical knowledge, and a dynamic,\npatient-specific Individual Protocol that evolves over time.\nThese memory streams are jointly managed by a multi-\nagent controller comprising a Router, Reasoner, Auditor,\nand Steward, enabling continuous context optimization over\nan effectively infinite horizon. In addition, TRACE employs\na separate Reflector agent used exclusively during offline\nprotocol induction to induce and refine the Global Protocol.\n3.1. Dual-Memory Architecture\nTRACE\nmaintains\nthe\ninference\nstate\nSt\n=\n(PG, PI,t, Ebuff), where Ebuff is a short rolling buffer\nof recent raw tokens.\n1. Global Protocol (PG): The Institutional Playbook.\nPG serves as the “Long-Term Semantic Memory” contain-\ning transferable medical heuristics (e.g., sepsis bundles, in-\nsulin sliding scales). Unlike vector-based RAG which suf-\nfers from retrieval noise, PG is structured as a Key-Value\nCheatsheet (Suzgun et al., 2025). Keys correspond to clin-\nical triggers (e.g., [TRIGGER: LACTATE > 4]), and\nvalues contain precise action guidelines. This memory is\nlearned offline and frozen during inference (see Sec. 3.4).\n2. Individual Protocol (PI,t): The Patient State.\nPI,t\nis a dynamic, evolving JSON object representing the spe-\ncific patient’s current physiological status. It functions as a\nstructured state-space model, tracking active latent variables\nrather than summarizing past tokens:\nPI,t = {”active problems” : [d1, d2 . . . ],\n”current meds” : [m1, m2 . . . ],\n”trajectory” : [trend1, . . . ]}\n3.2. Offline Protocol Induction via the Reflector\nTRACE incorporates a dedicated Reflector agent responsi-\nble for inducing and refining the Global Protocol PG during\noffline protocol induction. The Reflector operates exclu-\nsively offline and is never invoked during inference.\nGiven a failed prediction at timestep t, the Reflector is pro-\nvided with the patient trajectory E1:t, the model’s predicted\naction bYt+1, and the ground-truth intervention Y ∗\nt+1. Its ob-\njective is to determine whether the error arises from missing\ninstitutional knowledge or an underspecified clinical rule.\nWhen such a gap is identified, the Reflector synthesizes a\nnew generalizable rule of the form:\nIF [trigger] THEN [action],\nwhich is categorized and appended to the Global Protocol\nPG. Once learned, PG is fixed and reused across all down-\nstream patient trajectories.\n3.3. The TRACE Inference Loop\nAt each timestep t, TRACE executes a coordinated loop\ndesigned to minimize computational cost while maximizing\nsafety. This loop operates solely over inference-time agents\n(Router, Reasoner, Auditor, Steward); the Reflector is not\nactive during deployment.\nStep 1: Trigger-Guided Routing.\nThe Router selects a\nsubset of protocol entries from PG relevant to the current\nstate given Et and PI,t:\nCt = Router(Et, PI,t, PG).\nThe Router is prompted to match observed triggers in Et\n(e.g., hypotension) to protocol keys in PG, producing a\ncompact set of candidate rules for downstream reasoning.\nStep 2: Predictive Reasoning.\nThe Reasoner generates\nthe prediction bYt+1 using the context. It is prompted to\nexplicitly cite rules from Ct to justify its actions:\nbYt+1, logprobs = LLM(Prompt ⊕Ct ⊕PI,t ⊕Ebuff)\nStep 3: Trigger-Based Auditing for Computational Effi-\nciency.\nTo reduce the inference cost of reflective verifica-\ntion, the Auditor is conditional. We define an uncertainty\nproxy U(bYt+1) from the average token log-probability of\nthe generated output. The Auditor is triggered only if:\n1. Uncertainty: U(bYt+1) > τuncertainty.\n2. Safety Criticality: bYt+1 ∩Vrisk ̸= ∅(where Vrisk is a\nvocabulary of high-stakes interventions).\n4\n"}, {"page": 5, "text": "TRACE: Temporal Reasoning via Agentic Context Evolution for Streaming EHRs\nWhen triggered, the Auditor validates bYt+1 against (i) PG\nand (ii) explicit safety constraints derived from the struc-\ntured patient state PI,t (e.g., allergies, active problems).\nStep 4: The Steward and Protocol Mitosis.\nThe Stew-\nard manages the context budget via Mitosis, a structured\nstate compression algorithm. When |Ebuff| > Llimit, the\nSteward absorbs the raw information into the structured\nstate:\nPI,t+1 = Update(PI,t, Ebuff)\nUnlike text summarization, Mitosis performs discrete\nstate\nupdates\n(e.g.,\nremoving\na\nmedication\nfrom\ncurrent meds upon a stop order). The raw buffer Ebuff\nis then flushed. This keeps the prompt budget bounded and\nindependent of the trajectory length T, while preserving the\nstate fidelity required for clinical safety.\n3.4. Optimization Strategy: Two-Phase Evolution\nTo prevent data contamination and ensure robust general-\nization, we adopt a two-phase learning strategy inspired by\nGEPA (Agrawal et al., 2025).\nPhase I: Offline Global Learning (Protocol Induction).\nWe execute TRACE on the training set. When the model\nfails to predict a ground-truth intervention Y ∗\nt+1, the Re-\nflector analyzes the error. If the error stems from missing\nknowledge (e.g., institutional dosage limits), the Reflector\nsynthesizes a new rule r and appends it to PG. This phase\ninduces a high-quality ”Medical Playbook” from data.\nPhase II: Online Deployment (Test-Time Adaptation).\nDuring evaluation on the test set, PG is frozen. The system\nadapts solely via the Individual Protocol PI. This strictly\nevaluates the system’s ability to maintain patient-specific\ncontext and apply learned rules to unseen trajectories with-\nout parameter updates.\n4. Data Construction\nWe transform the relational structure of Electronic Health\nRecords (EHRs) into a linearized, semi-structured event\nstream suitable for long-horizon agentic reasoning. Raw\nEHR data are inherently heterogeneous and temporally\nsparse, spanning laboratory measurements, medication or-\nders, diagnoses, and procedures recorded at irregular in-\ntervals. Directly modeling such relational tables as a flat\nsequence leads to long, low-density contexts and poor tem-\nporal alignment. To address this, we construct compact\nevent bundles that aggregate clinically related observations\nwhile preserving temporal ordering.\n4.1. Source Dataset\nWe use MIMIC-IV v2.2 (Johnson et al., 2023), a large-scale,\ndeidentified critical care database derived from admissions\nto the Beth Israel Deaconess Medical Center. From the\nrelational schema, we extract diagnoses, medications, lab-\noratory results, and procedures associated with each ICU\nadmission. Diagnoses and procedures are represented using\nnormalized ICD codes enriched with their textual descrip-\ntions. Medication data are parsed into explicit start and stop\nevents with associated metadata such as dosage and route.\nLaboratory measurements are paired with reference ranges\nto support semantic interpretation.\n4.2. Event Normalization and Semantic Discretization\nTo maximize information density per token and reduce nu-\nmerical noise, continuous clinical variables are discretized\ninto semantic categories relative to reference ranges or\npatient-specific baselines (e.g., Low, Normal, High).\nNormal laboratory results are aggregated when possible\n(e.g., CMP: All Normal), while abnormal values are ex-\nplicitly reported together with their measured magnitude\n(e.g., Creatinine:\n2.1 (High)). This semantic\ndiscretization preserves clinically salient deviations while\nsubstantially reducing token usage.\n4.3. Event Bundle Construction\nClinical events are sorted chronologically within each ad-\nmission and grouped into Event Bundles based on temporal\nproximity. Events occurring within a fixed one-hour window\nare coalesced into a single bundle Et, which summarizes\nall observations, interventions, and measurements recorded\nduring that interval. This aggregation avoids excessive frag-\nmentation of closely related events while maintaining a\nclinically meaningful temporal resolution.\nTo handle extended periods of clinical silence, we in-\nsert explicit time-delta tokens (e.g., [TIME DELTA: +12\nhours]) whenever the gap between consecutive bundles\nexceeds a predefined threshold. These tokens allow the\nmodel to reason about elapsed time without processing\nredundant empty steps, yielding more compact and inter-\npretable trajectories.\n4.4. Serialized Clinical Streams\nThe above steps define a deterministic transformation\nϕ : Drelational →Etext,\nwhich maps raw relational EHR tables to a serialized event\nstream E = (E1, . . . , ET ). Each event bundle is rendered\nas a compact textual summary with structured sections cor-\nresponding to diagnoses, medications, laboratory results,\nand procedures. The resulting representation serves as the\n5\n"}, {"page": 6, "text": "TRACE: Temporal Reasoning via Agentic Context Evolution for Streaming EHRs\nsole input to the TRACE inference loop described in Sec-\ntion 3, enabling consistent processing across models and\nexperimental conditions.\nAcross the evaluation cohort, this construction yields con-\ncise patient trajectories with a manageable number of inter-\naction steps per ICU stay; detailed statistics on trajectory\nlength and token counts are reported in Section X.\n5. Experimental Setup\nWe evaluate TRACE in a streaming clinical decision-making\nsetting using serialized event bundles constructed as de-\nscribed in Section 4. All experiments follow a prequential\n(predict-then-update) protocol to prevent temporal leakage\nand reflect realistic deployment conditions.\nEvaluation Protocol.\nEvaluation proceeds in two phases.\nIn Phase I (offline protocol induction), TRACE is applied to\na training cohort of N = 100,804 patients. At each timestep\nt, the system predicts bYt+1 given the observed history; when\nthe prediction does not match the ground-truth action Y ∗\nt+1,\nthe Reflector agent analyzes the failure and, when appropri-\nate, synthesizes a new generalizable rule that is appended to\nthe Global Protocol PG. After processing the full training\ncohort, PG is frozen. In Phase II (streaming inference), we\nevaluate on a held-out test set of N = 100,863 patients.\nEach trajectory is processed sequentially, one event bundle\nat a time: the system predicts bYt+1, the prediction is scored\nagainst Y ∗\nt+1, and the Individual Protocol PI,t is updated\nvia the Steward using the observed outcome. No parameter\nupdates or PG modifications occur during this phase.\nDataset Statistics.\nAfter normalization and event bundle\nconstruction (Sec. 4), the corpus contains approximately\n5.0M event bundles per phase, comprising over 43M clini-\ncal events. Each bundle aggregates events recorded within\na one-hour window and contains on average 8.6 events,\nprimarily laboratory measurements (4.3 per bundle) and\nmedication orders (3.2 per bundle), with diagnoses and pro-\ncedures occurring less frequently. Patient trajectories are\nlong-horizon, with an average of 48–49 event bundles per\nICU admission and approximately 420 events per patient\nafter aggregation and discretization. In Phase I, TRACE\ninduces a Global Protocol containing 441 rules. The re-\nsulting protocol is compact (21 words on average per rule),\nhuman-readable, and explicitly editable, allowing clinicians\nor system designers to inspect, modify, or extend institu-\ntional heuristics without retraining the underlying model.\nBackbone Models.\nTRACE is tested on 5 open-source\nLLMs spanning general-purpose and domain-specific set-\ntings:\nLlama-3.1-70B-Instruct, Qwen-2.5-72B-Instruct,\nMixtral-8x22B-v0.1, Meditron-70B, and DeepSeek-V3.1.\nAll agent roles (Router, Reasoner, Auditor, Steward, and\nReflector) are instantiated as prompted LLM calls using the\nsame backbone within a given experiment.\nPrompt Structure and Context Budget.\nInference is con-\nducted under a fixed prompt budget with predefined token\nallocations for system instructions, retrieved Global Proto-\ncol entries, the structured Individual Protocol, and a short\nrolling buffer of recent event bundles. This design ensures\nthat prompt length remains bounded and independent of tra-\njectory length. Prompt templates are shared across models\nand are provided in Appendix A.\nBaselines.\nWe compare TRACE against three baseline ap-\nproaches that represent common strategies for longitudinal\nclinical reasoning with LLMs: (i) a long-context clinical\nLLM that ingests the raw serialized history up to the context\nlimit; (ii) a retrieval-augmented generation (RAG) system\nusing a Contriever-based retriever to select top-K historical\nsegments from the patient’s past; and (iii) a monolithic agent\n(MemGPT-style) that maintains a single free-text summary\nof patient state without separating institutional knowledge\nfrom individual context. All baselines receive the same\nevent bundle inputs, use identical backbone models where\napplicable, and operate under the same fixed prompt budget\nduring inference.\nMetrics.\nWe report four metrics: (i) Recall@5 for next-\nstep prediction of medications, lab orders, and procedures;\n(ii) Protocol Adherence, the fraction of timesteps where\npredictions explicitly cite an activated Global Protocol rule;\n(iii) Clinical Equivalence (1–5), a GPT-4o judged mea-\nsure of plan-level clinical acceptability allowing reasonable\nalternatives; and (iv) Auditor Activation Rate, the frac-\ntion of timesteps escalated to conditional verification due to\nuncertainty or safety-critical actions.\n6. Results\nWe report main results on the held-out test cohort in Table 1.\nEvaluation is performed over serialized event-stream tra-\njectories constructed per ICU admission (Sec. 4) using the\nprequential streaming protocol described in Sec. 5. Perfor-\nmance is measured using Recall@5 for next-step prediction\nof medications, lab orders, and procedures, together with\na GPT-4o judged Clinical Equivalence score (1–5). For\nTRACE, we additionally report Protocol Adherence and\nthe Auditor Activation Rate, which measures how often the\nsystem escalates a decision to conditional verification.\n6\n"}, {"page": 7, "text": "TRACE: Temporal Reasoning via Agentic Context Evolution for Streaming EHRs\nTable 1. Main Performance Comparison on MIMIC-IV. We report Recall@5 for medication prediction, lab orders, and procedures, and\nthe GPT-4 judged Clinical Equivalence Score (1-5). Best results in bold.\nMethod\nMedication\nLab Order\nProcedure\nClinical\nProtocol\nAuditor\nRecall@5\nRecall@5\nRecall@5\nEquivalence\nAdherence\nActivation Rate\nLong-Context (Llama-3-70B)\n0.3192\n0.2119\n0.3511\n2.95\n-\n-\nStatic RAG (Contriever)\n0.3221\n0.1245\n0.2827\n3.10\n-\n-\nMonolithic Agent (MemGPT)\n0.3224\n0.136\n0.3313\n3.28\n-\n-\nTRACE (Llama-3.1-70B)\n0.5986\n0.4176\n0.4184\n3.56\n92.8%\n9.42%\nTRACE (Qwen-2.5-72B-Instruct)\n0.5327\n0.4332\n0.3817\n3.71\n93.6%\n7.13%\nTRACE (Mixtral-8x22B-v0.1)\n0.5530\n0.5727\n0.3718\n3.85\n92.1%\n5.15%\nTRACE (DeepSeek-V3.1)\n0.3348\n0.4323\n0.3089\n3.96\n94.7%\n6.23%\nTRACE (Meditron-70B)\n0.5723\n0.4872\n0.4219\n3.91\n94.0%\n5.27%\n6.1. Main Results: Predictive Performance and Clinical\nQuality\nTRACE substantially improves Recall@5 over all base-\nlines.\nThe long-context baseline achieves Recall@5 of\n0.3192 (medications), 0.2119 (lab orders), and 0.3511 (pro-\ncedures). Static RAG and the monolithic agent perform\ncomparably on medications (0.3221 and 0.3224), but de-\ngrade markedly on lab orders (0.1245 and 0.1360) and pro-\ncedures (0.2827 and 0.3313). This pattern highlights a core\nchallenge of longitudinal clinical streams: temporally appro-\npriate ordering depends on localized triggers and evolving\nstate, which similarity-based retrieval and free-text sum-\nmaries often fail to preserve.\nAcross backbone models, TRACE consistently improves\nRecall@5 for medications (0.5327–0.5986) and lab or-\nders (0.4176–0.5727). Procedure prediction also improves,\nwith TRACE achieving up to 0.4219 (Meditron-70B)\nand strong performance across other backbones (0.3089–\n0.4184). These results indicate that explicit state tracking\nand trigger-guided protocol routing improve exact-match\nprediction across multiple clinical action types, with partic-\nularly large gains for medication and lab ordering.\nClinical equivalence improves even when exact matches\nremain difficult.\nExact-match Recall@5 can underesti-\nmate clinically valid decisions, as recorded action sequences\nmay omit acceptable alternatives (e.g., class-equivalent med-\nications or alternative diagnostic workups). The Clinical\nEquivalence score complements Recall@5 by assessing\nplan-level clinical acceptability. TRACE improves equiva-\nlence from 2.95 (long-context) and 3.28 (monolithic agent)\nto 3.56–3.96 across backbones. Notably, DeepSeek-V3.1\nattains the highest equivalence score (3.96) despite only\nmoderate Recall@5, suggesting that TRACE often gener-\nates clinically reasonable alternatives that differ from the\nexact recorded tokens.\nHigh protocol adherence reflects explicit institutional\ngrounding.\nTRACE maintains consistently high Protocol\nAdherence (92.1–94.7%), demonstrating that the Router\nreliably activates relevant Global Protocol entries and that\nthe Reasoner grounds its predictions in explicitly cited rules\nunder a bounded prompt budget. We do not report adherence\nfor baselines, as they do not operate over an explicit, citeable\nprotocol representation.\nAuditor activation remains conditional rather than con-\nstant.\nTable 1 reports the Auditor Activation Rate, defined\nas the fraction of timesteps where TRACE escalates a pre-\ndiction to the Auditor due to high uncertainty or safety-\ncritical action types. Activation rates range from 5.15%\n(Mixtral-8x22B) to 9.42% (Llama-3.1-70B), indicating that\nverification is invoked on a minority of steps rather than\ncontinuously. This metric reflects verification frequency\nand computational overhead, not the rate of contraindicated\nrecommendations.\n6.2. Ablation Studies\nTable 2 reports ablations of TRACE components using the\nLlama-3.1-70B backbone.\nGlobal Protocol contributes substantially to predictive\nperformance.\nRemoving the Global Protocol results in\na large drop in Recall@5 (0.5319 →0.2134), indicating\nthat institution-specific rules induced offline provide criti-\ncal signal beyond what the backbone model recovers from\npretraining alone.\nStructured state maintenance reduces uncertainty and\nstabilizes grounding.\nDisabling Mitosis and structured\nstate updates reduces Recall@5 (0.5319 →0.2637) and Pro-\ntocol Adherence (92.8% →64.3%), while sharply increas-\ning Auditor Activation (9.42% →27.8%). This suggests\nthat compact, structured patient state representations reduce\nuncertainty and prevent frequent escalation to verification.\n7\n"}, {"page": 8, "text": "TRACE: Temporal Reasoning via Agentic Context Evolution for Streaming EHRs\nAuditing stabilizes the agent loop beyond safety checks.\nRemoving the Auditor reduces Recall@5 to 0.2132 and\nlowers adherence to 81.2%. Although auditing is designed\nas a conditional safety mechanism, these results suggest\nit also stabilizes the overall agent loop by preventing low-\nconfidence outputs from propagating into subsequent state\nupdates. Auditor Activation Rate is undefined in this setting\nbecause the mechanism is removed.\nTable 2. Ablation Study. Impact of removing the Global Protocol\n(PG), the Structured State (PI), and the Auditor.\nConfiguration\nRecall@5\nAdherence\nAuditor Act.\nTRACE (Llama-3.1-70B)\n0.5319\n92.8%\n9.42%\nw/o Global Protocol\n0.2134\n-\n14.5%\nw/o Mitosis (state)\n0.2637\n64.3%\n27.8%\nw/o Auditor\n0.2132\n81.2%\n-\n6.3. Qualitative Analysis: Phase II Reasoning Trail\nThis example shows a short ICU trajectory in which a sep-\nsis protocol is executed across multiple timesteps using a\nserialized event stream. At t = 0, an abnormal lactate mea-\nsurement is observed, after which the system predicts the\nset of protocol-relevant actions, including fluid resuscitation\nand antibiotics. The prediction at this stage reflects recog-\nnition of a sepsis pattern rather than a direct reaction to a\nsingle event. As the trajectory progresses, observed interven-\ntions are incorporated step by step. After fluid resuscitation\nis recorded at t = 1, the next predicted bundle advances\nto blood cultures, reflecting that fluids have already been\nadministered while cultures have not yet occurred. At t = 2,\nonce blood cultures are observed, the predicted next action\nbecomes initiation of broad-spectrum antibiotics. Previ-\nously completed interventions are not re-predicted, and the\npredicted actions change only as the execution state of the\nprotocol changes.\nAfter all protocol-specified interventions are observed, the\nsystem produces no further predictions. Overall, the exam-\nple illustrates stepwise execution of a multi-action clinical\nprotocol over a longitudinal event stream, where each pre-\ndiction depends on the cumulative set of actions already\ntaken rather than on isolated recent events.\n7. Conclusion\nWe introduced TRACE, a framework for long-horizon rea-\nsoning with frozen large language models that replaces un-\nbounded context accumulation with explicit, structured state.\nEmpirically, our results show that performance gains are\nprimarily driven by the dual-memory design, which sepa-\nrates a static Global Protocol from a dynamic, structured\nIndividual Protocol. Ablation studies indicate that removing\neither component substantially degrades Recall@5 and pro-\nInput event stream (single-type bundles)\nE0 (Labs, abnormal): Lactate 4.8\nE1 (Medications): Start IV fluids 30 ml/kg\nE2 (Procedures): Blood cultures\nE3 (Medications): Start broad-spectrum antibiotics\nTRACE state at initialization (t = 0)\nGlobal protocol (frozen):\nSEPSIS V1: IF Lactate > 4 OR MAP < 65 THEN fluids +\nbroad-spectrum antibiotics\nIndividual protocol state:\nactive problems = [ ]\n—\ncurrent meds = [ ]\n—\ntrends = [ ]\nPhase II stepwise execution\nt = 0 (after observing E0):\nRouter: detects Lactate 4.8 →activates SEPSIS V1\nReasoner: enumerates protocol-mandated actions →\n{Start IV fluids 30 ml/kg, Start broad-spectrum antibi-\notics}\nAuditor: checks safety constraints →PASS\nSteward: updates state →\nactive problems=[suspected sepsis], current meds=[ ],\ntrends=[lactate high]\nt = 1 (after observing E1):\nRouter: remains on SEPSIS V1\nReasoner: predicts next unfulfilled bundle →{Blood cul-\ntures}\nAuditor: PASS\nSteward: updates medications →current meds=[IV fluids]\nt = 2 (after observing E2):\nRouter: remains on SEPSIS V1\nReasoner: predicts next unfulfilled bundle →{Start broad-\nspectrum antibiotics}\nAuditor: PASS\nSteward: updates procedures →procedures=[blood cul-\ntures]\nt = 3:\nPrediction matches observed E3 →Phase II completes\nsuccessfully\nFigure 2. Phase II qualitative example of protocol-grounded\nbundle execution. With the sepsis protocol fixed, TRACE in-\ncrementally predicts the next required bundle as prior actions are\nobserved and incorporated into state.\ntocol adherence, highlighting the importance of explicitly\nrepresenting both institutional rules and evolving state.\nThe agentic inference loop supports this structure by en-\nabling trigger-based protocol selection and state-aware pro-\ngression across timesteps, while conditional auditing sta-\nbilizes predictions without constant verification. Together,\nthese components enable reliable reasoning over long event\nstreams with bounded inference cost. Although evaluated in\nthe clinical domain, the design addresses a general challenge\nin sequential decision-making with LLMs where relevant\ncontext must be preserved and updated over extended hori-\nzons.\n8\n"}, {"page": 9, "text": "TRACE: Temporal Reasoning via Agentic Context Evolution for Streaming EHRs\nImpact Statement\nThis work proposes TRACE, a framework for improving the\nreliability and transparency of LLMs in long-horizon, non-\nstationary reasoning settings by structuring and maintaining\ncontext explicitly rather than updating model parameters.\nWhile our experiments focus on the clinical domain, the\nprimary contribution is methodological: TRACE introduces\na general approach for deploying frozen LLMs in complex\nreal-world environments where decisions must be made\nsequentially under evolving constraints.\nFrom a positive impact perspective, TRACE has the poten-\ntial to improve the safety, interpretability, and auditability\nof LLM-based decision-support systems. By representing\nboth institutional knowledge (Global Protocol) and instance-\nspecific state (Individual Protocol) in human-readable and\neditable form, the framework enables external inspection,\ncorrection, and alignment with domain-specific rules. This\ntransparency is particularly important in high-stakes do-\nmains, where opaque or untraceable model behavior can\nlead to downstream harm. More broadly, the proposed de-\nsign pattern may benefit applications beyond healthcare,\nincluding scientific workflows, software maintenance, and\noperational decision support.\nAt the same time, this work has important limitations. Our\nempirical evaluation relies on MIMIC-IV, a deidentified in-\ntensive care unit dataset with restricted access requirements.\nAs a result, reproducibility is limited to researchers who\nare able to obtain appropriate data use approvals, and the\ndataset reflects the practices and patient population of a sin-\ngle healthcare system. Moreover, TRACE is not intended\nto function as an autonomous clinical decision-maker, and\nany deployment in real-world clinical settings would require\nrigorous validation, governance, and human oversight.\nFinally, like all LLM-based systems, TRACE may inherit bi-\nases present in its LLM backbones and training data. While\nthe framework emphasizes structured reasoning and explicit\nrule grounding, it does not eliminate the risk of biased\nor inappropriate predictions. We therefore emphasize that\nTRACE should be viewed as a research contribution toward\nsafer and more interpretable LLM systems, rather than as a\nready-to-deploy solution, and that careful domain-specific\nevaluation remains essential before use in practice.\nReferences\nAgrawal, L. A., Tan, S., Soylu, D., Ziems, N., Khare, R.,\nOpsahl-Ong, K., Singhvi, A., Shandilya, H., Ryan, M. J.,\nJiang, M., et al.\nGepa: Reflective prompt evolution\ncan outperform reinforcement learning. arXiv preprint\narXiv:2507.19457, 2025.\nChen, Z., Cano, A. H., Romanou, A., Bonnet, A., Ma-\ntoba, K., Salvi, F., Pagliardini, M., Fan, S., K¨opf, A.,\nMohtashami, A., et al. Meditron-70b: Scaling medical\npretraining for large language models. arXiv preprint\narXiv:2311.16079, 2023.\nCuconasu, F., Trappolini, G., Siciliano, F., Filice, S., Cam-\npagnano, C., Maarek, Y., Tonellotto, N., and Silvestri, F.\nThe power of noise: Redefining retrieval for rag systems.\nIn Proceedings of the 47th International ACM SIGIR\nConference on Research and Development in Information\nRetrieval, pp. 719–729, 2024.\nCui, S. and Mitra, P. Automated multi-task learning for joint\ndisease prediction on electronic health records. Advances\nin Neural Information Processing Systems, 37:129187–\n129208, 2024.\nFernando, C., Banarse, D., Michalewski, H., Osindero, S.,\nand Rockt¨aschel, T. Promptbreeder: self-referential self-\nimprovement via prompt evolution. In Proceedings of the\n41st International Conference on Machine Learning, pp.\n13481–13544, 2024.\nGriot, M., Vanderdonckt, J., Yuksel, D., and Hemptinne, C.\nPattern recognition or medical knowledge? the problem\nwith multiple-choice questions in medicine. In Proceed-\nings of the 63rd Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers), pp.\n5321–5341, 2025.\nHe, H., Hao, W., Xi, Y., Chen, Y., Malin, B., and Ho,\nJ. A flexible generative model for heterogeneous tab-\nular {EHR} with missing modality.\nIn The Twelfth\nInternational Conference on Learning Representations.\nhttps://openreview. net/forum? id= W2tCmRrj7H, 2024.\nJohnson, A. E., Bulgarelli, L., Shen, L., Gayles, A., Sham-\nmout, A., Horng, S., Pollard, T. J., Hao, S., Moody, B.,\nGow, B., et al. Mimic-iv, a freely accessible electronic\nhealth record dataset. Scientific data, 10(1):1, 2023.\nLi, T., Zhang, G., Do, Q. D., Yue, X., and Chen, W. Long-\ncontext llms struggle with long in-context learning. arXiv\npreprint arXiv:2404.02060, 2024.\nLiu, J., Zhu, D., Bai, Z., He, Y., Liao, H., Que, H., Wang, Z.,\nZhang, C., Zhang, G., Zhang, J., et al. A comprehensive\nsurvey on long context language modeling. arXiv preprint\narXiv:2503.17407, 2025.\nLiu, N. F., Lin, K., Hewitt, J., Paranjape, A., Bevilacqua,\nM., Petroni, F., and Liang, P. Lost in the middle: How\nlanguage models use long contexts. Transactions of the\nAssociation for Computational Linguistics, 12:157–173,\n2024.\n9\n"}, {"page": 10, "text": "TRACE: Temporal Reasoning via Agentic Context Evolution for Streaming EHRs\nMadaan, A., Tandon, N., Gupta, P., Hallinan, S., Gao,\nL., Wiegreffe, S., Alon, U., Dziri, N., Prabhumoye, S.,\nYang, Y., et al. Self-refine: Iterative refinement with self-\nfeedback. Advances in Neural Information Processing\nSystems, 36:46534–46594, 2023.\nNori, H., King, N., McKinney, S. M., Carignan, D., and\nHorvitz, E. Capabilities of gpt-4 on medical challenge\nproblems. arXiv preprint arXiv:2303.13375, 2023.\nPacker, C., Fang, V., Patil, S., Lin, K., Wooders, S., and\nGonzalez, J. Memgpt: Towards llms as operating systems.\n2023.\nPoulain, R. and Beheshti, R. Graph transformers on ehrs:\nBetter representation improves downstream performance.\nIn The Twelfth International Conference on Learning\nRepresentations, 2024.\nPress, O., Smith, N., and Lewis, M. Train short, test long:\nAttention with linear biases enables input length extrapo-\nlation. In International Conference on Learning Represen-\ntations, 2022. URL https://openreview.net/\nforum?id=R8sQPpGCv0.\nQu, Z. and F¨arber, M. Medieval: A unified medical bench-\nmark for patient-contextual and knowledge-grounded rea-\nsoning in llms. arXiv preprint arXiv:2512.20822, 2025.\nShinn, N., Cassano, F., Gopinath, A., Narasimhan, K., and\nYao, S. Reflexion: Language agents with verbal rein-\nforcement learning. Advances in Neural Information\nProcessing Systems, 36:8634–8652, 2023.\nSinghal, K., Azizi, S., Tu, T., Mahdavi, S. S., Wei, J., Chung,\nH. W., Scales, N., Tanwani, A., Cole-Lewis, H., Pfohl, S.,\net al. Large language models encode clinical knowledge.\nNature, 620(7972):172–180, 2023.\nSuzgun, M., Yuksekgonul, M., Bianchi, F., Jurafsky, D.,\nand Zou, J.\nDynamic cheatsheet: Test-time learning\nwith adaptive memory. arXiv preprint arXiv:2504.07952,\n2025.\nWaxler, S., Blazek, P., White, D., Sneider, D., Chung, K.,\nNagarathnam, M., Williams, P., Voeller, H., Wong, K.,\nSwanhorst, M., et al. Generative medical event models\nimprove with scale. arXiv preprint arXiv:2508.12104,\n2025.\nWornow, M., Xu, Y., Thapa, R., Patel, B., Steinberg, E.,\nFleming, S., Pfeffer, M. A., Fries, J., and Shah, N. H. The\nshaky foundations of large language models and foun-\ndation models for electronic health records. npj digital\nmedicine, 6(1):135, 2023.\nWornow, M., Bedi, S., Hernandez, M. A. F., Steinberg, E.,\nFries, J. A., R´e, C., Koyejo, S., and Shah, N. H. Context\nclues: Evaluating long context models for clinical pre-\ndiction tasks on ehrs. arXiv preprint arXiv:2412.16178,\n2024.\nXia, P., Zhu, K., Li, H., Wang, T., Shi, W., Wang, S.,\nZhang, L., Zou, J., and Yao, H.\nMMed-RAG: Ver-\nsatile multimodal RAG system for medical vision lan-\nguage models. In The Thirteenth International Confer-\nence on Learning Representations, 2025. URL https:\n//openreview.net/forum?id=s5epFPdIW6.\nXu, R., Shi, W., Yu, Y., Zhuang, Y., Jin, B., Wang, M. D.,\nHo, J., and Yang, C. Ram-ehr: Retrieval augmentation\nmeets clinical predictions on electronic health records.\nIn Proceedings of the 62nd Annual Meeting of the Asso-\nciation for Computational Linguistics (Volume 2: Short\nPapers), pp. 754–765, 2024.\nYang, C., Wang, X., Lu, Y., Liu, H., Le, Q. V., Zhou, D.,\nand Chen, X. Large language models as optimizers. In\nThe Twelfth International Conference on Learning Repre-\nsentations, 2023.\nZhang, Q., Hu, C., Upasani, S., Ma, B., Hong, F., Kamanuru,\nV., Rainton, J., Wu, C., Ji, M., Li, H., et al. Agentic con-\ntext engineering: Evolving contexts for self-improving\nlanguage models.\narXiv preprint arXiv:2510.04618,\n2025.\nZhong, Y., Wang, X., Wang, J., Zhang, X., Wang, Y., Huai,\nM., Xiao, C., and Ma, F. Synthesizing multimodal elec-\ntronic health records via predictive diffusion models. In\nProceedings of the 30th ACM SIGKDD Conference on\nKnowledge Discovery and Data Mining, pp. 4607–4618,\n2024.\nZhou, Y., Muresanu, A. I., Han, Z., Paster, K., Pitis, S.,\nChan, H., and Ba, J. Large language models are human-\nlevel prompt engineers. In The eleventh international\nconference on learning representations, 2022.\nZhou, Y., Liu, X., Ning, C., Zhang, X., and Wu, J. Re-\nliable and diverse evaluation of LLM medical knowl-\nedge mastery. In The Thirteenth International Confer-\nence on Learning Representations, 2025. URL https:\n//openreview.net/forum?id=TXfzH933qV.\nZuo, Y., Qu, S., Li, Y., Chen, Z.-R., Zhu, X., Hua, E., Zhang,\nK., Ding, N., and Zhou, B. MedxpertQA: Benchmark-\ning expert-level medical reasoning and understanding.\nIn Forty-second International Conference on Machine\nLearning, 2025. URL https://openreview.net/\nforum?id=IyVcxU0RKI.\n10\n"}, {"page": 11, "text": "TRACE: Temporal Reasoning via Agentic Context Evolution for Streaming EHRs\nA. Agent Prompt Templates\nWe provide the Jinja2-style Python templates used by the five agents in TRACE. All templates are model-agnostic and\npopulated dynamically at runtime with the current patient context, memory contents, and protocol index.\nA.1. Phase I Agent: Reflector (Offline)\nReflector System Prompt Template\nREFLECTOR_TEMPLATE = \"\"\"\nYou are a Senior Medical Auditor responsible for improving institutional protocols.\n[SCENARIO]\nAn AI clinical agent failed to predict the correct intervention for a patient.\nPatient History:\n{{ patient_history_text }}\nGround Truth Action:\n{{ ground_truth_action }}\nAI Prediction (Incorrect):\n{{ ai_prediction }}\n[TASK]\nAnalyze the gap. Why did the AI miss this?\n- Was it missing medical knowledge?\n- Was it missing an institutional rule (e.g., \"IF Glucose > 180 THEN start insulin\")?\n[INSTRUCTION]\nPropose a generalizable rule that would prevent this error in the future.\n- The rule must be conditional: \"IF [Trigger] THEN [Action]\".\n- Do not reference any patient identifiers.\n- Assign a medical category label (e.g., \"ENDOCRINE_MGMT\", \"SEPSIS\", \"RENAL\").\n[OUTPUT FORMAT]\nReturn ONLY a valid JSON object:\n{\n\"error_analysis\": \"Brief explanation of the failure mode.\",\n\"proposed_rule\": {\n\"category\": \"ENDOCRINE_MGMT\",\n\"trigger_condition\": \"Blood Glucose > 180 mg/dL\",\n\"action_directive\": \"Initiate sliding scale insulin protocol\",\n\"rule_text\": \"IF Glucose > 180 mg/dL AND patient is NPO, THEN start basal insulin.\"\n}\n}\n\"\"\"\nA.2. Phase II Agent: Router\nRouter System Prompt Template\nROUTER_TEMPLATE = \"\"\"\nYou are a Clinical Knowledge Router. Your goal is to select the most relevant\nclinical protocols for the current situation.\n[INPUT CONTEXT]\nActive Patient State:\n11\n"}, {"page": 12, "text": "TRACE: Temporal Reasoning via Agentic Context Evolution for Streaming EHRs\n{{ patient_state_json }}\nRecent Events (Last 6 hours):\n{{ recent_events_text }}\nAvailable Protocol Index:\n{{ protocol_index_list }}\n[INSTRUCTION]\nAnalyze the recent events and patient state for clinical triggers\n(e.g., Lactate > 4, Hypotension, New admission).\nSelect up to 3 protocol IDs from the index that are critical for the immediate next\nsteps.\nIf no specific protocol applies, return an empty list.\n[OUTPUT FORMAT]\nReturn ONLY a valid JSON object:\n{\n\"reasoning\": \"Brief explanation of why these protocols are relevant.\",\n\"selected_protocol_ids\": [\"SEPSIS_01\", \"RENAL_03\"]\n}\n\"\"\"\nA.3. Phase II Agent: Reasoner\nReasoner System Prompt Template\nREASONER_TEMPLATE = \"\"\"\nYou are TRACE, an expert clinical decision agent. Predict the next logical bundle\nof clinical actions.\n[MEMORY BANK]\nInstitutional Rules (Global Protocol):\n{{ selected_rules_text }}\nPatient Tracker (Individual Protocol):\n{{ patient_state_json }}\n[SCENARIO]\nPatient event history:\n{{ event_stream_history }}\n[TASK]\nPredict the next Clinical Event Bundle. Use the following heuristic:\n- If the last bundle was primarily Observation (labs/vitals), the next is often\nDecision (meds/procedures).\n- If the last bundle was Intervention, the next is often Monitoring (labs).\n[CONSTRAINTS]\nCitations Required:\nYou MUST cite a Rule ID (e.g., [R-01]) or a State ID (e.g., [S-05]) for every major\ndecision.\nPrecision:\nUse specific medication names and dose categories (e.g., \"low-dose norepinephrine\"),\nnot generic classes (e.g., \"vasopressors\").\n[OUTPUT FORMAT]\nReturn ONLY a valid JSON object:\n{\n12\n"}, {"page": 13, "text": "TRACE: Temporal Reasoning via Agentic Context Evolution for Streaming EHRs\n\"thought_process\": \"Short rationale grounded in cited facts/rules.\",\n\"next_bundle_type\": \"MEDICATIONS\" | \"LABS\" | \"PROCEDURES\",\n\"predicted_actions\": [\n\"Order 1L crystalloid bolus\",\n\"Start broad-spectrum antibiotics\"\n],\n\"citations\": [\"S-01\", \"R-01\"]\n}\n\"\"\"\nA.4. Phase II Agent: Auditor\nAuditor System Prompt Template\nAUDITOR_TEMPLATE = \"\"\"\nYou are a Clinical Safety Sentinel. Review the proposed AI decision for safety\nviolations.\n[CONTEXT]\nProposed Actions:\n{{ proposed_actions_list }}\nPatient Contraindications / Problems:\n{{ active_problems_list }}\nRelevant Rules:\n{{ active_rules_text }}\n[CHECKLIST]\n- Contraindications: Does the patient have a condition that forbids the action (e.g.,\nrenal failure)?\n- Rule adherence: Does the action violate an institutional rule?\n- Hallucination: Does the AI cite a patient fact that is not present in the provided\ncontext?\n[OUTPUT FORMAT]\nReturn ONLY a valid JSON object:\n{\n\"status\": \"PASS\" | \"FAIL\",\n\"risk_level\": \"LOW\" | \"HIGH\",\n\"critique\": \"If FAIL, explain the violation and reference the conflicting rule/state.\n\",\n\"corrected_action\": \"If FAIL, propose a safer alternative; otherwise leave empty.\"\n}\n\"\"\"\nA.5. Phase II Agent: Steward\nSteward System Prompt Template\nSTEWARD_TEMPLATE = \"\"\"\nYou are the State Manager. Update the structured patient record based on new raw\nevents.\n[CURRENT STATE]\n{{ current_state_json }}\n13\n"}, {"page": 14, "text": "TRACE: Temporal Reasoning via Agentic Context Evolution for Streaming EHRs\n[NEW RAW EVENTS]\n{{ new_event_bundle_text }}\n[INSTRUCTION]\nPerform a structured state update (mitosis):\n- Diagnoses: Add new confirmed diagnoses; move resolved ones to history.\n- Medications: Add new starts; if a medication is stopped/discontinued, remove it from\ncurrent meds.\n- Trends: Update key lab/vital trends (e.g., creatinine, lactate).\n[OUTPUT FORMAT]\nReturn ONLY the updated JSON state object. Do not summarize.\nBe precise with values and maintain a consistent schema.\n\"\"\"\n14\n"}]}