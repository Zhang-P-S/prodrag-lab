{"doc_id": "arxiv:2512.20298", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2512.20298.pdf", "meta": {"doc_id": "arxiv:2512.20298", "source": "arxiv", "arxiv_id": "2512.20298", "title": "Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives", "authors": ["Karolina Drożdż", "Kacper Dudzic", "Anna Sterna", "Marcin Moskalewicz"], "published": "2025-12-23T12:05:01Z", "updated": "2025-12-23T12:05:01Z", "summary": "Growing reliance on LLMs for psychiatric self-assessment raises questions about their ability to interpret qualitative patient narratives. We present the first direct comparison between state-of-the-art LLMs and mental health professionals in diagnosing Borderline (BPD) and Narcissistic (NPD) Personality Disorders utilizing Polish-language first-person autobiographical accounts. We show that the top-performing Gemini Pro models surpassed human professionals in overall diagnostic accuracy by 21.91 percentage points (65.48% vs. 43.57%). While both models and human experts excelled at identifying BPD (F1 = 83.4 & F1 = 80.0, respectively), models severely underdiagnosed NPD (F1 = 6.7 vs. 50.0), showing a reluctance toward the value-laden term \"narcissism.\" Qualitatively, models provided confident, elaborate justifications focused on patterns and formal categories, while human experts remained concise and cautious, emphasizing the patient's sense of self and temporal experience. Our findings demonstrate that while LLMs are highly competent at interpreting complex first-person clinical data, they remain subject to critical reliability and bias issues.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2512.20298v1", "url_pdf": "https://arxiv.org/pdf/2512.20298.pdf", "meta_path": "data/raw/arxiv/meta/2512.20298.json", "sha256": "46e4ab54565cb4fb0a72bd608ae5c49aea0ccebe64b6862940001996323d9a06", "status": "ok", "fetched_at": "2026-02-18T02:23:56.358787+00:00"}, "pages": [{"page": 1, "text": "Patterns vs. Patients: Evaluating LLMs against Mental Health\nProfessionals on Personality Disorder Diagnosis through First-Person\nNarratives\nKarolina Dro˙zd˙z1*, Kacper Dudzic1,2,3*, Anna Sterna4, Marcin Moskalewicz1,4,5\n1IDEAS Research Institute, Warsaw, Poland\n2Adam Mickiewicz University, Pozna´n, Poland\n3AMU Center for Artificial Intelligence, Pozna´n, Poland\n4Pozna´n University of Medical Sciences, Pozna´n, Poland\n5Maria Curie-Skłodowska University, Lublin, Poland\nCorrespondence: karolina.drozdz@ideas.edu.pl\nAbstract\nGrowing reliance on LLMs for psychiatric self-\nassessment raises questions about their abil-\nity to interpret qualitative patient narratives.\nWe present the first direct comparison between\nstate-of-the-art LLMs and mental health pro-\nfessionals in diagnosing Borderline (BPD) and\nNarcissistic (NPD) Personality Disorders utiliz-\ning Polish-language first-person autobiographi-\ncal accounts. We show that the top-performing\nGemini Pro models surpassed human profes-\nsionals in overall diagnostic accuracy by 21.91\npercentage points (65.48% vs. 43.57%). While\nboth models and human experts excelled at\nidentifying BPD (F1 = 83.4 & F1 = 80.0,\nrespectively), models severely underdiagnosed\nNPD (F1 = 6.7 vs. 50.0), showing a reluc-\ntance toward the value-laden term „narcissism.”\nQualitatively, models provided confident, elab-\norate justifications focused on patterns and for-\nmal categories, while human experts remained\nconcise and cautious, emphasizing the patients’\nsense of self and temporal experience. Our find-\nings demonstrate that while LLMs are highly\ncompetent at interpreting complex first-person\nclinical data, their outputs still carry critical\nreliability and bias issues.\n1\nIntroduction\nSystemic pressures on mental healthcare have cre-\nated critical accessibility gaps and diagnostic de-\nlays (Sun et al., 2023; Barbui et al., 2025). Conse-\nquently, the public is increasingly turning to widely\navailable Large Language Models (LLMs) for self-\nassessment, thereby bypassing traditional clinical\npathways (Lawrence et al., 2024; McBain et al.,\n2025). While this trend may partially relieve strain\n*Equal contribution.\non the healthcare system, it also introduces consid-\nerable ethical and clinical risks, such as the poten-\ntial for inaccurate or misleading diagnoses (Har-\nrer, 2023). This study empirically compares the\ndiagnostic capabilities of current open- and closed-\nsource LLMs to mental health professionals in iden-\ntifying a complex and frequently misdiagnosed con-\ndition of Personality Disorder (PD).\nPrevious research shows that state-of-the-art\nLLMs can achieve performance levels that ap-\nproach, or in some cases surpass, those of\ntrained clinicians on standardized medical bench-\nmarks (Grzybowski et al., 2025; Workum et al.,\n2025), and substantially improve clinicians’ diag-\nnostic accuracy when used as a decision-support\ntool (Noda et al., 2025). These capabilities extend\nto chatbot-patient interaction, where recent inves-\ntigations suggest that LLMs can surpass human\nphysicians in expressing empathy in written clini-\ncal communication (Ayers et al., 2023). However,\nit remains unclear whether such capabilities can be\neffectively applied to complex psychiatric condi-\ntions, where diagnoses often lack well-established\nobjective markers and depend heavily on nuanced,\nsubjective accounts of patients.\nA limited body of work evaluating LLMs specifi-\ncally on psychiatric and psychological benchmarks\nreveals a more uneven performance. Studies show\nthat while models such as GPT-4 and Llama 3\nachieve high accuracy (up to 85%) in binary mental\ndisorder detection tasks, their performance varies\nsignificantly across different datasets (Hanafi et al.,\n2025).\nNotably, LLMs fine-tuned on domain-\nspecific data do not outperform generalist mod-\nels on existing benchmarks (Fouda et al., 2025;\nNguyen et al., 2025).\nDespite these advances, most existing evalua-\n1\narXiv:2512.20298v1  [cs.CL]  23 Dec 2025\n"}, {"page": 2, "text": "tions rely on binary or multiple-choice answer for-\nmats and use clinical-annotated datasets or noisy so-\ncial media posts. Such evaluations are not directly\ncomparable to the semi-structured, first-person nar-\nrative through which patients typically communi-\ncate their experiences to a mental health profes-\nsional. Furthermore, existing studies have priori-\ntized outcome metrics over explanatory evaluations\nof the reasoning process. Consequently, they do\nnot verify whether models emulate human cogni-\ntive processes or if their justifications correspond to\nhuman diagnostic decisions. This discrepancy high-\nlights a critical research gap: it remains unknown\nif LLMs can maintain diagnostic accuracy on raw\nfirst-person testimonies, provide diagnosis-relevant\njustifications, and whether their performance and\nreasoning compare with those of mental health pro-\nfessionals.\nWe explore this gap in a specific context of two\nconditions, namely Borderline Personality Disor-\nder (BPD) and Narcissistic Personality Disorder\n(NPD). These are strong, yet underexplored, cases\nfor model evaluation, particularly as their diagnos-\ntic assessment might be overdetermined by the the-\noretical framework applied, or the lack thereof (as\nwith the lay understanding of the terms „borderline”\nand „narcissism”).\nWhile the DSM-III (American Psychiatric Asso-\nciation, 1980) formally established Personality Dis-\norder (PD) as a standalone diagnostic unit, its ini-\ntial categorical approach—in which mental health\ndisorders are perceived as binary categories—has\nbeen criticized for producing high comorbidity and\npermitting substantial heterogeneity within cate-\ngories (Widiger and Trull, 2007). In response, re-\ncent revisions in DSM-5 (American Psychiatric\nAssociation, 2022) and ICD-11 (World Health Or-\nganization, 2022) have redirected attention from\ndistinct categories of PD to transdiagnostic com-\nmonalities and their continuous variation, i.e., a\ndimensional, non-exclusive approach. The DSM-5\nAMPD (Section III) (American Psychiatric Associ-\nation, 2022) introduced a general criterion (Crite-\nrion A) that defines a shared basis for all PD, inde-\npendent of their categorical manifestations (Pincus\net al., 2020).\nGiven the prominence of the ICD and DSM\nframeworks, current LLMs could be biased toward\na dimensional understanding of PD. Conversely,\nthe ubiquity of terms like „borderline” and „narcis-\nsism” in everyday language—and thus in training\ncorpora—suggests a potential counter-bias toward\na categorical understanding of PD. Since empirical\nevidence does not clarify whether current LLMs\nlean toward a dimensional or categorical view of\nPD, we examined both frameworks independently.\nIn summary, our contributions are as follows:\n• We present the first evaluation of state-of-the-\nart LLMs on raw, first-person accounts of pa-\ntients’ life stories, assessing the models’ ca-\npacity to interpret lived biographical experi-\nences.\n• We introduce an expert-informed evaluation\nprotocol that encompasses diverse conceptual-\nizations of mental disorders (i.e., categorical\nvs. dimensional).\n• We directly compare the diagnostic perfor-\nmance of human experts and LLMs on com-\nplex mental disorders, moving beyond iso-\nlated model benchmarking.\n• We adopt an explanatory approach to both hu-\nman data and model outputs, aiming not only\nto quantify performance but also to provide\ninterpretable insights.\n2\nMethods\n2.1\nData\nTo ensure the clinical validity of the sensitive\nfirst-person data used for evaluation, all narra-\ntives were collected at the Psychiatric Hospital in\nMi˛edzyrzecz, Poland, following a multi-stage pro-\ncedure.\nFirst, 120 patients with a diagnosed personality\ndisorder were identified. Each diagnosis had been\nestablished in outpatient care and subsequently\nconfirmed by two experienced psychiatrists dur-\ning inpatient admission, followed by an assessment\nby a clinical psychologist. Second, cases involv-\ning suicidal crisis, psychotic decompensation, or\ncomorbid substance use disorders were excluded.\nThird, we employed intensity sampling to select\ninformation-rich, yet non-extreme, cases suitable\nfor both qualitative and computational analysis.\nBased on ICD-10 diagnostic coding, 24 BPD\nand 20 NPD cases were shortlisted. To ensure\ncomparability, we assessed personality functioning\nand maladaptive traits using a multi-dimensional\nprotocol (see Appendix A). All patients partici-\npated in 50–70 minute semi-structured qualitative\ninterviews adapted from McAdams’ Life Story In-\nterview (McAdams, 1988), designed to explore nar-\nrative identity. Two additional questions probing re-\nflective self-experience were included. Interviews\n2\n"}, {"page": 3, "text": "were audio-recorded and transcribed, resulting in a\nPolish-language corpus exceeding 200,000 words.\nThe qualitative analyses of all BPD cases (Sterna\net al., 2025) and all NPD cases (conducted for this\nproject) provided an in-depth understanding of the\nsubjective nuances represented in the data.\nSix cases—three BPD and three NPD—were\nselected for this study. These were meticulously\nchosen to represent mild, moderate, and severe lev-\nels of impairment, and to capture the breadth of\nnarrative expression within each disorder. Their\nselection reflects both the unique richness of their\nnarratives and the practical constraints imposed by\na human-model comparison (since each narrative is\nlong, complex, and requires significant time com-\nmitment and detailed evaluation).\nAdditionally, from a pool of 20 control partic-\nipants who underwent the same interview proce-\ndure, one control case with no personality disorder\nand subclinical personality functioning was chosen.\nIn total, the evaluation dataset comprised 7 tran-\nscriptions of autobiographical interviews: 3 BPD,\n3 NPD, and 1 Healthy Control.\n2.2\nModel Selection\nWe included a total of N = 16 leading models and\nvariants, split into a closed-source (N = 9) and an\nopen-source group (N = 7). Our selection criteria\nencompassed: general public interest and availabil-\nity, presence in recent evaluations on related mate-\nrial (Fouda et al., 2025; Hua et al., 2025; Nguyen\net al., 2025), access model (licensing), parameter\ncount, country of origin, and reasoning ability.\nThe closed-source group included: Gemini 2.5\nPro (Gemini Team, 2025), Gemini 3 Pro (Google,\n2025), Claude Opus 4.1 (Anthropic, 2025), GPT-\n4o (OpenAI, 2024), GPT-4.1 (OpenAI, 2025b), and\nfour variants of GPT-5 (OpenAI, 2025a) with all\navailable values of the OpenAI API’s reasoning\neffort parameter (from minimal to high). The open-\nsource group consisted of: Gemma 3 27B (Gemma\nTeam, 2025), Llama 3.3 70B (Llama Team, 2024),\nDeepSeek R1 0528 (DeepSeek-AI, 2025a), two\nvariants of DeepSeek v3.1 Terminus (DeepSeek-AI,\n2025b) with reasoning either enabled or disabled,\nand two variants of Qwen 3 32B (Qwen Team,\n2025), also with and without reasoning.\nWe did not include domain-specific models\ntrained on medical data for two reasons. Firstly,\nthe context windows of available medical models\nevaluated in existing literature (Fouda et al., 2025;\nHanafi et al., 2025; Hua et al., 2025; Nguyen et al.,\n2025) proved to be too small for the full patient\ntestimonies—except for MentalQLM (Shi et al.,\n2025), which has not been made publicly avail-\nable. Secondly, recent studies indicate that general-\npurpose models perform similarly to or better than\nmedical models on psychiatric tasks (Fouda et al.,\n2025).\n2.3\nMental Health Experts\nThe study sample consisted of N = 6 highly ex-\nperienced mental health professionals, comprising\nthree psychiatrists and three psychotherapists, re-\ncruited through our professional network.\nThe\ngroup was balanced by gender, with three partici-\npants identifying as men and three as women; the\nmean age was 48.5 years (SD = 11.18), with an\naverage of 18.5 years of professional experience.\nImportantly, the experts were external to the orig-\ninal diagnostic teams. They were blinded to the\npatients’ previous medical records and ground truth\ndiagnoses, and had never previously encountered\nthe patients whose narratives they evaluated.\n2.4\nProcedure\nHuman and model participants conducted a diag-\nnostic assessment of each autobiographical testi-\nmony, adhering to a 6-step response template (see\nAppendix B). The 6-step protocol required par-\nticipants to assign a (1) categorical diagnosis and\n(2) severity rating, each with a corresponding con-\nfidence level (3 & 4). Participants were also in-\nstructed to provide a brief justification for both (5)\nthe diagnosis and (6) severity assessment, in no\nmore than 200 words, indicating relevant evidence\nfrom the testimony and outlining their theoretical\nunderstanding of PD and their origins. All assess-\nments were conducted in Polish, reflecting the lan-\nguage of the source data and the native language of\nthe mental health professionals.\nTo avoid priming and to allow participants to\napply their expert knowledge, the categorical diag-\nnosis was an open-ended task without predefined\noptions. In contrast, both the severity rating and the\nconfidence ratings followed fixed scales: severity\nwas rated on a 0–3 scale (0 = none, 1 = mild, 2\n= moderate, 3 = severe), and confidence on a 1–4\nscale (1 = guessing, 2 = somewhat confident, 3 =\nfairly confident, 4 = completely confident).\nWhile human participants evaluated each testi-\nmony once, models were presented with each case\nthree times to address potential diagnostic incon-\nsistency stemming from their non-deterministic na-\n3\n"}, {"page": 4, "text": "ture. This resulted in 7 trials per human expert and\n21 trials (7 cases × 3 repetitions) per model.\n2.5\nData Analysis\n2.5.1\nPerformance Metrics\nTwo complementary performance metrics were\ncomputed: a categorical and a dimensional score.\nThe first, based on the open-ended diagnosis, cap-\ntured performance within the traditional categorical\nmodel, which assumes the presence or absence of\ndiscrete diagnostic entities. The second was cal-\nculated from the severity rating, which reflects the\ndimensional model conceptualizing personality dis-\norder along a continuum of severity.\nFor human participants, each score represented\nthe total number of correct evaluations across the\nseven cases (0–7). For the models, scores were\ncomputed across all 21 trials to account for relia-\nbility (7 cases × 3 repetitions; 0–21 score). Since\na correct model response required both accuracy\nand consistency across the repeated trials, a perfect\nscore would indicate not only a valid diagnostic\njudgment but also a fully consistent performance.\n2.5.2\nDiagnostic Justifications\nHuman mental health professionals can arrive at\nsimilar diagnostic conclusions through different\ncognitive and emotional pathways (Biondi et al.,\n2022). Traces of these mental processes are re-\nflected in the semantic content of the justifications\nprovided during the diagnosis. To use this informa-\ntion alongside quantitative metrics, we mapped the\ndiagnostic justifications onto a high-dimensional\nsemantic embedding space. This allowed for a com-\nparison of diagnostic expertise leverage between\nhuman and model participants, as well as among\ndifferent models.\nBAAI/bge-multilingual-gemma21 was cho-\nsen as the embedding model owing to its supe-\nrior performance on Polish-language tasks in the\nMMTEB benchmark (Enevoldsen et al., 2025). We\ncreated a single summary embedding representing\nthe averaged semantic content of justifications for\neach model separately, as well as a single one repre-\nsenting all human participant data to account for its\ncomparative scarcity. A more detailed process of\nembedding creation was described in Appendix G.\nThe summary embeddings were aggregated into\ntwo distinct datasets: a global dataset comprising\nall agents (both models and humans) to assess the\n1https://huggingface.co/BAAI/\nbge-multilingual-gemma2\nhuman-AI semantic gap, and a model-only dataset\nto allow for a finer-grained analysis of inter-model\nsemantic differences.\nTo visualize the high-dimensional relationships\nbetween these representations, we employed a dual-\nmethod dimensionality reduction approach utiliz-\ning Multidimensional Scaling (MDS) (Kruskal,\n1964) and Uniform Manifold Approximation and\nProjection (UMAP) (McInnes et al., 2020). This\ncombination was chosen to provide a comprehen-\nsive view of the semantic space: MDS was selected\nfor its ability to preserve global metric distances,\noffering a faithful representation of the relative\ndissimilarities between models. Complementar-\nily, UMAP was utilized for its strength in manifold\nlearning and local structure preservation, which\nallows for the identification of distinct semantic\nclusters (neighborhoods).\nMDS was conducted using the scikit-learn2\nlibrary (Pedregosa et al., 2011). Before dimension-\nality reduction, a pairwise cosine distance matrix\nwas computed for the embeddings to ensure that the\nangular relationships inherent to semantic vector\nspaces were preserved. UMAP was conducted us-\ning the umap-learn3 library. Details on the hyper-\nparameter values used can be found in Appendix F.\n2.5.3\nLexical Features\nTo further investigate the divergence between lin-\nguistic justification of diagnostic reasoning in hu-\nmans and models, we conducted a follow-up in-\nquiry into interpretable differences. We aggregated\nall justifications into two distinct corpora—human-\nwritten and model-written—and sought to identify\nlexical features that were statistically overrepre-\nsented in one group relative to the other. The fea-\ntures were identified with the weighted log-odds\nratio with informative Dirichlet prior method orig-\ninally applied to the problem of detecting lexical\npolarization in political discourse (Monroe et al.,\n2008).\nIn the technical implementation, we first ap-\nplied a text pre-processing pipeline to the two cor-\npora, converting non-Polish non-ASCII characters\ninto ASCII equivalents, as well as removing LLM-\ncharacteristic text formatting artifacts, punctuation,\ndigits, and optionally stop words. Finally, we ap-\nplied Monroe et al.’s method through the ConvoKit\nlibrary (Chang et al., 2020). We considered two pa-\nrameters to adjust in the feature generation process:\n2https://github.com/scikit-learn/scikit-learn\n3https://github.com/lmcinnes/umap\n4\n"}, {"page": 5, "text": "stop word removal—either enabled or disabled, and\nthe maximum n-gram length—exclusive ranges of\n1 to 3 and a combined 1–3 one, ultimately choosing\nunigrams with the stop words removed as the most\ninformative configuration.\n3\nResults\n3.1\nDiagnostic Performance\nFigure 1: Categorical and dimensional score (recalcu-\nlated on a 0–1 scale) comparison between mental health\nprofessionals and models.\nFigure 2: Average model and mental health profession-\nals’ scores by true diagnosis.\nA comparative analysis of diagnostic performance\nrevealed significant variability among models and\nmental health professionals, as summarized below.\nBest-performing models outperform the hu-\nman diagnostic average. The overall human av-\nerage score was 43.57%, with a categorical score\nof 3.60 out of 7 (51.43%) and a dimensional score\nof 2.50 out of 7 (35.71%). An exploratory analysis\nof the participant sub-groups suggested a potential\nperformance gap: psychotherapists scored higher\non the categorical task (mean difference: 2.33),\nwhile psychiatrists scored slightly higher on the\ndimensional task (mean difference: 0.33).\nModel performance, evaluated over 21 tri-\nals, was relatively dispersed, with several top-\nperforming models exceeding the human average\n(see Figure 1).\nFor the categorical task, most\nmodels (12 of 16) converged on a score of 12/21\n(57.1%), outperforming the human average of\n51.4%. Gemini 3 Pro achieved the highest cat-\negorical accuracy (15/21; 71.4%), while Gemini\n2.5 Pro performed best on the dimensional score\n(14/21; 66.7%). Notably, the averaged Gemini Pro\nmodel family overall score exceeded the human\noverall average by 21.91 percentage points (65.48%\nvs. 43.57%). Conversely, Gemma 3 27B was the\nworst-performing model, scoring 9/21 (42.8%) on\nthe categorical task and 6/21 (28.5%) on the dimen-\nsional task.\nFurther analysis of model performance indicated\nthat reasoning did not consistently improve diag-\nnostic accuracy. Model size appeared to be a factor,\nwith smaller models generally performing worse\nthan larger ones. No clear performance gap was\nobserved between closed-source and open-source\nmodels.\nBPD overdiagnosis and NPD underdiagno-\nsis drive systematic bias, most pronounced in\nmodels. An analysis of the N = 378 total diag-\nnoses (see Appendix C, Table C.1) by both models\n(N = 336) and humans (N = 42) revealed system-\natic diagnostic bias.\nBPD was the most common diagnosis, account-\ning for 53.97% of all combined diagnoses. This\ntendency to overdiagnose BPD resulted in a near-\nperfect categorical recall for models (97.9%, F1 =\n83.4), substantially higher than that of human ex-\nperts (66.7%, F1 = 80.0). However, such sen-\nsitivity came at the cost of precision (72.7%),\nwhereas human experts demonstrated perfect pre-\ncision (100%), suggesting that while clinicians\nmissed some cases, their positive diagnoses were\nfully reliable. The high categorical recall for both\nmodels and humans was often paired with a lower\ndimensional recall (45.14% for models, 38.89% for\nhumans; see Figure 2).\nIn contrast, NPD was severely underdiagnosed\nby both humans and models, representing 2.65%\n(10 of 378) of all diagnoses, with humans outper-\nforming the models (14% against 1.5% for mod-\nels). Gemini 2.5 Pro and Gemini 3 Pro were the\n5\n"}, {"page": 6, "text": "only models to correctly identify 1 out of 3 NPD\ncases (in 2 out of 3 trials for Gemini 2.5 Pro,\nand 3 out of 3 trials for Gemini 3 Pro). Conse-\nquently, the aggregate model recall for NPD col-\nlapsed to just 3.5% (F1 = 6.7). While the rare\nNPD diagnoses provided by models were accurate\n(precision = 100%), the vast majority of cases\nwere missed. This contrasts with human experts,\nwho achieved a higher recall of 33.3% (F1 = 50.0).\nHowever, a distinct positive dissociation was ob-\nserved in model performance: despite failing to cat-\negorically identify the disorder, models achieved\na significantly higher dimensional recall (40.97%)\nfor the same NPD cases, notably outperforming\nhuman experts (22.22%) on the severity metric.\nThe „healthy” label was the second most com-\nmon, accounting for 21.43% of all assigned diag-\nnoses. Models were highly effective at identify-\ning the absence of pathology (recall = 87.5%,\nF1 = 69.4) compared to human experts (recall =\n60.0%, F1 = 50.0). Despite these high scores, a\ndetailed analysis of diagnostic distributions (see\nAppendix D, Figure D.1) reveals a specific „de-\npathologizing bias” in the GPT family. GPT-4o\nshowed the most extreme bias, misclassifying cases\nas healthy 10 times. GPT-4.1 followed with 5 false\npositives, whereas the GPT-5 variants had 2–3 each.\nThis suggests a tendency in the GPT model family\nto favor non-clinical classifications. Notably, hu-\nmans also showed a slight bias toward non-clinical\nclassifications, evidenced by 4 false positives (see\nAppendix D, Figure D.1), driven by frequent as-\nsessments that the testimonies lacked sufficient evi-\ndence for a PD diagnosis.\nA significant misclassification bias was observed\nfor Avoidant Personality Disorder (AvPD) (see Ap-\npendix C, Table C.1). It emerged as the third most\ncommon diagnosis overall (15.08%), but this preva-\nlence was driven largely by models. AvPD ac-\ncounted for 16.07% (54 of 336) of model-generated\ndiagnoses, compared to 7.14% (3 of 42) of human\ndiagnoses. Given that AvPD was not present in the\nground truth answers, this high prevalence points to\na systematic tendency to misinterpret symptoms of\nother conditions as AvPD. On the other hand, only\none out of 336 diagnoses by models indicated a PD\ncategory not present in current diagnostic frame-\nworks, namely Masochistic PD.\nModels demonstrate higher and more uni-\nform confidence than human experts. Overall,\nmodels displayed higher certainty than human prac-\ntitioners for both categorical diagnosis (M = 2.94\nvs. M = 2.52) and severity assessment (M = 3.07\nvs. M = 2.86). Across both groups, certainty was\nhigher for severity assessments than for categorical\ndiagnoses. Among the individual models, Gemini\n3 Pro (M = 3.69) and Gemini 2.5 Pro (M = 3.40),\nthe top-performing models in this study, exhibited\nthe highest levels of certainty. Conversely, GPT-\n5 with high reasoning effort was the least certain\nmodel (M = 2.57). The most striking difference\nbetween groups was that the models never utilized\nthe lowest certainty score (1 – „guessing”) whereas\nhuman practitioners used it in 19% of diagnostic\nratings and 11.1% of severity ratings.\n3.2\nDiagnostic Justifications\n3.2.1\nSemantic Embeddings\nFigure 3: MDS and UMAP projections of the semantic\nembeddings of diagnosis justifications.\nThe MDS and UMAP projections of the semantic\nembeddings of diagnosis justifications are visual-\nized in Figure 3. Overall, for this analysis, MDS\nproved to be a more informative dimensionality-\nreduction method than UMAP, contributing to most\nof the observations summarized as follows.\nModels from a single family (but not necessar-\nily the same series) are generally close seman-\ntically. This is a general trend observable among\nall the evaluated model families: DeepSeek, GPT,\nGemini, and Qwen, with their points creating visi-\nble neighborhoods distance-wise. Additionally, on\nthe example of DeepSeek v3.1 Terminus, Qwen\n3 32B, and GPT-5 clusters, we observe that the\nimpact of chain-of-thought reasoning—either its\n6\n"}, {"page": 7, "text": "binary presence in the case of the first two, or its\ngradation in the case of the last one—on model\nsemantics is rather low.\nGPT-4.1 correlates semantically with the\nGPT-5 cluster, but not with GPT-4o. GPT-4.1,\nbeing from the same model family but not the same\nseries, is located close to the GPT-5 model variants\non each projection, echoing the previous observa-\ntion. Yet, this did not apply to GPT-4o, which\nemerged as a singular exception to the trend of se-\nmantic closeness within a model family by being\nlocated far from both the GPT and the main point\nclusters.\nLlama 3.3 70B exhibits atypical semantics\ncompared to every other agent. The distinctive-\nness of Llama’s semantics does not stem from un-\ndertaking vastly different diagnostic pathways than\nthe rest of the agents, but from its comparably poor\ncommand of the Polish language. Llama’s explana-\ntions tended to contain incorrect grammar, nonexis-\ntent words, or seemingly random „artifact” tokens\nunrelated grammatically and semantically to the\nrest of the justifications’ linguistic content. Inter-\nestingly, this did not seem to have significantly\nimpeded Llama’s diagnosis capabilities, as it was\nthe ex-aequo third-best performing model (see Fig-\nure 1).\nModels performing weakly in terms of diag-\nnostic performance also exhibit more atypical\nsemantics. Both Qwen variants, Gemma 3 27B,\nand GPT-4o not only achieved the lowest cumula-\ntive diagnostic performance scores (see Figure 1),\nbut also are all semantically located relatively far\naway from the main model cluster, while at the\nsame time being located close to each other.\nHuman participant semantics strongly differ\nfrom model semantics. A large observable dif-\nference between the general semantic tendencies\nof human participants compared to models can be\nattributed to differing justification strategies. Hu-\nman participants provided concise and direct ex-\nplanations, rarely approaching the 100-word limit.\nOne psychotherapist and one psychiatrist copied\nexcerpts from patient testimonies rather than gener-\nating original justifications, while two other psychi-\natrists produced unusually brief responses: one did\nnot justify healthy-control diagnoses, whereas the\nother declined to justify low-confidence decisions.\nSeveral participants explicitly cut their justifica-\ntions short, noting insufficient information for a\nreliable diagnosis. In contrast, all models consis-\ntently produced long, detailed, and highly confident\njustifications, never withholding a diagnosis based\non inconclusive data.\n3.2.2\nLexical features\nWe analyzed the 20 most characteristic features\nidentified for human and model outputs by z-score\nvalues (for the full list, see Appendix E). The origi-\nnal Polish unigrams were supplemented with their\nclosest English translations and are referred to as\nsuch in this section for clarity.\nA higher prevalence of nouns characterized the\nhuman-characteristic lexical features group. Specif-\nically, several features point to a human-centric\napproach to the diagnoses and their subsequent jus-\ntifications, emphasizing a person’s sense of self\nand their interactions with society: patient, one’s\nown, interpersonal, others, image. Additionally,\na more temporal focus is noticeable through the\nterms: time, sense of (time), future. Finally, the\nobservable reluctance to give a definite diagnosis\nbased just on textual data was reflected by mentions\nof its scarcity by some human participants: lack of,\ndata.\nIn comparison, the model-characteristic lexical\nfeatures group had a high prevalence of adjec-\ntives. This seems to be brought on by a more spe-\ncific strong tendency of the models to categorize\nand formalize the patients’ subjective experiences\nand symptoms: persistent, severe, severity, moder-\nate, chronic, intense, rigid, entrenched. The mod-\nels also exhibit three pronounced single-feature\npropensities; heavy focus on seeing patterns in pa-\ntients’ testimonies: patterns, comparatively high\nfocus on violent life experiences: violence, and a\npredisposition (contrasting with humans) to create\nown interpretations of the particulars of the pa-\ntients’ conditions when faced with unsatisfyingly\ndetailed or unclear data: (I) understand (as).\n4\nDiscussion\nBeyond diagnostic accuracy, this study has several\nimplications for the use of AI technology in clinical\nmental health contexts.\nRegarding the conceptualization of mental disor-\nders, our results highlight a tension between evolv-\ning psychiatric frameworks and the persistence of\ntraditional diagnostic classifications. While human\nexperts performed better on the categorical than\nthe dimensional task, models achieved relatively\nbalanced scores across both, with a performance\npreference for categorical diagnosis. This suggests\n7\n"}, {"page": 8, "text": "that the current shift toward a dimensional under-\nstanding of personality pathology (American Psy-\nchiatric Association, 2022; World Health Organi-\nzation, 2022) may be overshadowed by the legacy\nof earlier categorical systems, whose labels remain\nprevalent in everyday discourse and online corpora.\nThe prominence of such labels in training cor-\npora may also explain the severe underdiagnosing\nof NPD by models. This could stem from the neg-\native semantic load and social stigma associated\nwith the term „narcissist”, combined with the cur-\nrent LLM preference alignment training regimen\n(i.e., RLHF techniques) rewarding agreeable and\nnon-confrontational behavior, sometimes border-\ning on (social) sycophancy (Cheng et al., 2025;\nSharma et al., 2025). Assigning a stigmatized label\nto a first-person narrator—essentially „calling the\nuser a narcissist”—conflicts with these preferences.\nImportantly, this avoidance does not reflect inabil-\nity, as models showed higher dimensional recall\nfor NPD cases, indicating sensitivity to severity\nwithout using value-laden labels. A similar aver-\nsion to stigmatizing terminology may explain the\ndepathologizing bias observed in the GPT models\nfamily, where avoidance of psychiatric labels can\ndownplay genuine symptoms and delay necessary\ntreatment (Semigran et al., 2015). Conversely, BPD\nis increasingly treated in the literature as a clini-\ncal condition rather than a pejorative label. The\ncomparatively extensive body of BPD research rel-\native to other disorders (Blashfield and Intoccia,\n2000) likely contributes to the models’ inclination\nto overdiagnose it.\nNotably, a critical divergence between humans\nand LLMs was observed in the assessment of con-\nfidence. Models never utilized the „guessing” or\nlow-confidence options, whereas human experts\nfrequently expressed uncertainty. This might pose\na potential safety risk for clinical application. As ar-\ngued by Ulmer et al. (Ulmer et al., 2025), the ability\nof an AI to express doubt in a „human-like” man-\nner is a necessary safety feature to ensure users can\ntrust the uncertainty being conveyed. Paradoxically,\nalthough both humans and models demonstrated\nhigher objective performance on the categorical\ntask, they consistently reported higher subjective\ncertainty regarding their dimensional ratings. Fu-\nture studies could investigate the underlying mech-\nanisms of this metacognitive dissociation, examin-\ning why both human and non-human agents per-\nceive their answers regarding dimensional severity\nas more certain, despite their objective performance\nsuperiority in categorical classification.\nFurthermore, the semantic analysis reveals that\nalthough models may achieve higher accuracy, their\n„reasoning” remains fundamentally distinct from\nclinical practice. Human justifications were con-\ncise, cautious, and patient-centered. Model justifi-\ncations, conversely, were elaborate, formulaic, and\npattern-focused. Additionally, models that showed\nreduced performance also had more atypical seman-\ntics. This suggests a link between diagnostic accu-\nracy and justification semantics; lower-performing\nmodels may have failed to attend to the most clini-\ncally informative aspects of the patient narratives.\nLlama 3.3 70B was a notable exception, achieving\nhigh diagnostic accuracy despite generating justi-\nfications riddled with linguistic artifacts, nonexis-\ntent words, and poor Polish grammar. This can be\nunderstood in terms of a multilingual generative-\ndiscriminative performance gap, in which Llama\n3.3 70B demonstrates sufficient passive understand-\ning of Polish to assign accurate diagnoses, while ex-\nhibiting markedly weaker Polish fluency when gen-\nerating justifications for those decisions. Follow-up\nresearch could investigate how the performance of\nthis model would change if its diagnostic reasoning\nwere generated before assigning diagnostic scores,\nrather than as a post-hoc justification.\n5\nConclusion\nIn this study, we provided a first-of-its-kind eval-\nuation of state-of-the-art LLMs on raw, first-\nperson patient data, assessed under a novel expert-\ninformed evaluation protocol and directly com-\npared with human specialists. Our findings indicate\nthat current LLMs possess a surprisingly high level\nof diagnostic competence, largely surpassing men-\ntal health professionals in the examined context. At\nthe same time, the models demonstrated suscepti-\nbility to bias and overconfidence. Taken together,\nthese findings underscore the need for a collabo-\nrative human–AI framework, in which the clinical\njudgment and ethical oversight of experts balance\nthe analytical consistency of models. Such inte-\ngration has the potential to mitigate the respective\nlimitations of each agent—model bias and human\nvariability—thereby achieving higher diagnostic\nvalidity than either could attain alone.\nLimitations\nThis study has several limitations. First, humans\nand LLMs were compared on the textual diagnostic\n8\n"}, {"page": 9, "text": "modality only, whereas actual psychiatric assess-\nment is inherently multimodal; clinicians rely on\nvisual cues, affect, prosody, and interactional dy-\nnamics that are absent in text transcripts. Accord-\ningly, the human experts in our experiment reported\ndifficulties in relying solely on text without seeing\nthe patient. However, given the rapid post-COVID\nrise of remote medicine, as well as the more recent\nsurge in AI-driven therapeutic chatbots, the textual\nmodality may gain prominence in the future. The\nsecond limitation is that the sample comprised only\nseven narratives. Although small, this sample size\nreflects a deliberate trade-off necessitated by the\ndepth of the data and the substantial cognitive and\ntime demands of human experts. The fact that this\nstudy was conducted within a specific cultural con-\ntext may also be considered a limitation. This is\nbecause the diagnostic approaches of human ex-\nperts and the narrative styles of patients may not be\ngeneralizable to other populations. Future research\nshould explore whether these findings remain con-\nsistent across different cultural settings.\nEthical considerations\nAll procedures performed in this study involving\nhuman participants were in accordance with the\nethical standards of the institutional and/or national\nresearch committee and with the 1964 Helsinki\nDeclaration and its later amendments or compara-\nble ethical standards. Human participants signed\nan informed consent form by hand. The qualitative\ninterview protocol was approved by the hospital\nand the Bioethics Committee of Poznan University\nof Medical Sciences (decision no. KB-367/23). All\npersonal information was anonymized, ensuring\nfull privacy of the patients’ identities.\nMental health diagnosis remains a fundamen-\ntally human responsibility requiring empathy, ethi-\ncal judgment, and contextual understanding beyond\nmere pattern recognition. Nevertheless, in recent\nyears, patients have already begun to independently\nuse AI-based consumer tools for self-assessment\noutside established clinical frameworks. We ac-\nknowledge the ethical and moral dilemmas asso-\nciated with the use of AI in clinical research and\npractice, and, as noted above, advocate that AI tech-\nnologies be deployed in clinical settings only under\nthe supervision of human experts.\nReferences\nAmerican Psychiatric Association. 1980. Diagnostic\nand statistical manual of mental disorders (3rd ed.).\nAmerican Psychiatric Association, Washington, D.C.\nAmerican Psychiatric Association. 2022. Diagnostic\nand statistical manual of mental disorders (5th ed.,\ntext rev.). American Psychiatric Association, Wash-\nington, D.C.\nAnthropic.\n2025.\nSystem\nCard:\nClaude\nOpus\n4\n&\nClaude\nSonnet\n4.\nhttps://www-cdn.anthropic.com/\n4263b940cabb546aa0e3283f35b686f4f3b2ff47.\npdf. Accessed: 2025-12-18.\nJohn W. Ayers, Adam Poliak, Mark Dredze, Eric C.\nLeas, Zechariah Zhu, Jessica B. Kelley, Dennis J.\nFaix, Aaron M. Goodman, Christopher A. Longhurst,\nMichael Hogarth, and Davey M. Smith. 2023. Com-\nparing Physician and Artificial Intelligence Chatbot\nResponses to Patient Questions Posted to a Pub-\nlic Social Media Forum. JAMA Internal Medicine,\n183(6):589–596.\nCorrado Barbui, Jordi Alonso, Dan Chisholm, Sara\nEvans-Lacko, Roxanne C. Keynejad, Ledia Lazeri,\nNuman Miah, Zivile Valuckiene, and Chiara Gastal-\ndon. 2025. Mental health service coverage and gaps\namong adults in Europe: a systematic review. The\nLancet Regional Health–Europe, 57.\nMassimo Biondi, Angelo Picardi, Mauro Pallagrosi,\nand Laura Fonzi, editors. 2022. The Clinician in the\nPsychiatric Diagnostic Process, 1st edition. Springer\nCham, Switzerland.\nR. K. Blashfield and V. Intoccia. 2000. Growth of the\nliterature on the topic of personality disorders. Amer-\nican Journal of Psychiatry, 157(3):472–473.\nJonathan P. Chang, Caleb Chiam, Liye Fu, An-\ndrew Wang, Justine Zhang, and Cristian Danescu-\nNiculescu-Mizil. 2020. ConvoKit: A Toolkit for the\nAnalysis of Conversations. In Proceedings of the\n21th Annual Meeting of the Special Interest Group\non Discourse and Dialogue, pages 57–60, 1st virtual\nmeeting. Association for Computational Linguistics.\nMyra Cheng, Sunny Yu, Cinoo Lee, Pranav Khadpe, Lu-\njain Ibrahim, and Dan Jurafsky. 2025. ELEPHANT:\nMeasuring and understanding social sycophancy in\nLLMs. Preprint, arXiv:2505.13995.\nJan Cieciuch, Patryk Łakuta, Włodzimierz Strus,\nJoshua R. Oltmanns, and Thomas Widiger. 2022. As-\nsessment of personality disorder in the ICD-11 diag-\nnostic system: Polish validation of the Personality In-\nventory for ICD-11. Psychiatria Polska, 56(6):1185–\n1202.\nDeepSeek-AI. 2025a. DeepSeek-R1: Incentivizing Rea-\nsoning Capability in LLMs via Reinforcement Learn-\ning. Preprint, arXiv:2501.12948.\n9\n"}, {"page": 10, "text": "DeepSeek-AI. 2025b. DeepSeek-V3 Technical Report.\nPreprint, arXiv:2412.19437.\nKenneth Enevoldsen, Isaac Chung, Imene Kerboua,\nMárton Kardos,\nAshwin Mathur,\nDavid Stap,\nJay Gala, Wissam Siblini, Dominik Krzemi´nski,\nGenta Indra Winata, Saba Sturua, Saiteja Utpala,\nMathieu Ciancone, Marion Schaeffer, Gabriel Se-\nqueira, Diganta Misra, Shreeya Dhakal, Jonathan\nRystrøm, Roman Solomatin, and 67 others. 2025.\nMMTEB: Massive Multilingual Text Embedding\nBenchmark. Preprint, arXiv:2502.13595.\nAya E. Fouda, Abdelrahamn A. Hassan, Radwa J.\nHanafy, and Mohammed E. Fouda. 2025. Psychi-\natryBench: A Multi-Task Benchmark for LLMs in\nPsychiatry. Preprint, arXiv:2509.09711.\nGemini Team. 2025. Gemini 2.5: Pushing the Fron-\ntier with Advanced Reasoning, Multimodality, Long\nContext, and Next Generation Agentic Capabilities.\nPreprint, arXiv:2507.06261.\nGemma Team. 2025.\nGemma 3 Technical Report.\nPreprint, arXiv:2503.19786.\nGoogle. 2025.\nGemini 3 Pro Model Card.\nhttps:\n//storage.googleapis.com/deepmind-media/\nModel-Cards/Gemini-3-Pro-Model-Card.pdf.\nAccessed: 2025-12-18.\nŁukasz\nGrzybowski,\nJakub\nPokrywka,\nMichał\nCiesiółka, Jeremi Ignacy Kaczmarek, and Marek\nKubis. 2025.\nPolish-English medical knowledge\ntransfer: A new benchmark and results. In Findings\nof the Association for Computational Linguistics:\nEMNLP 2025, pages 9042–9063, Suzhou, China.\nAssociation for Computational Linguistics.\nAbdelrahman Hanafi, Mohammed Saad, Noureldin\nZahran, Radwa J. Hanafy, and Mohammed E. Fouda.\n2025.\nA Comprehensive Evaluation of Large\nLanguage Models on Mental Illnesses.\nPreprint,\narXiv:2409.15687.\nStefan Harrer. 2023. Attention is not all you need: the\ncomplicated case of ethically using large language\nmodels in healthcare and medicine. eBioMedicine,\n90.\nYining Hua, Hongbin Na, Zehan Li, Fenglin Liu, Xiao\nFang, David Clifton, and John Torous. 2025. A scop-\ning review of large language models for generative\ntasks in mental health care. npj Digital Medicine,\n8(1):230.\nJoseph B. Kruskal. 1964. Multidimensional scaling by\noptimizing goodness of fit to a nonmetric hypothesis.\nPsychometrika, 29(1):1–27.\nH.R. Lawrence, R.A. Schneider, S.B. Rubin, M.J.\nMatari´c, D.J. McDuff, and M. Jones Bell. 2024. The\nopportunities and risks of large language models in\nmental health. JMIR Mental Health, 11.\nLlama Team. 2024.\nThe Llama 3 Herd of Models.\nPreprint, arXiv:2407.21783.\nDan P. McAdams. 1988. Power, Intimacy, and the Life\nStory: Personological Inquiries Into Identity. Guil-\nford Press.\nRyan K. McBain, Robert Bozick, Melissa Dilib-\nerti, Li Ang Zhang, Fang Zhang, Alyssa Burnett,\nAaron Kofner, Benjamin Rader, Joshua Breslau,\nand Bradley D. Stein. 2025.\nUse of Generative\nAI for Mental Health Advice Among US Adoles-\ncents and Young Adults.\nJAMA Network Open,\n8(11):e2542281.\nLeland McInnes, John Healy, and James Melville.\n2020. UMAP: Uniform Manifold Approximation\nand Projection for Dimension Reduction. Preprint,\narXiv:1802.03426.\nBurt L. Monroe, Michael P. Colaresi, and Kevin M.\nQuinn. 2008. Fightin’ Words: Lexical Feature Se-\nlection and Evaluation for Identifying the Content of\nPolitical Conflict. Political Analysis, 16(4):372–403.\nViet Cuong Nguyen, Mohammad Taher, Dongwan\nHong, Vinicius Konkolics Possobom, Vibha Thirunel-\nlayi Gopalakrishnan, Ekta Raj, Zihang Li, Heather J.\nSoled, Michael L. Birnbaum, Srijan Kumar, and Mun-\nmun De Choudhury. 2025. Do Large Language Mod-\nels Align with Core Mental Health Counseling Com-\npetencies? In Findings of the Association for Compu-\ntational Linguistics: NAACL 2025, pages 7488–7511,\nAlbuquerque, New Mexico. Association for Compu-\ntational Linguistics.\nRyunosuke Noda, Kenichiro Tanabe, Daisuke Ichikawa,\nand Yugo Shibagaki. 2025. GPT-4’s performance\nin supporting physician decision-making in nephrol-\nogy multiple-choice questions. Scientific Reports,\n15(1):15439.\nOpenAI. 2024.\nGPT-4o System Card.\nPreprint,\narXiv:2410.21276.\nOpenAI. 2025a. GPT-5 System Card. https://cdn.\nopenai.com/gpt-5-system-card.pdf. Accessed:\n2025-12-18.\nOpenAI. 2025b.\nIntroducing GPT-4.1 in the\nAPI. https://openai.com/index/gpt-4-1/. Ac-\ncessed: 2025-12-18.\nFabian Pedregosa, Gaël Varoquaux, Alexandre Gram-\nfort, Vincent Michel, Bertrand Thirion, Olivier Grisel,\nMathieu Blondel, Peter Prettenhofer, Ron Weiss, Vin-\ncent Dubourg, Jake Vanderplas, Alexandre Passos,\nDavid Cournapeau, Matthieu Brucher, Matthieu Per-\nrot, and Édouard Duchesnay. 2011. Scikit-learn: Ma-\nchine Learning in Python. Journal of Machine Learn-\ning Research, 12(85):2825–2830.\nAaron L. Pincus, Nicole M. Cain, and Amy L. Halber-\nstadt. 2020. Importance of self and other in defin-\ning personality pathology. Psychopathology, 53(3–\n4):133–140.\nQwen Team. 2025. Qwen3 Technical Report. Preprint,\narXiv:2505.09388.\n10\n"}, {"page": 11, "text": "H. L. Semigran, J. A. Linder, C. Gidengil, and A. Mehro-\ntra. 2015. Evaluation of symptom checkers for self\ndiagnosis and triage: audit study. BMJ, 351.\nMrinank Sharma, Meg Tong, Tomasz Korbak, David\nDuvenaud,\nAmanda Askell,\nSamuel R. Bow-\nman, Newton Cheng, Esin Durmus, Zac Hatfield-\nDodds, Scott R. Johnston, Shauna Kravec, Timo-\nthy Maxwell, Sam McCandlish, Kamal Ndousse,\nOliver Rausch, Nicholas Schiefer, Da Yan, Miranda\nZhang, and Ethan Perez. 2025.\nTowards Under-\nstanding Sycophancy in Language Models. Preprint,\narXiv:2310.13548.\nJiayu Shi, Zexiao Wang, Jiandong Zhou, Chengyu Liu,\nPoly Z. H. Sun, Erying Zhao, and Lei Lu. 2025. Men-\ntalQLM: A Lightweight Large Language Model for\nMental Healthcare Based on Instruction Tuning and\nDual LoRA Modules. IEEE Journal of Biomedical\nand Health Informatics, Early Access:1–12.\nAnna Sterna, Thomas Fuchs, and Marcin Moskalewicz.\n2025. The Sense of Self and Interpersonal Func-\ntioning in Borderline Personality Disorder: Toward\nQualitative Evidence-Based Phenomenological Con-\nceptualization. Qualitative Health Research, page\n10497323251376224.\nChing-Fang Sun, Christoph U. Correll, Robert L. Trest-\nman, Yezhe Lin, Hui Xie, Maria Stack Hankey, Ray-\nmond Paglinawan Uymatiao, Riya T. Patel, Vemmy L.\nMetsutnan, and Erin Corinne McDaid. 2023. Low\navailability, long wait times, and high geographic\ndisparity of psychiatric outpatient care in the US.\nGeneral Hospital Psychiatry, 84:12–17.\nDennis Ulmer, Alexandra Lorson, Ivan Titov, and Chris-\ntian Hardmeier. 2025. Anthropomimetic Uncertainty:\nWhat Verbalized Uncertainty in Language Models is\nMissing. Preprint, arXiv:2507.10587.\nLaura C. Weekers, Martin Sellbom, Joost Hutsebaut,\nSebastian Simonsen, and Bo Bach. 2023. Normative\ndata for the LPFS-BF 2.0 derived from the Danish\ngeneral population and relationship with psychoso-\ncial impairment.\nPersonality and Mental Health,\n17(2):157–164.\nThomas A. Widiger and Timothy J. Trull. 2007. Plate\ntectonics in the classification of personality disorder:\nshifting to a dimensional model. American Psycholo-\ngist, 62(2):71–83.\nJessica D. Workum, Bas W. S. Volkers, Davy van de\nSande, Sumesh Arora, Marco Goeijenbier, Diederik\nGommers, and Michel E. van Genderen. 2025. Com-\nparative evaluation and performance of large lan-\nguage models on expert level critical care questions:\na benchmark study. Critical Care, 29:72.\nWorld Health Organization. 2022.\nICD-11: Inter-\nnational classification of diseases (11th revision).\nWorld Health Organization.\nPatryk Łakuta, Jan Cieciuch, Włodzimierz Strus, and\nJoost Hutsebaut. 2023. Level of Personality Function-\ning Scale-Brief Form 2.0: Validity and reliability of\nthe Polish adaptation. Psychiatria Polska, 57(2):247–\n260.\n11\n"}, {"page": 12, "text": "A\nClinical Assessment Instruments\nLevels of personality functioning and maladaptive trait domains were assessed using the Level of Per-\nsonality Functioning—Brief Scale 2.0 (LPFS-BF 2.0) (Łakuta et al., 2023) and the Personality Inventory\nfor ICD-11 (Cieciuch et al., 2022), ensuring comparability across individuals. LPFS-BF 2.0 scores were\ninterpreted relative to established cut-offs (Weekers et al., 2023), yielding a dimensional classification\nfrom subclinical to extreme impairment (0–48), independent of the categorical BPD/NPD labels.\nB\nModel Prompts\nOriginal Polish prompt used in the study\nJeste´s do´swiadczonym specjalist ˛a zdrowia psychicznego. Twoim zadaniem jest przeprowadzenie\nwst˛epnej oceny diagnostycznej na podstawie przedstawionego poni˙zej tekstu autobiograficznego.\nWykonaj 6-etapow ˛a analiz˛e, prezentuj ˛ac swoje wnioski w ´sci´sle okre´slonym formacie.\n# OCENA DIAGNOSTYCZNA\n## Krok 1\nPrzypisz diagnoz˛e kategorialn ˛a zaburzenia osobowo´sci. Pami˛etaj, ˙ze mo˙zliwa jest opcja „Brak\nzaburzenia”.\n## Krok 2\nOce´n stopie´n pewno´sci co do poprawno´sci swojej odpowiedzi z Kroku 1, u˙zywaj ˛ac skali 1–4,\ngdzie: 1 = zgadywałem/am, 2 = troch˛e pewny/a, 3 = do´s´c pewny/a, 4 = całkowicie pewny/a.\n## Krok 3\nUzasadnij swoj ˛a decyzj˛e diagnostyczn ˛a z Kroku 1. Wska˙z kluczowe fragmenty danych, które\npopieraj ˛a twoj ˛a ocen˛e. Nast˛epnie, odnie´s si˛e do tego czym s ˛a dla ciebie zaburzenia osobowo´sci i\nwyja´snij, jak rozumiesz ich ´zródła. Limit uzasadnienia to 100 słów.\n## Krok 4\nOce´n stopie´n nasilenia zaburzenia osobowo´sci, u˙zywaj ˛ac skali 0–3, gdzie: 0 = brak, 1 = łagodne, 2\n= umiarkowane, 3 = ci˛e˙zkie.\n## Krok 5\nOce´n stopie´n pewno´sci co do poprawno´sci oceny nasilenia z Kroku 4, u˙zywaj ˛ac skali 1–4, gdzie: 1\n= zgadywałem/am, 2 = troch˛e pewny/a, 3 = do´s´c pewny/a, 4 = całkowicie pewny/a.\n## Krok 6\nUzasadnij swoj ˛a odpowied´z z Kroku 4. Wska˙z kluczowe fragmenty danych, które popieraj ˛a Twoj ˛a\nocen˛e. Nast˛epnie, odnie´s si˛e do tego czym s ˛a dla ciebie zaburzenia osobowo´sci i wyja´snij, jak\nrozumiesz ich ´zródła. Limit uzasadnienia to 100 słów.\nUdziel odpowiedzi, u˙zywaj ˛ac poni˙zszego szablonu.\nAnaliza Przypadku [Numer przypadku]\nDiagnoza Kategorialna: [Twoja odpowied´z]\n12\n"}, {"page": 13, "text": "Pewno´s´c Diagnozy (1–4): [Twoja odpowied´z]\nUzasadnienie Diagnozy (do 100 słów): [Twoja odpowied´z]\nOcena Nasilenia (0–3): [Twoja odpowied´z]\nPewno´s´c Oceny Nasilenia (1–4): [Twoja odpowied´z]\nUzasadnienie Oceny Nasilenia (do 100 słów): [Twoja odpowied´z]\nTeraz zapoznaj si˛e z tekstem, przeprowad´z analiz˛e i odpowiedz zgodnie z podanym formatem.\n## TEKST AUTOBIOGRAFICZNY\n{text}\n## ODPOWIED´Z\nEnglish translation of the original prompt\nYou are an experienced mental health professional. Your task is to conduct a preliminary diagnostic\nassessment based on the autobiographical text presented below. Perform a 6-step analysis,\npresenting your conclusions in a strictly defined format.\n# DIAGNOSTIC ASSESSMENT\n## Step 1\nAssign a categorical personality disorder diagnosis.\nRemember that the option „No dis-\norder” is possible.\n## Step 2\nRate the degree of certainty regarding the correctness of your answer from Step 1, using\na scale of 1–4, where: 1 = I was guessing, 2 = somewhat certain, 3 = fairly certain, 4 = completely\ncertain.\n## Step 3\nJustify your diagnostic decision from Step 1.\nIndicate key data fragments that support\nyour assessment. Then, refer to what personality disorders are to you and explain how you\nunderstand their origins. The justification limit is 100 words.\n## Step 4\nRate the severity of the personality disorder, using a scale of 0–3, where: 0 = none, 1 =\nmild, 2 = moderate, 3 = severe.\n## Step 5\nRate the degree of certainty regarding the correctness of the severity assessment from\nStep 4, using a scale of 1–4, where: 1 = I was guessing, 2 = somewhat certain, 3 = fairly certain, 4\n= completely certain.\n## Step 6\n13\n"}, {"page": 14, "text": "Justify your answer from Step 4.\nIndicate key data fragments that support your assess-\nment. Then, refer to what personality disorders are to you and explain how you understand their\norigins. The justification limit is 100 words.\nProvide your answer using the template below.\nCase Analysis [Case Number]\nCategorical Diagnosis: [Your answer]\nDiagnosis Certainty (1–4): [Your answer]\nDiagnosis Justification (up to 100 words): [Your answer]\nSeverity Assessment (0–3): [Your answer]\nSeverity Assessment Certainty (1–4): [Your answer]\nSeverity Assessment Justification (up to 100 words): [Your answer]\nNow familiarize yourself with the text, perform the analysis, and answer according to the provided\nformat.\n## AUTOBIOGRAPHICAL TEXT\n{text}\n## ANSWER\nC\nDiagnostic Labels\nLabel\nCount\nPercentage\nBPD\n204\n53.97%\nHC (Healthy)\n81\n21.43%\nAvPD\n57\n15.08%\nNPD\n10\n2.65%\nUnspecified PD\n6\n1.59%\nDPD\n5\n1.32%\nAD/UNS\n4\n1.06%\nCannot diagnose\n3\n0.79%\nDePD\n2\n0.53%\nASPD\n2\n0.53%\nStPD\n1\n0.26%\nOPD\n1\n0.26%\nMPD\n1\n0.26%\nHPD\n1\n0.26%\nTable C.1: Distribution of diagnostic labels.\nThe diagnostic labels presented in Table C.1 correspond to the following clinical categories: BPD:\nBorderline Personality Disorder; NPD: Narcissistic Personality Disorder; AvPD: Avoidant Personality\nDisorder; HC: Healthy; StPD: Schizotypal Personality Disorder; DPD: Dependent Personality Disorder;\nDePD: Depressive Personality Disorder; AD/UNS: Anxiety Disorder/Unspecified; ASPD: Antisocial\nPersonality Disorder; OPD: Obsessive Personality Disorder; MPD: Masochistic Personality Disorder;\nHPD: Histrionic Personality Disorder.\n14\n"}, {"page": 15, "text": "D\nDiagnostic Performance Heatmap\nFigure D.1: Diagnostic performance heatmap of human experts and models.\nThe „Human Experts” row aggregates the performance of N = 5 professionals; one provided only\ndimensional ratings, thus their data was excluded from categorical analysis but retained for dimensional\nevaluation. A False Positive indicates diagnosing a disorder absent in the ground truth, while a False\nNegative denotes failing to identify a present condition. Each model row reflects N = 21 trials (7 cases x\n3 runs), whereas the human row corresponds to N = 35 independent assessments (7 cases x 5 experts).\n15\n"}, {"page": 16, "text": "E\nMost Representative Lexical Features\nFigure E.2: The 20 most representative lexical features for human experts and models by z-score.\n16\n"}, {"page": 17, "text": "F\nDimensionality Reduction Hyperparameters\nAlgorithm\nParameter\nValue\nMDS\ndissimilarity\nprecomputed\nn_components\n2\nrandom_state\n42\nUMAP\nn_components\n2\nn_neighbors\n4\nmin_dist\n0.1\nrandom_state\n42\nTable F.2: Dimensionality reduction algorithms hyperparameter values.\nHyperparameters not present in the table retained the default values set in the algorithm implementations.\nThe n_neighbors parameter for UMAP, which controls the balance between local and global structure,\nwas set to a low value to accommodate the small dataset size of N = 17/16 (with and without the human\nembedding). This setting prioritizes the detection of latent local substructures and family-specific clusters\nwithin the models.\nG\nSemantic Justification Embedding Creation Process\nThe process of mapping the diagnosis justifications acquired through our procedure onto a high-\ndimensional semantic embedding space consisted of four steps.\n1. The texts of all justifications were aggregated into groupings. For humans, due to the small amount\nof data relative to model outputs, a single grouping was created from all justifications for a single\nhuman participant. For each model, we created two separate groupings: one based on all categorical\njustifications and the other based on all dimensional justifications.\n2. Before the embedding process, simple text pre-processing with regular expressions was applied\nto remove LLM-characteristic text formatting artifacts, such as Markdown syntax and redundant\nwhitespace.\n3. Each\ngrouping\nwas\nconverted\ninto\na\ndense\nembedding\nusing\nthe\nchosen\nBAAI/bge-multilingual-gemma2 embedding model.\nThe model operated in 16-bit preci-\nsion on a single NVIDIA A100 (40GB) GPU, with a batch size of 8 and default remaining\nhyperparameter values.\n4. A summary embedding representing the semantic contents of justifications was created for each\nmodel by first calculating the mean value for the categorical and dimensional grouping embeddings\nseparately, and subsequently averaging these two values. For human participants, since there was no\ncategorical-dimensional grouping separation, a single summary embedding was derived by averaging\nthe embeddings of all individuals.\n17\n"}]}