{"doc_id": "arxiv:2602.05692", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2602.05692.pdf", "meta": {"doc_id": "arxiv:2602.05692", "source": "arxiv", "arxiv_id": "2602.05692", "title": "MedErrBench: A Fine-Grained Multilingual Benchmark for Medical Error Detection and Correction with Clinical Expert Annotations", "authors": ["Congbo Ma", "Yichun Zhang", "Yousef Al-Jazzazi", "Ahamed Foisal", "Laasya Sharma", "Yousra Sadqi", "Khaled Saleh", "Jihad Mallat", "Farah E. Shamout"], "published": "2026-02-05T14:18:20Z", "updated": "2026-02-05T14:18:20Z", "summary": "Inaccuracies in existing or generated clinical text may lead to serious adverse consequences, especially if it is a misdiagnosis or incorrect treatment suggestion. With Large Language Models (LLMs) increasingly being used across diverse healthcare applications, comprehensive evaluation through dedicated benchmarks is crucial. However, such datasets remain scarce, especially across diverse languages and contexts. In this paper, we introduce MedErrBench, the first multilingual benchmark for error detection, localization, and correction, developed under the guidance of experienced clinicians. Based on an expanded taxonomy of ten common error types, MedErrBench covers English, Arabic and Chinese, with natural clinical cases annotated and reviewed by domain experts. We assessed the performance of a range of general-purpose, language-specific, and medical-domain language models across all three tasks. Our results reveal notable performance gaps, particularly in non-English settings, highlighting the need for clinically grounded, language-aware systems. By making MedErrBench and our evaluation protocols publicly-available, we aim to advance multilingual clinical NLP to promote safer and more equitable AI-based healthcare globally. The dataset is available in the supplementary material. An anonymized version of the dataset is available at: https://github.com/congboma/MedErrBench.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2602.05692v1", "url_pdf": "https://arxiv.org/pdf/2602.05692.pdf", "meta_path": "data/raw/arxiv/meta/2602.05692.json", "sha256": "97295ae7fe66e99f87be04c57833e2e194daf03990c9fa0ef5870e1222e8a685", "status": "ok", "fetched_at": "2026-02-18T02:19:40.110109+00:00"}, "pages": [{"page": 1, "text": "MedErrBench: A Fine-Grained Multilingual Benchmark for Medical\nError Detection and Correction with Clinical Expert Annotations\nCongbo Ma1, Yichun Zhang2, Yousef Al-Jazzazi1, Ahamed Foisal1, Laasya Sharma3,\nYousra Sadqi4, Khaled Saleh4, Jihad Mallat4, Farah E. Shamout1\n1New York University Abu Dhabi, 2New York University,\n3University of Birmingham, 4Cleveland Clinic Abu Dhabi\nAbstract\nInaccuracies in existing or generated clinical\ntext may lead to serious adverse consequences,\nespecially if it is a misdiagnosis or incorrect\ntreatment suggestion. With Large Language\nModels (LLMs) increasingly being used across\ndiverse healthcare applications, comprehensive\nevaluation through dedicated benchmarks is\ncrucial. However, such datasets remain scarce,\nespecially across diverse languages and con-\ntexts.\nIn this paper, we introduce MedEr-\nrBench, the first multilingual benchmark for\nerror detection, localization, and correction, de-\nveloped under the guidance of experienced clin-\nicians. Based on an expanded taxonomy of\nten common error types, MedErrBench cov-\ners English, Arabic and Chinese, with natural\nclinical cases annotated and reviewed by do-\nmain experts. We assessed the performance of\na range of general-purpose, language-specific,\nand medical-domain language models across\nall three tasks.\nOur results reveal notable\nperformance gaps, particularly in non-English\nsettings, highlighting the need for clinically\ngrounded, language-aware systems. By mak-\ning MedErrBench and our evaluation proto-\ncols publicly-available, we aim to advance\nmultilingual clinical NLP to promote safer\nand more equitable AI-based healthcare glob-\nally. The dataset is available in the supplemen-\ntary material. An anonymized version of the\ndataset is available at: https://github.com/\ncongboma/MedErrBench.\n1\nIntroduction\nMedical error detection and correction are essen-\ntial for ensuring patient safety and healthcare qual-\nity (Anjum et al., 2024; Ahsani-Estahbanati et al.,\n2022). Some errors, such as misdiagnoses, can\nlead to severe adverse outcomes, such as morbidity\nand mortality, and high economic costs (Newman-\nToker et al., 2021; Soori, 2024). This need is es-\npecially critical in the era of generative AI and\nLarge Language Models (LLMs). Despite their\nFigure 1: Overview of MedErrBench.\nimportance, automated methods for detecting and\ncorrecting medical errors remain underexplored\ndue to three main challenges. First, there is a sig-\nnificant shortage of publicly available datasets for\nmedical error correction and detection. To date,\nMEDEC (Abacha et al., 2025) is one of the main\ndatasets specifically designed for this purpose, lim-\niting the development and evaluation of robust mod-\nels. Second, the diversity of error taxonomies is\noften insufficient, failing to reflect the complexity\nof real-world medical errors. The lack of standard-\nized expert-informed annotation protocols further\nresults in fragmented and incomplete error repre-\nsentations. Third, the existing datasets focus pri-\nmarily on English, limiting model development for\nmultilingual medical contexts. Given the global\nnature of healthcare, the lack of multilingual re-\n1\narXiv:2602.05692v1  [cs.CL]  5 Feb 2026\n"}, {"page": 2, "text": "sources hinders progress toward robust systems.\nTo address these limitations, we propose Med-\nErrBench, a multilingual benchmark dataset for\nclinical error detection and correction, grounded\nin expert-defined error categories and supported\nby high-quality annotated data. An overview is\nprovided in Figure 1. In collaboration with clin-\nicians, we distilled potential error types into ten\nrepresentative categories: Diagnosis, Management,\nTreatment, Pharmacotherapy, Causal Organism/-\nPathogen, Lab/Serum Value Interpretation, Physi-\nology, Histology, Anatomy, and Epidemiology (see\nTable 1 for definitions). These categories provide\ncomprehensive coverage of clinically relevant er-\nrors and serve as a practical guideline for data an-\nnotation and system evaluation.\nBased on this typology, we construct MedEr-\nrBench in English, Arabic, and Chinese. For En-\nglish and Chinese, we adapt samples from MedQA\n(Jin et al., 2021) by introducing expert-verified er-\nrors into clinical notes. Each instance is manually\nlabeled with the corresponding error type. Addi-\ntional erroneous examples were created by clini-\ncians for underrepresented error types. For Arabic,\nwe adapt samples from MedArabiQ (Daoud et al.,\n2025). Under the proposed typology, error types\nnot present in the original datasets were supple-\nmented with real-world clinical error cases con-\ntributed by practicing clinicians. Beyond error cate-\ngorization, we also label the difficulty level and rea-\nsoning type, enabling models to learn fine-grained,\nerror-focused reasoning not supported by existing\ndatasets. All data across the three languages are\nindependently reviewed by two clinicians, who cor-\nrected any issues introduced during the transforma-\ntion process and validated both content accuracy\nand annotation quality. This rigorous pipeline en-\nsures that MedErrBench is both clinically valid\nand well-suited for training and evaluating medical\nerror detection systems.\nThe new proposed MedErrBench dataset sup-\nports three key clinical NLP tasks: error detec-\ntion, localization, correction.\nTo explore these\ntasks, we evaluate three representative classes:\ngeneral-purpose LLMs, language-specific LLMs,\nand domain-specific medical LLMs, across English,\nArabic, and Chinese. Beyond overall performance\nbenchmarking, we conduct a series of in-depth\nanalyses: (1) investigation of the effects of pro-\nviding error-type definitions and exemplar cases;\n(2) analysis of example difficulty in few-shot learn-\ning settings; (3) performance differences between\nTable 1: Classification of medical error types, including\ndefinitions and representative examples.\nError Type\nDefinition\nExample Scenario\nDiagnosis\nFailure to correctly identify the un-\nderlying condition based on clinical\npresentation\nInterpreting myocardial infarction as GERD\ndespite ECG abnormalities and chest pain\nManagement\nInappropriate non-pharmacologic,\nnon-surgical clinical decision such\nas observation, monitoring, or dispo-\nsition\nAdvising “observation” in a patient with\nacute ST-elevation myocardial infarction\nTreatment\nInappropriate definitive intervention\n(surgical, procedural, or pharmaco-\nlogic); distinct from general manage-\nment\nRecommending testicular biopsy in sus-\npected torsion, delaying emergency surgery\nPharmacotherapy Incorrect drug selection, dosage,\nroute, timing, interaction, or dura-\ntion\nPrescribing\nheparin\nin\nheparin-induced\nthrombocytopenia (HIT)\nCausal Organ-\nism / Pathogen\nMisidentification of the causative mi-\ncroorganism in infectious disease\nAttributing syphilis to Pseudomonas instead\nof Treponema pallidum\nLab Value Inter-\npretation\nMisreading or misapplying diagnos-\ntic thresholds, reference ranges, or\nderived values\nInterpreting HbA1c of 5.2% as diagnostic for\ndiabetes\nPhysiology\nMisconception or misinterpretation\nof physiological principles (e.g.,\nECG, PFT, etc.)\nReading an irregular rhythm without P waves\nas sinus rhythm rather than atrial fibrillation\nHistology\nMisinterpretation of tissue morphol-\nogy, cellular structures, or micro-\nscopic patterns\nIdentifying psammoma bodies from papillary\nthyroid carcinoma as colon adenocarcinoma\nfeatures\nAnatomy\nErrors in anatomical structure, rela-\ntion, or spatial understanding\nDescribing the pancreas as an intraperitoneal\norgan\nEpidemiology\nMisuse of statistical tools or mis-\nstatement of incidence, prevalence,\nor risk factors\nClaiming colorectal cancer is more prevalent\nthan breast cancer among women globally\nknowledge-based and description-based clinical\nnotes, and (4) cross-lingual generalization. These\ncomprehensive experiments provide a detailed un-\nderstanding of current LLM capabilities and high-\nlight the need for clinically grounded, language-\naware models in high-stakes medical applications.\nOur main contributions are:\n• We establish a clinician-informed taxonomy\nof 10 clinical error types. This typology re-\nflects real-world challenges, and provides a\nfoundational schema for future dataset con-\nstruction and evaluation in clinical NLP.\n• We introduce MedErrBench, the first fine-\ngrained multilingual benchmark for medical\nerror detection and correction in English, Chi-\nnese, and Arabic. It supports three tasks: er-\nror detection, localization, correction, and is\nrigorously validated by clinicians to ensure\nmedical plausibility.\n• We systematically benchmark a range of\nLLMs across multiple languages and model\nfamilies, and conduct in-depth analyses to\nunderstand their capabilities and limitations\nin clinical error understanding. Our findings\nhighlight the challenges faced by current mod-\nels and motivate future research in building\nmore robust and clinically aware systems.\n2\n"}, {"page": 3, "text": "2\nRelated Work\n2.1\nGeneral Error Detection and Correction\nError detection and correction have been applied\nacross a range of domains, including grammatical\nerror correction (Peng et al., 2025; Ye et al., 2025;\nKaneko et al., 2022), code debugging and repair\n(Tsai et al., 2024; Tian et al., 2024), data clean-\ning (Reis et al., 2024), and fact verification (Setty,\n2024; Ni et al., 2024). To improve performance, es-\npecially under limited annotated data, researchers\nhave proposed techniques such as synthetic error\ngeneration (Stahlberg and Kumar, 2024) and aux-\niliary linguistic or contextual signals (Fei et al.,\n2023). More recently, LLMs have been applied to\nerror detection and correction (Kamoi et al., 2024a)\nthrough direct correction generation (Loem et al.,\n2023) and instruction tuning (Fan et al., 2023). Ad-\nditionally, some studies leverage LLM feedback\nloops to refine model outputs (Kamoi et al., 2024b;\nPan et al., 2024; Gou et al., 2024).\nAlthough\nLLMs occasionally exhibit over-correction and mis-\nalignment with user intent (Vasselli and Watanabe,\n2023), human evaluations often find their correc-\ntions more fluent and acceptable compared to task-\nspecific models (Zeng et al., 2024).\n2.2\nError Detection and Correction in\nHealthcare\nError detection and correction are critical in health-\ncare due to their impact on clinical decisions and\npatient safety. The MEDIQA-CORR 2024 Shared\nTask introduced MEDEC (Abacha et al., 2025), the\nfirst public dataset for evaluating errors in clin-\nical notes based on five main error types.\nEx-\nisting methods can be broadly categorized into\ntwo types: (1) prompting-based LLM strategies\nand (2) hybrid or traditional approaches. Prompt-\nbased systems employ few-shot in-context learning\nand chain-of-thought reasoning (Wu et al., 2024;\nGundabathula and Kolar, 2024), with some lever-\naging retrieval-augmented generation to incorpo-\nrate external knowledge (Rajwal et al., 2024; Cor-\nbeil, 2024). Strategies include structured prompt\ntemplates, error-type hints, and self-consistency\nsampling. Some systems adopt in-prompt ensem-\nbling by combining outputs from multiple expert\nprompts, weighted by trust scores (Valiev and Tu-\ntubalina, 2024), while others rely on manual error-\ntype categorization to guide the reasoning process.\nOthers train models to generate rationales before\nproposing corrections (Wu et al., 2024). Hybrid\nmethods combine traditional classifiers, such as\nsupport vector machines, with QA-based correction\nmodules (Saeed, 2024). These approaches empha-\nsize interpretability and efficiency by incorporating\ndomain-specific features like TF-IDF scores, clin-\nical terminology patterns, and handcrafted rules.\nNevertheless, current research predominantly de-\npends on MEDEC, which is monolingual and lacks\na broader coverage of other medical error types,\nconstraining the generalizability and clinical appli-\ncability of proposed methods.\n3\nMethodology\n3.1\nMultilingual Dataset Partitioning\nTo support robust and generalizable research in\nmedical error detection and correction, we con-\nstructed a trilingual dataset in English, Chinese,\nand Arabic, reflecting linguistic and regional diver-\nsity in medical education systems: English as the\nglobal scientific lingua franca, Chinese represent-\ning the world’s most spoken language, and Arabic\ncapturing the Middle East and North Africa region.\nWe note that the datasets are not translations and are\ncollected from multiple native-language sources,\nensuring multilingual fidelity. Multi-source design\nintroduces cross-site variability for more robust\nevaluation.\nThe English and Chinese subsets were initially\nsampled from MedQA (Jin et al., 2021), which\nincludes clinical cases sourced from medical li-\ncensing examination questions used in the US and\nChina. We applied filtering criteria to ensure con-\ntextual richness, removing short factoid-style ques-\ntions (typically 1–2 sentences) and retaining longer,\nmulti-sentence clinical notes that provide realistic\nand meaningful diagnostic or therapeutic contexts.\nThe Arabic subset was sampled from MedArabiQ\n(Daoud et al., 2025) and MedAraBench (Mouath\net al., 2026). Each Arabic question was tagged\nwith a question style label: either scenario-based\nor knowledge-based. Scenario-based questions typ-\nically include a brief clinical case and require in-\nterpretation in context, whereas knowledge-based\nquestions assess general medical facts. We used\nkeyword heuristics (e.g., “patient\", “age\", “child\")\nto extract scenario-based questions, and then hand-\npicked more challenging knowledge-based ques-\ntions with sufficient word count and specialty cov-\nerage.\n3\n"}, {"page": 4, "text": "3.2\nBuilding the Taxonomy of Clinical Error\nTypes\nTo construct a clinically grounded error typology,\nwe collaborated with experienced clinicians to iden-\ntify and refine ten representative error categories,\nbuilding on MEDEC and adding five new error\ntypes: Lab/Serum Value Interpretation, Physiology,\nHistology, Anatomy, and Epidemiology, alongside\npreviously established ones including Diagnosis,\nManagement, Treatment, Pharmacotherapy, and\nCausal Organism/Pathogen. These categories are\ndesigned to comprehensively capture the range of\nfactual errors commonly encountered in clinical\npractice and serve as a practical framework for both\ndata annotation and system evaluation. For each\nerror type, we provide a clear definition along with\nan example scenario to illustrate its typical mani-\nfestations. Table 1 provides detailed descriptions,\nwhile in the appendix Figures S9–S11 illustrate the\nten error types in MedErrBench.\n3.3\nError Injection & Dataset Construction\nTo develop a clinically grounded dataset for med-\nical error detection, we introduced the errors into\nthe partitioned multilingual clinical cases.\nFor each question, we preserved the correct an-\nswer and randomly selected one plausible but in-\ncorrect alternative, while discarding the remaining\ndistractors. Using these selected answers, we con-\nstructed two versions of a clinical note: one in\nwhich the correct answer was naturally integrated\ninto the context, and another in which the incorrect\nanswer was inserted in its place.\nThe original datasets lacked certain error types.\nTo address this gap and ensure comprehensive\ncoverage, we collaborated with experienced clin-\nicians who contributed real-world clinical cases\nfor the missing categories. Specifically, the En-\nglish dataset originally lacked Physiology, Histol-\nogy, Anatomy, and Epidemiology examples, while\nthe Arabic dataset lacked Lab/Serum Value Inter-\npretation examples. To operationalize this con-\nstruction process, we employed LLMs to assist in\ntransforming the original samples into full-length\nclinical narratives in all three languages. Supple-\nmentary Figures S2–S4 provide the prompts for\nreproducibility, while Figures S6-S8 illustrate error\ninsertion examples from MedErrBench.\n3.4\nImportant Clinical Words,\nDifficulty-Level and Reasoning-Type\nAnnotation\nTo better analyze task complexity and enable more\nfine-grained evaluation of model capabilities, we\nadditionally manually annotate each instance with\nthree auxiliary attributes: important clinical words,\ndifficulty level, and reasoning type. Important clin-\nical words capture the most salient concept or de-\ncision point in each case (e.g., a diagnosis, thera-\npeutic action, or critical finding), highlighting the\nkey linguistic cues that both humans and models\nmust attend to during error detection. Each instance\nwas assigned one of three difficulty levels: Easy,\nMedium, or Hard. The annotation process followed\na set of predefined clinical reasoning guidelines that\nconsidered multiple factors, including the clarity\nof clinical cues, the rarity or complexity of the un-\nderlying condition, the number of reasoning steps\nrequired to reach a correct conclusion, and the over-\nall length and ambiguity of the question text. Ad-\nditionally, each item was annotated according to\nthe type of reasoning required to answer it, using\na three-level classification scheme: Factual Recall,\nSingle-hop Reasoning, and Multi-hop Reasoning.\nThese categories reflect increasing levels of infer-\nential complexity and are critical for evaluating the\ndiagnostic reasoning abilities of LLMs.\n3.5\nExpert Review and Quality Control\nWe employed a rigorous two-stage human review\nand quality control process.\nIn the first stage,\nthree native-speaking NLP researchers (English,\nChinese, and Arabic), after studying the clinician-\ndefined taxonomy of ten clinical error types, per-\nformed initial annotation and manual verification.\nThis process involved identifying hallucinated or\nunnatural content, removing incorrect or extrane-\nous information introduced by LLMs, and segment-\ning overly long sentences, particularly in the Chi-\nnese dataset, where punctuation such as commas\noften failed to separate clauses properly.\nIn the second stage, two independent clinicians\nreviewed all instances to ensure medical validity.\nThey corrected transformation errors, validated er-\nror labels, and verified key clinical terms, difficulty\nlevels, and reasoning types. Disagreements were\ncategorized as logical errors, misclassifications, or\ntypos; typos were corrected directly, while other\nissues were revised if flagged by either clinician.\nNo conflicting corrections were proposed.\n4\n"}, {"page": 5, "text": "4\nExperiment and Results\n4.1\nEvaluation Metrics\nWe evaluated model performance across three\nsub-tasks: error detection, error localization, sen-\ntence correction. We use accuracy, ROUGE (Lin,\n2004) (including ROUGE-1, ROUGE-2, ROUGE-\nL), BLEU (Papineni et al., 2002), BERTScore\n(Zhang et al., 2020), and BLEURT (Sellam et al.,\n2020) as the main evaluation metrics1.\n4.2\nBaseline Models\nWe evaluate a diverse set of recent language mod-\nels, grouped by their design objectives:\nGroup 1: General-purpose LLMs. This group in-\ncludes models developed for broad, cross-domain\nlanguage tasks. We evaluate GPT-4o (OpenAI,\n2024b), GPT-4o-mini (OpenAI, 2024a), Gemini\n2.5 Flash Lite (Google Research, 2025a), Gemini\n2.0 Flash (Google Research, 2025a), LLaMA3-8B\n(Meta AI, 2024) and Llama-3.3-70B-Instruct2.\nGroup 2: Language-specialized LLMs. These\nmodels are primarily optimized for specific lan-\nguages. Our selection includes Chinese models (\nQwen2.5-7B-Instruct (Alibaba DAMO Academy,\n2024),\nDeepSeek-R1 (DeepSeek AI, 2024a),\nDeepSeek-V3 (DeepSeek AI, 2024b), Doubao-\n1.5-Thinking-Pro (Doubao Team, Volcano Engine,\n2024) and Arabic model3 ALLAM-7B (Bari et al.,\n2025).\nGroup 3:\nMedical-domain LLMs.\nThis\ngroup comprises models specifically designed for\nclinical and biomedical applications.\nWe in-\nclude MedGemma-4B (Google Research, 2025a,b),\nMedGemma-27B (Google Research, 2025a,b), and\nHuatuoGPT-o1-7B (Chen et al., 2024).\n4.3\nOverview of Dataset\nFigure 2 shows the distribution of difficulty level\nfor all three languages. The English dataset is\nskewed toward higher-difficulty content, with 65%\nof questions labeled as Hard, reflecting a greater\nemphasis on abstraction and multi-step integration.\n1Due to page limitations, we report Accuracy, ROUGE-1,\nBERTScore, and BLEURT in the main paper, and present the\nremaining evaluation results in the appendix.\n2https://huggingface.co/meta-llama/Llama-3.3-70B-\nInstruct\n3We evaluated Falcon and Jais; however, both exhibited\nissues for error detection and correction task. For example,\nFalcon-Arabic consistently returned <text id> 0 -1 NA for\nall cases. Therefore, we do not report results for these two\nmodels.\nFigure 2: Distribution of difficulty level and reasoning\ntype.\nThe Chinese dataset shows a more balanced dis-\ntribution, with 52.7% of questions categorized as\nMedium, and roughly equal proportions of Easy\n(24.3%) and Hard (23%) items. In contrast, the Ara-\nbic dataset contains a higher proportion of Medium\nquestions (47.3%) and fewer Hard items (16%),\nsuggesting simpler question formats and a stronger\nemphasis on factual recall.\nFigure 2 also shows the distribution of reasoning\ntype for all three languages. The English dataset is\noverwhelmingly multi-hop in nature, with 91% of\nquestions requiring the integration of multiple clini-\ncal elements, consistent with case-based diagnostic\nreasoning. Chinese questions show a more moder-\nate distribution, with 68.5% classified as Multi-hop\nand 31.5% as Single-hop, indicating a balance be-\ntween direct inference and integrative tasks. Arabic\nquestions, by contrast, are predominantly based on\nFactual Recall (61.4%), with lower proportions\nof Single-hop (21%) and Multi-hop (17.6%) rea-\nsoning. This variation in reasoning types across\ndatasets aligns closely with the observed difficulty\ndistributions and reinforces the need for language-\nspecific modeling and evaluation strategies.\nIn the English dataset, 7.5% of the test set in-\nstances were found to be mislabeled. The most fre-\nquent issue involved confusion between the Man-\nagement and Treatment categories, accounting for\napproximately 60% of all labeling errors. Addi-\ntional misclassifications included examples such\nas Diagnosis incorrectly labeled as Management,\nas well as errors involving Pharmacotherapy, Epi-\ndemiology, and Lab/Serum Value Interpretation. In\nthe Chinese dataset, two clinicians independently\nreviewed the data and identified issues in 5% and\n6.5% of instances, respectively. The most common\n5\n"}, {"page": 6, "text": "concern was the expression of clinical measure-\nment units, which often did not align with standard\nclinical usage. In the Arabic subset, clinical re-\nview identified issues in approximately 12% of the\ndata. These included outdated clinical procedures,\ncorrections that were inapplicable or clinically in-\nappropriate, and other medical inaccuracies. Ad-\nditionally, clinicians flagged a further 5% of the\nentries for spelling mistakes. Eight error-type mis-\nclassifications were also identified, including three\nphysiology-related questions that had been incor-\nrectly categorized under other types. Detailed data\nsplits, basic statistics, and the distribution of error\ntypes are provided in Table S1 and Figure S1 in the\nappendix.\nTable 2: Results on MedErrBench-EN.\nModels\nDetection\nLocalization\nError Correction\nAccuracy\nAccuracy\nROUGE-1\nBertScore\nBLEURT\nGeneral-purpose LLMs\ngpt-4o\n0.596\n0.346\n0.415\n0.428\n0.407\ngpt-4o-mini\n0.664\n0.524\n0.487\n0.498\n0.472\nGemini 2.5 Flash Lite\n0.567\n0.264\n0.349\n0.362\n0.346\nGemini 2.0 Flash\n0.514\n0.168\n0.281\n0.294\n0.288\nLlama3-8b\n0.519\n0.361\n0.266\n0.261\n0.282\nLlama-3.3-70B-Instruct\n0.582\n0.255\n0.369\n0.369\n0.385\nLanguage-specialized LLMs\nQwen2.5-7B-Instruct\n0.563\n0.490\n0.372\n0.450\n0.371\nDeepseek-R1\n0.582\n0.577\n0.700\n0.716\n0.681\nDeepseek-V3\n0.587\n0.582\n0.703\n0.732\n0.693\nDoubao-1.5\n0.779\n0.774\n0.766\n0.783\n0.773\nALLAM-7B\n0.029\n0.014\n0.015\n0.020\n0.014\nMedical-domain LLMs\nMedGemma-4b\n0.505\n0.438\n0.511\n0.518\n0.513\nMedGemma-27b\n0.543\n0.245\n0.377\n0.390\n0.349\nHuatuoGPT-o1-7b\n0.574\n0.530\n0.486\n0.475\n0.475\nTable 3: Results on MedErrBench-CN.\nModels\nDetection\nLocalization\nError Correction\nAccuracy\nAccuracy\nROUGE-1\nBertScore\nBLEURT\nGeneral-purpose LLMs\ngpt-4o\n0.630\n0.205\n0.265\n0.365\n0.266\ngpt-4o-mini\n0.505\n0.115\n0.244\n0.390\n0.257\nGemini 2.5 Flash Lite\n0.600\n0.375\n0.448\n0.533\n0.455\nGemini 2.0 Flash\n0.705\n0.455\n0.569\n0.659\n0.577\nLlama3-8b\n0.500\n0.320\n0.416\n0.532\n0.483\nLlama-3.3-70B-Instruct\n0.675\n0.380\n0.506\n0.606\n0.509\nLanguage-specialized LLMs\nQwen2.5-7B-Instruct\n0.625\n0.570\n0.493\n0.576\n0.462\nDeepseek-R1\n0.735\n0.705\n0.802\n0.851\n0.781\nDeepseek-V3\n0.650\n0.640\n0.833\n0.873\n0.806\nDoubao-1.5\n0.750\n0.735\n0.788\n0.835\n0.777\nALLAM-7B\n0.395\n0.340\n0.284\n0.360\n0.286\nMedical-domain LLMs\nMedGemma-4b\n0.525\n0.500\n0.549\n0.581\n0.547\nMedGemma-27b\n0.605\n0.285\n0.441\n0.537\n0.438\nHuatuoGPT-o1-7b\n0.525\n0.275\n0.167\n0.545\n0.530\n4.4\nOverall Performance\nWe evaluated the models on three core tasks\nacross the English, Chinese, and Arabic datasets\n(Tables 2-4).\nDetailed results for all evalua-\ntion metrics are reported in Tables S2-S4 in\nthe appendix. Overall, Doubao-1.5-thinking-pro,\nDeepseek-R1, Deepseek-V3 perform better than\nother models across the languages. Despite being\ntrained on domain-specific data, medical LLMs like\nMedGemma and HuatuoGPT do not consistently\noutperform general-purpose models. MedGemma\nTable 4: Results on MedErrBench-Ara.\nModels\nDetection\nLocalization\nError Correction\nAccuracy\nAccuracy\nROUGE-1\nBertScore\nBLEURT\nGeneral-purpose LLMs\ngpt-4o\n0.680\n0.320\n0.399\n0.592\n0.414\ngpt-4o-mini\n0.577\n0.175\n0.260\n0.469\n0.292\nGemini 2.5 Flash Lite\n0.495\n0.268\n0.303\n0.432\n0.318\nGemini 2.0 Flash\n0.598\n0.299\n0.315\n0.503\n0.332\nLlama3-8b\n0.371\n0.309\n0.311\n0.324\n0.313\nLlama-3.3-70B-Instruct\n0.557\n0.381\n0.412\n0.454\n0.405\nLanguage-specialized LLMs\nQwen2.5-7B-Instruct\n0.536\n0.381\n0.329\n0.473\n0.353\nDeepseek-R1\n0.711\n0.505\n0.568\n0.756\n0.610\nDeepseek-V3\n0.608\n0.505\n0.677\n0.814\n0.699\nDoubao-1.5\n0.670\n0.505\n0.582\n0.736\n0.583\nALLAM-7B\n0.072\n0.021\n0.045\n0.049\n0.046\nMedical-domain LLMs\nMedGemma-4b\n0.454\n0.433\n0.438\n0.450\n0.439\nMedGemma-27b\n0.552\n0.240\n0.266\n0.456\n0.286\nHuatuoGPT-o1-7b\n0.371\n0.397\n0.302\n0.450\n0.420\nmodels are trained on medical text, medical QA,\nEHR, and medical images, while HuatuoGPT lever-\nages medical exam questions. These models fo-\ncus on domain knowledge and factual recall rather\nthan error detection and correction, which requires\nbroader linguistic reasoning and robustness to noisy\nclinical text. The Arabic LLM underperformed sig-\nnificantly perhaps since it lacks medical domain\nadaptation. We tested three different prompts for\nALLAM-7B, yielding an average detection accu-\nracy of only 0.083, suggesting that prompt sensitiv-\nity alone does not explain the failure.\nThe drop in accuracy from detection to local-\nization is expected, as detection is a binary task,\nwhereas localization is a more complex multi-class\ntask requiring precise error-span identification; lo-\ncalization failures typically arise when an error is\ndetected but its span is misidentified. Overall, lo-\ncalization and correction remain more challenging\nthan detection across all models and languages, as\nreflected by their consistently lower scores. We did\nnot observe any error type that consistently chal-\nlenged all models. However, Llama3-8B showed\nweaker performance on Management errors in Ara-\nbic, while ALLAM-7B and Qwen2.5-7B-Instruct\nstruggled primarily with Anatomy, Causal Organ-\nism/Pathogen, and Diagnosis errors. Llama3-8B\nexhibits signs of overcorrection in Arabic: frequent\nNA predictions, combined with the metric’s assign-\nment of a score of 1 when both predicted and true\nlabels are NA, artificially inflate performance by\nincreasing true negatives. Meanwhile, models like\nALLAM-7B fail on out-of-domain or cross-lingual\ntasks, highlighting the importance of robust multi-\nlingual evaluation. A clinician performed a human\nevaluation of 50 Chinese samples, yielding average\nscores of 0.52 for Gemini 2.0 Flash and 0.17 for\nGPT-4o-mini.\n6\n"}, {"page": 7, "text": "Figure 3: Performance comparison across easy, medium, and hard examples in few-shot learning.\nTable 5: Performance comparison of models under dif-\nferent error type Conditions. “ET\" and “DEF\" indicate\nerror types and definitions, respectively.\nDetection\nLocalization\nError Correction\nAccuracy\nAccuracy\nROUGE-1\nBertScore\nBLEURT\nDeepseek-V3 (Zero-shot)\nw/o ET & DEF\n0.690\n0.645\n0.660\n0.735\n0.599\nw/o DEF\n0.625\n0.610\n0.731\n0.795\n0.685\nw ET & DEF\n0.650\n0.640\n0.730\n0.794\n0.684\nDeepseek-V3 (Few-shot)\nw/o ET & DEF\n0.720\n0.690\n0.695\n0.767\n0.639\nw/o DEF\n0.710\n0.705\n0.736\n0.796\n0.684\nw ET & DEF\n0.715\n0.715\n0.763\n0.821\n0.705\nDoubao-1.5-thinking-pro (Zero-shot)\nw/o ET & DEF\n0.695\n0.640\n0.637\n0.727\n0.607\nw/o DEF\n0.730\n0.710\n0.673\n0.751\n0.646\nw ET & DEF\n0.750\n0.725\n0.669\n0.728\n0.636\nDoubao-1.5-thinking-pro (Few-shot)\nw/o ET & DEF\n0.735\n0.695\n0.707\n0.765\n0.651\nw/o DEF\n0.765\n0.750\n0.729\n0.777\n0.671\nw ET & DEF\n0.775\n0.765\n0.699\n0.753\n0.665\n4.5\nImpact of Providing Examples and Error\nType Definitions\nTable 5 presents the performance of models un-\nder varying configurations of Error Type (ET) and\nDefinition (DEF) availability. Detailed evaluation\nresults are provided in Table S5 in the appendix.\nOverall, we observe that providing error type defi-\nnitions consistently improves performance, partic-\nularly in the zero-shot setting. For example, in the\nDeepseek-V3 (Zero-shot) setup, adding definitions\n(w DEF or w ET & DEF) boosts error correction\nmetrics compared to the baseline (w/o ET & DEF).\nThis highlights that semantic clarity from defini-\ntions is beneficial even without structural labels\nlike error types.\nAdditionally, few-shot configurations consis-\ntently outperform their zero-shot counterparts\nacross all models and settings, indicating that in-\ncontext examples provide strong guidance for both\ndetection and correction tasks. Interestingly, while\nproviding both ET and DEF is generally helpful,\nthe isolated impact of error types alone (i.e., w/o\nDEF) can be inconsistent. In some few-shot set-\ntings (e.g., Doubao-1.5-thinking-pro), adding ETs\nwithout definitions slightly improves detection but\nmay reduce correction performance, suggesting po-\ntential cognitive overload or prompt misalignment.\nThe performance divergence between Deepseek-\nV3 and Doubao under different prompt settings\nmay stem from their architectural and training dif-\nferences. Deepseek-V3 appears more responsive\nto structured definitions and error-type annotations,\npossibly due to multilingual and multitask training,\nwhich enhances its generalization across abstract\nprompt forms. In contrast, Doubao demonstrates\nstronger alignment with example-driven prompts,\nbut exhibits sensitivity or degradation when addi-\ntional structured elements (e.g., both ET and DEF)\nare introduced, especially in few-shot scenarios.\nThis suggests that prompt design must consider\nmodel-specific alignment and interpretability char-\nacteristics, as misaligned guidance may counterin-\ntuitively hinder performance.\n4.6\nImpact of Providing Example Difficulty\nLevels in Few-shot Learning Settings\nFigure 3 illustrates the relationship between ex-\nample difficulty levels and model performance in\nfew-shot learning across three baseline models with\ngood and stable performance on Chinese dataset:\nDeepseek-V3 (circle), Doubao-1.5-thinking-pro\n(square), and Gemini 2.0 Flash (triangle).\nFor\nDoubao-1.5-thinking-pro, the performance trend\nacross difficulty levels follows a consistent pattern\nof Medium > Easy > Hard across nearly all met-\nrics. In contrast, Deepseek-V3 shows a different\nbehavior. For correction tasks, the model clearly\nfollows Easy > Medium > Hard. For localization,\nDeepseek-V3 performs similarly across all diffi-\nculty levels, with Hard examples even slightly out-\nperforming the others. Gemini 2.0 Flash, however,\ndisplays an opposite trend to Doubao-1.5-thinking-\n7\n"}, {"page": 8, "text": "Figure 4: Comparison of models based on knowledge-based and description-based evaluation.\npro and Deepseek-V3. For most metrics, the order\nis Hard > Medium > Easy, with overall lower per-\nformance. This may imply that the task is relatively\nmore difficult for Gemini 2.0 Flash, and that harder\nin-context examples are more informative and help-\nful for its learning. In terms of confidence scores,\nDoubao-1.5-thinking-pro exhibits the highest confi-\ndence across all difficulty levels, noticeably exceed-\ning both Deepseek-V3 and Gemini 2.0 Flash. This\nsuggests that Doubao-1.5-thinking-pro is more cer-\ntain in its predictions, although confidence does not\nalways correlate perfectly with correctness, espe-\ncially in challenging scenarios.\n4.7\nAnalysis of Knowledge vs. Scenario-based\nData\nFigure 4 shows the evaluation results of six LLMs\non an Arabic dataset, segmented by knowledge-\nbased and scenario-based clinical notes. The goal\nis to assess whether LLMs can capture language-\nindependent conceptions. Most models perform\nbetter on scenario-based tasks, suggesting a re-\nliance on contextual pattern recognition rather than\nrobust internal medical knowledge in Arabic. An\nexception is Llama3-8b, which slightly performs\nbetter on knowledge-based tasks. This may indi-\ncate that its learned representations are more tightly\ncoupled with language-independent factual knowl-\nedge, allowing it to resist some misconceptions\nwhen direct medical facts are queried. Qwen2.5-\n7B-Instruct exhibits the largest performance gap\nwhich suggests that the model is over-reliant on\nsurface-level patterns and instruction-following\nheuristics, making it more vulnerable to reproduc-\ning misconceptions in structured factual queries,\nespecially in low-resource languages like Arabic.\nWe also evaluate the cross-lingual generalization,\nplease refer to the appendix section J.1.\n5\nConclusion and Discussion\nIn this work, we present a novel multilingual bench-\nmark dataset for clinical error detection and correc-\ntion, grounded in expert-defined error categories\nand validated across English, Chinese, and Ara-\nbic. The work addresses key limitations in existing\nresources by providing diverse, high-quality an-\nnotations that reflect the complexity of real-world\nmedical errors in multiple languages. Through ex-\ntensive evaluation of various LLMs, we reveal the\ncurrent challenges in automated clinical error un-\nderstanding and emphasize the importance of clini-\ncally informed and language-specific approaches.\nOur dataset and analysis lay a solid foundation\nfor advancing research in clinical NLP focused\non improving patient safety. In addition to de-\ntection, localization, and correction, our dataset\nsupports tasks such as error classification, key con-\ncept extraction, difficulty assessment, and reason-\ning type classification, enabling new avenues for\nfine-grained clinical reasoning in NLP models. Our\ndataset in this component focuses on errors in pro-\nfessional medical knowledge. In future work, we\nplan to expand it with real clinical data to further\nenhance its coverage and completeness. Our future\nefforts will also focus on (1) increasing the overall\nscale and diversity of the corpus; (2) developing\nmulti-agent systems to improve LLM performance\non clinical tasks; (3) advancing evaluation method-\nologies for medical error detection and correction;\n(4) integrating severity stratification and assessing\nharm-reduction strategies.\n8\n"}, {"page": 9, "text": "Limitations\nWe note two limitations of the present study. First,\nthe proposed dataset does not include explicit anno-\ntations for severity levels or equity-related dimen-\nsions. Our primary objective is to establish a robust\nmultilingual foundation for medical error detection\nand correction, rather than to exhaustively charac-\nterize downstream clinical risk or fairness proper-\nties. In this sense, the dataset represents an initial\nstep toward such analyses, and is, to our knowl-\nedge, only the second publicly available resource\nafter MEDEC that addresses medical errors in a\nmultilingual setting. Future work can build upon\nthis foundation by incorporating severity stratifi-\ncation and equity-aware annotations. Second, the\nArabic portion of the dataset remains under ac-\ntive expansion. Due to the limited availability of\nhigh-quality publicly accessible medical data in\nthis low-resource language, the current Arabic sub-\nset is smaller and less diverse than those of higher-\nresource languages. We plan to continue data col-\nlection and curation efforts to further expand and\nbalance the dataset across languages, which may\nimprove both coverage and robustness in future\niterations.\nAcknowledgments\nThis work was supported by the Meem Foundation,\nthe NYUAD Center for Artificial Intelligence and\nRobotics, funded by Tamkeen under the NYUAD\nResearch Institute Award CG010, the Center for\nBrain and Health, funded by Tamkeen under NYU\nAbu Dhabi Research Institute grant CG012, and\nthe Center for Interdisciplinary Data Science & AI\n(CIDSAI), funded by Tamkeen under the NYUAD\nResearch Institute Award CG016. The research\nwas carried out on the High Performance Comput-\ning resources at New York University Abu Dhabi\n(Jubail). We are grateful to Dr. Xinwei Hou and\nDr. Zijie Fang for their support and contributions\nto data annotation.\nReferences\nAsma Ben Abacha, Wen-wai Yim, Yujuan Fu, Zhaoyi\nSun, Fei Xia, and Meliha Yetisgen-Yildiz. 2024.\nOverview of the mediqa-corr 2024 shared task on\nmedical error detection and correction. In Proceed-\nings of the 6th Clinical Natural Language Processing\nWorkshop, pages 596–603.\nAsma Ben Abacha, Wen-wai Yim, Yujuan Fu, Zhaoyi\nSun, Meliha Yetisgen, Fei Xia, and Thomas Lin.\n2025. MEDEC: A benchmark for medical error de-\ntection and correction in clinical notes. In Findings of\nthe Association for Computational Linguistics, ACL\n2025, Vienna, Austria, July 27 - August 1, 2025, pages\n22539–22550.\nEhsan\nAhsani-Estahbanati,\nVladimir\nSergee-\nvich\nGordeev,\nand\nLeila\nDoshmangir.\n2022.\nInterventions to reduce the incidence of medical\nerror and its financial burden in health care systems:\nA systematic review of systematic reviews. Frontiers\nin medicine, 9:875426.\nAlibaba DAMO Academy. 2024.\nQwen2.5-7b-\ninstruct-1m.\nhttps://huggingface.co/Qwen/\nQwen2.5-7B-Instruct. Accessed: 2025-08-01.\nRenad Alzghoul, Ayaabdelhaq Ayaabdelhaq, Abdulrah-\nman Tabaza, and Ahmad Altamimi. 2024. Cld-mec\nat mediqa-corr 2024 task: Gpt-4 multi-stage clinical\nchain of thought prompting for medical errors detec-\ntion and correction. In Proceedings of the 6th Clini-\ncal Natural Language Processing Workshop, pages\n537–556.\nFauzia Anjum, Brigadier Raffi Ud Din, and Saira Ashraf.\n2024. Patient safety and quality improvement: Re-\nducing medical errors in healthcare.\nMultidisci-\nplinary Journal of Healthcare (MJH), 1(2):13–23.\nM. Saiful Bari, Yazeed Alnumay, Norah A. Alzahrani,\nand 1 others. 2025. Allam: Large language models\nfor arabic and english. In ICLR.\nJunying Chen, Zhenyang Cai, Ke Ji, Xidong Wang,\nWanlong Liu, Rongsheng Wang, Jianye Hou, and\nBenyou Wang. 2024.\nHuatuogpt-o1, towards\nmedical complex reasoning with llms.\nPreprint,\narXiv:2412.18925.\nJean-Philippe Corbeil. 2024.\nIryonlp at MEDIQA-\nCORR 2024: Tackling the medical error detection &\ncorrection task on the shoulders of medical agents.\nIn Proceedings of the 6th Clinical Natural Language\nProcessing Workshop, ClinicalNLP@NAACL 2024,\nMexico City, Mexico, June 21, 2024, pages 570–580.\nMouath Abu Daoud,\nChaimae Abouzahir,\nLeen\nKharouf, Walid Al-Eisawi, Nizar Habash, and\nFarah E Shamout. 2025. Medarabiq: Benchmark-\ning large language models on arabic medical tasks.\narXiv preprint arXiv:2505.03427.\nDeepSeek\nAI.\n2024a.\nDeepseek-r1.\nhttps://huggingface.co/deepseek-ai/\ndeepseek-llm-7b-base.\nAccessed:\n2025-08-\n01.\nDeepSeek AI. 2024b.\nDeepseek-v3.\nhttps://\nhuggingface.co/deepseek-ai/deepseek-vl-7b.\nAccessed: 2025-08-01.\nDoubao Team, Volcano Engine. 2024. Doubao-1.5-\nthinking-pro.\nhttps://console.volcengine.\ncom/ark/region:ark+cn-beijing/model/\ndetail?Id=doubao-1-5-thinking-pro.\nAc-\ncessed: 2025-08-01.\n9\n"}, {"page": 10, "text": "Yaxin Fan, Feng Jiang, Peifeng Li, and Haizhou Li.\n2023. Grammargpt: Exploring open-source llms for\nnative chinese grammatical error correction with su-\npervised fine-tuning. In Natural Language Process-\ning and Chinese Computing - 12th National CCF\nConference, NLPCC 2023, Foshan, China, October\n12-15, 2023, Proceedings, Part III, volume 14304,\npages 69–80.\nYuejiao Fei, Leyang Cui, Sen Yang, Wai Lam, Zhen-\nzhong Lan, and Shuming Shi. 2023. Enhancing gram-\nmatical error correction systems with explanations.\nIn Proceedings of the 61st Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n1: Long Papers), ACL 2023, Toronto, Canada, July\n9-14, 2023, pages 7489–7501.\nGoogle\nResearch.\n2025a.\nMedgemma:\nOpen\nmultimodal\nmodels\nfor\nmedical\nai.\nhttps://research.google/blog/\nmedgemma-our-most-capable-open-models-for\\\n-health-ai-development. Accessed: 2025-08-01.\nGoogle\nResearch.\n2025b.\nMedgemma:\nour\nmost\ncapable\nopen\nmodels\nfor\nhealth\nai.\nhttps://research.google/blog/\nmedgemma-our-most-capable-open-models-for\\\n-health-ai-development. Accessed: 2025-08-01.\nZhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen,\nYujiu Yang, Nan Duan, and Weizhu Chen. 2024.\nCRITIC: large language models can self-correct with\ntool-interactive critiquing.\nIn The Twelfth Inter-\nnational Conference on Learning Representations,\nICLR 2024, Vienna, Austria, May 7-11, 2024.\nSatya Kesav Gundabathula and Sriram R. Kolar. 2024.\nPromptmind team at MEDIQA-CORR 2024: Improv-\ning clinical text correction with error categorization\nand LLM ensembles. In Proceedings of the 6th Clin-\nical Natural Language Processing Workshop, Clini-\ncalNLP@NAACL 2024, Mexico City, Mexico, June\n21, 2024, pages 367–373.\nSuramya Jadhav, Abhay Shanbhag, Sumedh Joshi,\nAtharva Date, and Sheetal Sonawane. 2024. Maven\nat mediqa-corr 2024: Leveraging rag and medical llm\nfor error detection and correction in medical notes.\nIn Proceedings of the 6th Clinical Natural Language\nProcessing Workshop, pages 374–381.\nDi Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng,\nHanyi Fang, and Peter Szolovits. 2021. What disease\ndoes this patient have? a large-scale open domain\nquestion answering dataset from medical exams. Ap-\nplied Sciences, page 6421.\nRyo Kamoi, Sarkar Snigdha Sarathi Das, Renze Lou,\nJihyun Janice Ahn, Yilun Zhao, Xiaoxin Lu, Nan\nZhang, Yusen Zhang, Ranran Haoran Zhang, Su-\njeeth Reddy Vummanthala, Salika Dave, Shaobo Qin,\nArman Cohan, Wenpeng Yin, and Rui Zhang. 2024a.\nEvaluating llms at detecting errors in llm responses.\n2024 Conference on Language Modeling.\nRyo Kamoi, Yusen Zhang, Nan Zhang, Jiawei Han,\nand Rui Zhang. 2024b.\nWhen can llms Actually\ncorrect their own mistakes? A critical survey of self-\ncorrection of llms. Trans. Assoc. Comput. Linguistics,\n12:1417–1440.\nMasahiro Kaneko, Sho Takase, Ayana Niwa, and Naoaki\nOkazaki. 2022. Interpretability for language learners\nusing example-based grammatical error correction.\nIn Proceedings of the 60th Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n1: Long Papers), ACL 2022, Dublin, Ireland, May\n22-27, 2022, pages 7176–7187.\nChin-Yew Lin. 2004. Rouge: A package for automatic\nevaluation of summaries.\nIn Text summarization\nbranches out, pages 74–81.\nMengsay Loem, Masahiro Kaneko, Sho Takase, and\nNaoaki Okazaki. 2023. Exploring effectiveness of\nGPT-3 in grammatical error correction: A study\non performance and controllability in prompt-based\nmethods. In Proceedings of the 18th Workshop on\nInnovative Use of NLP for Building Educational Ap-\nplications, BEA@ACL 2023, Toronto, Canada, 13\nJuly 2023, pages 205–219.\nMeta AI. 2024. Llama 3: Open foundation and instruc-\ntion models. https://github.com/meta-llama/\nllama3. Accessed: 2025-08-01.\nAbu-Daoud Mouath, Kharouf Leen, El Hajj Omar,\nEl Samad Dana, Al-Omari Mariam, Mallat Jihad,\nSaleh Khaled, Habash Nizar, and E. Shamout Farah.\n2026.\nMedarabench: Large-scale arabic medical\nquestion answering dataset and benchmark. arXiv\npreprint arXiv:2602.01714.\nDavid E Newman-Toker, Zheyu Wang, Yuxin Zhu, Na-\njlla Nassery, Ali S Saber Tehrani, Adam C Schaffer,\nChihwen Winnie Yu-Moe, Gwendolyn D Clemens,\nMehdi Fanai, and Dana Siegal. 2021. Rate of diag-\nnostic errors and serious misdiagnosis-related harms\nfor major vascular events, infections, and cancers:\ntoward a national incidence estimate using the “big\nthree”. Diagnosis, 8(1):67–84.\nJingwei Ni, Minjing Shi, Dominik Stammbach, Mrin-\nmaya Sachan, Elliott Ash, and Markus Leippold.\n2024. Afacta: Assisting the annotation of factual\nclaim detection with reliable LLM annotators. In\nProceedings of the 62nd Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers), ACL 2024, Bangkok, Thailand, August\n11-16, 2024, pages 1890–1912.\nOpenAI.\n2024a.\nGpt-4o-mini\nmodel\ncard.\nhttps://research.google/blog/\nmedgemma-our-most-capable-open-models-for\\\n-health-ai-development. Accessed: 2025-08-01.\nOpenAI. 2024b. Gpt-4o technical overview. https:\n//platform.openai.com/docs/models#gpt-4o.\nAccessed: 2025-08-01.\n10\n"}, {"page": 11, "text": "Juan Pajaro, Edwin Puertas, David Villate, Laura\nEstrada, and Laura Tinjaca. 2024. Verbanexai at\nmediqa-corr: Efficacy of gru with biowordvec and\nclinicalbert in error correction in clinical notes. In\nProceedings of the 6th clinical natural language pro-\ncessing workshop, pages 461–469.\nLiangming Pan, Michael Saxon, Wenda Xu, Deepak\nNathani, Xinyi Wang, and William Yang Wang. 2024.\nAutomatically correcting large language models: Sur-\nveying the Landscape of Diverse Automated Correc-\ntion Strategies. Trans. Assoc. Comput. Linguistics,\n12:484–506.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic evalu-\nation of machine translation. In Proceedings of the\n40th Annual Meeting of the Association for Compu-\ntational Linguistics, July 6-12, 2002, Philadelphia,\nPA, USA, pages 311–318.\nGuangyue Peng, Wei Li, Wen Luo, and Houfeng Wang.\n2025. Encode errors: Representational retrieval of in-\ncontext demonstrations for multilingual grammatical\nerror correction. In Findings of the Association for\nComputational Linguistics: ACL 2025, pages 21166–\n21180.\nSwati Rajwal, Eugene Agichtein, and Abeed Sarker.\n2024. Em_mixers at mediqa-corr 2024: Knowledge-\nenhanced few-shot in-context learning for medical\nerror detection and correction. In Proceedings of the\n6th Clinical Natural Language Processing Workshop.\nEduardo Reis, Mohamed Abdelaal, and Carsten Binnig.\n2024. Generalizable data cleaning of tabular data in\nlatent space. Proceedings of the VLDB Endowment,\n17(13):4786–4798.\nNadia Saeed. 2024. Medifact at MEDIQA-CORR 2024:\nWhy AI needs a human touch. In Proceedings of the\n6th Clinical Natural Language Processing Workshop,\nClinicalNLP@NAACL 2024, Mexico City, Mexico,\nJune 21, 2024, pages 346–352.\nThibault Sellam, Dipanjan Das, and Ankur P. Parikh.\n2020.\nBLEURT: learning robust metrics for text\ngeneration. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguis-\ntics, ACL 2020, Online, July 5-10, 2020, pages 7881–\n7892.\nVinay Setty. 2024. Factcheck editor: Multilingual text\neditor with end-to-end fact-checking. In Proceedings\nof the 47th International ACM SIGIR Conference on\nResearch and Development in Information Retrieval,\npages 2744–2748.\nHamid Soori. 2024. Errors in medical procedures. In\nErrors in Medical Science Investigations, pages 205–\n224.\nFelix Stahlberg and Shankar Kumar. 2024. Synthetic\ndata generation for low-resource grammatical error\ncorrection with tagged corruption models. In Pro-\nceedings of the 19th Workshop on Innovative Use\nof NLP for Building Educational Applications, BEA\n2024, Mexico City, Mexico, June 20, 2024, pages\n11–16.\nRunchu Tian, Yining Ye, Yujia Qin, Xin Cong, Yankai\nLin, Yinxu Pan, Yesai Wu, Haotian Hui, Weichuan\nLiu, Zhiyuan Liu, and Maosong Sun. 2024.\nDe-\nbugbench: Evaluating debugging capability of large\nlanguage models. In Findings of the Association\nfor Computational Linguistics, ACL 2024, Bangkok,\nThailand and virtual meeting, August 11-16, 2024,\npages 4173–4198.\nYunDa Tsai, Mingjie Liu, and Haoxing Ren. 2024. Rtl-\nfixer: Automatically fixing rtl syntax errors with\nlarge language model. In Proceedings of the 61st\nACM/IEEE Design Automation Conference, pages\n1–6.\nAirat Valiev and Elena Tutubalina. 2024. Hse nlp team\nat mediqa-corr 2024 task: In-prompt ensemble with\nentities and knowledge graph for medical error cor-\nrection. In Proceedings of the 6th Clinical Natural\nLanguage Processing Workshop.\nJustin Vasselli and Taro Watanabe. 2023. A closer look\nat k-nearest neighbors grammatical error correction.\nIn Proceedings of the 18th Workshop on Innovative\nUse of NLP for Building Educational Applications,\nBEA@ACL 2023, Toronto, Canada, 13 July 2023,\npages 220–231.\nZhaolong Wu, Abul Hasan, Jinge Wu, Yunsoo Kim, Ja-\nson Cheung, Teng Zhang, and Honghan Wu. 2024.\nKnowlab_aimed at mediqa-corr 2024: Chain-of-\nthough (cot) prompting strategies for medical er-\nror detection and correction. In proceedings of the\n6th clinical natural language processing workshop,\npages 353–359.\nJingheng Ye, Shang Qin, Yinghui Li, Xuxin Cheng,\nLibo Qin, Hai-Tao Zheng, Ying Shen, Peng Xing,\nZishan Xu, Guo Cheng, and 1 others. 2025. Ex-\ncgec: A benchmark for edit-wise explainable chi-\nnese grammatical error correction. In Proceedings\nof the AAAI Conference on Artificial Intelligence,\nvolume 39, pages 25678–25686.\nMin Zeng, Jiexin Kuang, Mengyang Qiu, Jayoung Song,\nand Jungyeul Park. 2024.\nEvaluating prompting\nstrategies for grammatical error correction based on\nlanguage proficiency. In Proceedings of the 2024\nJoint International Conference on Computational\nLinguistics, Language Resources and Evaluation,\nLREC/COLING 2024, 20-25 May, 2024, Torino, Italy,\npages 6426–6430.\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.\nWeinberger, and Yoav Artzi. 2020. Bertscore: Evalu-\nating text generation with BERT. In 8th International\nConference on Learning Representations, ICLR 2020,\nAddis Ababa, Ethiopia, April 26-30, 2020.\n11\n"}, {"page": 12, "text": "A\nData Statistics\nA.1\nLanguage-wise data split and statistics\nTable S1 presents the official data splits and ba-\nsic statistics of the dataset, a multilingual clinical\nbenchmark covering English, Chinese, and Ara-\nbic. For each language, we report the number of\ninstances in the training, validation, and test sets,\nalong with the total number of samples. The En-\nglish dataset contains 1,024 instances, the Chinese\ndataset includes 1,000, and the Arabic dataset con-\nsists of 482. We also provide average, maximum,\nand minimum input lengths, as well as the number\nof samples with and without factual errors in each\nsplit.\nTable S1: Summary Statistics of the Dataset.\nLanguage\nMetric\nTrain\nValidation\nTest\nTotal\nEnglish\nNum.\n708\n108\n208\n1024\nAvg len\n755.7\n604.3\n872.1\n763.9\nMax len\n1594\n1250\n1396\n1594\nMin len\n220\n101\n63\n63\nw errors\n354\n54\n104\n512\nw/o errors\n354\n54\n104\n512\nChinese\nNum.\n700\n100\n200\n1000\nAvg len\n97.4\n96.3\n98\n97.3\nMax len\n269\n262\n191\n269\nMin len\n32\n41\n40\n32\nw errors\n350\n50\n100\n500\nw/o errors\n350\n50\n100\n500\nArabic\nNum.\n334\n51\n97\n482\nAvg len\n156\n168.2\n165.6\n159.2\nMax len\n457\n429\n501\n501\nMin len\n31\n48\n37\n31\nw errors\n179\n29\n53\n261\nw/o errors\n155\n22\n44\n221\nA.2\nDistribution of medical error types\nFigure S1 illustrates the distribution of ten com-\nmon medical error types in the dataset across three\nlanguages: English, Chinese, and Arabic. Each\ndonut chart represents the relative proportions of\nerror categories, including Diagnosis, Management,\nTreatment, Pharmacotherapy, Physiology, Causal\nOrganism, Anatomy, Lab/Serum Value, Histology,\nand Epidemiology. In the English subset (a), Di-\nagnosis (41.2%) and Management (24.2%) are the\nmost prevalent error types, followed by Physiol-\nogy (18.0%) and Pharmacotherapy (12.5%). The\nChinese subset (b) shows a stronger concentration\nin Diagnosis errors (45.4%), with moderate rep-\nresentations of Mangement (18.2%), Treatment\n(14.2%), Pharmacotherapy (13.0%), and notably\nfewer errors related to Physiology and Anatomy\n(2.6% each). In contrast, the Arabic subset (c)\npresents a more balanced distribution, where Di-\nagnosis (27.2%) remains the largest category, but\nPhysiology (21.5%) and Anatomy (18.8%) are\nmore prominent, while categories such as Treat-\nment (2.3%) and Causal Organism (1.9%) are less\nfrequent. These distributions highlight linguistic\nand potentially systemic differences in error typolo-\ngies across multilingual medical corpora.\nB\nBenchmark Tasks\nThe proposed MedErrBench dataset supports three\ncore tasks for benchmarking clinical error under-\nstanding:\n• Error Detection: Determine whether a given\nclinical note contains an error. This is formu-\nlated as a binary classification task distinguish-\ning between error-free and erroneous notes.\n• Error Localization: Identify which specific\nsentence within the clinical note contains the\nerror. This task focuses on sentence-level lo-\ncalization rather than token-level span extrac-\ntion, aligning with how clinicians typically\nreview clinical documentation.\n• Error Correction: Generate a revised version\nof the clinical note with the error corrected.\nThis task requires contextual understanding\nand clinical knowledge to produce plausible\nand medically valid corrections.\nBeyond the three primary tasks supported by\nMedErrBench, the dataset includes annotations of\ndifficulty level, reasoning type, and important clini-\ncal terms, which enable flexible task customization.\nFor instance, MedErrBench can be used for error\nclassification by assigning each clinical note to a\npredefined error category curated by expert clin-\nicians. In addition, annotated key clinical terms\nsupport token-level localization, facilitating the de-\nvelopment of alternative task formulations.\nC\nExperimental Settings\nDuring dataset construction, LLMs used for the\nEnglish, Chinese, and Arabic datasets were Gem-\nini 2.0 Flash, DeepSeek-V3-0324, and Gemini-1.5-\npro, respectively. In regard to the models, Qwen2.5-\n7B-Instruct was used and all the hyperparameters\nwere set to the default values4. ALLAM-7B was\nrun with hyperparameters: max_new_tokens=256,\n4https://www.alibabacloud.com/help/en/\nmodel-studio/use-qwen-by-calling-api\n12\n"}, {"page": 13, "text": "Figure S1: Distribution of Error Types by Language\ntop_k=50,\ntemperature=0.7,\ntop_p=0.9,\nand\ndo_sample=True. JAIS-adapted-13b-chat was run\nwiht max_new_tokens=256, do_sample=True, tem-\nperature=0.7, top_k = 50 and top_p=0.95. Doubao-\n1.5-Thinking-Pro was run with max_tokens=512,\nwith all other parameters (including temperature\nand top_p) set to default values5. DeepSeek-V3\nand DeepSeek-R-1 were run with hyperparame-\nters: max_tokens=512, while all other parameters\nwere set to their default values6. Meta-Llama-3.1-\n8B-Instruct was accessed via the Novita Inference-\nClient with hyperparameters: max_tokens=256,\ntemperature=0.2, do_sample=False. HuatuoGPT-\no1-8B was run locally with PyTorch with hy-\nperparameters: max_new_tokens=1024, temper-\nature=0.2, do_sample=False, and pad_token_id set\nto the tokenizer’s eos_token_id. GPT-4o, GPT-\n4o-mini, Gemini 2.0 Flash, Gemini 2.5 Flash\nLite, and MedGemma-4B, MedGemma-27B are\nall used with default parameters. We use BLEURT\nwith BLEURT-20 model7 and BERTScore with\nthe deberta-xlarge-mnli checkpoint8. For Chinese\ndata, ROUGE evaluation is performed using the\nROUGE-chinese package9, which provides tok-\nenization and evaluation methods specifically de-\nsigned for Chinese text.\nD\nEvaluation Metrics\nROUGE-1 (Lin, 2004) measures unigram overlap\nbetween the generated and reference texts, while\nROUGE-2 extends this to bigram overlap. ROUGE-\n5https://www.volcengine.com/docs/82379/1494384\n6api-docs.deepseek.com/api/\ncreate-chat-completion\n7https://github.com/google-research/bleurt\n8https://huggingface.co/microsoft/\ndeberta-xlarge-mnli\n9https://pypi.org/project/rouge-chinese/\nL (Lin, 2004) captures structural similarity based\non the longest common subsequence and ROUGE-\nSU (Lin, 2004) incorporates both unigrams and\nskip-bigrams with a maximum skip distance, of-\nfering a balance between flexibility and structure.\nBERTScore (Zhang et al., 2020) evaluates seman-\ntic similarity using contextual embeddings from a\npre-trained BERT model. BLEURT (Sellam et al.,\n2020) combines pre-trained language models with\nhuman-annotated data to assess the fluency and\nadequacy of the generated text.\nE\nDetailed Overall Performance Across\nLanguages\nWe report the complete results on all evaluation\nmetrics, including detection accuracy, localiza-\ntion accuracy, ROUGE-1, ROUGE-2, ROUGE-L,\nBLEU, BERTScore, and BLEURT, evaluated on\nMedErrBench-EN (Table S2), MedErrBench-CN\n(Table S3), and MedErrBench-Ara (Table S4).\nF\nDetailed Experimental Results on the\nImpact of Providing Example Difficulty\nLevels in Few-Shot Learning Settings\nTable S5 presents the complete results across\nall evaluation metrics, including detection accu-\nracy, localization accuracy, ROUGE-1/2/L, BLEU,\nBERTScore, and BLEURT, for analyzing the im-\npact of providing example difficulty levels in few-\nshot learning settings.\nG\nPrompts of Data Construction\nWe utilized large language models to help convert\nmedical examination materials into comprehensive\nclinical stories across English, Chinese, and Arabic.\nThe language-specific prompts used for generation\nare illustrated in Figure S2, Figure S3 and S4.\n13\n"}, {"page": 14, "text": "Table S2: Results on MedErrBench-EN.\nModels\nDetection\nLocalization\nError Correction\nAccuracy\nAccuracy\nROUGE-1\nROUGE-2\nROUGE-L\nBLEU\nBERTScore\nBLEURT\nGeneral-purpose LLMs\ngpt-4o\n0.596\n0.346\n0.415\n0.365\n0.403\n0.329\n0.428\n0.407\ngpt-4o-mini\n0.664\n0.524\n0.487\n0.441\n0.477\n0.409\n0.498\n0.472\nGemini 2.5 Flash Lite\n0.567\n0.264\n0.349\n0.307\n0.340\n0.279\n0.362\n0.346\nGemini 2.0 Flash\n0.514\n0.168\n0.281\n0.231\n0.268\n0.186\n0.294\n0.288\nLlama3-8b\n0.519\n0.361\n0.266\n0.225\n0.261\n0.219\n0.261\n0.283\nLlama-3.3-70B-Instruct\n0.582\n0.255\n0.369\n0.328\n0.356\n0.292\n0.369\n0.385\nLanguage-specialized LLMs\nQwen2.5-7B-Instruct\n0.563\n0.490\n0.372\n0.334\n0.345\n0.381\n0.450\n0.371\nDeepseek-R1\n0.582\n0.577\n0.700\n0.612\n0.682\n0.551\n0.716\n0.681\nDeepseek-V3\n0.587\n0.582\n0.703\n0.626\n0.687\n0.569\n0.732\n0.693\nDoubao-1.5\n0.779\n0.774\n0.766\n0.707\n0.752\n0.662\n0.783\n0.773\nALLAM-7B\n0.029\n0.014\n0.015\n0.014\n0.015\n0.286\n0.020\n0.014\nMedical-domain LLMs\nMedGemma-4b\n0.505\n0.438\n0.511\n0.499\n0.508\n0.489\n0.518\n0.513\nMedGemma-27b\n0.543\n0.245\n0.377\n0.337\n0.369\n0.305\n0.390\n0.349\nHuatuoGPT-o1-7b\n0.574\n0.530\n0.486\n0.466\n.485\n0.446\n0.475\n0.475\nTable S3: Results on MedErrBench-CN.\nModels\nDetection\nLocalization\nError Correction\nAccuracy\nAccuracy\nROUGE-1\nROUGE-2\nROUGE-L\nBLEU\nBERTScore\nBLEURT\nGeneral-purpose LLMs\ngpt-4o\n0.630\n0.205\n0.265\n0.169\n0.247\n0.148\n0.365\n0.266\ngpt-4o-mini\n0.505\n0.115\n0.244\n0.145\n0.223\n0.130\n0.390\n0.257\nGemini 2.5 Flash Lite\n0.600\n0.375\n0.448\n0.401\n0.439\n0.310\n0.533\n0.455\nGemini 2.0 Flash\n0.705\n0.455\n0.569\n0.510\n0.557\n0.405\n0.659\n0.577\nLlama3-8b\n0.500\n0.320\n0.416\n0.251\n0.377\n0.168\n0.532\n0.483\nLlama-3.3-70B-Instruct\n0.675\n0.380\n0.506\n0.459\n0.500\n0.438\n0.606\n0.509\nLanguage-specialized LLMs\nQwen2.5-7B-Instruct\n0.625\n0.570\n0.493\n0.429\n0.492\n0.331\n0.576\n0.462\nDeepseek-R1\n0.735\n0.705\n0.802\n0.708\n0.799\n0.491\n0.851\n0.781\nDeepseek-V3\n0.650\n0.640\n0.833\n0.741\n0.830\n0.540\n0.873\n0.806\nDoubao-1.5\n0.750\n0.735\n0.788\n0.709\n0.784\n0.508\n0.835\n0.777\nALLAM-7B\n0.395\n0.340\n0.284\n0.260\n0.283\n0.080\n0.360\n0.286\nMedical-domain LLMs\nMedGemma-4b\n0.525\n0.500\n0.549\n0.528\n0.545\n0.500\n0.581\n0.547\nMedGemma-27b\n0.605\n0.285\n0.441\n0.386\n0.430\n0.270\n0.537\n0.438\nHuatuoGPT-o1-7b\n0.525\n0.275\n0.167\n0.056\n0.167\n0.169\n0.545\n0.530\nH\nExamples for Error Insertion in\nMedErrBench Dataset\nFigure S6, S7 and S8 are examples for error inser-\ntion in the proposed MedErrBench dataset.\nI\nIllustrative Examples of the Ten Error\nTypes Defined in the MedErrBench\nDataset\nFigure S9, S10 and S11 are the illustrative exam-\nples of the ten error types defined in the MedEr-\nrBench dataset.\nJ\nPerformance of Existing Error\nDetection and Correction Methods on\nMedErrBench\nThe MEDIQA-CORR 2024 shared task (Abacha\net al., 2024) focused on detecting and correcting\nmultiple types of medical errors in clinical texts\nand attracted participation from seventeen teams.\nWe attempted to benchmark representative systems\nfrom this shared task on MedErrBench, our trilin-\ngual dataset. However, due to the unavailability\nor inactivity of most public GitHub repositories,\nonly a limited subset of methods could be success-\nfully reproduced and evaluated. Specifically, we\nbenchmarked CLD-MEC (Alzghoul et al., 2024),\nMaven (Jadhav et al., 2024), and VerbaNexAI (Pa-\njaro et al., 2024), including both VerbaNexAI-GRU\nand VerbaNexAI-ClinicalBERT.\nThe detailed results are reported in Table S6.\nOverall, these task-specific error detection and cor-\nrection models underperform compared to state-of-\nthe-art language-specialized LLMs, suggesting that\nlarge pretrained models with strong multilingual\nand generative capabilities may generalize more\neffectively across diverse error types and languages\nthan systems optimized for narrow task formula-\n14\n"}, {"page": 15, "text": "Table S4: Results on MedErrBench-Ara.\nModels\nDetection\nLocalization\nError Correction\nAccuracy\nAccuracy\nROUGE-1\nROUGE-2\nROUGE-L\nBLEU\nBERTScore\nBLEURT\nGeneral-purpose LLMs\ngpt-4o\n0.680\n0.320\n0.399\n0.357\n0.393\n0.321\n0.592\n0.414\ngpt-4o-mini\n0.577\n0.175\n0.260\n0.212\n0.250\n0.164\n0.469\n0.292\nGemini 2.5 Flash Lite\n0.495\n0.268\n0.303\n0.280\n0.299\n0.253\n0.432\n0.318\nGemini 2.0 Flash\n0.598\n0.299\n0.315\n0.281\n0.308\n0.251\n0.503\n0.332\nLlama3-8b\n0.371\n0.309\n0.311\n0.304\n0.310\n0.296\n0.324\n0.313\nLlama-3.3-70B-Instruct\n0.557\n0.381\n0.412\n0.385\n0.406\n0.364\n0.454\n0.405\nLanguage-specialized LLMs\nQwen2.5-7B-Instruct\n0.536\n0.381\n0.329\n0.298\n0.327\n0.348\n0.473\n0.353\nDeepseek-R1\n0.711\n0.505\n0.568\n0.500\n0.564\n0.457\n0.756\n0.610\nDeepseek-V3\n0.608\n0.505\n0.677\n0.628\n0.675\n0.592\n0.814\n0.699\nDoubao-1.5\n0.670\n0.505\n0.582\n0.510\n0.574\n0.452\n0.736\n0.583\nALLAM-7B\n0.072\n0.021\n0.045\n0.044\n0.045\n0.219\n0.049\n0.046\nMedical-domain LLMs\nMedGemma-4b\n0.454\n0.433\n0.438\n0.436\n0.438\n0.436\n0.450\n0.439\nMedGemma-27b\n0.552\n0.240\n0.266\n0.220\n0.257\n0.185\n0.456\n0.286\nHuatuoGPT-o1-7b\n0.371\n0.397\n0.351\n0.260\n0.329\n0.158\n0.450\n0.420\nTable S5: Performance comparison of models under different error type Conditions. “ET\" and “DEF\" indicate error\ntypes and definitions, respectively.\nDetection\nLocalization\nError Correction\nAccuracy\nAccuracy\nROUGE-1\nROUGE-2\nROUGE-L\nBLEU\nBERTScore\nBLEURT\nDeepseek-V3 (Zero-shot)\nw/o ET & DEF\n0.690\n0.645\n0.660\n0.490\n0.659\n0.192\n0.735\n0.599\nw/o DEF\n0.625\n0.610\n0.731\n0.564\n0.726\n0.227\n0.795\n0.685\nw ET & DEF\n0.650\n0.640\n0.730\n0.574\n0.724\n0.228\n0.794\n0.684\nDeepseek-V3 (Few-shot)\nw/o ET & DEF\n0.720\n0.690\n0.695\n0.535\n0.695\n0.249\n0.767\n0.639\nw/o DEF\n0.710\n0.705\n0.736\n0.561\n0.728\n0.215\n0.796\n0.684\nw ET & DEF\n0.715\n0.715\n0.763\n0.596\n0.758\n0.234\n0.821\n0.705\nDoubao-1.5-thinking-pro (Zero-shot)\nw/o ET & DEF\n0.695\n0.640\n0.637\n0.503\n0.632\n0.166\n0.727\n0.607\nw/o DEF\n0.730\n0.710\n0.673\n0.521\n0.665\n0.164\n0.751\n0.646\nw ET & DEF\n0.750\n0.725\n0.669\n0.531\n0.660\n0.171\n0.728\n0.636\nDoubao-1.5-thinking-pro (Few-shot)\nw/o ET & DEF\n0.735\n0.695\n0.707\n0.553\n0.695\n0.248\n0.765\n0.651\nw/o DEF\n0.765\n0.750\n0.729\n0.568\n0.716\n0.260\n0.777\n0.671\nw ET & DEF\n0.775\n0.765\n0.699\n0.535\n0.687\n0.209\n0.753\n0.665\ntions.\nMaven relies on a Retrieval-Augmented Genera-\ntion (RAG) pipeline that is explicitly designed for\nEnglish medical text. Its retrieval component uses\nan English-only knowledge base. When applied\nto Arabic or Chinese clinical texts, the retrieval\nmechanism fails to identify semantically relevant\ncontext, as embeddings derived from non-English\ninputs do not align well with English documents\nin the knowledge base. As a result, Maven pro-\nduces irrelevant or incorrect disease or pathogen\npredictions and cannot be reliably evaluated on the\nChinese or Arabic subsets of MedErrBench.\nIn\naddition,\nboth\nVerbaNexAI-GRU\nand\nVerbaNexAI-ClinicalBERT do not produce local-\nization or correction outputs, as they are funda-\nmentally classification-based models rather than\ngenerative systems. Consequently, they are only\npartially comparable to generative LLM-based ap-\nproaches in the full error detection and correction\nsetting.\nJ.1\nCross-lingual Generalization\nTo assess the effectiveness of machine-translated\nmultilingual data for error detection, localization,\nand correction, we translated the Chinese dataset\ninto English and Arabic. Chinese was selected ar-\nbitrarily as the source language and not for any spe-\ncific preference, but to test whether linguistic rep-\nresentation differences across languages and cross-\nlingual variation alone affect model performance.\nThe results are shown in Figure S5. We observe\nthat across all three tasks, most models experience\na performance drop to varying degrees on the trans-\nlated English and Arabic datasets, with the decline\nbeing particularly pronounced on the Arabic data,\n15\n"}, {"page": 16, "text": "Prompt Used in English Dataset Construction\nThe following is a medical narrative about a patient. You are a skilled medical doctor reviewing the clinical text.  The \ntext is either correct or contains one error. The text has one sentence per line. Each line starts with the sentence ID, \nfollowed by a pipe character then the sentence to check. \n \nThis text may contain the following types of errors: Failure of identification of the disease or clinical condition based on \nthe case presentation (Diagnosis). Incorrect or inappropriate immediate clinical decision-making step (non-\npharmacologic, non-surgical) based on the scenario. This includes next steps, monitoring, disposition, or supportive \ninterventions. This excludes pharmacotherapy and procedural treatments (Management). Errors in recommending or \ndescribing the definitive intervention, typically surgical, procedural, or medication. This is distinct from general \nmanagement (Treatment). Wrong drug choice, dose, route, timing, interactions or duration (Pharmacotherapy). Errors in \nidentifying the microorganism responsible for an infection or disease state (Causal organism / pathogen). Errors in lab \nreference ranges, thresholds, or interpretations (e.g., diagnostic cutoffs, ABG interpretation ) (Lab/serum value \ninterpretation cause). Misinterpretation of physiological concepts, including ECG, PFT, Capnography or Jugular \nwaveform, this excludes ABG which interpreted via serum readings (Physiology), errors in describing microscopic \nappearance, tissue structures, or classic cellular features (Histology). Errors in location, relation, or function of \nanatomical structures (Anatomy). False or misleading data regarding incidence, prevalence, risk factors, or statistical \nanalysis. This includes misuse or misinterpretation of biostatistical tools commonly used in epidemiology : misuse of \nsensitivity /specificity fomulas , P value , matching study design (Epidemiology). \n You need to determine whether the text is correct and output a single line result consisting of the following four parts:\n<Text ID>: A unique identifier for the text\n<Error Flag>: Indicates whether there is an error; enter 0 if correct, or 1 if there is an error\n<Error Sentence ID>: The ID of the erroneous sentence; enter -1 if correct, or the sentence ID if there is an error\n<Corrected sentence>: The corrected sentence; enter NA if correct, or the corrected sentence enclosed in double \nquotes if there is an error\nDo not output any explanations, additional text, or other formats.\nOutput strictly one line, in one of the following two formats:\nIf the text is correct, output:\n<Text ID> 0 -1 NA\nIf the text has an error, output:\n<Text ID> 1 <Error Sentence ID> \"<Corrected sentence>\"\nNow, please review the following text:\nText ID: {text_id}\n{text}\nFigure S2: Prompt Used in MedErrBench-En Construction.\nespecially with larger gaps observed in localization\naccuracy and average correction scores. This is\nmainly due to the substantial structural differences\nof the language and insufficient training data. In\nparticular, translated data fails to capture the unique\nexpressions and error patterns specific to Arabic,\nmaking it difficult for models to effectively transfer\nlearning. Therefore, relying solely on translated\ndata cannot meet the demands of high-quality mul-\ntilingual models. It is crucial to construct authen-\ntic, diverse, and high-quality native multilingual\ndatasets, so that the models deeply understand the\ncharacteristics of different languages, improve their\ncapabilities in fine-grained tasks like localization\nand correction, and thereby enhance cross-lingual\ngeneralization performance.\n16\n"}, {"page": 17, "text": "Prompt Used in Chinese Dataset Construction\n以下是一段关于患者的医学叙述。\n你是一位经验丰富的医生，正在审阅这段临床文本。\n文本要么完全正确，要么最多包含一个错误。\n每行是一句句子，格式为：句子 ID + 句子内容。\n这段文本中包含以下类型的错误：未能根据病例表现正确识别疾病或临床状态（诊断错误）；在当前情境下选择了不正确\n或不恰当的即时临床决策步骤（疾病管理错误），包括下一步措施、监测、处置或支持性干预，但不包括药物或手术治\n疗；在推荐或描述最终干预措施时出错，通常指手术、操作或药物干预（治疗错误）；选择了错误的药物、剂量、途径、\n时间、相互作用或疗程（药物治疗错误）；未能正确识别引起感染或疾病状态的微生物（致病生物识别错误）；对实验室\n参考范围、阈值或解释有错误（实验室/血清值解读错误）；对生理学概念的误解，包括心电图、肺功能、呼气末二氧化碳\n或颈静脉波形的解读（生理学误解）；在描述显微镜下外观、组织结构或典型细胞特征时出错（组织学描述错误）；在描\n述解剖结构的位置、关系或功能时出错（解剖学描述错误）；以及关于发病率、患病率、危险因素或统计分析的数据错误\n或误导性解释，包括生物统计工具的误用或误解，如敏感性/特异性公式、P 值、匹配研究设计的误用（流行病学分析错\n误）。\n你需要判断文本是否正确，并输出一行结果，结果由以下四个部分组成：\n- <Text ID>：文本的唯一标识符\n- <Error Flag>：是否有错误；如果正确填 0，如果有错误填 1\n- <Error Sentence ID>：出错的句子 ID；如果正确填 -1，如果有错误填出错的句子 ID\n- <Corrected sentence>：更正后的句子；如果正确填 NA，如果有错误填更正后的句子（需要用双引号括起来）\n不要输出任何解释、附加文字或其他格式。\n只输出严格一行，格式必须为以下两种之一：\n如果文本正确，输出：\n<Text ID> 0 -1 NA\n如果文本有错误，输出：\n<Text ID> 1 <Error Sentence ID> \"<Corrected sentence>\"\n现在，请审阅以下文本：\nText ID: {text_id}\n{text}\nFigure S3: Prompt Used in MedErrBench-CN Construction.\nTable S6: Results on Error Detection and Correction Models.\nModels\nDetection\nLocalization\nError Correction\nAccuracy\nAccuracy\nROUGE-1\nROUGE-2\nROUGE-L\nBLEU\nBERTScore\nBLEURT\nMedErrBench-EN\nCLD-MEC\n0.639\n0.615\n0.502\n0.477\n0.497\n0.462\n0.505\n0.534\nMaven\n0.264\n0.192\n0.035\n0.021\n0.027\n0.013\n0.128\n0.081\nVerbaNexAI-GRU\n0.510\n-\n-\n-\n-\n-\n-\n-\nVerbaNexAI-ClinicalBERT\n0.601\n-\n-\n-\n-\n-\n-\n-\nMedErrBench-CN\nCLD-MEC\n0.655\n0.630\n0.479\n0.430\n0.472\n0.414\n0.581\n0.503\nMedErrBench-Ara\nCLD-MEC\n0.464\n0.381\n0.302\n0.276\n0.296\n0.260\n0.355\n0.315\n17\n"}, {"page": 18, "text": "Prompt Used in Arabic Dataset Construction\n.اﻟﻔﻘرة اﻟﺗﺎﻟﯾﺔ ھﻲ ﺳرد طﺑﻲ ﻟﺣﺎﻟﺔ ﻣرﯾض. أﻧت طﺑﯾب ﻣﺎھر ﺗﻘوم ﺑﻣراﺟﻌﺔ اﻟﻧص اﻟﺳرﯾري\n.اﻟﻧص إﻣﺎ أن ﯾﻛون ﺻﺣﯾﺣًﺎ أو ﯾﺣﺗوي ﻋﻠﻰ ﺧطﺄ واﺣد. اﻟﻧص ﯾﺗﻛوّ ن ﻣن ﺟﻣﻠﺔ واﺣدة ﻓﻲ ﻛل ﺳطر\n.(، ﺛم اﻟﺟﻣﻠﺔ اﻟﻣطﻠوب اﻟﺗﺣﻘق ﻣﻧﮭﺎsentence ID) ﻛل ﺳطر ﯾﺑدأ ﺑﻣﻌرّف اﻟﺟﻣﻠﺔ\n:ﻗد ﯾﺣﺗوي اﻟﻧص ﻋﻠﻰ اﻷﻧواع اﻟﺗﺎﻟﯾﺔ ﻣن اﻷﺧطﺎء\n.(* ﻓﺷل ﻓﻲ ﺗﺣدﯾد اﻟﻣرض أو اﻟﺣﺎﻟﺔ اﻟﺳرﯾرﯾﺔ ﺑﻧﺎءً ﻋﻠﻰ اﻟﻌرض )اﻟﺗﺷﺧﯾص\n * ﻗرار ﺳرﯾري ﻏﯾر ﺻﺣﯾﺢ أو ﻏﯾر ﻣﻧﺎﺳب ﻓﻲ اﻟﺧطوة اﻟﻔورﯾﺔ )ﻏﯾر دواﺋﻲ، ﻏﯾر ﺟراﺣﻲ( ﺑﻧﺎءً ﻋﻠﻰ اﻟﺳﯾﻧﺎرﯾو. ﯾﺷﻣل ذﻟك اﻟﺧطوات اﻟﺗﺎﻟﯾﺔ، اﻟﻣراﻗﺑﺔ، اﻟﺧطﺔ اﻟﻌﻼﺟﯾﺔ، أو\n.اﻟﺗدﺧﻼت اﻟداﻋﻣﺔ )اﻹدارة اﻟﻌﺎﻣﺔ(، وﻻ ﯾﺷﻣل ذﻟك اﻟﻣﻌﺎﻟﺟﺔ اﻟدواﺋﯾﺔ أو اﻹﺟراﺋﯾﺔ\n.(* أﺧطﺎء ﻓﻲ اﻟﺗوﺻﯾﺔ أو وﺻف اﻟﺗدﺧل اﻟﻧﮭﺎﺋﻲ، واﻟذي ﯾﻛون ﻋﺎدةً ﺟراﺣﯾًﺎ أو إﺟراﺋﯾًﺎ أو دواﺋﯾًﺎ. وھذا ﯾﺧﺗﻠف ﻋن اﻹدارة اﻟﻌﺎﻣﺔ )اﻟﻌﻼج\n.(* اﺧﺗﯾﺎر دواء ﺧﺎطﺊ، أو ﺟرﻋﺔ، أو طرﯾق إﻋطﺎء، أو ﺗوﻗﯾت، أو ﺗداﺧﻼت دواﺋﯾﺔ، أو ﻣدة اﻟﻌﻼج )اﻟﻣﻌﺎﻟﺟﺔ اﻟدواﺋﯾﺔ\n.(* أﺧطﺎء ﻓﻲ ﺗﺣدﯾد اﻟﻛﺎﺋن اﻟﻣﻣرض اﻟﻣﺳؤول ﻋن ﻋدوى أو ﺣﺎﻟﺔ ﻣرﺿﯾﺔ )اﻟﻌﺎﻣل اﻟﻣﺳﺑب / اﻟﻣﻣرض\n.(* أﺧطﺎء ﻓﻲ اﻟﻘﯾم اﻟﻣرﺟﻌﯾﺔ اﻟﻣﺧﺑرﯾﺔ، اﻟﻌﺗﺑﺎت اﻟﺗﺷﺧﯾﺻﯾﺔ، أو اﻟﺗﻔﺳﯾرات )ﻣﺛل ﺣدود اﻟﺗﺷﺧﯾص، ﺗﻔﺳﯾر ﻏﺎزات اﻟدم اﻟﺷرﯾﺎﻧﻲ( )ﺗﻔﺳﯾر اﻟﻘﯾم اﻟﻣﺧﺑرﯾﺔ/اﻟﻣﺻﻠﯾﺔ\n * ﺗﻔﺳﯾر ﺧﺎطﺊ ﻟﻠﻣﻔﺎھﯾم اﻟﻔﺳﯾوﻟوﺟﯾﺔ، ﻣﺛل ﺗﺧطﯾط اﻟﻘﻠب، اﺧﺗﺑﺎرات وظﺎﺋف اﻟرﺋﺔ، ﻗﯾﺎس ﺛﺎﻧﻲ أﻛﺳﯾد اﻟﻛرﺑون، أو ﻣوﺟﺎت اﻟورﯾد اﻟوداﺟﻲ، ﺑﺎﺳﺗﺛﻧﺎء ﻏﺎزات اﻟدم اﻟﺷرﯾﺎﻧﻲ\n.(اﻟﺗﻲ ﺗُﻔﺳر ﻣن ﺧﻼل اﻟﻘراءات اﻟﻣﺧﺑرﯾﺔ )اﻟﻔﯾزﯾوﻟوﺟﯾﺎ\n.(* أﺧطﺎء ﻓﻲ وﺻف اﻟﺑﻧﯾﺔ اﻟﻣﺟﮭرﯾﺔ، أو ﻣظﮭر اﻷﻧﺳﺟﺔ، أو اﻟﺳﻣﺎت اﻟﺧﻠوﯾﺔ اﻟﻧﻣوذﺟﯾﺔ )اﻟﻧﺳﺞ\n.(* أﺧطﺎء ﻓﻲ ﺗﺣدﯾد ﻣوﻗﻊ أو ﻋﻼﻗﺔ أو وظﯾﻔﺔ اﻟﺑُﻧﻰ اﻟﺗﺷرﯾﺣﯾﺔ )اﻟﺗﺷرﯾﺢ\n * ﺑﯾﺎﻧﺎت ﻛﺎذﺑﺔ أو ﻣﺿﻠﻠﺔ ﺗﺗﻌﻠق ﺑﺎﻟﺣدوث، اﻻﻧﺗﺷﺎر، ﻋواﻣل اﻟﺧطر، أو اﻟﺗﺣﻠﯾل اﻹﺣﺻﺎﺋﻲ. ﯾﺷﻣل ذﻟك ﺳوء اﺳﺗﺧدام أدوات اﻹﺣﺻﺎء اﻟﺣﯾوي اﻟﺷﺎﺋﻌﺔ ﻓﻲ ﻋﻠم اﻟوﺑﺎﺋﯾﺎت، ﻣﺛل\n.((، أو ﺗﺻﻣﯾم اﻟدراﺳﺔ )اﻟوﺑﺎﺋﯾﺎتP value) اﻟﺣﺳﺎﺳﯾﺔ / اﻟﻧوﻋﯾﺔ، اﻟﻘﯾم اﻻﺣﺗﻣﺎﻟﯾﺔ\n:ﻣﮭﻣﺗك ھﻲ ﺗﺣدﯾد ﻣﺎ إذا ﻛﺎن اﻟﻧص ﺻﺣﯾﺣًﺎ أو ﯾﺣﺗوي ﻋﻠﻰ ﺧطﺄ، وأن ﺗُرﺟﻊ ﺳطرًا واﺣدًا ﻓﻘط ﯾﺣﺗوي ﻋﻠﻰ اﻷﺟزاء اﻷرﺑﻌﺔ اﻟﺗﺎﻟﯾﺔ\n<: ﻣﻌرّف ﻓرﯾد ﻟﻠﻧصText ID> *\n إذا ﻛﺎن ﯾﺣﺗوي ﻋﻠﻰ ﺧطﺄ1  إذا ﻛﺎن اﻟﻧص ﺻﺣﯾﺣًﺎ، أو0 <: ﯾﺣدد ﻣﺎ إذا ﻛﺎن ھﻧﺎك ﺧطﺄ؛ أدﺧلError Flag> *\n إذا ﻛﺎن اﻟﻧص ﺻﺣﯾﺣًﺎ، أو رﻗم اﻟﺟﻣﻠﺔ إذا ﻛﺎن ھﻧﺎك ﺧطﺄ1- <: ﻣﻌرّف اﻟﺟﻣﻠﺔ اﻟﺗﻲ ﺗﺣﺗوي ﻋﻠﻰ اﻟﺧطﺄ؛ أدﺧلError Sentence ID> *\n إذا ﻛﺎن اﻟﻧص ﺻﺣﯾﺣًﺎ، أو أدﺧل اﻟﺟﻣﻠﺔ اﻟﻣﺻﺣﺣﺔ ﺑﯾن ﻋﻼﻣﺗﻲ ﺗﻧﺻﯾص إذا ﻛﺎن ھﻧﺎك ﺧطﺄNA <: اﻟﺟﻣﻠﺔ اﻟﻣﺻﺣﺣﺔ؛ أدﺧلCorrected sentence> *\n.ﻻ ﺗُرﺟﻊ أي ﺗﻔﺳﯾرات أو ﻧص إﺿﺎﻓﻲ أو أي ﺗﻧﺳﯾق آﺧر\n:ﯾﺟب أن ﯾﻛون اﻹﺧراج ﻓﻲ ﺳطر واﺣد ﻓﻘط، ﺑﺻﯾﻐﺔ ﻣن اﻟﺻﯾﻐﺗﯾن اﻟﺗﺎﻟﯾﺗﯾن\n<Text ID> 0 -1 NA :إذا ﻛﺎن اﻟﻧص ﺻﺣﯾﺣًﺎ، أرﺟﻊ\n<Text ID> 1 <Error Sentence ID> <Corrected sentence> :إذا ﻛﺎن اﻟﻧص ﯾﺣﺗوي ﻋﻠﻰ ﺧطﺄ، أرﺟﻊ\n:اﻵن، ﯾرﺟﻰ ﻣراﺟﻌﺔ اﻟﻧص اﻟﺗﺎﻟﻲ\nText ID: {text_id}\n{text}\nFigure S4: Prompt Used in MedErrBench-Ara Construction.\n18\n"}, {"page": 19, "text": "Figure S5: Cross-lingual performance comparison of LLMs on Chinese-origin tasks.\n19\n"}, {"page": 20, "text": "Figure S6: Examples for Error Insertion in MedErrBench-EN.\n20\n"}, {"page": 21, "text": "Figure S7: Examples for Error Insertion in MedErrBench-CN.\nFigure S8: Examples for Error Insertion in MedErrBench-Ara.\n21\n"}, {"page": 22, "text": "Figure S9: Illustrative Examples of the Ten Error Types Defined in the MedErrBench-EN.\n22\n"}, {"page": 23, "text": "Figure S10: Illustrative Examples of the Ten Error Types Defined in the MedErrBench-CN.\n23\n"}, {"page": 24, "text": "Figure S11: Illustrative Examples of the Ten Error Types Defined in the MedErrBench-Ara.\n24\n"}]}