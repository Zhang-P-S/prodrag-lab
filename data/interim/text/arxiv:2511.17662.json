{"doc_id": "arxiv:2511.17662", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2511.17662.pdf", "meta": {"doc_id": "arxiv:2511.17662", "source": "arxiv", "arxiv_id": "2511.17662", "title": "Enhancing Breast Cancer Prediction with LLM-Inferred Confounders", "authors": ["Debmita Roy"], "published": "2025-11-20T22:19:31Z", "updated": "2025-11-20T22:19:31Z", "summary": "This study enhances breast cancer prediction by using large language models to infer the likelihood of confounding diseases, namely diabetes, obesity, and cardiovascular disease, from routine clinical data. These AI-generated features improved Random Forest model performance, particularly for LLMs like Gemma (3.9%) and Llama (6.4%). The approach shows promise for noninvasive prescreening and clinical integration, supporting improved early detection and shared decision-making in breast cancer diagnosis.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2511.17662v1", "url_pdf": "https://arxiv.org/pdf/2511.17662.pdf", "meta_path": "data/raw/arxiv/meta/2511.17662.json", "sha256": "653c00102a2693a3437f1fc1de4bd3e8f36302582ec5ae950bd0311837e7742b", "status": "ok", "fetched_at": "2026-02-18T02:26:34.018494+00:00"}, "pages": [{"page": 1, "text": "Enhancing Breast Cancer Prediction with LLM-Inferred Confounders​\nDebmita Roy \nWheeler High School, Marietta, GA \n \nAbstract  \nThis study enhances breast cancer prediction by using large language models to infer the likelihood of confounding \ndiseases, namely diabetes, obesity, and cardiovascular disease, from routine clinical data. These AI-generated \nfeatures improved Random Forest model performance, particularly for LLMs like Gemma (3.9%) and Llama (6.4%). \nThe approach shows promise for noninvasive prescreening and clinical integration, supporting improved early \ndetection and shared decision-making in breast cancer diagnosis. \nIntroduction  \nBreast cancer (BC) is a leading cause of death among women in the U.S., with most cases having unknown causes \ndespite known risk factors1. Researchers have identified correlations between BC and various clinical features and \nbiomarkers, such as body mass index, glucose, insulin, leptin, adiponectin, resistin, MCP-1, and HOMA, that can be \nmeasured through routine blood tests. Machine learning (ML) models using these features have been developed to \nsupport BC prediction and screening2. However, understanding confounding diseases is critical when using these \nmetabolic and inflammatory biomarkers to predict BC, because many other diseases can alter these markers, \nreducing specificity. A literature review identified Type-2 Diabetes, Obesity, and Cardiovascular Disease (CVD) as \nkey confounders3,4. In this paper, we propose to leverage Large Language Models (LLMs) to generate proxy \nmeasures for confounders not included in the original data and to integrate them with clinical features to enhance BC \nprediction models. This approach aims to mitigate confounding effects in prescreening, providing oncologists with \ncomprehensive insights to support BC diagnosis.  \nMethods  \nThis study used the Breast Cancer Coimbra dataset, which includes the above nine clinical features measured for 64 \npatients with BC and 52 healthy controls2. From the Together AI platform, we selected two LLMs with different \nsizes, Llama-3.3-70B (Meta, 70 billion parameters)5 and Gemma-2-27B (Google, 27 billion parameters)6, for \ninference via API service. We prompted both models with each patient's clinical features to estimate the likelihood \n(probability scores between 0 and 1) of having three confounding diseases: Diabetes, Obesity, and CVD. As a \nbenchmark, we also used the models to predict the likelihood of breast cancer itself. These four AI-generated \nsynthetic features were augmented to the original nine features. To evaluate model performance, we randomly split \nthe data into 20 different 80/20 train-test pairs. For each split, we trained Random Forest classifiers under several \nfeature configurations: (1) Baseline - Original nine clinical features; (2) LLM-only - LLM-generated breast cancer \nlikelihood; (3) Single-confounder - Nine features with one confounder likelihood (Diabetes, Obesity, or CVD); and \n(4) All-confounders - Nine features with all three confounder likelihoods. Performance metrics (accuracy, precision, \nrecall, AUC, and specificity) were averaged across all 20 iterations to obtain more stable and less biased estimates of \nthe model's performance. Standard errors indicated variability, and the pipeline was run separately for both Llama \nand Gemma, but it is compatible with any LLM accessible via API.  \nResults \nThe Random Forest classifier’s performance across feature configurations using both LLMs is summarized in Table \n1. As expected, the LLM-only setup performed the weakest, while adding a single confounder consistently \noutperformed the baseline for both models. The wAllConfounders configuration produced the highest gains, \nimproving over the baseline by an average of 3.9% (Gemma) and 6.4% (Llama). Figure 1 illustrates that Llama \ngenerally outperformed Gemma in this setup, except on recall—likely due to its larger model size and stronger \nability for meta-learning. Overall, incorporating AI-generated synthetic features improved predictions above \nbaseline, highlighting their potential to reduce confounder effects and enhance clinical integration. \nDiscussion and Conclusions \nThis study shows that LLM-generated confounder likelihoods can improve BC prediction using routine clinical data. \nAugmenting features with inferred risks of diabetes, obesity, and CVD boosted model performance, particularly with \nlarger models like Llama. Despite promising results, limitations include a small, homogeneous dataset and a lack of \naccess to more powerful LLMs. Future work should involve larger, more diverse cohorts, additional confounders \n(e.g., Polycystic Ovary Syndrome7, autoimmune diseases), additional systemic conditions (e.g., anemia)8, and \nincorporating interpretability by generating explanations for confounder likelihoods for enhancing clinical trust. \nOverall, this approach shows promise for improving early breast cancer screening and supporting Human-AI shared \ndecision-making, especially when integrated into electronic health record systems. \n"}, {"page": 2, "text": "Table 1. Performance metrics of Random Forest classifier under feature configurations: (1) Baseline - Original nine \nclinical features; (2) LLM-only - LLM-generated breast cancer likelihood; (3) Single-confounder - Nine features \nwith one confounder likelihood (Diabetes, Obesity, or CVD); and (4) All-confounders - Nine features with all three \nconfounder likelihoods. The performance corresponding to the LLMs, Gemma and Llama, is displayed separately.  \n \n \n \nBaseline \nClassifier \nGemma-2-27B \nBaseline \nClassifier \nLlama-3.3-70B \n \nLLM \nwDiabetes \nwCVD \nwObesity \nwAllConfounders \nLLM \nwDiabetes \nwCVD \nwObesity \nwAllConfounders \nAccuracy \n0.719 \n0.645 \n0.725 \n0.731 \n0.733 \n0.746 \n0.704 \n0.674 \n0.712 \n0.719 \n0.715 \n0.750 \nPrecision \n0.718 \n0.695 \n0.720 \n0.723 \n0.729 \n0.742 \n0.692 \n0.668 \n0.695 \n0.705 \n0.702 \n0.749 \nRecall \n0.619 \n0.437 \n0.630 \n0.644 \n0.636 \n0.667 \n0.674 \n0.594 \n0.661 \n0.672 \n0.661 \n0.683 \nAUC \n0.710 \n0.626 \n0.715 \n0.721 \n0.725 \n0.740 \n0.711 \n0.664 \n0.716 \n0.721 \n0.716 \n0.753 \nSpecificity \n0.801 \n0.814 \n0.801 \n0.798 \n0.813 \n0.813 \n0.749 \n0.734 \n0.770 \n0.770 \n0.771 \n0.822 \n \n  \nFigure 1. Performance comparison with error bars for a baseline Random Forest (RF) classifier vs a RF classifier \ntrained in the All-confounders configuration. In terms of percentage improvement over baseline, Llama consistently \noutperformed Gemma in the All-confounders setup across all metrics, except recall. \n \nAcknowledgments \nThe author would like to thank Dr. Wang Zhang from the Massachusetts Institute of Technology for his invaluable \nmentorship throughout this project, including weekly guidance on problem formulation, machine-learning concepts, \nAI model inference, and experimental iterations. His feedback during the implementation phase and manuscript \npreparation greatly strengthened the quality of this work. The author also wishes to thank Dr. Subhro Das from the \nMIT-IBM Watson AI Lab for his mentorship and for inspiring a deeper interest in research in this field. \nReferences​\n \n1.​\nObeagu EI, Obeagu GU. Breast cancer: A review of risk factors and diagnosis. Medicine. 2024 Jan \n19;103(3):e36905. \n2.​\nPatrício M, Pereira J, Crisóstomo J, Matafome P, Gomes M, Seiça R, Caramelo F. Using resistin, glucose, age \nand BMI to predict the presence of breast cancer. BMC Cancer. 2018 Jan 4;18(1):29. \n3.​\nTilg H, Moschen AR. Adipocytokines: Mediators linking adipose tissue, inflammation and immunity. Nature \nreviews immunology. 2006 Oct 1;6(10):772-83. \n4.​\nCao H. Adipocytokines in obesity and metabolic disease. Journal of Endocrinology. 2014 Feb 1;220(2):T47-59. \n5.​\nDubey A, Jauhri A, Pandey A, Kadian A, Al-Dahle A, Letman A, Mathur A, Schelten A, Yang A, Fan A, Goyal \nA. The Llama 3 herd of models. arXiv e-prints. 2024 Jul:arXiv-2407. \n6.​\nTeam G, Riviere M, Pathak S, Sessa PG, Hardin C, Bhupatiraju S, Hussenot L, Mesnard T, Shahriari B, Ramé \nA, Ferret J. Gemma 2: Improving open language models at a practical size. arXiv preprint arXiv:2408.00118. \n2024 Jul 31. \n7.​\nHemati A, Amini L, Haghani S, Hashemi EA. Investigation of the relationship between breast cancer and \nclinical symptoms of polycystic ovarian syndrome: A case-control study. BMC Women’s Health. 2024 \nFeb;24(1):586. https://doi.org/10.1186/s12905-024-03421-4. \n8.​\nChen X, Zhou H, Lv J. The importance of hypoxia-related to hemoglobin concentration in breast cancer. Cell \nBiochemistry and Biophysics. 2024 Sep;82(3):1893-906. \n"}]}