{"doc_id": "arxiv:2512.18440", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2512.18440.pdf", "meta": {"doc_id": "arxiv:2512.18440", "source": "arxiv", "arxiv_id": "2512.18440", "title": "An Agentic AI Framework for Training General Practitioner Student Skills", "authors": ["Victor De Marez", "Jens Van Nooten", "Luna De Bruyne", "Walter Daelemans"], "published": "2025-12-20T17:26:39Z", "updated": "2025-12-20T17:26:39Z", "summary": "Advancements in large language models offer strong potential for enhancing virtual simulated patients (VSPs) in medical education by providing scalable alternatives to resource-intensive traditional methods. However, current VSPs often struggle with medical accuracy, consistent roleplaying, scenario generation for VSP use, and educationally structured feedback. We introduce an agentic framework for training general practitioner student skills that unifies (i) configurable, evidence-based vignette generation, (ii) controlled persona-driven patient dialogue with optional retrieval grounding, and (iii) standards-based assessment and feedback for both communication and clinical reasoning. We instantiate the framework in an interactive spoken consultation setting and evaluate it with medical students ($\\mathbf{N{=}14}$). Participants reported realistic and vignette-faithful dialogue, appropriate difficulty calibration, a stable personality signal, and highly useful example-rich feedback, alongside excellent overall usability. These results support agentic separation of scenario control, interaction control, and standards-based assessment as a practical pattern for building dependable and pedagogically valuable VSP training tools.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2512.18440v1", "url_pdf": "https://arxiv.org/pdf/2512.18440.pdf", "meta_path": "data/raw/arxiv/meta/2512.18440.json", "sha256": "954f349a307fc56b0ef79e9c6f52daa4fce623fffb474ad0ecfe4260d5070259", "status": "ok", "fetched_at": "2026-02-18T02:24:02.264981+00:00"}, "pages": [{"page": 1, "text": "1\nAn Agentic AI Framework for Training General Practitioner Student\nSkills\nVictor De Marez, Jens Van Nooten, Luna De Bruyne, and Walter Daelemans\nThis work has been submitted to the IEEE for possible publication. Copyright may be transferred\nwithout notice, after which this version may no longer be accessible.\nAbstract—Advancements in large language models offer strong\npotential for enhancing virtual simulated patients (VSPs) in\nmedical education by providing scalable alternatives to resource-\nintensive traditional methods. However, current VSPs often strug-\ngle with medical accuracy, consistent roleplaying, scenario gen-\neration for VSP use, and educationally structured feedback. We\nintroduce an agentic framework for training general practitioner\nstudent skills that unifies (i) configurable, evidence-based vignette\ngeneration, (ii) controlled persona-driven patient dialogue with\noptional retrieval grounding, and (iii) standards-based assessment\nand feedback for both communication and clinical reasoning.\nWe instantiate the framework in an interactive spoken consul-\ntation setting and evaluate it with medical students (N=14).\nParticipants reported realistic and vignette-faithful dialogue,\nappropriate difficulty calibration, a stable personality signal, and\nhighly useful example-rich feedback, alongside excellent overall\nusability. These results support agentic separation of scenario\ncontrol, interaction control, and standards-based assessment as\na practical pattern for building dependable and pedagogically\nvaluable VSP training tools.\nIndex Terms—Agentic AI, evidence-based medicine, large lan-\nguage models, medical education, virtual simulated patients.\nI. INTRODUCTION\nI\nN medical education worldwide, simulated patients (SP),\nwhich are trained actors who portray patients with prede-\nfined symptoms and behaviors [1], are used to teach essential\nskills such as history taking and communication skills, and\nexplaining a diagnosis. They are also a traditional part of\nthe Objective structured clinical exams (OSCE) assessment\nof students, in which they are meant to focus on a specific\nskill, so that SPs are used to systematically measure clinical\nand communication skills in a standardized way [2].\nHowever, training and hiring these qualified SPs is a pro-\ncedure that requires substantial investments in resources and\ntime [3]. Furthermore, despite rigorous training efforts, perfect\nreplicability of the scenario is impossible due to inherent hu-\nman variance and errors. Additionally, the educational setting\nwith an SP can be distracting and stressful due to the presence\nof the tutor and other students [3].\nVirtual Simulated Patients (VSPs) are computer simulations\nof real-life patients programmed with clinical vignettes (clin-\nical scenarios that include patient information) that allow a\nManuscript received December 20, 2025. This research received funding\nfrom the Flemish Government under the “Onderzoeksprogramma Artifici¨ele\nIntelligentie (AI) Vlaanderen” programme. (Corresponding author: Victor De\nMarez.)\nVictor De Marez, Jens Van Nooten, Luna De Bruyne and Walter Daelemans\nare with the Center for Computational Linguistics, Psycholinguistics and\nSociolinguistics (CLiPS), University of Antwerp, Antwerp, Belgium (e-mail:\nfirstname.lastname@uantwerpen.be).\nThis\narticle\nhas\nsupplementary\ndownloadable\nmaterial\navailable\nat\nhttps://doi.org/...\nDashboard\nNeuroticism\nOpenness\nAgreeableness\n...\nConversation history\nRAG EBM\nvector DB\nEBM disease\ninformation\nVignette\nGenerator Agent\nPatient vignette\nPatient vignette\nVSP Agent\n1. Multi-step pre-process\n2. Generate answer\n3. Checklist post-process\nStudent doctor\nCritic Agent\nDuring conversation \nquick, short, feedback on \ncommunication \nAfter conversation\ndetail, long, feedback on \ncommunic. & diagnostics\nEBM disease\ninformation\nFeedback framework\n1\n2\n3\n4\nConv. history\nFig. 1.\nCore schema of the four main contributions of our framework:\nclinical vignette generation, a three-step VSP generation method, personality\ncustomization, and automated feedback generation\n.\nlearner to obtain a medical history, make a diagnosis, and\nprescribe a treatment plan [4]. Initially, VSPs were costly, and\nlimited in realism, natural language capabilities, effectiveness\nand applicability. However, advances in artificial intelligence\nhave accelerated development of VSPs [5], [6], thereby of-\nfering effective solutions to the aforementioned problems of\nSPs. Despite their initial limitations, VSPs offer multiple\nadvantages over SPs. For instance, virtual patients can be used\nby unlimited learners at virtually no incremental cost, therefore\nbeing more cost-friendly and less resource-intensive [7]. This\nscalability allows for interaction beyond stressful educational\nsettings, for instance from home. Moreover, VSPs can be\nconfigured to follow a predefined vignette consistently and\nto incorporate a larger number of case details than is typically\nfeasible for human actors.\nEarly VSPs were mainly comprised of rule-based backends,\nas in [8]. More recently, large language models (LLMs) such\nas GPT-4o [9] have largely replaced rule-based systems due\nto their ability to provide human-like responses. Due to their\nlong context lengths and contextual understanding, LLMs are\nshown to be promising for creating realistic and real person-\nbased agents with various personalities for simulating per-\nsonas. For this reason, they are already used in various educa-\narXiv:2512.18440v1  [cs.CL]  20 Dec 2025\n"}, {"page": 2, "text": "2\ntional fields [10]–[12]. Nonetheless, LLMs come with several\nchallenges for educational and agentic contexts, complicating\ntheir integration into VSPs. For example, a hallucinating LLM\ncan give plausible but inaccurate information, whether it is\nincorrect information relative to a VSP’s scenario or inaccurate\nfeedback in a critic agent [12]. If these hallucinations result in\nmedical incorrectness, despite the vast medical knowledge in\nthese LLMs, agents become unreliable [13]. Additionally, bias\nin large language models can lead to symptoms or conditions\nbeing linked to certain stereotypes more often, making students\nunprepared for real-world use cases [14].\nThe intersection of VSPs and LLMs leads to challenges\nof their own kind. Without thorough prompting and control,\na roleplaying LLM tends to lose its verbal communication\nstyle beyond 4–6 turns, shifting back to its initial agreeable\nhelpful assistant tone [15]. Additional difficulty comes from\nthe side of the end users. For instance, students tend to\ndislike a VSP more when it is unrealistic, limited in natural\nresponses, repetitive, or when the task is too difficult [16].\nThe latter can be the case if VSP objectives are not aligned\nwith educational goals in medical training, which is often the\ncase in current VSPs due to a lack of educational frameworks\n[17], [18]. Finally, the clinical vignettes in VSPs are often real\ncases or developed by experts, while many different vignettes\nare needed to prevent fraud, for example when used as an\nassessment tool during student exams [14], [17].\nThese challenges motivate a VSP design that prioritizes\n(i) scenario diversity, (ii) scenario fidelity (patient facts\naccording to or consistent with the vignette), (iii) medical\ngrounding when clinical knowledge is required, (iv) stable\npersona expression across turns, and (v) standards-based\nassessment that produces actionable feedback aligned with\neducational rubrics rather than generic chatbot advice.\nTo address these challenges, we present an AI framework\nfor training general practitioner student skills. Our main con-\ntributions, as visualized in Fig. 1, are the following:\n•\n1\nScenario control: generation of consistent, medically\ngrounded VSP scenarios using evidence-based medicine\n(EBM) and LLMs, enabling configurable training cases\nat scale;\n•\n2\nBehavior reliability: a response control scheme that\nimproves scenario fidelity and reduces hallucinations by\nseparating (a) structured reasoning over the utterance\ntype, (b) optional retrieval augmentation when needed,\nand (c) a final constraint/cleanup step prior to delivery;\n•\n3\nPersona variation: customization of VSP interaction\nstyle via Big Five traits (openness, conscientiousness,\nextraversion, agreeableness, neuroticism), operationalized\nthrough prompt-based control;\n•\n4\nStandards-based assessment: automated feedback on\nstudent communication based on the Master Interview\nRating Scale [19] (25 criteria) and on diagnostic perfor-\nmance by comparing student actions against evidence-\nbased guidelines.\nThe remainder of the paper is structured as follows. Section\nII reviews recent related work. In Section III, the framework\nis described with its three agent roles: (i) a scenario generator,\n(ii) a conversational agent, and (iii) a standards-based critic.\nFinally, in Section IV, we evaluate the framework in an\ninteractive spoken consultation setting.\nII. RELATED WORK\nA. LLMs for VSPs\nThe use of Virtual Simulated Patients (VSPs) in medical\neducation predates recent advances in large language models\n(LLMs), with reviews highlighting their potential but also\nlimitations in realism, curricular integration, and particularly\nfeedback generation [16], [20], [21]. Early AI-driven VSPs\nrelied on rule-based systems or simple NLP techniques, often\nstruggling with conversational flexibility [22]. The advent of\npowerful LLMs like GPT-4 has opened new possibilities,\ndemonstrating strong baseline medical knowledge [23] and\nimpressive capabilities in diagnostic dialogues, even out-\nperforming physicians in some text-based evaluations [24].\nSeveral studies confirm the feasibility of using LLMs to\nsimulate patients for history taking and other interactions [25]–\n[30], often perceived positively by students for enabling safe,\nrepeatable practice [28], [31].\nB. VSP Behavior and Personality\nHowever, leveraging LLMs effectively for VSPs requires\naddressing key challenges identified in the introduction and\nexplored in recent work, particularly controlling LLM behavior\nto maintain role and personality fidelity and avoid halluci-\nnations [27], [31]. Approaches using knowledge graphs and\nretrieval-augmented generation show promise for grounding\nresponses in factual data for more reliable simulation [32]–\n[34]. Simulating diverse personalities and challenging com-\nmunication styles, beyond just conveying medical information,\nis another focus, with studies exploring sophisticated prompt\nengineering to model specific personas [15], although the\nfundamental limitations of LLMs in replicating deep human\nstates persist [35]. Our work incorporates personality with Big\nFive traits, building on these efforts.\nC. Vignette generation\nAutomating the creation of complete, diverse and inclusive\nclinical scenarios is another area where LLMs offer potential\n[14], [36]–[39]. These studies demonstrate a rapid generation\nand adaptation of vignettes for different contexts and diversity\nrequirements, using structured prompts and templates. Despite\nthese promising findings, very few studies incorporate these\nartificial vignettes in their LLM-based conversation generation\npipelines. For example, [24] introduce AMIE, a fine-tuned\nversion of PaLM 2 for diagnostic dialogue, and include a\nvignette generation module, moderator, dialogue, critic and\ndoctor agent. Additionally, [40] generate clinically grounded\nvignettes using Claude 3.5 Sonnet, which are evaluated by do-\nmain experts. These vignettes are then used as a foundation for\nthe VSP during conversations. [41] adopt a similar approach\nby integrating artificial vignettes into a conversation pipeline\nusing LLMs. Our generator agent adopts similar principles as\nthese studies, but integrates EBM grounding, and configurable\nparameters for difficulty and personality.\n"}, {"page": 3, "text": "3\nCentral backend server\nStudent doctor\nCritic agent\nVignette Generator Agent\n[\nFeedback\nframeworks\n[\n[\nConversation\nhistory\n[\n[\nPatient vignette ]\nFurhat application\nDashboard\nVirtual Simulated Patient Agent\n[\nEBM disease\ninformation\n[\nLLM Provider\nMedical DB\nTTS / STT\nProvider\nFig. 2. Component diagram with the core contributions from Fig. 1 to the other components in the framework.\nD. Automated Feedback\nWhile the educational aspect of automated feedback is gaining\ntraction, it is often lacking or underdeveloped in VSP literature\n[16], [21]. Some systems incorporate AI-powered feedback\non transcripts [26], [31], use LLM ensembles on evaluation\nchecklists for assessment [34], or leverage LLMs to generate\nfeedback on limited parts of a consultation, such as history\ntaking in [42], or communication using Likert-scale scores\nin [43]. Other studies integrate checklists curated by domain\nexperts in prompts [44]. Unsupervised coevolution frameworks\nlike EvoPatient also implicitly involve feedback through expe-\nrience gathering [33]. However, these approaches either lack\neducational grounding such as evaluation frameworks, rely\non checklist conversions that are not available with generated\nvignettes, or are very narrow in scope.\nRelative to these studies, our key contribution lies in\npresenting a framework that integrates configurable scenario\ngeneration, controlled persona-driven interaction, and com-\nprehensive, standards-based automated feedback, addressing\nlimitations throughout the full VSP training lifecycle often\ntackled piecemeal in previous research.\nIII. SYSTEM ARCHITECTURE\nThe framework uses a distributed, three-tier architecture com-\nprising a web-based client dashboard, a central Python back-\nend server, and an embodied agent application running on the\nFurhat platform1 (Fig. 3). An overview can be found in Fig.\n2, and a more elaborate version in the Appendix.\nA training session proceeds as follows. The student con-\nfigures VSP parameters or selects a predefined case in the\ndashboard (Section III-B). The generator agent then creates\na detailed patient vignette on the backend server (Section\nIII-A). During the consultation, the student interacts through\nspoken dialogue: the Furhat application handles real-time\nspeech-to-text and text-to-speech I/O (Section III-C), while the\nconversational VSP agent and critic agent run on the backend\n1[Online]. Available: https://furhatrobotics.com/\nFig. 3. A Furhat robotic head embodying the speech-to-text and text-to-speech\nof the VSP agent.\nserver. The critic produces both in-session quick tips and post-\nsession standards-based feedback, which is delivered back to\nthe dashboard for review. A full end-to-end example using the\nframework is provided in the Supplementary Material.\nA. Central backend server\nThe central backend server, built in Python, acts as the\norchestration hub and hosts the core agentic logic. It is\nresponsible for maintaining the overall state of the simulation,\nincluding conversation history, patient status, and feedback\ndata. It manages persistent WebSocket connections from both\nthe web client and the Furhat application. All three key AI\nagents are housed on the server: the scenario generator agent,\nthe VSP conversational agent, and the feedback critic agent.\nWe employ a tiered model architecture to balance medical\nfidelity against conversational latency. For asynchronous tasks\nrequiring high adherence to EBM sources and complex eval-\nuation rubrics (generator and critic agents), we utilize GPT-\n4.1, prioritizing instruction-following reliability and grounded,\nstructured outputs over runtime. Conversely, for the syn-\nchronous VSP conversational agent, we prioritize low latency\n"}, {"page": 4, "text": "4\nto maintain natural spoken dialogue. We therefore utilize\nLlama 4 variants for core reasoning and open-weight control,\npaired with GPT-4o-mini for high-speed, cost-efficient post-\nprocessing and formatting.\nThe full flow of these agents can be found in the Appendix.\n1) Generator agent (•\n1\nand •\n3 ): The generator agent\nimplements the automated VSP scenario creation. Upon re-\nceiving configuration input (desired disease difficulty, Big Five\npersonality scores) from the client, it initiates a generation\nprocess. All prompts can be found in the Supplementary\nMaterial.\n1) Disease selection and difficulty adjustment: A dis-\nease is picked randomly from a selection of the list of\ndiseases and problems in the educational standards for\nstudents finishing the basic medical training at the Faculty\nof Medicine and Health Sciences in the University of\nGhent2. This represents a realistic Flemish educational\ncontext. The difficulty of the entire selection was previ-\nously judged by GPT 4.1 on a Likert scale from 1 to 10.\nUsing prompt engineering, complicating or easing factors\n(e.g., allergies, comorbidities) for the patient vignette are\ngenerated based on the evidence-based medicine (EBM)\npages pre-coupled with the chosen disease.\n2) Vignette generation: The agent prompts GPT-4.1 to\ngenerate a detailed patient vignette adhering to a struc-\ntured template distilled from the University of Tennessee\nHealth Science Center3, incorporating modifications sug-\ngested in the previous step to match the target difficulty.\n3) Consistency check and refinement: The generated vi-\ngnette undergoes a final check with GPT-4.1 to identify\nand correct between elements of the vignette.\n4) Persona selection: An appropriate Furhat face and\nElevenLabs voice are selected via another GPT-4.1 call,\ngiven the vignette content.\n5) Personality translation: Finally, the Big Five personality\nscores are translated to a textual prompt using the con-\nversion table given in the Appendix for more relevance\nin the context of patient communication, hereby partially\nrealizing contribution •\n3 . These texts are used when\npersonality is included in prompts of the VSP agent.\nThis process ensures scenarios are not only configurable\nbut also grounded in medical data and internally consistent.\nTherefore, the generation process above fully covers our main\ncontribution•\n1 .\n2) VSP conversational agent (•\n2\nand •\n3 ):\nThe VSP\nconversational agent manages the dialogue flow and imple-\nments the controlled response generation. When it receives\ntranscribed user speech (doctor’s utterance) from Furhat, it\nexecutes a multi-step reasoning pipeline to determine the\nresponse:\n1) Utterance\npreprocessing: An initial LLM call to\nLLaMA 4 Scout [45] analyzes the doctor’s last utterance\nin the context of the conversation history and patient\n2[Online].\nAvailable:\nhttps://www.ugent.be/ge/nl/studenten/\nopleidingsspecifieke-informatie/stages/eindtermen/hoofdstuk3.pdf\n3[Online].\nAvailable:\nhttps://webprod8.uthsc.edu/simulation/resources/\ncase-development.php\nvignette to classify the required response type (e.g.,\nanswer directly from vignette, requires external knowl-\nedge, question already answered, no question asked). The\ndecision flow can be found in Fig. 4, and the full prompt\nin the Supplementary Material. An exception to this step\nis the first message, where a custom first message prompt\nthat includes the personality and vignette, is automatically\nchosen, and the next step is skipped.\n2) Information retrieval (conditional): Based on the pre-\nprocessing decision, the agent decides on the generation\nprompt and included information in there (cf. Fig. 4;\nthe full prompt can be found in the Supplementary\nMaterial). If the answer is likely in the vignette, it uses\nthat information. If external medical knowledge is needed\n(e.g., typical duration of a symptom not specified in the\nvignette), it formulates a query and uses a RAG pipeline\n(LlamaIndex [46] with a vector database containing EBM\narticles) to retrieve relevant medical context. If common\nsense is sufficient, it proceeds without RAG.\n3) Response generation: LLaMA 4 Maverick [45] gener-\nates a draft response given the chosen generation prompt\nsupplemented with the retrieved information (this can\ninclude vignette and RAG context), the conversation\nhistory, and the personality texts.\n4) Personality and post-processing: A final LLM call to\nGPT-4o-mini (prompt in the Supplementary Material) re-\nfines the draft response. This critical step ensures the an-\nswer adheres strictly to the textual personality constraints,\navoids making diagnoses or proposing treatments (unless\nechoing the doctor), maintains consistency, and fits con-\nversational norms, such as a removal of thoughts, actions,\nor descriptions beyond the patient’s spoken words.\nThis pipeline prioritizes fidelity to the scenario and medical\ncorrectness (via RAG and constraints) while incorporating\npersonality and mitigating hallucinations, and therefore covers\nour main contribution•\n2 . The generation step, but mostly the\npost-processing step, ensure main contribution•\n3 .\n3) Critic agent (•\n4 ): The critic agent provides automated\nstandards-based feedback. All prompts can be found in the\nSupplementary Material.\n• Communication feedback: Feedback generation occurs\nin two phases, using the conversation transcript and eval-\nuation frameworks to prompt language models. During\nthe conversation, GPT-4o-mini is prompted based on the\nbest practices of [47] to provide concise, actionable quick\ntips. After the session, a detailed analysis is performed\nby prompting GPT-4.1 based on the Master Interview\nRating Scale (MIRS) [19]. GPT-4.1 returns scores on a\n1-5 Likert scale and textual justifications supported by\nquoted evidence for each MIRS item, generated with a\ntemperature setting of 0.1.\n• Clinical feedback: Post-session, the agent prompts GPT-\n4.1 to compare the student’s implicit diagnostic reasoning\nand proposed management (extracted from the conversa-\ntion) against the gold standard evidence-based common\npractice information derived from the EBM sources pre-\ncoupled with the generated disease. It provides structured\n"}, {"page": 5, "text": "5\nQ1: Out-\nof-scope?\nQ5: Question \nneeds medical \ncorrectness?\nQ4: Answer\nin vignette?\nQ3: Answer in \nchat history?\nQ2: Question \npresent?\nNo\nNo\nYes\nNo\nEBM RAG\nfor question\nYes\nLLM Call\n(case-specific prompt + \nconveration history)\n+ RAG result\n+ patient vignette\nYes\nNo\nYes\nYes\nNo\nFig. 4. Multi-step pre-processing and RAG steps of the VSP agent before response generation. The corresponding prompt can be found in the Supplementary\nMaterial.\nFig. 5. Screenshot of the client dashboard. The left side contains the conversation log, the avatar controls and the immediate feedback. The right side contains\nthe VSP configuration parameters, the patient generation launch button, and the generation log button.\nfeedback across predefined clinical categories: diagnosis,\ntreatment planning, follow-up and monitoring, adherence\nto guidelines, risk assessment, test and investigation or-\ndering, and preventive care.\nThis feedback, corresponding to contribution•\n4 , is then sent\nto the client dashboard via WebSockets.\nB. Client dashboard\nThe client dashboard (Fig. 5), developed using the Python\nNiceGUI framework [48], serves as the primary user inter-\nface. It allows users to configure training scenarios (selecting\ndisease difficulty and personality parameters), monitor the\nongoing conversation log, view real-time and final feedback,\nand control the simulation state (e.g., pause, resume, launch\npredefined patients). Communication between the client and\nthe server is handled exclusively via WebSockets.\nC. Furhat application\nThe Furhat application, developed in Kotlin, runs on the\nFurhat robot or its virtual equivalent. Using its WebSocket\nconnection to the central server, its primary roles are real-time\nspeech-to-text (STT) transcription of the user’s voice input and\ntext-to-speech (TTS) synthesis of the VSP agent’s responses.\nWhile the Furhat component handles the physical or virtual\nembodiment and direct speech I/O, the cognitive processing\nand decision-making for the VSP’s responses reside entirely\non the backend server.\nIV. EVALUATION\nA. Methodology\nWe evaluated our framework’s four main contributions (cf. Fig.\n1) with a user study involving five late undergraduate and nine\ngraduate-level medical students (total N=14) at the University\nof Antwerp (Belgium). Participants provided informed consent\nand indicated being open to conducting the consultation with a\nVSP in English. Each evaluation session took place in person,\nwith one user and one instructor present. The evaluation\nalternated between (i) interacting with the Furhat-based VSP\nin English and (ii) completing a laptop-based survey in Dutch.\nThe evaluation comprised four consecutive parts:\n1) Pre-intervention questionnaire\n2) Case 1: The instructor introduced the dashboard and\nasked the participant to interact with a VSP (predefined\ndifficulty, personality, and vignette) to find the correct\ndiagnosis. The VSP was loaded into the Furhat and the\nconversation had no time limit. After ending the inter-\naction and reading the automatically generated feedback,\nthe participant completed a case-specific post-intervention\nquestionnaire. The diagnosis was acute simple cystitis.\n"}, {"page": 6, "text": "6\n3) Case 2: The same procedure was repeated for a second\nVSP, followed by a case-specific post-intervention ques-\ntionnaire. The diagnosis was pancreatitis.\n4) Final post-intervention questionnaire\nThe questionnaire was structured in blocks aligned with the\nprocedure: one pre-intervention block, two case-specific post\nblocks (after each patient), and one final post block. Most\nquestions used 5-point Likert scales and were complemented\nby open-ended questions.\nThe pre-intervention block captured study phase, prior ex-\nperience with multiple simulation modalities, and baseline per-\nceptions of simulation-based training and AI tools in medical\neducation.\nEach case-specific post questionnaire assessed medical real-\nism, perceived difficulty, perceived inconsistencies, perceived\nBig Five personality (trait ratings + consistency item), useful-\nness of quick tips, and perceived clarity/accuracy/usefulness\nof generated feedback (communication and clinical).\nThe final post block assessed overall realism, ease of\nuse, intention to reuse/recommend, practical constraints (e.g.,\nwaiting time, embodiment, language), included the System\nUsability Scale (SUS) [49], which is a standardized ten-item\nquestionnaire widely used to measure perceived usability of\na system, and concluded with open-ended questions about\nstrengths, weaknesses, and integration in the curriculum.\nThe full (translated) survey is included in the Supplementary\nMaterial.\nB. Results and discussion\nTable I summarizes the quantitative outcomes.\nIn the pre-intervention questionnaire, participants reported\nsubstantial prior experience with actor-based simulated pa-\ntients, but limited exposure to virtual simulated patients and\nespecially to AI-driven virtual patients. This suggests that for\nmost participants, this was their first encounter with an AI-\nbased VSP.\nIn the case-specific questionnaires, students rated the med-\nical realism of both VSPs positively, and no participant\nreported inconsistencies or incorrect information during the\nconversations. In an open question about the framework’s\nstrengths, 85% of students (counting mentions) emphasized\nthe realism of the VSP responses. The perceived difficulty of\nthe interactions was rated close to the generated difficulty of\n5/10. This suggests a correct calibration of the generator agent\nand the VSP conversational agent (•\n1 and•\n2 ).\nAfter reading an informational text about the Big Five\ntraits, participants rated both patients’ personalities. Figure 6\ncompares the scripted profiles with student estimates. The\nstudents’ scores cluster tightly (SD ≈1; SE ≈0.30) and\nyield narrow 95% CIs (± 0.6–0.7). Within those intervals, the\ntwo patients show a clear, reproducible profile, most notably\na +1.05 point gap in extraversion. Personality consistency was\nrated high, indicating that the conversations conveyed a stable\npersonality signal. This also corresponds to the answers in an\nopen question on the personality, where 8 out of 14 students\nindicated the personality to be clear, credible, or realistic (•\n3 ).\nHowever, although consensus is high, accuracy is limited.\nFor both patients, three of five traits differ from the scripted\nO\nC\nE\nA\nN\n1\n2\n3\n4\n5\n(a) VSP 1: target profile (solid)\nvs student estimate mean (dashed)\nwith ±1 SD band (shaded).\nO\nC\nE\nA\nN\n1\n2\n3\n4\n5\n(b) VSP 2: target profile (solid)\nvs student estimate mean (dashed)\nwith ±1 SD band (shaded).\nO\nC\nE\nA\nN\n1\n2\n3\n4\n5\n(c) Comparison of student mean\nestimates: Person 1 (dashed) vs\nPerson 2 (dotted).\nFig. 6.\nRadar plots of Big Five personality (1–5 scale) of the two VSP\nscenarios in the evaluation, N = 14. O = Openness, C = Conscientiousness,\nE = Extraversion, A = Agreeableness, N = Neuroticism.\npersonality by ≥0.6 points and were significantly different in\none-sample tests (|t| ≥2.3, p ≤0.04). Students therefore\nagree with one another yet misjudge multiple traits. This\npattern has two plausible explanations: (i) the brief, verbal\ninteractions may support fast convergence on similar global\nimpressions while limiting mapping onto accurate Big Five\nscores (and constraining less observable traits) [50]–[52]; and\n(ii) there may be room to further refine how traits are expressed\nby the VSP conversational agent, for instance using more\ndetailed prompt engineering, few-shot learning or fine-tuning\n[53]–[55], or through mechanistic methods such as steering\nmodel internals [56].\nRegarding feedback, students reported high satisfaction with\nboth communication and clinical feedback, with item-level\nratings detailed in Table II. They particularly valued the\ninclusion of concrete dialogue excerpts in the communication\nfeedback, and they judged the feedback as well-aligned with\ntheir interaction and with known communication and clini-\ncal guidelines. Clarity was rated favorably overall, but 6/14\nstudents indicated the feedback was too long. The feedback\nwas consistently perceived as useful for identifying areas for\nimprovement. In contrast, the in-conversation quick tips were\nrated comparatively lower, suggesting they may be distracting\nwhen students follow a familiar consultation pattern. Overall,\nthese results suggest that the critic agent reliably delivers clear,\nguideline-concordant, example-rich commentary perceived as\nactionable, while leaving room to improve conciseness and\nreconsider the quick tips’ availability (•\n4 ).\n"}, {"page": 7, "text": "7\nTABLE I\nSUMMARY OF QUANTITATIVE EVALUATION OUTCOMES (N = 14).\nVALUES ARE MEAN (SD) AND USE A 5-POINT LIKERT SCALE UNLESS\nOTHERWISE NOTED\nMeasure\nCase 1\nCase 2\nBackground (reported once)\nExperience with actor-based SPs\n4.21 (0.70)\nExperience with virtual SPs\n1.71 (0.91)\nExperience with AI-driven virtual SPs\n1.57 (0.94)\nCase-specific outcomes\nMedical realism of VSP answers\n3.93 (0.62)\n3.64 (0.74)\nPerceived scenario difficulty (0–10)\n4.29 (2.06)\n6.07 (1.89)\nPersonality consistency\n4.21 (0.58)\n3.86 (0.77)\nUsefulness of quick communication\ntips\n2.79 (0.70)\n2.79 (0.89)\nCommunication\nfeedback\n(composite†; 5 items)\n4.23 (0.55)\n4.14 (0.74)\nIncludes relevant examples (single\nitem)\n4.43 (0.85)\n4.43 (0.65)\nClinical\nfeedback\n(composite†;\n4\nitems)\n4.32 (0.40)\n4.02 (0.69)\nOverall evaluation (reported once)\nOverall realism of interactions\n3.36 (0.50)\nInterest/engagement\n4.29 (0.61)\nRecommend to peers\n4.21 (0.97)\nRated 4 or 5\n11/14 (79%)\nReuse for other scenarios\n4.36 (0.74)\nRated 4 or 5\n12/14 (86%)\nBelief: VSPs prepare for station exam\n(pre →post)\n3.29 (0.47) →4.36 (0.84)\nSystem Usability Scale (SUS; 0–100)\n80.36 (10.37)\n†Item-level feedback ratings are reported in Table II.\nTABLE II\nITEM-LEVEL RATINGS OF THE AUTOMATICALLY GENERATED FEEDBACK.\nVALUES ARE MEAN (SD). ITEMS USE A 5-POINT LIKERT SCALE\nItem\nCase 1\nCase 2\nCommunication feedback (5 items)\nClear and easy to understand\n4.29 (0.73)\n3.93 (1.07)\nAccurately reflected my interaction\n4.07 (0.73)\n4.29 (0.83)\nAccurately\nreflected\ncommunication\nguidelines I know\n4.07 (0.83)\n3.93 (1.14)\nContained relevant examples from my\ninteraction\n4.43 (0.85)\n4.43 (0.65)\nUseful to identify areas for improvement\n4.29 (0.73)\n4.14 (1.10)\nClinical feedback (4 items)\nClear and easy to understand\n4.36 (0.63)\n3.79 (1.05)\nAccurately reflected my interaction\n4.36 (0.63)\n4.21 (0.80)\nAccurately reflected relevant medical\nguidelines I know\n4.00 (0.78)\n4.00 (0.96)\nUseful to identify areas for improvement\n4.57 (0.65)\n4.07 (1.14)\nIn the final post-intervention block, overall realism was rated\nmoderately, suggesting a VSP is more a supplement rather\nthan a replacement of real simulated patients. Engagement\nwas rated high and the intention to adopt the framework was\nlikewise strong, with high willingness to recommend it and to\nreuse it for other scenarios. Moreover, the participants’ belief\nthat VSP interactions would prepare them for their station\nexam increased from pre- to post-intervention.\nAcross open-ended responses, students most often high-\nlighted usability and scalability, medical accuracy, scenario\nrealism, and direct feedback. Reported improvement points\nincluded processing time (3.4s on average with an SD of\n1.84s, excluding outliers above Q3 + 1.5 · IQR, and an\nadditional 3-second listening timeout), and the lack of non-\nverbal communication on both the receiving and providing\nend. The SUS score indicated favorable usability [49].\nV. CONCLUSION\nTo address existing challenges in virtual simulated patients\n(VSPs), including realism, consistency, scenario generation\nfor simulation, and comprehensive feedback, we presented\nan agentic, LLM-based VSP framework to support the full\ntraining lifecycle of general practitioner (GP) skills: config-\nurable scenario creation, reliable persona-driven interaction,\nand standards-based assessment and feedback.\nThe framework separates concerns across three roles. The\ngenerator agent constrains the simulation by producing\nmedically grounded, configurable vignettes from evidence-\nbased medicine (EBM) sources. The conversational agent\nprioritizes scenario fidelity and medical grounding through a\ncontrolled generation pipeline (structured reasoning, optional\nretrieval augmentation, and a final constraint/cleanup step),\nwhile enabling systematic variation in interaction style via Big\nFive trait settings. The critic agent links transcript evidence\nto explicit standards by generating automated communication\nfeedback using MIRS and clinical feedback by comparison\nagainst EBM-derived guideline targets.\nWhile we instantiate these roles with specific models and\na spoken interaction setup, the framework is designed to\ngeneralize by swapping vignette templates, grounding sources,\nevaluation frameworks, and underlying language models with-\nout changing the overall control structure.\nIn a student evaluation (N=14), the VSP answers were\nrated medically realistic (mean ≈3.8/5), with no reported\ninconsistencies or incorrect scenario information. Perceived\ndifficulty was close to the targeted mid-level setting (mean\n≈5/10 across cases), suggesting effective calibration of\nscenario generation. Feedback after the conversation was a\nkey strength: both communication and clinical feedback were\nrated highly (overall ≈\n4.2/5), and students particularly\nvalued the inclusion of concrete dialogue excerpts to justify\nfeedback. However, always-on in-conversation quick tips may\nbe distracting. Usability and adoption intent were strong (SUS\n≈80), with high engagement, high willingness to recommend\nand reuse the system, and increased belief that VSP interac-\ntions can prepare students for station exams.\nBeyond these overall ratings, the results suggest three design\nimplications for LLM-based VSPs: (i) controlled grounding\nand structured response control can yield reliable, vignette-\nfaithful conversations (as reflected by the absence of reported\ninconsistencies) while still supporting adjustable difficulty;\n(ii) standards-based, example-rich post-session feedback\nis perceived as highly actionable, but must balance depth\nwith conciseness; and (iii) persona control can produce a\nstable and clearly perceived personality signal, but the current\n"}, {"page": 8, "text": "8\nsetup motivates calibrated persona controllers with behavior-\nbased evaluation, ensuring that intended trait settings translate\ninto consistently recognizable interaction patterns. General key\nareas for improvement are reducing processing time and ex-\ntending communicative realism through non-verbal behavior.\nVI. AVAILABILITY AND LICENSING\nThe source code is available at: https://github.com/Victordmz/\nagentic-framework-gp-skills.\nVII. LIMITATIONS AND FUTURE WORK\nWhile our framework effectively maintains personality fidelity,\nmedical accuracy in patient simulation, grounded vignette gen-\neration, and accurate feedback, several areas for improvement\nremain.\nFirst, the framework currently lacks integration of non-\nverbal communication. It neither captures non-verbal cues\nfrom the doctor nor allows the VSP to exhibit non-verbal\ncues toward the doctor, limiting communicative realism be-\nyond verbal interactions, and hindring empathy, impacting\ncommunication. Future collaboration with Human-Computer\nInteraction (HCI) experts could address this gap.\nAdditionally, we must address specific challenges observed\nduring user studies, such as overly extensive feedback, distract-\ning quick tips, and and the absence of physical examination\ncapabilities. We must also further investigate if there is an\ninaccurate reflection of certain personality trait combinations\nin conversations.\nFurther enhancements are needed in the three agents. The\ngenerator agent can be improved with an ability to create\nlongitudinal cases, adhere more closely to established best\npractices for OSCE case generation, expanding or adapting\npatient vignette templates, and more systematically defining\nthe difficulty levels of cases. The VSP conversational agent\nshould leverage recent research on personality integration (e.g.,\n[53]–[56]). Reducing generation latency is also desirable. The\ncritic agent could further benefit by incorporating frameworks\nspecifically tailored to various educational contexts.\nETHICAL CONSIDERATIONS\nTraining with VSPs should supplement, not replace, human\ninteraction and feedback from real educators and SPs where\nfeasible. The system should not be used for real diagnosis\nor treatment advice. Ensuring fairness and avoiding harmful\nstereotypes in generated scenarios and personality portrayals is\ncrucial and requires ongoing monitoring. Transparency about\nthe system being an AI is important for users.\nAPPENDIX A\nFULL SYSTEM ARCHITECTURE AND FLOW\nThe full system architecture can be found in Fig. 7. The\nflow of the framework, i.e., the way the system components\ninteract, can be found in Fig. 8.\nAPPENDIX B\nPERSONALITY SCORE TO TEXT CONVERSION TABLE\n• Neuroticism\n0: Consistently discusses even serious symptoms with a\ncalm, detached tone, rarely expressing any worry or\nseeking emotional reassurance\n1: Usually maintains a calm demeanor when describing\nsymptoms, seldom expressing anxiety and typically\nfocusing on factual aspects\n2: Occasionally mentions mild worry or concern about\nsymptoms but quickly pivots back to practical ques-\ntions, generally remaining composed\n3: Expresses a moderate level of worry appropriate to\nthe health concern, asking questions seeking both in-\nformation and reasonable reassurance\n4: Often expresses significant anxiety about symptoms\nor potential outcomes, frequently asking ’what if’\nquestions and seeking repeated reassurance from the\ndoctor\n5: Consistently voices strong fears and worries about\ntheir health, often catastrophizing minor symptoms and\npersistently seeking reassurance\n• Extraversion\n0: Speaks only in minimal, quiet, one-or-two-word re-\nsponses when directly questioned, never initiating con-\nversation or small talk\n1: Rarely offers information beyond direct, brief an-\nswers, speaking softly and infrequently making unso-\nlicited comments\n2: Answers questions politely but succinctly, seldom\nelaborating unprompted and maintaining a noticeably\nreserved, quiet demeanor\n3: Engages in polite back-and-forth, answers questions\nreasonably fully, and might offer a brief, relevant\npersonal comment occasionally\n4: Often elaborates extensively on answers, readily initi-\nates small talk or shares personal anecdotes, speaking\nwith noticeable energy\n5: Consistently dominates the conversation with lengthy,\nenergetic explanations and frequent personal stories,\noften filling any potential silences\n• Openness\n0: Consistently dismisses any non-standard treatment op-\ntions mentioned and asks only about the most practical,\nestablished procedures\n1: Frequently steers the conversation back to concrete\nsymptoms and immediate practical steps, rarely asking\n’why’ things work\n2: Occasionally asks a clarifying question about the\nbasic mechanisms but primarily focuses on routine and\nknown procedures\n3: Asks standard questions about the diagnosis and\ntreatment plan, accepting information straightforwardly\nwithout much speculation or resistance\n4: Often asks speculative ’what if’ questions about their\ncondition or expresses curiosity about the underlying\n"}, {"page": 9, "text": "9\nCentral backend server\nStudent doctor\nPersonality, disease difficulty\nStore\nAdd patient / doctor \nconversation log\nPatient text\nDoctor text\nTTS/STT Response\nTTS/STT Request Data\nEBM pages relevant\nto chosen disease\nR&R: Patient\nresponse &\npost-process\nR&R:Two \nkinds of\n feedback\nR&R:\nGeneration &\nconsistency check\n& refinement\n& persona selection\nPossible RAG pages\nin patient response\nGold standard\n EBM pages\nConversation\nlog\nTwo kinds\nof feedback\nBasic patient information\nTwo kinds\nof feedback\nConfigure and start simulation\nR&R: Conversation\nSimulated\npatient\nagent\nCritic \nagent\nVignette\ngenerator \nagent\nBasic patient information,\nconversation log,\ntwo kinds\nof feedback\n[\nEvaluation\nframeworks\n[\n[\nConversation\nhistory store\n[\n[\nGenerated\npatient vignette\n[\nFurhat\napplication\nDashboard\nMedical\ndatabase\nLLM Provider\nTTS / STT\nProvider\nFig. 7. System architecture diagram showing the three core agents (Generator, VSP, Critic) hosted on the server, the client dashboard, the embodied Furhat\napplication, the student doctor user, and key data components (medical DB, vignette, conversation history, evaluation frameworks). Arrows indicate the primary\nflow of information. R&R indicates a request and response that both convey information.\nbiological processes involved\n5: Consistently brings up alternative therapies or research\nthey’ve read, eagerly exploring various theoretical pos-\nsibilities for their condition\n• Agreeableness\n0: Consistently voices suspicion about the diagnosis or\ndoctor’s motives, frequently using challenging or crit-\nical language towards recommendations\n1: Often questions the doctor’s suggestions or expertise,\nexpressing skepticism about the necessity or effective-\nness of his utterances\n2: Occasionally voices mild disagreement or doubt about\na recommendation, asking probing questions before\nreluctantly agreeing\n3: Generally cooperates with the doctor’s requests and\nasks questions politely, expressing concerns in a non-\nconfrontational manner\n4: Often expresses explicit trust and gratitude towards the\ndoctor, readily agreeing with suggestions with minimal\nquestioning\n5: Consistently defers to the doctor’s judgment with\nstrong verbal agreement, frequently offering praise and\navoiding any hint of conflict\n• Conscientiousness\n0: Consistently gives vague, disorganized accounts of\nsymptoms and frequently mentions forgetting instruc-\ntions or medication doses\n1: Often struggles to recall specific details like symp-\ntom timelines or medication names, needing frequent\nprompting from the doctor\n2: Sometimes provides incomplete information or needs\nreminders about previous advice, occasionally men-\ntioning difficulties sticking to the plan\n3: Provides a reasonably clear account of their main\nissues and generally affirms understanding of instruc-\ntions, asking a few basic clarifying questions\n4: Often comes prepared with details or a mental list of\nquestions and frequently asks for detailed clarification\non treatment instructions to ensure accuracy\n5: Consistently presents details about symptoms and\nmedication adherence, meticulously double-checking\nevery aspect of the treatment plan\n"}, {"page": 10, "text": "10\nFull ﬂow: patient generation to ﬁnal feedback\nClient dashboard\n(NiceGUI)\nClient dashboard\n(NiceGUI)\nBackend server\n(Python agents)\nBackend server\n(Python agents)\nFurhat agent\n(Kotlin)\nFurhat agent\n(Kotlin)\nPatient generation\ngeneratePatient(params)\ngenerationStart()\nloop\n[Generation steps (1 to NR_OF_STEPS)]\ngenerationUpdate(text, step, totalSteps)\nGenerator agent active:\nstep-by-step processing\ngenerationStop(state=\"success\", text=\"...\")\nstartPatient(face, voice, new=true)\nstartPatient(face, voice, new=true)\nPatient interaction session begins\nConversation\nloop\n[Conversation Turn]\nStudent speaks...\ngetPatientResponse(doctorResponse=\"...\")\ndoctorResponse(response=\"...\", time=\"...\")\nVSP agent active:\nMulti-step reasoning,\n(optional RAG),\nresponse generation,\npost-processing\npatientGeneratedResponse(response=\"...\", time=\"...\"\nFurhat speaks (TTS)...\npatientGeneratedResponse(response=\"...\", time=\"...\")\nCritic agent active:\ngenerates quick feedback\nquickFeedbackResponse(response=\"...\")\nFurhat listens...\nFinal feedback\nstopAndGetFinalFeedback()\nstopPatient()\nstopPatient()\nInteraction stopped.\nCritic agent active:\ngenerates ﬁnal feedback\n(conversational MIRS + clinical)\nloop\n[For each ﬁnal feedback item]\nfeedbackResponse(criterium, mark, explanation, evidence, ...)\nclinicalFeedbackResponse(feedback=[...])\nStudent reviews ﬁnal feedback\nFig. 8. Sequence diagram of the full flow of the framework from generation to final feedback.\n"}, {"page": 11, "text": "11\nREFERENCES\n[1] C. Churchouse and C. McCafferty, “Standardized patients versus\nsimulated patients: Is there a difference?” Clinical Simulation in\nNursing, vol. 8, no. 8, pp. e363–e365, 2012. [Online]. Available:\nhttps://www.sciencedirect.com/science/article/pii/S1876139911000569\n[2] J. A. Cleland, K. Abe, and J.-J. R. and, “The use of simulated patients\nin medical education: Amee guide no 42,” Medical Teacher, vol. 31,\nno. 6, pp. 477–486, 2009, pMID: 19811162. [Online]. Available:\nhttps://doi.org/10.1080/01421590903002821\n[3] E.\nRideout,\nTransforming\nNursing\nEducation\nThrough\nProblem-\nbased Learning, ser. Faculty Resources Series.\nJones and Bartlett\nPublishers, 2001. [Online]. Available: https://books.google.be/books?\nid=xy5wpiNPmNwC\n[4] D. A. Cook and M. M. Triola, “Virtual patients: a critical literature\nreview and proposed next steps,” Medical education, vol. 43, no. 4, pp.\n303–311, 2009.\n[5] A. Hamilton, A. Molzahn, and K. McLemore, “The evolution from\nstandardized to virtual patients in medical education,” Cureus, vol. 16,\nno. 10, 2024.\n[6] D. A. Cook, “Creating virtual patients using large language models:\nscalable, global, and low cost,” Medical teacher, vol. 47, no. 1, pp.\n40–42, 2025.\n[7] B. Hayes-Roth, R. Saker, and K. Amano, “Using virtual patients to train\nclinical interviewing skills.” in AAAI Fall Symposium: Virtual Healthcare\nInteraction, 2009.\n[8] K. Maicher, D. Danforth, A. Price, L. Zimmerman, B. Wilcox, B. Liston,\nH. Cronau, L. Belknap, C. Ledford, D. Way, D. Post, A. Macerollo, and\nM. Rizer, “Developing a conversational virtual standardized patient to\nenable students to practice history-taking skills,” Simulation in Health-\ncare: The Journal of the Society for Simulation in Healthcare, vol. 12,\nno. 2, pp. 124–131, Apr. 2017.\n[9] A. Hurst, A. Lerer, A. P. Goucher, A. Perelman, A. Ramesh, A. Clark,\nA. Ostrow, A. Welihinda, A. Hayes, A. Radford et al., “Gpt-4o system\ncard,” arXiv preprint arXiv:2410.21276, 2024.\n[10] Y. Wang, J. Zhao, D. S. Ones, L. He, and X. Xu, “Evaluating the ability\nof large language models to emulate personality,” Scientific reports,\nvol. 15, no. 1, p. 519, 2025.\n[11] Z. Wang, D. Zhang, I. Agrawal, S. Gao, L. Song, and X. Chen,\n“Beyond profile: From surface-level facts to deep persona simulation\nin llms,” ArXiv, vol. abs/2502.12988, 2025. [Online]. Available:\nhttps://api.semanticscholar.org/CorpusID:276422444\n[12] Z. Chu, S. Wang, J. Xie, T. Zhu, Y. Yan, J. Ye, A. Zhong, X. Hu, J. Liang,\nP. S. Yu et al., “Llm agents for education: Advances and applications,”\narXiv preprint arXiv:2503.11733, 2025.\n[13] O. Perets, O. B. Shoham, N. Grinberg, and N. Rappoport, “Cup-\ncase: Clinically uncommon patient cases and diagnoses dataset,” arXiv\npreprint arXiv:2503.06204, 2025.\n[14] M. J. Bakkum, M. G. Hartjes, J. D. Pi¨et, E. M. Donker, R. Likic,\nE. Sanz, F. de Ponti, P. Verdonk, M. C. Richir, M. A. van Agtmael et al.,\n“Using artificial intelligence to create diverse and inclusive medical\ncase vignettes for education,” British Journal of Clinical Pharmacology,\nvol. 90, no. 3, pp. 640–648, 2024.\n[15] A. Bodonhelyi, C. Stegemann-Philipps, A. Sonanini, L. Herschbach,\nM. Sz´ep, A. Herrmann-Werner, T. Festl-Wietek, E. Kasneci, and F. Hold-\nerried, “Beyond the script: Testing llms for authentic patient communi-\ncation styles in healthcare,” arXiv preprint arXiv:2503.22250, 2025.\n[16] S. Kelly, E. Smyth, P. Murphy, and T. Pawlikowska, “A scoping review:\nvirtual patients for communication skills in medical undergraduates,”\nBMC medical education, vol. 22, no. 1, p. 429, 2022.\n[17] P. Bowers, K. Graydon, T. Ryan, J. H. Lau, and D. Tomlin, “Artificial\nintelligence-driven virtual patients for communication skill development\nin healthcare students: A scoping review,” Australasian Journal of\nEducational Technology, vol. 40, no. 3, p. 39–57, Jun. 2024. [Online].\nAvailable: https://ajet.org.au/index.php/AJET/article/view/9307\n[18] C. Meynhardt, P. Meybohm, P. Kranke, and C. R. H¨olzing, “Advanced\nprompt engineering in emergency medicine and anesthesia: Enhancing\nsimulation-based e-learning,” Electronics, vol. 14, no. 5, p. 1028, 2025.\n[19] P. L. Stillman, D. L. Sabers, and D. L. Redfield, “The use of parapro-\nfessionals to teach interviewing skills,” Pediatrics, vol. 57, no. 5, pp.\n769–774, 1976.\n[20] J. Lee, H. Kim, K. H. Kim, D. Jung, T. Jowsey, and C. S. Webster,\n“Effective\nvirtual\npatient\nsimulators\nfor\nmedical\ncommunication\ntraining: A systematic review,” Medical Education, vol. 54, no. 9,\npp. 786–795, Sep. 2020. [Online]. Available: https://onlinelibrary.wiley.\ncom/doi/10.1111/medu.14152\n[21] P. Bowers, K. Graydon, T. Ryan, J. H. Lau, and D. Tomlin, “Artificial\nintelligence-driven virtual patients for communication skill development\nin healthcare students: A scoping review,” Australasian Journal of\nEducational Technology, 2024.\n[22] K. R. Maicher, A. Stiff, M. Scholl, M. White, E. Fosler-Lussier,\nW.\nSchuler,\nP.\nSerai,\nV.\nSunder,\nH.\nForrestal,\nL.\nMendella,\nM. Adib, C. Bratton, K. Lee, and D. R. Danforth, “Artificial\nintelligence\nin\nvirtual\nstandardized\npatients:\nCombining\nnatural\nlanguage understanding and rule based dialogue management to\nimprove conversational fidelity,” Medical Teacher, vol. 45, no. 3, pp.\n279–285, Mar. 2023. [Online]. Available: https://www.tandfonline.com/\ndoi/full/10.1080/0142159X.2022.2130216\n[23] H. Nori, N. King, S. M. McKinney, D. Carignan, and E. Horvitz,\n“Capabilities of GPT-4 on Medical Challenge Problems,” Apr. 2023,\narXiv:2303.13375 [cs]. [Online]. Available: http://arxiv.org/abs/2303.\n13375\n[24] T. Tu, A. Palepu, M. Schaekermann, K. Saab, J. Freyberg, R. Tanno,\nA. Wang, B. Li, M. Amin, N. Tomasev, S. Azizi, K. Singhal,\nY.\nCheng,\nL.\nHou,\nA.\nWebson,\nK.\nKulkarni,\nS.\nS.\nMahdavi,\nC. Semturs, J. Gottweis, J. Barral, K. Chou, G. S. Corrado, Y. Matias,\nA. Karthikesalingam, and V. Natarajan, “Towards Conversational\nDiagnostic AI,” Jan. 2024, arXiv:2401.05654 [cs]. [Online]. Available:\nhttp://arxiv.org/abs/2401.05654\n[25] F. Holderried, C. Stegemann–Philipps, L. Herschbach, J.-A. Moldt,\nA. Nevins, J. Griewatz, M. Holderried, A. Herrmann-Werner, T. Festl-\nWietek, and M. Mahling, “A Generative Pretrained Transformer\n(GPT)–Powered Chatbot as a Simulated Patient to Practice History\nTaking: Prospective, Mixed Methods Study,” JMIR Medical Education,\nvol. 10, p. e53961, Jan. 2024. [Online]. Available: https://mededu.jmir.\norg/2024/1/e53961\n[26] L. Potter and C. Jefferies, “Enhancing communication and clinical\nreasoning\nin\nmedical\neducation:\nBuilding\nvirtual\npatients\nwith\ngenerative AI,” Future Healthcare Journal, vol. 11, p. 100043, Apr.\n2024. [Online]. Available: https://linkinghub.elsevier.com/retrieve/pii/\nS2514664524001553\n[27] C. Gr´evisse, “RasPatient Pi: A Low-Cost Customizable LLM-Based\nVirtual\nStandardized\nPatient\nSimulator,”\nin\nApplied\nInformatics,\nH. Florez and H. Astudillo, Eds.\nCham: Springer Nature Switzerland,\n2025, vol. 2237, pp. 125–137, series Title: Communications in\nComputer\nand\nInformation\nScience.\n[Online].\nAvailable:\nhttps:\n//link.springer.com/10.1007/978-3-031-75147-9 9\n[28] L. De Mattei, M. Q. Morato, V. Sidhu, N. Gautam, C. T. Mendonca,\nA. Tsai, M. Hammer, L. Creighton-Wong, and A. Azzam, “Are Artificial\nIntelligence Virtual Simulated Patients (AI-VSP) a Valid Teaching\nModality\nfor\nHealth\nProfessional\nStudents?”\nClinical\nSimulation\nin Nursing, vol. 92, p. 101536, Jul. 2024. [Online]. Available:\nhttps://linkinghub.elsevier.com/retrieve/pii/S1876139924000288\n[29] D. A. Cook, J. Overgaard, V. S. Pankratz, G. Del Fiol, and\nC. A. Aakre, “Virtual patients using large language models: Scalable,\ncontextualized simulation of clinician-patient dialogue with feedback,”\nJ Med Internet Res, vol. 27, p. e68486, Apr 2025. [Online]. Available:\nhttps://www.jmir.org/2025/1/e68486\n[30] A. Emerson, L. A. Ha, K. Evanini, S. Somay, K. Frome, P. Harik,\nand V. Yaneva, “Automated evaluation of standardized patients with\nLLMs,” in Proceedings of the Artificial Intelligence in Measurement\nand Education Conference (AIME-Con): Full Papers, J. Wilson,\nC. Ormerod, and M. Beiting Parrish, Eds.\nWyndham Grand Pittsburgh,\nDowntown, Pittsburgh, Pennsylvania, United States: National Council\non Measurement in Education (NCME), Oct. 2025, pp. 231–238.\n[Online]. Available: https://aclanthology.org/2025.aimecon-main.25/\n[31] A. Borg, I. Parodis, and G. Skantze, “Creating Virtual Patients\nusing Robots and Large Language Models: A Preliminary Study\nwith Medical Students,” in Companion of the 2024 ACM/IEEE\nInternational\nConference\non\nHuman-Robot\nInteraction.\nBoulder\nCO USA: ACM, Mar. 2024, pp. 273–277. [Online]. Available:\nhttps://dl.acm.org/doi/10.1145/3610978.3640592\n[32] H. Yu, J. Zhou, L. Li, S. Chen, J. Gallifant, A. Shi, X. Li, W. Hua,\nM. Jin, G. Chen, Y. Zhou, Z. Li, T. Gupte, M.-L. Chen, Z. Azizi,\nY. Zhang, T. L. Assimes, X. Ma, D. S. Bitterman, L. Lu, and L. Fan,\n“Aipatient: Simulating patients with ehrs and llm powered agentic\nworkflow,” 2024. [Online]. Available: https://arxiv.org/abs/2409.18924\n[33] Z. Du, L. Zheng, R. Hu, Y. Xu, X. Li, Y. Sun, W. Chen, J. Wu, H. Cai,\nand H. Ying, “LLMs Can Simulate Standardized Patients via Agent\nCoevolution,” Dec. 2024, arXiv:2412.11716 [cs]. [Online]. Available:\nhttp://arxiv.org/abs/2412.11716\n[34] Y. Li, C. Zeng, J. Zhong, R. Zhang, M. Zhang, and L. Zou,\n“Leveraging Large Language Model as Simulated Patients for Clinical\n"}, {"page": 12, "text": "12\nEducation,” Apr. 2024, arXiv:2404.13066 [cs]. [Online]. Available:\nhttp://arxiv.org/abs/2404.13066\n[35] Q. Wang, Z. Tang, and B. He, “From ChatGPT to DeepSeek:\nCan LLMs Simulate Humanity?” Feb. 2025, arXiv:2502.18210 [cs].\n[Online]. Available: http://arxiv.org/abs/2502.18210\n[36] S. Sumpter, “Automated generation of high-quality medical simulation\nscenarios through integration of semi-structured data and large language\nmodels,” 2024. [Online]. Available: https://arxiv.org/abs/2404.19713\n[37] J.\nR.\nA.\nBenoit,\n“ChatGPT\nfor\nClinical\nVignette\nGeneration,\nRevision, and Evaluation,” Feb. 2023. [Online]. Available: http:\n//medrxiv.org/lookup/doi/10.1101/2023.02.04.23285478\n[38] D. Reichenpfader and K. Denecke, “Simulating diverse patient popula-\ntions using patient vignettes and large language models,” in Proceed-\nings of the First Workshop on Patient-Oriented Language Processing\n(CL4Health)@ LREC-COLING 2024, 2024, pp. 20–25.\n[39] J. Faferek, A. A. Kononowicz, N. Bogutska, V. Da Silva Domingues,\nN. Davydova, A. Frankowska, I. Iguacel, A. Mayer, L. Morin,\nN. Pavlyukovich, I. Popova, T. Shchudrova, M. Sudacka, R. Szydlak,\nand I. Hege, “Applying chatgpt to plan and create a realistic\ncollection of virtual patients for clinical reasoning training,” BMC\nMedical Education, vol. 25, no. 1, p. 1277, 2025. [Online]. Available:\nhttps://doi.org/10.1186/s12909-025-08006-9\n[40] K. Lee, S. Lee, E. H. Kim, Y. Ko, J. Eun, D. Kim, H. Cho, H. Zhu,\nR. E. Kraut, E. E. Suh, E.-m. Kim, and H. Lim, “Adaptive-VP: A\nframework for LLM-based virtual patients that adapts to trainees’\ndialogue to facilitate nurse communication training,” in Findings of\nthe Association for Computational Linguistics: ACL 2025, W. Che,\nJ. Nabende, E. Shutova, and M. T. Pilehvar, Eds.\nVienna, Austria:\nAssociation for Computational Linguistics, Jul. 2025, pp. 2319–2352.\n[Online]. Available: https://aclanthology.org/2025.findings-acl.118/\n[41] A. Amithasagaran, S. Dakshit, B. Suryadevara, and L. Stockton, “Clivr:\nConversational learning system in virtual reality with ai-powered\npatients,” 2025. [Online]. Available: https://arxiv.org/abs/2510.19031\n[42] E. Br¨ugge, S. Ricchizzi, M. Arenbeck, M. N. Keller, L. Schur, W. Stum-\nmer, M. Holling, M. H. Lu, and D. Darici, “Large language models\nimprove clinical decision making of medical students through patient\nsimulation and structured feedback: a randomized controlled trial,” BMC\nMedical Education, vol. 24, no. 1, p. 1391, 2024.\n[43] J. Geathers, Y. Hicke, C. Chan, N. Rajashekar, J. Sewell, S. Cornes,\nR. F. Kizilcec, and D. Shung, “Benchmarking generative ai for scoring\nmedical student interviews in objective structured clinical examinations\n(osces),” 2025. [Online]. Available: https://arxiv.org/abs/2501.13957\n[44] J. Schi¨ott, W. Ivegren, A. Borg, I. Parodis, and G. Skantze, “Using\nLLMs to grade clinical reasoning for medical students in virtual patient\ndialogues,” in Proceedings of the 26th Annual Meeting of the Special\nInterest Group on Discourse and Dialogue, F. B´echet, F. Lef`evre,\nN. Asher, S. Kim, and T. Merlin, Eds.\nAvignon, France: Association\nfor Computational Linguistics, Aug. 2025, pp. 750–763. [Online].\nAvailable: https://aclanthology.org/2025.sigdial-1.56/\n[45] Meta,\n“The\nllama\n4\nherd:\nThe\nbeginning\nof\na\nnew\nera\nof\nnatively\nmultimodal\nintelligence,”\nhttps://ai.meta.com/blog/\nllama-4-multimodal-intelligence/, 2025, accessed: 2025-05-05.\n[46] J. Liu, “LlamaIndex,” 11 2022. [Online]. Available: https://github.com/\njerryjliu/llama index\n[47] A. King and R. B. Hoppe, ““best practice” for patient-centered com-\nmunication: a narrative review,” Journal of graduate medical education,\nvol. 5, no. 3, pp. 385–393, 2013.\n[48] F. Schindler and R. Trappe, “NiceGUI: Web-based user interfaces\nwith\nPython.\nThe\nnice\nway.”\nApr.\n2025.\n[Online].\nAvailable:\nhttps://github.com/zauberzeug/nicegui\n[49] J. Brooke et al., “Sus-a quick and dirty usability scale,” Usability\nevaluation in industry, vol. 189, no. 194, pp. 4–7, 1996.\n[50] M. C. Blackman and D. C. Funder, “The effect of information on con-\nsensus and accuracy in personality judgment,” Journal of Experimental\nSocial Psychology, vol. 34, no. 2, pp. 164–181, 1998.\n[51] S. V. Rouse and H. A. Haas, “Exploring the accuracies and inaccuracies\nof personality perception following internet-mediated communication,”\nJournal of research in personality, vol. 37, no. 5, pp. 446–467, 2003.\n[52] K. O. Tskhay and N. O. Rule, “Perceptions of personality in text-based\nmedia and osn: A meta-analysis,” Journal of research in personality,\nvol. 49, pp. 25–30, 2014.\n[53] A. Bodonhelyi, C. Stegemann-Philipps, A. Sonanini, L. Herschbach,\nM. Szep, A. Herrmann-Werner, T. Festl-Wietek, E. Kasneci, and F. Hold-\nerried, “Modeling challenging patient interactions: Llms for medical\ncommunication training,” arXiv preprint arXiv:2503.22250, 2025.\n[54] A. Kong, S. Zhao, H. Chen, Q. Li, Y. Qin, R. Sun, X. Zhou, E. Wang,\nand X. Dong, “Better zero-shot reasoning with role-play prompting,” in\nProceedings of the 2024 Conference of the North American Chapter\nof the Association for Computational Linguistics: Human Language\nTechnologies (Volume 1: Long Papers), 2024, pp. 4099–4113.\n[55] I. A. Brito, J. S. Dollis, F. B. F¨arber, P. S. F. B. Ribeiro, R. T. Sousa,\nand A. R. G. Filho, “Modeling, evaluating, and embodying personality\nin llms: A survey,” in Findings of the Association for Computational\nLinguistics: EMNLP 2025, 2025, pp. 9519–9532.\n[56] P. Bhandari, N. Fay, S. Selvaganapathy, A. Datta, U. Naseem, and\nM. Nasim, “Activation-space personality steering: Hybrid layer selection\nfor stable trait control in llms,” arXiv preprint arXiv:2511.03738, 2025.\n"}]}