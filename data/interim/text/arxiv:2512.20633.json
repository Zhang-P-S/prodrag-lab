{"doc_id": "arxiv:2512.20633", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2512.20633.pdf", "meta": {"doc_id": "arxiv:2512.20633", "source": "arxiv", "arxiv_id": "2512.20633", "title": "Enhancing Lung Cancer Treatment Outcome Prediction through Semantic Feature Engineering Using Large Language Models", "authors": ["MunHwan Lee", "Shaika Chowdhury", "Xiaodi Li", "Sivaraman Rajaganapathy", "Eric W Klee", "Ping Yang", "Terence Sio", "Liewei Wang", "James Cerhan", "Nansu NA Zong"], "published": "2025-12-01T23:56:45Z", "updated": "2025-12-01T23:56:45Z", "summary": "Accurate prediction of treatment outcomes in lung cancer remains challenging due to the sparsity, heterogeneity, and contextual overload of real-world electronic health data. Traditional models often fail to capture semantic information across multimodal streams, while large-scale fine-tuning approaches are impractical in clinical workflows. We introduce a framework that uses Large Language Models (LLMs) as Goal-oriented Knowledge Curators (GKC) to convert laboratory, genomic, and medication data into high-fidelity, task-aligned features. Unlike generic embeddings, GKC produces representations tailored to the prediction objective and operates as an offline preprocessing step that integrates naturally into hospital informatics pipelines. Using a lung cancer cohort (N=184), we benchmarked GKC against expert-engineered features, direct text embeddings, and an end-to-end transformer. Our approach achieved a mean AUROC of 0.803 (95% CI: 0.799-0.807) and outperformed all baselines. An ablation study further confirmed the complementary value of combining all three modalities. These results show that the quality of semantic representation is a key determinant of predictive accuracy in sparse clinical data settings. By reframing LLMs as knowledge curation engines rather than black-box predictors, this work demonstrates a scalable, interpretable, and workflow-compatible pathway for advancing AI-driven decision support in oncology.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2512.20633v1", "url_pdf": "https://arxiv.org/pdf/2512.20633.pdf", "meta_path": "data/raw/arxiv/meta/2512.20633.json", "sha256": "d178bd09590be6cc2acc1a4cfc709177618f5ec65c43910984403f05ba462a29", "status": "ok", "fetched_at": "2026-02-18T02:25:41.659327+00:00"}, "pages": [{"page": 1, "text": " \n \nEnhancing Lung Cancer Treatment Outcome \nPrediction through Semantic Feature \nEngineering Using Large Language Models \n \n \n \nMun Hwan Lee, PhD1, Shaika Chowdhury, PhD 1, Xiaodi Li, PhD¹, Sivaraman Rajaganapathy, \nPhD 1, Eric W. Klee, PhD¹, Ping Yang, MD, PhD¹, Terence Sio, MD, PhD¹, Liewei Wang, MD, \nPhD¹, James Cerhan, MD, PhD¹, Nansu N. A. Zong, PhD¹ \n \n \n \n1Mayo Clinic, Rochester, Minnesota, USA\n \n \n \n \n \n \nAbstract—Accurate prediction of treatment outcomes in lung \ncancer is critical yet remains limited by the sparsity, heterogeneity, \nand contextual overload of real-world electronic health data. \nTraditional models struggle to capture semantic meaning across \nmultimodal streams, while large-scale fine-tuning approaches are \ninfeasible in clinical workflows. We introduce a novel framework \nthat employs Large Language Models (LLMs) as Goal-oriented \nKnowledge Curators (GKC) to transform raw laboratory, \ngenomic, and medication data into high-fidelity, task-specific \nfeatures. Unlike generic embeddings, GKC aligns representation \nwith the prediction objective and integrates seamlessly as an \noffline preprocessing step, making it practical for deployment in \nhospital informatics pipelines. Using a lung cancer cohort (N=184), \nwe benchmarked GKC against expert-engineered features, direct \ntext embeddings, and an end-to-end transformer. Our approach \nachieved a superior mean AUC-ROC of 0.803 (95% CI: 0.799–\n0.807) and significantly outperformed all baselines. An ablation \nstudy further confirmed the synergistic value of combining all \nthree modalities. These results demonstrate that the quality of \nsemantic representation drives predictive accuracy in sparse \nclinical data settings. By reframing LLMs as knowledge curation \nengines rather than black-box predictors, our work highlights a \nscalable, interpretable, and workflow-compatible pathway for \nadvancing AI-driven decision support in oncology. \nKeywords— Treatment Outcome Prediction, Multi-Modal Data, \nLarge Language Models (LLMs), Semantic Representation, Lung \nCancer \nI. INTRODUCTION  \nLung cancer remains the leading cause of cancer-related \nmortality worldwide, accounting for over 1.8 million deaths \nannually [1]. Despite advances in diagnosis and therapy, the \ntreatment outcome for lung cancer patients is often poor, with \nfive-year survival rates languishing below 20% in most \npopulations [1, 2]. Accurate prediction of treatment outcome is \nessential for informed clinical decision-making, guiding \ntreatment selection, risk stratification, and the allocation of \nscarce medical resources [3, 4]. \nFor decades, the TNM staging system has served as the \nfoundation for lung cancer treatment outcome, providing critical \nguidance based on the anatomical extent of disease [5, 6]. While \nit remains the gold standard for initial risk stratification, \nsubstantial clinical evidence reveals that patients within the \nsame TNM stage can exhibit markedly different outcomes [7, \n8]. \nThis \nvariability \narises \nfrom \ncomplex \nbiological \nheterogeneity, which includes molecular driver mutations, the \ntumor immune microenvironment, and key laboratory-based \nbiomarkers [9]. As a result, there is a growing imperative to \ndevelop more accurate, personalized models by integrating \nmulti-modal data sources—including laboratory results, \ngenomic profiles, and medication histories—to capture the \nmultifaceted determinants of patient outcomes. \nNumerous studies have explored using traditional machine \nlearning to integrate multi-modal structured data, such as \nconcatenating feature vectors from different sources [10-13]. \nHowever, these models treat each feature as an isolated, context-\nfree data point. While they can identify correlations, they fail to \ncapture the underlying biological or clinical meaning that expert \nclinicians extract by synthesizing information holistically across \nmodalities [14]. This gap highlights a critical need for \ncomputational paradigms capable of performing deeper \nsemantic integration and interpretive inference on complex \nbiomedical data.  \n"}, {"page": 2, "text": " \n \nRecent advances in large language models (LLMs) show \npromise for biomedical applications [15, 16]. Fine-tuned \nmultimodal systems can integrate diverse inputs [17], and \nadvanced prompt engineering techniques [18] can approach \nspecialist performance without task-specific training. However, \npractical barriers remain. Fine-tuning demands large, high-\nquality labeled datasets, while sophisticated few-shot prompting \ndepends on many well-crafted exemplars. In clinical prediction, \nsuch resources are rare and datasets are typically small, sparse, \nand heterogeneous. This creates a clear disconnect: the most \npowerful LLM strategies are often unusable in real-world \nclinical settings, withholding advanced AI capabilities precisely \nwhere they are most urgently needed. \nIn this study, we address this gap with a framework that uses \nLLMs for modality-specific semantic summarization. Rather \nthan asking a model to make an end-to-end prediction from all \ndata at once, we first produce goal-aligned summaries per \nmodality (laboratory, genomics, medication). Each summary \ndistills the salient, task-relevant information available in that \nmodality and preserves an interpretable intermediate that can be \naudited in clinical workflows. The summaries are then \nembedded and supplied to a lightweight classifier. \nOur inputs are assay-grounded, clinician-facing profiles. The \ngenomics modality is a clinically deployed, expert-curated \ntargeted panel of 271 cancer-related genes, reviewed by \noncology and molecular genetics teams and focused on \nactionable driver and resistance biology. In routine care this \npanel-level genomics is available to a minority of patients due \nto cost and access constraints, making it pharmacogenomic \nhigh-value when present. Serial laboratory tests capture current \nphysiological state (e.g., inflammation and nutritional status). \nStructured medication history reflects therapeutic intent and \ndisease trajectory. Modeling these three streams together aligns \nwith how oncology teams actually review patient data. \nWe evaluate three representation strategies for the same \ncohort and task (1-year survival): (i) an expert-engineered \nnumerical baseline, (ii) a contextual text-embedding baseline \nthat embeds detailed modality profiles from biomedical \nknowledge bases, and (iii) the proposed modality-specific \nsummarization approach that first produces goal-aligned \nmodality summaries and then embeds them. All models are \nassessed with repeated stratified cross-validation under identical \nprotocols. \nOur results show a clear hierarchy of representations. \nModality-specific summarization achieves the best performance \n(AUC-ROC 0.803; AUC-PRC 0.859), exceeding both the \nexpert-engineered numerical baseline (AUC-ROC 0.619; AUC-\nPRC 0.713) and the contextual embedding baseline (AUC-ROC \n0.678; AUC-PRC 0.771). An ablation study confirms synergy \nacross modalities, and SHAP analyses indicate balanced \ncontributions from laboratory, genomics, and medication \nfeatures. Additionally, a long-context BERT baseline with a \nclassification head performed comparably to the contextual \nembedding baseline, further underscoring that task-aligned \nsummarization, rather than generic self-attention over long \nprofiles, drives the observed gains. \nIn summary, the key contributions of this work are: \n1. We introduce a modality-specific LLM summarization \nframework that converts assay-grounded clinical inputs \nFigure 1: Overview of the Three Feature Engineering Strategies. The figure illustrates the three systematic approaches compared in this study. \n(A) The Expert-Engineered Baseline transforms multi-modal clinical data into a structured numerical feature vector based on pre-defined domain \nknowledge. (B) The Contextual Text Embedding enriches the raw data with detailed descriptions from biomedical databases to create modality-specific \ntext profiles, which are then embedded. (C) Our Proposed 'Goal-oriented Knowledge Curators' Framework utilizes LLMs to generate a high-fidelity, \nsemantic summary for each modality, and the embeddings of these summaries are used as the final predictive features. \nMedication\nGene\nLab Tests\nEHR\nFeature Engineering Strategies\n27 Drug classes\n271 cancer-\nrelated genes \n10 Lab Test\nDrug\nBank\nNCBI\nGO\nKEGG\nEHR\n(B) Contextual Text \nEmbedding\n(A) Numeric \nFeatures\n- Pharmacodynamics\n- Indication\n- Toxicity\n- Mechanism of Action\n…\n- Pathway\n- Biological Process\n- Molecular Function\n…\nMedication Profiles\nGenomic Profiles\nLab Test Profiles\n- Test Normal Ranges\n- Test Results \n(Low, Normal, High)\n…\n- Primary anti-cancer \nStrategy\n- Inferred Disease \nStatus\n…\n- Activated Oncogenic \nDriver Pathways\n- Inactivated Tumor \nSuppressor Pathways\n…\nMedication Summary\n- Hematologic Stability\n- Inflammation Status\n- Nutritional Status\n…\n(C) Semantic \nSummarization\nGenomic Summary\nLab Test Summary\n"}, {"page": 3, "text": " \n \ninto compact, interpretable features suitable for audit and \ndeployment in real-world oncology. \n2. We establish a representation hierarchy, showing that \ngoal-aligned \nsummarization \noutperforms \nexpert-\nengineered features and direct embeddings. \n3. We demonstrate that preserving pharmacogenomically \nrich but scarce panel-level genomics alongside laboratory \nand medication streams improves prediction. \n4. We offer empirical evidence including ablations and \nmodel comparisons that explicit summarization, not \ngeneric self-attention, drives the observed gains in this \nsetting. \nII. METHODS \nA. Study Design and Patient Cohort  \nThis retrospective cohort study was conducted under IRB \napproval using de-identified electronic health record (EHR) data. \nWe included all adults diagnosed with lung cancer between June \n2011 and October 2022 who underwent targeted genomic panel \ntesting. To mitigate lead-time bias, a 90-day landmark was \napplied; only patients surviving ≥90 days after diagnosis were \neligible. Patients were required to have complete laboratory, \ngenomic, and medication data within this 90-day window. After \napplying these criteria, the final analytic cohort comprised 184 \npatients. \nB. Cohort Characteristics \nThe study cohort (N=184) had a mean age of 65.1 years and \nbalanced sex distribution (49% male, 51% female). At the 90-\nday landmark, 72% had metastatic disease, 46% had major \ncomorbidities, and the median number of mutated genes and \nprescribed drug classes per patient were 5 and 9, respectively. \nOverall, 36% of patients died within one year of the landmark. \nTable \n1 \nsummarizes \nkey \ndemographic \nand \nclinical \ncharacteristics. \nC. Data Sources and Preprocessing  \nWe extracted and integrated three distinct data modalities for \neach patient within the 90-day window from diagnosis to the \nlandmark time. \n• Medication Data (Med): We extracted prescription \nrecords for 64 drugs from the EHR. This list was \ncompiled by identifying 38 anti-cancer agents prescribed \nto our cohort from a list of FDA-approved lung cancer \ndrugs, and adding 26 key supportive care drugs also \nadministered to these patients. This selection was based \non a review of the most frequently prescribed \nmedications for this specific patient cohort, reflecting \nactual clinical practice. To build contextual profiles, we \nprogrammatically parsed the full DrugBank database [19] \nto extract detailed information for each drug, including \nits \ndescription, \nmechanism-of-action, \nindication, \npharmacodynamics, and toxicity. Individual drugs were \nthen grouped into 27 clinically meaningful classes (e.g., \nPlatinum-Based \nChemotherapy, \nPD-1/PD-L1 \nCheckpoint Inhibitors, Strong Opioids) based on their \nmechanism of action. \nTABLE I.  \nDEMOGRAPHICS AND CLINICAL CHARACTERISTICS OF THE \nSTUDY COHORT (N=184) \n \na. Key comorbidities include COPD, Coronary Artery Disease, Congestive Heart Failure, Chronic \nKidney Disease, Diabetes, Cerebrovascular Disease, or Connective Tissue Disease diagnosed at or \nbefore the 90-day landmark. These clinical variables were used to characterize the cohort. \nb. SD: Standard Deviation; IQR: Interquartile Range. All data presented as n (%), unless otherwise \nspecified \n \n• Genomic Data (Gene): We utilized data from a targeted \nsequencing panel of 271 cancer-related genes. This panel \nis clinically deployed and expert-curated at our \ninstitution, covering actionable driver and resistance \nbiology. All gene names were first normalized to their \nofficial HUGO Gene Nomenclature Committee (HGNC) \nsymbols. To create rich semantic profiles, we \nprogrammatically retrieved annotation data from \nestablished biomedical knowledge bases. This included \nfunctional summaries from the NCBI Gene database \n[20], pathway information from the KEGG database \n[21], and functional annotations (Biological Processes, \nMolecular Functions) from the Gene Ontology (GO) \ndatabase [22, 23] . \n• Laboratory Data (Lab): Based on a literature review in \nlung cancer, we selected 10 laboratory tests that are well-\nestablished \n[24, \n25] \nas \nmarkers \nfor \nsystemic \ninflammation, \nnutritional \nstatus, \nand \noverall \nphysiological resilience. These tests include Albumin, \nPlatelets, and components of the complete blood count \nwith differential (e.g., Neutrophils, Lymphocytes). For \neach patient, we collected the five most recent values for \nthese tests within the 90-day landmark period. If fewer \nthan five values were available, the series was padded \nusing the most recent available observation (last-\nobservation-carried-forward). Laboratory units were \nCharacteristic \nValue at Landmark \nDemographics \n  \nAge, years (Mean ± SDb) \n65.1 ± 10.4 \nSex, n (%) \n  \n    Male \n90 (48.9) \n    Female \n94 (51.1) \nClinical Characteristics \n  \nMetastatic Disease, n (%) \n132 (71.7) \nKey Comorbiditiesa, n (%) \n84 (45.7) \nKey Modality Summaries \n  \nLaboratory Values \n  \n    Albumin (g/dL), Mean ± SD \n3.8 ± 0.6 \n    Hemoglobin (g/dL), Mean ± SD \n11.7 ± 2.3 \n    Platelets (K/uL), Mean ± SD \n241.7 ± 119.0 \nGenomic and Medication Profile \n  \n    Mutated Genes per Patient,  \n    Median [IQR] \n5 [3-7] \n    Drug Classes per Patient,  \n    Median [IQR] \n9 [7-11] \nOutcome \n  \nDied within 1-Year \nfrom Landmark, n (%) \n67 (36.4) \n"}, {"page": 4, "text": " \n \nharmonized to institutional reference ranges prior to \nnormalization; missingness, out-of-range entries, and \nbiologically implausible values were screened and \nresolved by predefined rules. \nD. Feature Engineering Strategies \nWe systematically compared three distinct strategies for \nrepresenting the multi-modal data, each building upon the last. \nThe fundamental difference between our key models is \nconceptually illustrated using a hypothetical patient's genomic \nprofile in Fig 2. \n• ENF (Expert-Engineered Numerical Features) Model: \nThis baseline represents the traditional tabular data-\nbased approach (Fig 1A).  Features consisted of a single \nnumerical vector per patient, the five most recent lab \nvalues of 10 lab tests, the count of mutated genes, and a \nbinary indicator (0/1) for the prescription of each of the \n27 medication classes. Missing medication and genomic \nentries were treated as absent and encoded as zeros. We \nnormalized the lab values for each lab test to preserve \neach lab test data’s information range because each lab \ntest has a different Unit of test and normal criteria.  \n• CTE (Contextual Text Embedding) Model: This model \nwas designed to test the value of adding semantic context \ndirectly from biomedical databases (Fig. 1B).   For each \npatient, we generated three modality-specific text \nprofiles \nby \nconcatenating \ndetailed, \npre-written \ndescriptions for each relevant data point, as exemplified \nin Fig. 2A. These profiles were enriched with \ninformation from biomedical databases (DrugBank, \nGene Ontology, KEGG) for each modality. The \ncomplete text profile for each modality was then encoded \nand concatenated into a final feature vector. \n• E2E (End-to-End Transformer) Model: We added a \npowerful end-to-end baseline. This model uses a state-\nof-the-art long-context transformer (ModernBERT  [29]) \nfine-tuned directly on the same long-form contextual text \nprofiles used by the CTE model. This approach tests the \nhypothesis that a large transformer model can \nautomatically learn to summarize and predict without an \nexplicit knowledge curation step. \n• GKC (Goal‑oriented Knowledge Curators) Model: This \nis our proposed framework (Fig. 1C). It generates a \nseparate, goal-oriented modality summary for each \nmodality, an example of which is shown in Fig. 2B. The \nresulting three text summaries were then independently \nembedded, and their vectors concatenated, creating a \nmulti-channel semantic feature vector that preserves \nmodality-specific insights for the downstream classifier. \nCompared to CTE, the only architectural difference is the \nexplicit summarization step \nE. LLM-based Semantic Summarization Pipeline \nIn our work, 'Semantic Summarization' is defined as a goal-\noriented process that involves (1) extracting insights relevant to \nthe prediction target, (2) synthesizing relationships between \ndisparate data points, and (3) generating an interpretive narrative, \ngoing beyond simple compression. The core of our proposed \nmodel (GKC Model) is a pipeline designed to transform the \nverbose, context-rich text profiles used by CTE Model into high-\nfidelity, treatment outcomes related features. As illustrated in \nFig. 2, this process uses an LLM to synthesize the raw, \ndescriptive information (Fig. 2A) into a concise, goal-oriented \nnarrative focused specifically on implications for treatment \noutcomes (Fig. 2B). \nThis was achieved by prompting the LLM to act as a clinical \nexpert and generate a structured JSON report for each modality. \nThis strategy, a major contribution of this work, was designed to \nguide the LLM to act as a domain expert for each modality and \nincorporates three key principles: \n• Structured Output: To ensure consistency and enable \nautomated parsing, the LLM was instructed to generate \nits analysis in a structured JSON format with pre-defined \nkeys. We constrained outputs to a schema with required \nfields: summary, key domains, therapy implications, \npositives, and negatives \nIdentify applicable funding agency here. If none, delete this text box. \nFigure 2: Comparison of Feature Representation for a Hypothetical Patient's Genomic Profile. This figure illustrates the distinct inputs for CTE \nModel and GKC Model using a hypothetical patient profile. (A) The input for CTE Model is a long-form textual profile, created by concatenating detailed \ndescriptions for each dysregulated hallmark domain from public knowledge bases. (B) In contrast, the input for GKC Model is a concise, goal-oriented \nsummary generated by the 'Goal-oriented Knowledge Curators' LLM. This summary synthesizes the raw information from (A) into a high-fidelity narrative \nfocused specifically on implications of treatment outcomes, such as the synergistic effect of the co-mutations and likely immunotherapy resistance. This \nprocess transforms noisy, descriptive text into a dense, feature-rich summary for the downstream classifier. \n(B) LLM Summarizer Output Example:\n1. Summary: The patient's genomic profile, characterized by concurrent TP53 and \nKRAS mutations, suggests an aggressive tumor biology and a guarded \nprogress. The activating KRAS mutation will …\n2. Key domains\n2.1 Activated Oncogenic driver pathways: Ras, MAPK, PI3K-Akt , … \n2.2 Inactivated Tumor suppressor pathways: p53, Cell cycle control, Apoptosis …\n2.3 Therapeutic implications: Likely resistance to chemotherapy relying on p53 \nfunction. …\n3. Key positive factors: None,\n4. Key negative factors: (1) Concurrent mutation of a potent oncogene (KRAS) and a \ncritical tumor suppressor (TP53). \n(2) Activation of multiple pro-growth signaling pathways.\n…\n(A) Genomic Profile Example:\n1. Mutation Gene: TP53\n- Function: This gene encodes a tumor suppressor protein containing \ntranscriptional activation, DNA binding, and oligomerization domains. \nThe encoded protein responds to diverse cellular stresses … \n- KEGG Pathways: MAPK signaling pathway; Cell cycle; p53 signaling pathway; \nPI3K-Akt signaling pathway; Apoptosis; …\n- Biological Processes: negative regulation of transcription by RNA polymerase II; \n- Molecular Functions: transcription cis-regulatory region binding; transcription \ncis-regulatory region binding; \n2. Mutation Gene: KRAS\n- Function : This gene, a Kirsten ras oncogene homolog from the mammalian ras\ngene family, encodes … \n3. Mutation Gene: …\n4. Mutation Gene: …\n"}, {"page": 5, "text": " \n \n• Persona-based Role-playing: The prompt assigned the \nLLM a specific expert role (e.g., 'clinical pharmacologist' \nor 'systems biologist') tailored to each modality, aligning \nits interpretive framing with domain-specific knowledge. \nThis role prompting is used only to steer framing; we do \nnot invoke external tools or knowledge bases at \ngeneration time. \n• Specialized Task Guidance: A core innovation was \nspecializing the prompts for each data type. For instance, \nthe Gene prompt focused on oncogenic pathway \ndysregulation, while the Medication prompt assessed \ntreatment intent and disease burden, and the Lab report \nevaluated inflammation and nutritional status. \nThis approach forced the LLM to synthesize modality-\nspecific insights through a clinically relevant lens, rather than \nsimply re-stating information. Generation was strictly \n\"from‑context\": the model summarized only the provided \nmodality profiles. Decoding was deterministic (temperature=0.0; \ntop_k=1) to ensure reproducibility and reduce hallucination \nvariance. \nF. LLMs Model and Embedding Specifications \nWe extracted and integrated three distinct data modalities for \neach patient within the 90-day window from diagnosis to the \nlandmark time. \n• LLM for Knowledge Curation: All modality summaries \nfor GKC Model were generated using Gemini 2.0 Flash \n[26], chosen for its strong performance for Medical \nexpert-annotated \nhallucination \ntest \nincluding \nchronological ordering, lab data understating and \ndiagnosis prediction [27]. A zero-shot prompting \nstrategy was employed. No retrieval or external \nknowledge calls were used; summaries are produced \nsolely from the constructed modality profiles.  \n• Text Embedding and Dimensionality Reduction: All \ntextual data for both CTE Model and GKC Model were \nconverted into dense feature vectors using Google's text-\nembedding-005 model (Gecko) [28]. The task_type \nparameter was set to CLASSIFICATION to optimize the \nembeddings for this downstream task. \nG. Predictive Modeling and Evaluation \n• Classifier: To ensure that our findings were robust and \nnot dependent on a single algorithm, we benchmarked a \nsuite of standard machine learning classifiers. This \nincluded tree-based ensembles (XGBoost, Random \nForest), a neural network (Fully Connected Neural \nNetworks), a kernel method (Support Vector Machine), \nand a linear model (Logistic Regression with ElasticNet). \nThe final classifier for reporting all primary results was \nselected based on the highest and most stable \nperformance \nin \nthis \nbenchmark, \nwith \ndetailed \ncomparative results presented in Section 4.4. \n• E2E Model: We trained a long‑context transformer \n(ModernBERT [29], 8,192‑token context) with a \nclassification head under the same splits and evaluation \nprotocol. We fine‑tuned ModernBERT‑base (~149M \nparameters) with a classification head using a learning \nrate of 3e‑5, 8 epochs, a linear scheduler with a 10% \nwarm‑up ratio, max sequence length 8,192 (ensuring no \ntruncation of our longest profiles), and early stopping on \nvalidation AUC‑ROC within inner folds. Training used \nthe same repeated stratified CV splits as above. \n• Evaluation Protocol: All models were evaluated using \n10× repeated 5-fold stratified cross-validation with inner \nhyperparameter tuning. Primary metrics were Receiver \nOperating Characteristic Curve (AUC-ROC) and Area \nUnder the Precision-Recall Curve (AUC-PRC), both \nappropriate for imbalanced outcomes. \nH. Statistical and Interpretation Analysis \nModel performance was evaluated across the 10× repeated \n5-fold cross-validation runs. To compare distributions between \nmodels, we applied the non-parametric Wilcoxon signed-rank \ntest, which does not assume normality. A p-value < 0.05 was \nconsidered statistically significant. \nFor performance metrics (AUROC and AUPRC), 95% \nconfidence intervals were estimated using bootstrapping with \n1,000 resamples, providing robust uncertainty estimates. \nTo interpret the contribution of each data modality in the \nbest-performing GKC model, we applied SHapley Additive \nexPlanations (SHAP) [30] This approach quantifies the \nmarginal contribution of features from laboratory, genomic, and \nmedication streams, enabling a transparent assessment of how \neach modality informs model predictions. SHAP outputs were \nanalyzed both globally (across the entire cohort) and locally (per \npatient) to support interpretability in clinical contexts. \nIII. RESULTS  \nThis section presents the predictive performance of our \nproposed and baseline models on the task of 1-year survival \nprediction in lung cancer patients. Our key finding is that the \nGoal-oriented Knowledge Curator (GKC) model substantially \noutperformed all baselines, demonstrating that task-aligned \nsemantic summarization provides measurable gains in a data-\nscarce and heterogeneous clinical setting. Importantly, these \nimprovements address a clinically critical challenge: enabling \nrobust survival prediction even when multi-modal data are \nincomplete, sparse, or unevenly distributed. We organize the \nresults into three parts: (1) primary comparisons against baseline \nstrategies, (2) robustness of classifier choice, (3) ablation \nanalyses quantifying the synergistic effects of multi-modality, \nand (4) an in-depth qualitative case study illustrating \ninterpretability and clinical relevance.  \nA. Experimental Design and Evaluation Metrics  \nAll models were evaluated on 1-year survival prediction in a \ncohort of 184 lung cancer patients, using a 10-times repeated 5-\nfold stratified cross-validation scheme to provide stable \nestimates and reduce variance from small sample sizes. \nStratification ensured balanced outcome proportions across \nfolds, and all preprocessing steps were contained strictly within \ntraining folds to prevent information leakage. \n"}, {"page": 6, "text": " \n \n \nWe report two complementary performance metrics: Area \nUnder the Receiver Operating Characteristic Curve (AUC-\nROC), which measures overall discriminative ability, and Area \nUnder the Precision-Recall Curve (AUC-PRC), which is \nparticularly informative under class imbalance. To assess \nrobustness, 95% confidence intervals were obtained via \nbootstrapping. Statistical significance of model differences was \nevaluated with the non-parametric Wilcoxon signed-rank test (p \n< 0.05), ensuring fair and distribution-free comparison across \nidentical validation protocols. \nB. Primary Finding: Superiority of LLM-based Semantic \nSummarization \nOur primary analysis, summarized in Fig. 3, demonstrates a \nclear and consistent performance hierarchy across the evaluated \nfeature engineering strategies. The expert-engineered numerical \nbaseline (ENF Model) showed only modest discriminative \nability, with a mean AUC-ROC of 0.619 (95% CI: 0.618–0.621) \nand AUC-PRC of 0.713 (95% CI: 0.708–0.718), underscoring \nthe limitations of purely numerical, context-free encoding. \nIntroducing semantic enrichment through contextual biomedical \ntext embedding (CTE Model) improved performance to an \nAUC-ROC of 0.678 (95% CI: 0.675–0.681) and AUC-PRC of \n0.771 (95% CI: 0.768–0.775), highlighting the value of \nleveraging biomedical knowledge bases to capture context that \nnumeric features alone cannot provide. \nTo test whether a large-scale end-to-end approach could \novercome these limitations, we trained a long-context \ntransformer (E2E Model, ModernBERT, 8k tokens) directly on \nthe same contextual inputs used in the CTE model. Despite its \narchitectural capacity, the model achieved similar performance \n(AUC-ROC 0.675, 95% CI: 0.663–0.685; AUC-PRC 0.781, 95% \nCI: 0.772–0.791), with no statistically significant difference \nfrom CTE (Wilcoxon p=0.770 for AUC-ROC; p=0.105 for \nAUC-PRC). This finding indicates that simply scaling up the \narchitecture without explicit knowledge curation does not \novercome the inherent challenges of sparse, heterogeneous \nclinical data. \nBy contrast, our proposed Goal-oriented Knowledge Curator \n(GKC) model achieved a decisive leap in predictive accuracy, \nreaching an AUC-ROC of 0.803 (95% CI: 0.799–0.807) and \nAUC-PRC of 0.859 (95% CI: 0.855–0.862). Improvements \nwere statistically significant compared with all baselines \n(p<0.05 across both metrics), demonstrating that explicit, task-\naligned summarization captures clinically salient information \nthat is missed by both numerical aggregation and generic \nembeddings. To examine whether this advantage was merely a \nfunction of LLM choice, we tested a biomedical-specific variant \nof GKC using MedFound-176B [31]. This configuration \nachieved an AUC-ROC of 0.752 and AUC-PRC of 0.832, higher \nthan traditional baselines but still inferior to our optimal GKC \nsetup. Together, these findings indicate that the core strength of \nour framework lies not in model scale or domain specialization, \nbut in its design principles of goal-aligned summarization and \nefficient offline representation. \nFrom a clinical perspective, these findings underscore that \nsurvival prediction in lung cancer depends not merely on the \nquantity of data available but on how heterogeneous inputs are \ndistilled into meaningful, interpretable representations. The \nGKC framework reflects the way oncologists synthesize \nlaboratory results, genomic profiles, and medication histories \ninto concise, decision-ready narratives. In this way, our results \ndemonstrate that the quality of representation, rather than the \nraw volume of data, is the critical determinant of predictive \naccuracy in this setting. \nC. Robustness of the Predictive Classifier  \nTo evaluate the optimal classifier for LLM-derived semantic \nfeatures, we benchmarked multiple standard machine learning \nalgorithms on the identical feature set produced by the GKC \nmodel. As shown in Fig. 4, tree-based ensemble methods \nprovided the most reliable performance. XGBoost achieved the \nhighest mean AUC-ROC of 0.800 (±0.006) and a corresponding \nAUC-PRC of 0.859, followed by Random Forest with an AUC-\nROC of 0.760 (±0.007). In contrast, high-capacity models such \nas Fully Connected Neural Networks yielded both lower \naccuracy (AUC-ROC 0.720 ±0.012) and greater variance across \nfolds, reflecting overfitting in this small-sample regime (N=184). \nThese findings demonstrate that tree-based ensembles are \nparticularly well suited to dense embedding features in sparse \nclinical datasets, where their built-in regularization and capacity \nfor nonlinear interaction modeling provide stability without \nFigure 3: Comparative performance of feature engineering strategies \nfor 1-year survival prediction in lung cancer. Box plots show mean \nAUC-ROC and AUC-PRC across four approaches: numerical encoding \n(ENF), contextual text embedding (CTE), end-to-end transformer (E2E), \nand the proposed Goal-oriented Knowledge Curator (GKC). The GKC \nmodel significantly outperformed all baselines (p<0.05), achieving both \nhigher discrimination and precision-recall balance. These results \nhighlight that task-aligned semantic summarization provides clinically \nmeaningful improvements over conventional tabular, embedding-based, \nor end-to-end strategies. Error bars denote standard deviation. Asterisks \nindicate statistically significant differences. \n"}, {"page": 7, "text": " \n \nsacrificing discriminative power. Based on this evidence, \nXGBoost was chosen as the primary classifier for all subsequent \nanalyses. Clinically, this result underscores that methodological \nrigor in model choice can substantially impact predictive \nreliability, particularly in rare or data-limited patient cohorts. \n \nD. Synergistic Effect of Multi-Modality (Ablation Study)  \nWe next conducted an ablation study to quantify the \nindividual and combined contributions of laboratory, genomic, \nand medication modalities. Fig. 5 summarizes results across all \nseven possible modality combinations. Among single modalities, \nmedication history emerged as the strongest individual predictor \n(AUC-ROC 0.640; AUC-PRC 0.742), outperforming both \ngenomic data (AUC-ROC 0.590; AUC-PRC 0.701) and \nlaboratory tests (AUC-ROC 0.580; AUC-PRC 0.695). This \nsuggests that therapeutic intent and treatment trajectory encode \ncritical early survival signals. \nThe most striking finding was the synergistic benefit of \ncombining modalities. Performance improved monotonically as \nmore data streams were integrated, with the Gene+Med pairing \nyielding a marked boost (AUC-ROC 0.760; AUC-PRC 0.830). \nUltimately, the full tri-modal integration (Lab+Gene+Med) \ndelivered the best results, achieving AUC-ROC 0.800 and AUC-\nPRC 0.860. These gains were statistically significant (Wilcoxon \np<0.05 across comparisons), confirming that each modality \nprovides unique, complementary information. Clinically, this \nfinding validates the multidisciplinary perspective already \nemployed by oncology teams, where survival is best understood \nby synthesizing pharmacologic, genomic, and physiologic \nevidence rather than treating them in isolation. \n \nE. Modality Importance in the Final Model (SHAP Analysis)  \nTo better understand why the tri-modal GKC model \nsucceeds, we decomposed the predictive signal using SHAP. \nResults are shown in Fig. 6. At the global level, all three \nmodalities contributed almost equally (Medication 33.2%, Gene \n33.9%, Lab 32.9%), with pairwise tests confirming that none \ndominated (all p>0.05). This balance demonstrates that the \nmodel does not rely on a single “silver bullet” input, but instead \nintegrates complementary signals across domains. \nAt the patient level, the boxplot distribution (Fig. 6B) \nrevealed natural variability, where some patients’ predictions \nwere driven more by medications and others by genomics or labs. \nThis reflects real-world oncology practice, in which certain \npatients’ outcomes hinge more on pharmacologic trajectories \n(e.g., checkpoint inhibitors), while others are better explained by \nmolecular drivers or physiologic frailty. Clinically, this balanced \nreliance is reassuring: it indicates that the GKC framework \nlearns to weigh whichever modality is most informative for each \nindividual, much like a multidisciplinary care team does in \npractice. This modality-level interpretability provides both \nmechanistic validation and practical transparency for potential \ndeployment. \nFigure 4: Comparative Performance of Predictive Classifiers on \nGKC Model Features. Mean AUC-ROC and AUC-PRC for five \nstandard machine learning algorithms trained on the LLM-generated \nfeatures from GKC Model. XGBoost achieved the highest performance \nacross both metrics, justifying its selection as the primary classifier for \nthis study. \nFigure 5: Ablation Study of Modality Contribution to Treatment \nOutcome Prediction Performance. Mean AUC-ROC and AUC-PRC \nperformance from an ablation study on GKC Model, evaluating all \ncombinations of Lab, Gene, and Med data. The results show a clear \nstepwise improvement as modalities are combined, with the full three-\nmodality model achieving the highest performance. This demonstrates \nthat \neach \nmodality \nprovides \ncomplementary, \nnon-redundant \ninformation. \n \n"}, {"page": 8, "text": " \n \n \nF. In-depth Qualitative Case Study \nTo illustrate the mechanism of “knowledge curation” \nbeyond numerical performance, we present a representative \npatient case with seven oncogenic alterations (REL, RICTOR, \nMDM2, CDK4, ALK, ATR, KRAS). The raw input consisted \nof a concatenated, verbose profile from biomedical databases, \nspanning several thousand tokens and filled with redundant or \ntangential associations. \nThe GKC pipeline transformed this into a concise, structured \nJSON report as shown in Fig. 7, performing three expert-like \ninterpretive tasks that highlight the framework’s potential for \nclinically meaningful synthesis: \n1. Noise filtration: irrelevant entries (e.g., non-cancer \nfunctions of REL) were removed, and redundant \npathway mentions consolidated. \n2. Clinical inference potential: the LLM highlighted the \nco-occurrence of KRAS mutation and MDM2 \namplification as a synergistic “double-hit,” suggesting \nits potential negative prognostic implication. This \nrelationship is not explicitly present in the raw text and \nindicates that the system can surface higher-order \nassociations resembling what is often emphasized in \nexpert tumor board discussions, rather than being \nlimited to literal text extraction. \n3. Holistic \nsynthesis: \nthe \nseven \nmutations \nwere \ncontextualized into an “aggressive, therapy-resistant \nphenotype with genomic instability,” distilling disparate \nevidence into a coherent prognostic picture. \nThis restructuring turned an unwieldy gene-centric list into a \ngoal-aligned prognostic summary, with fields such as prognostic \nsummary and key negative factors. Importantly, the \ntransformation was deterministic and reproducible, minimizing \nstochastic variability often associated with LLMs.  \nClinically, this case illustrates how the GKC framework can \napproximate aspects of oncologists’ interpretive practices: \nfiltering noise, identifying potential synergies, and restructuring \nraw molecular data into actionable, interpretable insights. This \nqualitative evidence complements the quantitative performance \nlift, showing that our approach achieves its impact not by brute \ncomputational scale but by aligning LLM outputs with clinical \ninterpretive practices. \nIV. DISCUSSION  \nThis study demonstrates that task-aligned semantic \nsummarization by large language models (LLMs) can unlock \npredictive signal from sparse, heterogeneous real-world \noncology data. By positioning LLMs as “Goal-oriented \nGene Report Example \n{    \n1. \"prognostic_summary\": \"This patient's genomic profile \nsuggests an aggressive tumor phenotype with a potentially poor \nprognosis. The presence of mutant KRAS alongside MDM2 \namplification indicates strong activation of proliferative and \nsurvival signaling pathways, especially MAPK, PI3K-Akt, and \np53, which is further augmented by CDK4 activation. Concurrent \nREL activation suggests increased inflammatory response and NF-\nkB signaling, promoting tumor survival and immune evasion. \nATR mutations may compromise DNA damage repair, promoting \ngenomic \ninstability \nand \npotentially \naccelerating \ntumor \nprogression, while RICTOR activation may further contribute to \ncell growth and survival. The interplay of these mutations suggests \na highly proliferative, therapy-resistant tumor, which might be less \nresponsive to conventional treatments.\", \n2.  \"key_prognostic_domains\": { \n2.1    \"oncogenic_driver_pathways_activated\": [ \n      \"Ras signaling pathway\", \n      \"PI3K-Akt signaling pathway\", \n      \"Cell cycle (CDK4)\", \n      \"NF-kB signaling pathway (REL)\", \n      \"mTORC2 signaling (RICTOR)\"    ], \n2.2    \"tumor_suppressor_pathways_inactivated\": [ \n      \"p53 signaling pathway (MDM2 mediated)\", \n      \"DNA damage repair (ATR)\"    ], \n2.3    \"therapeutic_implications\": [ \n      \"Potential resistance to therapies targeting p53\", \n      \"Potential sensitivity to MEK or PI3K inhibitors (KRAS)\", \n      \"Potential sensitivity to CDK4/6 inhibitors (CDK4)\", \n      \"Potential sensitivity to ATR inhibitors but resistance if \nresistance mutations develop.“ ] \n  }, \n3.  \"key_positive_factors\": [], \n4.  \"key_negative_factors\": [ \n    \"Concurrent KRAS mutation and MDM2 amplification.\", \n    \"ATR mutation suggests genomic instability.\", \n    \"REL activation promoting survival and immune evasion.\"  ]} \nFigure 7: Gene Report Example generated by the Goal-oriented \nKnowledge Curator (GKC) framework. The structured output \nsummarizes seven oncogenic alterations into a concise prognostic \nprofile, highlighting activated driver pathways, inactivated tumor-\nsuppressor functions, and therapeutic implications. Key negative factors \nsuch as concurrent KRAS mutation with MDM2 amplification are \nexplicitly identified, demonstrating how GKC transforms verbose \ngenomic data into clinically interpretable insights.  \nFigure 6: Balanced Contribution of Multi-Modal Features to \nTreatment Outcome Prediction. SHAP analysis of the final prediction \nmodel. (A) The mean global feature importance is almost equally \ndistributed among the Lab, Gene, and Medication modalities. (B) Box \nplots showing the distribution of per-patient contributions confirm this \nbalanced interplay. This result provides a mechanistic explanation for \nour model's success, demonstrating that it learns by flexibly integrating \nall three independent information streams rather than relying on a single \ndominant modality.  \n"}, {"page": 9, "text": " \n \nKnowledge Curators,” we showed consistent and significant \nimprovements over numerical baselines, contextual embeddings, \nand even a powerful long-context transformer baseline. These \nfindings establish representation quality—not just data \nquantity—as a critical driver of predictive accuracy in clinical \nAI. \nA central insight of this work is that the “small data” problem \nextends beyond limited sample size. Conventional numerical \nfeatures strip away latent clinical meaning, whereas our \nmodality-specific summaries preserve the same interpretive \ncontext that oncologists extract when integrating evidence \nacross labs, genomics, and medications. The superior \nperformance of our framework demonstrates that models can \napproximate expert-like synthesis when provided with concise, \ntask-aligned representations. \nOur ablation analysis reinforces the importance of holistic \nintegration. Each modality contributed distinct perspectives: \nmedications captured therapeutic trajectory, genomics provided \nthe biological blueprint, and laboratories reflected the dynamic \nphysiological state. The highest accuracy was achieved only \nwhen all three were combined (AUC-ROC 0.803, AUC-PRC \n0.859). Importantly, the synergy observed between genomics \nand medications highlights how biological and therapeutic \nsignals must be interpreted together to approximate clinical \ndecision-making. \nA noteworthy and somewhat counterintuitive finding was \nthat our general-purpose LLM summarizer outperformed a \nbiomedical-specific model (MedFound-176B). We interpret this \nto reflect the nature of our task: the challenge is not simply \nbiomedical fact retrieval, but complex instruction-following and \nsynthesis into prognostic narratives. General-purpose LLMs, \ntrained on diverse textual forms and interpretive patterns, may \nbe particularly suited for such task-oriented knowledge curation. \nThis finding suggests that model scale and domain \nspecialization are secondary to framework design—goal-\naligned summarization and efficient offline representation are \nthe real drivers of performance. \nMechanistically, SHAP analysis revealed a balanced \ncontribution across all modalities. Rather than depending on a \nsingle dominant input, the model flexibly combined independent, \nhigh-fidelity streams. This validates our design choice to \npreserve modality-specific structure before integration, ensuring \nthat clinically meaningful interactions are not prematurely lost. \nDespite these encouraging results, several limitations must \nbe acknowledged. First, this proof-of-concept study was limited \nto a single institution with a modest sample size (N=184). While \nthis setting magnified the value of semantic summarization in \novercoming data scarcity, external validation on larger, multi-\ninstitutional cohorts is essential. Second, our inputs were \nrestricted to structured and semi-structured data; unstructured \nclinical narratives and imaging, which contain valuable \ninformation such as staging details and radiologic response, \nremain untapped. Third, the current implementation relies on \nproprietary APIs. While we demonstrated that the operational \ncost (~$0.001 per patient) and latency (≈1.6 seconds per patient) \nare negligible for deployment, further work with open-source \nmodels will be critical to ensure long-term reproducibility and \naccessibility. \nFuture directions include validation across cancers and \ninstitutions, integration of additional modalities such as \npathology and imaging, and exploration of deployment \npathways into clinical decision-support workflows. The \nmodularity of our pipeline makes it inherently adaptable: as \nopen-source LLMs and embedding models improve, they can be \nswapped into our framework without altering its core principles. \nUltimately, by aligning representation with clinical synthesis \nand abstraction, our approach offers a scalable foundation for \nprecision oncology in real-world practice. \nV. CONCLUSION \nIn this work, we confronted the challenge of prediction of \ntreatment outcomes from sparse, real-world clinical data. We \nhypothesized that the limitations of traditional numerical \nfeatures could be overcome by leveraging LLMs to generate \nhigh-quality, semantically rich features. To test this, we \ndeveloped a novel 'Goal-oriented Knowledge Curator' \nframework, where LLMs transform raw, multi-modal data (Lab, \nGenomics, Medication) into modality-specific modality \nsummaries. Our experiments systematically demonstrated the \nsuperiority of this approach, with our final model achieving best \nperformance with AUC-ROC of 0.803 and AUC-PRC of 0.859. \nThe primary contribution of this study is the finding that the \noptimal role for LLMs in this domain is as goal-oriented \nknowledge curators, generating high-fidelity intermediate \nfeatures for a downstream classifier. By capturing the \ncomplementary interplay among the biological 'blueprint' \n(Genomics), physiological 'state' (Lab), and therapeutic \n'trajectory' (Medication), our approach delivers a new \ncomputational paradigm with immediate clinical relevance and \nbroad future applicability for precision medicine in data-scarce \nenvironments. \nACKNOWLEDGMENT  \n \nREFERENCES \n[1]  H. Sung, J. Ferlay, R. L. Siegel, M. Laversanne, I. Soerjomataram, A. \nJemal, and F. Bray, 2021. Global Cancer Statistics 2020: GLOBOCAN \nEstimates of Incidence and Mortality Worldwide for 36 Cancers in 185 \nCountries. CA Cancer J Clin 71, 3 (May), 209-249.  \n[2] F. Bray, J. Ferlay, I. Soerjomataram, R. L. Siegel, L. A. Torre, and A. Jemal, \n2018. Global cancer statistics 2018: GLOBOCAN estimates of incidence and \nmortality worldwide for 36 cancers in 185 countries. CA Cancer J Clin 68, 6 \n(Nov), 394-424.  \n[3] G. S. Collins, J. B. Reitsma, D. G. Altman, and K. G. Moons, 2015. \nTransparent Reporting of a multivariable prediction model for Individual \nPrognosis or Diagnosis (TRIPOD): the TRIPOD statement. Ann Intern Med \n162, 1 (Jan 6), 55-63.  \n[4] Richard D. Riley, Danielle Van Der Windt, Peter Croft, and Karel G. M. \nMoons, 2019. Prognosis Research in Healthcare: Concepts, Methods, and \nImpact. Oxford University Press. \n[5] F. C. Detterbeck, G. A. Woodard, A. S. Bader, S. Dacic, M. J. Grant, H. S. \nPark, and L. T. Tanoue, 2024. The Proposed Ninth Edition TNM \nClassification of Lung Cancer. Chest 166, 4 (Oct), 882-895.  \n[6] O. Lababede and M. A. Meziane, 2018. The Eighth Edition of TNM Staging \nof Lung Cancer: Reference Chart and Diagrams. Oncologist 23, 7 (Jul), 844-\n848.  \n[7] K. Chansky, J. P. Sculier, J. J. Crowley, D. Giroux, . . . Institutions \nParticipating, 2009. The International Association for the Study of Lung \nCancer Staging Project: prognostic factors and pathologic TNM stage in \nsurgically managed non-small cell lung cancer. J Thorac Oncol 4, 7 (Jul), 792-\n801.  \n"}, {"page": 10, "text": " \n \n[8] J. P. Sculier, K. Chansky, J. J. Crowley, J. Van Meerbeeck, P. Goldstraw, \nCommittee International Staging, and Institutions Participating, 2008. The \nimpact of additional prognostic factors on survival and their relationship with \nthe anatomical extent of disease expressed by the 6th Edition of the TNM \nClassification of Malignant Tumors and the proposals for the 7th Edition. J \nThorac Oncol 3, 5 (May), 457-466.  \n[9] G. Cuyun Carter, A. M. Barrett, J. A. Kaye, A. M. Liepa, K. B. Winfree, \nand W. J. John, 2014. A comprehensive review of nongenetic prognostic and \npredictive factors influencing the heterogeneity of outcomes in advanced non-\nsmall-cell lung cancer. Cancer Manag Res 6, 437-449.  \n[10] X. Ruan, Y. Ye, W. Cheng, L. Xu, . . . F. Yan, 2022. Multi-Omics \nIntegrative Analysis of Lung Adenocarcinoma: An in silico Profiling for \nPrecise Medicine. Front Med (Lausanne) 9, 894338.  \n[11] A. Cheerla and O. Gevaert, 2019. Deep learning with multimodal \nrepresentation for pancancer prognosis prediction. Bioinformatics 35, 14 (Jul \n15), i446-i454.  \n[12] R. J. Chen, M. Y. Lu, J. Wang, D. F. K. Williamson, S. J. Rodig, N. I. \nLindeman, and F. Mahmood, 2022. Pathomic Fusion: An Integrated \nFramework for Fusing Histopathology and Genomic Features for Cancer \nDiagnosis and Prognosis. IEEE Trans Med Imaging 41, 4 (Apr), 757-770.  \n[13] D. Guo, Y. Wang, J. Chen, and X. Liu, 2024. Integration of multi-omics \ndata for survival prediction of lung adenocarcinoma. Comput Methods \nPrograms Biomed 250(Jun), 108192.  \n[14] J. N. Acosta, G. J. Falcone, P. Rajpurkar, and E. J. Topol, 2022. \nMultimodal biomedical AI. Nat Med 28, 9 (Sep), 1773-1784.  \n[15] L. Rasmy, Y. Xiang, Z. Xie, C. Tao, and D. Zhi, 2021. Med-BERT: \npretrained contextualized embeddings on large-scale structured electronic \nhealth records for disease prediction. Npj Digital Medicine 4, 1 (May 20), 86.  \n[16] K. Singhal, S. Azizi, T. Tu, S. S. Mahdavi, . . . V. Natarajan, 2023. Large \nlanguage models encode clinical knowledge. Nature 620, 7972 (Aug), 172-\n180.  \n[17] Tao Tu, Shekoofeh Azizi, Danny Driess, Mike Schaekermann, . . . Ira \nKtena, 2024. Towards generalist biomedical AI. Nejm Ai 1, 3, AIoa2300138. \n[18] Harsha Nori, Yin Tat Lee, Sheng Zhang, Dean Carignan, . . . Weishung \nLiu, 2023. Can generalist foundation models outcompete special-purpose \ntuning? case study in medicine. arXiv preprint arXiv:2311.16452. \n[19] Craig Knox, Mike Wilson, Christen M Klinger, Mark Franklin, . . . Seth A \nStrawbridge, 2024. DrugBank 6.0: the DrugBank knowledgebase for 2024. \nNucleic acids research 52, D1, D1265-D1275. \n[20] E. W. Sayers, J. Beck, E. E. Bolton, J. R. Brister, . . . K. D. Pruitt, 2025. \nDatabase resources of the National Center for Biotechnology Information in \n2025. Nucleic Acids Res 53, D1 (Jan 6), D20-D29.  \n[21] M. Kanehisa, M. Furumichi, Y. Sato, Y. Matsuura, and M. Ishiguro-\nWatanabe, 2025. KEGG: biological systems database as a model of the real \nworld. Nucleic Acids Res 53, D1 (Jan 6), D672-D677.  \n[22] M. Ashburner, C. A. Ball, J. A. Blake, D. Botstein, . . . G. Sherlock, 2000. \nGene ontology: tool for the unification of biology. The Gene Ontology \nConsortium. Nat Genet 25, 1 (May), 25-29.  \n[23] The Gene Ontology Consortium and Suzi A Aleksander and James Balhoff \nand Seth Carbon, . . . Monte Westerfield, 2023. The Gene Ontology \nknowledgebase in 2023. Genetics 224, 1.  \n[24] Stefan Diem, Sabine Schmid, Mirjam Krapf, Lukas Flatz, . . . Martin Früh, \n2017. Neutrophil-to-Lymphocyte ratio (NLR) and Platelet-to-Lymphocyte \nratio (PLR) as prognostic markers in patients with non-small cell lung cancer \n(NSCLC) treated with nivolumab. Lung cancer 111, 176-181. \n[25] Dan Li, Xia Yuan, Jia Liu, Changling Li, and Weimin Li, 2018. Prognostic \nvalue of prognostic nutritional index in lung cancer: a meta-analysis. Journal \nof thoracic disease 10, 9, 5298. \n[26] Gemini Team, Rohan Anil, Sebastian Borgeaud, Jean-Baptiste Alayrac, . . \n. Katie Millican, 2023. Gemini: a family of highly capable multimodal models. \narXiv preprint arXiv:2312.11805. \n[27] Yubin Kim, Hyewon Jeong, Shan Chen, Shuyue Stella Li, . . . Rodrigo \nGameiro, 2025. Medical hallucinations in foundation models and their impact \non healthcare. arXiv preprint arXiv:2503.05777. \n[28] Jinhyuk Lee, Zhuyun Dai, Xiaoqi Ren, Blair Chen, . . . Wen Ding, 2024. \nGecko: Versatile text embeddings distilled from large language models. arXiv \npreprint arXiv:2403.20327. \n[29] Benjamin Warner, Antoine Chaffin, Benjamin Clavié, Orion Weller, . . . \nTom Aarsen, 2024. Smarter, better, faster, longer: A modern bidirectional \nencoder for fast, memory efficient, and long context finetuning and inference. \narXiv preprint arXiv:2412.13663. \n[30] Scott M Lundberg and Su-In Lee, 2017. A unified approach to interpreting \nmodel predictions. Advances in neural information processing systems 30. \n[31] X. Liu, H. Liu, G. Yang, Z. Jiang, . . . G. Wang, 2025. A generalist medical \nlanguage model for disease diagnosis assistance. Nat Med 31, 3 (Mar), 932-\n942.  \n \n \n"}]}