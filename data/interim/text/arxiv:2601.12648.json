{"doc_id": "arxiv:2601.12648", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2601.12648.pdf", "meta": {"doc_id": "arxiv:2601.12648", "source": "arxiv", "arxiv_id": "2601.12648", "title": "Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?", "authors": ["Nafiz Imtiaz Khan", "Kylie Cleland", "Vladimir Filkov", "Roger Eric Goldman"], "published": "2026-01-19T01:45:51Z", "updated": "2026-01-19T01:45:51Z", "summary": "Procedural case logs are a core requirement in radiology training, yet they are time-consuming to complete and prone to inconsistency when authored manually. This study investigates whether large language models (LLMs) can automate procedural case log documentation directly from free-text radiology reports. We evaluate multiple local and commercial LLMs under instruction-based and chain-of-thought prompting to extract structured procedural information from 414 curated interventional radiology reports authored by nine residents between 2018 and 2024. Model performance is assessed using sensitivity, specificity, and F1-score, alongside inference latency and token efficiency to estimate operational cost. Results show that both local and commercial models achieve strong extraction performance, with best F1-scores approaching 0.87, while exhibiting different trade-offs between speed and cost. Automation using LLMs has the potential to substantially reduce clerical burden for trainees and improve consistency in case logging. These findings demonstrate the feasibility of AI-assisted documentation in medical education and highlight the need for further validation across institutions and clinical workflows.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2601.12648v1", "url_pdf": "https://arxiv.org/pdf/2601.12648.pdf", "meta_path": "data/raw/arxiv/meta/2601.12648.json", "sha256": "31b541d01dfd9c6e4e45e17c9ef9ce617fa7215c0e53927813ae87c51c3948fd", "status": "ok", "fetched_at": "2026-02-18T02:21:13.643091+00:00"}, "pages": [{"page": 1, "text": "Intelligent Documentation in Medical Education: Can AI Replace\nManual Case Logging?\nNafiz Imtiaz Khan, MSc∗\nDepartment of Computer Science, University of California, Davis, CA, USA\nKylie Cleland, BSc\nDepartment of Radiology, University of California, Davis, CA, USA\nVladimir Filkov, PhD\nDepartment of Computer Science, University of California, Davis, CA, USA\nRoger Eric Goldman, PhD\nDepartment of Radiology, University of California, Davis, CA, USA\nAbstract\nObjective: This study investigates the feasibility of\nusing large language models (LLMs) to automate pro-\ncedural case log documentation in radiology training.\nWe evaluate whether AI can replace manual logging,\nidentify which procedure types are most challeng-\ning for extraction, and assess integration into clinical\nworkflows.\nMaterials and Methods: We retrospectively an-\nalyzed 414 curated radiology reports authored by nine\ninterventional radiology residents between 2018 and\n2024.\nA set of candidate models, including local\n(Qwen-2.5) and commercial (Claude-3.5), were tested\nunder instruction and chain-of-thought prompting.\nPerformance was measured by sensitivity, specificity,\nand F1-score, along with inference time and token\nefficiency to estimate operational cost.\nResults: Both local and commercial LLMs out-\nperformed the standard benchmark.\nQwen-2.5\nachieved F1-scores of 86.66 with chain-of-thought\nprompting, while Claude-3.5-Haiku reached an F1-\nscore of 86.89%. Commercial inference delivered sub-\n2s latency and concise outputs, while local deploy-\nment traded speed for lower recurring cost. Automa-\ntion could save over 35 hours of manual annotation\nper resident annually.\nDiscussion:\nLLMs can provide a scalable and\naccurate solution for radiology case log documen-\ntation. Optimizing for procedure-specific challenges\nand ensuring seamless integration with existing sys-\n∗Corresponding author: Nafiz Imtiaz Khan, Department of\nComputer Science, University of California, Davis, CA 95616,\nUSA. Email: nikhan@ucdavis.edu\ntems will be essential. Future work should validate\nacross larger, multi-institution datasets and explore\nadditional prompting strategies.\nConclusion: LLMs show promise for automating\nradiology case log documentation, potentially reduc-\ning resident clerical burden.\nHowever, this single-\ninstitution feasibility study underscores the need for\nbroader validation across diverse institutions, assess-\nment of real-world workflow integration, and safe-\nguards against misclassification before clinical adop-\ntion.\nKeywords: artificial intelligence, large language\nmodels, radiology, case logs, medical education\nCorresponding\nAuthor:\nNafiz\nImtiaz\nKhan\n(nikhan@ucdavis.edu)\n1\nIntroduction\nAccurate and comprehensive clinical activity docu-\nmentation is paramount for medical education and\nprofessional practice [1]. Among the most critical ar-\ntifacts in this process are physician case logs, which\nserve as structured records that detail the types and\nfrequencies of procedures performed by individual\nclinicians. These logs are integral to multiple high-\nstakes functions.\nThey provide evidence for board\ncertification, serve as official documentation for cre-\ndentialing and privileging within hospitals, and sup-\nport quality assurance and performance evaluations\n[2, 3, 4, 5]. During medical training, case logs are\nespecially vital, enabling program directors to moni-\ntor resident progress, ensure exposure to a sufficient\nvariety and volume of procedures, and identify ar-\neas needing remediation. Importantly, these logs also\n1\narXiv:2601.12648v1  [cs.CL]  19 Jan 2026\n"}, {"page": 2, "text": "underpin institutional compliance with accreditation\nrequirements, such as those mandated by the Ac-\ncreditation Council for Graduate Medical Education\n(ACGME)1.\nHowever, the current reality of case log documen-\ntation in many specialties, particularly radiology, is\nthat the process remains highly manual, fragmented,\nand inefficient. Radiology trainees are typically re-\nquired to self-report the procedures they perform by\nentering data into spreadsheets or institutional log-\nging systems [6]. Each entry often includes detailed\nmetadata, such as the type of imaging modality, the\nanatomical site, the nature of the procedure, and\nwhether it was performed independently or under su-\npervision. According to Cox et al. [7], general resi-\ndents spend a median of 23.7 hours per week—nearly\n38% of their duty hours—engaged with the electronic\nhealth record (EHR). While this reflects overall doc-\numentation burden rather than case log entry specif-\nically, it highlights how clerical tasks consume sig-\nnificant trainee time.\nGiven that a radiology resi-\ndent may perform well over 1600 (typically 1500 to\n1800) procedures throughout their residency, the cu-\nmulative documentation burden is substantial. This\nmanual process consumes valuable time that could\notherwise be devoted to clinical learning or scholarly\nactivity. In addition, manual effort introduces consid-\nerable potential for errors and inconsistencies in the\ndocumentation. Moreover, the absence of real-time\nfeedback mechanisms limits the utility of these logs\nas tools for formative assessment.\nIn\nan\nera\nwhere\nnatural\nlanguage\nprocess-\ning\n(NLP)\nand\nmachine\nlearning\n(ML)\ntech-\nnologies—particularly\nlarge\nlanguage\nmodels\n(LLMs)—have\nmade\nsignificant\nadvancements\n[8, 9, 10], there exists a compelling opportunity\nto reimagine how procedural case logs are created\n[11, 12, 13, 14, 15, 16, 17, 18, 19]. Radiology reports,\nroutinely authored by radiology residents and attend-\nings, provide comprehensive narrative summaries of\ndiagnostic imaging encounters and are inherently\nrich in procedural detail. These reports are routinely\nproduced as part of standard clinical documentation\nand are stored in digital or semi-structured formats\nwithin Electronic Health Records (EHRs) [20], Ra-\ndiology Information Systems (RIS) [21], or Picture\nArchiving and Communication Systems (PACS) [22].\nUsing LLMs to automatically extract structured\nprocedural data from these unstructured narratives\ncould generate accurate procedural case logs with\nminimal human intervention.\nSuch automation\npromises not only to alleviate administrative burden\n1https://www.acgme.org/\nbut also to enhance the accuracy, completeness, and\ntimeliness of documentation. At the same time, prior\nexperience with clinical AI tools demonstrates the\nrisks of overclaiming performance without rigorous\nvalidation [23, 24], underscoring the importance of\ncautious evaluation in this domain.\nWhile the theoretical potential of LLMs in this\nspace is enticing, several important objectives mo-\ntivate this study.\nFirst, we assess whether AI can\neffectively automate procedural case log documenta-\ntion in radiology training, examining the feasibility\nand performance of using LLMs to convert narra-\ntive radiology reports into structured, loggable en-\ntries.\nSecond, we investigate whether performance\nvaries across procedure categories, identifying which\ncategories are difficult to classify, and explored the\nlinguistic or structural reasons behind these dispari-\nties. Finally, we examine the translational challenges\nof real-world deployment, including cost, and process-\ning time.\nIn sum, this is the first work that explores the inter-\nsection of artificial intelligence and procedural doc-\numentation in medical education by systematically\nevaluating the feasibility of automation, the varia-\ntion in accuracy across procedure categories, and the\npractical considerations for integration into clinical\nand educational workflows. Ultimately, we envision\na future in which intelligent systems reduce adminis-\ntrative burden, improve documentation quality, and\nallow medical trainees to devote more attention to\npatient care and professional development.\n2\nMethodology\nThis retrospective study was approved by the insti-\ntutional review board. The requirement of informed\nconsent for inclusion in the study was waived. No pro-\ntected health information is included in the reported\nresults.\n2.1\nData Collection\nWe retrospectively collected a dataset of raw radi-\nology reports from a tertiary-care academic medi-\ncal center, spanning the period from October 2018\nthrough September 2024.\nThese reports were au-\nthored by one of nine current or former Interven-\ntional Radiology (IR) residents. From this larger pool\n(36,659 reports across 301 unique exam codes, includ-\ning 162 distinct procedural codes), we curated a sub-\nset of 414 reports corresponding to 39 representative\nIR procedures. For each procedural exam code, at\nleast one corresponding radiology report was selected\nfor manual labeling. If a code was associated with\n2\n"}, {"page": 3, "text": "two reports, both were labeled. For codes with three\nor more associated reports, a random sample of three\nreports was selected for labeling. This ensured inclu-\nsion across the full range of required categories, but\nwe acknowledge the small sample size per category as\na limitation.\n2.2\nData Annotation\nFollowing data collection, we conducted a structured\nannotation process to determine which unique radiol-\nogy procedures were mentioned in each report. This\ntask involved identifying the presence or absence of\nany of 39 predefined radiology procedures, which were\nbased directly on the American Board of Radiology2\nCase Log.\nThe ABR case log was selected due to\nthe diversity of procedure categories, which closely\nmirrors individual hospital case log requirements for\nprivileges and is more granular than the ACGME\nlogs. Procedures were organized into three high-level\ncategories: Vascular Diagnosis (8 procedures), Vascu-\nlar Intervention (15), and Non-Vascular Intervention\n(16). The complete list is shown in Table 4.\nTwo independent annotators reviewed each report\nto assign binary labels for each of the 39 procedures:\none interventional radiology trainee and one board-\ncertified interventional radiologist with six years of\npost-graduate experience serving as an Assistant Pro-\nfessor at UC Davis Health. A label of 1 was assigned\nif a procedure was explicitly or implicitly mentioned\nin the report, and 0 otherwise.\nThe default label\nwas 0, and annotators marked 1 only when confident\na procedure was present. To assess labeling consis-\ntency, we calculated inter-annotator agreement using\nCohen’s Kappa, which accounts for chance agreement\n[25, 26]. The observed κ = 0.896 indicated strong\nagreement. Discrepancies were resolved by consen-\nsus, and the adjudicated labels served as the reference\nstandard.\n2.3\nData Pre-processing\nWe applied lightweight pre-processing to make the\nreports suitable for model inference.\nAll text was\nlowercased to reduce case-sensitivity bias.\nNon-\ninformative sections such as “attestation” and “adden-\ndum” were removed, as they typically contain admin-\nistrative or author-identifying information irrelevant\nto procedural content. Also, non-ASCII characters\nwere stripped to ensure tokenization compatibility.\n2https://www.theabr.org/\n2.4\nLLM Selection\nOur goal was to evaluate a set of local and commercial\nLLMs on their ability to extract procedural data from\nradiology reports. Importantly, this was an inference-\nonly study: no model training or fine-tuning was per-\nformed. All models were applied directly in zero-shot\nmode to the dataset, so a train/validation/test split\nwas not applicable.\n2.4.1\nSelection Criteria\nPrivacy and Compliance.\nGiven the sensitive\nnature of clinical data, model deployment was con-\nstrained to HIPAA-compliant environments.\nFor\ncommercial evaluation, we used the AWS Bedrock\nplatform3, which provides HIPAA-compliant infras-\ntructure. For local evaluation, models were run on an\ninstitutional secure server with HIPAA-aligned gov-\nernance.\nModel Type. We selected instruction-tuned mod-\nels, optimized for following prompts and returning\nstructured responses [27], since these are well-suited\nfor extraction tasks.\nHardware Constraints. Selection was also in-\nformed by available compute resources. Our local se-\ncure server had limited GPU memory, excluding ex-\ntremely large models. Server specifications are listed\nin Table B.1 of Appendix B.\nModel Version and Size. When multiple ver-\nsions existed, we chose the largest feasible variant\nwithin our hardware and compliance constraints. For\nexample, LLaMA 3.3-70B was used locally, while the\nmost performant model on AWS Bedrock at the time\n(Claude-3.5-Haiku, February 2025) was selected com-\nmercially.\n2.4.2\nSelected Models\nSix models were evaluated:\nfive open-source/local\nand one commercial. These included Mixtral-8x7B,\nLLaMA 3.3-70B,\nQwen 2.5-72B,\nMedLLaMA-2-7B,\nLLaMA-3-Med42-70B,\nand\nClaude-3.5-Haiku.\nModel details are provided in the Appendix E. No\nadditional fine-tuning was performed;\nall models\nwere evaluated as released by their developers.\n2.5\nBenchmark\nDefinition\n(Cross-\nwalk)\nFor comparison, we leveraged the “crosswalk” bench-\nmark [28], which is a rule-based mapping between\nexam codes or CPT codes and predefined procedure\n3https://aws.amazon.com/bedrock/\n3\n"}, {"page": 4, "text": "categories.\nFor example, CPT code 75625 corre-\nsponds to “Lower Extremity Angiography.” This ap-\nproach, while widely used and straightforward, is lim-\nited by coding variability and inability to capture\nmulti-procedure reports. As such, it offers high speci-\nficity but reduced sensitivity, and serves as a baseline\nagainst which LLM outputs can be compared.\n2.6\nPrompt Engineering\nTwo prompting strategies were tested with each\nmodel:\n(i) Instruction Prompting, where the task\nwas explicitly stated and the model was expected to\nreturn the output directly [29, 30], and (ii) Chain-\nof-Thought (CoT) prompting, where the model was\nguided to reason step-by-step before generating the fi-\nnal answer [31, 32]. CoT was implemented via a stan-\ndardized template enforcing stepwise reasoning and\na consistent output structure. No few-shot examples\nor fine-tuned prompts were introduced, to maintain\nconsistency across models.\n2.7\nPipeline Implementation\nWe developed a modular pipeline in Python to sup-\nport reproducible evaluation.\nThe pipeline man-\naged preprocessing, model querying (local via Ollama\n[33], cloud via AWS Bedrock), and logging of re-\nsults. Outputs were parsed into structured JSON and\nsaved with metadata (model, prompt type, report ID,\ntimestamp) for traceability. This ensured consistent\nhandling across all models and prompt strategies.\n2.8\nModel Evaluation\nWe evaluated model outputs against the adjudicated\nground truth labels. Metrics included True Positive\n(TP), True Negative (TN), False Positive (FP), False\nNegative (FN), Sensitivity, Specificity, and F1-score\n[34, 35]. We also tracked inference time and token\ncounts to estimate computational and financial costs.\nPerformance was summarized across all 39 proce-\ndure categories, with per-category error analysis con-\nducted to identify systematically difficult categories.\nAll evaluations were conducted under consistent ex-\nperimental conditions, following best practices such\nas STARD-AI for transparent reporting in medical\nAI [36].\n3\nResults\n3.1\nAutomating Procedural Case Log\nDocumentation\nWe evaluated model performance using a test set of\n414 radiology reports annotated by independent re-\nviewers.\nThe inter-annotator agreement, measured\nusing Cohen’s Kappa, was 0.896—indicating strong\nconsistency.\nDisagreements were resolved through\nconsensus to establish the final ground truth used for\nevaluation.\nTable 7 presents a detailed comparison between\nthe Crosswalk benchmark, the top-performing lo-\ncal model (Qwen-2.5:72B), and the top-performing\ncommercial model (Claude-3.5-Haiku) across two\nprompting strategies—Instruction Prompting (IP)\nand Chain-of-Thought (CoT)—as well as across three\nprocedural modality categories. The performance of\nother local models is provided in Table C.2 in the\nAppendix C.\nThe Crosswalk benchmark, which relies solely on\nstructured metadata from radiology reports, dis-\nplays excellent specificity across all categories (over-\nall specificity: 99.40%). This confirms its conserva-\ntive design, prioritizing false positive minimization.\nHowever, its sensitivity remains low (65.46%), in-\ndicating substantial under-detection of documented\nprocedures, particularly those mentioned only in free-\ntext. This trade-off is most pronounced in the Vascu-\nlar Intervention category, where sensitivity drops to\n59.02%, suggesting that the benchmark fails to cap-\nture many interventional procedures lacking struc-\ntured documentation. While Vascular Diagnosis and\nNon-Vascular Intervention fare slightly better (sen-\nsitivity: 63.84% and 75.88%, respectively), they still\nreflect the benchmark’s inherent limitation in sensi-\ntivity.\nIn contrast, the local model Qwen-2.5:72B demon-\nstrates marked improvements in both sensitivity and\noverall performance when augmented with prompt-\ning strategies. Under Instruction Prompting, Qwen\nachieves a sensitivity of 94.19% and specificity of\n98.17%, yielding a notable gain of +28.73% points in\nsensitivity over the Crosswalk baseline, without sub-\nstantially compromising specificity.\nThis results in\nan F1-score of 80.08—a lift over the benchmark. CoT\nprompting further improves the balance between sen-\nsitivity and specificity, with Qwen attaining a higher\nF1-score (86.66) among all local configurations. This\nis particularly driven by CoT’s effectiveness in reduc-\ning false positives in the Non-Vascular Intervention\ncategory (FP: 38 vs. 122 under IP), highlighting its\nability to support more nuanced reasoning in complex\n4\n"}, {"page": 5, "text": "textual contexts.\nThe commercial model Claude-3.5-Haiku similarly\nbenefits from both prompting paradigms.\nWith\nInstruction Prompting, it achieves a sensitivity of\n91.87%, specificity of 96.79%, and F1-score of 69.64.\nHowever, CoT prompting enhances performance fur-\nther: the F1-score rises to 86.89; the highest across all\nmodels and configurations—accompanied by an im-\nproved specificity of 99.29%. These results suggest\nthat Claude’s CoT-based reasoning is particularly\nbest-suited for the intricacies of radiology language.\nOn a per-modality basis, Claude demonstrates out-\nstanding sensitivity in Vascular Diagnosis (95.98%\nunder IP) and achieves the most consistent perfor-\nmance across all categories under CoT.\nA broader trend across all evaluated models is\nthat Vascular Diagnosis consistently yields the high-\nest sensitivity and F1-scores.\nThis is likely due to\nthe use of standardized terms and clear procedu-\nral language in the diagnostic procedural categories,\nwhich facilitates model understanding. On the other\nhand, Vascular Intervention remains the most chal-\nlenging category, especially for the Crosswalk bench-\nmark, but also for models operating under Instruction\nPrompting. The improved results from CoT prompt-\ning—particularly for Qwen (F1: 82.88) and Claude\n(F1: 85.55)—highlight the benefit of step-by-step rea-\nsoning in interpreting diverse and often implicit pro-\ncedural descriptions typical of interventional reports.\nOverall, these findings underscore the limitations\nof metadata-only benchmarks for procedure detec-\ntion and illustrate the potential of LLMs, especially\nwhen equipped with effective prompting strategies,\nto more accurately and comprehensively extract pro-\ncedural information from unstructured clinical text.\n3.2\nVariation Across Procedure Types\nTable D.4 in appendix D reports the number of false\npositives (FP) and false negatives (FN) committed\nby three algorithms—the Crosswalk benchmark, the\ntop-performing commercial model with CoT prompt-\ning (Claude-3.5-Haiku), and the top-performing local\nmodel with CoT prompting (Qwen-2.5:72B)—across\n39 radiological procedures.\nThis fine-grained error\nanalysis provides insight into procedure-level perfor-\nmance and helps assess whether certain procedures\nare consistently harder to detect.\nCompared to the Crosswalk benchmark (652 FNs,\n244 FPs), both LLMs achieve significant reductions\nin false negatives: Claude-3.5-Haiku reduces FNs to\n76, and Qwen-2.5:72B to 62. However, this gain in\nsensitivity comes at the cost of increased false pos-\nitives: Claude reports 109 FPs, while Qwen reports\n131—still lower than Crosswalk’s FP count.\nPoorly Classified Procedures. Certain proce-\ndures remain challenging for all models, with high\nerror rates suggesting inherent complexity or ambi-\nguity.\nNotably, Procedure 23 (Other, Vascular)\nand Procedure 39 (Other, NonVascular) exhibit the\nhighest cumulative errors across all three systems.\nFor example, Qwen reports 45 false positives on Pro-\ncedure 23 and both models struggle with Procedure\n39, where errors remain concentrated due to overlap-\nping semantics and subtle contextual clues.\nWell-Classified Procedures.\nSeveral proce-\ndures such as Procedure 2, Procedure 11, Procedure\n18, and Procedure 28 are consistently well-classified\nacross all models. These likely benefit from clearer\ntextual cues or isolated contexts.\nProcedures like\nProcedure 12, Procedure 16, and Procedure 30 show\nmodest improvements in both FP and FN rates with\nthe LLMs compared to Crosswalk.\nModel-Specific\nPatterns.\nClaude-3.5-Haiku\nmaintains a relatively balanced error profile with\nmoderate FPs and low FNs.\nIn contrast, Qwen-\n2.5:72B demonstrates aggressive prediction behav-\nior—especially in Procedure 23—resulting in more\nFPs but fewer FNs overall.\nThis behavior may be\nattributed to the model’s higher confidence threshold\nor broader generalization strategy.\n3.3\nPractical Deployment Considera-\ntions\nTable 2 presents descriptive statistics—including\nmaximum, minimum, mean, and standard devia-\ntion—for inference time and generated token count\nfor the Claude-3.5 Haiku and Qwen2.5:72B mod-\nels across the two prompting strategies:\nIP and\nCoT. The reported descriptive statistics reflect per-\nprocedure identification.\nTherefore,\nmultiplying\nthese values by 39 yields the corresponding per-report\nestimates.\nAdditionally, the cost metrics (inference time and\ngenerated token) of the additional local models are\npresented in Table C.3 in appendix C.\nInference Time. Inference Time/Latency is a key\noperational constraint in any real-world deployment.\nAmong the evaluated configurations, the commercial\nmodel Claude-3.5-Haiku using Instruction Prompting\n(IP) demonstrates the fastest average per-procedure\ninference time—1.97 seconds—with a minimum of\njust 1 second and maximum of 5 seconds. This near-\ninstant responsiveness positions Claude as a highly\npractical solution for interactive and high-volume use\ncases.\nIn contrast, the local model Qwen-2.5:70B,\nwhile effective in terms of accuracy, demonstrates\n5\n"}, {"page": 6, "text": "Table 1: Performance of the Crosswalk Benchmark Compared to the Top-Performing Local and Commercial\nLanguage Model\nModel Type\nModel-Name\nPrompting\nMethod\nModality\nTP\nTN\nFP\nFN\nSensitivity (%)\nSpecificity (%)\nF1-Score (%)\nBenchmark\nCross-Walk\nNA\nAll\n451\n15364\n93\n238\n65.46\n99.40\n73.15\nVascularDiagonsis\n143\n3065\n23\n81\n63.84\n99.26\n73.33\nVascularIntervention\n157\n5906\n38\n109\n59.02\n99.36\n68.11\nNonVascularIntervention\n151\n6393\n32\n48\n75.88\n99.50\n79.06\nLocal\nQwen-2.5:72B\nIP\nAll\n649\n15174\n283\n40\n94.19\n98.17\n80.08\nVascularDiagnosis\n219\n3068\n20\n5\n97.77\n99.35\n94.60\nVascularIntervention\n247\n5803\n141\n19\n92.86\n97.63\n75.54\nNonVascularIntervention\n183\n6303\n122\n16\n91.96\n98.10\n72.62\nCoT\nAll\n627\n15326\n131\n62\n91.00\n99.15\n86.66\nVascularDiagnosis\n214\n3071\n17\n10\n95.54\n99.45\n94.07\nVascularIntervention\n242\n5868\n76\n24\n90.98\n98.72\n82.88\nNonVascularIntervention\n171\n6387\n38\n28\n85.93\n99.41\n83.82\nCommercial\nClaude-3.5-Haiku\nIP\nAll\n633\n14961\n496\n56\n91.87\n96.79\n69.64\nVascularDiagnosis\n215\n3067\n21\n9\n95.98\n99.32\n93.48\nVascularIntervention\n230\n5737\n207\n36\n86.47\n96.52\n65.43\nNonVascularIntervention\n188\n6157\n268\n11\n94.47\n95.83\n57.41\nCoT\nAll\n613\n15348\n109\n76\n88.97\n99.29\n86.89\nVascularDiagnosis\n210\n3069\n19\n14\n93.75\n99.38\n92.71\nVascularIntervention\n228\n5905\n39\n38\n85.71\n99.34\n85.55\nNonVascularIntervention\n175\n6374\n51\n24\n87.94\n99.21\n82.35\nTable 2: Per Procedure Identiciation Cost of Running the Language Model in Relation to Inference Time\nand Generated Tokens\nModel Name\nModel\nType\nPrompting\nMethod\nInference Time (Second)\nGenerated Tokens (Count)\nMax\nMin\nMean\nStd Dev\nMax\nMin\nMean\nStd Dev\nQwen2.5:72B\nLocal\nIP\n20.00\n4.00\n9.70\n2.15\n127\n27\n63.01\n14.39\nCoT\n48.00\n9.00\n13.47\n3.23\n111\n26\n53.98\n12.27\nClaude-3.5-Haiku\nCommercial\nIP\n5.00\n1.00\n1.97\n0.70\n67\n13\n40.26\n9.77\nCoT\n15.00\n3.00\n6.97\n2.15\n80\n10\n29.79\n9.60\nTable 3: Comparative Cost of Running the Most Performant Models in Commercial (Claude-3.5-Haiku via\nAWS Bedrock) and Local (Qwen2.5:72B) Environments\nModel\nPrompting\nMethod\nCategory\nInput\n/ Time\nOutput Tokens\nCost (USD)\nClaude-3.5-Haiku\n(Commercial, AWS Bedrock)\nIP\nProcedure\n837.41 tokens\n40.05 tokens\n$0.0008\nReport\n32658.96 tokens\n1561.79 tokens\n$0.0324\nCoT\nProcedure\n1232.77 tokens\n30.84 tokens\n$0.0011\nReport\n48077.96 tokens\n1202.84 tokens\n$0.0433\nQwen2.5:72B\n(Local Server)\nIP\nProcedure\n9.70 s\n—\n$0.00094\nReport\n378.30 s\n—\n$0.03670\nCoT\nProcedure\n13.47 s\n—\n$0.00131\nReport\n525.33 s\n—\n$0.05096\n6\n"}, {"page": 7, "text": "Table 4: Categorization of procedures into predefined modality groups: Vascular Diagnosis, Vascular\nIntervention, and Non-Vascular Intervention\nCount\nProcedure Description\nModality\n1\nComputed Tomography Angiography (CTA)\nVascular\nDiagnosis\n2\nMagnetic Resonance Angiography (MRA)\n3\nNoninvasive vascular lab (duplex, color flow, PVRs, etc.)\n4\nCardiac Imaging\n5\nArteriography (all: peripheral, renal mesenteric, carotid, etc.)\n6\nVenography (all)\n7\nDialysis access evaluations\n8\nCarotid artery imaging\n9\nVenous access (all: tunneled, nontunneled, ports)\nVascular\nIntervention\n10\nIVC filter placement, retrieval\n11\nVenous ablation (varicose veins)\n12\nDialysis access intervention\n13\nTIPS & TIPS evaluation/revision\n14\nAngioplasty/stents/covered stents:\narterial (peripheral renal,\nmesenteric)\n15\nAngioplasty/stents/covered stents: venous (all)\n16\nCarotid stenting\n17\nThrombolytic therapy (all), thrombectomy\n18\nAortic endografting (thoracic and/or abdominal)\n19\nEmbolization, emergency (trauma, GI bleed, bronchial bleed,\nother)\n20\nEmbolization,\nelective (uterine fibroids,\nPAVMs,\nperipheral\nAVMs, varicoceles, etc.)\n21\nChemoembolization (TACE)\n22\nRadioembolization (selective internal radiotherapy)\n23\nOther, Vascular\n24\nBiopsy\nNon Vascular\nIntervention\n25\nAbscess drainage & tube checks\n26\nParacentesis, thoracentesis\n27\nChest tube placement\n28\nPleurodesis\n29\nPTC, biliary drainage, biliary stents; tube checks\n30\nNephrostomy, nephroureterostomy; tube checks\n31\nGastrostomy, gastrojejunostomy; tube checks\n32\nCholecystostomy; tube checks\n33\nAspiration, drainage, sclerosis (cyst, lymphocele); tube checks\n34\nStents, miscellaneous nonvascular (esophageal, tracheobronchial,\nduodenal, colonic)\n35\nTransplant interventions, miscellaneous\n36\nTumor ablation (RFA, laser, microwave, cryo, ethanol, other)\n37\nPain management\n38\nFallopian tube recanalization\n39\nOther, Nonvascular\n7\n"}, {"page": 8, "text": "a higher computational burden.\nUnder Chain-of-\nThought (CoT) prompting, it reaches a mean infer-\nence time of 13.47 seconds per procedure, with out-\nliers extending to 48 seconds. This latency may con-\nstrain scalability, particularly in batch-processing or\nreal-time scenarios, unless sufficient parallelization or\nhardware resources are available.\nToken Efficiency and Output Volume.\nTo-\nken generation affects not only the cost of the model,\nespecially in commercial settings, but also the in-\nterpretability and processing overhead. Claude-3.5-\nHaiku again leads in efficiency, with CoT prompt-\ning producing an average of 29.79 tokens per pro-\ncedure, and IP generating slightly longer responses\nat 40.26 tokens. By contrast, Qwen’s IP configura-\ntion yields significantly longer outputs (mean: 63.01\ntokens), suggesting more verbose justifications. Al-\nthough longer responses can provide more rationale,\nthey also increase downstream token-related costs\nand may slow user consumption of the output. Thus,\nfrom a human-in-the-loop perspective, Claude’s con-\ncise formatting is more aligned with practical review\nand integration.\nTable 3 details the estimated cost of running the\nQwen2.5:72B model in a local deployment environ-\nment, providing both per procedure and per report\ncosts in USD for the two strategies—IP and CoT.\nThese cost estimates are based on the model’s aver-\nage inference time, which serves as a practical proxy\nfor computational resource utilization in local set-\ntings. Specifically, the cost of running the local model\nis computed by multiplying the per-procedure infer-\nence time by the estimated per-second operational ex-\npense of the local server. This estimate incorporates\nhardware depreciation, electricity consumption, and\ngeneral infrastructure overhead.\nThe detailed cost\nbreakdown for operating the local system is outlined\nbelow.\nCost Calculation for Local Model. We per-\nformed inference on an NVIDIA A100 GPU with\n24GB VRAM equipped server. To quantify its oper-\national cost, we considered three main components:\nhardware depreciation, power consumption, and re-\ncurring overhead (e.g., maintenance, physical space,\nand administrative costs).\nThe A100 GPU with\n24GB VRAM has an upfront cost of approximately\n$8,000 USD [37, 38]. Commercial entities typically\namortize such hardware over three years but we adopt\na more conservative five-year depreciation schedule to\nreflect longer usage cycles common in academic envi-\nronments. This results in an hourly depreciation cost\nof roughly $0.23.\nThe estimated power draw of the server—including\nGPU, CPU, memory, storage, and cooling infrastruc-\nture—is approximately 400 watts [39]. At an average\nelectricity rate of $0.19 per kilowatt-hour [40] (US av-\nerage), this corresponds to $0.06 in energy costs per\nhour. To account for auxiliary operational expenses,\nwe add a 20% overhead margin to the base cost, con-\ntributing an additional $0.06 per hour.\nSumming these components, the total estimated\ncost of operating the server is $0.35 per hour. When\nexpressed on a per-second basis, this translates to\nan operational cost of approximately $0.000097, or\n0.01 cents per second.\nThis estimate serves as\na realistic baseline for evaluating the cost-efficiency\nof locally hosted LLM inference in academic and re-\nsearch settings.\nTable 3 presents the per-procedure and per-report\ncost of deploying the Claude-3.5-Haiku model in\na commercial environment via AWS Bedrock.\nUn-\nlike local deployments, commercial usage is priced\nbased on token consumption—typically charged per\ninput and output token. Thus, for the commercial\nmodel, costs were calculated based on the number of\ninput and generated tokens per procedure under each\nprompting strategy.\nCost Calculation for the Commercial Model.\nUnlike local deployments, commercial language mod-\nels such as Claude-3.5-Haiku are billed based on to-\nken usage, with separate rates for input and output\ntokens. According to the official AWS Bedrock pric-\ning documentation [41], the cost is $0.0008 per 1,000\ninput tokens and $0.004 per 1,000 output tokens.\nTherefore, for a given inference task—such as iden-\ntifying whether a procedure was performed—if the\ninput prompt contains 1,000 tokens and the model\ngenerates a 1,000-token response, the total cost for\nthat inference would be $0.0008+$0.004=$0.0048.\nComparative Cost of Local vs.\nCommer-\ncial Deployment. For the local model, see Table\n3, with a per-second operating cost of $0.000097 (de-\nrived above), the estimated cost per 9.7s procedure\nis $0.00094 using IP and $0.00131 using CoT. Ex-\ntrapolated to full reports containing an average of\n39 procedures, the per-report costs are $0.03670 (IP)\nand $0.05096 (CoT)—affordable in many academic\nand clinical research settings.\nOn the commercial side, Table 3 shows IP prompts\ncost $0.0008 per procedure and $0.0324 per report,\nwhile CoT prompts cost slightly more ($0.0011 per\nprocedure; $0.0433 per report), due to increased in-\nput token length. These values indicate that Claude’s\ncommercial deployment is competitive with local\ndeployment of Qwen, particularly when factoring\nin maintenance-free scalability, security compliance,\nand minimal hardware investment.\nComparison with Manual Logging Burden.\n8\n"}, {"page": 9, "text": "Radiology residents are responsible for documenting\nupwards of 1,600 reports during the time of residency,\nwith each report averaging 39 distinct procedural en-\ntries. Assuming just 2 seconds per manual entry, this\namounts to:\nTotal manual annotation time = 1,600 × 39 × 2 seconds\n= 124,800 seconds\n≈35 hours.\nThis represents almost one full-time workweek\nspent on clerical documentation per resident—time\nthat could be redirected toward patient care, educa-\ntional development, or research. Furthermore, man-\nual annotation is susceptible to human error, variabil-\nity in documentation diligence, and inconsistent un-\nderstanding of procedural terminology—all of which\ndegrade data quality in high-stakes applications like\ncredentialing and competency tracking.\n4\nDiscussion\n4.1\nLimitations & Future Work\nThis study has several limitations that open avenues\nfor future research.\nFirst, the analysis was performed on a relatively\nsmall dataset comprising 414 radiology reports. This\nlimited sample size, driven primarily by data avail-\nability and labeling time constraints, may affect the\ngeneralizability of the findings in broader clinical con-\ntexts. Future work should aim to validate these re-\nsults using a larger and more diverse dataset spanning\nmultiple institutions, imaging modalities, and patient\ndemographics.\nSecond, our evaluation focused on a single com-\nmercially available, most up-to-date model on the\nBedrock platform—Claude-3.5-Haiku (as of Febru-\nary 15, 2025). Although it demonstrated strong per-\nformance across prompting strategies, the commer-\ncial LLM landscape is evolving rapidly, with emerging\nmodels offering varying trade-offs in speed, cost, and\nreasoning capabilities. Future studies should conduct\ncomparative evaluations across a wider range of com-\nmercial LLMs from different HIPAA-compliant plat-\nforms to identify the most suitable models for specific\nclinical use cases and infrastructure constraints.\nThird, we limited our experimentation to two\nprompting strategies: IP and CoT. Although these\nare among the most commonly adopted prompting\nparadigms, recent advances have introduced a variety\nof alternatives—including few-shot prompting, self-\nconsistency prompting, and tool-augmented prompt-\ning; that may further enhance model performance,\ninterpretability, or robustness.\nIncorporating and\nbenchmarking these strategies could provide deeper\ninsights into optimizing LLM-driven clinical automa-\ntion.\nFourth, while this study focused on procedural ex-\ntraction from radiology reports, the broader clinical\ndocumentation landscape includes many other enti-\nties, such as diagnoses, findings, measurements, and\nrecommendations, that were not addressed here. Ex-\npanding the scope of LLM applications to include\nthese additional dimensions could contribute to more\ncomprehensive automation and structured documen-\ntation in healthcare workflows.\nFinally, the evaluation was limited to a single in-\nstitution with a specific reporting style and workflow.\nRadiology documentation conventions differ across\nhospitals, specialties, and even individual clinicians.\nAs such, the reported performance may not gener-\nalize to other settings. Multi-institutional validation\nacross varied EHR and PACS systems is essential be-\nfore clinical deployment.\nFuture research should therefore pursue multi-site\ncollaborations, larger annotated corpora, and ex-\npanded prompting paradigms. Equally important is\nassessing usability and trust among residents, faculty,\nand credentialing bodies, as automation bias or over-\nreliance on AI outputs could compromise oversight.\nIntegrating LLM-based tools in a way that supports,\nrather than replaces, human review will be critical.\nBy addressing these gaps, the field can move toward\nsafe, equitable, and scalable automation of clinical\ndocumentation in medical education.\n4.2\nConclusion\nThis study evaluated the use of large language models\nto automate procedural case log documentation in ra-\ndiology training. Both open-weight (Qwen-2.5:72B)\nand commercial (Claude-3.5-Haiku) models outper-\nformed a metadata-only benchmark, reliably identi-\nfying common procedures while struggling with cat-\negories marked by vague or overlapping language.\nOperational analyses showed that local and commer-\ncial deployments offer broadly comparable costs, with\ntrade-offs between speed, scalability, and data pri-\nvacy. These findings suggest that LLMs are a feasible\ncomplement to current documentation workflows, of-\nfering the potential to reduce clerical burden, though\nfurther validation across institutions, procedures, and\nprompting strategies is required to ensure safe inte-\ngration into training and clinical practice.\n9\n"}, {"page": 10, "text": "Code & Data Availability\nThe project codebase and its documentation are\navailable on a dedicated website, accessible here:\nhttps://nafiz43.github.io/PCL-Fetcher/.\nDue\nto confidentiality, the data has not been made avail-\nable.\nFunding\nNo funding was received for this work.\nReferences\n[1] Nygaard, Rachel M and Daly, Samuel R and Van\nCamp, Joan M. General surgery resident case\nlogs: do they accurately reflect resident experi-\nence?. Journal of surgical education. Elsevier.\n2015.\n[2] Cadish, Lauren A and Fung, Vicki and Lane, Fe-\nlicia L and Campbell, Eric G. Surgical case log-\nging habits and attitudes: a multispecialty survey\nof residents. Journal of surgical education. Else-\nvier. 2016.\n[3] Accreditation\nCouncil\nfor\nGraduate\nMed-\nical\nEducation.\nACGME\nCase\nLog\nSys-\ntem.\n2025.\nhttps://www.acgme.org/\nprogram-directors-and-coordinators/\ncase-log-system. Accessed: 2025-09-17.\n[4] Accreditation\nCouncil\nfor\nGraduate\nMedi-\ncal\nEducation.\nDiagnostic\nRadiology\nCase\nLog\nMinimums.\n2025.\nhttps://www.acgme.\norg/specialties/diagnostic-radiology/\nprogram-requirements-and-faqs-and-applications/.\nAccessed: 2025-09-17.\n[5] Accreditation\nCouncil\nfor\nGradu-\nate\nMedical\nEducation.\nInterventional\nRadiology–Integrated\nCase\nLog\nMini-\nmums.\n2025.\nhttps://www.acgme.org/\nspecialties/interventional-radiology/\nprogram-requirements-and-faqs-and-applications/.\nAccessed: 2025-09-17.\n[6] Vesselle, Hubert and Chiramal, Justy Antony\nand Hawes, Stephen E and Schulze, Eric and\nNguyen, Tham and Ndumia, Rose and Vinayak,\nSudhir. Development of an online authentic radi-\nology viewing and reporting platform to test the\nskills of radiology trainees in Low-and Middle-\nIncome Countries. BMC Medical Education.\nSpringer. 2024.\n[7] Cox, Christopher and others. Documentation\nWorkload and Its Impact on Resident Work-\nflow in Graduate Medical Education. Journal\nof Graduate Medical Education. 2018. doi:\n10.4300/JGME-D-17-00745.1.\n[8] He, Kai and Mao, Rui and Lin, Qika and Ruan,\nYucheng and Lan, Xiang and Feng, Mengling\nand Cambria, Erik. A survey of large language\nmodels for healthcare:\nfrom data, technology,\nand applications to accountability and ethics. In-\nformation Fusion. Elsevier. 2025.\n[9] Naveed, Humza and Khan, Asad Ullah and Qiu,\nShi and Saqib, Muhammad and Anwar, Saeed\nand Usman, Muhammad and Akhtar, Naveed\nand Barnes, Nick and Mian, Ajmal. A compre-\nhensive overview of large language models. arXiv\npreprint arXiv:2307.06435. 2023.\n[10] Wei,\nJason\nand\nTay,\nYi\nand\nBommasani,\nRishi and Raffel,\nColin and Zoph,\nBarret\nand Borgeaud, Sebastian and Yogatama, Dani\nand Bosma, Maarten and Zhou, Denny and\nMetzler, Donald and others. Emergent abili-\nties of large language models. arXiv preprint\narXiv:2206.07682. 2022.\n[11] Bizzo, Bernardo C and Almeida, Renata R and\nAlkasab, Tarik K. Artificial intelligence enabling\nradiology reporting. Radiologic Clinics. Elsevier.\n2021.\n[12] Hosny, Ahmed and Parmar, Chintan and Quack-\nenbush, John and Schwartz, Lawrence H and\nAerts, Hugo JWL. Artificial intelligence in radi-\nology. Nature Reviews Cancer. Nature Publish-\ning Group UK London. 2018.\n[13] Sacoransky, Ethan and Kwan, Benjamin YM\nand Soboleski, Donald. ChatGPT and assistive\nAI in structured radiology reporting: A system-\natic review. Current Problems in Diagnostic Ra-\ndiology. Elsevier. 2024.\n[14] Babar, Zaheer and van Laarhoven, Twan and\nZanzotto, Fabio Massimo and Marchiori, Elena.\nEvaluating diagnostic content of AI-generated\nradiology reports of chest X-rays. Artificial In-\ntelligence in Medicine. Elsevier. 2021.\n[15] Casey, Adrian and Banerjee, Ishita and Langer,\nSteve and Lu, Zhiyong. Natural language pro-\ncessing for clinical radiology reports: a system-\natic review. Journal of the American College of\nRadiology. 2021. doi: 10.1016/j.jacr.2020.11.014.\n10\n"}, {"page": 11, "text": "[16] Xavier, Jean and Franco, Alvaro and Costa, Fer-\nnando. Extracting structured information from\nradiology reports using natural language process-\ning:\na scoping review. Insights into Imaging.\n2022. doi: 10.1186/s13244-022-01162-9.\n[17] Pereira, Ricardo and others. Applications of nat-\nural language processing in radiology:\na nar-\nrative review. European Radiology. 2024. doi:\n10.1007/s00330-024-10874-7.\n[18] Kim, Jin and Patel, Sneha and Wang, Xin and\nothers. Automated CPT code prediction from\nclinical notes using deep learning. JMIR Medi-\ncal Informatics. 2022. doi: 10.2196/35678.\n[19] Nguyen, Thao and Chen, David and Lee, James.\nArtificial intelligence for coding in healthcare:\npromise and pitfalls. NEJM AI. 2024. doi:\n10.1056/AI0056.\n[20] Seymour, Tom and Frantsvog, Dean and Grae-\nber,\nTod.\nElectronic health records (EHR).\nAmerican Journal of Health Sciences. The Clute\nInstitute. 2012.\n[21] Rebelo, Luís and Fidalgo, Filipe and Oliveira,\nÂngela. Radiology Information System (RIS).\n2022 17th Iberian Conference on Information\nSystems and Technologies (CISTI). IEEE. 2022.\n[22] Choplin, Robert H and Boehme 2nd, JM and\nMaynard, C Douglas. Picture archiving and com-\nmunication systems: an overview.. Radiograph-\nics. 1992.\n[23] Wong, Alicia and Otles, Erkin and Donnelly,\nJanelle P. and others. External validation of\na widely implemented proprietary sepsis predic-\ntion model in hospitalized patients. JAMA In-\nternal Medicine. 2021. doi: 10.1001/jamaintern-\nmed.2021.2626.\n[24] Lyons, Patrick G. and others. Systematic bias\nand poor performance of a commercial sepsis\nprediction algorithm. Critical Care Medicine.\n2023. doi: 10.1097/CCM.0000000000005810.\n[25] Artstein,\nRon.\nInter-annotator\nagreement.\nHandbook of linguistic annotation. Springer.\n2017.\n[26] Kvålseth, Tarald O. Note on Cohen’s kappa. Psy-\nchological reports. SAGE Publications Sage CA:\nLos Angeles, CA. 1989.\n[27] Zhang, Shengyu and Dong, Linfeng and Li, Xi-\naoya and Zhang, Sen and Sun, Xiaofei and\nWang, Shuhe and Li, Jiwei and Hu, Runyi and\nZhang, Tianwei and Wu, Fei and others. Instruc-\ntion tuning for large language models: A survey.\narXiv preprint arXiv:2308.10792. 2023.\n[28] Wang, Kenneth C and Patel, Jigar B and Vyas,\nBimal and Toland, Michael and Collins, Beverly\nand Vreeman, Daniel J and Abhyankar, Swapna\nand Siegel, Eliot L and Rubin, Daniel L and Lan-\nglotz, Curtis P. Use of radiology procedure codes\nin health care: the need for standardization and\nstructure. Radiographics. Radiological Society of\nNorth America. 2017.\n[29] Zhang, Shengyu and Dong, Linfeng and Li, Xi-\naoya and Zhang, Sen and Sun, Xiaofei and\nWang, Shuhe and Li, Jiwei and Hu, Runyi and\nZhang, Tianwei and Wu, Fei and others. Instruc-\ntion tuning for large language models: A survey.\narXiv preprint arXiv:2308.10792. 2023.\n[30] Marvin, Ggaliwango and Hellen, Nakayiza and\nJjingo, Daudi and Nakatumba-Nabende, Joyce.\nPrompt engineering in large language models. In-\nternational conference on data intelligence and\ncognitive informatics. Springer. 2023.\n[31] Wei, Jason and Wang, Xuezhi and Schuurmans,\nDale and Bosma, Maarten and Xia, Fei and Chi,\nEd and Le, Quoc V and Zhou, Denny and others.\nChain-of-thought prompting elicits reasoning in\nlarge language models. Advances in neural infor-\nmation processing systems. 2022.\n[32] Yu, Zihan and He, Liang and Wu, Zhen and Dai,\nXinyu and Chen, Jiajun. Towards better chain-\nof-thought prompting strategies: A survey. arXiv\npreprint arXiv:2310.04959. 2023.\n[33] Marcondes, Francisco S and Gala, Adelino and\nMagalhães, Renata and Perez de Britto, Fer-\nnando and Durães, Dalila and Novais, Paulo.\nUsing Ollama. Natural Language Analytics with\nGenerative Large-Language Models: A Practical\nApproach with Ollama and Open-Source LLMs.\nSpringer. 2025.\n[34] Rahman, Tawsifur and Khandakar, Amith and\nKadir, Muhammad Abdul and Islam, Khan-\ndaker Rejaul and Islam,\nKhandakar F and\nMazhar, Rashid and Hamid, Tahir and Islam,\nMohammad Tariqul and Kashem, Saad and\nMahbub, Zaid Bin and others. Reliable tubercu-\nlosis detection using chest X-ray with deep learn-\ning, segmentation and visualization. Ieee Access.\nIEEE. 2020.\n11\n"}, {"page": 12, "text": "[35] Shenoy, Vishal and Malik, Sachin. CovXR: au-\ntomated detection of COVID-19 pneumonia in\nchest X-rays through machine learning. 2021\nIEEE Symposium Series on Computational In-\ntelligence (SSCI). IEEE. 2021.\n[36] European Society of Radiology. Structured re-\nporting in radiology: update from the European\nSociety of Radiology (ESR). Insights into Imag-\ning. 2023. doi: 10.1186/s13244-023-01457-5.\n[37] Danny\nCastonguay.\nCost\nof\nInference.\n2025.\nhttps://blog.dannycastonguay.com/\nCost-of-Inference/. Accessed: 2025-05-18.\n[38] Chuan\nLi.\nTesla\nA100\nServer\nTo-\ntal\nCost\nof\nOwnership\nAnalysis.\n2021.\nhttps://lambda.ai/blog/\ntesla-a100-server-total-cost-of-ownership.\n[39] David Mytton. How much energy do data cen-\nters use?. 2025. https://davidmytton.blog/\nhow-much-energy-do-data-centers-use/.\nAccessed: 2025-05-18.\n[40] EnergySage. How much does electricity cost in\n2025?.\n2025.\nhttps://www.energysage.com/\nlocal-data/electricity-cost/.\nAccessed:\n2025-05-18.\n[41] Amazon Web Services. Amazon Bedrock Pric-\ning. 2025. https://aws.amazon.com/bedrock/\npricing/. Accessed: 2025-05-18.\n[42] Mistral\nAI.\nMixtral-8x7B-v0.1.\n2023.\nhttps://huggingface.co/mistralai/\nMixtral-8x7B-v0.1.\n[43] Qwen Team. Qwen2.5:\nA Party of Founda-\ntion Models. 2024. https://qwenlm.github.\nio/blog/qwen2.5/.\n[44] Siraj Raval. MedLLaMA2 7B. Hugging Face.\n2023.\nhttps://huggingface.co/llSourcell/\nmedllama2_7b. Accessed: 2025-04-13.\n[45] Clément Christophe and Praveen K Kanithi\nand Tathagata Raha and Shadab Khan and\nMarco AF Pimentel. Med42-v2:\nA Suite of\nClinical LLMs. 2024. https://arxiv.org/abs/\n2408.06142.\n[46] M42\nHealth.\nLlama3-Med42-70B.\n2024.\nhttps://huggingface.co/m42-health/\nLlama3-Med42-70B.\n[47] Anthropic. Claude 3.5 Haiku. 2024. https://\nwww.anthropic.com/claude/haiku.\n12\n"}, {"page": 13, "text": "A\nPrompt Templates\nI will provide you with a radiology report, followed by a question about whether a specific\n,→radiology study or procedure was performed.\n<procedure\\_specific\\_question>\n### **Strict Output Format**\nYour response **must** be a **valid JSON object** with the following keys:\n‘‘‘json\n{\n\"reason_for_the_label\": \"A concise explanation justifying the classification.\",\n\"label\": 1 or 0\n}\nListing 1: Prompt Template for Chain-of-Thought prompting, in which the <procedure_specific_question>\nplaceholder is dynamically replaced with a specific question tailored to the target radiology procedure\nI will provide you with a radiology report, followed by several questions about it. Your task is to\n,→\ndetermine whether a specific radiology study or procedure was performed. Please follow these\n,→strict formatting guidelines for your response:\nOutput must be in valid JSON format with the following keys:\n{\n\"reason_for_the_label\": \"A string explaining the reasoning behind the classification.\",\n\"label\": 1 or 0\n}\nLabeling criteria:\nReturn 1 if the radiology study or procedure was explicitly mentioned as performed.\nReturn 0 if the study or procedure was not performed, not documented, or uncertain in the report.\nDo not include any additional text or explanations outside the JSON response.\nEnsure strict adherence to this format for every response\nListing 2: Prompt Template for Instruction Prompting\nB\nServer Configuration\nWe conducted all the experiments for our study on a dedicated local server with a well-defined configuration\nto ensure consistency and reliability in our results. The configuration of the server is presented in table 5.\nC\nPerformance & Cost of the Additional Local Models\nThe performance and cost metrics of the additional local models are presented in Table 2 and Table 3,\nrespectively.\nTable 2 highlights their effectiveness across different tasks and prompting strategies, while\nTable 3 provides a breakdown of the associated computational costs\nD\nModel Error Count\n13\n"}, {"page": 14, "text": "Table 5: Local server configuration\nComponent\nConfiguration\nPrimary Memory (RAM)\n64 GB\nSecondary Memory (Hard Disk)\n512 GB SSD\nProcessor\nName: Intel(R) Xeon(R) W-2135 CPU @ 3.70GHz\nArchitecture: x86_64\nCPU(s): 12\nThread(s) per core: 2\nCore(s) per socket: 6\nMax Clock Speed: 4500.00 MHz\nMin Clock Speed: 1200.00 MHz\nPCI Express Lanes: 48\nIntegrated Graphics: None\nTDP (Thermal Design Power): 140 W\nCache\nL1d cache: 192 KiB (6 instances)\nL1i cache: 192 KiB (6 instances)\nL2 cache: 6 MiB (6 instances)\nL3 cache: 8.3 MiB (1 instance)\nGPU\nName: A100 (PCIe)\nMemory: 24 GB HBM2\nMemory Interface Width: 3840 bits\nMemory Bandwidth: 1555 GB/s\nBase Clock Speed: 1095 MHz\nBoost Clock Speed: 1410 MHz\nMemory Clock Speed: 1215 MHz\nCUDA Cores: 6912\nTensor Cores: 432 (3rd Gen)\nThermal Design Power (TDP): 250 W\nE\nDescription of the selected Models\nMixtral-8x7B. Mixtral-8x7B 4 is a mixture-of-experts model released by Mistral AI. The 8x7B version\nactivates 2 out of 8 expert pathways per token, which offers a balance between model expressiveness and\ncomputational efficiency. It has shown competitive performance across a range of multilingual and general-\npurpose NLP tasks.\nLLaMA 3.3-70B. LLaMA 3 is the latest generation of Meta’s foundational language models. The 70B\nversion demonstrates significant gains in general understanding, reasoning, and instruction-following 5. It is\nparticularly effective for downstream fine-tuning and multi-turn prompt applications.\nQwen 2.5-72B. Qwen 2.5 6 is a high-performance transformer model developed by Alibaba. The 72B\nversion is instruction-tuned and optimized for accuracy in information extraction tasks. It supports a wide\nmultilingual range and is designed for competitive performance in both zero- and few-shot settings.\nMedLLaMA-2-7B. MedLLaMA-2-7B is a biomedical adaptation of Meta’s LLaMA architecture, fine-tuned\non large-scale medical corpora. The 7B parameter variant focuses on healthcare and clinical domains, making\nit suitable for domain-specific tasks such as radiology procedural report interpretation.\nLLaMA-3-Med42-70B. LLaMA-3-Med42-70B 7 is a domain-specialized version of LLaMA 3.3-70B, fine-\ntuned on a curated medical dataset named Med42 [45]. It is intended for complex clinical reasoning, proce-\ndural understanding, and structured medical data generation.\nClaude-3.5-Haiku. Claude 3.5 Haiku 8 is a lightweight commercial LLM developed by Anthropic. Despite\n4https://huggingface.co/mistralai/Mixtral-8x7B-v0.1\n5https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct\n6https://qwenlm.github.io/blog/qwen2.5/\n7https://huggingface.co/m42-health/Llama3-Med42-70B\n8https://www.anthropic.com/claude/haiku\n14\n"}, {"page": 15, "text": "Table 6: Performance of the Crosswalk Benchmark Compared to the Top-Performing Local and Commercial\nLanguage Model\nModel-Name\nPrompting\nMethod\nModality\nTP\nTN\nFP\nFN\nSensitivity (%)\nSpecificity (%)\nF1-Score (%)\nLlama3-Med42:70B\nIP\nAll\n662\n14714\n743\n27\n96.08\n95.19\n63.23\nIP\nVascularDiagnosis\n215\n3039\n49\n9\n95.98\n98.41\n88.11\nIP\nVascularIntervention\n257\n5559\n385\n9\n96.62\n93.52\n56.61\nIP\nNonVascularIntervention\n190\n6116\n309\n9\n95.48\n95.19\n54.45\nCoT\nAll\n645\n15037\n420\n44\n93.61\n97.28\n73.54\nCoT\nVascularDiagnosis\n211\n3042\n46\n13\n94.20\n98.51\n87.73\nCoT\nVascularIntervention\n250\n5816\n128\n16\n93.98\n97.85\n77.64\nCoT\nNonVascularIntervention\n184\n6179\n246\n15\n92.46\n96.17\n58.50\nLlama3.3:70B\nIP\nAll\n662\n14826\n631\n27\n96.08\n95.92\n66.80\nIP\nVascularDiagnosis\n215\n3048\n40\n9\n95.98\n98.70\n89.77\nIP\nVascularIntervention\n256\n5647\n297\n10\n96.24\n95.00\n62.51\nIP\nNonVascularIntervention\n191\n6131\n294\n8\n95.98\n95.42\n55.85\nCoT\nAll\n628\n15191\n266\n61\n91.15\n98.28\n79.35\nCoT\nVascularDiagnosis\n200\n3052\n36\n24\n89.29\n98.83\n86.96\nCoT\nVascularIntervention\n249\n5834\n110\n17\n93.61\n98.15\n79.68\nCoT\nNonVascularIntervention\n179\n6305\n120\n20\n89.95\n98.13\n71.89\nMedllama2:7B\nIP\nAll\n321\n8909\n6548\n368\n46.59\n57.64\n8.49\nIP\nVascularDiagnosis\n126\n1959\n1129\n98\n56.25\n63.44\n17.04\nIP\nVascularIntervention\n107\n3372\n2572\n159\n40.23\n56.73\n7.26\nIP\nNonVascularIntervention\n88\n3578\n2847\n111\n44.22\n55.69\n5.62\nCoT\nAll\n605\n3771\n11686\n84\n87.81\n24.40\n9.32\nCoT\nVascularDiagnosis\n206\n885\n2203\n18\n91.96\n28.66\n15.65\nCoT\nVascularIntervention\n245\n412\n5532\n21\n92.11\n6.93\n8.11\nCoT\nNonVascularIntervention\n154\n2474\n3951\n45\n77.39\n38.51\n7.15\nMixtral:8x7B\nIP\nAll\n623\n14728\n729\n66\n90.42\n95.28\n61.05\nIP\nVascularDiagnosis\n194\n3050\n38\n30\n86.61\n98.77\n85.09\nIP\nVascularIntervention\n243\n5608\n336\n23\n91.35\n94.35\n57.52\nIP\nNonVascularIntervention\n186\n6070\n355\n13\n93.47\n94.47\n50.27\nCoT\nAll\n601\n14444\n1013\n88\n87.23\n93.45\n52.20\nCoT\nVascularDiagnosis\n199\n2940\n148\n25\n88.84\n95.21\n69.70\nCoT\nVascularIntervention\n234\n5500\n444\n32\n87.97\n92.53\n49.57\nCoT\nNonVascularIntervention\n168\n6004\n421\n31\n84.42\n93.45\n42.64\nTable 7: Cost of Running the Language Model in Relation to Inference Time and Generated Tokens for the\nRest of the Local Models\nModel Name\nPrompting\nMethod\nInference Time (Second)\nGenerated Tokens (Count)\nMax\nMin\nMean\nStd Dev\nMax\nMin\nMean\nStd Dev\nLlama3-Med42:70B\nIP\n13.00\n3.00\n6.53\n1.65\n147\n14\n53.81\n17.92\nCoT\n18.00\n7.00\n10.44\n1.80\n152\n34\n70.65\n16.61\nLlama3:70B\nIP\n330.00\n2.00\n57.32\n21.66\n433\n1\n71.03\n29.69\nCoT\n59.00\n11.00\n28.52\n4.67\n84\n12\n29.10\n10.28\nMedllama2:7B\nIP\n1497.00\n0.00\n2.97\n47.93\n66420\n13\n135.31\n2125.40\nCoT\n1027.00\n0.00\n3.83\n56.79\n74564\n5\n244.15\n4004.62\nMixtral:8x7B\nIP\n32.00\n0.00\n0.98\n1.17\n116\n1\n30.20\n17.07\nCoT\n9.00\n1.00\n2.21\n0.77\n124\n14\n41.83\n16.65\n15\n"}, {"page": 16, "text": "Table 8: Classification error count (False Postive and False Negative) of the models on each of the procedures\nProcedure\nNumber\nCrosswalk\nClaude-3.5-Haiku\nQwen-2.5:72B\nFP Count\nFN Count\nFP Count\nFN Count\nFP Count\nFN Count\n1\n1\n21\n8\n0\n10\n0\n2\n0\n0\n1\n0\n0\n0\n3\n0\n9\n5\n0\n3\n0\n4\n10\n1\n0\n0\n0\n0\n5\n29\n77\n1\n2\n1\n3\n6\n22\n57\n2\n10\n1\n6\n7\n0\n20\n1\n2\n1\n0\n8\n0\n39\n1\n0\n1\n1\n9\n0\n13\n2\n4\n2\n6\n10\n1\n8\n1\n0\n0\n0\n11\n0\n0\n3\n0\n2\n0\n12\n0\n8\n1\n1\n0\n1\n13\n6\n3\n0\n1\n0\n1\n14\n0\n12\n4\n0\n3\n0\n15\n0\n74\n3\n2\n5\n1\n16\n0\n3\n1\n0\n1\n0\n17\n15\n36\n2\n0\n2\n0\n18\n0\n0\n0\n0\n0\n0\n19\n30\n62\n3\n14\n1\n9\n20\n39\n56\n7\n4\n15\n2\n21\n0\n3\n1\n1\n0\n1\n22\n3\n0\n0\n2\n0\n2\n23\n6\n24\n11\n9\n45\n1\n24\n29\n2\n3\n1\n1\n1\n25\n14\n14\n5\n1\n1\n3\n26\n3\n13\n4\n0\n6\n0\n27\n0\n4\n0\n0\n0\n0\n28\n0\n0\n1\n0\n0\n0\n29\n7\n8\n1\n1\n0\n1\n30\n0\n5\n1\n1\n0\n1\n31\n0\n3\n5\n0\n3\n0\n32\n5\n14\n1\n0\n0\n0\n33\n4\n4\n2\n1\n1\n1\n34\n0\n3\n7\n1\n14\n1\n35\n0\n9\n6\n0\n5\n0\n36\n0\n0\n0\n0\n0\n0\n37\n0\n6\n0\n5\n0\n6\n38\n0\n0\n0\n0\n0\n0\n39\n20\n41\n15\n13\n7\n14\nTotal\n244\n652\n109\n76\n131\n62\n16\n"}, {"page": 17, "text": "its smaller size, it exhibits strong instruction-following and chain-of-thought reasoning capabilities. It is\noptimized for fast response times while maintaining high accuracy in structured generation tasks.\nF\nLLM Prompts\nThis section outlines the various prompting techniques employed in the study.\nF.1\nInstruction Prompting\nPrompt for Question 1:\nPlease answer 1 if the report explicitly states that a CTA (CT Angiography) or an intra-operative\n,→cone-beam CT with contrast was performed. If a CTA or intra-operative cone-beam CT with contrast\n,→\nwas not performed or not mentioned, please answer 0.\nPrompt for Question 2:\nPlease answer 1 if the report specifies an MRA or MR Angiography was performed. Otherwise, please\n,→answer 0\nPrompt for Question 3:\nPlease answer 1 if the report specifies a noninvasive vascular lab study was performed. Examples\n,→include a duplex, color flow, or Pulse Volume Recording (PVR). Otherwise, please answer 0\nPrompt for Question 4:\nPlease answer 1 if the report specifies a cardiac imaging study was performed. Examples include a\n,→CT coronary angiogram or nuclear medicine cardiac stress test. Otherwise, please answer 0\nPrompt for Question 5:\nPlease answer 1 if a dedicated arteriography was performed. Arteriography is defined as imaging of\n,→arteries using fluoroscopy and contrast specifically to evaluate arterial anatomy or pathology.\n,→The contrast must be specifically administered into an artery. Arteriography does not include\n,→venography. Answr 0 if arteriography was not performed or not documented\nPrompt for Question 6:\nPlease answer 1 if a dedicated venography was performed . Venorgaphy is defined as imaging of veins\n,→\nusing fluoroscopy and contrast specifically to evaluate venous anatomy or pathology. The\n,→contrast must be specifically administered into a vein. Venography does not include\n,→arteriography. Answer 0 if no dedicated venography was performed\nPrompt for Question 7:\nPlease answer 1 if a dialysis access evaluation was performed. These evaluations include ultrasound\n,→\nstudies, fistulagrams, and graft evaluations. Answer 0 if a dialysis access evaluation was not\n,→performed or not documented\nPrompt for Question 8:\nPlease answer 1 if carotid artery imaging was performed. Answer 0 if carotid artery imaging was not\n,→\nperformed or not documented\nPrompt for Question 9:\nPlease answer 1 if a central venous catheter procedure was performed. This includes placement,\n,→removal, and revision of central venous catheters, ports, and PICCs. Answer 0 if a central\n,→venous catheter procedure was not performed or not documented\nPrompt for Question 10:\n17\n"}, {"page": 18, "text": "Please answer 1 if an IVC filter placement or removal procedure was performed. Answer 0 if an IVC\n,→filter procedure was not performed or not documented\nPrompt for Question 11:\nPlease answer 1 if a venous ablation procedure was performed. Venous ablations are performed for\n,→varicose veins,. Answer 0 if venous ablation was not performed or not documented\nPrompt for Question 12:\nPlease answer 1 if a dialysis access intervention was performed. These interventions inlcude\n,→fistulagrams, graft evaluations, and declot procedures specifically and only on arteriovenous\n,→access. Answer 0 if a dialysis access intervention was not performed or not documented\nPrompt for Question 13:\nPlease answer 1 if any intervention involving a portosystemic shunt was performed. Typical shunts\n,→include Transjugular Intrahepatic Portosystemic Shunt (TIPS), Direct intrahepatic portocaval\n,→shunt (DIPS) and transjugular transcaval intrahepatic portosystemic shunt (TTIPS). Interventions\n,→\ninlcude shunt placement, evaluation, or revision. Answer 0 if a portosystemic shunt\n,→intervention was not performed or not documented\nPrompt for Question 14:\nPlease answer 1 if angioplasty or stent placement in the arterial system was performed. The\n,→arterial system is defined as any artery in the body. Answer 0 if angioplasty or stent placement\n,→\nin the arterial system was not performed or not documented\nPrompt for Question 15:\nPlease answer 1 if angioplasty or stent placement in the venous system was performed. The venous\n,→system is defined as any vein in the body. Angioplasty means any inflation of a balloon in the\n,→venous system for opening a lumen or for mechanical disruption. Answer 0 if angioplasty or stent\n,→\nplacement in the venous system was not performed or not documented\nPrompt for Question 16:\nPlease answer 1 if stent placement in the carotid artery was performed and 0 if it was not\n,→performed or not documented\nPrompt for Question 17:\nPlease answer 1 if thrombolytic therapy or thrombectomy was performed. Thrombolytic therapy may be\n,→administration of any tissue plasminogen activator (tPA) usch as tenecteplase or alteplase.\n,→Thrombectomy may include mechanical suction thrombectomy, balloon thrombectomy, or\n,→pharmacomechanical thrombectomy. Answer 0 if thrombolytic therapy or thrombectomy was not\n,→performed or not documented\nPrompt for Question 18:\nPlease answer 1 if aortic endograft placement or revision was performed and 0 if it was not\n,→performed or not documented\nPrompt for Question 19:\nPlease answer 1 if an emergency embolization was performed. Emergency embolization is defined as\n,→the intravascular administration of an occlusive material to stop or control bleeding and\n,→hemrrohage. Possible indications include trauma, gastrointestinal (GI) bleeding, hemoptysis,\n,→iatrogenic, and tumoral. Embolization materials may include Gelfoam, Onyx, beads, coils, and\n,→plugs. Answer 0 if an emergency embolization was not performed or not documented\nPrompt for Question 20:\n18\n"}, {"page": 19, "text": "Please answer 1 if an elective embolization was performed. Elective embolization is defined as the\n,→intravascular administration of an occlusive material to stop or reduce flow of blood or for\n,→administration of a medication. Elective embolization procedures include uterine artery\n,→emboliztion (UAE), uterine fibroid embolization (UFE), arteriovenous malformation (AVM)\n,→embolization, varicocele embolization, and gondal vein embolization. Transarterial\n,→chemoembolization (TACE) and transarterial radioemboliztion (TARE) should not be included in\n,→this group unless protective embolization was performed. Answer 0 if an elective embolization\n,→was not performed or not documented\nPrompt for Question 21:\nPlease answer 1 if a transarterial chemoembolization (TACE) was performed. TACE is defined as the\n,→intravascular administration of a chemotherapy gent to treat a tumor. Answer 0 if a TACE\n,→procedure was not performed or not documented\nPrompt for Question 22:\nPlease answer 1 if a transarterial radioembolization (TARE) procedure was performed. TARE\n,→procedures include angiographic mapping with or without MAA administration and yttrium-90 (Y90)\n,→administration. Answer 0 if a TARE procedure was not performed or not documented\nPrompt for Question 23:\nPlease answer 1 if an intravascular procedure was performed that doesn’t fit into one of the\n,→following categories: Venous access (such as port placement, exchange, or removal, or central\n,→venous catheter placement, exchange, or removal, or dialysis catheter placement, exchange, or\n,→removal), dialysis access intervention, IVC filter placement or removal, ablation, stent or\n,→stent-graft placement, TIPS, DIPS, embolization, TACE, or TARE. Examples might include a\n,→transjugular liver or renal biopsy, other intravscalar biopsy or fiducial placement. Otherwise,\n,→please answer 0\nPrompt for Question 24:\nPlease answer 1 if a percutaneous biopsy was performed and 0 if it was not performed or not\n,→documented. Percutaneous biopsy does not include intravascular biopsy procedures such as\n,→transjugular liver biopsy and transsjugular renal biopsy\nPrompt for Question 25:\nPlease answer 1 if an abscess drainage procedure was performed. These procedures include an abscess\n,→\nor fluid collection drain placement, revision, repositioning, upsize, or removal. This excludes\n,→\nbiliary drains and tubes, cholecystostomy drains and tubes, nephrostomy drains and tubes,\n,→nephroureterostomy drains and tubes, and chest drains and tubes. Answer 0 if an abscess drainage\n,→\nprocedure was not performed or not documented\nPrompt for Question 26:\nPlease answer 1 if\nparacentesis or thoracentesis was performed and 0 if it was not performed or\n,→not documented\nPrompt for Question 27:\nPlease answer 1 if a chest tube placement was performed and 0 if it was not performed or not\n,→documented\nPrompt for Question 28:\nPlease answer 1 if pleurodesis was performed and 0 if it was not performed or not documented\nPrompt for Question 29:\n19\n"}, {"page": 20, "text": "Please answer 1 if any procedure involving a biliary drain or stent was performed. These procedures\n,→\ninclude percutaneous transhepatic cholangiography (PTC), biliary drain placement, evaluation,\n,→or revision, and biliary stent placement or revision. Cholecystostomy placement/exchange/removal\n,→\nprocedures are not considered a biliary drain or stent procedure. Answer 0 if no biliary drain\n,→or biliary stent procedure was performed or documented\nPrompt for Question 30:\nPlease answer 1 if any procedure involving a geniturinary drain procedure was performed. These\n,→procedures include nephrostomy tube and nephrourteral stent placement, exchange, revision, or\n,→removal. Answer 0 if any procedure involving a geniturinary drain procedure was not performed or\n,→\nnot documented\nPrompt for Question 31:\nPlease answer 1 if any enterostomy procedure was performed. These procedures include gastrostomy,\n,→gastrojejunostomy, jejunostromy, iliostomy, and cecostomy placement, exchange, revision, or\n,→removal. Answer 0 if an enterostomy procedure was not performed or not documented\nPrompt for Question 32:\nPlease answer 1 if any cholecystostomy procedure was performed. These procedures include\n,→cholecystostomy drain or tube placement, exchange, revision, or removal and cholecystography.\n,→Answer 0 if a cholecystostomy procedure was not performed or not documented\nPrompt for Question 33:\nPlease answer 1 if a cyst or lymphocele procedure was performed. These procedures include\n,→aspiration, drain placement, exchange, revision, or removal and sclerosis of a cyst or\n,→lymphocele. This does not include interventions on abscesses or other fluid collections. Answer\n,→0 if a cyst or lymphocele procedure was not performed or not documented\nPrompt for Question 34:\nPlease answer 1 if a nonvascular stent placement was performed. Nonvascular stents include\n,→esophageal, tracheobronchial, duodenal, and colonic stents. Answer 0 if a nonvascular stent\n,→placement was not performed or not documented\nPrompt for Question 35:\nPlease answer 1 if a miscellaneous nonvascular transplant intervention was performed. Miscellaneous\n,→\nnonvascular transplant interventions are interventions performed exclusively on a transplant\n,→organ outside of the arteries and veins. The text must explicitly report that the organ is a\n,→transplant organ. A transplant organ is not a native organ. Intravascular procedures involving a\n,→\ntransplant organ, such as transplant renal artery stenosis (TRAS) or transjular biopsy, should\n,→not considered as examples because they are vascular. Examples of nonvascular transplant\n,→interventions include stent placements involving a transplant organ or balloon plasty procedures\n,→\nsuch as ureteroplasty. Procedures such as nephrostomy and nephroureterostomy placement,\n,→exchange, or removal and biliary tube placement, exchange, and removal should NOT be considered\n,→in this miscellaneous category. Answer 0 if a miscellaneous nonvascular transplant intervention\n,→was not performed or not documented\nPrompt for Question 36:\nPlease answer 1 if a tumor ablation was performed. Tumor ablations may include radiofrequency (RFA)\n,→, laser, microwave, cryoablation, and ethanol administration. Answer 0 if a tumor ablation was\n,→not performed or not documented\nPrompt for Question 37:\nPlease answer 1 if a pain managment procedure was performed. Pain managment procedures may include\n,→steroid injection, celiac plexus neurolysis, or nerve and periosteal cryoablation. Answer 0 if a\n,→\npain managment procedure was not performed or not documented\n20\n"}, {"page": 21, "text": "Prompt for Question 38:\nPlease answer 1 if a Fallopian tube recanalization was performed and 0 if it was not performed or\n,→not documented\nPrompt for Question 39:\nAn invasive procedure involves inserting instruments or devices into the body, typically through\n,→the skin or a natural body orifice. Please answer 1 if the report specifies that a nonvascular,\n,→invasive procedure was performed and it does not fall into any of the following categories:\n,→Biopsy, Abscess drainage & tube checks, Paracentesis, Thoracentesis, Chest tube placement,\n,→Pleurodesis, PTC, Biliary drainage catheter placement/exchange/removal, Biliary stent placement/\n,→exchange/removal, Tube checks, Genitourinary catheter placement/exchange/removal, Nephrostomy\n,→placement/exchange/removal, Nephroureteral tube placement/exchange/removal, Gastrostomy\n,→placement/exchange/removal, Gastrojejunostomy placement/exchange/removal, Cholecystostomy\n,→placement/exchange/removal, Cyst or lymphocele intervention, Nonvascular stents (esophageal,\n,→tracheobronchial, duodenal, colonic), Miscellaneous transplant interventions, Tumor ablation,\n,→Pain management interventions, Fallopian tube recanalization, or any intravascular procedure (\n,→including venous access procedures such as port placement, exchange, or removal; central venous\n,→catheter placement, exchange, or removal; dialysis catheter placement, exchange, or removal;\n,→dialysis access intervention; IVC filter placement or removal; Ablation; Stent or stent-graft\n,→placement; TIPS; DIPS; Embolization; Transarterial chemoembolization (TACE); or Transarterial\n,→radioembolization (TARE)). If a non-vascuar invasive procedure was not performed, please answer\n,→0.\nF.2\nChain-of-Thought\nPrompt for Question 1:\nYour task is to determine whether a **CTA (CT Angiography)** or **intra-operative cone-beam CT with\n,→\ncontrast** was explicitly performed.\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions**: Extract all references to CTA or intra-operative cone-beam CT with\n,→contrast in the report.\n2. **Assess Explicitness**: Determine if the report explicitly states that the procedure **was\n,→performed** (e.g., ‘CTA was conducted,’ ’A cone-beam CT with contrast was completed’).\n3. **Resolve Ambiguities**: If the procedure is only **suggested, planned, considered, or\n,→recommended**, but there is no explicit confirmation that it was performed, classify it as **not\n,→\nperformed**.\n4. **Handle Uncertainty**: If the report lacks a direct mention of the procedure, assume it was **\n,→not performed**.\n5. **Generate JSON Output**: Construct a response in strict JSON format, adhering to the following\n,→structure:\nPrompt for Question 2:\nYour task is to determine whether an **MRA (MR Angiography)** was explicitly performed.\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n21\n"}, {"page": 22, "text": "### **Reasoning Steps**\n1. **Identify Mentions**: Extract all references to MRA (MR Angiography) in the report.\n2. **Assess Explicitness**: Determine if the report explicitly states that the procedure **was\n,→performed** (e.g., ’MRA was conducted,’ ’MR Angiography was completed’).\n3. **Resolve Ambiguities**: If the procedure is only **suggested, planned, considered, or\n,→recommended**, but there is no explicit confirmation that it was performed, classify it as **not\n,→\nperformed**.\n4. **Handle Uncertainty**: If the report lacks a direct mention of MRA, assume it was **not\n,→performed**.\n5. **Generate JSON Output**: Construct a response in strict JSON format, adhering to the following\n,→structure:\nPrompt for Question 3:\nYour task is to determine whether a **noninvasive vascular lab study** was explicitly performed.\n,→Examples include **duplex ultrasound, color flow study, or Pulse Volume Recording (PVR)**.\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions**: Extract all references to **duplex ultrasound, color flow study, Pulse\n,→Volume Recording (PVR), or any other noninvasive vascular lab study** in the report.\n2. **Assess Explicitness**: Determine if the report clearly states that the procedure **was\n,→performed** (e.g., ’A duplex ultrasound was conducted,’ ’PVR testing was completed’).\n3. **Resolve Ambiguities**: If the procedure is only **suggested, planned, considered, or\n,→recommended** but not explicitly confirmed as performed, classify it as **not performed**.\n4. **Handle Uncertainty**: If the report lacks a direct mention of a noninvasive vascular lab study\n,→, assume it **was not performed**.\n5. **Generate JSON Output**: Construct a response in strict JSON format, adhering to the following\n,→structure:\nPrompt for Question 4:\nYour task is to determine whether a **cardiac imaging study** was explicitly performed. Examples\n,→include a **CT coronary angiogram** or **nuclear medicine cardiac stress test**.\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions**: Extract all references to **CT coronary angiogram, nuclear medicine\n,→cardiac stress test, or any other cardiac imaging study** in the report.\n2. **Assess Explicitness**: Determine if the report clearly states that the procedure **was\n,→performed** (e.g., ’A CT coronary angiogram was conducted,’ ’A nuclear medicine cardiac stress\n,→test was completed’).\n3. **Resolve Ambiguities**: If the procedure is only **suggested, planned, considered, or\n,→recommended** but not explicitly confirmed as performed, classify it as **not performed**.\n4. **Handle Uncertainty**: If the report lacks a direct mention of a cardiac imaging study, assume\n,→it **was not performed**.\n5. **Generate JSON Output**: Construct a response in strict JSON format, adhering to the following\n,→structure:\nPrompt for Question 5:\n22\n"}, {"page": 23, "text": "Your task is to determine whether a **dedicated arteriography** was explicitly performed. **\n,→Arteriography** is defined as imaging of arteries using **fluoroscopy and contrast**\n,→specifically to evaluate arterial anatomy or pathology. The contrast **must be administered\n,→directly into an artery**. **Venography does not count as arteriography.**\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions**: Extract all references to **arteriography** in the report. Look for terms\n,→\nlike **arteriogram, fluoroscopic arterial imaging, or direct intra-arterial contrast\n,→administration**.\n2. **Confirm Modality & Contrast Administration**: Ensure the report specifies that the imaging was\n,→\nperformed **using fluoroscopy and contrast**. The contrast **must** be administered **into an\n,→artery** to qualify as arteriography.\n3. **Differentiate from Venography**: If the procedure involves **venous imaging** (e.g.,\n,→venography or venogram), **do not classify it as arteriography**.\n4. **Resolve Ambiguities**: If the procedure is only **suggested, planned, considered, or\n,→recommended** but not explicitly confirmed as performed, classify it as **not performed**.\n5. **Handle Uncertainty**: If the report lacks a direct mention of **arteriography with intra-\n,→arterial contrast administration**, assume it **was not performed**.\n6. **Generate JSON Output**: Construct a response in strict JSON format, adhering to the following\n,→structure:\nPrompt for Question 6:\nYour task is to determine whether a **dedicated venography** was explicitly performed. **Venography\n,→** is defined as imaging of veins using **fluoroscopy and contrast** specifically to evaluate **\n,→venous anatomy or pathology**. The contrast **must be administered directly into a vein**. **\n,→Arteriography does not count as venography.**\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions**: Extract all references to **venography** in the report. Look for terms\n,→like **venogram, fluoroscopic venous imaging, or direct intra-venous contrast administration**.\n2. **Confirm Modality & Contrast Administration**: Ensure the report specifies that the imaging was\n,→\nperformed **using fluoroscopy and contrast**. The contrast **must** be administered **into a\n,→vein** to qualify as venography.\n3. **Differentiate from Arteriography**: If the procedure involves **arterial imaging** (e.g.,\n,→arteriography or arteriogram), **do not classify it as venography**.\n4. **Resolve Ambiguities**: If the procedure is only **suggested, planned, considered, or\n,→recommended** but not explicitly confirmed as performed, classify it as **not performed**.\n5. **Handle Uncertainty**: If the report lacks a direct mention of a **venography with intra-venous\n,→\ncontrast administration**, assume it **was not performed**.\n6. **Generate JSON Output**: Construct a response in strict JSON format, adhering to the following\n,→structure:\nPrompt for Question 7:\nYour task is to determine whether a **dialysis access evaluation** was explicitly performed. These\n,→evaluations include:\n23\n"}, {"page": 24, "text": "- **Ultrasound studies** (e.g., Doppler ultrasound of dialysis access).\n- **Fistulagrams** (fluoroscopic imaging of a dialysis fistula using contrast).\n- **Graft evaluations** (imaging studies assessing the function and patency of dialysis grafts).\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions**: Extract all references to **dialysis access evaluation** in the report.\n,→Look for terms such as **dialysis access ultrasound, fistulagram, or graft evaluation**.\n2. **Confirm the Type of Study**: Ensure that the report explicitly states that one of the\n,→following procedures was performed:\n- **Ultrasound study** for dialysis access.\n- **Fistulagram** (contrast-based evaluation of a fistula).\n- **Graft evaluation** (assessment of a dialysis graft using imaging).\n3. **Resolve Ambiguities**: If the procedure is only **suggested, planned, considered, or\n,→recommended** but not explicitly confirmed as performed, classify it as **not performed**.\n4. **Handle Uncertainty**: If the report lacks a direct mention of any of the qualifying dialysis\n,→access studies, assume it **was not performed**.\n5. **Generate JSON Output**: Construct a response in strict JSON format, adhering to the following\n,→structure:\nPrompt for Question 8:\nYour task is to determine whether **carotid artery imaging** was explicitly performed. This\n,→includes imaging studies specifically evaluating the carotid arteries, such as:\n- **Carotid ultrasound (Doppler or duplex ultrasound of the carotid arteries)**\n- **Carotid CT angiography (CTA)**\n- **Carotid MR angiography (MRA)**\n- **Carotid angiography (fluoroscopy with contrast administered into the carotid arteries)**\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions**: Extract all references to **carotid artery imaging** in the report. Look\n,→for terms such as **carotid ultrasound, carotid Doppler, carotid CTA, carotid MRA, or carotid\n,→angiogram**.\n2. **Confirm the Imaging Modality**: Ensure that the report explicitly states that one of the\n,→following procedures was performed:\n- **Ultrasound study** (e.g., Doppler or duplex of the carotid arteries).\n- **CT angiography (CTA)** of the carotid arteries.\n- **MR angiography (MRA)** of the carotid arteries.\n- **Catheter-based carotid angiography** (contrast-enhanced fluoroscopic evaluation).\n3. **Resolve Ambiguities**: If the procedure is only **suggested, planned, considered, or\n,→recommended** but not explicitly confirmed as performed, classify it as **not performed**.\n4. **Handle Uncertainty**: If the report lacks a direct mention of any carotid artery imaging study\n,→, assume it **was not performed**.\n5. **Generate JSON Output**: Construct a response in strict JSON format, adhering to the following\n,→structure:\nPrompt for Question 9:\n24\n"}, {"page": 25, "text": "Your task is to determine whether a **central venous catheter (CVC) procedure** was explicitly\n,→performed. This includes:\n- **Placement** of a central venous catheter, port, or peripherally inserted central catheter (PICC\n,→).\n- **Removal** of a central venous catheter, port, or PICC.\n- **Revision** or adjustment of an existing central venous catheter, port, or PICC.\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions**: Extract all references to **central venous catheter procedures** in the\n,→report. Look for terms such as **CVC placement, central line insertion, port-a-cath placement,\n,→PICC line insertion, catheter revision, or catheter removal**.\n2. **Confirm Procedure Type**: Ensure that the report explicitly states that one of the following\n,→procedures was performed:\n- **Placement of a CVC, port, or PICC** (e.g., via ultrasound or fluoroscopic guidance).\n- **Removal of a CVC, port, or PICC** (e.g., catheter extraction or explantation).\n- **Revision or adjustment** of an existing CVC, port, or PICC.\n3. **Resolve Ambiguities**: If the procedure is only **suggested, planned, considered, or\n,→recommended** but not explicitly confirmed as performed, classify it as **not performed**.\n4. **Handle Uncertainty**: If the report lacks a direct mention of any **CVC-related procedure**,\n,→assume it **was not performed**.\n5. **Generate JSON Output**: Construct a response in strict JSON format, adhering to the following\n,→structure:\nPrompt for Question 10:\nYour task is to determine whether an **Inferior Vena Cava (IVC) filter placement or removal\n,→procedure** was explicitly performed. This includes:\n- **Placement** of an IVC filter (implantation of a filter within the inferior vena cava to prevent\n,→\nembolism).\n- **Removal** or **retrieval** of an IVC filter (extraction of a previously placed filter).\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions**: Extract all references to **IVC filter procedures** in the report. Look\n,→for terms such as **IVC filter placement, IVC filter removal, IVC filter retrieval, or caval\n,→filter implantation**.\n2. **Confirm Procedure Type**: Ensure that the report explicitly states that one of the following\n,→procedures was performed:\n- **Placement of an IVC filter** (e.g., via catheter-based insertion in the inferior vena cava).\n- **Removal or retrieval of an existing IVC filter** (e.g., endovascular retrieval of the device\n,→).\n3. **Resolve Ambiguities**: If the procedure is only **suggested, planned, considered, or\n,→recommended** but not explicitly confirmed as performed, classify it as **not performed**.\n4. **Handle Uncertainty**: If the report lacks a direct mention of any **IVC filter placement or\n,→removal**, assume it **was not performed**.\n5. **Generate JSON Output**: Construct a response in strict JSON format, adhering to the following\n,→structure:\nPrompt for Question 11:\n25\n"}, {"page": 26, "text": "Your task is to determine whether a **venous ablation procedure** was explicitly performed. Venous\n,→ablations are performed primarily to treat **varicose veins** and involve techniques such as:\n- **Endovenous laser ablation (EVLA)**\n- **Radiofrequency ablation (RFA)**\n- **Chemical sclerotherapy (foam or liquid injection for vein closure)**\n- **Mechanochemical ablation (MOCA, ClariVein, etc.)**\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions**: Extract all references to **venous ablation procedures** in the report.\n,→Look for terms such as **venous ablation, endovenous laser ablation (EVLA), radiofrequency\n,→ablation (RFA), sclerotherapy, or mechanochemical ablation**.\n2. **Confirm the Procedure Type**: Ensure that the report explicitly states that one of the\n,→following procedures was performed:\n- **Endovenous thermal ablation (laser or radiofrequency-based techniques).**\n- **Sclerotherapy (chemical injection for vein closure).**\n- **Mechanochemical ablation (combining mechanical and chemical vein closure techniques).**\n3. **Resolve Ambiguities**: If the procedure is only **suggested, planned, considered, or\n,→recommended** but not explicitly confirmed as performed, classify it as **not performed**.\n4. **Handle Uncertainty**: If the report lacks a direct mention of any **venous ablation procedure\n,→**, assume it **was not performed**.\n5. **Generate JSON Output**: Construct a response in strict JSON format, adhering to the following\n,→structure:\nPrompt for Question 12:\nYour task is to determine whether a **dialysis access intervention** was explicitly performed.\n,→These interventions are specific to **arteriovenous (AV) access** and include:\n- **Fistulagrams** (angiographic evaluation of an AV fistula).\n- **Graft evaluations** (imaging or interventional assessment of AV grafts).\n- **Declot procedures** (thrombectomy or thrombolysis specifically performed on AV access).\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions**: Extract all references to **dialysis access interventions** in the report\n,→. Look for terms such as **fistulagram, AV fistula angiography, AV graft evaluation,\n,→thrombectomy, thrombolysis, or declot procedure on an AV access**.\n2. **Confirm the Procedure Type**: Ensure that the report explicitly states that one of the\n,→following procedures was performed **on an arteriovenous access**:\n- **Fistulagram** (AV fistula imaging and assessment).\n- **Graft evaluation** (assessment of an AV graft for function or complications).\n- **Declot procedure** (thrombectomy or thrombolysis **specifically on an AV access**).\n3. **Resolve Ambiguities**: If the procedure is only **suggested, planned, considered, or\n,→recommended** but not explicitly confirmed as performed, classify it as **not performed**.\n4. **Exclude Non-Relevant Procedures**: Ensure that procedures **not related to arteriovenous\n,→access** (such as central venous catheter interventions) **are not mistakenly classified as\n,→dialysis access interventions**.\n5. **Handle Uncertainty**: If the report lacks a direct mention any **dialysis access intervention\n,→**, assume it **was not performed**.\n26\n"}, {"page": 27, "text": "6. **Generate JSON Output**: Construct a response in strict JSON format, adhering to the following\n,→structure:\nPrompt for Question 13:\nYour task is to determine whether **any intervention involving a portosystemic shunt** was\n,→explicitly performed. These interventions include:\n- **Shunt placement** (creation of a new portosystemic shunt).\n- **Shunt evaluation** (imaging or assessment of an existing shunt for patency or function).\n- **Shunt revision** (modification, balloon angioplasty, or stenting of a pre-existing shunt).\nThe **portosystemic shunts** of interest include:\n- **Transjugular Intrahepatic Portosystemic Shunt (TIPS)**\n- **Direct Intrahepatic Portocaval Shunt (DIPS)**\n- **Transjugular Transcaval Intrahepatic Portosystemic Shunt (TTIPS)**\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions**: Extract all references to **portosystemic shunt interventions** in the\n,→report. Look for terms such as **TIPS, DIPS, TTIPS, transjugular intrahepatic shunt, portocaval\n,→shunt, portosystemic shunt placement, shunt revision, or shunt evaluation**.\n2. **Confirm the Procedure Type**: Ensure that the report explicitly states that one of the\n,→following procedures was performed:\n- **Shunt Placement** (creation of a new TIPS, DIPS, or TTIPS).\n- **Shunt Evaluation** (assessment of an existing shunt’s function, flow, or patency).\n- **Shunt Revision** (angioplasty, stenting, or any modification to an existing shunt).\n3. **Resolve Ambiguities**: If the procedure is only **suggested, planned, considered, or\n,→recommended** but not explicitly confirmed as performed, classify it as **not performed**.\n4. **Exclude Non-Relevant Procedures**: Ensure that unrelated vascular or hepatic interventions (\n,→such as portal vein thrombectomy or general liver angiography) **are not mistaken for\n,→portosystemic shunt interventions**.\n5. **Handle Uncertainty**: If the report lacks a direct mention of any **portosystemic shunt\n,→intervention**, assume it **was not performed**.\n6. **Generate JSON Output**: Construct a response in strict JSON format, adhering to the following\n,→structure:\nPrompt for Question 14:\nYour task is to determine whether **angioplasty or stent placement in the arterial system** was\n,→explicitly performed. The **arterial system** includes **any artery in the body**, such as:\n- **Coronary arteries** (e.g., coronary angioplasty, coronary stenting).\n- **Carotid arteries** (e.g., carotid artery stenting, carotid angioplasty).\n- **Peripheral arteries** (e.g., femoral, iliac, popliteal artery interventions).\n- **Visceral arteries** (e.g., renal, mesenteric artery stenting).\n- **Aortic branches** (e.g., subclavian, vertebral artery stenting).\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions**: Extract all references to **angioplasty or stent placement** within the\n,→**arterial system** from the report. Look for terms such as **angioplasty, percutaneous\n27\n"}, {"page": 28, "text": ",→transluminal angioplasty (PTA), arterial stenting, vascular stenting, endovascular stent\n,→placement, or balloon dilation of an artery**.\n2. **Confirm the Procedure Type**: Ensure that the report explicitly states that one of the\n,→following procedures was performed:\n- **Angioplasty** (balloon dilation of an arterial stenosis).\n- **Stent Placement** (implantation of a stent within an artery).\n3. **Resolve Ambiguities**: If the procedure is only **suggested, planned, considered, or\n,→recommended** but not explicitly confirmed as performed, classify it as **not performed**.\n4. **Exclude Non-Relevant Procedures**: Ensure that interventions performed **in the venous system\n,→** (such as venous angioplasty or venous stenting) **are not mistaken for arterial interventions\n,→**.\n5. **Handle Uncertainty**: If the report lacks a direct mention of any **arterial angioplasty or\n,→stent placement**, assume it **was not performed**.\n6. **Generate JSON Output**: Construct a response in strict JSON format, adhering to the following\n,→structure:\nPrompt for Question 15:\nYour task is to determine whether **angioplasty or stent placement in the venous system** was\n,→explicitly performed. The **venous system** includes **any vein in the body**, such as:\n- **Central veins** (e.g., superior vena cava (SVC), inferior vena cava (IVC), subclavian,\n,→brachiocephalic veins).\n- **Peripheral veins** (e.g., iliac, femoral, popliteal, upper extremity veins).\n- **Portal or hepatic veins** (e.g., hepatic vein stenting, portal vein angioplasty).\n- **Pelvic veins** (e.g., gonadal, ovarian, or internal iliac vein interventions).\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions**: Extract all references to **venous angioplasty or venous stent placement\n,→** from the report. Look for terms such as **venous angioplasty, balloon venoplasty, venous\n,→stenting, endovenous stent placement, mechanical luminal disruption, or vein dilation with a\n,→balloon**.\n2. **Confirm the Procedure Type**: Ensure that the report explicitly states that one of the\n,→following procedures was performed:\n- **Venous Angioplasty** (balloon inflation to open a vein or disrupt an obstruction).\n- **Venous Stent Placement** (implantation of a stent within a vein).\n3. **Resolve Ambiguities**: If the procedure is only **suggested, planned, considered, or\n,→recommended** but not explicitly confirmed as performed, classify it as **not performed**.\n4. **Exclude Non-Relevant Procedures**: Ensure that interventions performed **in the arterial\n,→system** (such as arterial angioplasty or arterial stenting) **are not mistakenly classified as\n,→venous interventions**.\n5. **Handle Uncertainty**: If the report lacks direct mention of any **venous angioplasty or stent\n,→placement**, assume it **was not performed**.\n6. **Generate JSON Output**: Construct a response in strict JSON format, adhering to the following\n,→structure:\nPrompt for Question 16:\nYour task is to determine whether **stent placement in the carotid artery** was explicitly\n,→performed. The carotid arteries include:\n- **Common carotid artery (CCA)**\n- **Internal carotid artery (ICA)**\n- **External carotid artery (ECA)**\n28\n"}, {"page": 29, "text": "If the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions**: Extract all references to **stent placement in the carotid artery** from\n,→the report. Look for terms such as **carotid stenting, carotid artery stent placement,\n,→endovascular stenting of the carotid, carotid angioplasty with stenting, or CAS (Carotid Artery\n,→Stenting)**.\n2. **Confirm the Procedure Type**: Ensure that the report explicitly states that **a stent was\n,→placed in the carotid artery**.\n3. **Resolve Ambiguities**: If the procedure is only **suggested, planned, considered, or\n,→recommended** but not explicitly confirmed as performed, classify it as **not performed**.\n4. **Exclude Non-Relevant Procedures**: Ensure that other **carotid interventions (such as carotid\n,→angiography, balloon angioplasty without stent placement, or diagnostic imaging)** are **not\n,→mistaken for carotid stenting**.\n5. **Handle Uncertainty**: If the report lacks a direct mention of **carotid artery stent placement\n,→**, assume it **was not performed**.\n6. **Generate JSON Output**: Construct a response in strict JSON format, adhering to the following\n,→structure:\nPrompt for Question 17:\nYour task is to determine whether **thrombolytic therapy or thrombectomy** was explicitly performed\n,→. These interventions include:\n#### **Thrombolytic Therapy** (Clot-Dissolving Medication)\n- **Systemic or catheter-directed administration** of thrombolytic agents.\n- **Common drugs:**\n- **tPA (tissue plasminogen activator)**\n- **Tenecteplase**\n- **Alteplase**\n#### **Thrombectomy** (Clot Removal Procedures)\n- **Mechanical thrombectomy** - Direct clot removal using specialized devices (e.g., aspiration\n,→catheters, stent retrievers).\n- **Balloon thrombectomy** - Clot extraction using a balloon catheter.\n- **Pharmacomechanical thrombectomy** - Combination of thrombolytic drugs with mechanical clot\n,→disruption.\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions**: Extract all references to **thrombolytic therapy or thrombectomy** from\n,→the report. Look for terms such as **tPA administration, thrombolysis, lytic therapy, alteplase,\n,→\ntenecteplase, mechanical thrombectomy, aspiration thrombectomy, balloon thrombectomy, or\n,→pharmacomechanical thrombectomy**.\n2. **Confirm the Procedure Type**: Ensure that the report explicitly states that **one of the\n,→following was performed**:\n- **Thrombolytic therapy** (administration of clot-dissolving drugs).\n- **Thrombectomy** (mechanical or pharmacomechanical clot removal).\n3. **Resolve Ambiguities**: If the procedure is only **suggested, planned, considered, or\n,→recommended** but not explicitly confirmed as performed, classify it as **not performed**.\n4. **Exclude Non-Relevant Procedures**: Ensure that other **vascular interventions (such as\n,→angioplasty or stenting)** are **not mistaken for thrombolytic therapy or thrombectomy**.\n29\n"}, {"page": 30, "text": "5. **Handle Uncertainty**: If the report lacks a direct mention of **thrombolytic therapy or\n,→thrombectomy**, assume it **was not performed**.\n6. **Generate JSON Output**: Construct a response in strict JSON format, adhering to the following\n,→structure:\nPrompt for Question 18:\nYour task is to determine whether **aortic endograft placement or revision** was explicitly\n,→performed. This includes procedures related to:\n- **Endovascular Aneurysm Repair (EVAR)** - Placement of an endograft to treat an abdominal aortic\n,→aneurysm (AAA).\n- **Thoracic Endovascular Aortic Repair (TEVAR)** - Endograft placement in the thoracic aorta.\n- **Fenestrated Endovascular Aortic Repair (FEVAR)** - Endograft placement with fenestrations for\n,→branch vessels.\n- **Endograft Revision** - Any modification, extension, or repair of a previously placed aortic\n,→endograft.\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions**: Extract all references to **aortic endograft placement or revision** from\n,→\nthe report. Look for terms such as **EVAR, TEVAR, FEVAR, aortic stent graft placement, aortic\n,→endograft deployment, endovascular aortic repair, endograft revision, or endograft extension**.\n2. **Confirm the Procedure Type**: Ensure that the report explicitly states that **one of the\n,→following was performed**:\n- **Aortic endograft placement** (initial deployment of an aortic stent graft).\n- **Aortic endograft revision** (modification or extension of a prior graft).\n3. **Resolve Ambiguities**: If the procedure is only **suggested, planned, considered, or\n,→recommended** but not explicitly confirmed as performed, classify it as **not performed**.\n4. **Exclude Non-Relevant Procedures**: Ensure that other **vascular interventions (such as aortic\n,→angiography, open surgical repair, or stenting of non-aortic vessels)** are **not mistaken for\n,→aortic endograft placement or revision**.\n5. **Handle Uncertainty**: If the report lacks a direct mention of **aortic endograft placement or\n,→revision**, assume it **was not performed**.\n6. **Generate JSON Output**: Construct a response in strict JSON format, adhering to the following\n,→structure:\nPrompt for Question 19:\nYour task is to determine whether **an emergency embolization** was explicitly performed. Emergency\n,→\nembolization is defined as the **intravascular administration of an occlusive material to stop\n,→or control active bleeding or hemorrhage**.\n#### **Common Indications for Emergency Embolization**\n- **Trauma-related bleeding** (e.g., liver, spleen, kidney, or pelvic trauma).\n- **Gastrointestinal (GI) bleeding** (e.g., gastric, duodenal, or colonic bleeding).\n- **Hemoptysis** (severe lung bleeding).\n- **Iatrogenic bleeding** (bleeding caused by medical procedures).\n- **Tumor-related hemorrhage** (e.g., bleeding from hypervascular tumors).\n#### **Common Embolization Materials**\n- **Gelfoam** (temporary occlusion).\n- **Onyx** (liquid embolic agent).\n- **Beads or microparticles** (used for tumor or GI bleeding control).\n30\n"}, {"page": 31, "text": "- **Coils and plugs** (mechanical occlusion devices).\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions**: Extract all references to **emergency embolization** in the report. Look\n,→for terms such as **embolization, endovascular embolization, vascular occlusion, coil\n,→embolization, Onyx injection, Gelfoam, particle embolization, or hemorrhage control procedure**.\n2. **Confirm the Procedure Type**: Ensure that the report explicitly states that an **embolization\n,→procedure** was performed **for emergency bleeding control** rather than elective or\n,→prophylactic purposes.\n3. **Determine the Indication**: Verify that the embolization was performed for **active bleeding,\n,→trauma, GI hemorrhage, hemoptysis, iatrogenic causes, or tumor-related bleeding** rather than\n,→for **tumor devascularization, arteriovenous malformation (AVM) treatment, or preoperative\n,→embolization**.\n4. **Resolve Ambiguities**: If the report mentions **embolization was considered, planned, or\n,→recommended** but does not confirm that it was **performed**, classify it as **not performed**.\n5. **Exclude Non-Relevant Procedures**: Ensure that **angiography, stent placement, thrombectomy,\n,→or other vascular interventions** are **not mistaken for emergency embolization**.\n6. **Handle Uncertainty**: If the report lacks a direct mention of **emergency embolization**,\n,→assume it **was not performed**.\n7. **Generate JSON Output**: Construct a response in strict JSON format, adhering to the following\n,→structure:\nPrompt for Question 20:\nYour task is to determine whether **an elective embolization** was explicitly performed. Elective\n,→embolization is defined as the **intravascular administration of an occlusive material to stop\n,→or reduce blood flow for non-emergency therapeutic purposes** or for the **administration of\n,→medication**.\n#### **Types of Elective Embolization Procedures**\n- **Uterine Artery Embolization (UAE)** - Used to treat uterine fibroids.\n- **Uterine Fibroid Embolization (UFE)** - Specific type of UAE for fibroid treatment.\n- **Arteriovenous Malformation (AVM) Embolization** - Used to block abnormal blood vessel\n,→connections.\n- **Varicocele Embolization** - Treats enlarged veins in the scrotum.\n- **Gonadal Vein Embolization** - Treats venous insufficiency in reproductive organs.\n- **Protective Embolization** - Performed before procedures to prevent complications.\n#### **Exclusion Criteria**\n- **Transarterial Chemoembolization (TACE) and Transarterial Radioembolization (TARE)** should **\n,→not** be considered **elective embolization** **unless protective embolization** was performed.\n- **Emergency embolization for active bleeding or trauma** is **not elective** and should be\n,→excluded.\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions**: Extract all references to **elective embolization** from the report. Look\n,→\nfor terms such as **uterine artery embolization, fibroid embolization, AVM embolization,\n,→varicocele embolization, gonadal vein embolization, protective embolization, or planned vascular\n,→\nocclusion**.\n31\n"}, {"page": 32, "text": "2. **Confirm the Procedure Type**: Ensure that the embolization was performed **for elective (non-\n,→emergency) indications**, such as **fibroids, AVMs, or varicoceles**, rather than for **acute\n,→hemorrhage control**.\n3. **Differentiate from Non-Elective Procedures**:\n- **Exclude emergency embolization** for trauma, GI bleeding, hemoptysis, or tumor-related\n,→hemorrhage.\n- **Exclude TACE or TARE unless protective embolization was explicitly mentioned.**\n4. **Resolve Ambiguities**: If the report mentions **embolization was considered, planned, or\n,→recommended** but does not confirm that it was **performed**, classify it as **not performed**.\n5. **Exclude Non-Relevant Procedures**: Ensure that **angiography, venous sclerotherapy, or other\n,→vascular interventions** are **not mistaken for elective embolization**.\n6. **Handle Uncertainty**: If the report lacks a direct mention of **elective embolization**,\n,→assume it **was not performed**.\n7. **Generate JSON Output**: Construct a response in strict JSON format, adhering to the following\n,→structure:\nPrompt for Question 21:\nYour task is to determine whether **a transarterial chemoembolization (TACE) procedure** was\n,→explicitly performed. **TACE is defined as the intravascular administration of a chemotherapy\n,→agent to treat a tumor.**\n#### **Key Criteria for TACE**\n- **Must involve intra-arterial chemotherapy delivery** (e.g., doxorubicin, cisplatin, mitomycin C)\n,→.\n- **Must involve arterial embolization** to reduce tumor blood supply.\n- **Indications typically include hepatocellular carcinoma (HCC) or metastatic liver tumors.**\n#### **Exclusion Criteria**\n- **Transarterial Radioembolization (TARE)** - Uses radioactive microspheres instead of\n,→chemotherapy.\n- **Elective Embolization (e.g., uterine fibroid embolization, AVM embolization)** - Not the same\n,→as TACE.\n- **Emergency Embolization** - Performed for bleeding, not tumor treatment.\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions**: Extract all references to **TACE, transarterial chemoembolization, intra-\n,→arterial chemotherapy, or embolization for tumor treatment** in the report.\n2. **Confirm the Procedure Type**: Ensure the report explicitly states that **chemotherapy was\n,→administered intra-arterially** and that **embolization was performed as part of the procedure\n,→**.\n3. **Differentiate from Other Procedures**:\n- **Exclude TARE** (radioembolization with Y-90 microspheres).\n- **Exclude elective embolization for fibroids, AVMs, or varicoceles.**\n- **Exclude emergency embolization for trauma or hemorrhage.**\n4. **Resolve Ambiguities**: If the report mentions **TACE was considered, planned, or recommended**\n,→\nbut does not confirm that it was **performed**, classify it as **not performed**.\n5. **Exclude Non-Relevant Procedures**: Ensure that **biopsy, angiography, or systemic chemotherapy\n,→** are **not mistaken for TACE**.\n6. **Handle Uncertainty**: If the report lacks a direct mention of **TACE**, assume it **was not\n,→performed**.\n7. **Generate JSON Output**: Construct a response in strict JSON format, adhering to the following\n,→structure:\nPrompt for Question 22:\n32\n"}, {"page": 33, "text": "Your task is to determine whether **a transarterial radioembolization (TARE) procedure** was\n,→explicitly performed. **TARE is defined as the intra-arterial administration of radioactive\n,→microspheres, most commonly Yttrium-90 (Y90), to treat tumors.**\n#### **Key Criteria for TARE**\n- **Must involve intra-arterial administration of radioactive material** (e.g., Yttrium-90\n,→microspheres).\n- **May include angiographic mapping with or without macroaggregated albumin (MAA) administration**\n,→\nto assess vascular anatomy before Y90 treatment.\n- **Typically performed for hepatic tumors (e.g., hepatocellular carcinoma, metastatic liver\n,→disease).**\n#### **Exclusion Criteria**\n- **Transarterial Chemoembolization (TACE)** - Uses **chemotherapy agents** instead of radioactive\n,→microspheres.\n- **Elective Embolization (e.g., uterine fibroid embolization, AVM embolization)** - Not the same\n,→as TARE.\n- **Emergency Embolization** - Performed for hemorrhage control, not tumor treatment.\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions**: Extract all references to **TARE, transarterial radioembolization,\n,→Yttrium-90 (Y90) therapy, angiographic mapping, or MAA administration** in the report.\n2. **Confirm the Procedure Type**: Ensure the report explicitly states that **radioactive\n,→microspheres were administered intra-arterially** or that **angiographic mapping for TARE was\n,→performed.**\n3. **Differentiate from Other Procedures**:\n- **Exclude TACE** (chemoembolization with doxorubicin, cisplatin, mitomycin C).\n- **Exclude elective embolization for AVMs, fibroids, or varicoceles.**\n- **Exclude emergency embolization for trauma or bleeding.**\n4. **Resolve Ambiguities**: If the report mentions **TARE was considered, planned, or recommended**\n,→\nbut does not confirm that it was **performed**, classify it as **not performed**.\n5. **Exclude Non-Relevant Procedures**: Ensure that **angiography alone, hepatic artery\n,→catheterization, or systemic radiation therapy** are **not mistaken for TARE**.\n6. **Handle Uncertainty**: If the report is vague or does not explicitly mention of **TARE**,\n,→assume it **was not performed**.\n7. **Generate JSON Output**: Construct a response in strict JSON format, adhering to the following\n,→structure:\nPrompt for Question 23:\nYour task is to determine whether an **intravascular procedure was performed** that **does not fit\n,→into** any of the following predefined categories:\n- **Venous access procedures** (e.g., port placement, exchange, or removal, central venous catheter\n,→\nprocedures, dialysis catheter procedures).\n- **Dialysis access interventions** (e.g., fistulagrams, graft evaluations, declot procedures for\n,→arteriovenous access).\n- **IVC filter placement or removal**.\n- **Ablation procedures** (e.g., venous ablation).\n- **Stent or stent-graft placement** (arterial or venous).\n- **TIPS, DIPS, or other portosystemic shunt procedures**.\n- **Embolization procedures** (elective or emergency).\n33\n"}, {"page": 34, "text": "- **Transarterial Chemoembolization (TACE)**.\n- **Transarterial Radioembolization (TARE)**.\nIf a procedure **does not fall under any of these categories** and involves **intravascular access\n,→**, it qualifies for a **label of ‘1‘**. Examples of qualifying procedures include:\n- **Transjugular liver or renal biopsy**\n- **Other intravascular biopsies**\n- **Fiducial marker placement using an intravascular approach**\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Any Intravascular Procedure**:\n- Look for descriptions of procedures that involve catheter-based access to blood vessels.\n2. **Check for Exclusion Criteria**:\n- If the procedure is **already classified** under venous access, dialysis interventions, IVC\n,→filters, ablations, stents, TIPS, embolization, TACE, or TARE, **do not count it**.\n3. **Check for Inclusion Criteria**:\n- If the procedure is **not one of the excluded categories** but still involves **vascular\n,→access**, determine if it falls under examples such as **intravascular biopsy (e.g.,\n,→transjugular liver biopsy, renal biopsy) or fiducial marker placement**.\n4. **Resolve Ambiguities**:\n- If the report states that **a procedure was planned or considered** but does not confirm that\n,→it was **performed**, classify it as **not performed**.\n5. **Ensure No Misclassification**:\n- Verify that **angiography, diagnostic imaging alone, or systemic procedures** are **not\n,→mistakenly included** as intravascular interventions.\n6. **Generate JSON Output**:\n- Your response **must** be a **valid JSON object** with the following structure:\nPrompt for Question 24:\nYour task is to determine whether a **percutaneous biopsy** was performed.\n- **Percutaneous biopsy** refers to a biopsy procedure where a needle is inserted **through the\n,→skin** to obtain a tissue sample from an organ or mass.\n- **Percutaneous biopsy does NOT include intravascular biopsy procedures** such as:\n- **Transjugular liver biopsy**\n- **Transjugular renal biopsy**\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Any Biopsy Procedure**:\n- Look for key terms indicating a **biopsy** was performed. Common descriptors include:\n- ’Fine-needle aspiration (FNA)’\n- ’Core needle biopsy (CNB)’\n34\n"}, {"page": 35, "text": "- ’Image-guided biopsy’ (e.g., ultrasound-guided, CT-guided)\n2. **Confirm Percutaneous Approach**:\n- Ensure the biopsy was performed **through the skin** and not via a **vascular approach**.\n- If terms like **’transjugular’**, **’intravascular’**, or **’endovascular’** appear, **do not\n,→count it** as percutaneous.\n3. **Resolve Ambiguities**:\n- If the report states that a **biopsy was considered or planned** but does not confirm it was\n,→**performed**, classify it as **not performed**.\n4. **Ensure No Misclassification**:\n- If the procedure involves **resection, excision, or surgical biopsy**, it is **not** a\n,→percutaneous biopsy and should be excluded.\n- If only **biopsy results** are mentioned but **no procedural details** are given, assume the\n,→biopsy is **not documented** in this report.\n5. **Generate JSON Output**:\n- Your response **must** be a **valid JSON object** with the following structure:\nPrompt for Question 25:\nYour task is to determine whether an **abscess drainage procedure** was performed.\n- **Abscess drainage procedures** include:\n- Placement of a drain for an **abscess** or **fluid collection**\n- **Drain revision, repositioning, upsizing, or removal**\n- **Exclusions** (Do **not** count the following as abscess drainage):\n- **Biliary drains and tubes**\n- **Cholecystostomy drains and tubes**\n- **Nephrostomy drains and tubes**\n- **Nephroureterostomy drains and tubes**\n- **Chest drains and tubes**\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Any Drainage Procedure**:\n- Look for terms indicating **drain placement, removal, revision, or repositioning** related to\n,→an **abscess or fluid collection**.\n- Common descriptors include:\n- ’Percutaneous abscess drainage’\n- ’Fluid collection drainage’\n- ’Drain placed for abscess’\n- ’Drain repositioning/upsize’\n2. **Confirm That It Is an Abscess Drainage Procedure**:\n- Ensure the **drainage target** is an **abscess or fluid collection**, not an excluded category\n,→.\n- If the report specifies a **biliary, cholecystostomy, nephrostomy, nephroureterostomy, or\n,→chest drain**, **do not count it** as abscess drainage.\n3. **Resolve Ambiguities**:\n35\n"}, {"page": 36, "text": "- If the report states that **drainage was planned or considered** but does **not confirm it was\n,→\nperformed**, classify it as **not performed**.\n- If **only fluid aspiration is performed without drain placement**, it should **not** be\n,→classified as a drainage procedure.\n4. **Ensure No Misclassification**:\n- **Exclude surgical drainage procedures** if they were performed in an **operating room**\n,→instead of radiologically guided drainage.\n- If the **report only mentions drain presence** without confirming **drain placement, revision,\n,→\nor removal**, assume it is **not documented** in this report.\n5. **Generate JSON Output**:\n- Your response **must** be a **valid JSON object** with the following structure:\nPrompt for Question 26:\nYour task is to determine whether a **paracentesis or thoracentesis** procedure was performed.\n- **Definitions**:\n- **Paracentesis**: A procedure involving **needle drainage of peritoneal fluid (ascites)** from\n,→the **abdomen**.\n- **Thoracentesis**: A procedure involving **needle drainage of pleural fluid (effusion)** from\n,→the **chest (pleural cavity)**.\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Any Drainage Procedure**:\n- Look for terms indicating **fluid drainage** from the **abdomen (paracentesis)** or **pleural\n,→space (thoracentesis)**.\n- Common descriptors include:\n- ’Paracentesis performed’\n- ’Thoracentesis completed’\n- ’Fluid removed from the peritoneal cavity’\n- ’Pleural effusion drained under ultrasound guidance’\n2. **Confirm That It Matches the Definition**:\n- Ensure the report **explicitly states** that **paracentesis or thoracentesis was performed**.\n- If the procedure is **planned or considered but not confirmed as performed**, classify it as\n,→**not performed**.\n3. **Exclude Unrelated Drainage Procedures**:\n- **Do not classify as paracentesis/thoracentesis** if:\n- **Fluid aspiration was performed without drainage**.\n- The report describes **abscess drainage, biliary drainage, or nephrostomy**, which are **not\n,→** paracentesis/thoracentesis.\n- A **chest tube** was placed instead of thoracentesis.\n4. **Resolve Ambiguities**:\n- If the report **only mentions the presence of fluid (ascites or pleural effusion)** but does\n,→not confirm a **drainage procedure**, classify as **not documented**.\n- If the **procedure attempt failed and no fluid was drained**, classify as **not performed**.\n5. **Generate JSON Output**:\n- Your response **must** be a **valid JSON object** with the following structure:\n36\n"}, {"page": 37, "text": "Prompt for Question 27:\nYour task is to determine whether a **chest tube placement** procedure was performed.\n- **Definition**:\n- **Chest tube placement** refers to the insertion of a tube into the **pleural space** to drain\n,→**air (pneumothorax), fluid (pleural effusion), blood (hemothorax), pus (empyema), or chyle (\n,→chylothorax)**.\n- This is distinct from **thoracentesis**, which involves a needle aspiration without an\n,→indwelling tube.\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Any Tube Placement Procedure**:\n- Look for terms indicating a **chest tube was inserted**.\n- Common descriptors include:\n- ’Chest tube placed’\n- ’Thoracostomy tube inserted’\n- ’Pleural drain inserted’\n- ’Intercostal drain placement’\n2. **Confirm That It Matches the Definition**:\n- Ensure that the **tube was actually placed into the pleural space**.\n- **Exclude** procedures that only describe **thoracentesis (needle drainage without a tube)**.\n3. **Resolve Ambiguities**:\n- If the report states that **a chest tube was planned or considered** but does **not confirm it\n,→\nwas performed**, classify it as **not performed**.\n- If the **report only mentions the presence of a chest tube** but does not confirm **placement\n,→in this report**, assume it is **not documented** in this instance.\n4. **Ensure No Misclassification**:\n- **Do not classify as chest tube placement if:**\n- The procedure was an **aspiration-only thoracentesis** without a tube.\n- The report describes **pleural catheter placement**, which is distinct from a chest tube.\n- The tube was placed **outside the pleural cavity**, such as an abdominal or mediastinal\n,→drain.\n5. **Generate JSON Output**:\n- Your response **must** be a **valid JSON object** with the following structure:\nPrompt for Question 28:\nYour task is to determine whether a **pleurodesis procedure** was performed.\n- **Definition**:\n- **Pleurodesis** is a medical procedure that **induces adhesion between the pleural layers** to\n,→prevent the recurrence of pleural effusion or pneumothorax.\n- This is typically achieved by **introducing a chemical agent (e.g., talc, doxycycline, or\n,→bleomycin) or mechanical abrasion into the pleural space**.\n37\n"}, {"page": 38, "text": "If the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Any Mention of Pleurodesis**:\n- Look for terms indicating **pleurodesis was performed**.\n- Common descriptors include:\n- ’Chemical pleurodesis with talc/doxycycline performed’\n- ’Mechanical pleurodesis via abrasion’\n- ’Instillation of pleurodesis agent into pleural space’\n2. **Confirm That It Matches the Definition**:\n- Ensure that the **procedure was actually carried out**, not just considered or planned.\n- Verify that **the agent or mechanical technique used for pleurodesis is explicitly stated**.\n3. **Resolve Ambiguities**:\n- If the report states that **pleurodesis was planned or considered** but does **not confirm it\n,→was performed**, classify it as **not performed**.\n- If the **report only mentions a prior pleurodesis** without confirming that a **new\n,→pleurodesis was performed**, assume it is **not documented in this instance**.\n4. **Ensure No Misclassification**:\n- **Do not classify as pleurodesis if:**\n- The procedure **only describes chest tube placement** without mention of pleurodesis.\n- The **pleural space was drained** (e.g., thoracentesis) but **no pleurodesis agent or\n,→abrasion was applied**.\n- The procedure was a **pleural biopsy or another intervention unrelated to pleurodesis**.\n5. **Generate JSON Output**:\n- Your response **must** be a **valid JSON object** with the following structure:\nPrompt for Question 29:\nYour task is to determine whether a **procedure involving a biliary drain or biliary stent** was\n,→performed.\n- **Definition**:\n- **Biliary drain or stent procedures** include:\n- **Percutaneous transhepatic cholangiography (PTC)**\n- **Biliary drain placement, evaluation, or revision**\n- **Biliary stent placement or revision**\n- **Exclusion**:\n- **Cholecystostomy procedures (placement, exchange, or removal) do NOT count as biliary drain\n,→or stent procedures.**\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions of a Biliary Drain or Stent Procedure**:\n- Look for phrases such as:\n- ’Percutaneous transhepatic cholangiography (PTC) performed’\n- ’Biliary drain placement/revision/exchange’\n- ’Biliary stent placement/revision’\n- ’Intervention in the biliary system with drain or stent’\n38\n"}, {"page": 39, "text": "2. **Confirm That It Matches the Definition**:\n- Ensure that the procedure was **actually performed**, not just recommended or considered.\n- Verify that **it involves the biliary system** and is **not related to the gallbladder (\n,→cholecystostomy)**.\n3. **Resolve Ambiguities**:\n- If the report **mentions a prior biliary drain or stent** but does **not confirm a new\n,→procedure was performed**, classify as **not documented**.\n- If the report **only discusses imaging of the biliary system (e.g., MRCP) without intervention\n,→**, classify as **not performed**.\n4. **Exclude Non-Biliary Procedures**:\n- **Do not classify as a biliary drain or stent procedure if:**\n- The procedure was a **cholecystostomy placement, exchange, or removal**.\n- The report describes **only a diagnostic cholangiogram with no intervention**.\n- The intervention was **related to another organ system (e.g., pancreatic duct stenting,\n,→nephrostomy placement, or GI stenting)**.\n5. **Generate JSON Output**:\n- Your response **must** be a **valid JSON object** with the following structure:\nPrompt for Question 30:\nYour task is to determine whether a **genitourinary drain procedure** was performed.\n- **Definition**:\n- **Genitourinary drain procedures** include:\n- **Nephrostomy tube placement, exchange, revision, or removal**\n- **Nephroureteral stent placement, exchange, revision, or removal**\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions of a Genitourinary Drain Procedure**:\n- Look for phrases such as:\n- ’Nephrostomy tube placed/exchanged/revised/removed’\n- ’Nephroureteral stent placement/exchange/revision/removal’\n- ’Percutaneous nephrostomy procedure performed’\n- ’Intervention involving urinary drainage system’\n2. **Confirm That It Matches the Definition**:\n- Ensure that the procedure was **actually performed**, not just recommended or considered.\n- Verify that the procedure was **specific to the genitourinary system**, particularly **kidneys\n,→\nand ureters**.\n3. **Resolve Ambiguities**:\n- If the report **mentions a prior nephrostomy tube or stent** but does **not confirm a new\n,→procedure**, classify as **not documented**.\n- If the report **only discusses imaging of the genitourinary system (e.g., CT Urogram, MR\n,→Urogram) without intervention**, classify as **not performed**.\n4. **Exclude Non-Genitourinary Procedures**:\n- **Do not classify as a genitourinary drain procedure if:**\n39\n"}, {"page": 40, "text": "- The procedure was **related to the bladder or urethra (e.g., Foley catheter placement,\n,→suprapubic catheter placement)**.\n- The report describes **only diagnostic imaging without any interventional component**.\n- The intervention was **related to another organ system (e.g., biliary drains, chest tubes,\n,→or gastrointestinal stents)**.\n5. **Generate JSON Output**:\n- Your response **must** be a **valid JSON object** with the following structure:\nPrompt for Question 31:\nYour task is to determine whether an **enterostomy procedure** was performed.\n- **Definition**:\n- **Enterostomy procedures** include:\n- **Gastrostomy placement, exchange, revision, or removal**\n- **Gastrojejunostomy placement, exchange, revision, or removal**\n- **Jejunostomy placement, exchange, revision, or removal**\n- **Ileostomy placement, exchange, revision, or removal**\n- **Cecostomy placement, exchange, revision, or removal**\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions of an Enterostomy Procedure**:\n- Look for phrases such as:\n- ’Gastrostomy tube placed/exchanged/revised/removed’\n- ’Gastrojejunostomy tube placement/exchange/revision/removal’\n- ’Jejunostomy procedure performed’\n- ’Percutaneous enterostomy tube placement’\n- ’Ileostomy or cecostomy intervention performed’\n2. **Confirm That It Matches the Definition**:\n- Ensure that the procedure was **actually performed**, not just recommended or considered.\n- Verify that the procedure was **specific to the gastrointestinal system**, particularly the\n,→stomach, small intestine, or colon.\n3. **Resolve Ambiguities**:\n- If the report **mentions a prior enterostomy procedure** but does **not confirm a new\n,→procedure**, classify as **not documented**.\n- If the report **only discusses enteric imaging (e.g., fluoroscopy to check tube placement)\n,→without intervention**, classify as **not performed**.\n4. **Exclude Non-Enterostomy Procedures**:\n- **Do not classify as an enterostomy procedure if:**\n- The procedure was **related to the esophagus or rectum (e.g., esophageal stenting, rectal\n,→tube placement)**.\n- The report describes **only diagnostic imaging without any interventional component**.\n- The intervention was **related to another organ system (e.g., biliary or genitourinary\n,→procedures)**.\n5. **Generate JSON Output**:\n- Your response **must** be a **valid JSON object** with the following structure:\nPrompt for Question 32:\n40\n"}, {"page": 41, "text": "Your task is to determine whether a **cholecystostomy procedure** was performed.\n- **Definition**:\n- **Cholecystostomy procedures** include:\n- **Cholecystostomy drain or tube placement**\n- **Cholecystostomy drain or tube exchange**\n- **Cholecystostomy drain or tube revision**\n- **Cholecystostomy drain or tube removal**\n- **Cholecystography (contrast imaging of the gallbladder through a cholecystostomy tube)**\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions of a Cholecystostomy Procedure**:\n- Look for phrases such as:\n- ’Cholecystostomy tube placed/exchanged/revised/removed’\n- ’Percutaneous cholecystostomy performed’\n- ’Cholecystography performed via cholecystostomy tube’\n2. **Confirm That It Matches the Definition**:\n- Ensure that the procedure was **actually performed**, not just recommended or considered.\n- Verify that the procedure was **specific to the gallbladder**, involving intervention with a\n,→drain, tube, or contrast study.\n3. **Resolve Ambiguities**:\n- If the report **mentions a prior cholecystostomy procedure** but does **not confirm a new\n,→procedure**, classify as **not documented**.\n- If the report **only describes gallbladder imaging (e.g., ultrasound, CT, or MRI) without\n,→intervention**, classify as **not performed**.\n4. **Exclude Non-Cholecystostomy Procedures**:\n- **Do not classify as a cholecystostomy procedure if:**\n- The procedure was **related to the biliary system but did not involve a cholecystostomy\n,→drain or tube (e.g., biliary stenting, ERCP, PTC)**.\n- The report describes **only gallbladder assessment without intervention**.\n- The intervention was **related to another organ system (e.g., enterostomy or nephrostomy\n,→procedures)**.\n5. **Generate JSON Output**:\n- Your response **must** be a **valid JSON object** with the following structure:\nPrompt for Question 33:\nYour task is to determine whether a **cyst or lymphocele procedure** was performed.\n- **Definition**:\n- **Cyst or lymphocele procedures** include:\n- **Aspiration of a cyst or lymphocele**\n- **Drain placement for a cyst or lymphocele**\n- **Drain exchange, revision, or removal for a cyst or lymphocele**\n- **Sclerosis of a cyst or lymphocele (injecting a sclerosing agent to obliterate the lesion)**\n41\n"}, {"page": 42, "text": "If the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions of a Cyst or Lymphocele Procedure**:\n- Look for phrases such as:\n- ’Aspiration of cyst/lymphocele performed’\n- ’Drain placed/exchanged/revised/removed for cyst/lymphocele’\n- ’Sclerotherapy performed for cyst/lymphocele’\n2. **Confirm That It Matches the Definition**:\n- Ensure that the procedure was **actually performed**, not just recommended or considered.\n- Verify that the intervention was **specific to a cyst or lymphocele**.\n3. **Resolve Ambiguities**:\n- If the report **mentions a prior cyst or lymphocele procedure** but does **not confirm a new\n,→procedure**, classify as **not documented**.\n- If the report **only describes imaging (e.g., ultrasound, CT, or MRI) of a cyst or lymphocele\n,→without intervention**, classify as **not performed**.\n4. **Exclude Non-Cyst/Lymphocele Procedures**:\n- **Do not classify as a cyst or lymphocele procedure if:**\n- The procedure was **related to an abscess or other fluid collection (e.g., abscess drainage,\n,→\nseroma drainage, or pleural effusion drainage)**.\n- The report describes **only diagnostic assessment without an interventional procedure**.\n- The intervention was **related to another organ system (e.g., biliary drainage, peritoneal\n,→fluid drainage, nephrostomy, or cholecystostomy procedures)**.\n5. **Generate JSON Output**:\n- Your response **must** be a **valid JSON object** with the following structure:\nPrompt for Question 34:\nYour task is to determine whether a **nonvascular stent placement** was performed.\n- **Definition**:\n- **Nonvascular stents** refer to stents placed in non-blood vessel structures, including:\n- **Esophageal stent placement**\n- **Tracheobronchial (airway) stent placement**\n- **Duodenal stent placement**\n- **Colonic stent placement**\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions of a Nonvascular Stent Placement**:\n- Look for terms such as:\n- ’Esophageal stent placed’\n- ’Tracheal/bronchial stent placement performed’\n- ’Duodenal stent deployed’\n- ’Colonic stent placement completed’\n42\n"}, {"page": 43, "text": "2. **Confirm That It Matches the Definition**:\n- Ensure that the procedure was **actually performed**, not just recommended or planned.\n- Verify that the **stent was placed in a nonvascular structure**.\n3. **Resolve Ambiguities**:\n- If the report **mentions a prior nonvascular stent placement** but does **not confirm a new\n,→procedure**, classify as **not documented**.\n- If the report **only describes imaging (e.g., X-ray, fluoroscopy, or CT) of a stent without\n,→confirming a new placement**, classify as **not performed**.\n4. **Exclude Non-Stent and Vascular Stent Procedures**:\n- **Do not classify as nonvascular stent placement if:**\n- The procedure involves **vascular (arterial or venous) stents**, such as in coronary,\n,→carotid, iliac, or femoral arteries.\n- The procedure involves **other non-stent interventions**, such as dilation without stent\n,→placement.\n- The report describes **only a stent exchange, removal, or revision** without confirming a\n,→new stent placement.\n5. **Generate JSON Output**:\n- Your response **must** be a **valid JSON object** with the following structure:\nPrompt for Question 35:\nYour task is to determine whether a **miscellaneous nonvascular transplant intervention** was\n,→performed.\n- **Definition**:\n- A **miscellaneous nonvascular transplant intervention** refers to **procedures performed\n,→exclusively on a transplant organ that do not involve arteries or veins**.\n- The report **must explicitly confirm that the organ is a transplant organ** (not a native organ\n,→).\n- **Examples include**:\n- **Stent placement** involving a transplant organ\n- **Balloon plasty procedures**, such as **ureteroplasty**\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions of a Transplant Organ**:\n- Look for explicit mentions that the **organ is a transplant**:\n- Phrases like ’**transplant kidney**,’ ’**transplant liver**,’ or ’**transplant ureter**’\n,→confirm that the organ is not native.\n- If the report does **not** specify that the organ is a **transplant**, classify as **not\n,→documented (0)**.\n2. **Identify a Relevant Nonvascular Intervention**:\n- Look for **nonvascular procedures** performed **on the transplant organ**:\n- Stent placements in a transplant organ\n- Balloon plasty procedures (e.g., **ureteroplasty**)\n- **Do NOT include vascular procedures**, such as:\n- **Transplant renal artery stenosis (TRAS) interventions**\n- **Transjugular biopsy procedures**\n- **Do NOT include** general drainage procedures such as:\n- Nephrostomy placement/exchange/removal\n- Nephroureterostomy placement/exchange/removal\n43\n"}, {"page": 44, "text": "- Biliary tube placement/exchange/removal\n3. **Confirm That the Procedure Was Performed**:\n- The procedure must be **explicitly stated as completed**, not just planned or considered.\n- If the report only describes **imaging or evaluation** without confirming an **intervention**,\n,→\nclassify as **not performed**.\n4. **Resolve Ambiguities**:\n- If the report **mentions a prior nonvascular transplant intervention** but does **not confirm\n,→a new procedure**, classify as **not documented**.\n- If the procedure is **only vascular in nature**, classify as **not performed**.\n5. **Generate JSON Output**:\n- Your response **must** be a **valid JSON object** with the following structure:\nPrompt for Question 36:\nYour task is to determine whether a **tumor ablation** procedure was performed.\n- **Definition**:\n- A **tumor ablation** is a procedure that destroys tumor tissue using thermal, chemical, or\n,→energy-based methods.\n- **Examples of tumor ablation methods include**:\n- **Radiofrequency ablation (RFA)**\n- **Laser ablation**\n- **Microwave ablation**\n- **Cryoablation**\n- **Ethanol injection/administration**\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions of a Tumor Ablation Procedure**:\n- Look for terms indicating that a **tumor ablation** was **performed**, such as:\n- **’Radiofrequency ablation (RFA) performed’**\n- **’Microwave ablation completed’**\n- **’Cryoablation applied to tumor’**\n- **’Ethanol injection administered’**\n2. **Differentiate from Other Procedures**:\n- **Do NOT include** interventions that are **not ablations**, such as:\n- **Surgical tumor resection**\n- **Tumor embolization (TACE or TARE)**\n- **Biopsy procedures**\n- If the report only mentions **imaging, planning, or evaluation** for an ablation **without\n,→confirming its completion**, classify as **not performed**.\n3. **Confirm That the Procedure Was Performed**:\n- The procedure must be **explicitly stated as completed**, not just planned or considered.\n- If the report only describes an **intended** or **future** ablation, classify as **not\n,→performed**.\n4. **Resolve Ambiguities**:\n- If the report mentions a **prior tumor ablation** but does not confirm a new procedure,\n,→classify as **not documented**.\n44\n"}, {"page": 45, "text": "- If the ablation is only referenced as a **potential treatment option** but was not performed,\n,→classify as **not performed**.\n5. **Generate JSON Output**:\n- Your response **must** be a **valid JSON object** with the following structure:\nPrompt for Question 37:\nYour task is to determine whether a **pain management procedure** was performed.\n- **Definition**:\n- A **pain management procedure** is an interventional procedure aimed at alleviating pain.\n- **Examples of pain management procedures include**:\n- **Steroid injection**\n- **Celiac plexus neurolysis**\n- **Nerve cryoablation**\n- **Periosteal cryoablation**\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions of a Pain Management Procedure**:\n- Look for terms indicating that a **pain management intervention** was **performed**, such as:\n- **’Steroid injection administered’**\n- **’Celiac plexus neurolysis performed’**\n- **’Nerve cryoablation completed’**\n- **’Periosteal cryoablation applied’**\n2. **Differentiate from Other Procedures**:\n- **Do NOT include** interventions that are **not specifically pain management**, such as:\n- **General anesthesia or sedation**\n- **Surgical nerve decompression**\n- **Tumor ablation procedures (unless explicitly performed for pain relief)**\n- If the report only mentions **imaging, planning, or evaluation** for a pain management\n,→procedure **without confirming its completion**, classify as **not performed**.\n3. **Confirm That the Procedure Was Performed**:\n- The procedure must be **explicitly stated as completed**, not just planned or considered.\n- If the report only describes an **intended** or **future** pain management procedure, classify\n,→\nas **not performed**.\n4. **Resolve Ambiguities**:\n- If the report mentions a **prior pain management procedure** but does not confirm a new one,\n,→classify as **not documented**.\n- If the procedure is only referenced as a **potential treatment option** but was not performed,\n,→\nclassify as **not performed**.\n5. **Generate JSON Output**:\n- Your response **must** be a **valid JSON object** with the following structure:\nPrompt for Question 38:\nYour task is to determine whether a **Fallopian tube recanalization** was performed.\n45\n"}, {"page": 46, "text": "- **Definition**:\n- **Fallopian tube recanalization (FTR)** is an interventional radiology procedure aimed at\n,→reopening blocked Fallopian tubes to restore fertility.\n- **This procedure involves**:\n- The use of **fluoroscopy and contrast dye** to visualize the Fallopian tubes.\n- **Catheterization** or **balloon inflation** to clear obstructions.\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify Mentions of a Fallopian Tube Recanalization Procedure**:\n- Look for terms indicating that an **FTR procedure** was performed, such as:\n- **’Fallopian tube recanalization completed’**\n- **’Selective catheterization of the Fallopian tube performed’**\n- **’Balloon dilation of Fallopian tube performed’**\n2. **Differentiate from Related Procedures**:\n- **Do NOT include** procedures that are **not Fallopian tube recanalization**, such as:\n- **Hysterosalpingography (HSG) alone** (without intervention)\n- **Salpingectomy (Fallopian tube removal)**\n- **In vitro fertilization (IVF) procedures**\n- **General fertility evaluations or imaging**\n3. **Confirm That the Procedure Was Performed**:\n- The procedure must be **explicitly stated as completed**, not just planned or considered.\n- If the report only describes an **intended** or **future** Fallopian tube recanalization,\n,→classify as **not performed**.\n4. **Resolve Ambiguities**:\n- If the report mentions a **prior Fallopian tube recanalization** but does not confirm a new\n,→one, classify as **not documented**.\n- If the procedure is only referenced as a **potential treatment option** but was not performed,\n,→\nclassify as **not performed**.\n5. **Generate JSON Output**:\n- Your response **must** be a **valid JSON object** with the following structure:\nPrompt for Question 39:\nYour task is to determine whether a **nonvascular, invasive procedure** was performed, while\n,→ensuring it **does not** fall into any of the **excluded categories** listed below.\n- **Definition**:\n- A **nonvascular, invasive procedure** involves the insertion of instruments or devices into the\n,→\nbody, either through the skin or a natural orifice, **but does not** involve blood vessels (\n,→arteries or veins).\n- **Excluded Categories**:\n- **Biopsy (percutaneous or otherwise)**\n- **Abscess drainage & tube checks**\n- **Paracentesis or thoracentesis**\n- **Chest tube placement or pleurodesis**\n- **Biliary interventions** (PTC, biliary drainage/stent procedures)\n- **Tube checks (for any previously placed drainage tubes)**\n46\n"}, {"page": 47, "text": "- **Genitourinary interventions** (nephrostomy, nephroureteral tube placements/exchanges/removals\n,→)\n- **Gastrointestinal interventions** (gastrostomy, gastrojejunostomy, cholecystostomy)\n- **Cyst or lymphocele interventions**\n- **Nonvascular stents** (esophageal, tracheobronchial, duodenal, colonic)\n- **Transplant-related nonvascular interventions**\n- **Tumor ablation (RFA, microwave, cryoablation, ethanol)**\n- **Pain management procedures (nerve blocks, neurolysis, cryoablation)**\n- **Fallopian tube recanalization**\n- **Any intravascular procedure** (angioplasty, stenting, embolization, ablation, dialysis access\n,→, venous access, TIPS, DIPS, IVC filter procedures, TACE, TARE)\nIf the procedure was explicitly performed, return ‘1‘ along with an explanation. Otherwise, return\n,→‘0‘ with an explanation.\nFollow a structured reasoning approach to do the task:\n### **Reasoning Steps**\n1. **Identify the Presence of an Invasive Procedure**:\n- Look for descriptions of **instrumentation insertion** into the body through the skin or\n,→natural orifices.\n- Common indicators include:\n- **\"Percutaneous intervention\"**\n- **\"Endoscopic intervention\"**\n- **\"Device placement\"**\n- **\"Surgical instrument insertion\"**\n2. **Check If the Procedure Falls Into an Excluded Category**:\n- Compare the procedure against the **list of excluded interventions**.\n- If the procedure **matches any exclusion**, classify as **not qualifying (return ‘0‘)**.\n3. **Determine If the Procedure Is a Nonvascular, Invasive Procedure Not Listed as Excluded**:\n- If it **does not** involve **arteries or veins** and is **not in the exclusion list**,\n,→classify as **qualifying (return ‘1‘)**.\n- Examples of qualifying procedures:\n- **Foreign body removal from a nonvascular structure**\n- **Fiducial marker placement (nonvascular target, such as lung or prostate)**\n- **Percutaneous decompression of a non-abscess fluid collection (not cyst/lymphocele-related)\n,→**\n4. **Resolve Ambiguities**:\n- If the report **only mentions a history of a procedure but no new procedure was performed**,\n,→classify as **not documented (‘0‘)**.\n- If the procedure is **described as planned but not yet performed**, classify as **not\n,→performed (‘0‘)**.\n5. **Generate JSON Output**:\n- Your response **must** be a **valid JSON object** with the following structure:\nF.3\nExample Report and Labels\nExample Report\nPre-procedure diagnosis: Cholelithiasis\nPost-procedure diagnosis: Same\nIndication: Cholelithiasis\nAdditional clinical history: None\n47\n"}, {"page": 48, "text": "Complications: No immediate complications.\nIMPRESSION:\n*\nExtensive cholelithiasis with partial removal of gallstones.\n*\nStricture at the cystic duct, status post balloon dilation.\n*\nAppropriately positioned internal/external biliary drain.\nPlan:\n*\nMaintain biliary drain to gravity drainage. Flush twice daily to ensure tube patency.\n*\nPlan for staged gallstone lithotripsy and extraction.\nPROCEDURE SUMMARY:\n- Transhepatic cholangiogram via the existing access\n- Cholangioscopy with gallstone lithotripsy and extraction.\n- Additional procedure(s): Internal/external biliary drain placement.\nPROCEDURE DETAILS:\nPre-procedure\nConsent: Informed consent for the procedure including risks, benefits and alternatives was obtained\n,→\nand time-out was performed prior to the procedure.\nPreparation: The site was prepared and draped using maximal sterile barrier technique including\n,→cutaneous antisepsis.\nAnesthesia/sedation\nLevel of anesthesia/sedation: General anesthesia\nAnesthesia/sedation administered by: Anesthesiology\nTotal intra-service sedation time (minutes): See anesthesia flow sheet.\nCholangiogram, cholangioscopy, and gallstone lithotripsy/extraction.\nLocal anesthesia was administered. Contrast was injected through the indwelling biliary drain. A\n,→guidewire was passed through the gallbladder, cystic and common bile ducts, into the small bowel\n,→. Sequential dilation was performed, until ultimately a peel-away sheath was inserted into the\n,→gallbladder. A cholangioscope was advanced over the wire into the gallbladder. Electrohydraulic\n,→lithotripsy and basket retrieval of gallstones were performed. Due to extensive gallstone burden\n,→\nof large size and limited electrohydraulic lithotripsy devices, the visualized gallstones were\n,→incompletely extracted. A cholangiogram was subsequently performed through the peel-away sheath,\n,→\ndemonstrating a focal area of stenosis at the cystic duct. Balloon dilation of the cystic and\n,→common duct was performed, with resolution of the previous area of stenosis.. A new internal/\n,→external biliary drainage catheter was placed, and the location of the distal tip was confirmed\n,→to be within small bowel following contrast injection..\nInitial cholangiogram findings: Extensive gallstones burden. Contrast flows across the cystic duct\n,→into the duodenum.\nNew biliary drain: Cook internal/external biliary drain\nNew biliary drain diameter (French): 14\nNew biliary drain modifications: None\nFinal cholangiogram findings: Cholelithiasis. Internal/external biliary drain in place with\n,→contrast draining into the duodenum.\nExternal catheter securement:\nNon-absorbable suture\nContrast\nContrast agent: Omnipaque 300\nContrast volume (mL): 20\nRadiation Dose\nFluoroscopy time (minutes): 17.0\nReference air kerma (mGy): 185.1\nKerma area product (uGy-m2): 2685.2\n48\n"}, {"page": 49, "text": "Additional Details\nAdditional description of procedure: None\nEquipment details: None\nSpecimens removed: None\nEstimated blood loss (mL): Less than 10\nResponse from Claude-3.5-Haiku with CoT Prompting\nResponse for Question 1:\n\"No explicit mention or evidence of CTA or intra-operative cone-beam CT with contrast in the\n,→radiology report. Procedures were fluoroscopy-guided with contrast cholangiography.\"\nResponse for Question 2:\n\"No mention or evidence of MR Angiography (MRA) in the radiology report. The procedure involved\n,→endoscopic gallstone lithotripsy, cholangiography, and biliary drain placement using fluoroscopy\n,→.\"\nResponse for Question 3:\n\"No noninvasive vascular lab study (duplex ultrasound, color flow study, or PVR) was mentioned or\n,→performed in this radiology report, which focused on an endoscopic gallstone procedure.\"\nResponse for Question 4:\n\"No cardiac imaging study was performed in this radiology report, which details an endoscopic\n,→gallstone lithotripsy and biliary intervention procedure.\"\nResponse for Question 5:\n\"No arteriography was performed. The procedure was an endoscopic gallstone lithotripsy with biliary\n,→\ncholangiography, using contrast in the biliary system, not an arterial study.\"\nResponse for Question 6:\n\"No venography was performed. The procedure was an endoscopic gallstone lithotripsy with\n,→cholangiography using biliary contrast, not a venous imaging study.\"\nResponse for Question 7:\n\"No dialysis access evaluation was performed in this radiology report, which describes a biliary\n,→procedure involving gallstone lithotripsy and drain placement.\"\nResponse for Question 8:\n\"No carotid artery imaging was performed or mentioned in this radiology report, which describes an\n,→endoscopic gallstone lithotripsy procedure with biliary interventions.\"\nResponse for Question 9:\n\"No central venous catheter procedure was performed. The report details a biliary drain procedure\n,→with cholangioscopy and gallstone lithotripsy.\"\nResponse for Question 10:\n\"No IVC filter placement or removal was mentioned in the radiology report. The procedure focused on\n,→\ngallstone lithotripsy and biliary drain placement.\"\nResponse for Question 11:\n\"The radiology report describes a biliary intervention for gallstone management, with no mention of\n,→\nany venous ablation procedure\"\n49\n"}, {"page": 50, "text": "Response for Question 12:\n\"No dialysis access intervention was performed. This report describes a biliary procedure involving\n,→\ngallstone lithotripsy and biliary drain placement.\"\nResponse for Question 13:\n\"No portosystemic shunt intervention was performed. The procedure was a biliary intervention\n,→involving gallstone lithotripsy and biliary drain placement.\"\nResponse for Question 14:\n\"The report describes an endoscopic gallstone lithotripsy with biliary drain placement and balloon\n,→dilation of biliary ducts, but no arterial angioplasty or stent placement was performed.\"\nResponse for Question 15:\n\"The radiology report describes a biliary intervention with no venous angioplasty or stent\n,→placement performed\"\nResponse for Question 16:\n\"The radiology report describes an endoscopic gallstone lithotripsy and biliary drain placement\n,→procedure, with no mention of carotid artery stenting.\"\nResponse for Question 17:\n\"No thrombolytic therapy or thrombectomy was performed in this biliary intervention procedure\n,→focused on gallstone management\"\nResponse for Question 18:\n\"No evidence of aortic endograft placement or revision in this radiology report. The procedure was\n,→a biliary intervention involving gallstone lithotripsy and drain placement.\"\nResponse for Question 19:\n\"No emergency embolization was performed. The procedure was a gallstone lithotripsy with biliary\n,→drain placement.\"\nResponse for Question 20:\n\"No evidence of elective embolization in this radiology report. The procedure was a gallstone\n,→lithotripsy and biliary intervention.\"\nResponse for Question 21:\n\"The report describes an endoscopic gallstone lithotripsy and biliary drain procedure. There is no\n,→mention of TACE, chemotherapy administration, or tumor embolization. The procedure focuses on\n,→gallstone removal and biliary drainage, which is entirely unrelated to transarterial\n,→chemoembolization.\"\nResponse for Question 22:\n\"This report describes an endoscopic gallstone lithotripsy with biliary drain placement. No\n,→evidence of transarterial radioembolization (TARE) was present.\"\nResponse for Question 23:\n\"This is a biliary procedure involving cholangioscopy and gallstone lithotripsy, with no\n,→intravascular intervention performed\"\nResponse for Question 24:\n50\n"}, {"page": 51, "text": "\"No percutaneous biopsy was performed in this radiology report. The procedure was focused on\n,→gallstone lithotripsy, cholangioscopy, and biliary drain placement.\"\nResponse for Question 25:\n\"This is a biliary drain placement procedure, which is explicitly excluded from abscess drainage\n,→procedures according to the defined criteria.\"\nResponse for Question 26:\n\"No paracentesis or thoracentesis was performed. The report describes an endoscopic gallstone\n,→lithotripsy with biliary drain placement, which is a different type of procedure.\"\nResponse for Question 27:\n\"This radiology report describes a biliary drain placement procedure, not a chest tube placement.\n,→The tube was placed in the biliary system, not the pleural space.\"\nResponse for Question 28:\n\"No pleurodesis procedure was performed. The report describes an endoscopic gallstone lithotripsy\n,→and biliary drain placement, with no mention of any pleural space intervention.\"\nResponse for Question 29:\n\"An internal/external biliary drain was explicitly placed during the procedure, with detailed\n,→documentation of drain type, size, and placement confirmation\"\nResponse for Question 30:\n\"The report describes a biliary intervention with biliary drain placement, which is not a\n,→genitourinary drain procedure. No nephrostomy tubes or nephroureteral stents were placed.\"\nResponse for Question 31:\n\"The report describes a biliary intervention with cholangioscopy and drain placement, but no\n,→enterostomy procedure was performed.\"\nResponse for Question 32:\n\"While a biliary drain was placed, this was not a specific cholecystostomy procedure. The\n,→intervention involved cholangioscopy, gallstone lithotripsy, and biliary drain placement, but\n,→did not meet the strict definition of a cholecystostomy.\"\nResponse for Question 33:\n\"This report describes a biliary intervention for gallstones, with no cyst or lymphocele procedure\n,→performed. The procedure involved cholangioscopy, gallstone lithotripsy, and biliary drain\n,→placement.\"\nResponse for Question 34:\n\"An internal/external biliary drain (nonvascular stent) was placed during the procedure,\n,→specifically a Cook 14 French biliary drain\"\nResponse for Question 35:\n\"No transplant organ was mentioned; this was a procedure on a native biliary system\"\nResponse for Question 36: False Positive\n\"No tumor ablation procedure was performed. The report details an endoscopic gallstone lithotripsy\n,→and biliary drain placement procedure.\"\n51\n"}, {"page": 52, "text": "Response for Question 37:\n\"No pain management procedure was performed. The report details a gallstone lithotripsy and biliary\n,→\nintervention without any specific pain management intervention.\"\nResponse for Question 38:\n\"The radiology report describes a biliary procedure involving gallstone lithotripsy and does not\n,→mention any Fallopian tube intervention.\"\nResponse for Question 39: False Negative\n\"The procedure involves biliary interventions, specifically biliary drainage and drain placement,\n,→which are explicitly excluded from qualifying as a nonvascular, invasive procedure.\"\n52\n"}]}