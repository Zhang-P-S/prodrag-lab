{"doc_id": "arxiv:2601.06645", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2601.06645.pdf", "meta": {"doc_id": "arxiv:2601.06645", "source": "arxiv", "arxiv_id": "2601.06645", "title": "A Multimodal Deep Learning Framework for Predicting ICU Deterioration: Integrating ECG Waveforms with Clinical Data and Clinician Benchmarking", "authors": ["Juan Miguel López Alcaraz", "Xicoténcatl López Moran", "Erick Dávila Zaragoza", "Claas Händel", "Richard Koebe", "Wilhelm Haverkamp", "Nils Strodthoff"], "published": "2026-01-10T18:11:12Z", "updated": "2026-01-10T18:11:12Z", "summary": "Artificial intelligence holds strong potential to support clinical decision making in intensive care units where timely and accurate risk assessment is critical. However, many existing models focus on isolated outcomes or limited data types, while clinicians integrate longitudinal history, real time physiology, and heterogeneous clinical information. To address this gap, we developed MDS ICU, a unified multimodal machine learning framework that fuses routinely collected data including demographics, biometrics, vital signs, laboratory values, ECG waveforms, surgical procedures, and medical device usage to provide continuous predictive support during ICU stays. Using 63001 samples from 27062 patients in MIMIC IV, we trained a deep learning architecture that combines structured state space S4 encoders for ECG waveforms with multilayer perceptron RealMLP encoders for tabular data to jointly predict 33 clinically relevant outcomes spanning mortality, organ dysfunction, medication needs, and acute deterioration. The model achieved strong discrimination with AUROCs of 0.90 for 24 hour mortality, 0.92 for sedative administration, 0.97 for invasive mechanical ventilation, and 0.93 for coagulation dysfunction. Calibration analysis showed close agreement between predicted and observed risks, with consistent gains from ECG waveform integration. Comparisons with clinicians and large language models showed that model predictions alone outperformed both, and that providing model outputs as decision support further improved their performance. These results demonstrate that multimodal AI can deliver clinically meaningful risk stratification across diverse ICU outcomes while augmenting rather than replacing clinical expertise, establishing a scalable foundation for precision critical care decision support.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2601.06645v1", "url_pdf": "https://arxiv.org/pdf/2601.06645.pdf", "meta_path": "data/raw/arxiv/meta/2601.06645.json", "sha256": "c4b72ab93a60c60173297855c1d84bab07e2a644c37c81ffd810fdfef0982d20", "status": "ok", "fetched_at": "2026-02-18T02:21:50.478953+00:00"}, "pages": [{"page": 1, "text": "A Multimodal Deep Learning Framework for Predicting ICU\nDeterioration: Integrating ECG Waveforms with Clinical Data\nand Clinician Benchmarking\nJuan Miguel L´opez Alcaraz1, Xicot´encatl L´opez Moran2, Erick D´avila Zaragoza3, Claas H¨andel4,\nRichard Koebe5, Wilhelm Haverkamp6, Nils Strodthoff1,*\n1AI4Health Division, Carl von Ossietzky Universit¨at Oldenburg, Oldenburg, Germany\n2CAPASITS, Secretariat of Health of the State of Colima, Tecom´an, M´exico\n3Department of Interventional Cardiology, Hospital Puerta de Hierro Colima, Colima, M´exico\n4Institute for Medical Informatics and Statistics, Kiel University and University Hospital Schleswig-Holstein,\nKiel, Germany\n5Department of Anesthesiology, Intensive Care Medicine, Emergency Medicine, and Pain Therapy, Carl von\nOssietzky Universit¨at & Klinikum Oldenburg, Oldenburg, Germany\n6Department of Cardiology, Angiology and Intensive Care Medicine, Charit´e Campus Mitte, German Heart\nCenter of the Charit´e-University Medicine Berlin, Berlin, Germany\nAbstract\nArtificial intelligence (AI) holds substantial promise for supporting clinical decision-making\nin intensive care units (ICUs), where timely and accurate risk assessment is essential. However,\nmany existing predictive models remain narrowly scoped, focusing on isolated outcomes or limited\ndata modalities, whereas clinicians routinely synthesize longitudinal clinical history, real-time\nphysiological signals, and heterogeneous diagnostic information when assessing patient risk. To\naddress this gap, we developed MDS-ICU, a unified multimodal machine learning framework that\nfuses routinely collected patient data—including demographics, biometrics, vital signs, laboratory\nvalues, ECG waveforms, surgical procedures, and medical device usage—to provide comprehensive\npredictive support throughout ICU stays. Using data from 63,001 samples across 27,062 patients\nin MIMIC-IV, we trained a deep learning architecture combining structured state-space (S4) en-\ncoders for ECG waveforms with multilayer perceptron (RealMLP) encoders for tabular features to\njointly predict 33 clinically relevant outcomes spanning mortality, organ dysfunction, medication\nrequirements, and acute deterioration events. The framework demonstrated strong discriminative\nperformance, achieving AUROCs of 0.90 for 24-hour mortality, 0.92 for sedative administration,\n0.97 for invasive mechanical ventilation, and 0.93 for coagulation dysfunction. Calibration analyses\nshowed close alignment between predicted probabilities and observed outcomes, with ECG wave-\nform inclusion yielding consistent improvements in both discrimination and predictive reliability.\nDirect comparison with clinicians and LLMs showed that model predictions alone outperformed\nclinicians’ judgment and LLM predictions. Furthermore, providing model outputs as augmented\ndecision support further increased predictive accuracy of both clinicians and LLMs. These results\ndemonstrate that multimodal AI frameworks can deliver continuous, clinically meaningful risk\nstratification across diverse ICU outcomes while empirically showing that AI augments—rather\nthan replaces—clinical expertise. This work establishes a scalable foundation for the integration of\nhigh-frequency physiological data into precision-oriented critical care decision support.\nIntroduction\nProspects of AI in the ICU Artificial intelligence (AI) is rapidly reshaping critical care medicine,\nparticularly in the intensive care unit (ICU), where timely and accurate decisions are essential [1].\nClinicians must continuously monitor complex physiological signals and respond to signs of deterioration,\noften under severe time pressure [2]. AI-driven systems have shown promise in enabling early detection\nof adverse events, improving triage, forecasting deterioration, and supporting diagnostic reasoning\n[3]. By leveraging large-scale clinical records and real-time physiological data, these models can help\n1\narXiv:2601.06645v1  [eess.SP]  10 Jan 2026\n"}, {"page": 2, "text": "mitigate the cognitive overload inherent to ICU environments [4]. Despite this potential, current clinical\nAI systems frequently remain limited in scope.\nNarrow scope of existing prediction models Most existing ICU models focus on a narrow set of\npredefined outcomes, rely on short prediction horizons that fail to reflect long-term patient trajectories\n[5], and underutilize rich multimodal clinical context [6].\nIn particular, continuous physiological\nwaveforms such as electrocardiograms (ECGs) are often excluded [7, 8], despite evidence that they\ncan outperform traditional clinical variables across prognostic and non-cardiovascular tasks [3]. These\nsignals provide high-resolution, real-time insight into patient physiology and are routinely collected as\npart of standard ICU monitoring [9], making their omission a notable limitation.\nLack of benchmarking datasets Progress is further constrained by the lack of high-quality, open-\naccess, multimodal ICU datasets. Widely used benchmarks [7, 8, 10] often lack waveform data, temporal\nstructure, or a diverse set of clinically meaningful prediction targets. Although recent efforts aggregate\nmultiple data sources across large databases [11, 12], they still fall short in modality integration, task\ndiversity, and representation of longitudinal patient trajectories. Crucially, most studies evaluate\nmodels exclusively against retrospective labels, without systematic comparison to clinician judgment or\nassessment of clinical significance [13]. As a result, strong predictive performance does not necessarily\ntranslate into actionable clinical value, limiting trust and deployment relevance.\nContributions In this work, we introduce a generalist multimodal decision-support system for ICU\ncare that integrates raw ECG waveforms with structured clinical data and explicitly benchmarks AI\npredictions against clinical judgment. Our contributions are threefold: (1) The construction and public\nrelease of a rich multimodal ICU dataset combining demographics, biometrics, vital sign and laboratory\ntrends, surgical procedures, medical device usage, and raw ECG waveforms, together with 33 clinically\nmeaningful deterioration targets spanning mortality, medication administration, organ dysfunction\n(Sepsis-3 SOFA), and acute clinical events. (2) A unified multimodal fusion framework that integrates\nhigh-frequency ECG waveforms with discrete clinical markers into a shared latent representation. This is\nachieved by combining statistical trend-based feature extraction for non-waveform time series, structured\nstate-space models for ECG waveforms, and an enhanced deep tabular encoder. The architecture\nsupports joint prediction across heterogeneous modalities, yielding high predictive performance (macro\nAUROC = 0.865) and strong calibration (Brier score = 0.0860).\nBy comparison, the unimodal\nnon-waveform model achieves 0.8583 AUROC and 0.0873 calibration, highlighting the added value\nof incorporating waveform information. (3) Clinician-centered benchmarks evaluating (i) clinician\nand LLM judgment versus model predictions where the proposed model outperforms both, and (ii)\nclinician/LLM judgment augmented with model outputs where on average, AI predictions increased the\nclinicians’ predictive by a Youden index increase of 12% and LLM performance by 16%, demonstrating\nthe model’s clinically meaningful benefit both alone and as augmented support. We envision this\nresource as both a clinically relevant benchmark and a foundation for reproducible research in ICU\ndecision support. We refer to this dataset and framework as MDS-ICU (Multimodal Decision Support\nin the ICU).\nResults\nApproach We developed MDS-ICU , a multimodal predictive framework for intensive care decision\nsupport that integrates 10-second 12-lead ECG waveforms with comprehensive tabular clinical data\nfrom the MIMIC-IV database. The dataset comprises 63,001 samples from 27,062 patients across\n33,590 ICU stays, with each sample containing raw ECG signals and 801 temporal features derived\nfrom demographics, vital signs, laboratory measurements, and procedural context. We trained models\nto predict 33 clinically relevant labels spanning four categories: mortality at multiple time horizons\n(ICU, hospital, and 1-365 days), organ dysfunction (Sepsis-3 criteria), medication administration within\n24 hours (13 drug classes), and acute clinical deterioration events (hypoxemia, mechanical ventilation,\ncardiac arrest, extracorporeal membrane oxygenation(ECMO)). Our approach employs S4 encoders\nfor ECG waveforms and RealMLP for tabular features with late fusion, evaluated using stratified\npatient-wise splits and macro-averaged AUROC as the primary metric. We further benchmarked model\npredictions against assessments by ICU clinicians on a subset of cases, both independently and with\nAI-augmented decision support. Figure 1 illustrates the MDS-ICU predictive workflow.\nDescriptive summary Table 1 provides descriptive statistics of the MDS-ICU dataset across major\nclinical feature groups, including demographics, biometrics, vital signs, laboratory values, surgical\n2\n"}, {"page": 3, "text": "Clinical and predictive workflow\nICU admission \nICU endpoint (discharge, death, etc.)\nObservation window \n(random start & length) \nECG waveforms \nPrediction horizon \n(task-dependent, irregularlar)\nBiometrics\nVital signs\nLaboratory values\nDemographics\nDeep-learning model\nMortality\nMedications\nOrgan dysfunction\nSupport devices\nSurgeries\nClinical deteriorations\nEvaluation protocols\nDiscrimination and calibration \n(AUROC, Brier)\nClinical benchmark 1\n(Sensitivity, Specificity)\nVS\nClinical benchmark 2\n(Sensitivity, Specificity)\n+\nFigure 1: Overview of the MDS-ICU clinical and predictive modeling workflow. For each 10-second,\n12-lead ECG recorded during an ICU stay, a corresponding observation window is constructed, spanning\nfrom ICU admission up to the ECG acquisition time. Within this observation window, multimodal\nclinical data, including demographics, vital signs, laboratory measurements, and biometrics, are\nextracted to form the feature set. These inputs feed into a unified model trained to perform a wide\nrange of prediction tasks, such as clinical deterioration, early warning scores, medication administrations,\ndischarge diagnoses, discharges, and mortalities. The dataset integrates and harmonizes structured\nclinical records and waveform data from MIMIC-IV, MIMIC-IV-ECG, and MIMIC-IV-ECG-ICD,\nenabling a comprehensive and temporally aligned view of each ICU episode. Rigorous preprocessing\nensures the clinical plausibility and quality of extracted features, establishing a robust foundation for\ntraining generalizable and clinically useful decision support systems.\ninterventions, mechanical ventilation, and ECG-derived features. The cohort shows a broadly uniform\nage distribution across quartiles (18–57, 57–68, 68–78, and 78–100 years, each contributing 24–26%),\nwith a predominance of male patients (60.22%). Ethnically, the population is mainly white (67.39%),\nfollowed by other (16.51%), black (10.02%), hispanic (3.43%), and asian (2.65%) groups. Biometrics\nindicate a median body mass index in the overweight range (27 kg/m2), while vital signs reflect typical\nICU-level cardiovascular, respiratory/ventilatory, neurological, and temperature profiles. Laboratory\n3\n"}, {"page": 4, "text": "Table 1: Descriptive statistics of the MDS-ICU dataset at the sample level. Continuous variables\nare summarized as median (interquartile range) with units, and categorical or binary variables are\nreported as counts and percentages. Feature groups include demographics, biometrics, vital signs\n(cardiovascular, respiratory/ventilation, neurological, temperature), laboratory values (hematology,\nelectrolytes/metabolic, renal/liver, other), surgeries, and mechanical ventilation. The ECG features are\nwaveform-derived features and are only for reference of the waveforms in-hand, they were not used as\ninput features in the model, all remaining features serve as input features for the model along with a\n10s ECG waveform.\nFeature Group\nStatistics\nDemographics\nAge (quantiles): 18–57: 26.34%, 57–68: 25.39%, 68–78: 24.30%, 78–100:\n23.98%\nGender: Male 60.22%, Female 39.77%\nEthnicity: White 67.39%, Other 16.51%, Black 10.02%, Hispanic 3.43%, Asian\n2.65%\nBiometrics\nHeight: 66 in (63–69), Weight: 169 lb (143–201), Body Mass Index: 27 kg/m2\n(23–31)\nVital Signs\nCardiovascular: Systolic Blood Pressure 114 mmHg (101–130), Diastolic\nBlood Pressure 58 mmHg (51–67), Mean Arterial Pressure 8.5 kPa (7–11) ,\nCentral Venous Pressure 11 mmHg (8–15), Heart Rate 84 bpm (72–99), Non-\ninvasive Systolic Blood Pressure 115 mmHg (101–132), Non-invasive Diastolic\nBlood Pressure 63 mmHg (53–74)\nRespiratory and Ventilation: Respiratory Rate 19 breaths/min (16–23),\nTidal Volume 473 mL (400–545), Minute Volume 8.4 L/min (7.1–10.4), Positive\nEnd-Expiratory Pressure 5 cmH2O (5–5), Peak Inspiratory Pressure 19 cmH2O\n(13–24), Inspired Oxygen Fraction 50% (40–60), Oxygen Flow 3 L/min (2–10),\nOxygen Saturation 98% (95–100), Apnea Interval 20 s (20–20)\nNeurological and Consciousness: Glasgow Coma Scale Eye Spontaneously 0\n(Spontaneously 0–To Speech 1), Glasgow Coma Scale Motor Obeys Commands\n0 (Obeys Commands 0–Localizes Pain 1), Glasgow Coma Scale Verbal Confused\n1 (Oriented 0–No Response-ETT 5), Level of Consciousness Alert 0 (Alert\n0–Arouse to Stimulation 3), Goal Richmond Agitation-Sedation Scale Alert and\ncalm 0 (Alert and calm 0–Awakens to voice 1), Richmond Agitation-Sedation\nScale Alert and calm 4 (Alert and calm 4–Light sedation 6)\nTemperature: Temperature 98.3 °F (97.7–98.9)\nLaboratory Values\nHematology: White Blood Cells 10.9 x103/µL (8–15), Red Blood Cells 3.36\nx106/µL (2.91–3.86), Hemoglobin 10.0 g/dL (8.7–11.5), Hematocrit 30.4%\n(26.7–34.7), Platelet Count 183 x103/µL (129–252), Basophils 0.02 x103/µL\n(0–0.04), Eosinophils 0.6 x103/µL (0.1–1.6), Lymphocytes 10.0% (5.6–16.4),\nNeutrophils 81.0% (73.8–87)\nElectrolytes and Metabolic: Sodium 139 mmol/L (136–142), Potassium\n4.1 mmol/L (3.8–4.5), Chloride 104 mmol/L (99–108), Calcium 8.4 mg/dL\n(7.9–8.9), Ionized Calcium 1.13 mmol/L (1.08–1.18), Magnesium 2.1 mg/dL\n(1.9–2.3), Phosphate 3.5 mg/dL (2.8–4.3), Bicarbonate 24 mmol/L (21–27)\nRenal and Liver: Creatinine 1.1 mg/dL (0.8–1.8), Blood Urea Nitrogen\n23 mg/dL (15–40), Bilirubin Total 0.7 mg/dL (0.4–1.3), Bilirubin Direct 1.7\nmg/dL (0.6–4.5), Albumin 3.0 g/dL (2.5–3.4), Alkaline Phosphatase 87 U/L\n(63–132), Alanine Aminotransferase 30 U/L (17–67)\nOther: C-Reactive Protein 93.7 mg/L (36.7–179.9), Troponin T 0.1 ng/mL\n(0.01–0.57), Carbon Dioxide Production 188 mL/min (154–232), End-Tidal\nCarbon Dioxide 35 mmHg (30–40), pH 7.37 (7.3–7.43), Oxygen Saturation 94%\n(74–97)\nSurgeries\nCardiac 12,100 (19.21%), General 5,260 (8.35%), Neurosurgery 3,547 (5.63%),\nVascular 1,467 (2.33%), Thoracic 1,079 (1.71%), Plastic 116 (0.18%)\nMechanical Ventilation\nInvasive 33,989 (53.95%), Non-invasive 2,758 (4.38%)\nECG Features\nQRS Duration 96 ms (86–113), P-wave Duration 104 ms (72–120), RR Interval\n740 ms (612–882), JT Interval 288 ms (254–322), P Axis 60° (40–86), QRS\nAxis 13° (–18–48), T Axis 48° (11–84)\n4\n"}, {"page": 5, "text": "measurements span hematological, metabolic, renal, hepatic, and inflammatory markers, capturing\nwide interquartile ranges consistent with acute critical illness. Procedural data reveal that cardiac and\ngeneral surgeries were the most frequent, over half of the samples involved invasive mechanical ventila-\ntion, and ECG waveform-derived features exhibit physiologically plausible distributions. Collectively,\nthese statistics highlight the clinical heterogeneity and demographic diversity of the ICU population\nrepresented in the MDS-ICU dataset.\nPredictive performance\nTable 2: Comparative predictive performance (AUROC). Predictive performance of the multimodal\nfusion architecture integrating ECG waveforms and routine clinical data compared with a clinical-\ndata-only baseline across 33 ICU outcomes spanning mortality, medication administration, clinical\ndeterioration, and organ dysfunction. Outcome counts and prevalence are reported in parentheses.\nThe best-performing model is highlighted in bold and underlined; when the alternative model is not\nstatistically significantly worse, it is also shown in bold. Rows where only the multimodal model is\nhighlighted indicate prediction tasks where the integration of ECG waveforms provides a significant\nperformance advantage. Exemplary tasks considered for the clinical benchmark are marked with an\nasterisk.\nPrediction target\nMultimodal\nUnimodal\n(counts, prevalence)\n(ECG+routine data)\n(routine data)\nS4+RealMLP\nRealMLP\nMortality (different horizons)\nICU mortality (7,028; 11.16%)\n0.8809\n0.8459\nStay mortality (9,443; 14.99%)∗\n0.8561\n0.8356\n1-day mortality (1,822; 2.89%)\n0.9009\n0.8932\n2-day mortality (2,744; 4.36%)\n0.8834\n0.8809\n7-day mortality (5,968; 9.47%)\n0.8645\n0.8416\n28-day mortality (11,128; 17.66%)\n0.8609\n0.8349\n90-day mortality (15,097; 23.96%)\n0.8495\n0.8237\n180-day mortality (17,681; 28.06%)\n0.8393\n0.8166\n1-year mortality (20,752; 32.94%)\n0.8320\n0.8109\nMedications (administration within the next 24 hours)\nCrystalloids (57,752; 91.67%)\n0.8811\n0.8883\nElectrolytes (33,568; 53.28%)\n0.8017\n0.8101\nAntibiotics (37,136; 58.95%)\n0.8570\n0.8562\nVasopressors (21,012; 33.35%)∗\n0.8854\n0.8781\nInotropes (5,746; 9.12%)\n0.8732\n0.8738\nAntiarrhythmics (6,663; 10.58%)\n0.7909\n0.7434\nAnticoagulants / Antiplatelets (28,825; 45.75%)\n0.7954\n0.7903\nSedatives (26,562; 42.16%)\n0.9182\n0.9149\nAnalgesics (31,672; 50.27%)\n0.8683\n0.8583\nNeuromuscular blockers (2,995; 4.75%)\n0.8889\n0.8831\nGI protection (21,096; 33.49%)\n0.7160\n0.7060\nBlood products / Transfusions (9,205; 14.61%)\n0.8995\n0.9007\nParenteral nutrition (1,370; 2.17%)\n0.8780\n0.8402\nClinical Deterioration (adverse events within the next 24 hours)\nSevere hypoxemia (4,343; 6.89%)\n0.7585\n0.6653\nECMO (1,369; 2.17%)\n0.8486\n0.8740\nInvasive mechanical ventilation (27,257; 43.26%) ∗\n0.9722\n0.9701\nNon-invasive mechanical ventilation (1,348; 2.14%)\n0.9712\n0.9525\nCardiac arrest (204; 0.32%)\n0.9175\n0.8101\nOrgan dysfunction (SOFA subscore ≥2 within the next 24 hours)\nRespiratory (22,129; 85.33%)\n0.7381\n0.7325\nNervous system (28,824; 47.45%)\n0.9346\n0.9351\nCardiovascular (13,729; 21.79%)\n0.8716\n0.8628\nLiver (5,144; 8.16%)\n0.9324\n0.9362\nCoagulation (8,903; 14.13%)\n0.9325\n0.9224\nKidneys (20,978; 33.30%) ∗\n0.8457\n0.8477\nMacro average\n0.8650\n0.8583\nTable 2 summarizes predictive performance across 33 ICU outcomes and identifies tasks for which\nintegrating ECG waveforms provides a statistically significant advantage. Notably, there are no outcomes\nwhere the clinical tabular model is uniquely superior, as indicated by the absence of rows where only\n5\n"}, {"page": 6, "text": "Figure 2: Calibration plots for a subset of representative labels, one per category: mortality (within\nstay), invasive mechanical ventilation (clinical deterioration), vasopressors (medications), and SOFA\nkidney (organ dysfunction). Probabilities were calibrated using isotonic regression on the validation set.\nBoth models are overall well-calibrated, with S4+RealMLP showing improved alignment with observed\noutcomes, particularly in the higher probability ranges. Calibration was computed using a quantile\nstrategy with 10 bins.\nthe unimodal model is highlighted. Instead, ECG waveform integration yields significant improvements\nin 14 of 33 outcomes, spanning mortality, medication administration, clinical deterioration, and organ\ndysfunction, and results in a significantly higher macro-average AUROC. Appendix A presents additional\nresults for a tree-based model as an alternative to the tabular-only model. This baseline achieves a\nlower macro-average AUROC (0.8460) compared to the RealMLP model, highlighting the superior\nperformance of deep learning approaches over traditional tabular methods, in line with findings in [14].\nPerformance gains are most evident for outcomes linked to acute physiological instability and cardiovas-\ncular dynamics. For mortality prediction, ECG-augmented models outperform tabular models for ICU\nmortality, stay mortality, and intermediate-term horizons (7–28 days), suggesting that short-term elec-\ntrical signals provide prognostic information beyond static clinical variables. In medication prediction,\nwaveform features significantly improve discrimination for antiarrhythmics, vasopressors, sedatives,\nanalgesics, and parenteral nutrition—therapies typically initiated in response to evolving hemodynamic\nor electrophysiological changes.\nThe largest and most consistent benefits are observed in clinical deterioration tasks, where ECG\nwaveforms substantially enhance prediction of severe hypoxemia, invasive and non-invasive mechanical\nventilation, and cardiac arrest, reflecting their ability to capture early decompensation not evident in\nroutine charted data. For organ dysfunction, waveform integration significantly improves prediction of\ncardiovascular and coagulation dysfunction, while remaining comparable for respiratory, neurological,\nhepatic, and renal outcomes. Overall, the improved macro-average AUROC indicates that multimodal\n6\n"}, {"page": 7, "text": "Figure 3: Clinical benchmark plots for a subset of representative labels, one per category: mortality\n(within stay), invasive mechanical ventilation (clinical deterioration), vasopressors (medications), and\nSOFA kidney (organ dysfunction). Each plot contains the the main investigated model (S4+RealMLP)\nAUROC, as well as sensitivity and specificity of clinicians, GPT, and Claude for both benchmark A\n(clinician/LLM alone) and B (clinician/LLM+model).\nintegration provides a consistent benefit without degrading performance on any task.\nCalibration\nFigure 2 shows that both S4+RealMLP and tabular-only RealMLP produce generally well-calibrated\npredictions across diverse clinical outcomes. Incorporating ECG waveforms (S4) leads to a measurable\nimprovement: for mortality during the stay, the Brier score decreased from 0.084 to 0.078; for invasive\nmechanical ventilation, remained in 0.052; for vasopressors, remained in 0.128; and for SOFA kidney,\nfrom 0.129 to 0.128. This indicates that S4+RealMLP better aligns predicted probabilities with observed\nevent frequencies, particularly in the higher probability ranges, reducing over- or underestimation. These\nresults highlight that adding waveform-derived features improves not only discriminative performance\nbut also the reliability of probabilistic predictions, which is crucial for informed clinical decision-making.\nSee Appendix B for a complete set of figures across all investigated labels.\nClinical benchmark\nSetup To evaluate the added clinical value of our model, we selected a random subset of 20 test\nsamples and shared them with 4 clinicians with relevant ICU expertise. For this benchmark, we focused\non four key prediction targets, one from each category: stay mortality, vasopressors administration,\ninvasive mechanical ventilation, and kidney dysfunction. In Benchmark A, clinicians were tasked to\n7\n"}, {"page": 8, "text": "solve the four prediction tasks using the same information that was provided to the multimodal model.\nIn Benchmark B, they were provided model predicted probabilities in order to refine their predictions.\nTogether, these two benchmarks provide a structured, reproducible assessment of the added value of\nmultimodal AI predictions in ICU decision support. In addition, we include two proprietary LLMs\n(GPT 5.2 and Claude Sonnet 4.5) receiving only the clinical features as input. In order to avoid to\nspecify a threshold when comparing continuous model predictions to binary clinicians’ predictions and\nbaselines, we plot these predictions along with the model’s ROC curve, see Figure 3.\nBenchmark A: Model vs. clinicians Across the four tasks, clinicians exceed the model’s ROC\nperformance in 12.5% of the cases, perform comparably in 31.25%, and underperform in 56.25% of the\ncases, reflecting notable variability in their performance. LLMs exceed the model in 12.5% of cases, are\non par in 25%, and underperform in 62.5%, see Appendix C for details. These results indicate that, on\naverage, the model outperforms both clinicians and LLMs for the considered tasks.\nBenchmark B: Model-assisted decision-making The inclusion of the model predictions lead to\nnotable improvement in model performance. Clinicians outperform the model in 37% of the cases,\nperform on par in about 31% of the cases and underperform only in about 31% of the cases. Similarly,\nthe augmented LLMs outperform in 37.5% of the cases, perform on par in 25% and underperform i\n37.5% of the cases. Beyond summary statistics, we consider differences in the Youden index (sensitivity\n+ specificity – 1) to quantify improvement for each decision maker. Across all tasks, clinicians’ indices\nincreased on average by 12% when assisted by the model, while LLMs show a larger improvement of\n16%, see Appendix C for details. Overall, the model predictions enhance both clinicians and LLMs\nperformance, by providing the greatest benefit to LLM-based decision-making for treatment-related\ntasks, while still offering substantial added value to clinicians on outcomes-related tasks.\nDiscussion\nClinical significance Table 2 suggests that ECG waveforms provide complementary and clinically\nmeaningful information beyond routine ICU data. The improvements in short- and medium-term\nmortality indicate that waveform dynamics capture acute physiological instability not fully reflected\nin standard clinical variables. Enhanced prediction of medications such as antiarrhythmics, sedatives,\nanalgesics, vasopressors, and parenteral nutrition highlights the close coupling between cardiac electro-\nphysiology and treatment intensity; in particular, these findings align with prior work demonstrating\nthat ECG-based models can identify arrhythmic risk and guide antiarrhythmic therapy [15, 16]. ECG\nalso improved detection of severe hypoxemia and cardiac arrest, emphasizing their sensitivity to acute\nphysiological collapse. These results are consistent with evidence that hypoxemia induces detectable\nchanges in heart rate variability, conduction, and repolarization [17, 18], and that early electrical\ninstability precedes cardiac arrest [19, 20]. For organ dysfunction, waveform data were particularly infor-\nmative for cardiovascular and coagulation outcomes, whereas other organ systems remained adequately\nmodeled by clinical variables. Overall, integrating ECG waveforms into ICU decision support models\ncould enhance early risk stratification, guide treatment prioritization [21], and improve monitoring of\nhigh-risk patients for deterioration events.\nCalibration Figure 2 illustrates that both S4+RealMLP and tabular-only RealMLP provide reasonably\nwell-calibrated probability estimates across different clinical outcomes. Incorporating ECG waveforms\n(S4) generally improves calibration, particularly for higher predicted probabilities, reducing over-\nor underestimation of risk. This effect is most notable for ICU mortality and invasive mechanical\nventilation, reflecting the additional signal captured by ECG features.\nBrier scores confirm this\ntrend, with consistently lower values for the S4+RealMLP model. These results demonstrate that\nwaveform-informed models not only improve discriminative performance but also provide more reliable\nprobabilistic predictions, enhancing clinician trust and their utility for clinical decision support.\nClinical benchmark The clinical benchmark reflected in Figure 3 demonstrates that clinicians and\nLLMs on average underperform compared to the proposed model. However, when both of them have\naccess to the model’s predictions, their performance improves consistently, achieving higher sensitivity\nand specificity across diverse tasks. This suggests that while the model provides strong standalone\npredictive power, its greatest value lies in supporting clinicians, enhancing their decision-making. The\nclinicians leveraging model predictions outperform/underperform the model in 37.5%/31.25% of the\ncases, respectively. If substantiated in larger user studies this would be an example of the most desirable\naugmentation scenario, where the augmented clinicians’ performance exceeds the model performance\n8\n"}, {"page": 9, "text": "[22]. At this point, one has to note that some tasks like medication administration prediction or the\nmechanical ventilation prediction represent therapy decisions and not predictions of the natural course\nof the patient trajectory, and might be affected by different clinical preferences.\nLimitations While our dataset and methodology offer a significant step forward in multimodal ICU\nprediction, some limitations remain. Although our internal evaluation demonstrates strong performance,\nexternal validation could not be conducted due to the lack of publicly available datasets with comparable\nmultimodal characteristics, particularly those including raw waveforms. We remain eager to apply our\nmethods to external datasets as soon as suitable resources, even from private domains, become accessible.\nThe set of input features is already very comprehensive, but does not cover current medication. While it\nwas left out intentionally to avoid the complexity of different drugs and different dosages, it represents\nan important piece of information, which would typically be taken into account by an ICU clinician\nto assess a patient’s state. The inclusion of medications as input features is a promising direction for\nfuture work.\nFuture work Future directions include the exploration of alternative tabular encoders and more\nsophisticated multimodal fusion strategies to better capture dependencies across data types. We\nalso aim to investigate dynamic temporal modeling approaches that can handle irregularly sampled\ndata natively, potentially reducing reliance on discrete sampling that often involves imputation and\ninterval hyperparameter choice. Similarly, the inclusion of other waveforms and waveforms trends via\nembeddings.\nTo achieve real clinical impact and successful deployment, AI systems like the proposed must overcome\ncritical barriers [23] including clinical integration challenges such as workflow adaptation and clinician\ntrust, rigorous clinical validation ideally via randomized controlled trials, and regulatory frameworks\nthat balance safety with innovation. Similarly, practical implementation also involves addressing\ndata sharing and privacy and algorithm transparency [24]. Effectively navigating these multifaceted\nchallenges is essential for integrating AI into existing clinical workflows and meeting regulatory demands\nacross diverse healthcare settings. In this context, foundational ECG models [25] provide a promising\navenue, as pretrained ECG representations can enhance both discriminative performance and calibration\nacross multiple clinical tasks.\nEnhancing explainability before clinical adoption is an essential step to increase clinician trust and\nfacilitate safe implementation in practice. Currently, methods such as those proposed in [26] provide\ncausal explanations for unimodal time series data, but have not been extended towards multimodal\nscenarios.\nMethods\nPredictive workflow and dataset creation\nFor each ECG recorded during an ICU stay, a single observation window is extracted from ICU\nadmission up to the ECG timestamp, during which clinical features are collected. These inputs are\nused to train a unified model capable of addressing a broad set of clinically meaningful prediction\ntasks spanning the ICU stay and subsequent outcomes. The MDS-ICU dataset integrates data from\nMIMIC-IV [27], MIMIC-IV-ECG [28], and MIMIC-IV-ECG-ICD [29], focusing on ICU patients with at\nleast one 10-second 12-lead ECG. ECG waveforms are included due to prior evidence demonstrating\ntheir statistically significant added value for related clinical prediction tasks [3]. Data preprocessing\ninvolves rigorous feature cleaning, including outlier removal and correction of implausible values. The\nuse of MIMIC is motivated by its breadth of patient populations and data modalities, providing a robust\nfoundation for developing and benchmarking ICU decision-support systems. We highlight differences to\nexisting ICU datasets and benchmarking frameworks in terms of source databases, populations, size,\nfeatures, tasks, and open source availability in Appendix E.\nFeature extraction\nWe extracted a comprehensive set of clinical features aligned with each 10-second, 12-lead ECG to\nprovide contextual information for predictive modeling. Each sample includes the raw ECG waveform\ncapturing high-resolution cardiac electrical activity at the time of prediction, alongside demographic\nattributes (age, gender, ethnicity), biometric measurements (height, weight, body mass index), and\n9\n"}, {"page": 10, "text": "vital signs summarized up to the ECG acquisition time. Vital signs span cardiovascular, respiratory,\nneurological, thermal, and oxygenation systems and reflect continuously monitored ICU physiology.\nLaboratory measurements provide quantitative insight into systemic physiology and organ function and\ninclude hematological, metabolic, electrolyte, inflammatory, perfusion, and cardiac markers, selected\nbased on clinical relevance following [30] to avoid label-driven bias. We further incorporate procedural\ncontext, including surgical interventions during the ICU stay or within the preceding 24 hours, as well\nas the use of supporting devices such as invasive and non-invasive mechanical ventilation within the\npatient context window.\nTo model temporal dependencies in irregularly sampled vital signs and laboratory data, we apply\na statistical feature extraction approach that aggregates descriptive statistics over the observation\nwindow. Features include the minimum, maximum, first and last values, and the time elapsed since\nthe last observation. In addition, we compute a secondary time series from first-order differences and\napply the same summarization to capture temporal variation. This dual-level encoding represents both\nabsolute trends and dynamic changes, yielding a compact and expressive feature set well suited for\ntemporal tabular clinical prediction models.\nPrediction tasks\nPrediction tasks are grouped into four clinically relevant categories: mortalities, medications, clinical\ndeterioration and organ dysfunction, covering both short- and long-term ICU decision-support needs.\nMortality is predicted during the ICU and hospital stay at irregular intervals, as well as at fixed horizons\nof 1, 2, 7, 28, 90, 180, and 365 days from the prediction time. Medication prediction is formulated\nas binary classification of drug class administration within the next 24 hours, including crystalloids,\nelectrolytes, antibiotics, vasopressors, inotropes, antiarrhythmics, anticoagulants/antiplatelets, sedatives,\nanalgesics, neuromuscular blockers, gastrointestinal protection agents, blood products, and parenteral\nnutrition. Clinical deterioration targets acute adverse events within 24 hours, including severe hypoxemia,\nmechanical ventilation, in-hospital cardiac arrest, and extracorporeal membrane oxygenation (ECMO)\ninitiation, supporting timely intervention and resource planning. Organ dysfunction is assessed via early\nwarning score prediction, specifically Sepsis-3 [31] defined by SOFA ≥2 [32], over a 24-hour window to\nenable proactive risk stratification. Definitions for all prediction targets can be found in Appendix D.\nThe final dataset consists of 33 labels across 63,001 samples from 27,062 patients across 33,590 ICU\nstays. Each input includes a single 10-second ECG waveform along with 801 tabular features.\nModel architectures\nS4\nBlock\nPooling Head\nS4\nBlock\nS4\nBlock\nS4\nBlock\nS4Block\nS4Layer\nDropout\nGeLU\nTranspLinear\n+\nLayerNorm\nLayerNorm\nLayerNorm\nLayerNorm\n+\n+\n+\nRobust Scaling + Smooth Clip \nLearnable Scaling Layer\nNTPLinear\nNTPLinear\nNTPLinear\n(zero init)\nSELU\nSELU\nConcat Head\nOutput\nFigure 4: Overview of the multimodal architecture. The data flow proceeds from left to right. The top\nbranch shows the time-series encoder based on structured state space models (S4), consisting of four\nS4 blocks followed by a pooling head. The bottom branch depicts the tabular encoder implemented\nusing RealMLP, which applies robust quantile-based feature scaling, learnable feature re-scaling, and a\nstack of scaled linear layers (NTPLinear) with SELU activations. The outputs of both encoders are\nconcatenated to form a joint multimodal representation used for prediction.\nWe adopt a multimodal learning setup that combines ECG waveforms and clinical tabular features.\nECG waveforms are processed using an S4-based encoder built on structured state space models [33],\nwhich has demonstrated superior performance over conventional deep learning architectures such as\n10\n"}, {"page": 11, "text": "CNNs, RNNs, and transformers in physiological time-series modeling [29, 34]. The encoder consists\nof four stacked S4 blocks, each comprising an S4 layer, dropout, a GeLU activation function, and a\ntransposed linear layer, with normalization layers applied between blocks. A pooling head is used\nto obtain a fixed-dimensional representation. Tabular clinical features are encoded using RealMLP\n[35], an improved multilayer perceptron architecture that has been shown to perform competitively\nwith state-of-the-art tree-based methods on tabular benchmarks [14]. The RealMLP encoder applies a\nrobust quantile-based scaling with smooth value clipping, followed by a learnable feature-scaling layer\nand three scaled linear layers (NTPLinear) with SELU activation functions. We employ a late fusion\nstrategy by concatenating the representations produced by the two encoders to form a joint multimodal\nrepresentation used for prediction. To assess the contribution of waveform data, we benchmark both the\nmultimodal model and a tabular-only variant. Additionally, we report further tabular-only baselines\nusing a tree-based model (XGBoost) in the appendix.\nTraining and evaluation\nWe adopt stratified patient-wise data splits to ensure balanced representation across key clinical factors\nsuch as gender, age groups, and discharge diagnoses. Specifically, we divide the dataset into 20 stratified\nfolds, allocating them to training, validation, and testing sets using a ratio of 18:1:1. The stratified folds\nare in line with the protocol from [29]. We apply median imputation based on training set statistics\nto handle missing data and introduce binary indicator columns to flag imputed values, following the\nprotocol outlined in [29], in line with best practices from the literature [36].\nWe use AdamW [37] as the optimizer with a learning rate of 0.001 and weight decay of 0.001, maintaining\na constant learning rate schedule. Training is performed with a batch size of 64 for 20 epochs. Overfitting\nis controlled by selecting the best model based on validation performance. We minimize binary cross-\nentropy loss. Model performance is evaluated using macro average AUROC across all labels, and 95%\nconfidence intervals for AUROC are estimated using empirical bootstrap with 1000 iterations. The\nprimary evaluation metric is macro AUROC, as it best reflects a model’s discriminative power without\nrequiring predefined decision thresholds, also in the presence of label imbalance [38]. We assess the\nstatistical significance of performance differences between two models by bootstrapping the performance\ndifference between two models. The difference is considered statistically significant if the confidence\ninterval does not cover the zero.\nClininical benchmark\nClinicians’ benchmark For Benchmark A, clinicians received a single PDF file per patient sample\ncontaining all tabular features and a 12-lead ECG plot, and were asked to provide binary predictions\nfor each of the four prediction targets. This allowed direct comparison between clinician judgment and\nmodel predictions. For Benchmark B, clinicians were given the same samples along with the model’s\npredicted probabilities, allowing them to revise their predictions based on the model output. This\nbenchmark evaluated whether providing AI support improved clinician decision-making.\nLLM baselines We also assess the ability of proprietary LLMs to solve the four benchmarking tasks.\nFor simplicity, we resorted to text-only LLMs, i.e. presented only the clinical data but not the ECG\nwaveform. We used GPT 5.2 and Claude Sonnet 4.5 for this experiment. See Appendix 6 for the\nspecific prompt that was used to generate these both benchmarks.\nStudy protocol and reporting standards\nThis study follows a comprehensive protocol aligned with established guidelines such as the Transparent\nReporting of a Multivariable Prediction Model for Individual Prognosis or Diagnosis (TRIPOD).\nDetailed documentation is provided in the supplementary material.\nData Availability\nThe datasets generated and/or analysed during this study are available from the publicly accessible\nMIMIC-IV, MIMIC-IV-ECG, and MIMIC-IV-ECG-ICD repositories, subject to the respective data use\nagreements. All preprocessing steps and code required to generate the dataset used in this study are\nprovided in our open-access repository: https://github.com/AI4HealthUOL/MDS-ICU.\n11\n"}, {"page": 12, "text": "Code Availability\nAll custom code used to generate the results reported in this manuscript, including preprocessing, feature\nextraction, and model training, is available in our repository: https://github.com/AI4HealthUOL/\nMDS-ICU. This code is sufficient to reproduce the analyses presented, and no restrictions apply beyond\nthose specified by the underlying MIMIC-IV datasets.\nFunding\nThis work received no funding.\nAuthor information\nJuan Miguel Lopez Alcaraz is the sole first author. Nils Strodthoff is the sole senior author.\nAuthor contributions\nConceptualization: JMLA, NS Methodology: JMLA, NS Software: JMLA, NS Validation:\nJMLA, XLM, EDZ, CH, WH, RK Formal analysis: JMLA Investigation: JMLA, XLM, EDZ, CH,\nWH, RK Resources: NS Data curation: JMLA Writing – Original Draft: JMLA, NS Writing –\nReview & Editing: JMLA, NS, XLM, EDZ, CH, RK, WH Visualization: JMLA Supervision: NS\nProject administration: JMLA, NS\nCorresponding author\nCorrespondence should be addressed to nils.strodthoff@uol.de. ORCID 0000-0003-4447-0162.\nEthics declaration\nEthics approval\nThe datasets used in this study are publicly available, de-identified, and have previously received ethical\napproval by their respective institutions. No additional ethical approval was required for this secondary\ndata analysis.\nCompeting interests\nAll authors declare no financial or non-financial competing interests.\n12\n"}, {"page": 13, "text": "References\n1.\nVan de Sande, D., van Genderen, M. E., Huiskens, J., Gommers, D. & van Bommel, J. Moving\nfrom bytes to bedside: a systematic review on the use of artificial intelligence in the intensive care\nunit. Intensive care medicine 47. doi: 10.1007/s00134-021-06446-7, 750–760 (2021).\n2.\nBlythe, R. et al. Clinician perspectives and recommendations regarding design of clinical prediction\nmodels for deteriorating patients in acute care. BMC Medical Informatics and Decision Making\n24. doi: 10.1186/s12911-024-02647-4, 241 (2024).\n3.\nAlcaraz, J. M. L., Bouma, H. & Strodthoff, N. Enhancing clinical decision support with physiological\nwaveforms—A multimodal benchmark in emergency care. Computers in Biology and Medicine\n192. doi: 10.1016/j.compbiomed.2025.110196, 110196. arXiv: 2407.17856 [cs.LG] (2025).\n4.\nGholami, B., Haddad, W. M. & Bailey, J. M. AI in the ICU: In the intensive care unit, artificial\nintelligence can keep watch. IEEE Spectrum 55. doi: 10.1109/MSPEC.2018.8482421, 31–35\n(2018).\n5.\nAllam, A., Feuerriegel, S., Rebhan, M. & Krauthammer, M. Analyzing patient trajectories with\nartificial intelligence. Journal of medical internet research 23. doi: 10.2196/29812, e29812 (2021).\n6.\nAcosta, J. N., Falcone, G. J., Rajpurkar, P. & Topol, E. J. Multimodal biomedical AI. Nature\nmedicine 28. doi: 10.1038/s41591-022-01981-2, 1773–1784 (2022).\n7.\nWornow, M., Thapa, R., Steinberg, E., Fries, J. & Shah, N. Ehrshot: An ehr benchmark for\nfew-shot evaluation of foundation models. Advances in Neural Information Processing Systems 36.\ndoi: 10.1038/s41591-022-01981-2 (2024).\n8.\nY`eche, H. et al. HiRID-ICU-Benchmark–A Comprehensive Machine Learning Benchmark on\nHigh-resolution ICU Data. arXiv preprint arXiv:2111.08536. doi: https://doi.org/10.48550/\narXiv.2111.08536 (2021).\n9.\nGoldstein, B. Intensive care unit ECG monitoring. Cardiac Electrophysiology Review 1. doi:\n10.1023/A:1009944301690, 308–310 (1997).\n10.\nSheikhalishahi, S., Balaraman, V. & Osmani, V. Benchmarking machine learning models on\nmulti-centre eICU critical care dataset. Plos one 15. doi: 10.1371/journal.pone.0235424,\ne0235424 (2020).\n11.\nVan de Water, R. et al. Yet Another ICU Benchmark: A Flexible Multi-Center Framework for\nClinical ML in The Twelfth International Conference on Learning Representations (2024).\n12.\nGupta, M. et al. An extensive data processing pipeline for mimic-iv in Machine Learning for\nHealth (2022), 311–325.\n13.\nBinuya, M., Engelhardt, E., Schats, W., Schmidt, M. & Steyerberg, E. Methodological guidance\nfor the evaluation and updating of clinical prediction models: a systematic review. BMC Medical\nResearch Methodology 22. doi: 10.1186/s12874-022-01801-8, 316 (2022).\n14.\nErickson, N. et al. Tabarena: A living benchmark for machine learning on tabular data. arXiv\npreprint arXiv:2506.16791. doi: https://doi.org/10.48550/arXiv.2506.16791 (2025).\n15.\nAyyub, A., Politis, C. & Usman, M. A. A comprehensive review of AI-Based detection of\nArrhythmia using Electrocardiogram (ECG). Computers in Biology and Medicine 196. doi:\n10.1016/j.compbiomed.2025.110594, 110594 (2025).\n16.\nSiontis, K. C., Noseworthy, P. A., Attia, Z. I. & Friedman, P. A. Artificial intelligence–enabled\nelectrocardiography for risk stratification of arrhythmias. European Heart Journal 42. doi: 10.\n1016/S2589-7500(24)00172-9, 4214–4224 (2021).\n17.\nBuchner, N. J., Sanner, B. M., Borgel, J. & Rump, L. C. Heart rate variability in hypoxemia.\nChest 121, 436–441 (2002).\n18.\nSomers, V. K., Mark, A. L. & Abboud, F. M. Sympathetic neural mechanisms in hypoxia and\nhypercapnia. The Journal of Clinical Investigation 83, 301–309 (1989).\n19.\nAttia, Z. I. et al. An artificial intelligence-enabled ECG algorithm for the identification of patients\nwith left ventricular systolic dysfunction. The Lancet 394, 861–867 (2019).\n13\n"}, {"page": 14, "text": "20.\nAhmad, S., Tejuja, A., Newman, K. D., Zarychanski, R. & Seely, A. J. Continuous electrocardio-\ngraphic monitoring improves prediction of in-hospital cardiac arrest. Resuscitation 113, 72–78\n(2017).\n21.\nKoebe, R., Saibel, N., Alcaraz, J. M. L., Sch¨afer, S. & Strodthoff, N. Towards actionable hypotension\nprediction–predicting catecholamine therapy initiation in the intensive care unit. arXiv preprint\narXiv:2510.24287. doi: https://doi.org/10.48550/arXiv.2510.24287 (2025).\n22.\nVaccaro, M., Almaatouq, A. & Malone, T. When combinations of humans and AI are useful: A\nsystematic review and meta-analysis. Nature Human Behaviour 8, 2293–2303 (2024).\n23.\nKelly, C. J., Karthikesalingam, A., Suleyman, M., Corrado, G. & King, D. Key challenges for\ndelivering clinical impact with artificial intelligence. BMC medicine 17. doi: 10.1186/s12916-\n019-1426-2, 1–9 (2019).\n24.\nHe, J. et al. The practical implementation of artificial intelligence technologies in medicine. Nature\nmedicine 25. doi: 10.1038/s41591-018-0307-0, 30–36 (2019).\n25.\nAl-Masud, M., Alcaraz, J. M. L. & Strodthoff, N. Benchmarking ECG Foundational Models: A\nReality Check Across Clinical Tasks. arXiv preprint arXiv:2509.25095. doi: https://doi.org/\n10.48550/arXiv.2509.25095 (2025).\n26.\nLopez Alcaraz, J. M. & Strodthoff, N. Explaining Time Series Classification Predictions via Causal\nAttributions in 2025 IEEE 37th International Conference on Tools with Artificial Intelligence\n(ICTAI) doi: 10.1109/ICTAI66417.2025.00014 (IEEE Computer Society, Los Alamitos, CA,\nUSA, Nov. 2025), 42–51.\n27.\nJohnson, A. E. W. et al. MIMIC-IV, a freely accessible electronic health record dataset. Scientific\nData 10. doi: 10.1038/s41597-022-01899-x (Jan. 2023).\n28.\nGow, B. et al. MIMIC-IV-ECG: Diagnostic Electrocardiogram Matched Subset doi: 10.13026/4nqg-\nsb35. 2023.\n29.\nStrodthoff, N., Lopez Alcaraz, J. M. & Haverkamp, W. Prospects for artificial intelligence-enhanced\nelectrocardiogram as a unified screening tool for cardiac and non-cardiac conditions: an explorative\nstudy in emergency care. European Heart Journal-Digital Health. doi: 10.1093/ehjdh/ztae039,\nztae039 (2024).\n30.\nMoor, M. et al. Predicting sepsis using deep learning across international sites: a retrospective\ndevelopment and validation study. EClinicalMedicine 62. doi: 10.1016/j.eclinm.2023.102124\n(2023).\n31.\nHofford, M. R. et al. OpenSep: a generalizable open source pipeline for SOFA score calculation\nand Sepsis-3 classification. JAMIA open 5. doi: 10.1093/jamiaopen/ooac105, ooac105 (2022).\n32.\nLambden, S., Laterre, P. F., Levy, M. M. & Francois, B. The SOFA score—development, utility\nand challenges of accurate assessment in clinical trials. Critical Care 23. doi: 10.1186/s13054-\n019-2663-7, 1–9 (2019).\n33.\nGu, A., Goel, K. & R´e, C. Efficiently modeling long sequences with structured state spaces.\nInternational Conference on Learning Representations (2021).\n34.\nMehari, T. & Strodthoff, N. Towards quantitative precision for ECG analysis: Leveraging state\nspace models, self-supervision and patient metadata. IEEE Journal of Biomedical and Health\nInformatics. doi: 10.1109/JBHI.2023.3310989 (2023).\n35.\nHolzm¨uller, D., Grinsztajn, L. & Steinwart, I. Better by default: Strong pre-tuned mlps and\nboosted trees on tabular data. Advances in Neural Information Processing Systems 37, 26577–\n26658 (2024).\n36.\nMorvan, M. L. & Varoquaux, G. Imputation for prediction: beware of diminishing returns. in The\nThirteenth International Conference on Learning Representations (2025).\n37.\nLoshchilov, I. & Hutter, F. Decoupled Weight Decay Regularization in International Conference\non Learning Representations (2019).\n38.\nMcDermott, M. B., Zhang, H., Hansen, L. H., Angelotti, G. & Gallifant, J. A Closer Look at\nAUROC and AUPRC under Class Imbalance in The Thirty-eighth Annual Conference on Neural\nInformation Processing Systems (2024).\n14\n"}, {"page": 15, "text": "A\nPredictive performance\nTable 3 lists the predictive performance including confidence intervals via bootstrapping. In addition\nto the results from the main text, the table contains an additional tree-based baseline prediction model\n(XGBoost).\nTable 3: Predictive performance (AUROC) comparison across models using ECG waveform–derived\nfeatures and routine clinical data.\nOutcome counts and prevalence are reported in parentheses.\nColumns correspond to models trained with ECG waveforms plus RealMLP (S4+RealMLP), tabular-\nonly RealMLP, and XGBoost. Columns “Sig vs RealMLP” and “Sig vs XGBoost” indicate paired\nbootstrap significance of S4+RealMLP. Confidence intervals represent 95% CI from 1000 bootstrap\niterations.\nLabel (Counts, prevalence)\nS4+RealMLP\nRealMLP\nXGBoost\nSig vs RealMLP\nSig vs XGBoost\nMortality\nICU mortality (7,028; 11.16%)\n0.8809 (0.8525–0.9082)\n0.8459 (0.8133–0.8809)\n0.8419 (0.8048–0.8754)\n✓\n✓\nStay mortality (9,443; 14.99%)\n0.8561 (0.8301–0.8841)\n0.8356 (0.8052–0.8653)\n0.8283 (0.7974–0.8581)\n✓\n✓\n1-day mortality (1,822; 2.89%)\n0.9009 (0.8551–0.9435)\n0.8932 (0.8387–0.9416)\n0.8195 (0.7490–0.8864)\n✓\n2-day mortality (2,744; 4.36%)\n0.8834 (0.8375–0.9262)\n0.8809 (0.8345–0.9243)\n0.8425 (0.7890–0.8906)\n✓\n7-day mortality (5,968; 9.47%)\n0.8645 (0.8321–0.8956)\n0.8416 (0.8066–0.8766)\n0.8308 (0.7939–0.8653)\n✓\n✓\n28-day mortality (11,128; 17.66%)\n0.8609 (0.8372–0.8862)\n0.8349 (0.8092–0.8624)\n0.8459 (0.8212–0.8696)\n✓\n90-day mortality (15,097; 23.96%)\n0.8495 (0.8275–0.8715)\n0.8237 (0.7988–0.8469)\n0.8324 (0.8093–0.8561)\n✓\n✓\n180-day mortality (17,681; 28.06%)\n0.8393 (0.8188–0.8604)\n0.8166 (0.7935–0.8373)\n0.8298 (0.8088–0.8522)\n✓\n1-year mortality (20,752; 32.94%)\n0.8320 (0.8105–0.8531)\n0.8109 (0.7865–0.8324)\n0.8037 (0.7805–0.8253)\n✓\n✓\nMedications\nCrystalloids (57,752; 91.67%)\n0.8811 (0.8521–0.9077)\n0.8883 (0.8614–0.9129)\n0.8789 (0.8501–0.9073)\nElectrolytes (33,568; 53.28%)\n0.8017 (0.7755–0.9092)\n0.8101 (0.7995–0.9304)\n0.8101 (0.7960–0.9367)\nAntibiotics (37,136; 58.95%)\n0.8570 (0.8285–0.9092)\n0.8562 (0.7995–0.9304)\n0.8562 (0.7961–0.9367)\nVasopressors (21,012; 33.35%)\n0.8854 (0.8575–0.9092)\n0.8781 (0.7995–0.9304)\n0.8781 (0.7961–0.9367)\nInotropes (5,746; 9.12%)\n0.8732 (0.8471–0.9092)\n0.8738 (0.7995–0.9304)\n0.8738 (0.7961–0.9367)\nAntiarrhythmics (6,663; 10.58%)\n0.7909 (0.7614–0.8283)\n0.7434 (0.7995–0.9304)\n0.7434 (0.7961–0.9367)\n✓\nAnticoagulants / Antiplatelets (28,825; 45.75%)\n0.7954 (0.7755–0.8283)\n0.7903 (0.7995–0.9304)\n0.7903 (0.7961–0.9367)\n✓\nSedatives (26,562; 42.16%)\n0.9182 (0.8931–0.9416)\n0.9149 (0.8703–0.9187)\n0.9149 (0.8362–0.9367)\n✓\nAnalgesics (31,672; 50.27%)\n0.8683 (0.8483–0.8918)\n0.8583 (0.7995–0.9304)\n0.8583 (0.7961–0.9367)\n✓\nNeuromuscular blockers (2,995; 4.75%)\n0.8889 (0.8591–0.9092)\n0.8831 (0.7995–0.9304)\n0.8831 (0.7961–0.9367)\n✓\nGI protection (21,096; 33.49%)\n0.7160 (0.6896–0.7420)\n0.7060 (0.6752–0.7323)\n0.7060 (0.6553–0.7317)\n✓\nBlood products / Transfusions (9,205; 14.61%)\n0.8995 (0.8732–0.9007)\n0.9007 (0.7995–0.9304)\n0.9007 (0.7961–0.9367)\nParenteral nutrition (1,370; 2.17%)\n0.8780 (0.8402–0.9092)\n0.8402 (0.7995–0.9304)\n0.8402 (0.7961–0.9367)\n✓\nClinical Deterioration\nSevere hypoxemia (4,343; 6.89%)\n0.7585 (0.7083–0.8088)\n0.6653 (0.6023–0.7179)\n0.6653 (0.6023–0.7179)\n✓\n✓\nECMO (1,369; 2.17%)\n0.8486 (0.8207–0.8740)\n0.8740 (0.7995–0.9304)\n0.8740 (0.7961–0.9367)\nInvasive mechanical ventilation (27,257; 43.26%)\n0.9722 (0.9639–0.9795)\n0.9701 (0.9623–0.9783)\n0.9701 (0.9613–0.9786)\n✓\nNon-invasive mechanical ventilation (1,348; 2.14%)\n0.9712 (0.9455–0.9904)\n0.9525 (0.9380–0.9914)\n0.9525 (0.9148–0.9817)\n✓\nCardiac arrest (204; 0.32%)\n0.9175 (0.8279–1.0000)\n0.8101 (0.7432–1.0000)\n0.8101 (0.6978–0.9458)\n✓\n✓\nOrgan dysfunction\nRespiratory (22,129; 85.33%)\n0.7381 (0.7083–0.8088)\n0.7325 (0.6964–0.7987)\n0.7325 (0.6023–0.7179)\n✓\n✓\nNervous system (28,824; 47.45%)\n0.9346 (0.9229–0.9459)\n0.9351 (0.9196–0.9433)\n0.9351 (0.9232–0.9466)\nCardiovascular (13,729; 21.79%)\n0.8716 (0.8279–0.9092)\n0.8628 (0.7995–0.9304)\n0.8628 (0.7961–0.9367)\n✓\nLiver (5,144; 8.16%)\n0.9324 (0.9074–0.9542)\n0.9362 (0.8724–0.9397)\n0.9362 (0.9079–0.9590)\nCoagulation (8,903; 14.13%)\n0.9325 (0.8279–0.9542)\n0.9224 (0.7433–0.9314)\n0.9224 (0.6990–0.9458)\n✓\n✓\nKidneys (20,978; 33.30%)\n0.8457 (0.8083–0.8680)\n0.8477 (0.8316–0.8719)\n0.8477 (0.8272–0.8686)\nMacro\n0.8650 (0.8561–0.8733)\n0.8583 (0.8493–0.8676)\n0.8460 (0.8362–0.8554)\n✓\n✓\n15\n"}, {"page": 16, "text": "B\nCalibration\nTables 5-8 shows calibration curves for all considered prediction targets.\nFigure 5: Calibration figures for the mortality category.\n16\n"}, {"page": 17, "text": "Figure 6: Calibration figures for the medications category.\n17\n"}, {"page": 18, "text": "Figure 7: Calibration figures for the clinical deterioration category.\nFigure 8: Calibration figures for the organ dysfunction category.\nC\nClinical benchmark: Additional results\nTable 4 and 5 reports the counts below, comparable, or above the model for clinicians and LLMs across\nall tasks for both benchmarks. Table 6 reports the Youden index for four clinicians, two proprietary\nLLMs (GPT 5.2 and Claude Sonnet 4.5), and the baseline model across four clinical deterioration\nlabels. Values for benchmark A →B and their corresponding changes (Δ) are shown for each model.\n18\n"}, {"page": 19, "text": "Table 4: Summary of decision makers’ performance relative to the model’s ROC curve for benchmark\nA: model vs clinicians. Counts indicate the number of instances above, comparable, or below the model\n(by comparing to the model’s ROC curve). Percentages in the last row are computed relative to total\nobservations for clinicians (16) and LLMs (8).\nTask\nClinicians\nLLMs\nMortality\n1 / 1 / 2\n0 / 0 / 2\nVasopressors\n1 / 0 / 3\n0 / 0 / 2\nMechanical ventilation\n0 / 2 / 2\n0 / 1 / 1\nKidney dysfunction\n0 / 2 / 2\n1 / 1 / 0\nSum\n2 / 5 / 9\n1 / 2 / 5\nSum (%)\n12.5 / 31.25 / 56.25\n12.5 / 25 / 62.5\nTable 5: Summary of decision makers’ performance relative to the model’s ROC curve for benchmark\nB: model and clinicians. Counts indicate the number of instances above, comparable, or below the\nmodel (by comparing to the model’s ROC curve). Percentages in the last row are computed relative to\ntotal observations for clinicians (16) and LLMs (8).\nTask\nClinicians\nLLMs\nMortality\n3 / 0 / 1\n2 / 0 / 0\nVasopressors\n1 / 1 / 2\n0 / 1 / 1\nMechanical ventilation\n0 / 3 / 1\n0 / 1 / 1\nKidney dysfunction\n2 / 1 / 1\n1 / 0 / 1\nSum\n6 / 5 / 5\n3 / 2 / 3\nSum (%)\n37.5 / 31.25 / 31.25\n37.5 / 25 / 37.5\nTable 6: Youden index comparison across clinicians, and LLMs for different clinical deterioration labels.\nModel / Label\nMortality Stay\nMedications Vasopressors\nMechanical Ventilation Invasive\nOrgan Dysfunction Kidneys\nClinician 1\n0.330 →0.429 (Δ=0.099)\n0.232 →0.525 (Δ=0.293)\n0.600 →0.700 (Δ=0.100)\n0.200 →0.500 (Δ=0.300)\nClinician 2\n0.385 →0.637 (Δ=0.253)\n0.323 →0.576 (Δ=0.253)\n0.500 →0.800 (Δ=0.300)\n0.400 →0.500 (Δ=0.100)\nClinician 3\n0.000 →0.000 (Δ=0.000)\n0.889 →0.778 (Δ=-0.111)\n0.700 →0.700 (Δ=0.000)\n0.300 →0.400 (Δ=0.100)\nClinician 4\n0.155 →0.176 (Δ=0.021)\n0.067 →0.121 (Δ=0.055)\n0.222 →0.000 (Δ=-0.222)\n0.044 →0.417 (Δ=0.372)\nGPT 5.2\n0.319 →0.692 (Δ=0.374)\n0.010 →0.141 (Δ=0.131)\n0.300 →0.200 (Δ=-0.100)\n0.500 →0.400 (Δ=-0.100)\nClaude Sonnet 4.5\n0.396 →0.286 (Δ=-0.110)\n-0.152 →0.465 (Δ=0.616)\n0.300 →0.800 (Δ=0.500)\n0.500 →0.500 (Δ=0.000)\n19\n"}, {"page": 20, "text": "D\nDefinition of prediction targets\nTables 7-9 provide specific definitions for the prediction targets considered in this work.\nTable 7: Descriptive table defining medication label groups based on specific drugs. The left column\nlists medication labels, and the right column details the drugs tracked. A positive label is assigned if\nany drug from the corresponding group was administered within the evaluated time horizon\nLabel\nDrugs\nmedication crystalloids\nNaCl 0.9%, Dextrose 5%, Free Water, LR, D5NS, D5 1/2NS, D5LR,\nD5 1/4NS, NaCl 0.45%, Sterile Water, Dextrose 10%, Dextrose 20%,\nDextrose 30%, Dextrose 40%, Dextrose 50%, NaCl 3% (Hypertonic\nSaline), NaCl 23.4%\nmedication electrolytes\nPotassium Chloride, KCL (Bolus), KCl (CRRT), K Phos, Na Phos,\nCalcium Gluconate, Calcium Gluconate (CRRT), Calcium Gluconate\n(Bolus), Calcium Chloride, Magnesium Sulfate, Magnesium Sulfate\n(Bolus), Magnesium Sulfate (OB-GYN), Sodium Bicarbonate 8.4%,\nSodium Bicarbonate 8.4% (Amp), Hydrochloric Acid - HCL\nmedication antibiotics\nCefepime,\nVancomycin,\nCeftriaxone,\nLevofloxacin,\nAzithromycin,\nMetronidazole,\nBactrim\n(SMX/TMP),\nCefazolin,\nCiprofloxacin,\nMeropenem, Piperacillin/Tazobactam (Zosyn), Piperacillin, Omepra-\nzole (Prilosec), Tobramycin, Doxycycline, Linezolid, Daptomycin, Cef-\ntazidime, Ampicillin/Sulbactam (Unasyn), Ampicillin, Acyclovir, Clin-\ndamycin, Aztreonam, Colistin, Amikacin, Imipenem/Cilastatin, Ceftaro-\nline, Rifampin, Erythromycin, Gentamicin, Nafcillin, Tamiflu, Penicillin\nG potassium, Keflex, Quinine, Isoniazid, Ethambutol, Pyrazinamide\nmedication vasopressors\nEpinephrine, Epinephrine., Norepinephrine, Vasopressin, Dobutamine,\nDopamine, Phenylephrine, Phenylephrine (50/250), Phenylephrine\n(200/250), Isuprel, Angiotensin II (Giapreza)\nmedication inotropes\nEpinephrine, Epinephrine., Dobutamine, Dopamine, Isuprel, Milrinone\nmedication antiarrhythmics\nAmiodarone, Amiodarone 600/500, Amiodarone 450/250, Amiodarone\n150/100, Esmolol, Lidocaine, Procainamide, Verapamil, Diltiazem,\nAdenosine\nmedication anticoagulants antiplatelets\nHeparin Sodium, Heparin Sodium (Prophylaxis), Heparin Sodium (Im-\npella), Heparin Sodium (CRRT-Prefilter), Enoxaparin (Lovenox), Bi-\nvalirudin (Angiomax), Eptifibatide (Integrilin), Coumadin (Warfarin),\nArgatroban, Fondaparinux, Tirofiban (Aggrastat), Abciximab (Reopro),\nLepirudin, ACD-A Citrate (1000ml), ACD-A Citrate (500ml), Citrate,\nProtamine sulfate\nmedication sedatives\nPropofol, Midazolam (Versed), Lorazepam (Ativan), Diazepam (Valium),\nDexmedetomidine (Precedex), Ketamine, Pentobarbital\nmedication analgesics\nFentanyl, Fentanyl (Concentrate), Morphine Sulfate, Hydromorphone\n(Dilaudid), Meperidine (Demerol), Acetaminophen-IV, Methadone Hy-\ndrochloride, Ketorolac (Toradol), Naloxone (Narcan)\nmedication neuromuscular blockers\nVecuronium, Rocuronium, Cisatracurium, Neostigmine (Prostigmin)\nmedication gi protection\nRanitidine (Prophylaxis), Pantoprazole (Protonix), Famotidine (Pepcid),\nLansoprazole (Prevacid), Omeprazole (Prilosec), Carafate (Sucralfate),\nEsomeprazole (Nexium), Ranitidine\nmedication blood products transfusions\nPacked Red Blood Cells (pRBCs), Platelets, Fresh Frozen Plasma (FFP),\nCryoprecipitate, Whole Blood, Albumin 5%, Albumin 25%, IVIG (Intra-\nvenous Immunoglobulin), Factor VIII, Factor IX, Prothrombin Complex\nConcentrate (PCC), Recombinant Factor VIIa, Fibrinogen Concentrate,\nThrombin, Tranexamic Acid (TXA), Erythropoietin (EPO), Iron Su-\ncrose (Venofer), Iron Dextran, Iron Gluconate, Ferumoxytol\nmedication parenteral nutrition\nTPN w/ Lipids, TPN without Lipids, Peripheral Parenteral Nutrition,\nDextrose PN, Amino Acids, Lipids 20%, Lipids 10%, Lipids (additive)\n20\n"}, {"page": 21, "text": "Table 8: Descriptive table defining early warning score labels based on specific SOFA score (Sepsis-3)\ndefinition. The left column list the early warning score based od diverse physiological systems and the\nright columns details the criteria for its definition. A positive label is assigned if an event happened\nwithin the next 24 hours\nLabel\nDefinition\nsofa respiratory\nPaO2/FiO2 (mmHg) < 300\nsofa nervous\nGCS ≤12\nsofa cardiovascular\nVasopressor\nadministration\n(e.g.,\ndopamine,\ndobutamine,\nepinephrine, norepinephrine)\nsofa liver\nBilirubin (mg/dl) ≥2\nsofa coagulation\nPlatelets (×103/ml) < 100\nsofa kidneys\nCreatinine (mg/dl) ≥2 or urine output < 500 ml/day\nTable 9: Descriptive table defining clinical deterioration labels based on specific events. The left column\nlist the clinical deterioration labels, and the right columns details the events tracked. A positive label\nis assigned if any event from the corresponding group happened within the valuation time horizon\nLabel\nDefinition\nsevere hypoxemia\nO2 saturation pulseoxymetry <= 85\necmo\nProcedure: Sheath (Venous). Chartevents: Circuit Configuration\n(ECMO), Speed (ECMO), Flow (ECMO), Sweep (ECMO), Flow\nAlarm (Lo) (ECMO), Flow Alarm (Hi) (ECMO), FiO2 (ECMO),\nSuction events (ECMO), Cannula sites visually inspected (ECMO),\nOxygenator visible (ECMO), Pump plugged into RED outlet\n(ECMO), Circuit inspected for clot (ECMO), P1 - P2 (ECMO), P1\n(ECMO), P2 (ECMO), Emergency Equipment at bedside (ECMO),\nFlow Sensor repositioned (ECMO), Oxygenator/ECMO, ECMO\nihca\nProcedure: Cardioversion/Defibrillation\nmechanical ventilation invasive\nProcedures: Invasive Ventilation\nmechanical ventilation invasive\nProcedures: Non-invasive Ventilation\n21\n"}, {"page": 22, "text": "E\nRelated ICU datasets\nExisting ICU datasets vary in scope and modality. EHRSHOT [7] provides longitudinal medication\ndata across 15 tasks but lacks biometrics, waveforms, and vital trends. The work in [10] use eICU with\ndemographics, vitals, and labs across 770 tasks but omit temporal trends and waveforms. HiRID [8]\noffers detailed ICU stay data over 23 labels but excludes physiological waveforms. YAIB [11] aggregates\nmultiple sources for a large, diverse cohort but provides only five tasks and no waveform or trend\ndata. Gupta et al. [12] uses MIMIC-IV with broad demographic, vital, and lab coverage over nine\ntasks but without waveforms. In contrast, MDS-ICU builds on MIMIC-IV to integrate waveform\nsignals and temporal trends of vitals and labs, supporting a large number of prediction tasks with\nmultimodal, temporally rich representations, uniquely suited for advanced ICU time series modeling.\nFurthermore, we incorporate a benchmark with relevant medical specialists to further validate clinical\nutility. Relevant related datasets are compared in Table 10.\nTable 10: Direct comparison with related works in terms of dataset size, features, availability, and\nnumber of target labels.\nName\nDetail\nEHRSHOT\nSheik. et al\nYeche et al\nYAIB\nGupta et al\nMDS-ICU\nReference\n[7]\n[10]\n[8]\n[11]\n[12]\nThis work\nDB source\nOwn\neICU\nHiRID\nMultiple\nMIMIC-IV\nMIMIC-IV\nPopulation\nLongitudinal\nICU\nICU\nICU\nLongitudinal\nICU\nSize\nPatients\n6739\n52325\n-1\n+2336961\n65366\n27,062\nVisits\n921499\n73718\n33905\n313400\n94458\n33,590\nFeatures\nDemographics\n✓\n✓\n✓\n✓\n✓\n✓\nBiometrics\n✗\n✓\n✓\n✓\n✓\n✓\nVital parameters\n✗\n✓\n✓\n✓\n✓\n✓(T)\nLab. values\n✓\n✓\n✓\n✓\n✓\n✓(T)\nWaveforms\n✗\n✗\n✗\n✗\n✗\n✓\nChief complaint\n✗\n✗\n✗\n✗\n✗\n✗\nMedications\n✓\n✗\n✓\n✓(T)\n✓\n✗\nTasks\nLabels\n15\n770\n23\n5\n9\n33\nAvailability\nOpen source\n✓\n✓\n✓\n✓\n✓\n✓\nWe use diverse symbology to express the contribution where ✓= available, ✗= unavailable, E = available in the form\nof embeddings, and T = available in the form of trends or at least two sampled values.\n1HiRID only provides stay-level\nidentifiers.\nF\nLLM Evaluation Prompts\nF.1\nPrompt A: Initial Binary Prediction\nLLM Evaluation Prompt A\nYou are an ICU expert and have to predict four binary clinical outcomes given ICU patient\ndata:\n1. Will the patient die during the ICU or hospital stay? 2. Will the patient require vasopressor\nadministration within the next 24 hours? 3. Will the patient require invasive mechanical\nventilation at any point within the next 24 hours? 4. Will the patient develop acute kidney\ninjury within the next 24 hours, defined as either (a) a doubling of creatinine or (b) urine output\nbelow 500 ml?\nSome features are binary e.g. gender, race, surgeries, and mechanical ventilations. Other features\nare categorical like the GCS scores. The rest is continuous. for the features, we have either raw\n(in their respective unit of measurement) or differences (from one to another record). We also\nprovide statistical features to observe trends e.g. min, max, first and last, and also the time in\nhours that has happened since that event until prediction time.\nHere are the features and their units of measurements: {Features}\nThis is the patient data: {Patient data}\nPlease avoid excessive explanation, and just deliver binary predictions given the features.\n22\n"}, {"page": 23, "text": "F.2\nPrompt B: Prediction Update After Model Probabilities\nLLM Evaluation Prompt B\nYou are an ICU expert and have to predict four binary clinical outcomes given ICU patient\ndata:\n1. Will the patient die during the ICU or hospital stay? 2. Will the patient require vasopressor\nadministration within the next 24 hours? 3. Will the patient require invasive mechanical\nventilation at any point within the next 24 hours? 4. Will the patient develop acute kidney\ninjury within the next 24 hours, defined as either (a) a doubling of creatinine or (b) urine output\nbelow 500 ml?\nSome features are binary e.g. gender, race, surgeries, and mechanical ventilations. Other features\nare categorical like the GCS scores. The rest is continuous. for the features, we have either raw\n(in their respective unit of measurement) or differences (from one to another record). We also\nprovide statistical features to observe trends e.g. min, max, first and last, and also the time in\nhours that has happened since that event until prediction time.\nHere are the features and their units of measurements: {Features}\nYou have previously predicted this: {Predictions}\nFor this patient data: {Patient data}\nYou are now provided with predicted probabilities from a deep learning model. {Probabilities}\nWould you change any of your binary predictions after seeing these probabilities? If so, provide\nan updated list of binary predictions.\nNote: These probabilities do not imply a fixed 50% decision threshold. Avoid any explanation.\n23\n"}]}