{"doc_id": "arxiv:2602.10553", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2602.10553.pdf", "meta": {"doc_id": "arxiv:2602.10553", "source": "arxiv", "arxiv_id": "2602.10553", "title": "Contrastive Learning for Multi Label ECG Classification with Jaccard Score Based Sigmoid Loss", "authors": ["Junichiro Takahashi", "Masataka Sato", "Satoshi Kodeta", "Norihiko Takeda"], "published": "2026-02-11T05:58:34Z", "updated": "2026-02-11T05:58:34Z", "summary": "Recent advances in large language models (LLMs) have enabled the development of multimodal medical AI. While models such as MedGemini achieve high accuracy on VQA tasks like USMLE MM, their performance on ECG based tasks remains limited, and some models, such as MedGemma, do not support ECG data at all. Interpreting ECGs is inherently challenging, and diagnostic accuracy can vary depending on the interpreter's experience. Although echocardiography provides rich diagnostic information, it requires specialized equipment and personnel, limiting its availability. In this study, we focus on constructing a robust ECG encoder for multimodal pretraining using real world hospital data. We employ SigLIP, a CLIP based model with a sigmoid based loss function enabling multi label prediction, and introduce a modified loss function tailored to the multi label nature of ECG data. Experiments demonstrate that incorporating medical knowledge in the language model and applying the modified loss significantly improve multi label ECG classification. To further enhance performance, we increase the embedding dimensionality and apply random cropping to mitigate data drift. Finally, per label analysis reveals which ECG findings are easier or harder to predict. Our study provides a foundational framework for developing medical models that utilize ECG data.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2602.10553v1", "url_pdf": "https://arxiv.org/pdf/2602.10553.pdf", "meta_path": "data/raw/arxiv/meta/2602.10553.json", "sha256": "8da70bb52fff69eea9e95a242e8e12a54c43187fe035e18b1616b9b0c72642c0", "status": "ok", "fetched_at": "2026-02-18T02:19:25.437884+00:00"}, "pages": [{"page": 1, "text": "Contrastive Learning for Multi-Label ECG\nClassification with Jaccard Score–Based Sigmoid Loss\nJunichiro Takahashi\nMasataka Sato\nSatoshi Kodeta\nNorihiko Takeda\nDepartment of Cardiovascular Medicine\nThe University of Tokyo Hospital\nTokyo, Japan\nkodera@tke.att.ne.jp\nAbstract\nRecent advances in large language models (LLMs) have enabled the development\nof multimodal medical AI. While models such as MedGemini achieve high ac-\ncuracy on VQA tasks like USMLE-MM, their performance on ECG-based tasks\nremains limited, and some models, such as MedGemma, do not support ECG data\nat all. Interpreting ECGs is inherently challenging, and diagnostic accuracy can\nvary depending on the interpreter’s experience. Although echocardiography pro-\nvides rich diagnostic information, it requires specialized equipment and personnel,\nlimiting its availability.\nIn this study, we focus on constructing a robust ECG encoder for multimodal\npretraining using real-world hospital data. We employ SigLIP, a CLIP-based model\nwith a sigmoid-based loss function enabling multi-label prediction, and introduce a\nmodified loss function tailored to the multi-label nature of ECG data. Experiments\ndemonstrate that incorporating medical knowledge in the language model and\napplying the modified loss significantly improve multi-label ECG classification.\nTo further enhance performance, we increase the embedding dimensionality and\napply random cropping to mitigate data drift.\nFinally, per-label analysis reveals which ECG findings are easier or harder to\npredict. Our study provides a foundational framework for developing medical\nmodels that utilize ECG data.\n1\nIntroduction\nIn recent years, alongside the emergence of large language models (LLMs), multimodal medical\nAI has been developed. Recently, models such as MedGemini [6] and MedGemma [7] have been\nintroduced, marking the appearance of multimodal models in the medical domain. However, while\nMedGemini achieves high accuracy on VQA tasks such as USMLE-MM, reaching 93.5%, its\nperformance on ECG-QA, which involves electrocardiogram data (ECG), is considerably lower at\n57.7%. In addition, MedGemma does not support an ECG at all. This discrepancy can be attributed\nto the inherently challenging nature of ECGs for model training.\nIn real-world clinical settings, interpreting ECGs is one of the more challenging tasks, and it is well\nknown that diagnostic accuracy can vary significantly depending on the interpreter’s professional\nbackground and level of experience [3]. Although transthoracic echocardiography is recommended for\nthe diagnosis of cardiovascular diseases due to its rich informational content [2], it requires specialized\ntechnicians, and many facilities lack sufficient infrastructure to perform the examination [11]. In\nthis context, the development of a multimodal model capable of handling electrocardiogram data\nand estimating echocardiographic findings from ECGs could provide substantial support in clinical\nsettings. However, to date, no such clinically useful multimodal model exists.\n39th Conference on Neural Information Processing Systems (NeurIPS 2025).\narXiv:2602.10553v1  [cs.LG]  11 Feb 2026\n"}, {"page": 2, "text": "To build a high-quality multimodal model, it is essential to design ECG encoders suitable for the\nmodality. In this study, we focus on the construction of a convincing encoder for ECGs. Previous\nstudies have reported attempts to apply CLIP [5] has been used as a pretraining method for ECGs [1,\n4, 12], but these approaches have several limitations. First, many of these studies rely on publicly\navailable datasets such as PTB-XL [8] rather than real-world clinical data. While previous studies\nhave made predictions using simplified PTB-XL labels, actual clinical findings are more finely\ncategorized, and other predictive factors present in a single ECG can be overlooked. Therefore, a\nmore detailed classification is necessary. Second, while real-world cardiovascular diseases often\ninvolve multiple abnormalities simultaneously, representing a multi-label problem, existing studies\napplying CLIP have been limited to single-class prediction. Therefore, CLIP-based contrastive\nlearning for ECGs may not capture the inherent multi-label characteristics of ECG data.\nIn this study, we employed real-world hospital data and conducted pretraining based on SigLIP [13],\nassessing its performance in multi-label prediction tasks. SigLIP is a model that replaces the\nCrossEntropyLoss of CLIP with a sigmoid-based loss function, thereby enabling multi-label inference\nfor each prediction. We also demonstrate that improving the loss function is necessary to enhance\nmulti-label classification performance when training ECG data using SigLIP. Moreover, we addressed\nthe clinically significant task of estimating echocardiographic findings from ECGs, investigating the\npotential of ECGs as a surrogate for echocardiography.\nOverall, our study introduces two principal contributions. First, it leverages authentic clinical\ndata for multimodal pretraining, enhancing the clinical validity of the model. Second, it adopts a\nsigmoid-based loss function to facilitate multi-label prediction, thereby enabling clinically meaningful\ninferences from ECGs that were not achievable with previous CLIP-based approaches.\n2\nMethods\n2.1\nModel architecture\nIn this study, we trained an ECG encoder using SigLIP and evaluated its performance in multi-label\nclassification. The predicted findings are presented in the Appendix 5.1. We adopted a 1D ResNet-18\nas an ECG Encoder as previous studies [1, 4] have reported superior performance compared with\nVision Transformer (ViT) architectures. As the language model, we employed Qwen3-8B [10],\nwhich was selected based on preliminary evaluation indicating a favorable balance between model\nsize and domain-specific knowledge regarding the target labels. For the ablation study, we utilized\nGemma3-4B [9] to investigate whether ECG knowledge in language models influences pretraining\neffectiveness. By examining its generated outputs, we found that Gemma3-4B possesses limited ECG\nknowledge related to ECGs.\n2.2\nDataset\nThe dataset consisted of 33,732 ECG data from our hospital. The ECG data consisted of 12-lead\nrecordings sampled at 500 Hz over a duration of 10 seconds. We split the data such that the label\ndistribution is uniform across the training, validation, and test sets. We ensured that the same patient\ndid not appear across different splits, as this could lead to data leakage. The training text was\nformatted as: “This ECG shows {finding_1}, {finding_2}, ..., {finding_n}.”\n3\nExperiments\nWe conducted a series of experiments for comparison. In the first experiment, we followed the\nstandard SigLIP training process. In the second experiment, we modified the loss function of the\nstandard SigLIP to account for the multi-label nature specific to ECG data. While SigLIP trains\nby treating diagonal pairs as the correct labels, ECG datasets with a limited number of diagnostic\ncategories may contain patients with the same ECG findings within the same batch, which can lead to\nlabel conflicts. To address this issue, we modified the loss function. The modified loss was designed\nto treat patients with the same condition as similar pairs, and the loss calculation was adjusted\naccordingly to account for this similarity. We used the Jaccard Score as a metric for this similarity.\nFurther details are provided in the Appendix 5.2.\n2\n"}, {"page": 3, "text": "For all two experiments, training was conducted using the Adam optimizer with a learning rate of\n1 × 10−3. The models were trained for 250 epochs, with a warm-up phase of 5,000 steps.\nThe results are presented in Table 1. Evaluation was performed using the multi-label metrics:\nHamming Loss, Precision (Micro), Recall (Micro), F1 Score (Micro), and Jaccard Index.\nTable 1: Results of the standard SigLIP and SigLIP with the modified loss\nMetric\nStandard\nModified loss\nHamming Loss\n0.0665 ↓\n0.0451 ↓\nPrecision (Micro)\n0.5067 ↑\n0.3147 ↑\nRecall (Micro)\n0.0365 ↑\n0.3020 ↑\nF1 Score (Micro)\n0.0681 ↑\n0.3082 ↑\nJaccard Index\n0.0373 ↑\n0.0858 ↑\nFrom Table 1, it can be observed that the Modified Loss exhibits superior performance in multi-\nlabel ECG classification, as indicated by metrics such as F1 Score (Micro), Jaccard Index, and\nHamming Loss.\nIn the third experiment, we trained SigLIP using a language model without ECG-related knowledge\nto investigate how the presence or absence of domain knowledge in the language model affects\npretraining performance. In all subsequent experiments, we employ our Jaccard-based sigmoid loss\nfunction instead of the original sigmoid loss of SigLIP.\nTable 2: Results of SigLIP with the modified loss, and Gemma3-4b\nMetric\nModified loss (Qwen3-8B)\nGemma3-4b\nHamming Loss\n0.0451 ↓\n0.0539 ↓\nPrecision (Micro)\n0.3147 ↑\n0.2451 ↑\nRecall (Micro)\n0.3020 ↑\n0.2970 ↑\nF1 Score (Micro)\n0.3082 ↑\n0.2686 ↑\nJaccard Index\n0.0858 ↑\n0.0736 ↑\nFrom the results in Table 2, it can be seen that the medical knowledge of the language model affects\nthe overall performance of multi-label classification.\nThrough the experiments conducted thus far, we have demonstrated that employing the Modified\nSigmoid Loss, which is tailored for multi-label classification, together with a language model incorpo-\nrating medical knowledge, leads to performance improvements. However, the overall F1 Score (Micro)\nremains low at 0.3082, which is insufficient for practical applications.\nTo further enhance the F1 Score (Micro), we conducted several performance improvement experi-\nments. The first approach involved increasing the dimensionality of the embedding vector, which\nrepresents the final similarity, from 128 to 256. The reason for increasing the embedding dimension-\nality is that 128 dimensions may be insufficient to adequately capture the representations of ECG\nsignals. We also experimented with 512 dimensions, but no further performance improvement was\nobserved; therefore, those results are omitted. The second approach aimed to address the issue of\ndata drift by randomly cropping ECG waveforms. Since real ECG signals may vary in both start and\nend times, this variability can degrade performance. By applying random cropping, we mitigate this\nissue.\nIn addition, to ensure that the effect of random cropping is properly reflected in the model, we set the\nwarmup steps to 20,000, following the original SigLIP paper, and increased the number of training\nepochs to 600.\nThe results are presented in Table 3. As a result, the final F1 Score (Micro) increased to 0.5028.\nAlthough the type and amount of data differ, this result achieves an F1-score comparable to that\nreported in the prior CLIP-based study [4]. From these results, it can be seen that increasing the\nembedding dimensionality to enhance ECG representation and applying random cropping to address\ndata drift both contribute to improved multi-label prediction performance when training ECGs with\nSigLIP.\n3\n"}, {"page": 4, "text": "Table 3: Performance comparison of baseline and proposed enhancements\nMetric\nBaseline\nEmbedding\ndim 256\nEmbedding dim 256\n+ random crop\n(250 epoch, 5k warmup)\nEmbedding dim 256\n+ random crop\n(600 epoch, 20k warmup)\nHamming Loss\n0.0451 ↓\n0.0769 ↓\n0.0856 ↓\n0.0680 ↓\nPrecision (Micro)\n0.3147 ↑\n0.4097 ↑\n0.3824 ↑\n0.4898 ↑\nRecall (Micro)\n0.3020 ↑\n0.3521 ↑\n0.4636 ↑\n0.5165 ↑\nF1 Score (Micro)\n0.3082 ↑\n0.3788 ↑\n0.4191 ↑\n0.5028 ↑\nJaccard Index\n0.0858 ↑\n0.2218 ↑\n0.2827 ↑\n0.3495 ↑\nWe will now examine the classification performance of the final model for each individual label. The\nAccuracy, Precision, Recall, and F1 Score for each label are presented in Appendix Table 5.\nFrom this table, it can be seen that some labels are easier to train with SigLIP-based contrastive\nlearning on ECGs, while others are more difficult. For example, findings such as ventricular premature\ncontractions and myocardial infarction have low F1 scores, indicating that they are difficult to predict\nfrom ECGs. Additionally, conditions observable via echocardiography, such as left atrial enlargement\nand left ventricular hypertrophy, have relatively low accuracy, showing that it is challenging to predict\nthem without any misclassification. In contrast, labels such as atrial fibrillation, ST-T abnormalities,\nand right and left bundle branch blocks are easier to predict from ECGs. Additionally, for lowEF,\nwhich is a condition observable via echocardiography, the model achieves a high accuracy of 0.9138\nand an F1 Score of 0.5152. Furthermore, as shown in Appendix 5.4, lowEF achieved a high AUC of\n0.887, confirming its strong average predictive performance. This indicates that SigLIP is capable of\npredicting certain conditions, such as lowEF, which are typically identified from echocardiography,\ndirectly from ECG data.\nWe investigated whether performance degradation occurs when using ECG data obtained from a\ndifferent hospital. The results are presented in Appendix 5.5. Overall, the F1 score decreased only\nslightly to 0.4841, a reduction of approximately 0.02, indicating minimal decline in the model’s\ninference performance. Predictions for conditions such as lowEF also maintained an AUC of 0.888.\nThese results suggest that our training approach is capable of preserving performance even on data\nfrom a different medical institution.\nFurthermore, the experiments with the ResNet1D multi-label model are presented in Appendix 5.7.\nIn these experiments as well, our model demonstrated superior performance.\n4\nConclusion\nIn this study, we enhanced the performance of multi-label electrocardiogram (ECG) classification\nby employing a SigLIP-based ECG encoder trained on real-world clinical data and a modified loss\nfunction incorporating the Jaccard similarity. By increasing the embedding dimension and applying\nrandom cropping, the F1 score improved to 0.50, revealing which findings are relatively easy or\ndifficult to predict. These results contribute to establishing a foundation for multimodal medical AI\nutilizing ECG data.\nReferences\n[1] Mingsheng Cai, Jiuming Jiang, Wenhao Huang, Che Liu, and Rossella Arcucci. Supreme: A\nsupervised pre-training framework for multimodal ecg representation learning, 2025. URL\nhttps://arxiv.org/abs/2502.19668.\n[2] Paul A Heidenreich, Biykem Bozkurt, David Aguilar, Larry A Allen, Joni J Byun, Monica M\nColvin, Anita Deswal, Mark H Drazner, Shannon M Dunlay, Linda R Evers, et al. 2022\naha/acc/hfsa guideline for the management of heart failure: a report of the american college of\ncardiology/american heart association joint committee on clinical practice guidelines. Journal\nof the American College of Cardiology, 79(17):e263–e421, 2022.\n[3] Anthony H Kashou, Peter A Noseworthy, Thomas J Beckman, Nandan S Anavekar, Michael W\nCullen, Kurt B Angstman, Benjamin J Sandefur, Brian P Shapiro, Brandon W Wiley, Andrew M\n4\n"}, {"page": 5, "text": "Kates, et al. Ecg interpretation proficiency of healthcare professionals. Current problems in\ncardiology, 48(10):101924, 2023.\n[4] Jun Li, Che Liu, Sibo Cheng, Rossella Arcucci, and Shenda Hong. Frozen language model\nhelps ecg zero-shot learning, 2023. URL https://arxiv.org/abs/2303.12311.\n[5] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agar-\nwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya\nSutskever. Learning transferable visual models from natural language supervision, 2021. URL\nhttps://arxiv.org/abs/2103.00020.\n[6] Khaled Saab, Tao Tu, Wei-Hung Weng, Ryutaro Tanno, David Stutz, Ellery Wulczyn, Fan\nZhang, Tim Strother, Chunjong Park, Elahe Vedadi, Juanma Zambrano Chaves, Szu-Yeu Hu,\nMike Schaekermann, Aishwarya Kamath, Yong Cheng, David G. T. Barrett, Cathy Cheung,\nBasil Mustafa, Anil Palepu, Daniel McDuff, Le Hou, Tomer Golany, Luyang Liu, Jean baptiste\nAlayrac, Neil Houlsby, Nenad Tomasev, Jan Freyberg, Charles Lau, Jonas Kemp, Jeremy\nLai, Shekoofeh Azizi, Kimberly Kanada, SiWai Man, Kavita Kulkarni, Ruoxi Sun, Siamak\nShakeri, Luheng He, Ben Caine, Albert Webson, Natasha Latysheva, Melvin Johnson, Philip\nMansfield, Jian Lu, Ehud Rivlin, Jesper Anderson, Bradley Green, Renee Wong, Jonathan\nKrause, Jonathon Shlens, Ewa Dominowska, S. M. Ali Eslami, Katherine Chou, Claire Cui,\nOriol Vinyals, Koray Kavukcuoglu, James Manyika, Jeff Dean, Demis Hassabis, Yossi Matias,\nDale Webster, Joelle Barral, Greg Corrado, Christopher Semturs, S. Sara Mahdavi, Juraj\nGottweis, Alan Karthikesalingam, and Vivek Natarajan. Capabilities of gemini models in\nmedicine, 2024. URL https://arxiv.org/abs/2404.18416.\n[7] Andrew Sellergren, Sahar Kazemzadeh, Tiam Jaroensri, Atilla Kiraly, Madeleine Traverse,\nTimo Kohlberger, Shawn Xu, Fayaz Jamil, Cían Hughes, Charles Lau, Justin Chen, Fereshteh\nMahvar, Liron Yatziv, Tiffany Chen, Bram Sterling, Stefanie Anna Baby, Susanna Maria Baby,\nJeremy Lai, Samuel Schmidgall, Lu Yang, Kejia Chen, Per Bjornsson, Shashir Reddy, Ryan\nBrush, Kenneth Philbrick, Mercy Asiedu, Ines Mezerreg, Howard Hu, Howard Yang, Richa\nTiwari, Sunny Jansen, Preeti Singh, Yun Liu, Shekoofeh Azizi, Aishwarya Kamath, Johan Ferret,\nShreya Pathak, Nino Vieillard, Ramona Merhej, Sarah Perrin, Tatiana Matejovicova, Alexandre\nRamé, Morgane Riviere, Louis Rouillard, Thomas Mesnard, Geoffrey Cideron, Jean bastien\nGrill, Sabela Ramos, Edouard Yvinec, Michelle Casbon, Elena Buchatskaya, Jean-Baptiste\nAlayrac, Dmitry Lepikhin, Vlad Feinberg, Sebastian Borgeaud, Alek Andreev, Cassidy Hardin,\nRobert Dadashi, Léonard Hussenot, Armand Joulin, Olivier Bachem, Yossi Matias, Katherine\nChou, Avinatan Hassidim, Kavi Goel, Clement Farabet, Joelle Barral, Tris Warkentin, Jonathon\nShlens, David Fleet, Victor Cotruta, Omar Sanseviero, Gus Martins, Phoebe Kirk, Anand Rao,\nShravya Shetty, David F. Steiner, Can Kirmizibayrak, Rory Pilgrim, Daniel Golden, and Lin\nYang. Medgemma technical report, 2025. URL https://arxiv.org/abs/2507.05201.\n[8] Nils Strodthoff, Temesgen Mehari, Claudia Nagel, Philip J Aston, Ashish Sundar, Claus\nGraff, Jørgen K Kanters, Wilhelm Haverkamp, Olaf Dössel, Axel Loewe, et al. Ptb-xl+, a\ncomprehensive electrocardiographic feature dataset. Scientific data, 10(1):279, 2023.\n[9] Gemma Team, Aishwarya Kamath, Johan Ferret, Shreya Pathak, Nino Vieillard, Ramona Merhej,\nSarah Perrin, Tatiana Matejovicova, Alexandre Ramé, Morgane Rivière, Louis Rouillard,\nThomas Mesnard, Geoffrey Cideron, Jean bastien Grill, Sabela Ramos, Edouard Yvinec,\nMichelle Casbon, Etienne Pot, Ivo Penchev, Gaël Liu, Francesco Visin, Kathleen Kenealy,\nLucas Beyer, Xiaohai Zhai, Anton Tsitsulin, Robert Busa-Fekete, Alex Feng, Noveen Sachdeva,\nBenjamin Coleman, Yi Gao, Basil Mustafa, Iain Barr, Emilio Parisotto, David Tian, Matan\nEyal, Colin Cherry, Jan-Thorsten Peter, Danila Sinopalnikov, Surya Bhupatiraju, Rishabh\nAgarwal, Mehran Kazemi, Dan Malkin, Ravin Kumar, David Vilar, Idan Brusilovsky, Jiaming\nLuo, Andreas Steiner, Abe Friesen, Abhanshu Sharma, Abheesht Sharma, Adi Mayrav Gilady,\nAdrian Goedeckemeyer, Alaa Saade, Alex Feng, Alexander Kolesnikov, Alexei Bendebury,\nAlvin Abdagic, Amit Vadi, András György, André Susano Pinto, Anil Das, Ankur Bapna,\nAntoine Miech, Antoine Yang, Antonia Paterson, Ashish Shenoy, Ayan Chakrabarti, Bilal\nPiot, Bo Wu, Bobak Shahriari, Bryce Petrini, Charlie Chen, Charline Le Lan, Christopher A.\nChoquette-Choo, CJ Carey, Cormac Brick, Daniel Deutsch, Danielle Eisenbud, Dee Cattle,\nDerek Cheng, Dimitris Paparas, Divyashree Shivakumar Sreepathihalli, Doug Reid, Dustin\nTran, Dustin Zelle, Eric Noland, Erwin Huizenga, Eugene Kharitonov, Frederick Liu, Gagik\n5\n"}, {"page": 6, "text": "Amirkhanyan, Glenn Cameron, Hadi Hashemi, Hanna Klimczak-Pluci´nska, Harman Singh,\nHarsh Mehta, Harshal Tushar Lehri, Hussein Hazimeh, Ian Ballantyne, Idan Szpektor, Ivan\nNardini, Jean Pouget-Abadie, Jetha Chan, Joe Stanton, John Wieting, Jonathan Lai, Jordi\nOrbay, Joseph Fernandez, Josh Newlan, Ju yeong Ji, Jyotinder Singh, Kat Black, Kathy Yu,\nKevin Hui, Kiran Vodrahalli, Klaus Greff, Linhai Qiu, Marcella Valentine, Marina Coelho,\nMarvin Ritter, Matt Hoffman, Matthew Watson, Mayank Chaturvedi, Michael Moynihan, Min\nMa, Nabila Babar, Natasha Noy, Nathan Byrd, Nick Roy, Nikola Momchev, Nilay Chauhan,\nNoveen Sachdeva, Oskar Bunyan, Pankil Botarda, Paul Caron, Paul Kishan Rubenstein, Phil\nCulliton, Philipp Schmid, Pier Giuseppe Sessa, Pingmei Xu, Piotr Stanczyk, Pouya Tafti,\nRakesh Shivanna, Renjie Wu, Renke Pan, Reza Rokni, Rob Willoughby, Rohith Vallu, Ryan\nMullins, Sammy Jerome, Sara Smoot, Sertan Girgin, Shariq Iqbal, Shashir Reddy, Shruti Sheth,\nSiim Põder, Sijal Bhatnagar, Sindhu Raghuram Panyam, Sivan Eiger, Susan Zhang, Tianqi Liu,\nTrevor Yacovone, Tyler Liechty, Uday Kalra, Utku Evci, Vedant Misra, Vincent Roseberry, Vlad\nFeinberg, Vlad Kolesnikov, Woohyun Han, Woosuk Kwon, Xi Chen, Yinlam Chow, Yuvein\nZhu, Zichuan Wei, Zoltan Egyed, Victor Cotruta, Minh Giang, Phoebe Kirk, Anand Rao, Kat\nBlack, Nabila Babar, Jessica Lo, Erica Moreira, Luiz Gustavo Martins, Omar Sanseviero, Lucas\nGonzalez, Zach Gleicher, Tris Warkentin, Vahab Mirrokni, Evan Senter, Eli Collins, Joelle\nBarral, Zoubin Ghahramani, Raia Hadsell, Yossi Matias, D. Sculley, Slav Petrov, Noah Fiedel,\nNoam Shazeer, Oriol Vinyals, Jeff Dean, Demis Hassabis, Koray Kavukcuoglu, Clement Farabet,\nElena Buchatskaya, Jean-Baptiste Alayrac, Rohan Anil, Dmitry, Lepikhin, Sebastian Borgeaud,\nOlivier Bachem, Armand Joulin, Alek Andreev, Cassidy Hardin, Robert Dadashi, and Léonard\nHussenot. Gemma 3 technical report, 2025. URL https://arxiv.org/abs/2503.19786.\n[10] Qwen Team. Qwen3 technical report, 2025. URL https://arxiv.org/abs/2505.09388.\n[11] Peter W Wood, Jonathan B Choy, Navin C Nanda, and Harald Becher. Left ventricular ejection\nfraction and volumes: it depends on the imaging method. Echocardiography, 31(1):87–100,\n2014.\n[12] Han Yu, Peikun Guo, and Akane Sano. Ecg semantic integrator (esi): A foundation ecg model\npretrained with llm-enhanced cardiological text, 2024. URL https://arxiv.org/abs/2405.\n19366.\n[13] Xiaohua Zhai, Basil Mustafa, Alexander Kolesnikov, and Lucas Beyer. Sigmoid loss for\nlanguage image pre-training. In Proceedings of the IEEE/CVF international conference on\ncomputer vision, pages 11975–11986, 2023.\n6\n"}, {"page": 7, "text": "5\nAppendix\n5.1\nLabels\nIn this study, the labels used for training is selected under the guidance of the cardiologists. These\nlabels are listed in Table 4. Note that the ground truth for lowEF, left ventricular hypertrophy, and left\natrial enlargement was obtained from echocardiography data not than from ECG.\nTable 4: ECG findings used in this study\nECG Findings\nLeft ventricular hypertrophy\nLeft atrial enlargement\nLow ejection fraction (lowEF)\nNormal range (Normal)\nProlonged QT interval\nTall T wave\nLeft axis deviation\nArtificial pacemaker rhythm\nIntraventricular conduction delay\nComplete right bundle branch block\nComplete left bundle branch block\nFlat T wave\nInverted T wave\nST-T abnormality\nPoor R wave progression\nAbnormal Q wave\nAnterior wall myocardial infarction\nLateral wall myocardial infarction\nInferior wall myocardial infarction\nAnterior septal myocardial infarction\nVentricular premature contraction\nFrequent ventricular premature contraction\nVentricular bigeminy\nVentricular tachycardia\nCouplet of ventricular premature contractions\nAtrial fibrillation\n5.2\nModified sigmoid loss\nWe improved the original loss (Listing 1) to enhance multi-label prediction performance.\n1\n# img_emb\n: image model embedding [n, dim]\n2\n# txt_emb\n: text model embedding [n, dim]\n3\n# t_prime, b : learnable temperature and bias\n4\n# n\n: mini-batch size\n5\n6\nt = exp(t_prime)\n7\nzimg = l2_normalize(img_emb)\n8\nztxt = l2_normalize(txt_emb)\n9\nlogits = dot(zimg, ztxt.T) * t + b\n10\nlabels = 2 * eye(n) - ones(n) # -1 with diagonal 1\n11\nl = -sum(log_sigmoid(labels * logits)) / n\nListing 1: Original Sigmoid loss pseudo-implementation.\nSpecifically, we modified the eye component in Listing 1. The original eye is defined as a diagonal\nmatrix\neye = {E ∈{0, 1}n×n | Eii = 1, Eij = 0 (i ̸= j)},\n(1)\n7\n"}, {"page": 8, "text": "that is, a matrix whose diagonal entries are one and off-diagonal entries are zero. The entries of one\ncorrespond to positive labels, whereas the zeros represent negative labels. This implies that the i-th\nECG finding is considered positive only for the i-th label.\nHowever, it can easily occur that the patients with the same diseases are included in the same batch.\nWe then modified the eye in Eq. 1 based on the similarity of ECG findings among patients within a\nbatch.\nWe employed the Jaccard similarity to represent the similarity of these ECG findings. The modified\neye is defined as in Eq. 2, where the set of ECG findings for the i-th data is denoted by Ai and that\nfor the j-th data is denoted by Aj.\nJaccard(Ai, Aj) = |Ai ∩Aj|\n|Ai ∪Aj|,\neyeij = Jaccard(Ai, Aj),\n∀i, j ∈{1, . . . , n},\n(2)\nThe Jaccard similarity satisfies 0 ≤Jaccard(Ai, Aj) ≤1, Jaccard(Ai, Aj) = Jaccard(Aj, Ai),\nand Jaccard(Ai, Aj) = 1 when i = j. Here, a value of Jaccard(Ai, Aj) closer to 1 indicates that\nthe patients have more similar diseases. Using the modified eye defined in Eq. 2, we conducted the\nexperiments in this study.\n5.3\nAppendix: Individual Label Metrics 5\nTable 5: Classification performance for each label of the final model\nLabel\nAccuracy\nPrecision\nRecall\nF1-Score\nlowEF\n0.9138\n0.5038\n0.5271\n0.5152\nNormal\n0.9091\n0.8054\n0.5526\n0.6555\nProlonged QT\n0.9368\n0.5161\n0.2753\n0.3590\nTall T wave\n0.9842\n0.1471\n0.1515\n0.1493\nLeft axis deviation\n0.9296\n0.3872\n0.5884\n0.4670\nLeft atrial enlargement\n0.7949\n0.4000\n0.3336\n0.3638\nLeft ventricular hypertrophy\n0.7404\n0.5932\n0.4410\n0.5059\nArtificial pacemaker rhythm\n0.9804\n0.6564\n0.6995\n0.6773\nIntraventricular conduction delay\n0.9578\n0.1085\n0.1655\n0.1311\nComplete right bundle branch block\n0.9674\n0.8351\n0.7607\n0.7962\nComplete left bundle branch block\n0.9737\n0.4138\n0.8571\n0.5581\nFlat T wave\n0.8808\n0.5251\n0.5849\n0.5534\nInverted T wave\n0.9355\n0.5065\n0.4140\n0.4556\nST-T abnormality\n0.9122\n0.8242\n0.6239\n0.7102\nPoor R wave progression\n0.9339\n0.4179\n0.6062\n0.4947\nAbnormal Q wave\n0.9553\n0.0234\n0.0420\n0.0300\nAnterior wall myocardial infarction\n0.9314\n0.0422\n0.3226\n0.0746\nLateral wall myocardial infarction\n0.9423\n0.0382\n0.2778\n0.0671\nInferior wall myocardial infarction\n0.9380\n0.1887\n0.4348\n0.2632\nAnterior septal myocardial infarction\n0.9426\n0.1771\n0.4551\n0.2549\nVentricular premature contraction\n0.9163\n0.3149\n0.3242\n0.3195\nFrequent ventricular premature contraction\n0.9751\n0.4298\n0.3190\n0.3662\nVentricular bigeminy\n0.9777\n0.1020\n0.3409\n0.1571\nVentricular tachycardia\n0.9665\n0.0000\n0.0000\n0.0000\nCouplet of ventricular premature contractions\n0.9672\n0.0314\n0.1034\n0.0482\nAtrial fibrillation\n0.9685\n0.8971\n0.8700\n0.8833\n8\n"}, {"page": 9, "text": "5.4\nAppendix: ROC curves\n9\n"}, {"page": 10, "text": "10\n"}, {"page": 11, "text": "5.5\nEvaluation on data from a different medical institution\nWe performed inference using data from a medical institution different from the one used for training\nin the paper, in order to examine the degradation in performance caused by differences in data\ndistribution. Note that the dataset from this institution did not include any positive cases for Left\nAtrial enlargement or Frequent ventricular premature contractions.\nTable 6: Results of the different institutions\nMetric\nOriginal dataset\nDifferent dataset\nHamming Loss\n0.0680 ↓\n0.0536 ↓\nPrecision (Micro)\n0.4898 ↑\n0.4601 ↑\nRecall (Micro)\n0.5165 ↑\n0.5107 ↑\nF1 Score (Micro)\n0.5028 ↑\n0.4841 ↑\nJaccard Index\n0.3495 ↑\n0.3360 ↑\nTable 7: Classification performance for each label of different dataset\nLabel\nAccuracy\nPrecision\nRecall\nF1-score\nlowEF\n0.9264\n0.5483\n0.4504\n0.4946\nNormal\n0.8793\n0.8056\n0.6121\n0.6956\nProlonged QT\n0.9531\n0.3803\n0.1421\n0.2069\nTall T wave\n0.9878\n0.1471\n0.1667\n0.1563\nLeft axis deviation\n0.9443\n0.3804\n0.5243\n0.4409\nLeft atrial enlargement\n0.9110\n0.0000\n0.0000\n0.0000\nLeft ventricular hypertrophy\n0.7525\n0.4535\n0.3595\n0.4011\nArtificial pacemaker rhythm\n0.9660\n0.4909\n0.3649\n0.4186\nIntraventricular conduction delay\n0.9724\n0.0833\n0.1905\n0.1159\nComplete right bundle branch block\n0.9649\n0.8281\n0.6901\n0.7528\nComplete left bundle branch block\n0.9812\n0.3333\n0.8444\n0.4780\nFlat T wave\n0.8922\n0.5204\n0.5141\n0.5172\nInverted T wave\n0.9420\n0.4643\n0.4333\n0.4483\nST-T abnormality\n0.9257\n0.7807\n0.5848\n0.6687\nPoor R wave progression\n0.9527\n0.4007\n0.6859\n0.5059\nAbnormal Q wave\n0.9740\n0.0172\n0.0169\n0.0171\nAnterior wall myocardial infarction\n0.9570\n0.0407\n0.2188\n0.0686\nLateral wall myocardial infarction\n0.9581\n0.1043\n0.3036\n0.1553\nInferior wall myocardial infarction\n0.9570\n0.1477\n0.3939\n0.2149\nAnterior septal myocardial infarction\n0.9663\n0.1489\n0.4200\n0.2199\nVentricular premature contraction\n0.9567\n0.4213\n0.4601\n0.4399\nFrequent ventricular premature contraction\n0.9798\n0.0000\n0.0000\n0.0000\nVentricular bigeminy\n0.9835\n0.0909\n0.3158\n0.1412\nVentricular tachycardia\n0.9703\n0.0000\n0.0000\n0.0000\nCoupled ventricular premature contraction\n0.9740\n0.0364\n0.3077\n0.0650\nAtrial fibrillation\n0.9783\n0.8721\n0.8766\n0.8743\n11\n"}, {"page": 12, "text": "5.6\nAppendix: ROC curves of different data\n12\n"}, {"page": 13, "text": "13\n"}, {"page": 14, "text": "5.7\nAblation Study: Comparison with a ResNet-Based Multilabel Classification Model\nAs an ablation study, we used a ResNet-1D model for multilabel prediction. The model was trained\nfor 600 epochs with a learning rate of 1e-4 and a batch size of 32. As described, we applied data\naugmentation to the training set using random cropping. Since training can become unstable when\nonly a small number of samples are available for certain labels, we weighted the loss according to the\nlabel distribution.\nTable 8: Performance comparison of baseline and a ResNet-based multi-label model\nMetric\nSigLIP Embedding dim 256\n+ random crop\n(600 epoch, 20k warmup)\nResNet-based multi-label model\n+ random crop\nHamming Loss\n0.0680 ↓\n0.1854 ↓\nPrecision (Micro)\n0.4898 ↑\n0.2444 ↑\nRecall (Micro)\n0.5165 ↑\n0.8526 ↑\nF1 Score (Micro)\n0.5028 ↑\n0.3799 ↑\nJaccard Index\n0.3495 ↑\n0.2641 ↑\nAs shown in Table 8, the proposed SigLIP-based method achieved a higher F1 score than a ResNet-\nbased multi-label classification. This improvement is likely because multimodal training allows\nthe model to leverage features embedded in the text, enabling more accurate inference even with a\nsmaller number of ECG findings.\n14\n"}]}