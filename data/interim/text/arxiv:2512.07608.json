{"doc_id": "arxiv:2512.07608", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2512.07608.pdf", "meta": {"doc_id": "arxiv:2512.07608", "source": "arxiv", "arxiv_id": "2512.07608", "title": "Metric-Fair Prompting: Treating Similar Samples Similarly", "authors": ["Jing Wang", "Jie Shen", "Xing Niu", "Tong Zhang", "Jeremy Weiss"], "published": "2025-12-08T14:56:46Z", "updated": "2025-12-08T14:56:46Z", "summary": "We introduce \\emph{Metric-Fair Prompting}, a fairness-aware prompting framework that guides large language models (LLMs) to make decisions under metric-fairness constraints. In the application of multiple-choice medical question answering, each {(question, option)} pair is treated as a binary instance with label $+1$ (correct) or $-1$ (incorrect). To promote {individual fairness}~--~treating similar instances similarly~--~we compute question similarity using NLP embeddings and solve items in \\emph{joint pairs of similar questions} rather than in isolation. The prompt enforces a global decision protocol: extract decisive clinical features, map each \\((\\text{question}, \\text{option})\\) to a score $f(x)$ that acts as confidence, and impose a Lipschitz-style constraint so that similar inputs receive similar scores and, hence, consistent outputs. Evaluated on the {MedQA (US)} benchmark, Metric-Fair Prompting is shown to improve performance over standard single-item prompting, demonstrating that fairness-guided, confidence-oriented reasoning can enhance LLM accuracy on high-stakes clinical multiple-choice questions.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2512.07608v1", "url_pdf": "https://arxiv.org/pdf/2512.07608.pdf", "meta_path": "data/raw/arxiv/meta/2512.07608.json", "sha256": "28ba42e0e3a7bf525df2ed0cd702abdcdc40066fce4196fc26fe3a183d71c967", "status": "ok", "fetched_at": "2026-02-18T02:24:44.429577+00:00"}, "pages": [{"page": 1, "text": "Metric-Fair Prompting: Treating Similar Samples\nSimilarly\nJing Wang\nNLM\njing.wang20@nih.gov\nJie Shen\nStevens Institute of Technology\njie.shen@stevens.edu\nXing Niu\nAWS AI\nxingniu@amazon.com\nTong Zhang\nUniversity of Illinois Urbana-Champaign\ntongzhang@tongzhang-ml.org\nJeremy Weiss\nNLM\njeremy.weiss@nih.gov\nAbstract\nWe introduce Metric-Fair Prompting, a fairness-aware prompting framework that\nguides large language models (LLMs) to make decisions under metric-fairness\nconstraints. In the application of multiple-choice medical question answering, each\n(question, option) pair is treated as a binary instance with label +1 (correct) or −1\n(incorrect). To promote individual fairness – treating similar instances similarly –\nwe compute question similarity using NLP embeddings and solve items in joint\npairs of similar questions rather than in isolation. The prompt enforces a global\ndecision protocol: extract decisive clinical features, map each (question, option)\nto a score f(x) that acts as confidence, and impose a Lipschitz-style constraint so\nthat similar inputs receive similar scores and, hence, consistent outputs. Evaluated\non the MedQA (US) benchmark, Metric-Fair Prompting is shown to improve\nperformance over standard single-item prompting, demonstrating that fairness-\nguided, confidence-oriented reasoning can enhance LLM accuracy on high-stakes\nclinical multiple-choice questions.\n1\nIntroduction\nMachine learning systems may disadvantage certain populations when fairness is not addressed\n[6, 2, 3]. Such concern recently extends to large language models (LLMs), and is increasingly\nobserved in high-stakes domains such as clinical decision making and medical examinations. In such\nsettings, it is crucial to promote individual fairness, i.e. treating similar instances similarly, and to\nbase predictions on clinically determinative features rather than sensitive attributes (e.g. age, gender,\nrace) unless those attributes are explicitly and directly relevant to the clinical task.\nWe study one of the most important problems: multiple-choice medical question answering (MedQA)\n[10], casting each (question, option) pair as a binary classification task (+1 for correct, −1 for\nincorrect). We introduce Metric-Fair Prompting, a prompting framework that guides an LLM under\na metric-fairness constraint. Concretely, we (i) compute similarity among questions using text\nembeddings to identify pairs of deterministically similar items; (ii) present similar questions jointly\nso the model can enforce cross-item consistency; and (iii) ask the model to extract decisive clinical\nfeatures and map each pair (question, option) to a score f(x) whose magnitude can be thought of\nas confidence, similar to the margin in support vector machines. Technically, the metric-fairness is\nimposed under Lipschitz constraints on samples: if two inputs (x, x′) are close under a task-relevant\nmetric d(x, x′), then their scores would remain close, encouraging consistent outcomes for clinically\nsimilar cases [6].\n39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Metric-Fair Prompting:\nTreating Similar Samples Similarly.\narXiv:2512.07608v1  [cs.CL]  8 Dec 2025\n"}, {"page": 2, "text": "Q1: the patient \nis a 28 years \nold women, she \nhas taken Covid \nand flu vaccine \ntwo weeks, she \nexperienced \nfatigue, hard to \nfall asleep.\nOption A\nOption B\nOption C\nOption D\nOption E\nQ2: the patient is \na 32 years old \nman, he has taken \nCovid and flu \nvaccine one week \nago. Since then, \nhe reports \npersistent dry \ncough, daytime \nfatigue, \ndepression.\nOption A\nOption B\nOption C\nOption D\nOption E\nQ1, A1\nQ3: the patient is \na 68 years old \nman, comes to the \nphysician because \nof a 10-day \nhistory of fatigue \nand lower leg \nswelling. Over the \npast 6 months, he \nhas had a 3.6-kg \n(8-lb) weight loss\nOption A\nOption B\nOption C\nOption D\nOption E\nQ1, B1\nQ1, C1\nQ1, D1\nQ1, E1\nQ2, B2\nQ2, A2\nQ2, C2\nQ2, D2\nQ2, E2\nQ3, D3\nQ3, A3\nQ3, C3\nQ3, B3\nQ3, E3\nd\nd+s\nd+s+p\nDecision boundary\nDecision boundary\nDecision boundary\nFigure 1: Geometric view of Metric-Fair Prompting. Questions 1 and 2 are highly similar (small\nmetric distance d); their correct options lie on the same side of the decision boundary with nearby\nmargins d and d + s (s > 0 small). Question 3 is less similar to Question 1 (larger distance d + s,\np > 0): its correct option remains in the same half-space but with a more separated margin d + s + p.\nThe metric-fair (Lipschitz-like) constraint encourages similar items to receive similar scores and thus\nconsistent decisions.\nOur approach complements prior prompt-engineering methods that improve reasoning via intermedi-\nate structure, such as chain-of-thought [22], self-consistency [21], and search-based prompting (e.g.,\nTree-of-Thoughts [24] and ReAct [25]). However, unlike these techniques that often typically treat\nitems independently and optimize intra-item reasoning, Metric-Fair Prompting explicitly introduces\nan inter-item coupling via a similarity metric, thereby promoting fairness through stability to small,\nclinically irrelevant changes.\nFigure 1 shows an illustrative example. Questions 1 and 2 exhibit high similarity under the embedding\nmetric (small d); the questions together with correct options are mapped to nearby points in a hyper-\nplane. By contrast, Question 3 is less similar to Question 1 (larger d); although its correct option falls\non the same side of the decision boundary, it lies farther from Question 1’s point in the range space.\nMain contributions.\n(1) We propose a fairness-aware prompting framework that treats MedQA as\nbinary classification over (question, option) pairs and enforces a metric-based Lipschitz constraint\nto encourage individual fairness. (2) We introduce a joint-inference protocol that feeds pairs of\nsimilar questions to the LLM, enabling cross-item consistency and reducing near-boundary errors.\n(3) On MedQA (US), the proposed protocol improves accuracy over single-item prompting (see\ndetails in Section 4), showing that fairness-guided, confidence-oriented reasoning can enhance LLM\nperformance in clinical multiple-choice settings.\n2\n"}, {"page": 3, "text": "Table 1: MedQA–US examples: two patients with similar deterministic features yield similar correct\noptions.\nItem\nContent\nQuestion 1 (Q1)\nA 62-year-old man presents with 5 days of fatigue, fever, and chills. He has a 9-\nmonth history of hand pain and stiffness and started a new medication 3 months ago;\nprior meds included ibuprofen, prednisone, and hydroxychloroquine. He does not\nsmoke or drink. Exam: subcutaneous nodule at left elbow, old joint destruction with\nboutonnière deformity, no active synovitis. Labs: Hb 10.5 g/dL, WBC 3500/mm3,\nplatelets 100,000/mm3. Which of the following is most likely to have prevented these\nlaboratory abnormalities?\nOptions for Q1\nA) Cobalamin\nB) Amifostine\nC) Pyridoxine\nD) Leucovorin\nE) Mesna\nQuestion 2 (Q2)\nA 58-year-old woman presents with 1 week of worsening fatigue and a 1-year history\nof hand pain and stiffness. She started a new medication 4 months ago; prior meds\nincluded ibuprofen, prednisone, and hydroxychloroquine. Exam: subcutaneous\nnodule at left elbow, old joint destruction with Boutonnière deformity. Labs: Hb 10.1\ng/dL, WBC 3400/mm3, platelets 101,000/mm3; methylmalonic acid normal. Which\nof the following could have prevented these laboratory abnormalities?\nOptions for Q2\nA) Vitamin B6\nB) Vitamin B12\nC) Amifostine\nD) 2-Mercaptoethanesulfonate\nE) Leucovorin\nDeterministic features\nRA phenotype + new DMARD started months earlier + pancytopenia (anemia,\nleukopenia, thrombocytopenia) + normal MMA ⇒methotrexate-related folate path-\nway toxicity. Prevention: folate supplementation or folinic acid (leucovorin) rescue.\nCorrect answers\nQ1: D\nQ2: E\nFigure 2: Correlations between the options of\nQuestion 1 and Question 2 in Table 1 by Qwen3-\n8B embedding.\nFigure 3: Correlations between questions and\noptions from Table 1 by Qwen3-8B embedding.\n2\nProblem Setup\nWe study metric-fair learning on a domain X endowed with a similarity metric d : X ×X →[0, 1]. A\nlearning algorithm receives d and a set of i.i.d. samples from a distribution D over labeled examples\n(x, y) ∈X × {±1} and outputs a classifier. To accommodate fairness, we focus on probabilistic\nclassifiers h : X →[0, 1] and interpret h(x) as the probability of label +1 (so the probability of −1\nequals 1 −h(x)). We refer to such probabilistic classifiers as predictors.\nWe consider fairness as treating similar individuals similarly: two individuals that are close under d\nshould receive similar predictions. To this end, we consider learning score function f : X →R that\nis Lipschitz in the following sense.\nDefinition 1 (Lipschitz mapping). Let D be some metric on R. A mapping f : X →R satisfies the\n(D, d)-Lipschitz property if for all x, x′ ∈X,\nD\n\u0000f(x), f(x′)\n\u0001\n≤d(x, x′).\n(1)\n3\n"}, {"page": 4, "text": "When D and d are clear from context we simply say that f is Lipschitz.\nGiven a loss function L : R × {±1} →R≥0, our goal is to find a mapping f that minimizes expected\nloss subject to the Lipschitz fairness constraint. This naturally leads to the optimization problem:\nmin\nf\nE(x,y)∼DL(f(x), y)\ns.t.\nD\n\u0000f(x), f(x′)\n\u0001\n≤d(x, x′) ∀x, x′ ∈X.\n(2)\nFor intuition we connect to linear classification. The goal is to learn a weight vector w ∈Rd such\nthat the prediction sign(w · x) agrees with the label y for (x, y) drawn from D. In this case, f is\nparameterized by w: it maps x to w · x. For logistic regression, this score f(x) will be fed to the\nsigmoid function to obtain the probability distribution of labels. In both cases, it is common to choose\nD(·, ·) as the absolute function and d as certain norm.\nIn our application to multiple-choice medical QA, each option paired with its question is treated as\nan input x, and the classifier maps (question, option) to {−1, 1} (incorrect versus correct). Metric\nfairness requires that if two question–option pairs are similar under d, then their predictive distribu-\ntions (and thus their distances to the decision boundary) should also be similar; conversely, dissimilar\npairs shall receive different predictions.\n3\nOur Approach\nMotivation.\nIn complex reasoning tasks such as medical examinations, distinct items can exhibit\nsubstantial semantic and clinical overlap. As illustrated in Table 1, two stems may share deterministic\nfeatures (e.g., key signs, pathognomonic labs), and consequently their correct options tend to align\n[18]. Such prior knowledge is taken into our algorithmic design by computing similarity between\nquestions and between (question, option) pairs using sentence embedding models (e.g., Qwen3-4B).\nEmpirically, the correct option for a given stem has higher similarity to the stem than distractors,\nand stems that are similar under the embedding metric d(·, ·) often share clinically consistent answer\npatterns.\nOverview.\nWe propose Metric-Fair Prompting, a joint-inference protocol that treats each\n(question, option) as a binary instance and guides the LLM to behave like a margin-based clas-\nsifier under a metric-fairness constraint. Recall that f : X →R is a score function. The predicted\nlabel is y = 1{f(x) > α} for some pre-determined threshold α; for example, α = 1/2 in logistic\nregression.\nPipeline.\nGiven a set of samples, our approach consists of five major steps:\n(i) Pair selection. Embed all stems; for each stem select its nearest neighbor under d(·, ·) to form a\ntwo-item batch (high-similarity pair).\n(ii) Metric fairness. Instruct the LLM that similar items should yield similar decisions (Lipschitz-like\nconstraint), and that decisions must rely on clinically determinative features rather than sensitive\nattributes.\n(iii) Margin/half-space reasoning. For each (question, option), compute the score f(x). Then,\neliminate clear negatives (large negative margin), and deal with near-boundary candidates using\ndecisive clinical discriminators (guidelines, pathognomonic findings, contraindications).\n(iv) Cross-item consistency. Reconcile near ties within the pair by preferring choices that maintain\nconsistency across similar items under d(·, ·).\n(v) Strict output. Emit only machine-parsable results (e.g., JSON with {\"index\":\ni, \"answer\":\n\"A|B|C|D|E\"} for i ∈{1, 2}).\nJointly presenting similar items introduces an inter-item coupling that stabilizes decisions near the\nboundary, encourages fairness via Lipschitz stability, and reduces reliance on spurious cues. This\nconfidence-informed, metric-fair prompting improves robustness on clinically proximate stems while\npreserving a strict, parseable interface for evaluation.\n4\n"}, {"page": 5, "text": "Table 2: Metric-Fair Prompt with a Binary Margin Classifier.\nObjective\nRead both questions and their options jointly; decide one option (A–E) per\nquestion. Output {\"index\":\ni, \"answer\":\n\"A|B|C|D|E\"} for each i ∈\n{1, 2} (JSON only).\nFormulation\nConsider potential correlation between the two questions. Identify deterministic\nclinical features that may be shared by the patients/situations. Items that are\nsimilar under a task-relevant metric should receive similar decisions (fairness-by-\nsimilarity).\nFeature selection\nFor each question, extract the most important features from the stem (signs, key\nlabs/imaging, contraindications, guideline thresholds). For each option, form a\nfeature representation x = ϕ(question, option).\nMargin-based classifier\nUse a binary large-margin classifier f : X →R on x. The predicted label is\ny = 1{f(x) > 0} ∈{0, 1} (1 = correct), with confidence magnitude |f(x)|.\nSelect, for each question, the option with the largest positive margin.\nFairness\nLet d : X × X →[0, 1] be a similarity metric on question–option pairs.\nEnforce a Lipschitz-like constraint so that similar inputs yield similar scores. If\ntwo questions are similar in decisive clinical features, prefer consistent answer\npatterns unless a clear clinical conflict exists.\nCross-item reconciliation\nIf two options (within or across the two questions) are near the decision bound-\nary, re-check decisive discriminators and prefer the choice that maintains cross-\nitem consistency under d(·, ·) and standard clinical guidance.\nOutput format\nJSON only, no prose. Example:\n[ {\"index\":\n1, \"answer\":\n\"C\"}, {\"index\":\n2, \"answer\":\n\"A\"} ]\n4\nExperiments\nSetup.\nAll experiments were conducted on a single NVIDIA RTX 6000 Ada.1 We evaluate\nQwen models [1] from HuggingFace (via transformers) with Unsloth optimizations for effi-\ncient inference. Unless stated otherwise, we use a low temperature (T=0.2) and greedy decoding\n(do_sample=False) to stabilize multiple–choice predictions.\nDataset.\nWe use the MedQA (US) test split (N=1,273 items), each with one correct option (A–E).\nWe frame each (question, option) as a binary instance (correct vs. incorrect).\nSimilarity and pairing.\nWe embed every question with Qwen3-4B embedding and compute cosine\nsimilarity. For each question q, we select its nearest neighbor q′ (excluding itself) to form a two-item\nbatch (q, q′). This produces N pairs (some questions may appear in multiple pairs as a neighbor).\nThe top-3 example pairs by similarity have scores 0.9612, 0.9020, and 0.8314.\nPrompting protocol.\nWe apply the Metric-Fair Prompting template in Table 2: (i) jointly read\nboth questions; (ii) enforce a metric-fair (Lipschitz-like) constraint over similar items; (iii) use a\nmargin/half-space decision rule over (question, option) features; (iv) reconcile near-boundary choices\nto maintain cross-item consistency; and (v) output strict JSON containing only the two answers.\nConflict resolution.\nBecause a question can appear in multiple pairs, it may receive two predictions.\nWhen predictions disagree, we trigger a light-weight review prompt that asks the model to re-evaluate\nboth items jointly and to output (A-E) with a scalar confidence. We keep the answer with higher\nconfidence; if confidences tie, we prefer the answer with larger decision margin (when available) or\nfall back to the original single-item prediction.\nBaselines and metric.\nThe main baseline is single-item prompting (standard instruction, one\nquestion at a time). We report accuracy (%) on the test split.\n1No multi-GPU or model parallelism was used.\n5\n"}, {"page": 6, "text": "Five days after undergoing an emergency appendectomy under \ngeneral inhalational anesthesia while on a trip to Haiti, a 43-year-old woman \ndevelops low-grade fever, vomiting, and abdominal pain. During the surgery, she \nreceived a transfusion of 1 unit of packed red blood cells. Three days after the \nsurgery, she was stable enough to be transported back to the United States. She \nhas no history of serious illness and takes no medications. Her temperature is \n38.3°C (100.9°F), pulse is 80/min, and blood pressure is 138/76 mm Hg. \nExamination shows jaundice of the skin and conjunctivae. Abdominal examination \nshows moderate tenderness over the liver. The liver is palpated 2 to 3 cm below \nthe right costal margin. Laboratory studies show:\\nHemoglobin count 12.0 g/\ndL\\nLeukocyte count 10,400 mm3\\nSegmented neutrophils 55%\\nBands 1%\n\\nEosinophils 13%\\nLymphocytes 28%\\nMonocytes 3%\\nPlatelet count 160,000 \nmm3\\nSerum\\nAlkaline phosphatase 102 U/L\\nAspartate aminotransferase 760 U/\nL\\nBilirubin\\nTotal 3.8 mg/dL\\nDirect 3.1 mg/dL\\nAnti-HAV IgG positive\\nAnti-HAV \nIgM negative\\nAnti-HBs positive\\nHBsAg negative\\nAnti-HCV antibodies \nnegative\\nAbdominal ultrasonography shows an enlarged liver. A biopsy of the \nliver shows massive centrilobular necrosis. Which of the following is the most \nlikely underlying cause of this patient\\'s condition?\nA 48-year-old woman comes to the emergency department \nbecause of a 1-day history of fever, vomiting, and abdominal \npain. Two weeks ago, while visiting Guatemala, she had an \nemergency appendectomy under general inhalational anesthesia. \nDuring the surgery, she received a transfusion of 1 unit of packed \nred blood cells. Her temperature is 38.3°C (100.9°F) and blood \npressure is 138/76 mm Hg. Examination shows jaundice and \ntender hepatomegaly. Serum studies show:\\nAlkaline \nphosphatase 102 U/L\\nAspartate aminotransferase 760 U/\nL\\nBilirubin\\nTotal 3.8 mg/dL\\nDirect 3.1 mg/dL\\nAnti-HAV IgG \npositive\\nAnti-HAV IgM negative\\nAnti-HBs positive\\nHBsAg \nnegative\\nAnti-HCV antibodies negative\\nAbdominal \nultrasonography shows an enlarged liver. A biopsy of the liver \nshows massive centrilobular necrosis. Which of the following is \nthe most likely underlying cause of this patient\\'s condition?\nBoth questions are **identical in clinical features**, **lab results**, and **biopsy findings**.  The only difference is the **patient’s age** (43 \nvs. 48), but **age is not a distinguishing factor** in the differential. The **most important features** are: **Centrilobular necrosis** (points to \n**toxic/metabolic liver injury**)\n- **No evidence of viral hepatitis** (HBV, HCV, or acute HAV)\n- **No cholestatic features** (ALP not elevated)\n- **Recent transfusion and anesthesia**\n- Similar to Question 1, but the patient is 48 years old and the \nappendectomy was 2 weeks ago in Guatemala.  \n- Same lab findings: elevated AST, direct bilirubin, anti-HAV IgG \npositive, anti-HAV IgM negative, anti-HBs positive, HBsAg \nnegative, anti-HCV negative.  \n- Same liver biopsy: centrilobular necrosis. \n- An emergency appendectomy with general anesthesia in Haiti.  \n- Received 1 unit of packed RBCs.  \n- Symptoms: fever, vomiting, abdominal pain, jaundice, hepatomegaly.  \n- Lab findings: elevated AST (760 U/L), direct bilirubin (3.1 mg/dL), \nanti-HAV IgG positive, anti-HAV IgM negative, anti-HBs positive, \nHBsAg negative, anti-HCV negative.  \n- Liver biopsy: centrilobular necrosis.\nMost important features\nMost important features\nCorrelation between Questions\nA: Adverse effect of anesthetic  \nB: Gram-negative bacteria in the bloodstream  \nC: Trauma to the bile duct  \nD: Acalculous inflammation of the gallbladder  \nE: Excessive lysis of red blood cells  \nA: Acalculous inflammation of the gallbladder  \nB: Virus-mediated hepatocellular injury  \nC: Trauma to the bile duct  \nD: Adverse effect of anesthetic  \nE: Gram-negative bacteria in the bloodstream  \n### Final Answers:  \n- **Question 1 (Index: 1):** **A**  \n- **Question 2 (Index: 2):** **D**\nFigure 4: Example of LLM output for two questions with cosine similarity 0. 9612 (embedding by\nQwen3-4B embedding) given our prompt. The two patients are identical in clinical features, lab\nresults and biopsy findings. The only difference is the age, which is not a distinguishing factor. Hence\nthe correct option is same, “Adverse effect of anesthetic”.\nTable 3: MedQA (US) test accuracy (%). Qwen3-14B with Metric-Fair Prompting substantially\noutperforms single-item prompting.\nModel / Prompt\nSingle-item\nMetric-Fair (two-item)\nQwen3-14B\n68.0\n84.0\nResults.\nMetric-Fair Prompting with Qwen3-14B improves accuracy from 68% (single-item) to\n84% (two-item, metric-fair, joint inference), demonstrating that coupling similar items via a fairness-\naware, margin-oriented protocol yields substantial gains on near-boundary decisions and promotes\ncross-item consistency.\n4.1\nQualitative Examples\nWe illustrate how Metric-Fair Prompting enforces cross-item consistency and fairness on three\nhighly similar question pairs selected by cosine similarity of stem embeddings (Qwen3-4B). In each\ncase, the model reads both items jointly, extracts decisive clinical/statistical features, and applies a\nmargin-based decision with a Lipschitz-like stability constraint.\n6\n"}, {"page": 7, "text": "Please refer to the summary above to answer this \nquestion\\nA medical student is examining the table in the \nabstract. She notices that the standard error surrounding \nmeasurements in the pulmharkimab 150 mg/day group is \ngenerally greater than the standard errors for the placebo \nand pulmharkimab 75 mg/day groups. Which of the \nfollowing statements is the best explanation for the \nincreased standard error in the pulmharkimab 150 mg/day \ngroup?\"\\n\"Impact of pulmharkimab on asthma control and \ncardiovascular disease progression in patients with \ncoronary artery disease and comorbid \nasthma\\nIntroduction:\\nActive asthma has been found to be \nassociated with a more than two-fold increase in the risk of \nmyocardial infarction, even after adjusting ......\nPlease refer to the summary above to answer this question\\nA \ncardiologist at another institution is trying to replicate the table in \nthe abstract with a very similar study that he is conducting. After \ncollecting data on changes in plaque volume, LDL-C levels, FEV1/\nFVC ratio, and ACQ scores from baseline to 12-month follow-up, \nhe is curious if the changes in the aforementioned measurements \nare statistically significant. Which of the following is the most \nappropriate statistical method to compare the groups?\"\\n\"Impact of \npulmharkimab on asthma control and cardiovascular disease \nprogression in patients with coronary artery disease and comorbid \nasthma\\nIntroduction:\\nActive asthma has been found to be \nassociated with a more than two-fold increase in the risk of \nmyocardial infarction, even after adjusting for cardiovascular risk \nfactors. It has been suggested that the inflammatory mediators \nand accelerated .....\n Both questions refer to the **same study abstract**.\n- The first question is about **interpretation of standard error** (which relates to sample size and variability).\n- The second question is about **statistical method** to determine **significance** of group differences.\n- The **sample size** is a **key factor** in the first question (which explains the standard error).\n- The **ANOVA** is the correct method in the second question, given that it is a **randomized controlled trial** with **multiple continuous \noutcomes**.\n- The goal is to determine **statistical significance** of \n**changes** in **continuous variables** (plaque volume, LDL-C, \nFEV1/FVC, ACQ scores).\n- The question is about **comparing multiple groups** (placebo \nvs. two doses of pulmharkimab) on **continuous outcomes**.\n- The data is **normally distributed** (as stated in the abstract).\n- **Standard error** is **greater** in the **150 mg/day** group.\n- The question is asking for the **reason** for this increased standard \nerror.\n- The options relate to **interpretation of standard error** in terms of \n**sample size, validity, statistical significance, confidence intervals**, \netc.\"\nMost important features\nMost important features\nCorrelation between Questions\nA:It indicates an increased likelihood of bias \nB: It indicates decreased external validity \nC: It indicates a lack of statistical significance \nD: It reflects a smaller sample size \nE: It indicates more narrow confidence intervals\nA:Pearson correlation analysis \nB: Chi-square test \nC: Analysis of variance \nD: Meta-analysis \nE: Kaplan-Meier analysis\n### Final Answers:  \n- **Question 1 (Index: 1):** **D**  \n- **Question 2 (Index: 2):** **C**\nFigure 5: Example of LLM output for two questions with cosine similarity 0.9020 (embedding by\nQwen3-4B embedding) given our prompt. Both questions refer to the same study abstract. The first\nquestion is about interpretation of standard error (which relates to sample size and variability). The\nsecond question is about statistical method to determine significance of group differences.\nNear-duplicate clinical stems (cosine = 0.9612).\nFigure 4 shows two stems that are clinically\nindistinguishable with respect to decisive features (symptoms, exam, labs, biopsy). The only differ-\nence is age, which is not determinative for the underlying mechanism queried. Under the metric-fair\nconstraint, the model maps both (question, option) pairs to nearby points in the half-space and selects\nthe same correct option, Adverse effect of anesthetic. This demonstrates: (i) individual fairness:\nsimilar items receive similar scores/decisions; (ii) demographic robustness: age is ignored when it\nis not clinically decisive; and (iii) boundary stability: small semantic perturbations do not flip the\ndecision.\nShared evidence, different foci (cosine = 0.9020).\nIn Figure 5, both stems reference the same study\nabstract but ask distinct, yet related questions: one on interpretation of the standard error (sample\nsize/variability), the other on choosing an inferential method for group differences. Joint presentation\nencourages the model to: (a) build a single internal representation of the study’s statistical structure;\n(b) project each item to the appropriate decision subspace (interpretation vs. method); and (c) preserve\ncross-item consistency (e.g., larger n ⇒smaller SE; appropriate test tied to design/assumptions). The\npairwise setting reduces near-boundary errors that arise when interpreting an abstract in isolation.\nTrauma mechanism coherence (cosine = 0.8314).\nFigure 6 presents two trauma cases with shared\nmechanism (unrestrained MVA) and overlapping findings (chest wall bruising; hemodynamic/ECG\n7\n"}, {"page": 8, "text": "A 27-year-old man presents to the emergency \ndepartment after a motor vehicle collision. The patient was \nthe front seat unrestrained driver in a head on collision. The \npatient’s echocardiogram (ECG) is notable only for sinus \ntachycardia. His temperature is 99.5°F (37.5°C), blood \npressure is 107/58 mmHg, pulse is 120/min, respirations are \n17/min, and oxygen saturation is 98% on room air. The \npatient is given 2 liters of Ringer lactate solution and \nmorphine. Initial workup demonstrates that the patient’s \npulmonary capillary wedge pressure and troponins are \nelevated. The patient is currently complaining of chest pain. \nPhysical exam is notable for an uncomfortable young man \nwith bruising over his chest wall. Which of the following is \nthe most likely diagnosis?\nA 46-year-old man is brought to the emergency department 15 \nminutes after being involved in a motor vehicle collision where he \nwas the unrestrained driver. On arrival, he is unconscious. His \nrespirations are 24/min, and palpable systolic blood pressure is 60 \nmm Hg, and pulse is 141/min and irregularly irregular. Examination \nshows multiple ecchymoses over the chest. There is a 3-cm (1.2-in) \nlaceration over the abdomen and a 4-cm (1.6-in) laceration over the \nscalp. Jugular venous pressure is increased. Bilateral crackles are \nheard at the lung bases. Cardiac examination shows no murmurs, \nrubs, or gallops. The abdomen is soft. Two large bore intravenous \ncatheters are inserted and 0.9% saline infusion is begun. Focused \nassessment with sonography in trauma (FAST) is negative. An \nelectrocardiogram shows absent p-waves. After 5 minutes, his pulse \nis 160/min and palpable systolic blood pressure is 50 mm Hg. \nVasopressors are administered. One hour later, the patient dies. \nWhich of the following was the most likely diagnosis?\n### **Shared Features Between Both Patients:**\n1. **Both were unrestrained drivers in MVA (mechanism of injury)**\n2. **Both have chest wall bruising**\n3. **Both have low blood pressure and tachycardia**\n4. **Both have signs of cardiac involvement (elevated troponins, PCWP in Q1; absent P-waves, low BP, and death in Q2)**\n**Findings:**  \n- Unconscious  \n- Very low BP (60 mmHg → 50 mmHg)  \n- Irregularly irregular pulse (suggests atrial fibrillation or flutter)  \n- Ecchymoses over the chest  \n- Crackles in lungs  \n- FAST negative  \n**Findings:**  \n- Sinus tachycardia  \n- Low BP (107/58 mmHg)  \n- Elevated PCWP and troponins  \n- Chest pain  \n- Bruising over chest wall\nMost important features\nMost important features\nCorrelation between Questions\nA:Cardiac contusion \nB: Hemorrhage \nC: Myocardial infarction \nD: Pulmonary contusion \nE: Takotsubo cardiomyopathy\nA:Cardiac contusion \nB: Hemothorax \nC: Aortic dissection \nD: Pulmonary contusion \nE: Cardiac tamponade\n### Final Answers:  \n- **Question 1 (Index: 1):** **A**  \n- **Question 2 (Index: 2):** **A**\nFigure 6: Example of LLM output for two questions with cosine similarity 0.8314 (embedding\nby Qwen3-4B embedding) given our prompt. Cardiac contusion (Option A) is the only option\nthat is plausible in both cases, given similar mechanism of injury (unrestrained MVA), chest wall\nbruising, Elevated troponins (Q1), Cardiac dysfunction, Absence of other clear causes like MI or\naortic dissection. The correct answer is same for both questions.\nabnormalities). Among the options, Cardiac contusion (A) is uniquely plausible across both stems,\nconsistent with elevated troponins or LV dysfunction and the absence of signs pointing to MI or\ndissection.\nThe model aligns both answers, reflecting: (i) mechanism-level similarity captured by embeddings;\n(ii) margin reconciliation across items (selecting the option that remains viable in both contexts);\nand (iii) fairness by similarity: clinically equivalent trauma patterns map to consistent outcomes.\nMethodological notes.\nFor each question q, we retrieve its nearest neighbor q′ by cosine similarity\non normalized sentence embeddings. The pair (q, q′) is fed to the LLM with the joint protocol\n(Table 2). The model internally clusters decisive features, eliminates clear negatives (large negative\nmargins), and resolves near-boundary options while enforcing a Lipschitz-like stability: if d(q, q′) is\nsmall, then the score difference |f(x) −f(x′)| remains small, promoting consistent outputs unless\ncontradicted by a decisive discriminator (e.g., a contraindication).\nFairness and robustness.\nAcross the examples, demographic attributes (e.g., age) are used only\nwhen explicitly clinically determinative; otherwise they are down-weighted by the prompt’s fairness\nguard. The pairwise setting serves as a regularizer against spurious cues: when two similar items\n8\n"}, {"page": 9, "text": "are solved jointly, option choices that are inconsistent across the pair are penalized by the metric\nconstraint, improving reliability on near-boundary decisions.\n5\nRelated Work\nThere is a growing body of work attempting to study the question of algorithmic discrimination. This\nliterature is characterized by high-level distinction, group and individual notions of fairness. We also\nintroduce the prompt engineering related works.\nIndividual fairness posits that “similar individuals should be treated similarly” [6]. This powerful\nguarantees is formalized via a Lipschitz condition on the classifier mapping individuals to distributions\nover outcomes. Recent works study study different individual level fairness in the contexts of\nreinforcement and online learning. study different individual level fairness in the contexts of bandit\n[11]. [17] studies metric-fair active learning of homogeneous halfspaces [16, 15], and show that\nunder the distribution-dependent PAC learning model. Fairness and label efficiency can be achieved\nsimultaneously.\nGroup fairness notions assume the existence of a protected attribute (e.g. gender, race), which induces\na partition of the instance space into some small number of groups. A fair classifier is one that\nachieves parity of some statistical measure across these groups. There are prominent measures include\nclassification rates (statistical parity [7], calibration, and false positive or negative rates [8]. [23]\nincorporating the fairness notion of [8] into a statistical and computational theory of learning, and\nproposed a relaxation of the fairness definition to make it feasible to optimize the learning objective.\nLLMs are known to have already absorbed rich commonsense that makes it possible to propose\nreasonable plans conditioned on problem setting [4, 9, 20]. The idea of Chain-of-Thought is to enrich\nthe few-shot examples with reasoning steps [22] . There are many studies to improve the performance\nof DoT on complex tasks such as dynamic least-to-most prompting [5], active Prompt [4]. Tree of\nthought approach extends planning formulations by considering multiple potentially feasible plans\nsimultaneously at each problem-solving step [24]. [13] introduced the “self-reflection” mechanism,\nLLMs provide feedback to their generation candidates. [12] introduces review steps cover the actions\nand states, deciding the next action. “self-guided decoding” followers a tree-search procedure with\nleaves sampled from stochastic beam search decoding. Our prompt teaches LLMs to think like a\nmachine learning algorithm with constraint and objective function, the constraint is the fairness metric\n[19]. [14] embeds LLMs in an algorithmic search procedure to help solve problems like question\nanswering step-by-step, in which relevant paragraphs that might provide answers.\n6\nSocietal Impact and Limitations\nWe believe that this work will have positive societal impact as it provides a new approach for\nusing LLMs in healthcare with fairness property. One potential limitation of this work is that the\nperformance is not completely understood from a rigorous theoretical perspective. Also, despite the\nobserved gains, results are not always stable. Future work will: (i) improve stability via calibrated\ndecoding, temperature-free beam search, and ensembling; (ii) learn task-specific similarity metrics\nwith clinical supervision; (iii) integrate confidence estimation and selective answering; (iv) study\npair construction beyond nearest neighbors (e.g., cluster-then-cover, active pairing); (v) evaluate on\nbroader datasets and multilingual settings; and (vi) incorporate human-in-the-loop review and bias\naudits. These steps aim to strengthen reliability, fairness, and generalizability while keeping the\nmethod practical and transparent.\n7\nAcknowledgments\nThis research was supported in part by the Intramural Research Program of the National Institutes\nof Health (NIH). The contributions of the NIH authors are considered Works of the United States\nGovernment. The findings and conclusions presented in this paper are those of the authors and do not\nnecessarily reflect the views of the NIH or the U.S. Department of Health and Human Services. Jie\nShen is supported by NSF-AF-2239376 (CAREER award).\n9\n"}, {"page": 10, "text": "References\n[1] Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin\nGe, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu,\nGao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren,\nChuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu,\nBenfeng Xu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu,\nHongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang,\nChang Zhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang Zhu. Qwen technical report. arXiv\npreprint arXiv:2309.16609, 2023.\n[2] Solon Barocas and Andrew D. Selbst. Big data’s disparate impact. California Law Review,\n104(3):671–732, 2016.\n[3] Alexandra Chouldechova and Aaron Roth. A snapshot of the frontiers of fairness in machine\nlearning. Communications of the ACM, 63(5):82–89, 2020. Earlier version: arXiv:1811.08810\n(2018).\n[4] Shizhe Diao, Pengcheng Wang, Yong Lin, Rui Pan, Xiang Liu, and Tong Zhang. Active\nprompting with chain-of-thought for large language models. In Proceedings of the 62nd Annual\nMeeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages\n1330–1350, 2024.\n[5] Andrew Drozdov, Nathanael Schärli, Ekin Akyürek, Nathan Scales, Xinying Song, Xinyun\nChen, Olivier Bousquet, and Denny Zhou. Compositional semantic parsing with large language\nmodels. arXiv preprint arXiv:2209.15003, 2022.\n[6] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. Fairness\nthrough awareness. In Proceedings of the 3rd Innovations in Theoretical Computer Science\nConference (ITCS), 2012.\n[7] Michael Feldman, Sorelle A Friedler, John Moeller, Carlos Scheidegger, and Suresh Venkata-\nsubramanian. Certifying and removing disparate impact. In proceedings of the 21th ACM\nSIGKDD international conference on knowledge discovery and data mining, pages 259–268,\n2015.\n[8] Moritz Hardt, Eric Price, and Nati Srebro. Equality of opportunity in supervised learning.\nAdvances in neural information processing systems, 29, 2016.\n[9] Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch. Language models as\nzero-shot planners: Extracting actionable knowledge for embodied agents. In International\nconference on machine learning, pages 9118–9147. PMLR, 2022.\n[10] Di Jin, Yifan Pan, Nazneen Oufattole, Wei-Hung Weng, Hanyi Fang, and Peter Szolovits. What\ndisease does this patient have? a large-scale open domain question answering dataset from\nmedical exams. In Proceedings of EMNLP, 2020.\n[11] Matthew Joseph, Michael Kearns, Jamie Morgenstern, Seth Neel, and Aaron Roth. Better fair\nalgorithms for contextual bandits.\n[12] Geunwoo Kim, Pierre Baldi, and Stephen McAleer. Language models can solve computer tasks.\nAdvances in Neural Information Processing Systems, 36:39648–39677, 2023.\n[13] Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri\nAlon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et al. Self-refine: Iterative refinement\nwith self-feedback. Advances in Neural Information Processing Systems, 36:46534–46594,\n2023.\n[14] Imanol Schlag, Sainbayar Sukhbaatar, Asli Celikyilmaz, Wen-tau Yih, Jason Weston, Juergen\nSchmidhuber, and Xian Li. Large language model programs. 2023.\n[15] Jie Shen. On the power of localized perceptron for label-optimal learning of halfspaces with\nadversarial noise. In International Conference on Machine Learning, pages 9503–9514. PMLR,\n2021.\n10\n"}, {"page": 11, "text": "[16] Jie Shen. Sample-optimal pac learning of halfspaces with malicious noise. In International\nConference on Machine Learning, pages 9515–9524. PMLR, 2021.\n[17] Jie Shen, Nan Cui, and Jing Wang. Metric-fair active learning. In International conference on\nmachine learning, pages 19809–19826. PMLR, 2022.\n[18] Jing Wang, Jie Shen, and Ping Li. Provable variable selection for streaming features. In\nInternational Conference on Machine Learning, pages 5171–5179. PMLR, 2018.\n[19] Jing Wang and Jeremy C Weiss. A large-language model framework for relative timeline\nextraction from pubmed case reports. AMIA Summits on Translational Science Proceedings,\n2025:598, 2025.\n[20] Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, and Ee-Peng\nLim. Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large\nlanguage models. arXiv preprint arXiv:2305.04091, 2023.\n[21] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha\nChowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language\nmodels. In Proceedings of ICLR, 2023.\n[22] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le,\nDenny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models.\nAdvances in neural information processing systems, 35:24824–24837, 2022.\n[23] Blake Woodworth, Suriya Gunasekar, Mesrob I Ohannessian, and Nathan Srebro. Learning\nnon-discriminatory predictors. In Conference on learning theory, pages 1920–1953. PMLR,\n2017.\n[24] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik\nNarasimhan. Tree of thoughts: Deliberate problem solving with large language models. arXiv\npreprint arXiv:2305.10601, 2023.\n[25] Shunyu Yao, Jeffrey Zhao, Dian Yu, Yuan Cao, Da Yu, Izhak Shafran, Tom Griffiths, and\nKarthik Narasimhan. React: Synergizing reasoning and acting in language models. arXiv\npreprint arXiv:2210.03629, 2022.\n11\n"}, {"page": 12, "text": "NeurIPS Paper Checklist\nThe checklist is designed to encourage best practices for responsible machine learning research,\naddressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove\nthe checklist: The papers not including the checklist will be desk rejected. The checklist should\nfollow the references and follow the (optional) supplemental material. The checklist does NOT count\ntowards the page limit.\nPlease read the checklist guidelines carefully for information on how to answer these questions. For\neach question in the checklist:\n• You should answer [Yes] , [No] , or [NA] .\n• [NA] means either that the question is Not Applicable for that particular paper or the\nrelevant information is Not Available.\n• Please provide a short (1–2 sentence) justification right after your answer (even for NA).\nThe checklist answers are an integral part of your paper submission. They are visible to the\nreviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it\n(after eventual revisions) with the final version of your paper, and its final version will be published\nwith the paper.\nThe reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation.\nWhile \"[Yes] \" is generally preferable to \"[No] \", it is perfectly acceptable to answer \"[No] \" provided a\nproper justification is given (e.g., \"error bars are not reported because it would be too computationally\nexpensive\" or \"we were unable to find the license for the dataset we used\"). In general, answering\n\"[No] \" or \"[NA] \" is not grounds for rejection. While the questions are phrased in a binary way, we\nacknowledge that the true answer is often more nuanced, so please just use your best judgment and\nwrite a justification to elaborate. All supporting evidence can appear either in the main paper or the\nsupplemental material, provided in appendix. If you answer [Yes] to a question, in the justification\nplease point to the section(s) where related material for the question can be found.\nIMPORTANT, please:\n• Delete this instruction block, but keep the section heading “NeurIPS Paper Checklist\",\n• Keep the checklist subsection headings, questions/answers and guidelines below.\n• Do not modify the questions and only use the provided macros for your answers.\n1. Claims\nQuestion: Do the main claims made in the abstract and introduction accurately reflect the\npaper’s contributions and scope?\nAnswer: [Yes]\nJustification: [TODO]\nGuidelines:\n• The answer NA means that the abstract and introduction do not include the claims\nmade in the paper.\n• The abstract and/or introduction should clearly state the claims made, including the\ncontributions made in the paper and important assumptions and limitations. A No or\nNA answer to this question will not be perceived well by the reviewers.\n• The claims made should match theoretical and experimental results, and reflect how\nmuch the results can be expected to generalize to other settings.\n• It is fine to include aspirational goals as motivation as long as it is clear that these goals\nare not attained by the paper.\n2. Limitations\nQuestion: Does the paper discuss the limitations of the work performed by the authors?\nAnswer: [Yes]\nJustification: [TODO]\n12\n"}, {"page": 13, "text": "Guidelines:\n• The answer NA means that the paper has no limitation while the answer No means that\nthe paper has limitations, but those are not discussed in the paper.\n• The authors are encouraged to create a separate \"Limitations\" section in their paper.\n• The paper should point out any strong assumptions and how robust the results are to\nviolations of these assumptions (e.g., independence assumptions, noiseless settings,\nmodel well-specification, asymptotic approximations only holding locally). The authors\nshould reflect on how these assumptions might be violated in practice and what the\nimplications would be.\n• The authors should reflect on the scope of the claims made, e.g., if the approach was\nonly tested on a few datasets or with a few runs. In general, empirical results often\ndepend on implicit assumptions, which should be articulated.\n• The authors should reflect on the factors that influence the performance of the approach.\nFor example, a facial recognition algorithm may perform poorly when image resolution\nis low or images are taken in low lighting. Or a speech-to-text system might not be\nused reliably to provide closed captions for online lectures because it fails to handle\ntechnical jargon.\n• The authors should discuss the computational efficiency of the proposed algorithms\nand how they scale with dataset size.\n• If applicable, the authors should discuss possible limitations of their approach to\naddress problems of privacy and fairness.\n• While the authors might fear that complete honesty about limitations might be used by\nreviewers as grounds for rejection, a worse outcome might be that reviewers discover\nlimitations that aren’t acknowledged in the paper. The authors should use their best\njudgment and recognize that individual actions in favor of transparency play an impor-\ntant role in developing norms that preserve the integrity of the community. Reviewers\nwill be specifically instructed to not penalize honesty concerning limitations.\n3. Theory assumptions and proofs\nQuestion: For each theoretical result, does the paper provide the full set of assumptions and\na complete (and correct) proof?\nAnswer: [NA]\nJustification: No theory\nGuidelines:\n• The answer NA means that the paper does not include theoretical results.\n• All the theorems, formulas, and proofs in the paper should be numbered and cross-\nreferenced.\n• All assumptions should be clearly stated or referenced in the statement of any theorems.\n• The proofs can either appear in the main paper or the supplemental material, but if\nthey appear in the supplemental material, the authors are encouraged to provide a short\nproof sketch to provide intuition.\n• Inversely, any informal proof provided in the core of the paper should be complemented\nby formal proofs provided in appendix or supplemental material.\n• Theorems and Lemmas that the proof relies upon should be properly referenced.\n4. Experimental result reproducibility\nQuestion: Does the paper fully disclose all the information needed to reproduce the main ex-\nperimental results of the paper to the extent that it affects the main claims and/or conclusions\nof the paper (regardless of whether the code and data are provided or not)?\nAnswer: [Yes]\nJustification: [TODO]\nGuidelines:\n• The answer NA means that the paper does not include experiments.\n13\n"}, {"page": 14, "text": "• If the paper includes experiments, a No answer to this question will not be perceived\nwell by the reviewers: Making the paper reproducible is important, regardless of\nwhether the code and data are provided or not.\n• If the contribution is a dataset and/or model, the authors should describe the steps taken\nto make their results reproducible or verifiable.\n• Depending on the contribution, reproducibility can be accomplished in various ways.\nFor example, if the contribution is a novel architecture, describing the architecture fully\nmight suffice, or if the contribution is a specific model and empirical evaluation, it may\nbe necessary to either make it possible for others to replicate the model with the same\ndataset, or provide access to the model. In general. releasing code and data is often\none good way to accomplish this, but reproducibility can also be provided via detailed\ninstructions for how to replicate the results, access to a hosted model (e.g., in the case\nof a large language model), releasing of a model checkpoint, or other means that are\nappropriate to the research performed.\n• While NeurIPS does not require releasing code, the conference does require all submis-\nsions to provide some reasonable avenue for reproducibility, which may depend on the\nnature of the contribution. For example\n(a) If the contribution is primarily a new algorithm, the paper should make it clear how\nto reproduce that algorithm.\n(b) If the contribution is primarily a new model architecture, the paper should describe\nthe architecture clearly and fully.\n(c) If the contribution is a new model (e.g., a large language model), then there should\neither be a way to access this model for reproducing the results or a way to reproduce\nthe model (e.g., with an open-source dataset or instructions for how to construct\nthe dataset).\n(d) We recognize that reproducibility may be tricky in some cases, in which case\nauthors are welcome to describe the particular way they provide for reproducibility.\nIn the case of closed-source models, it may be that access to the model is limited in\nsome way (e.g., to registered users), but it should be possible for other researchers\nto have some path to reproducing or verifying the results.\n5. Open access to data and code\nQuestion: Does the paper provide open access to the data and code, with sufficient instruc-\ntions to faithfully reproduce the main experimental results, as described in supplemental\nmaterial?\nAnswer: [Yes]\nJustification: [TODO]\nGuidelines:\n• The answer NA means that paper does not include experiments requiring code.\n• Please see the NeurIPS code and data submission guidelines (https://nips.cc/\npublic/guides/CodeSubmissionPolicy) for more details.\n• While we encourage the release of code and data, we understand that this might not be\npossible, so “No” is an acceptable answer. Papers cannot be rejected simply for not\nincluding code, unless this is central to the contribution (e.g., for a new open-source\nbenchmark).\n• The instructions should contain the exact command and environment needed to run to\nreproduce the results. See the NeurIPS code and data submission guidelines (https:\n//nips.cc/public/guides/CodeSubmissionPolicy) for more details.\n• The authors should provide instructions on data access and preparation, including how\nto access the raw data, preprocessed data, intermediate data, and generated data, etc.\n• The authors should provide scripts to reproduce all experimental results for the new\nproposed method and baselines. If only a subset of experiments are reproducible, they\nshould state which ones are omitted from the script and why.\n• At submission time, to preserve anonymity, the authors should release anonymized\nversions (if applicable).\n14\n"}, {"page": 15, "text": "• Providing as much information as possible in supplemental material (appended to the\npaper) is recommended, but including URLs to data and code is permitted.\n6. Experimental setting/details\nQuestion: Does the paper specify all the training and test details (e.g., data splits, hyper-\nparameters, how they were chosen, type of optimizer, etc.) necessary to understand the\nresults?\nAnswer: [Yes]\nJustification: [TODO]\nGuidelines:\n• The answer NA means that the paper does not include experiments.\n• The experimental setting should be presented in the core of the paper to a level of detail\nthat is necessary to appreciate the results and make sense of them.\n• The full details can be provided either with the code, in appendix, or as supplemental\nmaterial.\n7. Experiment statistical significance\nQuestion: Does the paper report error bars suitably and correctly defined or other appropriate\ninformation about the statistical significance of the experiments?\nAnswer: [Yes]\nJustification:\nGuidelines:\n• The answer NA means that the paper does not include experiments.\n• The authors should answer \"Yes\" if the results are accompanied by error bars, confi-\ndence intervals, or statistical significance tests, at least for the experiments that support\nthe main claims of the paper.\n• The factors of variability that the error bars are capturing should be clearly stated (for\nexample, train/test split, initialization, random drawing of some parameter, or overall\nrun with given experimental conditions).\n• The method for calculating the error bars should be explained (closed form formula,\ncall to a library function, bootstrap, etc.)\n• The assumptions made should be given (e.g., Normally distributed errors).\n• It should be clear whether the error bar is the standard deviation or the standard error\nof the mean.\n• It is OK to report 1-sigma error bars, but one should state it. The authors should\npreferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis\nof Normality of errors is not verified.\n• For asymmetric distributions, the authors should be careful not to show in tables or\nfigures symmetric error bars that would yield results that are out of range (e.g. negative\nerror rates).\n• If error bars are reported in tables or plots, The authors should explain in the text how\nthey were calculated and reference the corresponding figures or tables in the text.\n8. Experiments compute resources\nQuestion: For each experiment, does the paper provide sufficient information on the com-\nputer resources (type of compute workers, memory, time of execution) needed to reproduce\nthe experiments?\nAnswer: [Yes]\nJustification: [TODO]\nGuidelines:\n• The answer NA means that the paper does not include experiments.\n• The paper should indicate the type of compute workers CPU or GPU, internal cluster,\nor cloud provider, including relevant memory and storage.\n15\n"}, {"page": 16, "text": "• The paper should provide the amount of compute required for each of the individual\nexperimental runs as well as estimate the total compute.\n• The paper should disclose whether the full research project required more compute\nthan the experiments reported in the paper (e.g., preliminary or failed experiments that\ndidn’t make it into the paper).\n9. Code of ethics\nQuestion: Does the research conducted in the paper conform, in every respect, with the\nNeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?\nAnswer: [Yes]\nJustification: [TODO]\nGuidelines:\n• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.\n• If the authors answer No, they should explain the special circumstances that require a\ndeviation from the Code of Ethics.\n• The authors should make sure to preserve anonymity (e.g., if there is a special consid-\neration due to laws or regulations in their jurisdiction).\n10. Broader impacts\nQuestion: Does the paper discuss both potential positive societal impacts and negative\nsocietal impacts of the work performed?\nAnswer: [Yes]\nJustification: [TODO]\nGuidelines:\n• The answer NA means that there is no societal impact of the work performed.\n• If the authors answer NA or No, they should explain why their work has no societal\nimpact or why the paper does not address societal impact.\n• Examples of negative societal impacts include potential malicious or unintended uses\n(e.g., disinformation, generating fake profiles, surveillance), fairness considerations\n(e.g., deployment of technologies that could make decisions that unfairly impact specific\ngroups), privacy considerations, and security considerations.\n• The conference expects that many papers will be foundational research and not tied\nto particular applications, let alone deployments. However, if there is a direct path to\nany negative applications, the authors should point it out. For example, it is legitimate\nto point out that an improvement in the quality of generative models could be used to\ngenerate deepfakes for disinformation. On the other hand, it is not needed to point out\nthat a generic algorithm for optimizing neural networks could enable people to train\nmodels that generate Deepfakes faster.\n• The authors should consider possible harms that could arise when the technology is\nbeing used as intended and functioning correctly, harms that could arise when the\ntechnology is being used as intended but gives incorrect results, and harms following\nfrom (intentional or unintentional) misuse of the technology.\n• If there are negative societal impacts, the authors could also discuss possible mitigation\nstrategies (e.g., gated release of models, providing defenses in addition to attacks,\nmechanisms for monitoring misuse, mechanisms to monitor how a system learns from\nfeedback over time, improving the efficiency and accessibility of ML).\n11. Safeguards\nQuestion: Does the paper describe safeguards that have been put in place for responsible\nrelease of data or models that have a high risk for misuse (e.g., pretrained language models,\nimage generators, or scraped datasets)?\nAnswer: [Yes]\nJustification: [TODO]\nGuidelines:\n• The answer NA means that the paper poses no such risks.\n16\n"}, {"page": 17, "text": "• Released models that have a high risk for misuse or dual-use should be released with\nnecessary safeguards to allow for controlled use of the model, for example by requiring\nthat users adhere to usage guidelines or restrictions to access the model or implementing\nsafety filters.\n• Datasets that have been scraped from the Internet could pose safety risks. The authors\nshould describe how they avoided releasing unsafe images.\n• We recognize that providing effective safeguards is challenging, and many papers do\nnot require this, but we encourage authors to take this into account and make a best\nfaith effort.\n12. Licenses for existing assets\nQuestion: Are the creators or original owners of assets (e.g., code, data, models), used in\nthe paper, properly credited and are the license and terms of use explicitly mentioned and\nproperly respected?\nAnswer: [Yes]\nJustification: public dataset\nGuidelines:\n• The answer NA means that the paper does not use existing assets.\n• The authors should cite the original paper that produced the code package or dataset.\n• The authors should state which version of the asset is used and, if possible, include a\nURL.\n• The name of the license (e.g., CC-BY 4.0) should be included for each asset.\n• For scraped data from a particular source (e.g., website), the copyright and terms of\nservice of that source should be provided.\n• If assets are released, the license, copyright information, and terms of use in the\npackage should be provided. For popular datasets, paperswithcode.com/datasets\nhas curated licenses for some datasets. Their licensing guide can help determine the\nlicense of a dataset.\n• For existing datasets that are re-packaged, both the original license and the license of\nthe derived asset (if it has changed) should be provided.\n• If this information is not available online, the authors are encouraged to reach out to\nthe asset’s creators.\n13. New assets\nQuestion: Are new assets introduced in the paper well documented and is the documentation\nprovided alongside the assets?\nAnswer: [Yes]\nJustification: will release the code\nGuidelines:\n• The answer NA means that the paper does not release new assets.\n• Researchers should communicate the details of the dataset/code/model as part of their\nsubmissions via structured templates. This includes details about training, license,\nlimitations, etc.\n• The paper should discuss whether and how consent was obtained from people whose\nasset is used.\n• At submission time, remember to anonymize your assets (if applicable). You can either\ncreate an anonymized URL or include an anonymized zip file.\n14. Crowdsourcing and research with human subjects\nQuestion: For crowdsourcing experiments and research with human subjects, does the paper\ninclude the full text of instructions given to participants and screenshots, if applicable, as\nwell as details about compensation (if any)?\nAnswer: [NA]\nJustification: public dataset\n17\n"}, {"page": 18, "text": "Guidelines:\n• The answer NA means that the paper does not involve crowdsourcing nor research with\nhuman subjects.\n• Including this information in the supplemental material is fine, but if the main contribu-\ntion of the paper involves human subjects, then as much detail as possible should be\nincluded in the main paper.\n• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,\nor other labor should be paid at least the minimum wage in the country of the data\ncollector.\n15. Institutional review board (IRB) approvals or equivalent for research with human\nsubjects\nQuestion: Does the paper describe potential risks incurred by study participants, whether\nsuch risks were disclosed to the subjects, and whether Institutional Review Board (IRB)\napprovals (or an equivalent approval/review based on the requirements of your country or\ninstitution) were obtained?\nAnswer: [NA]\nJustification: public dataset\nGuidelines:\n• The answer NA means that the paper does not involve crowdsourcing nor research with\nhuman subjects.\n• Depending on the country in which research is conducted, IRB approval (or equivalent)\nmay be required for any human subjects research. If you obtained IRB approval, you\nshould clearly state this in the paper.\n• We recognize that the procedures for this may vary significantly between institutions\nand locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the\nguidelines for their institution.\n• For initial submissions, do not include any information that would break anonymity (if\napplicable), such as the institution conducting the review.\n16. Declaration of LLM usage\nQuestion: Does the paper describe the usage of LLMs if it is an important, original, or\nnon-standard component of the core methods in this research? Note that if the LLM is used\nonly for writing, editing, or formatting purposes and does not impact the core methodology,\nscientific rigorousness, or originality of the research, declaration is not required.\nAnswer: [NA]\nJustification: only for polishing paper\nGuidelines:\n• The answer NA means that the core method development in this research does not\ninvolve LLMs as any important, original, or non-standard components.\n• Please refer to our LLM policy (https://neurips.cc/Conferences/2025/LLM)\nfor what should or should not be described.\n18\n"}]}