{"doc_id": "arxiv:2511.05901", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2511.05901.pdf", "meta": {"doc_id": "arxiv:2511.05901", "source": "arxiv", "arxiv_id": "2511.05901", "title": "Retrieval-Augmented Generation in Medicine: A Scoping Review of Technical Implementations, Clinical Applications, and Ethical Considerations", "authors": ["Rui Yang", "Matthew Yu Heng Wong", "Huitao Li", "Xin Li", "Wentao Zhu", "Jingchi Liao", "Kunyu Yu", "Jonathan Chong Kai Liew", "Weihao Xuan", "Yingjian Chen", "Yuhe Ke", "Jasmine Chiat Ling Ong", "Douglas Teodoro", "Chuan Hong", "Daniel Shi Wei Ting", "Nan Liu"], "published": "2025-11-08T07:52:47Z", "updated": "2025-11-13T06:14:22Z", "summary": "The rapid growth of medical knowledge and increasing complexity of clinical practice pose challenges. In this context, large language models (LLMs) have demonstrated value; however, inherent limitations remain. Retrieval-augmented generation (RAG) technologies show potential to enhance their clinical applicability. This study reviewed RAG applications in medicine. We found that research primarily relied on publicly available data, with limited application in private data. For retrieval, approaches commonly relied on English-centric embedding models, while LLMs were mostly generic, with limited use of medical-specific LLMs. For evaluation, automated metrics evaluated generation quality and task performance, whereas human evaluation focused on accuracy, completeness, relevance, and fluency, with insufficient attention to bias and safety. RAG applications were concentrated on question answering, report generation, text summarization, and information extraction. Overall, medical RAG remains at an early stage, requiring advances in clinical validation, cross-linguistic adaptation, and support for low-resource settings to enable trustworthy and responsible global use.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2511.05901v2", "url_pdf": "https://arxiv.org/pdf/2511.05901.pdf", "meta_path": "data/raw/arxiv/meta/2511.05901.json", "sha256": "d8b0fbc1ab20bf1e24059844257f729db7793ca9794245b4a60a22ca6cf2fc9a", "status": "ok", "fetched_at": "2026-02-18T02:28:20.974802+00:00"}, "pages": [{"page": 1, "text": "Requests for resources should be directed to and will be fulfilled by the lead contact,  \nNan Liu (email: liu.nan@duke-nus.edu.sg). \n1 \nRetrieval-Augmented Generation in Medicine: A Scoping Review of \nTechnical Implementations, Clinical Applications, and Ethical \nConsiderations \n \nRui Yang1,2†, Matthew Yu Heng Wong3†, Huitao Li1,2†, Xin Li1,2, Wentao Zhu1,2, Jingchi \nLiao1,2, Kunyu Yu1,2, Jonathan Chong Kai Liew1,2, Weihao Xuan4, Yingjian Chen5, Yuhe \nKe2,6, Jasmine Chiat Ling Ong2,7, Douglas Teodoro8, Chuan Hong9,10, Daniel Shi Wei \nTing11,12,13, Nan Liu1,2,9,14,15* \n \n†: co-first authors    *: corresponding author \n1 Center for Quantitative Medicine, Duke–NUS Medical School, Singapore 169857, Singapore \n2 Duke-NUS AI + Medical Sciences Initiative, Duke-NUS Medical School, Singapore 169857, Singapore \n3 School of Clinical Medicine, University of Cambridge, Cambridge CB2 0SP, UK \n4 Graduate School of Frontier Sciences, The University of Tokyo, Tokyo 277-8561, Japan \n5 Graduate School of Engineering, The University of Tokyo, Tokyo 113-8654, Japan \n6 Division of Anesthesiology and Perioperative Medicine, Singapore General Hospital, Singapore 169608, Singapore \n7 Division of Pharmacy, Singapore General Hospital, Singapore 169608, Singapore \n8 Department of Radiology and Medical Informatics, University of Geneva, Geneva 1202, Switzerland \n9 Department of Biostatistics and Bioinformatics, Duke School of Medicine, Durham, NC 27710, USA \n10 Duke Clinical Research Institute, Durham, NC 27705, USA \n11 Singapore Eye Research Institute, Singapore National Eye Center, Singapore 168751, Singapore \n12 Byers Eye Institute, Stanford University, Stanford, CA 94303, USA \n13 Artificial Intelligence Office, Singapore Health Services, Singapore 168582, Singapore \n14 Pre-hospital & Emergency Research Centre, Health Services and Systems Research, Duke–NUS Medical School, \nSingapore 169857, Singapore \n15 NUS Artificial Intelligence Institute, National University of Singapore, Singapore 119391, Singapore \n \n*Corresponding Author: Nan Liu, Centre for Quantitative Medicine, Duke-NUS Medical \nSchool, 8 College Road, Singapore 169857, Singapore \nEmail: liu.nan@duke-nus.edu.sg \n \n \n \n \n \n \n"}, {"page": 2, "text": " \n2 \nSummary \nThe rapid growth of medical knowledge and increasing complexity of clinical practice \npose challenges. In this context, large language models (LLMs) have demonstrated \nvalue; however, inherent limitations remain. Retrieval-augmented generation (RAG) \ntechnologies show potential to enhance their clinical applicability. This study reviewed \nRAG applications in medicine. We found that research primarily relied on publicly \navailable data, with limited application in private data. For retrieval, approaches \ncommonly relied on English-centric embedding models, while LLMs were mostly \ngeneric, with limited use of medical-specific LLMs. For evaluation, automated metrics \nevaluated generation quality and task performance, whereas human evaluation focused \non accuracy, completeness, relevance, and fluency, with insufficient attention to bias \nand safety. RAG applications were concentrated on question answering, report \ngeneration, text summarization, and information extraction. Overall, medical RAG \nremains at an early stage, requiring advances in clinical validation, cross-linguistic \nadaptation, and support for low-resource settings to enable trustworthy and \nresponsible global use. \n \nKeywords \nlarge language models, retrieval-augmented generation, global health equity \n \n \n \n \n \n \n \n \n \n \n \n \n"}, {"page": 3, "text": " \n3 \nIntroduction \nContemporary clinical practice is facing the rapid expansion of medical knowledge and \nthe increasing complexity of diagnostic and therapeutic decision-making.1 At the same \ntime, the growing demand for personalized health care posts unprecedented challenges \nin the retrieval, integration, and application of medical information, further intensifying \nclinicians’ workload.2 In this context, large language models (LLMs) are gradually being \nintroduced into medicine and have demonstrated potential value. Existing proprietary \nLLMs3–13 and open-weight LLMs14–24 have shown outstanding performance in \ngenerative tasks, while reasoning-oriented LLMs have further extended the boundaries \nof complex tasks.25–28 Meanwhile, specific LLMs such as Med-Gemini29,30 and \nMedGemma31 have achieved high adaptability to medical scenarios by incorporating \nspecific knowledge.32 Collectively, these advances highlight the potential applications of \nLLMs in clinical consultation,33 disease diagnosis,34–37 treatment management,33 medical \neducation,38 and scientific research,39 while also suggesting their role in alleviating the \nburden on clinicians and improving overall health care quality.32,33 \n \nDespite this, LLMs face significant challenges in medical applications. First, LLMs rely on \nstatic training data, limiting their ability to keep pace with rapidly evolving medical \nknowledge.40 Second, they are prone to generate content without factual grounding.36 \nThird, LLMs typically function as \"black boxes\" with outputs lacking explainability.36 \nFourth, they cannot access private patient-specific data or hospital-specific guidelines, \nrestricting their utility in personalized diagnostic and treatment support.40 Lastly, LLMs \nmay perpetuate inherent biases from training data, potentially exacerbating disparities \nfor specific populations and further widening health inequities.41 These issues are not \nonly technical bottlenecks but also involve safety and ethical governance as well as \nglobal health equity.42 \n \nAgainst this backdrop, retrieval-augmented generation (RAG) has emerged as a \npromising solution.40,43 RAG technologies enable LLMs to incorporate information from \nexternal sources during the generation process, providing outputs that are up-to-date, \nrelevant, and fact-grounded. The initial “Naive RAG” follows an “index-retrieve-\ngenerate” pipeline, as shown in Figure 1. The RAG system first retrieves information \nfrom external knowledge sources, such as research literature or clinical guidelines, and \n"}, {"page": 4, "text": " \n4 \nthen augments LLMs with the relevant information, helping them generate the \nanswer.40 Later, “Advanced RAG” introduces pre-retrieval optimization and post-\nretrieval processing strategies to improve the quality of retrieved content.36 Meanwhile, \n“Modular RAG” provides a more flexible architecture, allowing for the combination of \nfunctional modules adapted to specific medical scenarios. These technological \nadvancements offer different pathways to mitigate the limitations of LLMs.36,44 \n \n \nFigure 1. Naive RAG framework. The framework consists of three stages: first, the \nretrieval module obtains information relevant to the query; next, the query and the \nretrieved information are provided to the LLM; finally, the LLM generates the answer. \n \nSeveral studies have examined the development of RAG in medicine, providing valuable \nperspectives on this rapidly evolving field. Yang et al. analyze the possible contributions \nthat RAG could bring to health care in equity, reliability, and personalization.40 Liu et al. \nconducted a meta-analysis of 20 studies, demonstrating that RAG systems improved the \nperformance of LLMs, and proposed guidelines for unified implementation and \ndevelopment of enhanced LLM applications with RAG in clinical settings.45 Amugongo et \nal. carried out a systematic review with a focus on methodology, analyzing 70 studies to \ncompare different RAG paradigms and their technical implementations in medical \nscenarios.46 He et al. surveyed RAG datasets, technologies, and applications in medicine, \nwith particular emphasis on technical components and system architectures.43 While \nexisting studies offer important insights, they have not systematically mapped the \nimplementation pathways and application patterns of RAG in medicine. More critically, \nthe evaluation of RAG technologies—especially concerning bias, safety, and deployment \nGeneration\nMedical Textbook\nElectronic \nHealth Record\nKnowledge Graph\nClinicial Guideline\nDense\nEncode\nEmbeddings\nHybrid\nMatched\nSparse\nTokenize\nTokens\nRetrieval\nQuestion\nExternal Resources\nAugmented\nPrompt\nQuestion\nContext\nContext\nBiomedical \nScientific Corpora\nOnline Information\nLexical\nMatch\nVector\nSearch\nHybrid\nSearch\nSparse\nDense\nLarge Language\n Models\n (LLMs)\nRAG Pipeline\nAnswer\n"}, {"page": 5, "text": " \n5 \nin low-resource settings—remains insufficiently explored. However, these factors are \ncrucial for advancing the equitable global application of RAG technologies. \n \nThis scoping review aims to systematically outline the research landscape of RAG in \nmedicine, mapping its implementation pathways and application patterns, and \nevaluating its potential value in addressing the rapid evolution of medical knowledge \nand other critical dimensions of clinical practice. Additionally, we emphasize that while \nRAG alleviates certain limitations of LLMs and facilitates their applications in medicine, \nit simultaneously introduces challenges. These challenges go beyond the reliability of \nknowledge sources and the protection of data privacy, encompassing human-centered \nevaluation and oversight, such as bias identification, safety monitoring, and the \nassurance of cross-linguistic fairness. Recognizing these issues is crucial for promoting \nthe responsible application of RAG in clinical practice and advancing its role in \nimproving the quality of global health care services.40 \n \nResults \nWe retrieved a total of 3,980 study records from PubMed, Embase, Web of Science, and \nScopus. After deduplication and screening of titles, abstracts, and full texts, 248 studies \nmet the inclusion criteria. Additionally, 3 relevant studies were manually identified, \nresulting in a total of 251 studies being analyzed. The PRISMA flow diagram is shown in \nFigure 2. \n"}, {"page": 6, "text": " \n6 \n \nFigure 2. PRISMA flow diagram for identifying related studies. Our search retrieved \n3,980 study records (n=673, 16.91% from PubMed; n=1,310, 32.91% from Scopus; \nn=1,115, 28.02% from Embase; n=882, 22.16% from Web of Science); of these, 2,151 \n(54.05%) were retained after deduplication. Following title, abstract, and full-text \nscreening, 248 studies were included, along with 3 additional studies manually \nidentified as relevant, resulting in a total of 251 included studies. \n \nComponents of RAG Framework \nExternal Retrieval Data \nIn terms of data source (Figure 3 - Data Source), most studies (80.35%, 184/229) relied \non publicly available data, while only 36 studies (15.72%) used private data, and 9 \nstudies (3.93%) used both public and private data. This distribution pattern indicates \nthat RAG research in medicine predominantly depends on open resources, with limited \nutilization of proprietary clinical data.  \n \nIdentification\nIncluded\nScreening\nTotal Studies\n(n=3,980)\nDuplicate Records\nRemoved\n(n=1,829)\nRecord Screened\n(n=352)\nRecords Excluded\nby Full-Text \n(n=104)\nStudies Included\n(n=251)\nPubMed\n(n=673)\nWeb of Science \n(n=882)\nScopus \n(n=1,310)\nEmbase \n(n=1,115)\nRecord Screened\n(n=2,151)\nRecords Excluded\nby Title/Abstract \n(n= 1,799)\nAdditional Studies\n(n=3)\n"}, {"page": 7, "text": " \n7 \nMeanwhile, RAG research primarily relies on diverse biomedical and clinical resources. \nAs shown in Figure 3 (Data Type), biomedical scientific corpora constitute the main \ndata source, used in 90 studies, with PubMed being a typical example. Clinical guidelines \nfollow closely, adopted in 68 studies and underscoring the key role of evidence-based \nmedicine in RAG applications. Online information (39 studies) and electronic health \nrecords (34 studies) are also common; the former reflects the demand for continuously \nupdated medical knowledge, while the latter represents data support closely tied to real \nclinical practice. In addition, medical textbooks are incorporated in 31 studies as \nfoundational learning and reference materials; knowledge graphs (30 studies), as a \nstructured form of knowledge representation, offer different possibilities for medical \nknowledge retrieval; and custom-built datasets (30 studies) reflect researchers' \nexploration of constructing tailored resources for specific contexts. Overall, the data \ntypes involved in medical RAG encompass both structured and unstructured \ninformation, forming a diversified support framework. \n \nRetrieval Method \nAs shown in Figure 3 (Retrieval Method), dense retrieval dominated among the \nincluded studies, with 189 studies (84.38%) adopting this approach. In contrast, sparse \nretrieval was used in only 11 studies (4.91%), while hybrid approaches were applied in \n24 studies (10.71%). Dense retrieval methods were primarily implemented in two \nways: one relied on general embedding models, such as OpenAI’s text-embedding \nseries;47 the other employed medical-specific embedding models including BioBERT48 \nand MedCPT,49 which are trained on biomedical corpora to better capture the semantics \nof the field. However, it is noteworthy that most dense retrieval embedding models are \nstill primarily trained on English corpora, posing significant limitations in non-English \nmedical scenarios.50 This is particularly evident when handling multilingual medical \ndata, localized clinical guidelines, and non-English patient records, where semantic \nmisinterpretation and reduced retrieval accuracy may occur.40 Sparse retrieval methods \nmainly relied on the traditional BM25 algorithm,51 but their usage frequency within the \nRAG framework is noticeably low. Hybrid retrieval approaches, which combine sparse \nand dense methods to balance lexical matching and semantic representation, exhibited \ncertain advantages in some studies.52 \n \n"}, {"page": 8, "text": " \n8 \nGenerative LLM \nAs shown in Figure 3 (LLM Type), proprietary LLMs were the most widely used, \nappearing in 103 studies (42.39%). Open-weight LLMs were utilized in 85 studies \n(34.98%), and a combination of both in 55 studies (22.63%). Proprietary LLMs were \nprimarily from the OpenAI’s GPT series,10,11,53 while open-weight LLMs mainly include \nthe DeepSeek, Gemma, LLaMA, and Qwen series.14–25 Notably, medical-specific LLMs \nwere rarely applied in existing RAG research. One possible reason is that proprietary \nmedical LLMs (e.g., Med-Gemini29,30) have not released APIs to the public, limiting their \naccessibility for research and practice. Additionally, open-weight medical LLMs have \ndeveloped more slowly than general LLMs, lagging in both scale and performance.54 \n \n \nFigure 3: Distribution of external retrieval data, retrieval methods, and \ngenerative LLMs among the 251 studies. In terms of data source, 184 studies \n(80.35%) used public data, 36 studies (15.72%) used private data, and 9 studies \n(3.93%) used both. In terms of data type, the studies mainly employed biomedical \nscientific corpora (90 studies), clinical guideline (68 studies), online information (39 \nstudies), electronic health record (34 studies), medical textbook (31 studies), \nknowledge graph (30 studies), self-collected information (30 studies), and question \nLLM Type\nData Type\nData Source\nRetrieval Method\nRAG\n184\n36\n9\nPublic\nPrivate\nBoth\n90\n68\n39\n34\n31\n30\n30\n9\nQuestion Answering Dataset\nSelf-Collected Information\nKnowledge Graph\nMedical Textbook\nElectronic Health Record\nOnline Information\nClinical Guideline\nBiomedical Scientific Corpora\n189\n11\n24\nDense\nSparse\nHybrid\n103\n85\n55\nProprietary Open-Weight\nBoth\n"}, {"page": 9, "text": " \n9 \nanswering dataset (9 studies). As for retrieval method, 189 studies (84.38%) applied \ndense retrieval, 11 studies (4.91%) applied sparse retrieval, and 24 studies (10.71%) \napplied hybrid retrieval. Regarding LLM type, 103 studies (42.39%) applied proprietary \nLLMs, 85 studies (34.98%) applied open-weight LLMs, and 55 studies (22.63%) applied \nboth. It should be noted that only information explicitly reported in the studies is \nincluded here, while some studies did not provide detailed descriptions. \n \nMedical Specialty and Application Scenario \nMedical Specialty Distribution \nThe distribution of RAG across medical specialties exhibits considerable variability. \nInternal Medicine occupies the most prominent position, with 48 studies, reflecting its \nbroad demand for synthesizing extensive clinical knowledge. Beyond this, Psychiatry \nand Neurology (24 studies), along with Radiology (22 studies), have shown a certain \nlevel of research activity. Additional specialties, including Preventive Medicine, \nEmergency Medicine, Orthopaedic Surgery, Medical Genetics and Genomics, and \nObstetrics and Gynecology, have been explored to a lesser extent, while engagement in \nremaining specialties is limited. In general, the adoption of RAG across medical \nspecialties remains uneven. \n \nClinical Application Scenario \nMeanwhile, RAG has been explored in a variety of medical scenarios. Among them, \nmedical question answering is the most widely used task, which supports clinicians \nwith evidence retrieval, diagnostic reasoning, and clinical decision-making, while also \nassisting patients in obtaining understandable answers to medical inquiries.55 Report \ngeneration is another application, where structured or semi-structured clinical data are \nautomatically transformed into complete clinical reports (e.g., radiology or pathology \nreports) to reduce documentation burden.55 Additionally, text summarization and \ninformation extraction have gained attention: the former condenses lengthy narratives \nto enhance information accessibility, while the latter converts unstructured text into \nstructured data to support downstream analysis.55 Other tasks, such as text \nsimplification, have also been explored. Collectively, these tasks demonstrate the \nmultifaceted potential of RAG in supporting clinical workflows. \n \n"}, {"page": 10, "text": " \n10 \nEvaluation and Ethical Considerations \nAutomatic and Human Evaluation  \nIn medical applications of RAG, evaluation methods demonstrate a relatively balanced \ndistribution between automated and human evaluations, as shown in Figure 4 \n(Automatic and Human Evaluation). Automated evaluation was the most common \nsetting, adopted in 112 studies (47.66%), while 43 studies (18.30%) only relied on \nhuman evaluation, and 80 studies (34.04%) combined both evaluations. Automated \nmetrics generally fall into two categories: (i) text generation quality metrics (e.g., \nROUGE,56 BERTScore,57 BLEU,58 METEOR59), which assess linguistic quality and \nsemantic similarity between generated content and reference texts; and (ii) task-\nspecific performance metrics (e.g., accuracy, recall, F1 score, AUROC), typically applied \nin tasks such as multiple-choice question answering and clinical risk prediction. Human \nevaluation, by contrast, plays an indispensable role in dimensions not fully captured by \nautomated metrics, with a primary focus on the factual accuracy and clinical utility of \ngenerated content, including completeness, relevance, fluency, as well as the detection \nof hallucination, bias, and safety concerns. Overall, current evaluation practices indicate \nthe importance of balancing quantifiable performance metrics with subjective \njudgments of clinical acceptability. \n \nEthical and Contextual Consideration \nAs shown in Figure 4 (Ethical and Contextual Considerations), only 7 (2.79%) studies \nexplicitly examined bias, 24 (9.56%) studies addressed safety, and 6 (2.39%) studies \nfocused on low-resource settings. For bias assessment, most studies relied on small-\nscale expert validation. Some studies invited clinicians to rate bias in LLM outputs, \nwhile others directly examined differences across age, sex, race, and socioeconomic \nstatus. For safety evaluation, existing methods included detecting hallucinations and \npotential harms in generated responses, or applying rule-based safety filters. Although \nthese explorations are valuable, they covered only a small fraction of the studies. In \naddition, research concerning low-resource settings involved countries such as \nIndia,60,61 but overall remained very limited. These findings point to an imbalance in \ncurrent evaluation practices, with insufficient attention given to ethical considerations. \n"}, {"page": 11, "text": " \n11 \n \nFigure 4: Distribution of evaluation methods and ethical considerations among \nthe 251 studies. A total of 235 included studies reported evaluation methods, with \nautomated evaluation (n = 112, 47.66%), human evaluation (n = 43, 18.30%), and a \ncombination of both (n = 80, 34.04%). Among all 251 studies, only 7 studies explicitly \nexamined bias, 24 studies addressed safety, and 6 studies were conducted in low-\nresource settings. \n \nDiscussion \nThis scoping review systematically analyzed 251 RAG studies in medicine, revealing \nmultifaceted characteristics and trends. Regarding data utilization, most studies relied \non publicly available resources, with biomedical scientific corpora, clinical guidelines, \nand online information being the most common; real-world clinical data such as \nelectronic health records were used only to a limited extent, while some studies also \nadopted medical textbooks and knowledge graphs. In terms of retrieval methods, dense \nretrieval emerged as the predominant approach, while sparse and hybrid strategies \nreported less frequently. For the generative model, proprietary LLMs dominated, with \nopen-weight LLMs also used to some extent; however, LLMs specialized for medicine \nwere rarely employed. Regarding specialty distribution, research was primarily \nconcentrated in Internal Medicine, with other specialties also explored, though the \noverall distribution remained uneven. As for applications, medical question answering \nemerged as the main task. Other important applications include report generation, text \nsummarization, and information extraction, all of which primarily focus on reducing the \nAutomatic and Human Evaluation\nEthical and Contextual Consideration\n7\n24\n6\n251\nBias \nEvaluation\nSafety\nEvaluation\nLow-Resource\nSetting\n112\n80\nAutomated\nEvaluation\nBoth\nHuman\nEvaluation\n43\n"}, {"page": 12, "text": " \n12 \nworkload of clinicians. In terms of evaluation methods, automated evaluation was the \nmain strategy, though many studies incorporated human evaluation to compensate for \nthe inadequacies of automated metrics in clinical contexts. Notably, only a small number \nof studies considered bias, safety, or low-resource settings. Overall, while medical RAG \nresearch has established a certain foundation in methodological exploration, it remains \nin early stages regarding data availability, clinical validation, and responsible \napplication. \n \nThe mode of data source selection reveals the constraints faced by the development of \nmedical RAG. While the widespread use of open data has facilitated technical validation, \nit may also confine the application of RAG systems to the level of general medical \nknowledge, creating limitations in personalized health care scenarios where integration \nof real-world clinical data is essential. The limited integration of private data is \nprimarily constrained by strict data privacy protection requirements, the lack of robust \ncross-institutional collaboration mechanisms, and the complexity of the implementation \nprocess. These challenges may hinder the further development of RAG technology in \npersonalized medicine. \n \nIn terms of retrieval methods, the dominance of dense retrieval in medical RAG \napplications reflects its advantage in capturing medical semantic relations, particularly \nwith the use of medical-specific embedding models such as MedCPT,49 which shows the \nimportance of domain adaptation for retrieval performance. However, the linguistic \nlimitations faced by current dense retrieval methods are especially prominent. First, \nreliance on English-centric embedding models may hinder effective coverage of non-\nEnglish medical data, thereby limiting the broader application of RAG technologies in \nglobal health care systems.62,63 Second, such linguistic bias may exacerbate inequities in \nmedical research and clinical practice, especially in low-resource languages and regions, \nwhere relevant medical knowledge is less likely to be adequately incorporated and \nutilized.64 Although some studies have explored combining sparse or hybrid retrieval \nstrategies to expand coverage, significant gaps remain in cross-lingual and fairness-\nrelated aspects of medical RAG, underscoring the need for further exploration in \nmultilingual embeddings and localized adaptation. \n \n"}, {"page": 13, "text": " \n13 \nA noteworthy phenomenon in the application of generative LLMs is the insufficient use \nof medical-specific LLMs. This may stem from the limited availability and relatively \nslower development progress of such models. While general LLMs perform well in text \ngeneration, they may face adaptability challenges in understanding complex medical \nterminology, clinical reasoning logic, and the integration of domain-specific knowledge. \nThis gap between technical capability and application requirements warrants further \nattention. \n \nThe distribution of RAG applications in medicine reflects varying levels of acceptance \nand practical demands across task types. Applications related to question answering \ndominate; these applications essentially work by retrieving external knowledge to \nsupport medical knowledge access, diagnostic reasoning, and clinical decision-making. \nHowever, this category carries substantial risks as well: if retrieval sources are opaque, \nevidence is not verified, or generated content is not validated, clinicians may be misled \ninto making incorrect judgments, and even pass harmful information on to patients—\nultimately compromising diagnostic patient safety and patient trust. In contrast, tasks \nrelated to information processing (such as report generation, text summarization, and \ninformation extraction) carry comparatively lower clinical risks, making them an ideal \nentry point for RAG in clinical settings. Their primary value lies in reducing \ndocumentation burdens and improving information management efficiency, rather than \nintervening directly in clinical workflow.  \n \nThe evaluation methods for current medical applications of RAG exhibit a diverse \npattern, with the combined use of automated and human evaluation reflecting the \ncomplexity of medical AI evaluation. However, this diversity brings challenges in terms \nof result comparability and reproducibility. The use of text generation quality metrics \nand task-specific performance metrics illustrates the varying evaluation priorities \nacross different medical tasks. Nevertheless, these metrics often fall short in capturing \nthe full scope of clinical practicality and potential risks within medical contexts. At the \nsame time, while human evaluation can compensate for some of these shortcomings, it \nis limited by subjectivity and cost, posing difficulties to scalability on a large-scale. More \nimportantly, existing studies show limited attention to issues of safety, bias, and \nfairness, which may pose potential risks in clinical practice. The absence of robust \n"}, {"page": 14, "text": " \n14 \nmechanisms for detecting and mitigating these issues could undermine fairness in \nhealth care delivery and threaten patient safety. Moreover, insufficient research in low-\nresource settings highlights the broader challenges that medical RAG faces in advancing \nglobal health equity. \n \nTo advance RAG toward real clinical implementation, breakthroughs are needed across \nmultiple critical dimensions, as shown in Figure 5. First, beyond continuous \nimprovements in technical reliability, there is an urgent need for rigorous clinical \nvalidation to ensure that generated content is not only factually accurate but also \nclinically actionable. Second, it is equally critical to establish traceability and \ntransparency mechanisms that enable clinicians to examine the retrieval sources and \nreasoning processes behind the output. Meanwhile, corresponding regulatory \nframeworks and ethical guidelines must be developed in parallel to ensure patient \nsafety and enhance trust between health care providers and patients. Finally, it is \nimportant to recognize that the global deployment of medical RAG will encounter \nmultidimensional challenges arising from linguistic, cultural, resource, and institutional \ndisparities. Therefore, substantial progress in cross-linguistic and cross-cultural \nadaptation, as well as the assurance of fairness in low-resource settings, will be \nrequired before international implementation. Only by addressing these challenges can \nRAG achieve safe, trustworthy, and responsible clinical use on a global scale. \n \n"}, {"page": 15, "text": " \n15 \n \nFigure 5. Important directions for advancing medical RAG toward real clinical \nimplementation. This figure outlines three strategic directions required for \nresponsible deployment of RAG in medicine: (1) Reliability—ensuring technical \nrobustness and rigorous clinical validation to guarantee system-level stability and \nclinical actionability; (2) Trustworthiness—establishing traceability and transparency \nmechanisms alongside regulatory frameworks and ethical guidelines; (3) Equity—\npromoting cross-linguistic and cross-cultural adaptation while supporting low-resource \nsettings to reduce global health disparities. \n \nLimitations \nThis study has several limitations. First, we excluded non-English publications, which \nmay introduce bias into the overview of RAG research in medicine. The results might \ndiffer if other languages and country-specific databases had been included. However, it \nis practically impossible to comprehensively cover all languages and national databases; \ntherefore, we followed common practice in the domain. Second, artificial intelligence \n(AI) research is typically published in peer-reviewed conference proceedings, which are \nnot well covered by existing search databases. Aside from Google Scholar, no other \nsearch engine can comprehensively capture all relevant AI studies, and Google Scholar \nT\nr\nu\ns\nt\nw\no\nr\nt\nh\ni\nn\ne\ns\ns\nE\nq\nu\ni\nt\ny\nR\ne\nl\ni\na\nb\ni\nl\ni\nt\ny\nRetrieval \nAugmented \nGeneration \nTr\na\nn\ns\np\na\nr\ne\nn\nc\ny\na\nn\nd\nG\no\nv\ne\nr\nn\na\nn\nce\nGl\no\nb\nal\nE\nq\nu\nit\ny\na\nn\nd\nA\nc\nc\ne\ns\nsi\nbi\nli\nty\nR\nel\nia\nb\nil\nit\ny\na\nn\nd\nV\na\nli\nd\na\nti\no\nn\nTraceability & Transparency\nMechanisms\nRegulatory Frameworks\n& Ethical Guidelines\nLinguistic & Cultural \nAdaptation\nSupport for\nLow-Resource Settings\nEnhanced Technical Reliability\nRigorous Clinical Validation\n"}, {"page": 16, "text": " \n16 \nitself has issues of reproducibility and search reliability. Lastly, given the extremely \nrapid development of this area, some recent relevant studies were inevitably missed \nduring our search. \n \nAcknowledgments \nThis work was supported by the Duke-NUS Signature Research Program funded by the \nMinistry of Health, Singapore. Any opinions, findings and conclusions or \nrecommendations expressed in this material are those of the author(s) and do not \nreflect the views of the Ministry of Health.  \n \nAuthor Contributions \nR.Y. and N.L. contributed to the conceptualization and methodology design. R.Y., M.W., \nH.L., X.L., W.Z., J.L., K.Y., and J.C.K.L. contributed to data curation. R.Y., H.L., Y.C., and W.X. \ncontributed to visualization. R.Y., M.W., H.L., and Y.K. drafted the manuscript, with \nfurther improvements by J.C.L.O., D.T., C.H., D.S.W.T., and N.L. N.L. supervised the study. \nAll authors contributed to the revision of the manuscript and approved the final version. \n \nDeclaration of Interests \nThe authors declare no competing interests. \n  \nMain Figure Titles and Legends \n \nFigure 1. Naive RAG framework. The framework consists of three stages: first, the \nretrieval module obtains information relevant to the query; next, the query and the \nretrieved information are provided to the LLM; finally, the LLM generates the answer. \n \nFigure 2. PRISMA flow diagram for identifying related studies. Our search retrieved \n3,980 study records (n=673, 16.91% from PubMed; n=1,310, 32.91% from Scopus; \nn=1,115, 28.02% from Embase; n=882, 22.16% from Web of Science); of these, 2,151 \n(54.05%) were retained after deduplication. Following title, abstract, and full-text \nscreening, 248 studies were included, along with 3 additional studies manually \nidentified as relevant, resulting in a total of 251 included studies. \n"}, {"page": 17, "text": " \n17 \n \nFigure 3: Distribution of external retrieval data, retrieval methods, and \ngenerative LLMs among the 251 studies. In terms of data source, 184 studies \n(80.35%) used public data, 36 studies (15.72%) used private data, and 9 studies \n(3.93%) used both. In terms of data type, the studies mainly employed biomedical \nscientific corpora (90 studies), clinical guideline (68 studies), online information (39 \nstudies), electronic health record (34 studies), medical textbook (31 studies), \nknowledge graph (30 studies), self-collected information (30 studies), and question \nanswering dataset (9 studies). As for retrieval method, 189 studies (84.38%) applied \ndense retrieval, 11 studies (4.91%) applied sparse retrieval, and 24 studies (10.71%) \napplied hybrid retrieval. Regarding LLM type, 103 studies (42.39%) applied proprietary \nLLMs, 85 studies (34.98%) applied open-weight LLMs, and 55 studies (22.63%) applied \nboth. It should be noted that only information explicitly reported in the studies is \nincluded here, while some studies did not provide detailed descriptions. \n \nFigure 4: Distribution of evaluation methods and ethical considerations among \nthe 251 studies. A total of 235 included studies reported evaluation methods, with \nautomated evaluation (n = 112, 47.66%), human evaluation (n = 43, 18.30%), and a \ncombination of both (n = 80, 34.04%). Among all 251 studies, only 7 studies explicitly \nexamined bias, 24 studies addressed safety, and 6 studies were conducted in low-\nresource settings. \n \nFigure 5. Important directions for advancing medical RAG toward real clinical \nimplementation. This figure outlines three strategic directions required for \nresponsible deployment of RAG in medicine: (1) Reliability—ensuring technical \nrobustness and rigorous clinical validation to guarantee system-level stability and \nclinical actionability; (2) Trustworthiness—establishing traceability and transparency \nmechanisms alongside regulatory frameworks and ethical guidelines; (3) Equity—\npromoting cross-linguistic and cross-cultural adaptation while supporting low-resource \nsettings to reduce global health disparities. \n \nSTAR★Methods \n"}, {"page": 18, "text": " \n18 \nResource Availability \n \nLead Contact \nRequests for resources, data, and materials should be directed to, and will be fulfilled \nby, the Lead Contact, Nan Liu (email: liu.nan@duke-nus.edu.sg). \n \nMaterials Availability \nThis study did not generate new unique materials or reagents. \n \nData and Code Availability \nAny data and code are available from the Lead Contact upon reasonable request. \n \nSearch Strategy \nWe conducted this scoping review following the Preferred Reporting Items for \nSystematic Reviews and Meta-Analyses Extension for Scoping Reviews (PRISMA-ScR) \nguideline to ensure transparency and rigor throughout the process.65 We performed a \ncomprehensive search across PubMed, Embase, Web of Science, and Scopus. The search \nstrategy involved using a combination of terms related to \"RAG\" and \"Medicine\" to \nensure maximum coverage and relevance. Our search period spans from 2017 (when \nthe “Transformer” architecture was introduced66) to July 1st, 2025, to ensure \ncomprehensive coverage of the full development trajectory of RAG technologies in the \ncontext of LLMs. Additionally, some important studies that could not be retrieved but \nwere considered highly relevant were manually included. For the detailed search \nstrategy, please refer to the Supplementary Material. \n \nInclusion Criteria and Exclusion Criteria \nStudies were included if they met the following criteria: (1) Implemented a RAG \nframework, defined as leveraging retrieved external knowledge to improve the \ngeneration of LLMs; and (2) Were applied in medical scenarios, with potential impact \nand contributions to health care services. Additionally, we excluded studies that lacked \nabstracts, were non-English, were not peer-reviewed, were non-research types (such as \nreview or perspective), as well as studies without clear RAG implementation details.  \n \n"}, {"page": 19, "text": " \n19 \nIn the title and abstract screening stage, each study was independently screened by at \nleast two researchers (RY, XL, KY, HL, JL, WZ, JL and MW) to determine eligibility. \nDuring the full-text screening stage, at least two researchers again independently \nscreened the studies and extracted data. Any disagreements arising during this process \nwere resolved through consultation with domain experts (RY, WX). \n \nData Extraction \nFor each included study, we extracted information across the following 6 perspectives: \n(1) metadata; (2) external retrieval data: data source, data availability, data scale, \nretrieval method; (3) model: generative model, model accessibility, embedding model; \n(4) application: medical specialty, application scenario; (5) evaluation: evaluation \nmetrics, inclusion of human evaluation; (6) bias, safety, and low-resource setting: \ninclusion of bias evaluation, inclusion of safety evaluation, and application in low-\nresource settings. \n \nRequests for resources should be directed to and will be fulfilled by the lead contact, \nNan Liu (email: liu.nan@duke-nus.edu.sg). \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n"}, {"page": 20, "text": " \n20 \nReferences \n1. \nShortliffe, E.H., and Sepúlveda, M.J. (2018). Clinical Decision Support in the Era of \nArtificial Intelligence. JAMA 320, 2199–2200. \n2. \nJameson, J.L., and Longo, D.L. (2015). Precision medicine--personalized, \nproblematic, and promising. N Engl J Med 372, 2229–2234. \n3. \nAnthropic. Claude 2. Available at: https://www.anthropic.com/news/claude-2. \nAccessed 1 November 2025. \n4. \nAnthropic. Claude 3.5 Sonnet. Available at: \nhttps://www.anthropic.com/news/claude-3-5-sonnet. Accessed 1 November \n2025. \n5. \nAnthropic. Introducing Claude 4. Available at: \nhttps://www.anthropic.com/news/claude-4. Accessed 1 November 2025. \n6. \nAnthropic. Claude Opus 4.1. Available at: \nhttps://www.anthropic.com/news/claude-opus-4-1. Accessed 1 November 2025. \n7. \nGemini Team, Anil, R., Borgeaud, S., Alayrac, J.-B., Yu, J., Soricut, R., Schalkwyk, J., \nDai, A.M., Hauth, A., Millican, K., et al. (2023). Gemini: A family of highly capable \nmultimodal models. arXiv [cs.CL]. https://doi.org/10.48550/ARXIV.2312.11805. \n8. \nGemini Team, Georgiev, P., Lei, V.I., Burnell, R., Bai, L., Gulati, A., Tanzer, G., Vincent, \nD., Pan, Z., Wang, S., et al. (2024). Gemini 1.5: Unlocking multimodal understanding \nacross millions of tokens of context. arXiv [cs.CL]. \nhttps://doi.org/10.48550/ARXIV.2403.05530. \n9. \nComanici, G., Bieber, E., Schaekermann, M., Pasupat, I., Sachdeva, N., Dhillon, I., \nBlistein, M., Ram, O., Zhang, D., Rosen, E., et al. (2025). Gemini 2.5: Pushing the \nfrontier with advanced reasoning, multimodality, long context, and next generation \nagentic capabilities. arXiv [cs.CL]. https://doi.org/10.48550/ARXIV.2507.06261. \n10. Brown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, \nA., Shyam, P., Sastry, G., Askell, A., et al. (2020). Language Models are Few-Shot \nLearners. arXiv [cs.CL]. https://doi.org/10.48550/ARXIV.2005.14165. \n11. OpenAI, Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F.L., \nAlmeida, D., Altenschmidt, J., Altman, S., et al. (2023). GPT-4 Technical Report. arXiv \n[cs.CL]. https://doi.org/10.48550/ARXIV.2303.08774. \n12. OpenAI, :, Hurst, A., Lerer, A., Goucher, A.P., Perelman, A., Ramesh, A., Clark, A., \nOstrow, A.J., Welihinda, A., et al. (2024). GPT-4o System Card. arXiv [cs.CL]. \nhttps://doi.org/10.48550/ARXIV.2410.21276. \n"}, {"page": 21, "text": " \n21 \n13. OpenAI. GPT-5 System Card. Available at: https://openai.com/index/gpt-5-system-\ncard/. Accessed 1 November 2025. \n14. DeepSeek-AI, Liu, A., Feng, B., Xue, B., Wang, B., Wu, B., Lu, C., Zhao, C., Deng, C., \nZhang, C., et al. (2024). DeepSeek-V3 Technical Report. arXiv [cs.CL]. \nhttps://doi.org/10.48550/ARXIV.2412.19437. \n15. Gemma Team, Mesnard, T., Hardin, C., Dadashi, R., Bhupatiraju, S., Pathak, S., Sifre, \nL., Rivière, M., Kale, M.S., Love, J., et al. (2024). Gemma: Open models based on \nGemini research and technology. arXiv [cs.CL]. \nhttps://doi.org/10.48550/ARXIV.2403.08295. \n16. Gemma Team, Riviere, M., Pathak, S., Sessa, P.G., Hardin, C., Bhupatiraju, S., \nHussenot, L., Mesnard, T., Shahriari, B., Ramé, A., et al. (2024). Gemma 2: Improving \nopen language models at a practical size. arXiv [cs.CL]. \nhttps://doi.org/10.48550/ARXIV.2408.00118. \n17. Gemma Team, Kamath, A., Ferret, J., Pathak, S., Vieillard, N., Merhej, R., Perrin, S., \nMatejovicova, T., Ramé, A., Rivière, M., et al. (2025). Gemma 3 Technical Report. \narXiv [cs.CL]. https://doi.org/10.48550/ARXIV.2503.19786. \n18. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, \nB., Goyal, N., Hambro, E., Azhar, F., et al. (2023). LLaMA: Open and efficient \nfoundation language models. arXiv [cs.CL]. \nhttps://doi.org/10.48550/ARXIV.2302.13971. \n19. Grattafiori, A., Dubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle, A., Letman, A., \nMathur, A., Schelten, A., Vaughan, A., et al. (2024). The Llama 3 herd of models. \narXiv [cs.AI]. https://doi.org/10.48550/ARXIV.2407.21783. \n20. Meta AI. The Llama 4 herd: The beginning of a new era of natively multimodal AI \ninnovation. Available at: https://ai.meta.com/blog/llama-4-multimodal-\nintelligence/. Accessed 1 November 2025. \n21. Bai, J., Bai, S., Chu, Y., Cui, Z., Dang, K., Deng, X., Fan, Y., Ge, W., Han, Y., Huang, F., et \nal. (2023). Qwen Technical Report. arXiv [cs.CL]. \nhttps://doi.org/10.48550/ARXIV.2309.16609. \n22. Yang, A., Yang, B., Hui, B., Zheng, B., Yu, B., Zhou, C., Li, C., Li, C., Liu, D., Huang, F., et \nal. (2024). Qwen2 Technical Report. arXiv [cs.CL]. \nhttps://doi.org/10.48550/ARXIV.2407.10671. \n23. Qwen, :, Yang, A., Yang, B., Zhang, B., Hui, B., Zheng, B., Yu, B., Li, C., Liu, D., et al. \n(2024). Qwen2.5 Technical Report. arXiv [cs.CL]. \nhttps://doi.org/10.48550/ARXIV.2412.15115. \n"}, {"page": 22, "text": " \n22 \n24. Yang, A., Li, A., Yang, B., Zhang, B., Hui, B., Zheng, B., Yu, B., Gao, C., Huang, C., Lv, C., \net al. (2025). Qwen3 Technical Report. arXiv [cs.CL]. \nhttps://doi.org/10.48550/ARXIV.2505.09388. \n25. DeepSeek-AI, Guo, D., Yang, D., Zhang, H., Song, J., Zhang, R., Xu, R., Zhu, Q., Ma, S., \nWang, P., et al. (2025). DeepSeek-R1: Incentivizing Reasoning Capability in LLMs \nvia Reinforcement Learning. arXiv [cs.CL]. \nhttps://doi.org/10.48550/ARXIV.2501.12948. \n26. OpenAI, :, Jaech, A., Kalai, A., Lerer, A., Richardson, A., El-Kishky, A., Low, A., Helyar, \nA., Madry, A., et al. (2024). OpenAI o1 System Card. arXiv [cs.AI]. \nhttps://doi.org/10.48550/ARXIV.2412.16720. \n27. OpenAI. OpenAI o3-mini System Card. Available at: https://openai.com/index/o3-\nmini-system-card/. Accessed 1 November 2025. \n28. OpenAI. OpenAI o3 and o4-mini System Card. Available at: \nhttps://openai.com/index/o3-o4-mini-system-card/. Accessed 1 November 2025. \n29. Saab, K., Tu, T., Weng, W.-H., Tanno, R., Stutz, D., Wulczyn, E., Zhang, F., Strother, T., \nPark, C., Vedadi, E., et al. (2024). Capabilities of Gemini models in medicine. arXiv \n[cs.AI]. https://doi.org/10.48550/ARXIV.2404.18416. \n30. Yang, L., Xu, S., Sellergren, A., Kohlberger, T., Zhou, Y., Ktena, I., Kiraly, A., Ahmed, F., \nHormozdiari, F., Jaroensri, T., et al. (2024). Advancing multimodal medical \ncapabilities of Gemini. arXiv [cs.CV]. https://doi.org/10.48550/ARXIV.2405.03162. \n31. Sellergren, A., Kazemzadeh, S., Jaroensri, T., Kiraly, A., Traverse, M., Kohlberger, T., \nXu, S., Jamil, F., Hughes, C., Lau, C., et al. (2025). MedGemma Technical Report. arXiv \n[cs.AI]. https://doi.org/10.48550/ARXIV.2507.05201. \n32. Thirunavukarasu, A.J., Ting, D.S.J., Elangovan, K., Gutierrez, L., Tan, T.F., and Ting, \nD.S.W. (2023). Large language models in medicine. Nat Med 29, 1930–1940. \n33. Yang, R., Tan, T.F., Lu, W., Thirunavukarasu, A.J., Ting, D.S.W., and Liu, N. (2023). \nLarge language models in health care: Development, applications, and challenges. \nHealth Care Sci 2, 255–263. \n34. McDuff, D., Schaekermann, M., Tu, T., Palepu, A., Wang, A., Garrison, J., Singhal, K., \nSharma, Y., Azizi, S., Kulkarni, K., et al. (2025). Towards accurate differential \ndiagnosis with large language models. Nature 642, 451–457. \n35. Vedadi, E., Barrett, D., Harris, N., Wulczyn, E., Reddy, S., Ruparel, R., Schaekermann, \nM., Strother, T., Tanno, R., Sharma, Y., et al. (2025). Towards physician-centered \noversight of conversational diagnostic AI. arXiv [cs.AI]. \nhttps://doi.org/10.48550/ARXIV.2507.15743. \n"}, {"page": 23, "text": " \n23 \n36. Yang, R., Liu, H., Marrese-Taylor, E., Zeng, Q., Ke, Y., Li, W., Cheng, L., Chen, Q., \nCaverlee, J., Matsuo, Y., et al. (2024). KG-rank: Enhancing large language models for \nmedical QA with knowledge graphs and ranking techniques. In Proceedings of the \n23rd Workshop on Biomedical Natural Language Processing (Association for \nComputational Linguistics), pp. 155–166. \n37. Ke, Y., Yang, R., Lie, S.A., Lim, T.X.Y., Ning, Y., Li, I., Abdullah, H.R., Ting, D.S.W., and \nLiu, N. (2024). Mitigating Cognitive Biases in Clinical Decision-Making Through \nMulti-Agent Conversations Using Large Language Models: Simulation Study. J Med \nInternet Res 26, e59439. \n38. Abd-Alrazaq, A., AlSaad, R., Alhuwail, D., Ahmed, A., Healy, P.M., Latifi, S., Aziz, S., \nDamseh, R., Alabed Alrazak, S., and Sheikh, J. (2023). Large Language Models in \nMedical Education: Opportunities, Challenges, and Future Directions. JMIR Med \nEduc 9, e48291. \n39. Yang, R., Tong, J., Wang, H., Huang, H., Hu, Z., Li, P., Liu, N., Lindsell, C.J., Pencina, M.J., \nChen, Y., et al. (2025). Enabling inclusive systematic reviews: incorporating \npreprint articles with large language model-driven evaluations. J Am Med Inform \nAssoc.  \n40. Yang, R., Ning, Y., Keppo, E., Liu, M., Hong, C., Bitterman, D.S., Ong, J.C.L., Ting, D.S.W., \nand Liu, N. (2025). Retrieval-augmented generation for generative artificial \nintelligence in health care. Npj Health Syst. 2. \n41. Omiye, J.A., Lester, J.C., Spichak, S., Rotemberg, V., and Daneshjou, R. (2023). Large \nlanguage models propagate race-based medicine. NPJ Digit Med 6, 195. \n42. Ong, J.C.L., Chang, S.Y.-H., William, W., Butte, A.J., Shah, N.H., Chew, L.S.T., Liu, N., \nDoshi-Velez, F., Lu, W., Savulescu, J., et al. (2024). Ethical and regulatory challenges \nof large language models in medicine. Lancet Digit Health 6, e428–e432. \n43. He, J., Zhang, B., Rouhizadeh, H., Chen, Y., Yang, R., Lu, J., Chen, X., Liu, N., Li, I., and \nTeodoro, D. (2025). Retrieval-Augmented Generation in biomedicine: A survey of \ntechnologies, datasets, and clinical applications. arXiv [q-bio.OT]. \nhttps://doi.org/10.48550/ARXIV.2505.01146. \n44. Gao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., Dai, Y., Sun, J., Wang, M., and Wang, H. \n(2023). Retrieval-Augmented Generation for Large Language Models: A Survey. \n45. Liu, S., McCoy, A.B., and Wright, A. (2025). Improving large language model \napplications in biomedicine with retrieval-augmented generation: a systematic \nreview, meta-analysis, and clinical development guidelines. J Am Med Inform Assoc \n32, 605–615. \n46. Amugongo, L.M., Mascheroni, P., Brooks, S., Doering, S., and Seidel, J. (2025). \n"}, {"page": 24, "text": " \n24 \nRetrieval augmented generation for large language models in healthcare: A \nsystematic review. PLOS Digital Health 4, e0000877. \n47. OpenAI. Vector embeddings. Available at: \nhttps://platform.openai.com/docs/guides/embeddings. Accessed 1 November \n2025. \n48. Lee, J., Yoon, W., Kim, S., Kim, D., Kim, S., So, C.H., and Kang, J. (2020). BioBERT: a \npre-trained biomedical language representation model for biomedical text mining. \nBioinformatics 36, 1234–1240. \n49. Jin, Q., Kim, W., Chen, Q., Comeau, D.C., Yeganova, L., Wilbur, W.J., and Lu, Z. (2023). \nMedCPT: Contrastive Pre-trained Transformers with large-scale PubMed search \nlogs for zero-shot biomedical information retrieval. Bioinformatics 39.  \n50. Xuan, W., Yang, R., Qi, H., Zeng, Q., Xiao, Y., Feng, A., Liu, D., Xing, Y., Wang, J., Gao, F., \net al. (2025). MMLU-ProX: A multilingual benchmark for advanced large language \nmodel evaluation. arXiv [cs.CL]. https://doi.org/10.48550/ARXIV.2503.10497. \n51. Robertson, S., and Zaragoza, H. (2009). The probabilistic relevance framework: \nBM25 and beyond. Found. Trends® Inf. Retr. 3, 333–389. \n52. Liu, H., Soroush, A., Nestor, J.G., Park, E., Idnay, B., Fang, Y., Pan, J., Liao, S., Bernard, \nM., Peng, Y., et al. (2024). Retrieval augmented scientific claim verification. Jamia \nOpen 7, ooae021. \n53. OpenAI. Introducing ChatGPT. Available at: https://openai.com/index/chatgpt/. \nAccessed 1 November 2025. \n54. Wu, J., Gu, B., Zhou, R., Xie, K., Snyder, D., Jiang, Y., Carducci, V., Wyss, R., Desai, R.J., \nAlsentzer, E., et al. (2025). BRIDGE: Benchmarking large language models for \nunderstanding real-world clinical practice text. arXiv [cs.CL]. \nhttps://doi.org/10.48550/ARXIV.2504.19467. \n55. Yang, R., Zeng, Q., You, K., Qiao, Y., Huang, L., Hsieh, C.-C., Rosand, B., Goldwasser, J., \nDave, A., Keenan, T., et al. (2024). Ascle-A Python Natural Language Processing \nToolkit for Medical Text Generation: Development and Evaluation Study. J Med \nInternet Res 26, e60601. \n56. Lin, C.-Y. (2004). Rouge: A package for automatic evaluation of summaries. \n57. Zhang, T., Kishore, V., Wu, F., Weinberger, K.Q., and Artzi, Y. (2019). BERTScore: \nEvaluating Text Generation with BERT. arXiv [cs.CL]. \nhttps://doi.org/10.48550/ARXIV.1904.09675. \n58. Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J. (2001). BLEU. In Proceedings of the \n"}, {"page": 25, "text": " \n25 \n40th Annual Meeting on Association for Computational Linguistics - ACL ’02 \n(Association for Computational Linguistics).  \n59. Banerjee, S., and Lavie, A. (2005). METEOR: An Automatic Metric for MT Evaluation \nwith Improved Correlation with Human Judgments. In Proceedings of the ACL \nWorkshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation \nand/or Summarization, pp. 65–72. \n60. Al Ghadban, Y., Lu, H. (yvonne), Adavi, U., Sharma, A., Gara, S., Das, N., Kumar, B., \nJohn, R., Devarsetty, P., and Hirst, J.E. (2023). Transforming Healthcare Education: \nHarnessing Large Language Models for Frontline Health Worker Capacity Building \nusing Retrieval-Augmented Generation. medRxiv, 2023.12.15.23300009. \nhttps://doi.org/10.1101/2023.12.15.23300009. \n61. Sun H, Li Q, Wang J, et al. (2024). A RAG-based Medical Assistant Especially for \nInfectious Diseases. IEEE Explore.  \n62. Yang, R., Nair, S.V., Ke, Y., D’Agostino, D., Liu, M., Ning, Y., and Liu, N. (2024). \nDisparities in clinical studies of AI enabled applications from a global perspective. \nNPJ Digit Med 7, 209. \n63. Akbarialiabad, H., Sadeghian, N., Haghighat, S., Grada, A., Paydar, S., Haghighi, A., \nKvedar, J.C., and Sewankambo, N.K. (2025). The utility of generative AI in advancing \nglobal health. NEJM AI 2. \n64. Localizing AI in the global south (2025). Nat. Mach. Intell.  \n65. Tricco, A.C., Lillie, E., Zarin, W., O’Brien, K.K., Colquhoun, H., Levac, D., Moher, D., \nPeters, M.D.J., Horsley, T., Weeks, L., et al. (2018). PRISMA Extension for Scoping \nReviews (PRISMA-ScR): Checklist and Explanation. Ann Intern Med 169, 467–473. \n66. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., \nand Polosukhin, I. (2017). Attention is all you need. arXiv [cs.CL]. \nhttps://doi.org/10.48550/ARXIV.1706.03762. \n \n"}]}