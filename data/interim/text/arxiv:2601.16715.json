{"doc_id": "arxiv:2601.16715", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2601.16715.pdf", "meta": {"doc_id": "arxiv:2601.16715", "source": "arxiv", "arxiv_id": "2601.16715", "title": "Dynamic Expert-Guided Model Averaging for Causal Discovery", "authors": ["Adrick Tench", "Thomas Demeester"], "published": "2026-01-23T13:01:30Z", "updated": "2026-01-23T13:01:30Z", "summary": "Understanding causal relationships is critical for healthcare. Accurate causal models provide a means to enhance the interpretability of predictive models, and furthermore a basis for counterfactual and interventional reasoning and the estimation of treatment effects. However, would-be practitioners of causal discovery face a dizzying array of algorithms without a clear best choice. This abundance of competitive algorithms makes ensembling a natural choice for practical applications. At the same time, real-world use cases frequently face challenges that violate the assumptions of common causal discovery algorithms, forcing heavy reliance on expert knowledge. Inspired by recent work on dynamically requested expert knowledge and LLMs as experts, we present a flexible model averaging method leveraging dynamically requested expert knowledge to ensemble a diverse array of causal discovery algorithms. Experiments demonstrate the efficacy of our method with imperfect experts such as LLMs on both clean and noisy data. We also analyze the impact of different degrees of expert correctness and assess the capabilities of LLMs for clinical causal discovery, providing valuable insights for practitioners.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2601.16715v1", "url_pdf": "https://arxiv.org/pdf/2601.16715.pdf", "meta_path": "data/raw/arxiv/meta/2601.16715.json", "sha256": "97aefa808b6d9fc96f706e6622dc049e4d269d1ed3ec29e2950737586d2e93fb", "status": "ok", "fetched_at": "2026-02-18T02:20:39.784076+00:00"}, "pages": [{"page": 1, "text": "Proceedings of Machine Learning Research LEAVE UNSET:1–16, 2026\nSubmitted LEAVE UNSET; Published LEAVE UNSET\nDynamic Expert-Guided Model Averaging for Causal Discovery\nAdrick Tench\nadrick.tench@ugent.be\nUGent - IMEC, Belgium\nThomas Demeester\nthomas.demeester@ugent.be\nUGent - IMEC, Belgium\nAbstract\nUnderstanding causal relationships is critical\nfor healthcare.\nAccurate causal models pro-\nvide a means to enhance the interpretability\nof predictive models, and furthermore a basis\nfor counterfactual and interventional reasoning\nand the estimation of treatment effects. How-\never, would-be practitioners of causal discov-\nery face a dizzying array of algorithms without\na clear best choice.\nThis abundance of com-\npetitive algorithms makes ensembling a natural\nchoice for practical applications. At the same\ntime, real-world use cases frequently face chal-\nlenges that violate the assumptions of common\ncausal discovery algorithms, forcing heavy re-\nliance on expert knowledge. Inspired by recent\nwork on dynamically requested expert knowl-\nedge and LLMs as experts, we present a flexi-\nble model averaging method leveraging dynam-\nically requested expert knowledge to ensemble\na diverse array of causal discovery algorithms.\nExperiments demonstrate the efficacy of our\nmethod with imperfect experts such as LLMs\non both clean and noisy data.\nWe also ana-\nlyze the impact of different degrees of expert\ncorrectness and assess the capabilities of LLMs\nfor clinical causal discovery, providing valuable\ninsights for practitioners.\nData and Code Availability\nAll of our data\ncomes from publicly available sources: the Bayesys\nrepository (Constantinou et al., 2020) and SimSUM\ndataset (Rabaey et al., 2025), the latter of which\nis available at https://huggingface.co/datasets/\nprabaey/simsum. Our code will be made available\non GitHub following peer review.\nAn anonymized\nversion is available at https://anonymous.4open.\nscience/r/expert-cd-ensemble-3281/.\nInstitutional Review Board (IRB)\nIRB ap-\nproval is not required, as our research does not in-\nvolve human subjects or sensitive data.\n1. Introduction\nMany applications in healthcare require not just ac-\ncurate predictive models, but a robust understand-\ning of the underlying causal mechanisms. Structural\nCausal Models (SCMs) such as Bayesian networks\n(BNs) are a popular choice for applications such as\nclinical decision support systems, due to their inher-\nent interpretability and capacity for counterfactual\nand interventional reasoning (Kyrimi et al., 2021).\nCausal discovery aims to learn SCMs from observa-\ntional data, potentially revealing valuable new causal\nrelationships for clinical research and practice.\nTo\nthis end, there has been significant interest in appli-\ncations of causal discovery in healthcare (Shen et al.,\n2021; Yang et al., 2023; Zahoor et al., 2025; Petrun-\ngaro et al., 2025).\nRandomized clinical trials (RCTs) are the gold\nstandard for determining causal relationships, but\nconducting RCTs is often costly and difficult, if not\nimpossible. Causal discovery can point the way to-\nwards the most useful clinical trials to perform and\nprovide insight in cases where clinical trials are in-\nfeasible. However, would-be practitioners of causal\ndiscovery face a great diversity of methods, with no\nclear indicators of which method is the best for their\nuse-case (Kitson et al., 2023).\nWe therefore seek to provide a general-purpose\nmethod for ensembling in causal discovery that can\nflexibly incorporate a diverse array of learning algo-\nrithms with expert domain knowledge. Our primary\ncontributions are threefold:\n• We provide a general model averaging strategy\nthat uses dynamically requested expert knowl-\nedge to mediate discrepancies between models.\nTo our knowledge, our method is the first to ex-\nplore the use of expert knowledge for model av-\neraging or ensembling in causal discovery.\n© 2026 A. Tench & T. Demeester.\narXiv:2601.16715v1  [cs.LG]  23 Jan 2026\n"}, {"page": 2, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\n• We evaluate the performance of our method\nas an ensembling approach for causal discov-\nery against several baselines on well-known, real-\nworld graphs, using both clean and noisy data to\nbetter reflect the challenges of real-world appli-\ncations of causal discovery.\n• We assess the use of LLMs and investigate the\nimpact of varying degrees of expert correctness\non our method, helping establish to what ex-\ntent imperfect experts can be useful in mediating\nmodel averaging.\n2. Related Work\n2.1. Assumptions and data noise\nThe theoretical bases for many causal discovery algo-\nrithms rely on assumptions that are frequently impos-\nsible to verify in practice, such as causal sufficiency\n(the absence of latent confounders). A plethora of al-\ngorithms exist that attempt to address different pos-\nsible assumption violations. For example, the well-\nknown FCI algorithm (Spirtes et al., 2000) works in\nthe presence of latent confounders and can provide\nsome insight in the presence of selection bias (Spirtes\net al., 2013); the SAT-based approach of Hyttinen\net al. (2013) handles latent confounders and cyclicity;\nand the hill-climbing based approach of Liu and Con-\nstantinou (2022) is shown to improve performance in\nthe face of missing data, including data Missing Not\nAt Random. However, such approaches typically only\naddress one or two assumptions while leaving others\nuntouched. Furthermore, analysis of the performance\nof well-known causal discovery algorithms under data\nnoise that violates various common assumptions re-\nveals inconsistencies in algorithm performance across\nmetrics and noise types (Constantinou et al., 2021).\n2.2. Ensembling in causal discovery\nThe performance of individual causal discovery al-\ngorithms can vary widely and unpredictably (Kitson\net al., 2023), making the improved robustness pro-\nvided by ensembling (Zhou, 2025) a natural choice for\napplying causal discovery in practical settings. How-\never, to our knowledge, little research has been done\nexploring the best methods for performing ensem-\nbling or model averaging in causal discovery. Con-\nstantinou (2019a) provides a method for model aver-\naging that greedily adds edges by order of the most\ncounts, avoiding cycles as the graph is constructed.\nAslani and Mohebbi (2023) treat ensembling as an\noptimization problem, using a distance measure be-\ntween graphs to maximize the marginal contribution\nof the edges in the final graph. Khatibi et al. (2024)\npresent their strongest results from a weighted ensem-\nble of existing causal discovery algorithms. However,\ntheir approach relies on access to unrealistic meta-\ndata about the ground-truth causal graph that would\nnot be available in a practical setting.\n2.3. Expert knowledge\nPrior work has typically focused on including ex-\npert knowledge as prior constraints (Constantinou\net al., 2023).\nA recent contribution from Kitson\nand Constantinou (2025) explored using dynamically-\nrequested expert knowledge in the score-based tabu\nalgorithm. Unlike our approach, their method is in-\ntended for use with a human expert, and evaluation\nlargely focused on a setting with clean data and a\nperfect (simulated) expert.\nThere has also been much interest in using LLMs as\nexperts to enable causal discovery (Liu et al., 2025).\nVashishtha et al. (2025) present a strong case for\nrestricting LLMs to answering causal ordering ques-\ntions, and provide a method for prompting LLMs to\nobtain a causal order over a whole graph, to be used\nas prior constraints. Khatibi et al. (2024) introduce\na general framework for using an LLM to refine the\noutput of a causal discovery algorithm. In line with\nthe dynamic knowledge method of Kitson and Con-\nstantinou (2025), Tao et al. (2025) use active requests\nto an LLM to augment continuous optimization algo-\nrithms (e.g. Zheng et al. (2018)’s NOTEARS).\nInspired by these contributions, we explore the use\nof imperfect experts (such as LLMs) to dynamically\nanswer causal ordering questions, improving model\naveraging across an ensemble of varied causal discov-\nery algorithms.\n3. Methods\n3.1. Expert Model Averaging\nWe treat the problem of ensembling as one of model\naveraging: given a set of causal models M and an\nexpert e, we seek the combined model m that best\nmatches the (unknown) ground-truth model g. By\nbeing agnostic to the means by which the causal mod-\nels M are generated, our method provides flexibil-\nity in the inclusion of different algorithms, making it\n2\n"}, {"page": 3, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nwidely applicable across different domains and data\ntypes.\nWe provide pseudocode for our model averag-\ning strategy in Algorithm 1, which we describe be-\nlow.\nOur pseudocode makes use of several helper\nfunctions, notably: connectionCounts(M), which\ncounts the total number of direct edges of any\nkind between each pair of nodes in a set of mod-\nels M; edgeCounts(M, x, y), which counts the to-\ntal number of edges x →y in a set of models\nM; m.edgeCreatesCycle(x, y), which determines if\nadding a new edge x →y to the model m would\ncreate a cycle; and e.acceptConnection(x, y) and\ne.determineOrientation(x, y), which dynamically\nquery an expert e for edge existence and orientation.\nInspired by the model averaging strategy of Con-\nstantinou (2019a), our method greedily adds edges\nthat avoid creating cycles by order of most occurrence\nin the component models M. However, crucially, our\nmethod treats the existence of a direct connection\nseparately from the orientation of that connection:\nwhen determining the counts by which edges will be\nadded, any direct edge between two nodes x and y\n(i.e. x →y, y →x, x −y) is weighted equally as in-\ndicating the presence of some direct edge. We use\na predetermined edge threshold θ1 that determines\nwhat percentage of component models M must con-\ntain a connection between x and y for an edge to be\nadded to m.\nFurthermore, when the percentage is\nabove θ1 but below 0.5 (a majority vote), we query\nthe expert e to potentially reject the presence of an\nedge between x and y.1\nIn the event that only one directed orientation\n(x →y or y →x) is a valid (non-cycle inducing)\naddition to m, that edge is added to m. When both\ndirected orientations are valid, we first check if the\npercentage of models with a particular orientation\n(Mx→y or My→x) out of the models containing a di-\nrect connection (Mxy) falls above a predetermined\norientation threshold θ2.\nIf so, that orientation is\nadded to m. Otherwise, the expert e is queried to\ndetermine the final orientation.\n1. As argued by Vashishtha et al. (2025), determining the\npresence of a direct edge in a causal graph generally re-\nquires the consideration of every node in the graph, making\nsuch a rejection query potentially risky. We therefore ex-\nplicitly query the expert to only reject an edge in the event\nthat there is no plausible causal link, direct or indirect.\nAlgorithm 1: Expert Model Averaging\nInput: a set of causal models M, edge threshold\nθ1, orientation threshold θ2, and expert e\nOutput: m, the final model\nC ←connectionCounts(M);\nn ←size(M);\nm ←DAG();\nfor x, y, c in sorted(C) do\nif c/n ≥θ1 and (c/n > 0.5 or\ne.acceptConnection(x, y)) then\nxy ←not m.edgeCreatesCycle(x, y);\nyx ←not m.edgeCreatesCycle(y, x);\nif xy and yx then\nif edgeCounts(M, x, y)/c ≥θ2 then\nm.addEdge(x, y);\nelse if edgeCounts(M, y, x)/c ≥θ2\nthen\nm.addEdge(y, x);\nelse\nm.addEdge(\ne.determineOrientation(x, y));\nend\nelse if xy then\nm.addEdge(x, y);\nelse if yx then\nm.addEdge(y, x);\nend\nend\nreturn m;\n3.2. Simulated Expert\nWe use a simulated expert in our experiments. Based\non the known ground-truth model g, the expert\nprovides correct answers to acceptConnection and\ndetermineOrientation queries in some fixed per-\ncentage of cases. As we focus on the potential impact\nof causal ordering questions, our simulated expert\nprovides answers based on presence of some chain\nx →... →y rather than merely a direct edge x →y.\nFrom the perspective of graphical accuracy, a cor-\nrect causal ordering answer from our simulated expert\nmay therefore not result in a correct edge in the final\ngraph (e.g. if there is a chain x →... →y but no edge\nx →y in g, when answering “correctly” our expert\nwill not block an edge between x and y). We choose\nto take this approach to better reflect the limitations\nof eliciting accurate expert knowledge in practice. Fi-\nnally, we note that when determineOrientation is\n3\n"}, {"page": 4, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\ncalled for two variables with no causal relation in the\nground truth model g, an arbitrary orientation is re-\nturned.\n4. Experiments\n4.1. Setup\nDatasets:\nWe use six networks taken from the\nBayesys repository (Constantinou et al., 2020), con-\ntaining real-world BNs from various application do-\nmains (including three clinical applications), de-\nscribed in Table 1. We use the corresponding syn-\nthetically generated data available in the Bayesys\nrepo, both clean data and the noisy data gener-\nated in Constantinou et al. (2021), with sample sizes\nn ∈{100, 1000, 10000, 100000}. We also include the\nSimSUM network (Rabaey et al., 2025), with noisy\ndata generated following the same procedure as Con-\nstantinou et al. (2021).\nTo mitigate the impact of\nvariable ordering on results (Kitson and Constanti-\nnou, 2024), we repeat each experiment over twenty\nrandom orderings of the dataset columns.\nAlgorithms and baselines:\nWe use a diverse ar-\nray of causal discovery algorithms in our ensem-\nble: the constraint-based PC-Stable (Colombo et al.,\n2014) and FCI (Spirtes et al., 2000); the score-based\nTabu (Bouckaert, 1995), GES (Chickering, 2002),\nMAHC (Constantinou et al., 2022), and BOSS (An-\ndrews et al., 2023); the hybrid MMHC (Tsamardi-\nnos et al., 2006); and the continuous optimization\napproach DAG-GNN (Yu et al., 2019), chosen for its\nhandling of discrete variables. We also compare to\ntwo existing ensembling approaches from Constanti-\nnou (2019a) and Aslani and Mohebbi (2023).\nFi-\nnally, we include Tabu-AL (Kitson and Constantinou,\n2025) as a baseline using dynamically requested ex-\npert knowledge, using the simulated expert described\nin Section 3.2. Hyperparameter choices and imple-\nmentation details for the algorithms are contained in\nAppendix A.\nMetrics:\nWe report several evaluation metrics,\nnamely the Balanced Scoring Function (BSF) (Con-\nstantinou, 2019b), F1-score, precision score, recall\nscore, and Structural Hamming Distance (SHD). In\nall cases, we treat a reversed or undirected edge (i.e.\nx ←y or x −y when the ground truth is x →y) as\na partial match (0.5 of a false negative and 0.5 of a\ntrue positive), in line with Constantinou (2019b), to\nreflect the relative value of discovering a true depen-\ndency without discovering its correct orientation.2\n4.2. Comparison results\nWe provide our main results using a simulated expert\nthat provides correct responses to queries in 80% of\ncases, an edge threshold θ1 of 0.0, and an orientation\nthreshold θ2 of 0.7. Section 4.5 shows that LLM per-\nformance on a subset of the benchmark networks is\nin-line with an expert correctness of 80%, supporting\nthis choice. The edge threshold θ1 = 0.0 and orien-\ntation threshold θ2 = 0.7 are chosen to optimize for\nthe BSF and F1 scores, as discussed in Appendix B.\nUnder these settings, we analyze the performance\nof our method in Table 2 and Figure 1.\nGiven\nthe large number of combinations of networks, sam-\nple sizes, and algorithms, it is impossible to pro-\nvide direct comparisons for all in the main text.\nTherefore, Table 2 includes only the most compet-\nitive baselines (Tabu-AL, which uses dynamic expert\nknowledge, and Bayesys Model Average, an ensem-\nbling method) on clinically relevant networks (ASIA,\nALARM, Pathfinder, and SimSUM). For compact-\nness and to assist overall comparison, Figure 1 pro-\nvides the metric deltas between our method and the\nbaselines, averaged across all networks, sample sizes,\nand seeds, for both clean and noisy data. Full result\ntables by network and sample size are available in\nAppendix C.\nSome results are excluded from the averaged cal-\nculations in Figure 1 due to either an invalid preci-\nsion score (in the case that a method returned a fully\nsparse graph) or a missing result (due to a timeout\nor exception). We acknowledge that this may bias re-\nsults, likely in favor of the algorithm that provided an\nexceptional result (as such exceptions typically occur\nin more difficult settings). More detail is provided in\nAppendix D.\nOur results show broad improvements in BSF and\nF1 score, typically improving over baseline methods\nby at least 10% on both clean and noisy data (closer\nto 5% on noisy data compared to other ensembling\nmethods).\nOur method further provides a compa-\nrable recall to other ensembling methods with much\n2. As in Constantinou et al. (2022), in the event of a latent\nconfounder under noisy data, only a bidirected edge counts\nas a full match, while any other edge counts as a partial\nmatch. This means that of our evaluated algorithms, only\nFCI can potentially achieve a perfect score in the noisy\ndata case.\n4\n"}, {"page": 5, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nTable 1: Properties of benchmark networks\nNetwork\nNodes\nEdges\nParameters\nDomain\nAsia\n8\n8\n18\nReasons causing dyspnea\nSports\n9\n15\n1,049\nFootball match outcomes\nProperty\n27\n31\n3,056\nProperty investment\nAlarm\n37\n46\n509\nALARM monitoring system\nFormed\n88\n138\n912\nForensic / criminal psychology\nPathfinder\n109\n195\n71,890\nDiagnosis of lymph-node diseases\nSimSUM\n16\n35\n3,368\nRespiratory diseases\nhigher precision. The relative SHD also typically im-\nproves, especially over other ensembling approaches.\nFinally, our method improves in BSF, recall, and F1\nover Tabu-AL on both clean and noisy data by at\nleast 9% on average, demonstrating the value of using\ndynamic expert knowledge for ensembling compared\nto augmenting an individual algorithm.\nWhile individual algorithms still often have higher\nprecision, this is balanced by the greatly improved\nrecall of our method. A higher edge threshold θ1 can\neasily be used to achieve higher precision at the cost\nof lower recall, as shown in 4.4.\n4.3. Impact of expert correctness\nWhile our main results focus on a simulated ex-\npert with 80% correctness, we examine the per-\nformance of simulated experts with correctnesses ∈\n{50%, 60%, 70%, 80%, 90%, 100%}. We find a linear\nrelationship between expert correctness and the per-\nformance of our method, across all metrics, networks,\nand sample sizes, under both clean and noisy data.\nFigure 2 plots the improvements across metrics, av-\neraged over all runs, compared to the Bayesys model\naveraging approach as a static baseline. Individual\nplots are available in Appendix E.\n4.4. Impact of edge threshold\nFigure 3 shows the impact of the edge threshold θ1\non graphical accuracy metrics. As expected, preci-\nsion increases with the edge threshold while recall\ndecreases.\nThe BSF and F1 scores also decrease\nwith a higher edge threshold, leading to our choice\nof θ1 = 0.0 as default.\n4.5. LLM as expert\nIn addition to a simulated expert, we conduct exper-\niments with an LLM expert, using OpenAI’s gpt-5-\nnano-2025-08-07 for all experiments. Full details of\nthe prompts used for acceptConnection (existence)\nand determineOrientation (orientation) queries are\navailable in Appendix F. While we average all re-\nsults across 20 seeds (consistent with our other ex-\nperiments), calls to the LLM were cached across\nseeds and sample sizes for cost saving purposes, such\nthat only one call to each of acceptConnection and\ndetermineOrientation is made for the same vari-\nables. To reduce ordering sensitivity, we query the\nLLM with both possible argument orders, and use the\nLLM’s choice only if it is consistent across both or-\nders; otherwise, we fall back to a majority vote among\nthe ensemble models M.\nWe assess LLM performance only on the clini-\ncal networks ASIA, ALARM, and SimSUM. While\nthe pathfinder network is also clinical, it is excluded\ndue to a lack of informative variable names.\nWe\nalso include only the clean versions of the networks,\nwhich contain no latent confounders.3\nFinally, we\nacknowledge the risk that the LLM has already seen\nand potentially memorized the benchmark networks,\nand provide a case-study in Appendix G that sug-\ngests that while the risk of memorization is high for\nthe ASIA network, it is low to nonexistent for the\nALARM and SimSUM networks.\nTable 3 shows the accuracy of LLM responses on\nexistence and orientation queries. (Here, we assess\nthe individual LLM responses for each variable order-\ning, not the results of any resulting fallbacks to ma-\njority voting.) For all networks, performance is higher\non orientation queries than existence queries, indicat-\ning that the LLM is better at determining plausible\ncausal orderings than the existence of causal relation-\nships. While the overall accuracy for ASIA and Sim-\n3. The detection of latent confounders is not directly consid-\nered in the current prompts, but could be an interesting\navenue for future work.\n5\n"}, {"page": 6, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nTable 2: Performance of our method with a simulated expert (θ1 = 0.0, θ2 = 0.7, expert correctness 80%)\nagainst the most competitive baselines on clinically relevant networks. mean ± std, averaged across\n20 random seeds. † indicates an invalid precision score was obtained for one or more seeds.\nNetwork\nSample size\nData\nAlgorithm\nBSF\nF1\nPrecision\nRecall\nAsia\n1000\nClean\nTabu-AL\n0.53 ± 0.18\n0.67 ± 0.14\n0.71 ± 0.15\n0.64 ± 0.13\nBayesys Model Avg\n0.38 ± 0.07\n0.56 ± 0.04\n0.46 ± 0.04\n0.72 ± 0.06\nExpert Model Avg (ours)\n0.58 ± 0.13\n0.69 ± 0.09\n0.65 ± 0.12\n0.75 ± 0.09\nNoisy\nTabu-AL\n0.34 ± 0.16\n0.51 ± 0.17\n0.81 ± 0.27\n0.37 ± 0.13\nBayesys Model Avg\n0.13 ± 0.00\n0.36 ± 0.00\n0.40 ± 0.00\n0.33 ± 0.00\nExpert Model Avg (ours)\n0.27 ± 0.10\n0.46 ± 0.10\n0.52 ± 0.08\n0.42 ± 0.11\n10000\nClean\nTabu-AL\n0.42 ± 0.34\n0.61 ± 0.21\n0.57 ± 0.24\n0.68 ± 0.17\nBayesys Model Avg\n0.31 ± 0.14\n0.53 ± 0.07\n0.40 ± 0.07\n0.80 ± 0.07\nExpert Model Avg (ours)\n0.67 ± 0.11\n0.72 ± 0.07\n0.60 ± 0.09\n0.93 ± 0.07\nNoisy\nTabu-AL\n0.36 ± 0.16\n0.54 ± 0.12\n0.54 ± 0.11\n0.54 ± 0.13\nBayesys Model Avg\n0.28 ± 0.04\n0.50 ± 0.03\n0.44 ± 0.03\n0.58 ± 0.03\nExpert Model Avg (ours)\n0.44 ± 0.12\n0.59 ± 0.08\n0.55 ± 0.06\n0.66 ± 0.12\nAlarm\n1000\nClean\nTabu-AL\n0.63 ± 0.05\n0.71 ± 0.07\n0.80 ± 0.10\n0.64 ± 0.05\nBayesys Model Avg\n0.70 ± 0.02\n0.50 ± 0.02\n0.36 ± 0.01\n0.80 ± 0.02\nExpert Model Avg (ours)\n0.77 ± 0.04\n0.70 ± 0.03\n0.63 ± 0.04\n0.80 ± 0.04\nNoisy\nTabu-AL\n0.35 ± 0.05\n0.48 ± 0.06\n0.75 ± 0.08\n0.35 ± 0.05\nBayesys Model Avg\n0.47 ± 0.02\n0.54 ± 0.01\n0.60 ± 0.02\n0.50 ± 0.02\nExpert Model Avg (ours)\n0.51 ± 0.04\n0.63 ± 0.04\n0.78 ± 0.05\n0.52 ± 0.04\n10000\nClean\nTabu-AL\n0.69 ± 0.06\n0.70 ± 0.07\n0.68 ± 0.09\n0.72 ± 0.05\nBayesys Model Avg\n0.80 ± 0.03\n0.58 ± 0.02\n0.43 ± 0.02\n0.89 ± 0.03\nExpert Model Avg (ours)\n0.82 ± 0.05\n0.75 ± 0.04\n0.67 ± 0.06\n0.85 ± 0.05\nNoisy\nTabu-AL\n0.55 ± 0.06\n0.61 ± 0.07\n0.64 ± 0.08\n0.58 ± 0.06\nBayesys Model Avg\n0.59 ± 0.01\n0.57 ± 0.01\n0.51 ± 0.01\n0.65 ± 0.02\nExpert Model Avg (ours)\n0.64 ± 0.04\n0.68 ± 0.03\n0.69 ± 0.04\n0.68 ± 0.05\nPathfinder\n1000\nClean\nTabu-AL\n0.21 ± 0.03\n0.19 ± 0.04\n0.17 ± 0.10\n0.26 ± 0.03\nBayesys Model Avg\n0.43 ± 0.03\n0.23 ± 0.05\n0.15 ± 0.05\n0.54 ± 0.03\nExpert Model Avg (ours)\n0.42 ± 0.02\n0.41 ± 0.03\n0.39 ± 0.06\n0.44 ± 0.02\nNoisy\nTabu-AL\n0.14 ± 0.01\n0.15 ± 0.02\n0.84 ± 0.07\n0.08 ± 0.01\nBayesys Model Avg\n0.26 ± 0.02\n0.27 ± 0.04\n0.32 ± 0.09\n0.25 ± 0.02\nExpert Model Avg (ours)\n0.24 ± 0.01\n0.30 ± 0.02\n0.64 ± 0.11\n0.20 ± 0.01\n10000\nClean\nTabu-AL\n0.37 ± 0.02\n0.44 ± 0.04\n0.54 ± 0.06\n0.38 ± 0.02\nBayesys Model Avg\n0.59 ± 0.05\n0.41 ± 0.05\n0.31 ± 0.05\n0.64 ± 0.05\nExpert Model Avg (ours)\n0.48 ± 0.04\n0.52 ± 0.03\n0.55 ± 0.06\n0.49 ± 0.04\nNoisy\nTabu-AL\n0.23 ± 0.01\n0.27 ± 0.02\n0.42 ± 0.03\n0.20 ± 0.01\nBayesys Model Avg\n0.34 ± 0.02\n0.39 ± 0.02\n0.48 ± 0.02\n0.33 ± 0.02\nExpert Model Avg (ours)\n0.29 ± 0.01\n0.38 ± 0.02\n0.70 ± 0.03\n0.26 ± 0.02\nSimSUM\n1000\nClean\nTabu-AL\n0.07 ± 0.02\n0.13 ± 0.03\n0.94 ± 0.11\n0.07 ± 0.02\nBayesys Model Avg\n0.16 ± 0.05\n0.46 ± 0.02\n0.35 ± 0.02\n0.69 ± 0.03\nExpert Model Avg (ours)\n0.39 ± 0.06\n0.57 ± 0.04\n0.53 ± 0.05\n0.62 ± 0.05\nNoisy\nTabu-AL\n0.01 ± 0.02\n0.03 ± 0.03\n0.72 ± 0.45†\n0.02 ± 0.01\nBayesys Model Avg\n0.08 ± 0.06\n0.31 ± 0.07\n0.48 ± 0.06\n0.23 ± 0.06\nExpert Model Avg (ours)\n0.14 ± 0.06\n0.33 ± 0.06\n0.62 ± 0.09\n0.23 ± 0.05\n10000\nClean\nTabu-AL\n0.31 ± 0.04\n0.47 ± 0.05\n0.97 ± 0.05\n0.31 ± 0.04\nBayesys Model Avg\n0.53 ± 0.06\n0.67 ± 0.05\n0.73 ± 0.07\n0.62 ± 0.04\nExpert Model Avg (ours)\n0.60 ± 0.04\n0.74 ± 0.03\n0.88 ± 0.04\n0.64 ± 0.03\nNoisy\nTabu-AL\n0.08 ± 0.02\n0.14 ± 0.04\n1.00 ± 0.00\n0.08 ± 0.02\nBayesys Model Avg\n0.17 ± 0.05\n0.29 ± 0.07\n0.95 ± 0.07\n0.17 ± 0.05\nExpert Model Avg (ours)\n0.21 ± 0.04\n0.34 ± 0.06\n0.98 ± 0.05\n0.21 ± 0.04\nSUM and orientation accuracy for ALARM are in-line\nwith the 80% accuracy we use for the main results of\nour simulated expert, the LLM notably struggles with\nanswering existence queries for the ALARM network,\neffectively answering with coin-flip accuracy. As dis-\ncussed further in Appendix H, this may be in part\ndue to particularities in the design of ALARM fore-\nmost as a diagnostic tool rather than a physiological\ncausal model.\nTable 4 compares the performance of the ensem-\nble using the LLM expert vs. the simulated expert\non BSF, SHD, F1, recall, and precision scores. The\nLLM expert typically performs better on recall and\ncomparably on BSF, but worse on the other metrics,\nespecially precision.\nThis likely reflects both a) a\n6\n"}, {"page": 7, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nFigure 1: The mean delta in graphical accuracy metrics compared to our method (edge threshold θ1 = 0.0,\norientation threshold θ2 = 0.7, and expert correctness = 80%).\nTo standardize the SHD, we\ncompute the relative SHD to our method. ∗indicates some missing results for an algorithm due\nto timeouts (>6h) or exceptions. † indicates some invalid results for an algorithm (only applicable\nto precision). Missing and invalid results are excluded from the calculation.\n7\n"}, {"page": 8, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nFigure 2: Graphical accuracy metrics, averaged across all runs, plotted over expert correctnesses ∈\n{50%, 60%, 70%, 80%, 90%, 100%}. Bayesys Model Avg is provided as a static baseline for com-\nparison, as an ensembling method not using expert knowledge.\nTable 3: LLM accuracy on orientation and existence\nqueries for benchmark clinical networks\nNetwork\nOrientation\nExistence\nOverall\nAsia\n100.0%\n70.0%\n84.2%\nAlarm\n82.6%\n49.9%\n58.1%\nSimSUM\n100.0%\n74.2%\n85.8%\nbias in the LLM towards accepting causal relation-\nships that it should reject, and, to a lesser extent,\nb) a consequence of the metrics weighing the correct\n(non)existence of an edge more highly than a correct\norientation, coupled with the LLM performing better\nat determining orientations than existence.\n4.6. Calls to expert\nTable 5 shows the number of calls made to the simu-\nlated expert and LLM on individual networks and\ntraining sizes, for clean and noisy data, averaged\nacross 20 seeds. The number of calls to the expert\ngenerally decreases as the sample size increases, likely\nreflecting an increase in the number of edges in the\nensemble that pass a majority vote and are there-\nfore not sent to the expert for possible rejection. The\nnumber of calls is also consistent between the LLM\nand simulated expert for the same network.\nCuri-\nously, some networks (sports, property, and ALARM)\ninstead show an increase in calls to the expert with\ngreater sample sizes under noisy data. This suggests\ngreater instability and disagreement between algo-\nrithms under noisy data for some networks than oth-\ners.\n8\n"}, {"page": 9, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nFigure 3: Graphical accuracy metrics, averaged across all runs, plotted over edge threshold θ1\n∈\n{0.0, 0.1, 0.2, ..., 1.0}, with fixed orientation threshold θ2 = 0.7 and expert correctness 80%.\nBayesys Model Avg is provided as a static baseline for comparison.\n5. Conclusion\nWe provide a flexible approach for model averaging in\ncausal discovery using dynamically requested expert\nknowledge. Experiments demonstrate the improve-\nments of our approach over both ensembles without\nexpert knowledge and individual algorithms using dy-\nnamically requested knowledge, on both clean and\nnoisy data.\nFurther experiments study the impact\nof expert correctness on our method and establish\nthe viability of using an LLM as an expert. To our\nknowledge, this study constitutes the first method\nfor leveraging expert knowledge in the ensembling of\ncausal discovery algorithms.\nOur work has several important limitations. Our\nexperiments involve only synthetic, categorical data.\nWhile our model averaging approach is general and\nshould be applicable to other types of data (e.g. con-\ntinuous or mixed), provided appropriate choices are\nmade for the component algorithms, this is not yet\nverified empirically. Furthermore, while we include\nexperiments on noisy data, the synthetic noise we use\ncannot be expected to cover all real-world conditions.\nFuture work can seek to address these limitations\nby employing our method on different data types and\nnoise distributions, including on real data.\nAddi-\ntional possibilities include using our model averag-\ning method across multiple runs of the same cho-\nsen algorithm rather than across an ensemble of dis-\nparate algorithms, providing improved stability (for\nnon-deterministic algorithms or algorithms sensitive\nto variable ordering) or efficiency (across different\ndata partitions). Finally, while to our knowledge this\nwork is the first to explore the use of dynamic ex-\npert knowledge for model averaging, we foresee great\npotential for future exploration along this avenue.\n9\n"}, {"page": 10, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nTable 4: LLM vs. simulated expert (θ1 = 0.0, θ2 = 0.7, expert correctness 80%)\n± indicates one standard deviation.\nNetwork\nSample size\nExpert\nBSF\nSHD\nF1\nPrecision\nRecall\nAsia\n100\nSim\n0.42 ± 0.15\n7.20 ± 1.84\n0.58 ± 0.11\n0.55 ± 0.11\n0.63 ± 0.11\n100\nLLM\n0.33 ± 0.07\n10.72 ± 1.07\n0.54 ± 0.04\n0.41 ± 0.03\n0.78 ± 0.07\n1000\nSim\n0.58 ± 0.13\n5.38 ± 1.81\n0.69 ± 0.09\n0.65 ± 0.12\n0.75 ± 0.09\n1000\nLLM\n0.54 ± 0.05\n7.55 ± 0.72\n0.65 ± 0.03\n0.52 ± 0.03\n0.87 ± 0.05\n10000\nSim\n0.67 ± 0.11\n5.80 ± 1.89\n0.72 ± 0.07\n0.60 ± 0.09\n0.93 ± 0.07\n10000\nLLM\n0.52 ± 0.12\n9.65 ± 2.37\n0.63 ± 0.06\n0.46 ± 0.07\n1.00 ± 0.00\n100000\nSim\n0.78 ± 0.12\n2.92 ± 1.70\n0.83 ± 0.09\n0.80 ± 0.12\n0.88 ± 0.09\n100000\nLLM\n0.81 ± 0.11\n3.90 ± 2.13\n0.81 ± 0.09\n0.69 ± 0.12\n1.00 ± 0.00\nAlarm\n100\nSim\n0.58 ± 0.06\n50.20 ± 8.80\n0.54 ± 0.04\n0.48 ± 0.07\n0.64 ± 0.06\n100\nLLM\n0.55 ± 0.03\n87.08 ± 15.37\n0.42 ± 0.03\n0.31 ± 0.05\n0.66 ± 0.05\n1000\nSim\n0.77 ± 0.04\n30.90 ± 3.79\n0.70 ± 0.03\n0.63 ± 0.04\n0.80 ± 0.04\n1000\nLLM\n0.75 ± 0.02\n59.48 ± 3.93\n0.56 ± 0.02\n0.43 ± 0.02\n0.83 ± 0.02\n10000\nSim\n0.82 ± 0.05\n26.42 ± 5.08\n0.75 ± 0.04\n0.67 ± 0.06\n0.85 ± 0.05\n10000\nLLM\n0.82 ± 0.02\n47.30 ± 4.17\n0.63 ± 0.02\n0.49 ± 0.02\n0.89 ± 0.02\n100000\nSim\n0.88 ± 0.03\n20.15 ± 2.29\n0.81 ± 0.02\n0.73 ± 0.03\n0.91 ± 0.03\n100000\nLLM\n0.88 ± 0.01\n30.98 ± 2.52\n0.73 ± 0.02\n0.61 ± 0.02\n0.92 ± 0.01\nSimSUM\n100\nSim\n0.39 ± 0.06\n32.88 ± 3.73\n0.57 ± 0.04\n0.53 ± 0.05\n0.62 ± 0.05\n100\nLLM\n0.39 ± 0.04\n41.12 ± 2.26\n0.57 ± 0.02\n0.45 ± 0.02\n0.78 ± 0.03\n1000\nSim\n0.39 ± 0.06\n32.88 ± 3.73\n0.57 ± 0.04\n0.53 ± 0.05\n0.62 ± 0.05\n1000\nLLM\n0.39 ± 0.04\n41.12 ± 2.26\n0.57 ± 0.02\n0.45 ± 0.02\n0.78 ± 0.03\n10000\nSim\n0.60 ± 0.04\n15.68 ± 1.84\n0.74 ± 0.03\n0.88 ± 0.04\n0.64 ± 0.03\n10000\nLLM\n0.64 ± 0.05\n16.32 ± 2.66\n0.75 ± 0.04\n0.80 ± 0.06\n0.71 ± 0.03\n100000\nSim\n0.66 ± 0.05\n13.42 ± 2.48\n0.78 ± 0.04\n0.90 ± 0.05\n0.70 ± 0.05\n100000\nLLM\n0.68 ± 0.05\n15.08 ± 2.50\n0.78 ± 0.03\n0.81 ± 0.05\n0.75 ± 0.03\nTable 5: Number of calls to expert (θ1 = 0.0, θ2 = 0.7, expert correctness 80%)\n± indicates one standard deviation.\nNetwork\nData\nLLM?\n100\n1000\n10000\n100000\nAsia\nClean\n19.50 ± 2.31\n12.30 ± 1.72\n14.90 ± 2.43\n8.10 ± 2.86\nAsia\nClean\n✓\n19.95 ± 2.82\n12.75 ± 1.80\n15.30 ± 2.47\n8.15 ± 2.92\nAsia\nNoisy\n8.25 ± 0.97\n8.00 ± 0.56\n8.15 ± 1.18\n6.80 ± 1.24\nSports\nClean\n12.00 ± 1.26\n12.00 ± 1.26\n16.70 ± 1.63\n12.80 ± 1.77\nSports\nNoisy\n10.20 ± 1.96\n6.80 ± 0.83\n15.70 ± 2.08\n16.65 ± 2.18\nProperty\nClean\n44.50 ± 2.42\n37.60 ± 4.56\n37.25 ± 4.44\n30.00 ± 4.71\nProperty\nNoisy\n32.85 ± 3.62\n31.90 ± 2.83\n48.05 ± 3.00\n65.45 ± 4.19\nAlarm\nClean\n130.40 ± 26.57\n96.35 ± 4.00\n79.95 ± 5.45\n48.70 ± 4.04\nAlarm\nClean\n✓\n131.60 ± 27.19\n99.40 ± 4.58\n81.35 ± 5.67\n51.90 ± 5.72\nAlarm\nNoisy\n62.35 ± 5.39\n55.15 ± 4.90\n56.50 ± 4.43\n78.15 ± 6.79\nFormed\nClean\n532.35 ± 139.07\n386.15 ± 95.09\n469.35 ± 88.45\n313.45 ± 166.68\nFormed\nNoisy\n430.20 ± 108.08\n430.20 ± 108.08\n411.15 ± 91.89\n157.15 ± 23.14\nPathfinder\nClean\n938.05 ± 27.69\n769.50 ± 145.09\n407.35 ± 95.69\n46.25 ± 6.90\nPathfinder\nNoisy\n249.55 ± 93.00\n249.55 ± 93.00\n167.00 ± 10.90\n31.65 ± 6.40\nSimSUM\nClean\n80.55 ± 3.52\n80.55 ± 3.52\n33.25 ± 3.26\n30.50 ± 3.14\nSimSUM\nClean\n✓\n83.45 ± 3.19\n83.45 ± 3.19\n33.90 ± 3.34\n31.20 ± 3.16\nSimSUM\nNoisy\n25.75 ± 2.55\n25.75 ± 2.55\n10.65 ± 1.76\n16.85 ± 2.46\n10\n"}, {"page": 11, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nReferences\nBryan\nAndrews,\nJoseph\nRamsey,\nRuben\nSanchez Romero, Jazmin Camchong, and Erich\nKummerfeld. Fast scalable and accurate discovery\nof dags using the best order score search and\ngrow shrink trees. Advances in neural information\nprocessing systems, 36:63945–63956, 2023.\nAnkur Ankan and Johannes Textor.\npgmpy:\nA\npython toolkit for bayesian networks.\nJour-\nnal of Machine Learning Research,\n25(265):1–\n8, 2024.\nURL http://jmlr.org/papers/v25/\n23-0487.html.\nBabak Aslani and Shima Mohebbi. Ensemble frame-\nwork for causality learning with heterogeneous di-\nrected acyclic graphs through the lens of opti-\nmization. Computers & Operations Research, 152:\n106148, 2023.\nIngo A Beinlich, Henri Jacques Suermondt, R Martin\nChavez, and Gregory F Cooper. The alarm moni-\ntoring system: A case study with two probabilistic\ninference techniques for belief networks. In AIME\n89: Second European Conference on Artificial In-\ntelligence in Medicine, London, August 29th–31st\n1989. Proceedings, pages 247–256. Springer, 1989.\nRemco Ronaldus Bouckaert.\nBayesian belief net-\nworks: from construction to inference. PhD thesis,\nUniversiteit Utrecht, 1995.\nDavid Maxwell Chickering.\nLearning equivalence\nclasses of bayesian-network structures. Journal of\nmachine learning research, 2(Feb):445–498, 2002.\nDiego\nColombo,\nMarloes\nH\nMaathuis,\net\nal.\nOrder-independent constraint-based causal struc-\nture learning. J. Mach. Learn. Res., 15(1):3741–\n3782, 2014.\nA Constantinou. The bayesys user manual. Queen\nMary University of London, London, UK.[Online].\nSoftware available: http://bayesian-ai. eecs. qmul.\nac. uk/bayesys, 2019a.\nAnthony C Constantinou. Evaluating structure learn-\ning algorithms with a balanced scoring function.\narXiv preprint arXiv:1905.12666, 2019b.\nAnthony C Constantinou,\nYang Liu,\nKiattikun\nChobtham, Zhigao Guo, and Neville K Kitson.\nThe bayesys data and bayesian network repository.\nQueen Mary University of London: London, UK,\n2020.\nAnthony C Constantinou,\nYang Liu,\nKiattikun\nChobtham, Zhigao Guo, and Neville K Kitson.\nLarge-scale empirical validation of bayesian net-\nwork structure learning algorithms with noisy data.\nInternational Journal of Approximate Reasoning,\n131:151–188, 2021.\nAnthony C Constantinou, Yang Liu, Neville K Kit-\nson, Kiattikun Chobtham, and Zhigao Guo.\nEf-\nfective and efficient structure learning with prun-\ning and model averaging strategies. International\nJournal of Approximate Reasoning, 151:292–321,\n2022.\nAnthony C Constantinou, Zhigao Guo, and Neville K\nKitson. The impact of prior knowledge on causal\nstructure learning.\nKnowledge and Information\nSystems, 65(8):3385–3434, 2023.\nAntti Hyttinen, Patrik O Hoyer, Frederick Eber-\nhardt, and Matti Jarvisalo.\nDiscovering cyclic\ncausal models with latent variables: A general sat-\nbased procedure. arXiv preprint arXiv:1309.6836,\n2013.\nElahe Khatibi, Mahyar Abbasian, Zhongqi Yang,\nIman Azimi, and Amir M Rahmani. Alcm: Au-\ntonomous llm-augmented causal discovery frame-\nwork. arXiv preprint arXiv:2405.01744, 2024.\nNeville K Kitson and Anthony C Constantinou. The\nimpact of variable ordering on bayesian network\nstructure learning.\nData Mining and Knowledge\nDiscovery, 38(4):2545–2569, 2024.\nNeville K Kitson and Anthony C Constantinou.\nCausal\ndiscovery\nusing\ndynamically\nrequested\nknowledge. Knowledge-Based Systems, 314:113185,\n2025.\nNeville Kenneth Kitson, Anthony C Constantinou,\nZhigao Guo, Yang Liu, and Kiattikun Chobtham.\nA survey of bayesian network structure learn-\ning.\nArtificial Intelligence Review, 56(8):8721–\n8814, 2023.\nEvangelia Kyrimi, Scott McLachlan, Kudakwashe\nDube, Mariana R Neves, Ali Fahmi, and Nor-\nman Fenton. A comprehensive scoping review of\nbayesian networks in healthcare: Past, present and\nfuture.\nArtificial Intelligence in Medicine, 117:\n102108, 2021.\n11\n"}, {"page": 12, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nXiaoyu Liu, Paiheng Xu, Junda Wu, Jiaxin Yuan,\nYifan Yang, Yuhang Zhou, Fuxiao Liu, Tianrui\nGuan, Haoliang Wang, Tong Yu, et al. Large lan-\nguage models and causal inference in collaboration:\nA comprehensive survey. Findings of the Associa-\ntion for Computational Linguistics: NAACL 2025,\npages 7668–7684, 2025.\nYang Liu and Anthony C Constantinou.\nGreedy\nstructure learning from data that contain system-\natic missing values.\nMachine Learning, 111(10):\n3867–3896, 2022.\nStuart Mitchell, Michael OSullivan, and Iain Dun-\nning.\nPulp:\na linear programming toolkit for\npython.\nThe University of Auckland, Auckland,\nNew Zealand, 65:25, 2011.\nBruno Petrungaro, Neville K Kitson, and Anthony C\nConstantinou.\nInvestigating potential causes of\nsepsis with bayesian network structure learning.\nApplied Intelligence, 55(6):496, 2025.\nPaloma Rabaey, Stefan Heytens, and Thomas De-\nmeester. Simsum–simulated benchmark with struc-\ntured and unstructured medical records. Journal of\nBiomedical Semantics, 16(1):20, 2025.\nJoseph Ramsey and Bryan Andrews. Py-tetrad and\nrpy-tetrad: A new python interface with r support\nfor tetrad causal search. In Causal Analysis Work-\nshop Series, pages 40–51. PMLR, 2023.\nMarco Scutari, Maintainer Marco Scutari, and Hiton-\nPC MMPC. Package ‘bnlearn’. Bayesian network\nstructure learning, parameter learning and infer-\nence, R package version, 4(1), 2019.\nXinpeng\nShen,\nSisi\nMa,\nPrashanthi\nVemuri,\nM Regina Castro, Pedro J Caraballo, and Gyorgy J\nSimon. A novel method for causal structure dis-\ncovery from ehr data and its application to type-2\ndiabetes mellitus. Scientific reports, 11(1):21025,\n2021.\nPeter Spirtes,\nClark N Glymour,\nand Richard\nScheines. Causation, prediction, and search. MIT\npress, 2000.\nPeter L Spirtes, Christopher Meek, and Thomas S\nRichardson.\nCausal inference in the presence of\nlatent variables and selection bias. arXiv preprint\narXiv:1302.4983, 2013.\nZhenchao Tao, Huanhuan Chen, Yijia Sun, Qiang Tu,\nFei Gao, Lyuzhou Chen, Wei Wang, and Yanze\nGao.\nActive differentiable structure learning for\nclinical causal discovery.\nKnowledge-Based Sys-\ntems, page 114145, 2025.\nIoannis Tsamardinos, Laura E Brown, and Con-\nstantin F Aliferis.\nThe max-min hill-climbing\nbayesian network structure learning algorithm.\nMachine learning, 65(1):31–78, 2006.\nAniket Vashishtha, Abbavaram Gowtham Reddy,\nAbhinav Kumar, Saketh Bachu, Vineeth N Bal-\nasubramanian, and Amit Sharma. Causal order:\nThe key to leveraging imperfect experts in causal\ninference. In The Thirteenth International Confer-\nence on Learning Representations, 2025.\nHaoyu Yang, Roshan Tourani, Jia Li, Pedro Cara-\nballo, Michael Steinbach, Vipin Kumar, and Gy-\norgy Simon.\nCausal structure learning from im-\nperfect longitudinal data in healthcare.\nIn 2023\nIEEE 11th International Conference on Healthcare\nInformatics (ICHI), pages 1–11. IEEE, 2023.\nYue Yu, Jie Chen, Tian Gao, and Mo Yu. Dag-gnn:\nDag structure learning with graph neural networks.\nIn International conference on machine learning,\npages 7154–7163. PMLR, 2019.\nSheresh Zahoor, Pietro Li`o, Ga¨el Dias, and Mo-\nhammed Hasanuzzaman. Integrating probabilistic\ntrees and causal networks for clinical and epidemi-\nological data.\narXiv preprint arXiv:2501.15973,\n2025.\nXun Zheng, Bryon Aragam, Pradeep K Ravikumar,\nand Eric P Xing. Dags with no tears: Continuous\noptimization for structure learning.\nAdvances in\nneural information processing systems, 31, 2018.\nYujia Zheng, Biwei Huang, Wei Chen, Joseph Ram-\nsey, Mingming Gong, Ruichu Cai, Shohei Shimizu,\nPeter Spirtes, and Kun Zhang.\nCausal-learn:\nCausal discovery in python. Journal of Machine\nLearning Research, 25(60):1–8, 2024.\nZhi-Hua Zhou. Ensemble methods: foundations and\nalgorithms. CRC press, 2025.\n12\n"}, {"page": 13, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nAppendix A. Hyperparameter and\nimplementation details\nWe list the implementations and hyperparameter\nchoices used for the baseline algorithms in Table 6.\nAppendix B. Selection of edge and\norientation thresholds\nKeeping the correctness of our simulated expert fixed\nat 80%, we test our method with all combinations of\nedge threshold θ1 ∈{0.0, 0.1, 0.2, ..., 1.0} and orien-\ntation threshold θ2 ∈{0.5, 0.6, 0.7, 0.8, 0.9, 1.0}. We\nchoose the settings θ1 = 0.0, θ2 = 0.7 as they pro-\nvide the highest BSF and F1 scores, averaged across\nall networks, sample sizes, for both clean and noisy\ndata.\nThese settings also provide the highest BSF\nwhen considering clean and noisy data separately.\nAppendix C. Complete results\nTables 7-18 report the BSF, SHD, F1-score, preci-\nsion, and recall of methods on individual networks\nand training sizes, for clean and noisy data, averaged\nacross 20 seeds. In all tables, A * or - indicates some\nor all runs, respectively, timed out (>6h) or yielded\nan exception. In the case of precision, † or nan indi-\ncates some or all runs, respectively, yielded an invalid\nprecision score. ± indicates one standard deviation.\nAppendix D. Excluded results\nA ”-” in the complete result tables in Appendix C\ngenerally indicates that all runs of that algorithm for\nthat network, data type, and sample size timed out\n(>6h), with the following exceptions:\n• Aslani & Mohebbi ensembling ran out of mem-\nory (>32GB) on the formed and pathfinder net-\nworks.\n• BOSS ran out of memory (>32GB) on the\npathfinder network.\nThe only algorithm that yielded exceptions on some\n(but not all) seeds for certain network, data type, and\nsample size combinations was BOSS, which occasion-\nally yielded an invalid comparator error.\nAppendix E. Individual plots for\nexpert correctness\nFigures 4-11 plot the BSF, F1-score, precision, and\nrecall of our method at expert correctnesses ∈\n{50%, 60%, 70%, 80%, 90%, 100%} on individual net-\nworks and training sizes, for clean and noisy data,\naveraged across 20 seeds. A linear improvement with\nexpert correctness is observed for most metrics, net-\nworks, and training sizes.\nAppendix F. LLM prompts\nWe provide our prompt templates below.\nThe\nrelevant substitutions (e.g.\nnetwork and variable\ndescriptions)\nare\nincluded\nin\nour\ncode,\navail-\nable\nat\nhttps://anonymous.4open.science/r/\nexpert-cd-ensemble-3281/. We use the following\nprompt for orientation queries:\nWe are currently constructing a causal\ngraph for a dataset covering <dataset\ndescription>.\nYou are an <expertise\ndescription>.\nAssume that there is a\nplausible causal relationship between\nthe following two variables (possibly\nindirect).\nYour task is to determine the\nmost plausible *causal ordering* between\nthem.\nCausation may be direct or indirect\n(via unobserved or observed mediators).\nThe two variables under consideration are:\n’’<X>’ with possible values <X values>,\ndescribed as <X description>\n’’<Y>’ with possible values <Y values>,\ndescribed as <Y description>\nBefore answering, consider:\n- Which variable is more plausibly\nupstream.\n- Whether intervening on one would\nreasonably be expected to change the other.\n- Whether one variable represents a more\ndownstream outcome.\nNote that aggregated\nvariables are downstream of (and directly\ncaused by) what they aggregate.\n- Whether either variable primarily serves\nas evidence of underlying processes rather\nthan a driver.\nA: ’<X>’ is a cause (possibly indirect) of\n’<Y>’ (<X> ->* <Y>).\nB: ’<Y>’ is a cause (possibly indirect) of\n’<X>’ (<Y> ->* <X>).\n13\n"}, {"page": 14, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nTable 6: Algorithm implementations and hyperparameter choices.\nWe typically use the hyperparameter\ndefaults of the implementation or the recommendations of the authors, as available.\nα is the dependency threshold [with dependency score], MID is the maximum in-degree\nAlgorithm\nSoftware\nHyperparameter settings\nPC-Stable\npgmpy (Ankan and Textor, 2024)\nα = 0.01[G2]\nFCI\ncausal-learn (Zheng et al., 2024)\nα = 0.01[Chi2]\nMMHC\nbnlearn (Scutari et al., 2019)\nα = 0.05 [MI], score BIC\nTabu\nImplemented in Python 3.12.3, using:\npgmpy (Ankan and Textor, 2024)\nescapes = 10, score BIC\nGES\npgmpy (Ankan and Textor, 2024)\nscore BIC\nMAHC\nImplemented in Python 3.12.3, using:\npgmpy (Ankan and Textor, 2024)\nMID(pruning) = 3, MID(learning) = 8,\nscore BIC\nBOSS\npy-tetrad\n(Ramsey\nand\nAndrews,\n2023)\nnum starts = 1, use BES = False,\nscore Bdeu\nDAG-GNN\noriginal Python source code (Yu et al.,\n2019)\nthreshold = 0.3, λ = 0, c = 1, τ = 0\nBayesys model average\nImplemented in Python 3.12.3, using:\npgmpy (Ankan and Textor, 2024)\nminimum count = 1\nAslani-Mohebbi ensemble\nImplemented in Python 3.12.3, using:\npgmpy (Ankan and Textor, 2024)\nPuLP (Mitchell et al., 2011)\np = 0.33, q = 0.15\nTabu-AL\nImplemented in Python 3.12.3, using:\npgmpy (Ankan and Textor, 2024)\nescapes = 10, score BIC, low delta thresh-\nold = 0.20, small counts threshold = 0.01,\nunreliable score threshold = 0.001, request\nlimit = ∞\nProvide a brief causal analysis (2-4\nsentences), then conclude with:\n\"The correct choice is:\n<A/B>\"\nAnd the following for existence queries:\nWe are currently constructing a causal\ngraph for a dataset covering <dataset\ndescription>.\nYou are an <expertise\ndescription>.\nYour task is to determine\nwhether there is a plausible *causal\nrelationship* between two variables.\nThe\nrelationship may be direct or indirect, and\nmay involve unobserved mediators.\nYou are\nnot asked to determine direction at this\nstage.\nThe two variables under consideration are:\n’’<X>’ with possible values <X values>,\ndescribed as <X description>\n’’<Y>’ with possible values <Y values>,\ndescribed as <Y description>\nAssume that:\n- The true causal graph may include\nunobserved variables.\n- Observed associations alone do not\ndetermine causal ordering.\nBefore answering, consider:\n- Whether the variables are part of\nthe same underlying (domain-relevant)\nmechanism.\n- Whether there exists a specific,\ndomain-supported causal mechanism by which\nchanging one would plausibly alter the\nother, beyond general shared factors.\n- Whether any observed association is\nmore likely explained by confounding or\nselection effects.\n- Whether the variables operate at\ncompatible levels (e.g., trait vs symptom,\nbackground vs outcome).\n- Whether the variables are better\n14\n"}, {"page": 15, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nunderstood as parallel consequences of\nbroader factors rather than causally linked\nto each other.\nA: There is a plausible causal relationship\nbetween ’<X>’ and ’<Y>’.\nB: There is no meaningful causal\nrelationship between ’<X>’ and ’<Y>’; any\nassociation is likely due to shared causes\nor noise.\nProvide a brief causal analysis (2-4\nsentences), then conclude with:\n\"The\ncorrect choice is:\n<A/B>\"\nFor the ALARM network, we include the following\nadditional text in the prompts for orientation queries:\nAdditionally, note that:\n- Variables that represent errors or\nsystem failures are root causes of\nother measurements and not downstream of\nanything.\n- Measurements, indicators, or monitoring\noutputs depend on underlying physiological\nstates and cannot cause them.\nLikewise, we include the following additional text\nin the prompts for existence queries:\nChoose A only if at least one of the\nfollowing clearly applies:\n- one variable directly produces the other\nthrough a known mechanism\n- one variable is an upstream structural or\npathological cause of the other\n- one variable is a downstream aggregate or\nconsequence of the other\nAppendix G. LLM memorization of\nbenchmark networks\nAs noted in 4.5, we acknowledge the potential that\nthe LLM has seen, and possibly memorized, the\nbenchmark networks in its training data.\nWe con-\nduct the following case study as a limited assessment\nof the degree to which this has occurred, prompting\nthe chosen LLM (gpt-5-nano) to provide the full\nstructure of the networks ASIA, ALARM, and\nSimSUM:\nProvide the structure of the <network\nname> bayesian network as a list of edges.\nFormat the answer as a python list of\ntuples strings, i.e.\n[(’x’, ’y’), ...],\nwhere (’x’, ’y’) indicates an edge x ->\ny in the network.\nDo your best even if\nyou don’t believe you have the network\nmemorized.\nAnswer only with the edge list.\nTo avoid ambiguity in the networks, we use the\nfollowing substitutions for ¡network name¿: ’ASIA’,\n’ALARM clinical monitoring’, and ’SimSUM patient\nencounters for respiratory diseases’.\nThe response for ASIA is almost perfect, merely\neliding the aggregate variable ’either’, indicating a\nhigh degree of memorization:\n[(’Asia’, ’Tuberculosis’), (’Smoking’,\n’Lung Cancer’), (’Tuberculosis’, ’XRay’),\n(’Lung Cancer’, ’XRay’), (’Tuberculosis’,\n’Dyspnea’), (’Lung Cancer’, ’Dyspnea’),\n(’Bronchitis’, ’Dyspnea’), (’Smoking’,\n’Bronchitis’)]\nThe LLM refused to provide a response for\nALARM, even after adding the text from ”Do your\nbest...” on (not initially included in the prompt), an-\nswering with an empty list.\nThe following response was provided for SimSUM.\nIt contains 22 edges compared to SimSUM’s 35, and\n20 nodes compared to SimSUM’s 16, with only 5\nof the 20 (25%) directly corresponding to nodes in\nSimSUM.\n[(’age’, ’pneumonia’), (’smoking’,\n’pneumonia’), (’exposure’, ’pneumonia’),\n(’age’, ’asthma exacerbation’),\n(’sex’, ’asthma exacerbation’),\n(’smoking’, ’copd exacerbation’),\n(’acute bronchitis’, ’cough’), (’pneumonia’,\n’cough’), (’pneumonia’, ’fever’),\n(’pneumonia’, ’sob’), (’fever’, ’cbc wbc’),\n(’cbc wbc’, ’pneumonia diagnosis’),\n(’cxr result’, ’pneumonia diagnosis’),\n(’pneumonia diagnosis’, ’antibiotics’),\n(’pneumonia diagnosis’, ’bronchodilators’),\n(’asthma exacerbation’, ’wheeze’),\n(’wheeze’, ’sob’), (’sob’, ’pulse ox’),\n(’resp rate’, ’pulse ox’), (’pulse ox’,\n’disposition’), (’antibiotics’,\n15\n"}, {"page": 16, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\n’disposition’), (’bronchodilators’,\n’disposition’)]\nOverall, these results point to high memorization\nfor the ASIA network, but low or none for ALARM\nand SimSUM.\nAppendix H. LLM performance on\nclinical networks\nAs seen in Section 4.5, the LLM performs much bet-\nter on the ASIA and SimSUM networks than the\nALARM network.\nLike ASIA and SimSUM, the\norientation of arrows in the ALARM has a realis-\ntic causal interpretation (from diagnosis to evidence\nrather than the reverse) (Beinlich et al., 1989), which\nshould allow an LLM to accurately answer orienta-\ntion queries. However, the structure of the ALARM\nnetwork may involve modeling choices that make it\ndifficult for an LLM to accurately determine the ex-\nistence of causal relationships between certain vari-\nables. For example, in the ALARM network the vari-\nables KINKEDTUBE and SHUNT are not in a causal rela-\ntionship, although an LLM may reasonably expect a\nkinked tube to be a possible (indirect) cause of a pul-\nmonary shunt by impacting ventilation. Such issues\nalso hold for other pairs of variables (e.g. VENTLUNG\nand SHUNT), but cannot be expected to wholly ac-\ncount for the LLM’s difficulties with the ALARM\nnetwork, given performance also decreased on orien-\ntation queries relative to the other networks.\n16\n"}, {"page": 17, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nTable 7: PC-Stable Complete Results\nNetwork\nSample size\nData\nBSF\nSHD\nF1\nPrecision\nRecall\nasia\n100\nClean\n0.01 ± 0.00\n8.50 ± 0.00\n0.11 ± 0.00\n0.33 ± 0.00\n0.06 ± 0.00\n100\nNoisy\n0.10 ± 0.00\n6.00 ± 0.00\n0.25 ± 0.00\n0.50 ± 0.00\n0.17 ± 0.00\n1000\nClean\n0.31 ± 0.00\n5.50 ± 0.00\n0.48 ± 0.00\n1.00 ± 0.00\n0.31 ± 0.00\n1000\nNoisy\n0.18 ± 0.00\n5.50 ± 0.00\n0.35 ± 0.00\n0.60 ± 0.00\n0.25 ± 0.00\n10000\nClean\n0.75 ± 0.00\n2.00 ± 0.00\n0.86 ± 0.00\n1.00 ± 0.00\n0.75 ± 0.00\n10000\nNoisy\n0.45 ± 0.00\n4.50 ± 0.00\n0.61 ± 0.00\n0.64 ± 0.00\n0.58 ± 0.00\n100000\nClean\n0.81 ± 0.00\n1.50 ± 0.00\n0.90 ± 0.00\n1.00 ± 0.00\n0.81 ± 0.00\n100000\nNoisy\n0.32 ± 0.00\n6.50 ± 0.00\n0.52 ± 0.00\n0.47 ± 0.00\n0.58 ± 0.00\nsports\n100\nClean\n0.21 ± 0.02\n11.80 ± 0.25\n0.35 ± 0.02\n1.00 ± 0.00\n0.21 ± 0.02\n100\nNoisy\n0.12 ± 0.05\n11.42 ± 0.71\n0.21 ± 0.08\n1.00 ± 0.00\n0.12 ± 0.05\n1000\nClean\n0.21 ± 0.02\n11.80 ± 0.25\n0.35 ± 0.02\n1.00 ± 0.00\n0.21 ± 0.02\n1000\nNoisy\n0.36 ± 0.05\n8.38 ± 0.60\n0.52 ± 0.05\n1.00 ± 0.00\n0.36 ± 0.05\n10000\nClean\n0.59 ± 0.04\n6.20 ± 0.66\n0.74 ± 0.03\n1.00 ± 0.00\n0.59 ± 0.04\n10000\nNoisy\n0.51 ± 0.07\n6.50 ± 1.01\n0.68 ± 0.05\n0.93 ± 0.06\n0.54 ± 0.05\n100000\nClean\n0.73 ± 0.11\n4.00 ± 1.71\n0.84 ± 0.08\n1.00 ± 0.00\n0.73 ± 0.11\n100000\nNoisy\n0.41 ± 0.09\n8.05 ± 1.24\n0.67 ± 0.05\n0.73 ± 0.08\n0.62 ± 0.08\nproperty\n100\nClean\n0.22 ± 0.02\n26.02 ± 0.68\n0.35 ± 0.03\n0.78 ± 0.04\n0.22 ± 0.03\n100\nNoisy\n0.11 ± 0.02\n29.72 ± 1.46\n0.19 ± 0.03\n0.74 ± 0.15\n0.11 ± 0.02\n1000\nClean\n0.48 ± 0.03\n17.98 ± 0.92\n0.63 ± 0.03\n0.88 ± 0.01\n0.49 ± 0.03\n1000\nNoisy\n0.30 ± 0.03\n23.28 ± 1.39\n0.45 ± 0.04\n0.91 ± 0.06\n0.30 ± 0.03\n10000\nClean\n0.77 ± 0.03\n10.88 ± 0.96\n0.82 ± 0.02\n0.86 ± 0.00\n0.78 ± 0.03\n10000\nNoisy\n0.58 ± 0.03\n19.18 ± 1.62\n0.67 ± 0.03\n0.75 ± 0.04\n0.60 ± 0.03\n100000\nClean\n0.88 ± 0.02\n6.35 ± 0.49\n0.90 ± 0.01\n0.90 ± 0.00\n0.89 ± 0.02\n100000\nNoisy\n0.75 ± 0.02\n20.38 ± 1.69\n0.71 ± 0.02\n0.65 ± 0.02\n0.79 ± 0.02\nalarm\n100\nClean\n0.20 ± 0.02\n40.02 ± 1.80\n0.32 ± 0.03\n0.73 ± 0.07\n0.21 ± 0.02\n100\nNoisy\n0.10 ± 0.01\n45.08 ± 0.86\n0.13 ± 0.02\n0.50 ± 0.06\n0.07 ± 0.01\n1000\nClean\n0.55 ± 0.01\n20.48 ± 0.50\n0.71 ± 0.01\n1.00 ± 0.00\n0.55 ± 0.01\n1000\nNoisy\n0.42 ± 0.02\n30.38 ± 1.23\n0.56 ± 0.02\n0.81 ± 0.02\n0.42 ± 0.02\n10000\nClean\n0.68 ± 0.00\n14.50 ± 0.00\n0.81 ± 0.00\n1.00 ± 0.00\n0.68 ± 0.00\n10000\nNoisy\n0.53 ± 0.02\n29.90 ± 1.96\n0.62 ± 0.02\n0.72 ± 0.03\n0.55 ± 0.02\n100000\nClean\n0.89 ± 0.01\n5.18 ± 0.24\n0.94 ± 0.00\n1.00 ± 0.00\n0.89 ± 0.01\n100000\nNoisy\n0.62 ± 0.05\n31.42 ± 3.04\n0.65 ± 0.04\n0.65 ± 0.03\n0.65 ± 0.06\nformed\n100\nClean\n0.13 ± 0.02\n125.88 ± 2.43\n0.22 ± 0.02\n0.75 ± 0.04\n0.13 ± 0.02\n100\nNoisy\n0.09 ± 0.01\n132.30 ± 2.07\n0.14 ± 0.01\n0.78 ± 0.09\n0.08 ± 0.01\n1000\nClean\n0.28 ± 0.02\n103.35 ± 2.72\n0.43 ± 0.02\n0.90 ± 0.01\n0.28 ± 0.02\n1000\nNoisy\n0.09 ± 0.01\n132.30 ± 2.07\n0.14 ± 0.01\n0.78 ± 0.09\n0.08 ± 0.01\n10000\nClean\n0.46 ± 0.02\n79.35 ± 3.16\n0.61 ± 0.02\n0.93 ± 0.01\n0.46 ± 0.02\n10000\nNoisy\n0.30 ± 0.02\n119.78 ± 2.78\n0.41 ± 0.02\n0.66 ± 0.02\n0.30 ± 0.02\n100000\nClean\n0.53 ± 0.02\n72.00 ± 3.61\n0.67 ± 0.02\n0.91 ± 0.01\n0.53 ± 0.02\n100000\nNoisy\n0.38 ± 0.02\n120.32 ± 4.36\n0.47 ± 0.02\n0.61 ± 0.03\n0.38 ± 0.02\npathfinder\n100\nClean\n0.05 ± 0.01\n197.80 ± 2.64\n0.09 ± 0.02\n0.44 ± 0.05\n0.05 ± 0.01\n100\nNoisy\n0.08 ± 0.00\n232.88 ± 1.13\n0.02 ± 0.00\n0.32 ± 0.06\n0.01 ± 0.00\n1000\nClean\n0.11 ± 0.01\n191.08 ± 5.12\n0.18 ± 0.01\n0.56 ± 0.07\n0.11 ± 0.01\n1000\nNoisy\n0.08 ± 0.00\n232.88 ± 1.13\n0.02 ± 0.00\n0.32 ± 0.06\n0.01 ± 0.00\n10000\nClean\n-\n-\n-\n-\n-\n10000\nNoisy\n0.13 ± 0.01\n228.40 ± 3.99\n0.13 ± 0.02\n0.53 ± 0.06\n0.08 ± 0.01\n100000\nClean\n-\n-\n-\n-\n-\n100000\nNoisy\n-\n-\n-\n-\n-\nsimsum\n100\nClean\n0.07 ± 0.00\n32.50 ± 0.00\n0.13 ± 0.00\n1.00 ± 0.00\n0.07 ± 0.00\n100\nNoisy\n0.01 ± 0.00\n34.50 ± 0.00\n0.03 ± 0.00\n1.00 ± 0.00\n0.01 ± 0.00\n1000\nClean\n0.07 ± 0.00\n32.50 ± 0.00\n0.13 ± 0.00\n1.00 ± 0.00\n0.07 ± 0.00\n1000\nNoisy\n0.01 ± 0.00\n34.50 ± 0.00\n0.03 ± 0.00\n1.00 ± 0.00\n0.01 ± 0.00\n10000\nClean\n0.30 ± 0.05\n24.55 ± 1.75\n0.46 ± 0.06\n1.00 ± 0.00\n0.30 ± 0.05\n10000\nNoisy\n0.10 ± 0.00\n31.50 ± 0.00\n0.18 ± 0.00\n1.00 ± 0.00\n0.10 ± 0.00\n100000\nClean\n0.19 ± 0.00\n28.50 ± 0.00\n0.31 ± 0.00\n1.00 ± 0.00\n0.19 ± 0.00\n100000\nNoisy\n0.20 ± 0.01\n28.15 ± 0.24\n0.33 ± 0.01\n1.00 ± 0.00\n0.20 ± 0.01\n17\n"}, {"page": 18, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nTable 8: FCI Complete Results\nNetwork\nSample size\nData\nBSF\nSHD\nF1\nPrecision\nRecall\nasia\n100\nClean\n0.19 ± 0.00\n6.50 ± 0.00\n0.32 ± 0.00\n1.00 ± 0.00\n0.19 ± 0.00\n100\nNoisy\n0.02 ± 0.00\n6.50 ± 0.00\n0.13 ± 0.00\n0.33 ± 0.00\n0.08 ± 0.00\n1000\nClean\n0.38 ± 0.00\n5.00 ± 0.00\n0.55 ± 0.00\n1.00 ± 0.00\n0.38 ± 0.00\n1000\nNoisy\n0.18 ± 0.00\n5.50 ± 0.00\n0.35 ± 0.00\n0.60 ± 0.00\n0.25 ± 0.00\n10000\nClean\n0.44 ± 0.00\n4.50 ± 0.00\n0.61 ± 0.00\n1.00 ± 0.00\n0.44 ± 0.00\n10000\nNoisy\n0.15 ± 0.00\n7.50 ± 0.00\n0.40 ± 0.00\n0.38 ± 0.00\n0.42 ± 0.00\n100000\nClean\n0.50 ± 0.00\n4.00 ± 0.00\n0.67 ± 0.00\n1.00 ± 0.00\n0.50 ± 0.00\n100000\nNoisy\n0.15 ± 0.00\n7.50 ± 0.00\n0.40 ± 0.00\n0.38 ± 0.00\n0.42 ± 0.00\nsports\n100\nClean\n0.17 ± 0.00\n12.50 ± 0.00\n0.29 ± 0.00\n1.00 ± 0.00\n0.17 ± 0.00\n100\nNoisy\n0.12 ± 0.00\n11.50 ± 0.00\n0.21 ± 0.00\n1.00 ± 0.00\n0.12 ± 0.00\n1000\nClean\n0.17 ± 0.00\n12.50 ± 0.00\n0.29 ± 0.00\n1.00 ± 0.00\n0.17 ± 0.00\n1000\nNoisy\n0.35 ± 0.00\n8.50 ± 0.00\n0.51 ± 0.00\n1.00 ± 0.00\n0.35 ± 0.00\n10000\nClean\n0.77 ± 0.00\n3.50 ± 0.00\n0.87 ± 0.00\n1.00 ± 0.00\n0.77 ± 0.00\n10000\nNoisy\n0.36 ± 0.02\n8.72 ± 0.30\n0.62 ± 0.02\n0.71 ± 0.01\n0.56 ± 0.02\n100000\nClean\n0.57 ± 0.00\n6.50 ± 0.00\n0.72 ± 0.00\n1.00 ± 0.00\n0.57 ± 0.00\n100000\nNoisy\n0.31 ± 0.03\n9.72 ± 0.34\n0.66 ± 0.02\n0.61 ± 0.01\n0.71 ± 0.03\nproperty\n100\nClean\n0.21 ± 0.00\n24.50 ± 0.00\n0.35 ± 0.00\n1.00 ± 0.00\n0.21 ± 0.00\n100\nNoisy\n0.09 ± 0.00\n30.00 ± 0.00\n0.17 ± 0.00\n0.75 ± 0.00\n0.09 ± 0.00\n1000\nClean\n0.35 ± 0.00\n21.00 ± 0.00\n0.51 ± 0.00\n0.92 ± 0.00\n0.35 ± 0.00\n1000\nNoisy\n0.36 ± 0.00\n23.00 ± 0.00\n0.51 ± 0.00\n0.80 ± 0.00\n0.38 ± 0.00\n10000\nClean\n0.57 ± 0.00\n15.00 ± 0.00\n0.71 ± 0.00\n0.90 ± 0.00\n0.58 ± 0.00\n10000\nNoisy\n0.46 ± 0.01\n32.52 ± 0.47\n0.51 ± 0.01\n0.49 ± 0.01\n0.52 ± 0.01\n100000\nClean\n0.61 ± 0.00\n12.00 ± 0.00\n0.76 ± 0.00\n1.00 ± 0.00\n0.61 ± 0.00\n100000\nNoisy\n0.41 ± 0.03\n48.20 ± 1.21\n0.41 ± 0.02\n0.34 ± 0.01\n0.52 ± 0.03\nalarm\n100\nClean\n0.17 ± 0.00\n38.00 ± 0.00\n0.30 ± 0.00\n1.00 ± 0.00\n0.17 ± 0.00\n100\nNoisy\n0.10 ± 0.00\n47.50 ± 0.00\n0.13 ± 0.00\n0.37 ± 0.00\n0.08 ± 0.00\n1000\nClean\n0.51 ± 0.00\n22.50 ± 0.00\n0.68 ± 0.00\n1.00 ± 0.00\n0.51 ± 0.00\n1000\nNoisy\n0.33 ± 0.01\n39.42 ± 0.94\n0.43 ± 0.01\n0.61 ± 0.02\n0.33 ± 0.01\n10000\nClean\n0.72 ± 0.01\n13.00 ± 0.51\n0.84 ± 0.01\n1.00 ± 0.00\n0.72 ± 0.01\n10000\nNoisy\n0.44 ± 0.01\n42.38 ± 0.84\n0.50 ± 0.01\n0.53 ± 0.01\n0.47 ± 0.02\n100000\nClean\n0.78 ± 0.01\n10.00 ± 0.51\n0.88 ± 0.01\n1.00 ± 0.00\n0.78 ± 0.01\n100000\nNoisy\n0.47 ± 0.01\n64.40 ± 0.95\n0.44 ± 0.01\n0.36 ± 0.01\n0.55 ± 0.01\nformed\n100\nClean\n0.15 ± 0.00\n117.50 ± 0.00\n0.26 ± 0.00\n1.00 ± 0.00\n0.15 ± 0.00\n100\nNoisy\n0.11 ± 0.00\n133.50 ± 0.00\n0.17 ± 0.00\n0.66 ± 0.00\n0.10 ± 0.00\n1000\nClean\n0.32 ± 0.00\n94.00 ± 0.00\n0.48 ± 0.00\n1.00 ± 0.00\n0.32 ± 0.00\n1000\nNoisy\n0.11 ± 0.00\n133.50 ± 0.00\n0.17 ± 0.00\n0.66 ± 0.00\n0.10 ± 0.00\n10000\nClean\n0.46 ± 0.00\n75.22 ± 0.34\n0.63 ± 0.00\n0.98 ± 0.00\n0.46 ± 0.00\n10000\nNoisy\n0.34 ± 0.00\n123.28 ± 0.75\n0.44 ± 0.00\n0.61 ± 0.00\n0.34 ± 0.00\n100000\nClean\n0.47 ± 0.00\n90.50 ± 0.00\n0.59 ± 0.00\n0.78 ± 0.00\n0.47 ± 0.00\n100000\nNoisy\n-\n-\n-\n-\n-\npathfinder\n100\nClean\n0.03 ± 0.00\n192.00 ± 0.00\n0.05 ± 0.00\n0.71 ± 0.00\n0.03 ± 0.00\n100\nNoisy\n0.08 ± 0.00\n238.00 ± 0.00\n0.02 ± 0.00\n0.21 ± 0.00\n0.01 ± 0.00\n1000\nClean\n0.08 ± 0.00\n182.00 ± 0.00\n0.15 ± 0.00\n0.84 ± 0.00\n0.08 ± 0.00\n1000\nNoisy\n0.08 ± 0.00\n238.00 ± 0.00\n0.02 ± 0.00\n0.21 ± 0.00\n0.01 ± 0.00\n10000\nClean\n-\n-\n-\n-\n-\n10000\nNoisy\n-\n-\n-\n-\n-\n100000\nClean\n-\n-\n-\n-\n-\n100000\nNoisy\n-\n-\n-\n-\n-\nsimsum\n100\nClean\n0.07 ± 0.00\n32.50 ± 0.00\n0.13 ± 0.00\n1.00 ± 0.00\n0.07 ± 0.00\n100\nNoisy\n0.01 ± 0.00\n35.00 ± 0.00\n0.05 ± 0.00\n0.50 ± 0.00\n0.03 ± 0.00\n1000\nClean\n0.07 ± 0.00\n32.50 ± 0.00\n0.13 ± 0.00\n1.00 ± 0.00\n0.07 ± 0.00\n1000\nNoisy\n0.01 ± 0.00\n35.00 ± 0.00\n0.05 ± 0.00\n0.50 ± 0.00\n0.03 ± 0.00\n10000\nClean\n0.27 ± 0.00\n25.50 ± 0.00\n0.43 ± 0.00\n1.00 ± 0.00\n0.27 ± 0.00\n10000\nNoisy\n0.11 ± 0.00\n31.00 ± 0.00\n0.21 ± 0.00\n1.00 ± 0.00\n0.11 ± 0.00\n100000\nClean\n0.43 ± 0.00\n20.00 ± 0.00\n0.60 ± 0.00\n1.00 ± 0.00\n0.43 ± 0.00\n100000\nNoisy\n0.17 ± 0.00\n29.00 ± 0.00\n0.29 ± 0.00\n1.00 ± 0.00\n0.17 ± 0.00\n18\n"}, {"page": 19, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nTable 9: MMHC Complete Results\nNetwork\nSample size\nData\nBSF\nSHD\nF1\nPrecision\nRecall\nasia\n100\nClean\n0.26 ± 0.04\n5.92 ± 0.34\n0.41 ± 0.05\n1.00 ± 0.00\n0.26 ± 0.04\n100\nNoisy\n0.20 ± 0.05\n4.78 ± 0.30\n0.34 ± 0.07\n1.00 ± 0.00\n0.20 ± 0.05\n1000\nClean\n0.48 ± 0.09\n4.12 ± 0.70\n0.65 ± 0.08\n1.00 ± 0.00\n0.48 ± 0.09\n1000\nNoisy\n0.34 ± 0.05\n3.98 ± 0.30\n0.50 ± 0.06\n1.00 ± 0.00\n0.34 ± 0.05\n10000\nClean\n0.57 ± 0.10\n3.48 ± 0.82\n0.72 ± 0.09\n1.00 ± 0.00\n0.57 ± 0.10\n10000\nNoisy\n0.38 ± 0.08\n4.95 ± 0.46\n0.55 ± 0.06\n0.60 ± 0.03\n0.51 ± 0.08\n100000\nClean\n0.57 ± 0.10\n3.48 ± 0.82\n0.72 ± 0.09\n1.00 ± 0.00\n0.57 ± 0.10\n100000\nNoisy\n0.44 ± 0.08\n5.25 ± 0.62\n0.59 ± 0.06\n0.55 ± 0.04\n0.64 ± 0.08\nsports\n100\nClean\n0.09 ± 0.02\n13.65 ± 0.24\n0.16 ± 0.03\n1.00 ± 0.00\n0.09 ± 0.02\n100\nNoisy\n0.00 ± 0.00\n13.00 ± 0.00\n0.00 ± 0.00\nnan\n0.00 ± 0.00\n1000\nClean\n0.09 ± 0.02\n13.65 ± 0.24\n0.16 ± 0.03\n1.00 ± 0.00\n0.09 ± 0.02\n1000\nNoisy\n0.35 ± 0.09\n8.40 ± 1.11\n0.52 ± 0.09\n1.00 ± 0.00\n0.35 ± 0.09\n10000\nClean\n0.53 ± 0.09\n7.12 ± 1.38\n0.68 ± 0.09\n1.00 ± 0.00\n0.53 ± 0.09\n10000\nNoisy\n0.46 ± 0.10\n6.98 ± 1.27\n0.63 ± 0.10\n1.00 ± 0.00\n0.46 ± 0.10\n100000\nClean\n0.51 ± 0.10\n7.42 ± 1.55\n0.66 ± 0.10\n1.00 ± 0.00\n0.51 ± 0.10\n100000\nNoisy\n0.51 ± 0.16\n6.48 ± 2.08\n0.68 ± 0.13\n0.92 ± 0.08\n0.55 ± 0.15\nproperty\n100\nClean\n0.14 ± 0.02\n26.65 ± 0.61\n0.25 ± 0.03\n1.00 ± 0.00\n0.14 ± 0.02\n100\nNoisy\n0.07 ± 0.01\n29.65 ± 0.43\n0.14 ± 0.02\n1.00 ± 0.00\n0.07 ± 0.01\n1000\nClean\n0.35 ± 0.04\n20.12 ± 1.19\n0.52 ± 0.04\n1.00 ± 0.00\n0.35 ± 0.04\n1000\nNoisy\n0.30 ± 0.02\n22.32 ± 0.63\n0.46 ± 0.02\n1.00 ± 0.00\n0.30 ± 0.02\n10000\nClean\n0.36 ± 0.05\n19.98 ± 1.59\n0.53 ± 0.05\n0.98 ± 0.04\n0.37 ± 0.05\n10000\nNoisy\n0.43 ± 0.04\n19.35 ± 1.92\n0.59 ± 0.05\n0.91 ± 0.05\n0.44 ± 0.04\n100000\nClean\n0.45 ± 0.05\n17.32 ± 1.70\n0.62 ± 0.05\n0.98 ± 0.04\n0.45 ± 0.05\n100000\nNoisy\n0.47 ± 0.07\n20.78 ± 2.84\n0.59 ± 0.07\n0.79 ± 0.06\n0.48 ± 0.07\nalarm\n100\nClean\n0.19 ± 0.02\n38.28 ± 1.01\n0.31 ± 0.03\n0.90 ± 0.01\n0.19 ± 0.02\n100\nNoisy\n0.08 ± 0.01\n43.82 ± 0.57\n0.09 ± 0.02\n0.68 ± 0.06\n0.05 ± 0.01\n1000\nClean\n0.48 ± 0.02\n24.10 ± 1.11\n0.64 ± 0.02\n1.00 ± 0.00\n0.48 ± 0.02\n1000\nNoisy\n0.25 ± 0.02\n35.67 ± 0.77\n0.37 ± 0.02\n0.91 ± 0.01\n0.23 ± 0.02\n10000\nClean\n0.60 ± 0.04\n18.27 ± 1.86\n0.75 ± 0.03\n1.00 ± 0.00\n0.60 ± 0.04\n10000\nNoisy\n0.43 ± 0.03\n30.65 ± 2.25\n0.56 ± 0.04\n0.79 ± 0.04\n0.44 ± 0.03\n100000\nClean\n0.62 ± 0.05\n17.98 ± 2.76\n0.76 ± 0.04\n0.98 ± 0.03\n0.62 ± 0.05\n100000\nNoisy\n0.41 ± 0.04\n35.22 ± 3.08\n0.52 ± 0.04\n0.68 ± 0.06\n0.42 ± 0.05\nformed\n100\nClean\n0.19 ± 0.01\n116.12 ± 1.28\n0.31 ± 0.01\n0.87 ± 0.01\n0.19 ± 0.01\n100\nNoisy\n0.12 ± 0.01\n125.95 ± 1.16\n0.20 ± 0.01\n0.90 ± 0.03\n0.11 ± 0.01\n1000\nClean\n0.36 ± 0.01\n88.52 ± 1.83\n0.53 ± 0.01\n0.98 ± 0.01\n0.37 ± 0.01\n1000\nNoisy\n0.12 ± 0.01\n125.95 ± 1.16\n0.20 ± 0.01\n0.90 ± 0.03\n0.11 ± 0.01\n10000\nClean\n0.48 ± 0.02\n76.18 ± 4.20\n0.63 ± 0.02\n0.94 ± 0.02\n0.48 ± 0.02\n10000\nNoisy\n0.40 ± 0.02\n100.52 ± 2.59\n0.53 ± 0.02\n0.77 ± 0.01\n0.41 ± 0.02\n100000\nClean\n0.52 ± 0.02\n73.30 ± 4.91\n0.66 ± 0.02\n0.91 ± 0.04\n0.52 ± 0.02\n100000\nNoisy\n0.48 ± 0.03\n101.20 ± 2.67\n0.57 ± 0.02\n0.70 ± 0.01\n0.49 ± 0.03\npathfinder\n100\nClean\n0.04 ± 0.00\n196.10 ± 1.35\n0.08 ± 0.01\n0.47 ± 0.04\n0.05 ± 0.00\n100\nNoisy\n0.08 ± 0.00\n228.88 ± 0.56\n0.03 ± 0.00\n0.60 ± 0.05\n0.01 ± 0.00\n1000\nClean\n0.06 ± 0.00\n189.92 ± 1.05\n0.11 ± 0.01\n0.64 ± 0.03\n0.06 ± 0.00\n1000\nNoisy\n0.08 ± 0.00\n228.88 ± 0.56\n0.03 ± 0.00\n0.60 ± 0.05\n0.01 ± 0.00\n10000\nClean\n0.07 ± 0.01\n190.02 ± 2.33\n0.12 ± 0.01\n0.62 ± 0.06\n0.07 ± 0.01\n10000\nNoisy\n0.12 ± 0.01\n226.28 ± 4.64\n0.11 ± 0.02\n0.60 ± 0.12\n0.06 ± 0.01\n100000\nClean\n0.06 ± 0.01\n191.50 ± 3.36\n0.11 ± 0.02\n0.60 ± 0.10\n0.06 ± 0.01\n100000\nNoisy\n0.11 ± 0.01\n227.72 ± 4.39\n0.09 ± 0.02\n0.58 ± 0.13\n0.05 ± 0.01\nsimsum\n100\nClean\n0.07 ± 0.02\n33.62 ± 1.02\n0.15 ± 0.03\n0.65 ± 0.11\n0.09 ± 0.02\n100\nNoisy\n0.00 ± 0.00\n35.00 ± 0.00\n0.00 ± 0.00\nnan\n0.00 ± 0.00\n1000\nClean\n0.07 ± 0.02\n33.62 ± 1.02\n0.15 ± 0.03\n0.65 ± 0.11\n0.09 ± 0.02\n1000\nNoisy\n0.00 ± 0.00\n35.00 ± 0.00\n0.00 ± 0.00\nnan\n0.00 ± 0.00\n10000\nClean\n0.30 ± 0.02\n24.32 ± 0.83\n0.47 ± 0.03\n1.00 ± 0.00\n0.30 ± 0.02\n10000\nNoisy\n0.09 ± 0.02\n31.85 ± 0.54\n0.16 ± 0.03\n1.00 ± 0.00\n0.09 ± 0.02\n100000\nClean\n0.47 ± 0.04\n18.70 ± 1.54\n0.63 ± 0.04\n1.00 ± 0.00\n0.47 ± 0.04\n100000\nNoisy\n0.14 ± 0.03\n29.95 ± 1.19\n0.25 ± 0.05\n1.00 ± 0.00\n0.14 ± 0.03\n19\n"}, {"page": 20, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nTable 10: BOSS Complete Results\nNetwork\nSample size\nData\nBSF\nSHD\nF1\nPrecision\nRecall\nasia\n100\nClean\n0.04 ± 0.12\n12.75 ± 1.28\n0.37 ± 0.07\n0.31 ± 0.05\n0.47 ± 0.10\n100\nNoisy\n0.20 ± 0.00\n6.00 ± 0.00\n0.40 ± 0.00\n0.50 ± 0.00\n0.33 ± 0.00\n1000\nClean\n0.65 ± 0.09\n5.90 ± 1.01\n0.71 ± 0.05\n0.58 ± 0.04\n0.91 ± 0.06\n1000\nNoisy\n0.05 ± 0.00\n7.50 ± 0.00\n0.29 ± 0.00\n0.33 ± 0.00\n0.25 ± 0.00\n10000\nClean\n0.68 ± 0.00\n5.00 ± 0.00\n0.74 ± 0.00\n0.64 ± 0.00\n0.88 ± 0.00\n10000\nNoisy\n0.40 ± 0.20\n5.15 ± 1.53\n0.56 ± 0.15\n0.56 ± 0.12\n0.57 ± 0.17\n100000\nClean\n0.73 ± 0.09\n2.85 ± 1.08\n0.82 ± 0.07\n0.84 ± 0.07\n0.79 ± 0.06\n100000\nNoisy\n0.16 ± 0.14\n7.88 ± 1.11\n0.42 ± 0.09\n0.37 ± 0.07\n0.48 ± 0.11\nsports\n100\nClean\n0.25 ± 0.04\n11.48 ± 0.73\n0.43 ± 0.03\n0.85 ± 0.11\n0.29 ± 0.03\n100\nNoisy\n0.13 ± 0.00\n11.50 ± 0.00\n0.30 ± 0.00\n0.71 ± 0.00\n0.19 ± 0.00\n1000\nClean\n0.25 ± 0.04\n11.48 ± 0.73\n0.43 ± 0.03\n0.85 ± 0.11\n0.29 ± 0.03\n1000\nNoisy\n0.34 ± 0.01\n8.57 ± 0.18\n0.51 ± 0.01\n0.98 ± 0.05\n0.35 ± 0.02\n10000\nClean\n0.36 ± 0.04\n10.05 ± 0.51\n0.55 ± 0.05\n0.83 ± 0.03\n0.42 ± 0.06\n10000\nNoisy\n0.41 ± 0.04\n7.65 ± 0.49\n0.58 ± 0.04\n1.00 ± 0.00\n0.41 ± 0.04\n100000\nClean\n0.59 ± 0.02\n6.15 ± 0.24\n0.74 ± 0.01\n1.00 ± 0.00\n0.59 ± 0.02\n100000\nNoisy\n0.54 ± 0.11\n6.00 ± 1.54\n0.71 ± 0.07\n0.96 ± 0.11\n0.56 ± 0.05\nproperty\n100\nClean\n0.52 ± 0.04\n21.60 ± 2.33\n0.61 ± 0.04\n0.69 ± 0.05\n0.55 ± 0.04\n100\nNoisy\n0.34 ± 0.01\n21.15 ± 0.37\n0.51 ± 0.01\n1.00 ± 0.00\n0.34 ± 0.01\n1000\nClean\n0.62 ± 0.08\n16.75 ± 3.88\n0.70 ± 0.07\n0.78 ± 0.07\n0.63 ± 0.08\n1000\nNoisy\n0.47 ± 0.02\n19.10 ± 1.14\n0.61 ± 0.02\n0.87 ± 0.03\n0.47 ± 0.02\n10000\nClean\n0.75 ± 0.10\n13.98 ± 5.87\n0.77 ± 0.09\n0.78 ± 0.10\n0.77 ± 0.10\n10000\nNoisy\n0.62 ± 0.06\n16.62 ± 2.41\n0.71 ± 0.05\n0.80 ± 0.04\n0.64 ± 0.06\n100000\nClean\n0.73 ± 0.10\n15.98 ± 6.03\n0.75 ± 0.09\n0.74 ± 0.10\n0.76 ± 0.09\n100000\nNoisy\n0.60 ± 0.08\n27.92 ± 4.28\n0.60 ± 0.06\n0.55 ± 0.05\n0.66 ± 0.08\nalarm\n100\nClean\n0.58 ± 0.05∗\n84.24 ± 3.55∗\n0.43 ± 0.02∗\n0.31 ± 0.02∗\n0.69 ± 0.05∗\n100\nNoisy\n0.16 ± 0.02∗\n66.45 ± 2.61∗\n0.21 ± 0.02∗\n0.23 ± 0.02∗\n0.20 ± 0.03∗\n1000\nClean\n0.75 ± 0.04\n44.08 ± 2.22\n0.63 ± 0.02\n0.51 ± 0.02\n0.80 ± 0.04\n1000\nNoisy\n0.41 ± 0.02∗\n33.63 ± 1.59∗\n0.52 ± 0.02∗\n0.72 ± 0.03∗\n0.41 ± 0.02∗\n10000\nClean\n0.79 ± 0.04∗\n20.47 ± 3.69∗\n0.78 ± 0.04∗\n0.76 ± 0.04∗\n0.81 ± 0.04∗\n10000\nNoisy\n0.50 ± 0.05∗\n35.53 ± 3.16∗\n0.57 ± 0.05∗\n0.62 ± 0.04∗\n0.53 ± 0.05∗\n100000\nClean\n0.78 ± 0.07∗\n16.55 ± 5.28∗\n0.81 ± 0.06∗\n0.84 ± 0.06∗\n0.79 ± 0.06∗\n100000\nNoisy\n0.45 ± 0.05∗\n55.37 ± 3.36∗\n0.45 ± 0.04∗\n0.41 ± 0.03∗\n0.51 ± 0.05∗\nformed\n100\nClean\n0.32 ± 0.03∗\n345.35 ± 8.05∗\n0.24 ± 0.01∗\n0.17 ± 0.01∗\n0.39 ± 0.03∗\n100\nNoisy\n0.17 ± 0.01∗\n214.44 ± 3.15∗\n0.20 ± 0.01∗\n0.21 ± 0.01∗\n0.19 ± 0.01∗\n1000\nClean\n0.66 ± 0.05∗\n136.12 ± 12.61∗\n0.58 ± 0.04∗\n0.50 ± 0.03∗\n0.69 ± 0.05∗\n1000\nNoisy\n0.17 ± 0.01∗\n214.44 ± 3.15∗\n0.20 ± 0.01∗\n0.21 ± 0.01∗\n0.19 ± 0.01∗\n10000\nClean\n0.73 ± 0.07∗\n108.17 ± 22.98∗\n0.66 ± 0.07∗\n0.59 ± 0.06∗\n0.75 ± 0.07∗\n10000\nNoisy\n0.38 ± 0.02∗\n124.25 ± 3.80∗\n0.47 ± 0.02∗\n0.58 ± 0.02∗\n0.39 ± 0.03∗\n100000\nClean\n0.75 ± 0.10∗\n120.67 ± 31.47∗\n0.64 ± 0.09∗\n0.55 ± 0.08∗\n0.77 ± 0.09∗\n100000\nNoisy\n0.50 ± 0.04∗\n151.89 ± 8.82∗\n0.49 ± 0.03∗\n0.46 ± 0.03∗\n0.52 ± 0.04∗\npathfinder\n100\nClean\n-\n-\n-\n-\n-\n100\nNoisy\n-\n-\n-\n-\n-\n1000\nClean\n-\n-\n-\n-\n-\n1000\nNoisy\n-\n-\n-\n-\n-\n10000\nClean\n-\n-\n-\n-\n-\n10000\nNoisy\n-\n-\n-\n-\n-\n100000\nClean\n-\n-\n-\n-\n-\n100000\nNoisy\n-\n-\n-\n-\n-\nsimsum\n100\nClean\n0.19 ± 0.05\n49.25 ± 2.15\n0.46 ± 0.03\n0.37 ± 0.02\n0.61 ± 0.05\n100\nNoisy\n−0.04 ± 0.00\n38.50 ± 0.00\n0.11 ± 0.00\n0.29 ± 0.00\n0.07 ± 0.00\n1000\nClean\n0.19 ± 0.05\n49.25 ± 2.15\n0.46 ± 0.03\n0.37 ± 0.02\n0.61 ± 0.05\n1000\nNoisy\n−0.04 ± 0.00\n38.50 ± 0.00\n0.11 ± 0.00\n0.29 ± 0.00\n0.07 ± 0.00\n10000\nClean\n0.42 ± 0.03\n22.05 ± 1.40\n0.59 ± 0.03\n0.83 ± 0.05\n0.46 ± 0.02\n10000\nNoisy\n0.07 ± 0.00\n32.50 ± 0.00\n0.13 ± 0.00\n1.00 ± 0.00\n0.07 ± 0.00\n100000\nClean\n0.47 ± 0.06\n20.70 ± 2.57\n0.64 ± 0.05\n0.83 ± 0.06\n0.52 ± 0.05\n100000\nNoisy\n0.16 ± 0.00\n29.55 ± 0.15\n0.27 ± 0.01\n1.00 ± 0.00\n0.16 ± 0.00\n20\n"}, {"page": 21, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nTable 11: Tabu Complete Results\nNetwork\nSample size\nData\nBSF\nSHD\nF1\nPrecision\nRecall\nasia\n100\nClean\n0.39 ± 0.00\n5.50 ± 0.00\n0.56 ± 0.00\n0.78 ± 0.00\n0.44 ± 0.00\n100\nNoisy\n0.20 ± 0.07\n4.80 ± 0.41\n0.33 ± 0.09\n1.00 ± 0.00\n0.20 ± 0.07\n1000\nClean\n0.40 ± 0.01\n5.98 ± 0.11\n0.57 ± 0.01\n0.67 ± 0.01\n0.50 ± 0.01\n1000\nNoisy\n0.33 ± 0.00\n4.00 ± 0.00\n0.50 ± 0.00\n1.00 ± 0.00\n0.33 ± 0.00\n10000\nClean\n0.86 ± 0.06\n1.70 ± 0.47\n0.89 ± 0.03\n0.88 ± 0.01\n0.91 ± 0.06\n10000\nNoisy\n0.45 ± 0.00\n4.50 ± 0.00\n0.61 ± 0.00\n0.64 ± 0.00\n0.58 ± 0.00\n100000\nClean\n0.88 ± 0.01\n0.98 ± 0.11\n0.94 ± 0.01\n1.00 ± 0.00\n0.88 ± 0.01\n100000\nNoisy\n0.49 ± 0.04\n4.85 ± 0.24\n0.63 ± 0.02\n0.58 ± 0.01\n0.69 ± 0.04\nsports\n100\nClean\n0.10 ± 0.01\n13.58 ± 0.18\n0.17 ± 0.02\n1.00 ± 0.00\n0.10 ± 0.01\n100\nNoisy\n0.00 ± 0.00\n13.00 ± 0.00\n0.00 ± 0.00\nnan\n0.00 ± 0.00\n1000\nClean\n0.10 ± 0.01\n13.58 ± 0.18\n0.17 ± 0.02\n1.00 ± 0.00\n0.10 ± 0.01\n1000\nNoisy\n0.37 ± 0.06\n8.20 ± 0.73\n0.54 ± 0.06\n1.00 ± 0.00\n0.37 ± 0.06\n10000\nClean\n0.47 ± 0.00\n8.50 ± 0.00\n0.67 ± 0.00\n0.81 ± 0.00\n0.57 ± 0.00\n10000\nNoisy\n0.33 ± 0.00\n9.00 ± 0.00\n0.57 ± 0.00\n0.75 ± 0.00\n0.46 ± 0.00\n100000\nClean\n0.85 ± 0.00\n2.50 ± 0.00\n0.92 ± 0.00\n0.93 ± 0.00\n0.90 ± 0.00\n100000\nNoisy\n0.85 ± 0.00\n2.00 ± 0.00\n0.92 ± 0.00\n1.00 ± 0.00\n0.85 ± 0.00\nproperty\n100\nClean\n0.33 ± 0.02\n23.58 ± 0.59\n0.47 ± 0.02\n0.78 ± 0.01\n0.34 ± 0.02\n100\nNoisy\n0.18 ± 0.01\n26.22 ± 0.38\n0.31 ± 0.02\n1.00 ± 0.00\n0.18 ± 0.01\n1000\nClean\n0.62 ± 0.00\n14.50 ± 0.00\n0.73 ± 0.00\n0.87 ± 0.00\n0.63 ± 0.00\n1000\nNoisy\n0.48 ± 0.00\n18.50 ± 0.00\n0.63 ± 0.00\n0.89 ± 0.00\n0.48 ± 0.00\n10000\nClean\n0.80 ± 0.00\n8.00 ± 0.00\n0.86 ± 0.00\n0.93 ± 0.00\n0.81 ± 0.00\n10000\nNoisy\n0.68 ± 0.00\n13.00 ± 0.00\n0.77 ± 0.00\n0.88 ± 0.00\n0.69 ± 0.00\n100000\nClean\n0.90 ± 0.00\n8.50 ± 0.00\n0.87 ± 0.00\n0.83 ± 0.00\n0.92 ± 0.00\n100000\nNoisy\n0.68 ± 0.01\n19.92 ± 0.18\n0.70 ± 0.00\n0.68 ± 0.00\n0.72 ± 0.01\nalarm\n100\nClean\n0.32 ± 0.00\n39.42 ± 0.18\n0.44 ± 0.00\n0.63 ± 0.00\n0.34 ± 0.00\n100\nNoisy\n0.09 ± 0.00\n45.92 ± 0.18\n0.12 ± 0.01\n0.43 ± 0.01\n0.07 ± 0.00\n1000\nClean\n0.58 ± 0.01\n27.58 ± 0.29\n0.67 ± 0.00\n0.75 ± 0.00\n0.60 ± 0.01\n1000\nNoisy\n0.30 ± 0.02\n36.75 ± 0.73\n0.42 ± 0.02\n0.73 ± 0.01\n0.29 ± 0.02\n10000\nClean\n0.70 ± 0.00\n33.38 ± 0.22\n0.67 ± 0.00\n0.62 ± 0.00\n0.73 ± 0.00\n10000\nNoisy\n0.57 ± 0.01\n30.02 ± 0.57\n0.64 ± 0.01\n0.69 ± 0.00\n0.60 ± 0.01\n100000\nClean\n0.79 ± 0.00\n24.50 ± 0.00\n0.75 ± 0.00\n0.70 ± 0.00\n0.82 ± 0.00\n100000\nNoisy\n0.58 ± 0.01\n43.58 ± 0.44\n0.57 ± 0.01\n0.51 ± 0.00\n0.63 ± 0.01\nformed\n100\nClean\n0.15 ± 0.04\n193.85 ± 17.48\n0.19 ± 0.05\n0.23 ± 0.08\n0.17 ± 0.04\n100\nNoisy\n0.02 ± 0.04\n207.28 ± 28.39\n0.04 ± 0.06\n0.12 ± 0.26\n0.03 ± 0.03\n1000\nClean\n0.23 ± 0.12\n227.32 ± 51.41\n0.25 ± 0.15\n0.25 ± 0.18\n0.26 ± 0.11\n1000\nNoisy\n0.02 ± 0.04\n207.28 ± 28.39\n0.04 ± 0.06\n0.12 ± 0.26\n0.03 ± 0.03\n10000\nClean\n0.25 ± 0.17\n311.25 ± 85.41\n0.23 ± 0.18\n0.20 ± 0.20\n0.31 ± 0.15\n10000\nNoisy\n0.04 ± 0.13\n341.85 ± 75.87\n0.09 ± 0.14\n0.09 ± 0.17\n0.09 ± 0.12\n100000\nClean\n0.29 ± 0.16\n348.85 ± 86.64\n0.24 ± 0.16\n0.18 ± 0.15\n0.37 ± 0.14\n100000\nNoisy\n0.11 ± 0.14\n391.40 ± 86.49\n0.13 ± 0.14\n0.11 ± 0.13\n0.18 ± 0.13\npathfinder\n100\nClean\n0.01 ± 0.00\n920.20 ± 8.11\n0.06 ± 0.00\n0.04 ± 0.00\n0.14 ± 0.00\n100\nNoisy\n0.14 ± 0.00\n222.18 ± 0.24\n0.14 ± 0.00\n0.64 ± 0.00\n0.08 ± 0.00\n1000\nClean\n0.14 ± 0.01\n663.62 ± 144.65\n0.13 ± 0.04\n0.10 ± 0.07\n0.23 ± 0.01\n1000\nNoisy\n0.14 ± 0.00\n222.18 ± 0.24\n0.14 ± 0.00\n0.64 ± 0.00\n0.08 ± 0.00\n10000\nClean\n0.30 ± 0.00\n224.32 ± 0.24\n0.35 ± 0.00\n0.40 ± 0.00\n0.31 ± 0.00\n10000\nNoisy\n0.20 ± 0.00\n261.18 ± 0.24\n0.22 ± 0.00\n0.35 ± 0.00\n0.16 ± 0.00\n100000\nClean\n0.51 ± 0.00\n154.50 ± 0.00\n0.57 ± 0.00\n0.62 ± 0.00\n0.52 ± 0.00\n100000\nNoisy\n0.37 ± 0.00\n196.60 ± 0.21\n0.46 ± 0.00\n0.63 ± 0.00\n0.36 ± 0.00\nsimsum\n100\nClean\n0.22 ± 0.01\n40.75 ± 0.26\n0.46 ± 0.01\n0.43 ± 0.00\n0.49 ± 0.01\n100\nNoisy\n0.00 ± 0.00\n35.00 ± 0.00\n0.00 ± 0.00\nnan\n0.00 ± 0.00\n1000\nClean\n0.22 ± 0.01\n40.75 ± 0.26\n0.46 ± 0.01\n0.43 ± 0.00\n0.49 ± 0.01\n1000\nNoisy\n0.00 ± 0.00\n35.00 ± 0.00\n0.00 ± 0.00\nnan\n0.00 ± 0.00\n10000\nClean\n0.36 ± 0.01\n22.85 ± 0.24\n0.54 ± 0.01\n0.93 ± 0.00\n0.38 ± 0.01\n10000\nNoisy\n0.08 ± 0.01\n32.02 ± 0.20\n0.16 ± 0.01\n1.00 ± 0.00\n0.09 ± 0.01\n100000\nClean\n0.47 ± 0.00\n19.00 ± 0.00\n0.64 ± 0.00\n0.94 ± 0.00\n0.49 ± 0.00\n100000\nNoisy\n0.14 ± 0.01\n30.22 ± 0.50\n0.24 ± 0.02\n1.00 ± 0.00\n0.14 ± 0.01\n21\n"}, {"page": 22, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nTable 12: GES Complete Results\nNetwork\nSample size\nData\nBSF\nSHD\nF1\nPrecision\nRecall\nasia\n100\nClean\n0.35 ± 0.06\n5.80 ± 0.47\n0.52 ± 0.06\n0.76 ± 0.03\n0.40 ± 0.06\n100\nNoisy\n0.17 ± 0.00\n5.00 ± 0.00\n0.29 ± 0.00\n1.00 ± 0.00\n0.17 ± 0.00\n1000\nClean\n0.40 ± 0.00\n6.00 ± 0.00\n0.57 ± 0.00\n0.67 ± 0.00\n0.50 ± 0.00\n1000\nNoisy\n0.33 ± 0.00\n4.00 ± 0.00\n0.50 ± 0.00\n1.00 ± 0.00\n0.33 ± 0.00\n10000\nClean\n0.60 ± 0.15\n4.15 ± 1.53\n0.72 ± 0.11\n0.77 ± 0.09\n0.68 ± 0.13\n10000\nNoisy\n0.47 ± 0.12\n4.38 ± 0.72\n0.62 ± 0.09\n0.64 ± 0.05\n0.60 ± 0.12\n100000\nClean\n0.52 ± 0.20\n5.55 ± 2.76\n0.67 ± 0.15\n0.68 ± 0.18\n0.67 ± 0.12\n100000\nNoisy\n0.33 ± 0.17\n6.58 ± 1.31\n0.53 ± 0.11\n0.46 ± 0.08\n0.62 ± 0.14\nsports\n100\nClean\n0.08 ± 0.02\n13.82 ± 0.24\n0.14 ± 0.03\n1.00 ± 0.00\n0.08 ± 0.02\n100\nNoisy\n0.00 ± 0.00\n13.00 ± 0.00\n0.00 ± 0.00\nnan\n0.00 ± 0.00\n1000\nClean\n0.08 ± 0.02\n13.82 ± 0.24\n0.14 ± 0.03\n1.00 ± 0.00\n0.08 ± 0.02\n1000\nNoisy\n0.23 ± 0.00\n10.00 ± 0.00\n0.38 ± 0.00\n1.00 ± 0.00\n0.23 ± 0.00\n10000\nClean\n0.35 ± 0.01\n10.50 ± 0.00\n0.57 ± 0.02\n0.74 ± 0.03\n0.46 ± 0.03\n10000\nNoisy\n0.39 ± 0.18\n8.02 ± 2.46\n0.60 ± 0.14\n0.84 ± 0.15\n0.47 ± 0.12\n100000\nClean\n0.49 ± 0.17\n8.62 ± 2.72\n0.69 ± 0.11\n0.73 ± 0.08\n0.66 ± 0.14\n100000\nNoisy\n0.66 ± 0.00\n4.50 ± 0.00\n0.81 ± 0.00\n0.90 ± 0.00\n0.73 ± 0.00\nproperty\n100\nClean\n0.35 ± 0.02\n21.85 ± 0.59\n0.50 ± 0.02\n0.85 ± 0.01\n0.36 ± 0.02\n100\nNoisy\n0.19 ± 0.00\n26.00 ± 0.00\n0.32 ± 0.00\n1.00 ± 0.00\n0.19 ± 0.00\n1000\nClean\n0.57 ± 0.05\n16.95 ± 2.45\n0.68 ± 0.05\n0.82 ± 0.05\n0.58 ± 0.05\n1000\nNoisy\n0.43 ± 0.01\n20.85 ± 0.24\n0.58 ± 0.01\n0.83 ± 0.00\n0.44 ± 0.01\n10000\nClean\n0.73 ± 0.08\n11.78 ± 4.51\n0.80 ± 0.08\n0.86 ± 0.08\n0.74 ± 0.08\n10000\nNoisy\n0.59 ± 0.01\n17.12 ± 0.81\n0.69 ± 0.01\n0.81 ± 0.02\n0.61 ± 0.01\n100000\nClean\n0.82 ± 0.02\n11.78 ± 1.24\n0.82 ± 0.02\n0.79 ± 0.02\n0.84 ± 0.02\n100000\nNoisy\n0.68 ± 0.00\n20.00 ± 0.00\n0.70 ± 0.00\n0.68 ± 0.00\n0.72 ± 0.00\nalarm\n100\nClean\n0.32 ± 0.02\n38.38 ± 1.99\n0.44 ± 0.03\n0.67 ± 0.04\n0.33 ± 0.02\n100\nNoisy\n0.09 ± 0.01\n45.75 ± 0.26\n0.12 ± 0.01\n0.45 ± 0.02\n0.07 ± 0.01\n1000\nClean\n0.56 ± 0.02\n28.40 ± 2.35\n0.65 ± 0.03\n0.75 ± 0.04\n0.57 ± 0.02\n1000\nNoisy\n0.31 ± 0.01\n36.50 ± 0.63\n0.43 ± 0.02\n0.73 ± 0.01\n0.30 ± 0.01\n10000\nClean\n0.72 ± 0.05\n23.02 ± 3.33\n0.75 ± 0.04\n0.76 ± 0.04\n0.73 ± 0.04\n10000\nNoisy\n0.54 ± 0.02\n31.25 ± 1.09\n0.62 ± 0.01\n0.69 ± 0.01\n0.56 ± 0.02\n100000\nClean\n0.74 ± 0.02\n26.65 ± 3.41\n0.72 ± 0.03\n0.69 ± 0.04\n0.76 ± 0.02\n100000\nNoisy\n0.56 ± 0.03\n42.78 ± 1.24\n0.56 ± 0.02\n0.52 ± 0.01\n0.61 ± 0.03\nformed\n100\nClean\n0.14 ± 0.04\n194.28 ± 17.02\n0.19 ± 0.05\n0.23 ± 0.08\n0.16 ± 0.03\n100\nNoisy\n0.02 ± 0.04\n207.25 ± 28.47\n0.04 ± 0.06\n0.12 ± 0.26\n0.03 ± 0.03\n1000\nClean\n0.22 ± 0.13\n229.10 ± 52.99\n0.24 ± 0.15\n0.24 ± 0.19\n0.25 ± 0.12\n1000\nNoisy\n0.02 ± 0.04\n207.25 ± 28.47\n0.04 ± 0.06\n0.12 ± 0.26\n0.03 ± 0.03\n10000\nClean\n0.25 ± 0.16\n312.55 ± 80.84\n0.23 ± 0.17\n0.19 ± 0.18\n0.30 ± 0.14\n10000\nNoisy\n0.04 ± 0.14\n340.08 ± 81.34\n0.09 ± 0.16\n0.10 ± 0.21\n0.09 ± 0.12\n100000\nClean\n0.27 ± 0.16\n352.85 ± 85.04\n0.23 ± 0.15\n0.17 ± 0.14\n0.35 ± 0.14\n100000\nNoisy\n0.10 ± 0.14\n391.68 ± 86.44\n0.13 ± 0.13\n0.10 ± 0.13\n0.18 ± 0.12\npathfinder\n100\nClean\n0.11 ± 0.02\n222.02 ± 6.01\n0.17 ± 0.02\n0.32 ± 0.04\n0.12 ± 0.02\n100\nNoisy\n0.14 ± 0.00\n222.20 ± 0.25\n0.14 ± 0.00\n0.64 ± 0.00\n0.08 ± 0.00\n1000\nClean\n0.17 ± 0.01\n240.35 ± 3.71\n0.23 ± 0.01\n0.31 ± 0.01\n0.19 ± 0.01\n1000\nNoisy\n0.14 ± 0.00\n222.20 ± 0.25\n0.14 ± 0.00\n0.64 ± 0.00\n0.08 ± 0.00\n10000\nClean\n0.29 ± 0.01\n224.55 ± 1.77\n0.35 ± 0.01\n0.40 ± 0.01\n0.31 ± 0.01\n10000\nNoisy\n0.20 ± 0.01\n260.50 ± 3.03\n0.22 ± 0.01\n0.35 ± 0.01\n0.16 ± 0.01\n100000\nClean\n0.49 ± 0.01\n155.62 ± 2.64\n0.56 ± 0.01\n0.63 ± 0.01\n0.50 ± 0.01\n100000\nNoisy\n0.37 ± 0.01\n194.35 ± 2.88\n0.46 ± 0.01\n0.64 ± 0.01\n0.36 ± 0.01\nsimsum\n100\nClean\n0.07 ± 0.00\n33.15 ± 0.24\n0.16 ± 0.01\n0.72 ± 0.05\n0.09 ± 0.01\n100\nNoisy\n0.00 ± 0.00\n35.00 ± 0.00\n0.00 ± 0.00\nnan\n0.00 ± 0.00\n1000\nClean\n0.07 ± 0.00\n33.15 ± 0.24\n0.16 ± 0.01\n0.72 ± 0.05\n0.09 ± 0.01\n1000\nNoisy\n0.00 ± 0.00\n35.00 ± 0.00\n0.00 ± 0.00\nnan\n0.00 ± 0.00\n10000\nClean\n0.40 ± 0.01\n21.60 ± 0.50\n0.57 ± 0.01\n0.94 ± 0.00\n0.41 ± 0.01\n10000\nNoisy\n0.09 ± 0.01\n31.88 ± 0.22\n0.16 ± 0.01\n1.00 ± 0.00\n0.09 ± 0.01\n100000\nClean\n0.44 ± 0.00\n21.50 ± 0.00\n0.61 ± 0.00\n0.85 ± 0.00\n0.47 ± 0.00\n100000\nNoisy\n0.11 ± 0.04\n31.22 ± 1.40\n0.22 ± 0.04\n0.88 ± 0.11\n0.12 ± 0.03\n22\n"}, {"page": 23, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nTable 13: MAHC Complete Results\nNetwork\nSample size\nData\nBSF\nSHD\nF1\nPrecision\nRecall\nasia\n100\nClean\n0.25 ± 0.00\n6.00 ± 0.00\n0.40 ± 0.00\n1.00 ± 0.00\n0.25 ± 0.00\n100\nNoisy\n0.00 ± 0.00\n6.00 ± 0.00\n0.00 ± 0.00\nnan\n0.00 ± 0.00\n1000\nClean\n0.38 ± 0.00\n5.00 ± 0.00\n0.55 ± 0.00\n1.00 ± 0.00\n0.38 ± 0.00\n1000\nNoisy\n0.33 ± 0.00\n4.00 ± 0.00\n0.50 ± 0.00\n1.00 ± 0.00\n0.33 ± 0.00\n10000\nClean\n0.69 ± 0.00\n2.50 ± 0.00\n0.81 ± 0.00\n1.00 ± 0.00\n0.69 ± 0.00\n10000\nNoisy\n0.20 ± 0.00\n6.00 ± 0.00\n0.40 ± 0.00\n0.50 ± 0.00\n0.33 ± 0.00\n100000\nClean\n0.69 ± 0.00\n2.50 ± 0.00\n0.81 ± 0.00\n1.00 ± 0.00\n0.69 ± 0.00\n100000\nNoisy\n0.55 ± 0.00\n4.50 ± 0.00\n0.67 ± 0.00\n0.60 ± 0.00\n0.75 ± 0.00\nsports\n100\nClean\n0.07 ± 0.00\n14.00 ± 0.00\n0.12 ± 0.00\n1.00 ± 0.00\n0.07 ± 0.00\n100\nNoisy\n0.00 ± 0.00\n13.00 ± 0.00\n0.00 ± 0.00\nnan\n0.00 ± 0.00\n1000\nClean\n0.07 ± 0.00\n14.00 ± 0.00\n0.12 ± 0.00\n1.00 ± 0.00\n0.07 ± 0.00\n1000\nNoisy\n0.15 ± 0.00\n11.00 ± 0.00\n0.27 ± 0.00\n1.00 ± 0.00\n0.15 ± 0.00\n10000\nClean\n0.45 ± 0.00\n8.50 ± 0.00\n0.64 ± 0.00\n0.88 ± 0.00\n0.50 ± 0.00\n10000\nNoisy\n0.23 ± 0.02\n9.98 ± 0.26\n0.38 ± 0.03\n1.00 ± 0.00\n0.23 ± 0.02\n100000\nClean\n0.46 ± 0.02\n8.07 ± 0.24\n0.63 ± 0.02\n1.00 ± 0.00\n0.46 ± 0.02\n100000\nNoisy\n0.26 ± 0.02\n9.60 ± 0.21\n0.41 ± 0.02\n1.00 ± 0.00\n0.26 ± 0.02\nproperty\n100\nClean\n0.11 ± 0.00\n27.50 ± 0.00\n0.20 ± 0.00\n1.00 ± 0.00\n0.11 ± 0.00\n100\nNoisy\n0.17 ± 0.00\n26.50 ± 0.00\n0.29 ± 0.00\n1.00 ± 0.00\n0.17 ± 0.00\n1000\nClean\n0.13 ± 0.00\n26.95 ± 0.15\n0.23 ± 0.01\n1.00 ± 0.00\n0.13 ± 0.00\n1000\nNoisy\n0.11 ± 0.00\n28.50 ± 0.00\n0.20 ± 0.00\n1.00 ± 0.00\n0.11 ± 0.00\n10000\nClean\n0.42 ± 0.00\n19.00 ± 0.00\n0.58 ± 0.00\n0.93 ± 0.00\n0.42 ± 0.00\n10000\nNoisy\n0.47 ± 0.00\n17.95 ± 0.15\n0.63 ± 0.00\n0.94 ± 0.00\n0.47 ± 0.00\n100000\nClean\n0.64 ± 0.00\n11.98 ± 0.11\n0.77 ± 0.00\n0.95 ± 0.00\n0.65 ± 0.00\n100000\nNoisy\n0.51 ± 0.00\n18.50 ± 0.00\n0.64 ± 0.00\n0.85 ± 0.00\n0.52 ± 0.00\nalarm\n100\nClean\n0.11 ± 0.00\n42.00 ± 0.00\n0.19 ± 0.00\n0.83 ± 0.00\n0.11 ± 0.00\n100\nNoisy\n0.08 ± 0.00\n43.50 ± 0.00\n0.10 ± 0.00\n0.71 ± 0.00\n0.06 ± 0.00\n1000\nClean\n0.44 ± 0.00\n27.50 ± 0.00\n0.60 ± 0.00\n0.91 ± 0.00\n0.45 ± 0.00\n1000\nNoisy\n0.11 ± 0.00\n42.50 ± 0.00\n0.14 ± 0.00\n0.78 ± 0.00\n0.08 ± 0.00\n10000\nClean\n0.68 ± 0.00\n14.50 ± 0.00\n0.81 ± 0.00\n1.00 ± 0.00\n0.68 ± 0.00\n10000\nNoisy\n0.31 ± 0.00\n34.50 ± 0.00\n0.44 ± 0.00\n0.82 ± 0.00\n0.30 ± 0.00\n100000\nClean\n0.79 ± 0.00\n11.50 ± 0.00\n0.86 ± 0.00\n0.95 ± 0.00\n0.79 ± 0.00\n100000\nNoisy\n0.50 ± 0.00\n37.98 ± 0.11\n0.56 ± 0.00\n0.59 ± 0.00\n0.53 ± 0.00\nformed\n100\nClean\n0.07 ± 0.03\n175.18 ± 18.70\n0.11 ± 0.05\n0.22 ± 0.20\n0.08 ± 0.03\n100\nNoisy\n0.02 ± 0.03\n140.43 ± 4.85\n0.02 ± 0.06\n0.10 ± 0.30\n0.01 ± 0.03\n1000\nClean\n0.13 ± 0.08\n179.48 ± 30.60\n0.19 ± 0.11\n0.28 ± 0.23\n0.15 ± 0.07\n1000\nNoisy\n0.02 ± 0.03\n140.43 ± 4.85\n0.02 ± 0.06\n0.10 ± 0.30\n0.01 ± 0.03\n10000\nClean\n0.24 ± 0.09\n341.28 ± 89.95\n0.22 ± 0.14\n0.20 ± 0.23\n0.31 ± 0.07\n10000\nNoisy\n0.10 ± 0.07\n392.92 ± 96.16\n0.13 ± 0.10\n0.14 ± 0.21\n0.17 ± 0.04\n100000\nClean\n0.45 ± 0.05\n329.50 ± 87.72\n0.32 ± 0.13\n0.26 ± 0.19\n0.52 ± 0.02\n100000\nNoisy\n0.24 ± 0.07\n379.95 ± 90.95\n0.21 ± 0.11\n0.17 ± 0.15\n0.32 ± 0.04\npathfinder\n100\nClean\n-\n-\n-\n-\n-\n100\nNoisy\n0.08 ± 0.00\n232.00 ± 0.00\n0.01 ± 0.00\n0.25 ± 0.00\n0.00 ± 0.00\n1000\nClean\n-\n-\n-\n-\n-\n1000\nNoisy\n0.08 ± 0.00\n232.00 ± 0.00\n0.01 ± 0.00\n0.25 ± 0.00\n0.00 ± 0.00\n10000\nClean\n0.06 ± 0.00\n192.52 ± 0.11\n0.11 ± 0.00\n0.56 ± 0.00\n0.06 ± 0.00\n10000\nNoisy\n0.09 ± 0.00\n227.00 ± 0.00\n0.04 ± 0.00\n0.71 ± 0.00\n0.02 ± 0.00\n100000\nClean\n0.23 ± 0.00\n157.52 ± 0.11\n0.37 ± 0.00\n0.85 ± 0.00\n0.23 ± 0.00\n100000\nNoisy\n0.15 ± 0.00\n212.00 ± 0.00\n0.17 ± 0.00\n0.88 ± 0.00\n0.09 ± 0.00\nsimsum\n100\nClean\n0.23 ± 0.02\n37.92 ± 0.96\n0.45 ± 0.01\n0.46 ± 0.01\n0.44 ± 0.01\n100\nNoisy\n0.00 ± 0.00\n35.00 ± 0.00\n0.00 ± 0.00\nnan\n0.00 ± 0.00\n1000\nClean\n0.23 ± 0.02\n37.92 ± 0.96\n0.45 ± 0.01\n0.46 ± 0.01\n0.44 ± 0.01\n1000\nNoisy\n0.00 ± 0.00\n35.00 ± 0.00\n0.00 ± 0.00\nnan\n0.00 ± 0.00\n10000\nClean\n0.29 ± 0.00\n25.00 ± 0.00\n0.44 ± 0.00\n1.00 ± 0.00\n0.29 ± 0.00\n10000\nNoisy\n0.09 ± 0.00\n32.00 ± 0.00\n0.16 ± 0.00\n1.00 ± 0.00\n0.09 ± 0.00\n100000\nClean\n0.47 ± 0.00\n18.50 ± 0.00\n0.64 ± 0.00\n1.00 ± 0.00\n0.47 ± 0.00\n100000\nNoisy\n0.10 ± 0.00\n31.50 ± 0.00\n0.18 ± 0.00\n1.00 ± 0.00\n0.10 ± 0.00\n23\n"}, {"page": 24, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nTable 14: DAG-GNN Complete Results\nNetwork\nSample size\nData\nBSF\nSHD\nF1\nPrecision\nRecall\nasia\n100\nClean\n0.16 ± 0.06\n8.57 ± 1.81\n0.37 ± 0.05\n0.57 ± 0.28\n0.31 ± 0.08\n100\nNoisy\n0.01 ± 0.09\n6.40 ± 0.97\n0.10 ± 0.10\n0.43 ± 0.41†\n0.06 ± 0.06\n1000\nClean\n0.51 ± 0.07\n4.68 ± 0.98\n0.66 ± 0.06\n0.80 ± 0.11\n0.57 ± 0.05\n1000\nNoisy\n0.00 ± 0.00\n6.00 ± 0.00\n0.00 ± 0.00\nnan\n0.00 ± 0.00\n10000\nClean\n0.17 ± 0.14\n10.78 ± 3.05\n0.45 ± 0.07\n0.42 ± 0.15\n0.52 ± 0.05\n10000\nNoisy\n0.02 ± 0.07\n5.90 ± 0.45\n0.03 ± 0.11\n1.00 ± 0.00†\n0.02 ± 0.07\n100000\nClean\n-\n-\n-\n-\n-\n100000\nNoisy\n-\n-\n-\n-\n-\nsports\n100\nClean\n0.04 ± 0.06\n14.80 ± 0.99\n0.16 ± 0.08\n0.58 ± 0.22†\n0.10 ± 0.05\n100\nNoisy\n−0.03 ± 0.08\n13.62 ± 1.20\n0.13 ± 0.09\n0.41 ± 0.29†\n0.08 ± 0.06\n1000\nClean\n0.04 ± 0.06\n14.80 ± 0.99\n0.16 ± 0.08\n0.58 ± 0.22†\n0.10 ± 0.05\n1000\nNoisy\n0.01 ± 0.04\n12.92 ± 0.52\n0.05 ± 0.06\n0.67 ± 0.40†\n0.03 ± 0.03\n10000\nClean\n0.04 ± 0.06\n14.55 ± 0.93\n0.09 ± 0.09\n0.77 ± 0.32†\n0.05 ± 0.05\n10000\nNoisy\n0.01 ± 0.06\n12.85 ± 0.76\n0.05 ± 0.07\n0.67 ± 0.47†\n0.03 ± 0.04\n100000\nClean\n-\n-\n-\n-\n-\n100000\nNoisy\n-\n-\n-\n-\n-\nproperty\n100\nClean\n0.11 ± 0.04\n37.45 ± 2.18\n0.19 ± 0.04\n0.29 ± 0.06\n0.15 ± 0.04\n100\nNoisy\n0.07 ± 0.05\n39.62 ± 3.32\n0.15 ± 0.06\n0.24 ± 0.10\n0.11 ± 0.04\n1000\nClean\n0.13 ± 0.05\n33.22 ± 2.55\n0.22 ± 0.06\n0.41 ± 0.10\n0.15 ± 0.05\n1000\nNoisy\n0.06 ± 0.03\n32.75 ± 2.05\n0.13 ± 0.05\n0.47 ± 0.19\n0.07 ± 0.03\n10000\nClean\n0.12 ± 0.05\n34.22 ± 2.88\n0.21 ± 0.07\n0.37 ± 0.11\n0.15 ± 0.05\n10000\nNoisy\n0.07 ± 0.03\n31.65 ± 1.59\n0.14 ± 0.04\n0.56 ± 0.18\n0.08 ± 0.02\n100000\nClean\n-\n-\n-\n-\n-\n100000\nNoisy\n-\n-\n-\n-\n-\nalarm\n100\nClean\n0.36 ± 0.05\n60.28 ± 6.54\n0.39 ± 0.04\n0.37 ± 0.05\n0.42 ± 0.05\n100\nNoisy\n0.11 ± 0.04\n52.28 ± 7.00\n0.14 ± 0.07\n0.29 ± 0.12\n0.10 ± 0.05\n1000\nClean\n0.47 ± 0.05\n52.80 ± 5.29\n0.48 ± 0.04\n0.44 ± 0.04\n0.52 ± 0.04\n1000\nNoisy\n0.14 ± 0.06\n42.12 ± 3.02\n0.20 ± 0.10\n0.70 ± 0.24\n0.12 ± 0.07\n10000\nClean\n0.50 ± 0.05\n46.68 ± 4.74\n0.52 ± 0.04\n0.50 ± 0.05\n0.54 ± 0.05\n10000\nNoisy\n0.15 ± 0.05\n41.90 ± 2.50\n0.22 ± 0.08\n0.68 ± 0.15\n0.13 ± 0.05\n100000\nClean\n-\n-\n-\n-\n-\n100000\nNoisy\n-\n-\n-\n-\n-\nformed\n100\nClean\n0.14 ± 0.02\n371.78 ± 61.03\n0.14 ± 0.02\n0.10 ± 0.02\n0.21 ± 0.03\n100\nNoisy\n0.04 ± 0.02\n350.40 ± 91.41\n0.07 ± 0.02\n0.06 ± 0.02\n0.09 ± 0.04\n1000\nClean\n0.23 ± 0.04\n214.32 ± 40.07\n0.25 ± 0.03\n0.27 ± 0.10\n0.26 ± 0.05\n1000\nNoisy\n0.04 ± 0.02\n350.40 ± 91.41\n0.07 ± 0.02\n0.06 ± 0.02\n0.09 ± 0.04\n10000\nClean\n0.26 ± 0.04\n157.15 ± 15.10\n0.33 ± 0.04\n0.41 ± 0.08\n0.28 ± 0.05\n10000\nNoisy\n0.11 ± 0.03\n131.55 ± 3.56\n0.18 ± 0.05\n0.72 ± 0.10\n0.10 ± 0.03\n100000\nClean\n-\n-\n-\n-\n-\n100000\nNoisy\n-\n-\n-\n-\n-\npathfinder\n100\nClean\n0.20 ± 0.02\n234.70 ± 18.41\n0.26 ± 0.02\n0.34 ± 0.05\n0.21 ± 0.02\n100\nNoisy\n0.20 ± 0.02\n317.98 ± 88.69\n0.21 ± 0.03\n0.28 ± 0.10\n0.18 ± 0.02\n1000\nClean\n0.30 ± 0.03\n262.68 ± 33.94\n0.33 ± 0.03\n0.33 ± 0.06\n0.32 ± 0.03\n1000\nNoisy\n0.20 ± 0.02\n317.98 ± 88.69\n0.21 ± 0.03\n0.28 ± 0.10\n0.18 ± 0.02\n10000\nClean\n0.28 ± 0.05\n353.25 ± 98.65\n0.27 ± 0.05\n0.24 ± 0.06\n0.32 ± 0.05\n10000\nNoisy\n0.20 ± 0.02\n201.32 ± 4.60\n0.26 ± 0.03\n0.84 ± 0.05\n0.15 ± 0.02\n100000\nClean\n-\n-\n-\n-\n-\n100000\nNoisy\n-\n-\n-\n-\n-\nsimsum\n100\nClean\n0.07 ± 0.07\n39.95 ± 6.31\n0.28 ± 0.02\n0.42 ± 0.12\n0.22 ± 0.02\n100\nNoisy\n0.11 ± 0.05\n32.20 ± 1.97\n0.26 ± 0.08\n0.67 ± 0.11\n0.16 ± 0.06\n1000\nClean\n0.07 ± 0.07\n39.95 ± 6.31\n0.28 ± 0.02\n0.42 ± 0.12\n0.22 ± 0.02\n1000\nNoisy\n0.11 ± 0.05\n32.20 ± 1.97\n0.26 ± 0.08\n0.67 ± 0.11\n0.16 ± 0.06\n10000\nClean\n0.16 ± 0.08\n32.70 ± 2.62\n0.31 ± 0.10\n0.59 ± 0.10\n0.22 ± 0.09\n10000\nNoisy\n0.07 ± 0.05\n32.60 ± 1.62\n0.14 ± 0.08\n0.90 ± 0.15\n0.08 ± 0.05\n100000\nClean\n0.14 ± 0.06\n32.62 ± 2.78\n0.28 ± 0.08\n0.62 ± 0.13\n0.19 ± 0.06\n100000\nNoisy\n0.08 ± 0.05\n32.42 ± 1.70\n0.16 ± 0.08\n0.87 ± 0.16\n0.09 ± 0.05\n24\n"}, {"page": 25, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nTable 15: Tabu-AL Complete Results\nNetwork\nSample size\nData\nBSF\nSHD\nF1\nPrecision\nRecall\nasia\n100\nClean\n0.44 ± 0.19\n5.00 ± 2.13\n0.60 ± 0.16\n0.84 ± 0.19\n0.49 ± 0.16\n100\nNoisy\n0.20 ± 0.15\n5.00 ± 1.12\n0.33 ± 0.19\n0.79 ± 0.32†\n0.22 ± 0.13\n1000\nClean\n0.53 ± 0.18\n5.10 ± 2.19\n0.67 ± 0.14\n0.71 ± 0.15\n0.64 ± 0.13\n1000\nNoisy\n0.34 ± 0.16\n4.28 ± 1.28\n0.51 ± 0.17\n0.81 ± 0.27\n0.37 ± 0.13\n10000\nClean\n0.42 ± 0.34\n7.72 ± 5.09\n0.61 ± 0.21\n0.57 ± 0.24\n0.68 ± 0.17\n10000\nNoisy\n0.36 ± 0.16\n5.45 ± 1.22\n0.54 ± 0.12\n0.54 ± 0.11\n0.54 ± 0.13\n100000\nClean\n0.27 ± 0.46\n10.42 ± 7.13\n0.55 ± 0.26\n0.49 ± 0.28\n0.65 ± 0.19\n100000\nNoisy\n0.24 ± 0.15\n7.50 ± 1.43\n0.47 ± 0.09\n0.41 ± 0.08\n0.56 ± 0.12\nsports\n100\nClean\n0.07 ± 0.01\n14.00 ± 0.16\n0.12 ± 0.02\n1.00 ± 0.00\n0.07 ± 0.01\n100\nNoisy\n0.05 ± 0.05\n12.40 ± 0.72\n0.11 ± 0.05\n0.85 ± 0.36\n0.06 ± 0.03\n1000\nClean\n0.07 ± 0.01\n14.00 ± 0.16\n0.12 ± 0.02\n1.00 ± 0.00\n0.07 ± 0.01\n1000\nNoisy\n0.37 ± 0.08\n8.18 ± 1.04\n0.54 ± 0.09\n1.00 ± 0.00\n0.37 ± 0.08\n10000\nClean\n0.42 ± 0.13\n9.15 ± 2.32\n0.62 ± 0.09\n0.82 ± 0.13\n0.51 ± 0.07\n10000\nNoisy\n0.48 ± 0.11\n6.88 ± 1.48\n0.66 ± 0.08\n0.91 ± 0.09\n0.53 ± 0.07\n100000\nClean\n0.51 ± 0.38\n8.52 ± 6.74\n0.72 ± 0.21\n0.73 ± 0.22\n0.72 ± 0.20\n100000\nNoisy\n0.56 ± 0.23\n5.95 ± 3.12\n0.75 ± 0.14\n0.80 ± 0.12\n0.71 ± 0.15\nproperty\n100\nClean\n0.35 ± 0.05\n21.10 ± 2.11\n0.51 ± 0.06\n0.92 ± 0.07\n0.35 ± 0.05\n100\nNoisy\n0.16 ± 0.04\n26.78 ± 1.13\n0.28 ± 0.05\n1.00 ± 0.00\n0.16 ± 0.04\n1000\nClean\n0.52 ± 0.07\n19.38 ± 4.79\n0.63 ± 0.08\n0.78 ± 0.12\n0.54 ± 0.06\n1000\nNoisy\n0.39 ± 0.04\n21.35 ± 2.03\n0.54 ± 0.04\n0.86 ± 0.07\n0.40 ± 0.04\n10000\nClean\n0.68 ± 0.07\n18.32 ± 5.67\n0.71 ± 0.08\n0.71 ± 0.11\n0.71 ± 0.06\n10000\nNoisy\n0.56 ± 0.08\n18.12 ± 6.44\n0.67 ± 0.09\n0.82 ± 0.15\n0.58 ± 0.07\n100000\nClean\n0.78 ± 0.07\n16.42 ± 5.45\n0.76 ± 0.07\n0.71 ± 0.09\n0.82 ± 0.06\n100000\nNoisy\n0.65 ± 0.07\n19.73 ± 7.28\n0.69 ± 0.09\n0.71 ± 0.12\n0.68 ± 0.06\nalarm\n100\nClean\n0.40 ± 0.03\n31.38 ± 2.46\n0.55 ± 0.04\n0.82 ± 0.06\n0.41 ± 0.03\n100\nNoisy\n0.11 ± 0.02\n42.28 ± 1.48\n0.15 ± 0.03\n0.79 ± 0.17\n0.09 ± 0.02\n1000\nClean\n0.63 ± 0.05\n24.40 ± 7.18\n0.71 ± 0.07\n0.80 ± 0.10\n0.64 ± 0.05\n1000\nNoisy\n0.35 ± 0.05\n34.50 ± 3.77\n0.48 ± 0.06\n0.75 ± 0.08\n0.35 ± 0.05\n10000\nClean\n0.69 ± 0.06\n29.12 ± 8.81\n0.70 ± 0.07\n0.68 ± 0.09\n0.72 ± 0.05\n10000\nNoisy\n0.55 ± 0.06\n33.78 ± 6.72\n0.61 ± 0.07\n0.64 ± 0.08\n0.58 ± 0.06\n100000\nClean\n0.76 ± 0.07\n29.72 ± 10.18\n0.71 ± 0.08\n0.65 ± 0.10\n0.79 ± 0.06\n100000\nNoisy\n0.53 ± 0.05\n50.95 ± 7.75\n0.51 ± 0.05\n0.45 ± 0.06\n0.59 ± 0.05\nformed\n100\nClean\n0.30 ± 0.03\n117.98 ± 5.66\n0.42 ± 0.03\n0.65 ± 0.04\n0.31 ± 0.03\n100\nNoisy\n0.14 ± 0.01\n124.28 ± 1.91\n0.23 ± 0.02\n0.87 ± 0.03\n0.13 ± 0.01\n1000\nClean\n0.58 ± 0.03\n74.15 ± 7.15\n0.68 ± 0.03\n0.83 ± 0.04\n0.58 ± 0.03\n1000\nNoisy\n0.14 ± 0.01\n124.28 ± 1.91\n0.23 ± 0.02\n0.87 ± 0.03\n0.13 ± 0.01\n10000\nClean\n0.74 ± 0.04\n59.00 ± 10.30\n0.78 ± 0.04\n0.81 ± 0.04\n0.75 ± 0.04\n10000\nNoisy\n0.48 ± 0.04\n88.98 ± 7.45\n0.61 ± 0.04\n0.80 ± 0.03\n0.49 ± 0.04\n100000\nClean\n0.77 ± 0.05\n65.15 ± 13.10\n0.77 ± 0.05\n0.76 ± 0.05\n0.78 ± 0.04\n100000\nNoisy\n0.58 ± 0.03∗\n115.66 ± 11.27∗\n0.59 ± 0.04∗\n0.59 ± 0.04∗\n0.60 ± 0.03∗\npathfinder\n100\nClean\n-\n-\n-\n-\n-\n100\nNoisy\n0.14 ± 0.01\n214.55 ± 3.63\n0.15 ± 0.02\n0.84 ± 0.07\n0.08 ± 0.01\n1000\nClean\n0.21 ± 0.03\n445.62 ± 88.40\n0.19 ± 0.04\n0.17 ± 0.10\n0.26 ± 0.03\n1000\nNoisy\n0.14 ± 0.01\n214.55 ± 3.63\n0.15 ± 0.02\n0.84 ± 0.07\n0.08 ± 0.01\n10000\nClean\n0.37 ± 0.02\n185.08 ± 17.15\n0.44 ± 0.04\n0.54 ± 0.06\n0.38 ± 0.02\n10000\nNoisy\n0.23 ± 0.01\n246.42 ± 6.75\n0.27 ± 0.02\n0.42 ± 0.03\n0.20 ± 0.01\n100000\nClean\n0.51 ± 0.01\n156.43 ± 10.22\n0.57 ± 0.02\n0.62 ± 0.03\n0.53 ± 0.01\n100000\nNoisy\n0.38 ± 0.01\n191.40 ± 5.60\n0.47 ± 0.01\n0.65 ± 0.02\n0.37 ± 0.01\nsimsum\n100\nClean\n0.07 ± 0.02\n32.80 ± 0.59\n0.13 ± 0.03\n0.94 ± 0.11\n0.07 ± 0.02\n100\nNoisy\n0.01 ± 0.02\n34.70 ± 0.83\n0.03 ± 0.03\n0.72 ± 0.45†\n0.02 ± 0.01\n1000\nClean\n0.07 ± 0.02\n32.80 ± 0.59\n0.13 ± 0.03\n0.94 ± 0.11\n0.07 ± 0.02\n1000\nNoisy\n0.01 ± 0.02\n34.70 ± 0.83\n0.03 ± 0.03\n0.72 ± 0.45†\n0.02 ± 0.01\n10000\nClean\n0.31 ± 0.04\n24.55 ± 1.53\n0.47 ± 0.05\n0.97 ± 0.05\n0.31 ± 0.04\n10000\nNoisy\n0.08 ± 0.02\n32.35 ± 0.71\n0.14 ± 0.04\n1.00 ± 0.00\n0.08 ± 0.02\n100000\nClean\n0.43 ± 0.07\n21.05 ± 3.01\n0.59 ± 0.07\n0.90 ± 0.06\n0.45 ± 0.07\n100000\nNoisy\n0.11 ± 0.04\n31.12 ± 1.30\n0.20 ± 0.06\n0.99 ± 0.05\n0.11 ± 0.04\n25\n"}, {"page": 26, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nTable 16: Bayesys Model Avg Complete Results\nNetwork\nSample size\nData\nBSF\nSHD\nF1\nPrecision\nRecall\nasia\n100\nClean\n0.08 ± 0.10\n13.78 ± 1.48\n0.42 ± 0.05\n0.32 ± 0.04\n0.62 ± 0.10\n100\nNoisy\n0.18 ± 0.05\n6.38 ± 0.60\n0.40 ± 0.04\n0.46 ± 0.06\n0.35 ± 0.03\n1000\nClean\n0.38 ± 0.07\n8.98 ± 0.95\n0.56 ± 0.04\n0.46 ± 0.04\n0.72 ± 0.06\n1000\nNoisy\n0.13 ± 0.00\n7.00 ± 0.00\n0.36 ± 0.00\n0.40 ± 0.00\n0.33 ± 0.00\n10000\nClean\n0.31 ± 0.14\n11.48 ± 2.44\n0.53 ± 0.07\n0.40 ± 0.07\n0.80 ± 0.07\n10000\nNoisy\n0.28 ± 0.04\n7.05 ± 0.54\n0.50 ± 0.03\n0.44 ± 0.03\n0.58 ± 0.03\n100000\nClean\n0.65 ± 0.13\n5.22 ± 2.28\n0.73 ± 0.09\n0.65 ± 0.13\n0.85 ± 0.04\n100000\nNoisy\n0.40 ± 0.05\n6.58 ± 0.29\n0.57 ± 0.03\n0.47 ± 0.02\n0.74 ± 0.05\nsports\n100\nClean\n0.21 ± 0.07\n12.38 ± 1.33\n0.43 ± 0.05\n0.72 ± 0.14\n0.30 ± 0.04\n100\nNoisy\n0.13 ± 0.07\n11.70 ± 1.04\n0.39 ± 0.04\n0.62 ± 0.10\n0.29 ± 0.04\n1000\nClean\n0.21 ± 0.07\n12.38 ± 1.33\n0.43 ± 0.05\n0.72 ± 0.14\n0.30 ± 0.04\n1000\nNoisy\n0.37 ± 0.05\n8.25 ± 0.72\n0.55 ± 0.04\n0.94 ± 0.08\n0.39 ± 0.04\n10000\nClean\n0.56 ± 0.07\n7.80 ± 1.19\n0.75 ± 0.04\n0.73 ± 0.05\n0.77 ± 0.08\n10000\nNoisy\n0.46 ± 0.05\n7.52 ± 0.70\n0.71 ± 0.03\n0.70 ± 0.02\n0.73 ± 0.05\n100000\nClean\n0.75 ± 0.10\n4.78 ± 1.67\n0.85 ± 0.06\n0.80 ± 0.05\n0.91 ± 0.08\n100000\nNoisy\n0.32 ± 0.09\n9.82 ± 1.23\n0.68 ± 0.04\n0.59 ± 0.04\n0.81 ± 0.07\nproperty\n100\nClean\n0.59 ± 0.04\n29.92 ± 2.41\n0.57 ± 0.03\n0.52 ± 0.03\n0.65 ± 0.04\n100\nNoisy\n0.40 ± 0.04\n31.08 ± 3.46\n0.48 ± 0.04\n0.52 ± 0.07\n0.44 ± 0.04\n1000\nClean\n0.72 ± 0.03\n23.88 ± 3.33\n0.67 ± 0.03\n0.59 ± 0.05\n0.77 ± 0.03\n1000\nNoisy\n0.58 ± 0.04\n22.42 ± 2.39\n0.64 ± 0.03\n0.66 ± 0.04\n0.62 ± 0.03\n10000\nClean\n0.85 ± 0.04\n20.90 ± 3.29\n0.73 ± 0.04\n0.61 ± 0.04\n0.91 ± 0.03\n10000\nNoisy\n0.76 ± 0.02\n30.32 ± 1.34\n0.64 ± 0.01\n0.52 ± 0.01\n0.85 ± 0.02\n100000\nClean\n0.92 ± 0.02\n16.08 ± 1.81\n0.79 ± 0.02\n0.67 ± 0.03\n0.96 ± 0.02\n100000\nNoisy\n0.70 ± 0.03\n49.98 ± 2.13\n0.52 ± 0.02\n0.38 ± 0.01\n0.85 ± 0.02\nalarm\n100\nClean\n0.54 ± 0.05\n106.25 ± 19.92\n0.38 ± 0.03\n0.27 ± 0.05\n0.69 ± 0.08\n100\nNoisy\n0.20 ± 0.03\n72.42 ± 4.93\n0.24 ± 0.03\n0.23 ± 0.03\n0.25 ± 0.03\n1000\nClean\n0.70 ± 0.02\n75.55 ± 4.09\n0.50 ± 0.02\n0.36 ± 0.01\n0.80 ± 0.02\n1000\nNoisy\n0.47 ± 0.02\n37.85 ± 1.40\n0.54 ± 0.01\n0.60 ± 0.02\n0.50 ± 0.02\n10000\nClean\n0.80 ± 0.03\n59.50 ± 4.46\n0.58 ± 0.02\n0.43 ± 0.02\n0.89 ± 0.03\n10000\nNoisy\n0.59 ± 0.01\n43.72 ± 1.60\n0.57 ± 0.01\n0.51 ± 0.01\n0.65 ± 0.02\n100000\nClean\n0.89 ± 0.02\n32.50 ± 2.74\n0.73 ± 0.02\n0.59 ± 0.02\n0.93 ± 0.02\n100000\nNoisy\n0.57 ± 0.02\n72.58 ± 1.93\n0.46 ± 0.01\n0.35 ± 0.01\n0.68 ± 0.02\nformed\n100\nClean\n0.26 ± 0.04\n546.92 ± 119.38\n0.16 ± 0.01\n0.10 ± 0.01\n0.38 ± 0.07\n100\nNoisy\n0.13 ± 0.03\n481.58 ± 103.90\n0.12 ± 0.02\n0.08 ± 0.02\n0.23 ± 0.03\n1000\nClean\n0.54 ± 0.08\n325.58 ± 77.37\n0.35 ± 0.08\n0.25 ± 0.09\n0.61 ± 0.09\n1000\nNoisy\n0.13 ± 0.03\n481.58 ± 103.90\n0.12 ± 0.02\n0.08 ± 0.02\n0.23 ± 0.03\n10000\nClean\n0.63 ± 0.07\n389.80 ± 82.33\n0.35 ± 0.08\n0.23 ± 0.08\n0.73 ± 0.07\n10000\nNoisy\n0.42 ± 0.03\n380.92 ± 85.00\n0.29 ± 0.08\n0.21 ± 0.11\n0.51 ± 0.02\n100000\nClean\n0.68 ± 0.06\n380.35 ± 76.72\n0.37 ± 0.07\n0.24 ± 0.06\n0.78 ± 0.06\n100000\nNoisy\n0.51 ± 0.04\n398.60 ± 80.65\n0.31 ± 0.07\n0.21 ± 0.07\n0.61 ± 0.04\npathfinder\n100\nClean\n0.25 ± 0.06\n962.10 ± 24.71\n0.14 ± 0.02\n0.08 ± 0.01\n0.40 ± 0.06\n100\nNoisy\n0.26 ± 0.02\n319.90 ± 87.44\n0.27 ± 0.04\n0.32 ± 0.09\n0.25 ± 0.02\n1000\nClean\n0.43 ± 0.03\n733.18 ± 139.47\n0.23 ± 0.05\n0.15 ± 0.05\n0.54 ± 0.03\n1000\nNoisy\n0.26 ± 0.02\n319.90 ± 87.44\n0.27 ± 0.04\n0.32 ± 0.09\n0.25 ± 0.02\n10000\nClean\n0.59 ± 0.05\n366.85 ± 96.08\n0.41 ± 0.05\n0.31 ± 0.05\n0.64 ± 0.05\n10000\nNoisy\n0.34 ± 0.02\n237.25 ± 6.28\n0.39 ± 0.02\n0.48 ± 0.02\n0.33 ± 0.02\n100000\nClean\n0.52 ± 0.01\n167.32 ± 4.39\n0.55 ± 0.01\n0.58 ± 0.01\n0.53 ± 0.01\n100000\nNoisy\n0.38 ± 0.00\n203.35 ± 3.20\n0.46 ± 0.01\n0.59 ± 0.01\n0.37 ± 0.00\nsimsum\n100\nClean\n0.16 ± 0.05\n56.10 ± 3.00\n0.46 ± 0.02\n0.35 ± 0.02\n0.69 ± 0.03\n100\nNoisy\n0.08 ± 0.06\n35.60 ± 2.06\n0.31 ± 0.07\n0.48 ± 0.06\n0.23 ± 0.06\n1000\nClean\n0.16 ± 0.05\n56.10 ± 3.00\n0.46 ± 0.02\n0.35 ± 0.02\n0.69 ± 0.03\n1000\nNoisy\n0.08 ± 0.06\n35.60 ± 2.06\n0.31 ± 0.07\n0.48 ± 0.06\n0.23 ± 0.06\n10000\nClean\n0.53 ± 0.06\n21.52 ± 3.44\n0.67 ± 0.05\n0.73 ± 0.07\n0.62 ± 0.04\n10000\nNoisy\n0.17 ± 0.05\n29.32 ± 1.68\n0.29 ± 0.07\n0.95 ± 0.07\n0.17 ± 0.05\n100000\nClean\n0.50 ± 0.05\n22.52 ± 2.69\n0.65 ± 0.04\n0.71 ± 0.05\n0.60 ± 0.04\n100000\nNoisy\n0.28 ± 0.05\n25.68 ± 1.77\n0.45 ± 0.06\n0.91 ± 0.06\n0.30 ± 0.05\n26\n"}, {"page": 27, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nTable 17: Aslani & Mohebbi Complete Results\nNetwork\nSample size\nData\nBSF\nSHD\nF1\nPrecision\nRecall\nasia\n100\nClean\n0.09 ± 0.11\n13.68 ± 1.39\n0.42 ± 0.06\n0.32 ± 0.04\n0.63 ± 0.12\n100\nNoisy\n0.22 ± 0.10\n6.18 ± 0.82\n0.42 ± 0.08\n0.48 ± 0.08\n0.38 ± 0.08\n1000\nClean\n0.35 ± 0.06\n9.18 ± 0.91\n0.54 ± 0.03\n0.45 ± 0.03\n0.68 ± 0.04\n1000\nNoisy\n0.13 ± 0.00\n7.00 ± 0.00\n0.36 ± 0.00\n0.40 ± 0.00\n0.33 ± 0.00\n10000\nClean\n0.32 ± 0.13\n11.40 ± 2.40\n0.54 ± 0.06\n0.40 ± 0.07\n0.81 ± 0.05\n10000\nNoisy\n0.27 ± 0.04\n7.10 ± 0.50\n0.49 ± 0.03\n0.43 ± 0.03\n0.58 ± 0.04\n100000\nClean\n0.66 ± 0.12\n4.78 ± 1.99\n0.74 ± 0.09\n0.68 ± 0.12\n0.83 ± 0.04\n100000\nNoisy\n0.40 ± 0.05\n6.62 ± 0.28\n0.57 ± 0.03\n0.47 ± 0.02\n0.73 ± 0.05\nsports\n100\nClean\n0.25 ± 0.08\n11.82 ± 1.55\n0.46 ± 0.06\n0.75 ± 0.15\n0.34 ± 0.04\n100\nNoisy\n0.19 ± 0.10\n10.88 ± 1.37\n0.46 ± 0.07\n0.66 ± 0.11\n0.35 ± 0.06\n1000\nClean\n0.25 ± 0.08\n11.82 ± 1.55\n0.46 ± 0.06\n0.75 ± 0.15\n0.34 ± 0.04\n1000\nNoisy\n0.41 ± 0.06\n7.72 ± 0.88\n0.59 ± 0.05\n0.95 ± 0.07\n0.43 ± 0.05\n10000\nClean\n0.54 ± 0.07\n8.02 ± 1.31\n0.73 ± 0.04\n0.74 ± 0.06\n0.73 ± 0.04\n10000\nNoisy\n0.50 ± 0.10\n7.02 ± 1.29\n0.73 ± 0.05\n0.72 ± 0.04\n0.75 ± 0.07\n100000\nClean\n0.77 ± 0.08\n4.40 ± 1.38\n0.86 ± 0.04\n0.81 ± 0.04\n0.93 ± 0.06\n100000\nNoisy\n0.37 ± 0.08\n9.18 ± 1.14\n0.70 ± 0.03\n0.61 ± 0.04\n0.84 ± 0.06\nproperty\n100\nClean\n0.60 ± 0.03\n29.38 ± 2.32\n0.58 ± 0.02\n0.52 ± 0.03\n0.66 ± 0.03\n100\nNoisy\n0.41 ± 0.03\n30.52 ± 3.40\n0.49 ± 0.04\n0.53 ± 0.07\n0.46 ± 0.03\n1000\nClean\n0.72 ± 0.04\n23.75 ± 3.53\n0.67 ± 0.04\n0.59 ± 0.05\n0.77 ± 0.04\n1000\nNoisy\n0.58 ± 0.04\n22.48 ± 2.43\n0.64 ± 0.03\n0.66 ± 0.04\n0.62 ± 0.04\n10000\nClean\n0.85 ± 0.04\n19.88 ± 3.26\n0.74 ± 0.04\n0.63 ± 0.04\n0.91 ± 0.04\n10000\nNoisy\n0.77 ± 0.02\n30.22 ± 1.31\n0.64 ± 0.01\n0.52 ± 0.01\n0.85 ± 0.02\n100000\nClean\n0.90 ± 0.02\n16.10 ± 2.11\n0.78 ± 0.02\n0.67 ± 0.03\n0.94 ± 0.02\n100000\nNoisy\n0.69 ± 0.03\n49.82 ± 2.28\n0.52 ± 0.02\n0.38 ± 0.01\n0.85 ± 0.03\nalarm\n100\nClean\n0.54 ± 0.04\n103.98 ± 19.89\n0.38 ± 0.03\n0.27 ± 0.05\n0.69 ± 0.07\n100\nNoisy\n0.21 ± 0.04\n71.35 ± 4.79\n0.25 ± 0.03\n0.24 ± 0.03\n0.27 ± 0.04\n1000\nClean\n0.70 ± 0.02\n73.05 ± 3.92\n0.50 ± 0.01\n0.37 ± 0.01\n0.81 ± 0.02\n1000\nNoisy\n0.52 ± 0.03\n35.50 ± 1.75\n0.58 ± 0.02\n0.62 ± 0.02\n0.55 ± 0.03\n10000\nClean\n0.80 ± 0.02\n57.05 ± 4.57\n0.59 ± 0.02\n0.44 ± 0.02\n0.88 ± 0.02\n10000\nNoisy\n0.59 ± 0.01\n43.62 ± 1.76\n0.57 ± 0.01\n0.51 ± 0.02\n0.65 ± 0.01\n100000\nClean\n0.88 ± 0.02\n30.80 ± 2.66\n0.73 ± 0.02\n0.61 ± 0.02\n0.92 ± 0.02\n100000\nNoisy\n0.57 ± 0.01\n70.97 ± 2.18\n0.46 ± 0.01\n0.35 ± 0.01\n0.69 ± 0.01\nformed\n100\nClean\n-\n-\n-\n-\n-\n100\nNoisy\n-\n-\n-\n-\n-\n1000\nClean\n-\n-\n-\n-\n-\n1000\nNoisy\n-\n-\n-\n-\n-\n10000\nClean\n-\n-\n-\n-\n-\n10000\nNoisy\n-\n-\n-\n-\n-\n100000\nClean\n-\n-\n-\n-\n-\n100000\nNoisy\n-\n-\n-\n-\n-\npathfinder\n100\nClean\n-\n-\n-\n-\n-\n100\nNoisy\n-\n-\n-\n-\n-\n1000\nClean\n-\n-\n-\n-\n-\n1000\nNoisy\n-\n-\n-\n-\n-\n10000\nClean\n-\n-\n-\n-\n-\n10000\nNoisy\n-\n-\n-\n-\n-\n100000\nClean\n-\n-\n-\n-\n-\n100000\nNoisy\n-\n-\n-\n-\n-\nsimsum\n100\nClean\n0.15 ± 0.06\n55.62 ± 2.86\n0.46 ± 0.03\n0.35 ± 0.02\n0.67 ± 0.05\n100\nNoisy\n0.10 ± 0.06\n34.70 ± 2.12\n0.34 ± 0.07\n0.50 ± 0.06\n0.26 ± 0.06\n1000\nClean\n0.15 ± 0.06\n55.62 ± 2.86\n0.46 ± 0.03\n0.35 ± 0.02\n0.67 ± 0.05\n1000\nNoisy\n0.10 ± 0.06\n34.70 ± 2.12\n0.34 ± 0.07\n0.50 ± 0.06\n0.26 ± 0.06\n10000\nClean\n0.52 ± 0.06\n21.42 ± 3.30\n0.67 ± 0.05\n0.73 ± 0.07\n0.61 ± 0.04\n10000\nNoisy\n0.18 ± 0.03\n28.75 ± 1.26\n0.31 ± 0.05\n0.95 ± 0.06\n0.19 ± 0.03\n100000\nClean\n0.53 ± 0.04\n21.35 ± 2.33\n0.67 ± 0.03\n0.73 ± 0.05\n0.63 ± 0.03\n100000\nNoisy\n0.29 ± 0.05\n25.20 ± 1.98\n0.46 ± 0.06\n0.91 ± 0.06\n0.31 ± 0.06\n27\n"}, {"page": 28, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nTable 18: Expert Model Average Complete Results\nNetwork\nSample size\nData\nBSF\nSHD\nF1\nPrecision\nRecall\nasia\n100\nClean\n0.42 ± 0.15\n7.20 ± 1.84\n0.58 ± 0.11\n0.55 ± 0.11\n0.63 ± 0.11\n100\nNoisy\n0.42 ± 0.15\n4.10 ± 1.15\n0.58 ± 0.14\n0.75 ± 0.15\n0.48 ± 0.14\n1000\nClean\n0.58 ± 0.13\n5.38 ± 1.81\n0.69 ± 0.09\n0.65 ± 0.12\n0.75 ± 0.09\n1000\nNoisy\n0.27 ± 0.10\n5.75 ± 0.70\n0.46 ± 0.10\n0.52 ± 0.08\n0.42 ± 0.11\n10000\nClean\n0.67 ± 0.11\n5.80 ± 1.89\n0.72 ± 0.07\n0.60 ± 0.09\n0.93 ± 0.07\n10000\nNoisy\n0.44 ± 0.12\n5.35 ± 0.86\n0.59 ± 0.08\n0.55 ± 0.06\n0.66 ± 0.12\n100000\nClean\n0.78 ± 0.12\n2.92 ± 1.70\n0.83 ± 0.09\n0.80 ± 0.12\n0.88 ± 0.09\n100000\nNoisy\n0.42 ± 0.12\n5.95 ± 0.86\n0.58 ± 0.07\n0.50 ± 0.05\n0.69 ± 0.11\nsports\n100\nClean\n0.26 ± 0.09\n11.50 ± 1.43\n0.46 ± 0.09\n0.78 ± 0.12\n0.34 ± 0.08\n100\nNoisy\n0.14 ± 0.08\n11.38 ± 1.05\n0.37 ± 0.08\n0.67 ± 0.14\n0.26 ± 0.07\n1000\nClean\n0.26 ± 0.09\n11.50 ± 1.43\n0.46 ± 0.09\n0.78 ± 0.12\n0.34 ± 0.08\n1000\nNoisy\n0.43 ± 0.06\n7.45 ± 0.78\n0.61 ± 0.06\n0.96 ± 0.06\n0.45 ± 0.07\n10000\nClean\n0.68 ± 0.12\n5.45 ± 2.08\n0.81 ± 0.07\n0.84 ± 0.07\n0.79 ± 0.10\n10000\nNoisy\n0.52 ± 0.10\n6.58 ± 1.34\n0.73 ± 0.06\n0.77 ± 0.06\n0.71 ± 0.09\n100000\nClean\n0.78 ± 0.08\n3.98 ± 1.32\n0.87 ± 0.05\n0.86 ± 0.05\n0.89 ± 0.07\n100000\nNoisy\n0.54 ± 0.11\n6.62 ± 1.60\n0.78 ± 0.05\n0.69 ± 0.05\n0.89 ± 0.06\nproperty\n100\nClean\n0.58 ± 0.05\n18.65 ± 2.96\n0.67 ± 0.05\n0.76 ± 0.08\n0.60 ± 0.05\n100\nNoisy\n0.40 ± 0.06\n22.68 ± 2.94\n0.54 ± 0.07\n0.78 ± 0.09\n0.41 ± 0.06\n1000\nClean\n0.70 ± 0.05\n14.32 ± 2.15\n0.76 ± 0.04\n0.80 ± 0.04\n0.72 ± 0.05\n1000\nNoisy\n0.55 ± 0.05\n17.48 ± 2.30\n0.67 ± 0.04\n0.85 ± 0.06\n0.56 ± 0.05\n10000\nClean\n0.86 ± 0.05\n9.93 ± 3.06\n0.85 ± 0.04\n0.81 ± 0.05\n0.88 ± 0.04\n10000\nNoisy\n0.80 ± 0.05\n14.92 ± 2.70\n0.78 ± 0.04\n0.74 ± 0.04\n0.83 ± 0.05\n100000\nClean\n0.90 ± 0.04\n7.70 ± 1.66\n0.88 ± 0.03\n0.85 ± 0.03\n0.91 ± 0.04\n100000\nNoisy\n0.77 ± 0.06\n22.42 ± 3.71\n0.70 ± 0.04\n0.61 ± 0.05\n0.82 ± 0.05\nalarm\n100\nClean\n0.58 ± 0.06\n50.20 ± 8.80\n0.54 ± 0.04\n0.48 ± 0.07\n0.64 ± 0.06\n100\nNoisy\n0.24 ± 0.03\n46.92 ± 2.96\n0.32 ± 0.03\n0.47 ± 0.06\n0.25 ± 0.03\n1000\nClean\n0.77 ± 0.04\n30.90 ± 3.79\n0.70 ± 0.03\n0.63 ± 0.04\n0.80 ± 0.04\n1000\nNoisy\n0.51 ± 0.04\n28.05 ± 2.80\n0.63 ± 0.04\n0.78 ± 0.05\n0.52 ± 0.04\n10000\nClean\n0.82 ± 0.05\n26.42 ± 5.08\n0.75 ± 0.04\n0.67 ± 0.06\n0.85 ± 0.05\n10000\nNoisy\n0.64 ± 0.04\n28.42 ± 3.20\n0.68 ± 0.03\n0.69 ± 0.04\n0.68 ± 0.05\n100000\nClean\n0.88 ± 0.03\n20.15 ± 2.29\n0.81 ± 0.02\n0.73 ± 0.03\n0.91 ± 0.03\n100000\nNoisy\n0.63 ± 0.04\n46.88 ± 4.41\n0.57 ± 0.03\n0.49 ± 0.03\n0.70 ± 0.04\nformed\n100\nClean\n0.30 ± 0.06\n292.23 ± 37.36\n0.25 ± 0.03\n0.20 ± 0.02\n0.35 ± 0.07\n100\nNoisy\n0.18 ± 0.03\n275.40 ± 47.62\n0.19 ± 0.03\n0.17 ± 0.05\n0.22 ± 0.03\n1000\nClean\n0.53 ± 0.08\n186.82 ± 33.84\n0.46 ± 0.07\n0.39 ± 0.10\n0.56 ± 0.08\n1000\nNoisy\n0.18 ± 0.03\n275.40 ± 47.62\n0.19 ± 0.03\n0.17 ± 0.05\n0.22 ± 0.03\n10000\nClean\n0.63 ± 0.09\n208.88 ± 40.77\n0.48 ± 0.08\n0.37 ± 0.09\n0.68 ± 0.08\n10000\nNoisy\n0.44 ± 0.04\n221.05 ± 39.94\n0.39 ± 0.07\n0.33 ± 0.11\n0.49 ± 0.03\n100000\nClean\n0.69 ± 0.08\n262.80 ± 83.01\n0.46 ± 0.12\n0.33 ± 0.12\n0.75 ± 0.06\n100000\nNoisy\n0.48 ± 0.06\n369.08 ± 82.29\n0.31 ± 0.09\n0.23 ± 0.10\n0.57 ± 0.05\npathfinder\n100\nClean\n0.27 ± 0.03\n313.05 ± 9.54\n0.27 ± 0.02\n0.25 ± 0.02\n0.30 ± 0.03\n100\nNoisy\n0.24 ± 0.01\n213.10 ± 17.37\n0.30 ± 0.02\n0.64 ± 0.11\n0.20 ± 0.01\n1000\nClean\n0.42 ± 0.02\n247.28 ± 27.37\n0.41 ± 0.03\n0.39 ± 0.06\n0.44 ± 0.02\n1000\nNoisy\n0.24 ± 0.01\n213.10 ± 17.37\n0.30 ± 0.02\n0.64 ± 0.11\n0.20 ± 0.01\n10000\nClean\n0.48 ± 0.04\n179.10 ± 20.80\n0.52 ± 0.03\n0.55 ± 0.06\n0.49 ± 0.04\n10000\nNoisy\n0.29 ± 0.01\n195.70 ± 5.45\n0.38 ± 0.02\n0.70 ± 0.03\n0.26 ± 0.02\n100000\nClean\n0.52 ± 0.01\n146.52 ± 2.71\n0.58 ± 0.01\n0.65 ± 0.01\n0.53 ± 0.01\n100000\nNoisy\n0.39 ± 0.00\n188.65 ± 3.30\n0.48 ± 0.01\n0.66 ± 0.02\n0.37 ± 0.00\nsimsum\n100\nClean\n0.39 ± 0.06\n32.88 ± 3.73\n0.57 ± 0.04\n0.53 ± 0.05\n0.62 ± 0.05\n100\nNoisy\n0.14 ± 0.06\n32.02 ± 2.39\n0.33 ± 0.06\n0.62 ± 0.09\n0.23 ± 0.05\n1000\nClean\n0.39 ± 0.06\n32.88 ± 3.73\n0.57 ± 0.04\n0.53 ± 0.05\n0.62 ± 0.05\n1000\nNoisy\n0.14 ± 0.06\n32.02 ± 2.39\n0.33 ± 0.06\n0.62 ± 0.09\n0.23 ± 0.05\n10000\nClean\n0.60 ± 0.04\n15.68 ± 1.84\n0.74 ± 0.03\n0.88 ± 0.04\n0.64 ± 0.03\n10000\nNoisy\n0.21 ± 0.04\n27.85 ± 1.52\n0.34 ± 0.06\n0.98 ± 0.05\n0.21 ± 0.04\n100000\nClean\n0.66 ± 0.05\n13.42 ± 2.48\n0.78 ± 0.04\n0.90 ± 0.05\n0.70 ± 0.05\n100000\nNoisy\n0.32 ± 0.04\n24.05 ± 1.52\n0.49 ± 0.05\n0.95 ± 0.05\n0.33 ± 0.05\n28\n"}, {"page": 29, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nFigure 4: BSF on clean data, plotted over expert correctnesses ∈{50%, 60%, 70%, 80%, 90%, 100%}. Bayesys\nModel Avg is provided as a static baseline for comparison, as an ensembling method not using\nexpert knowledge. The shaded region denotes one standard deviation.\n29\n"}, {"page": 30, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nFigure 5: BSF on noisy data, plotted over expert correctnesses ∈{50%, 60%, 70%, 80%, 90%, 100%}. Bayesys\nModel Avg is provided as a static baseline for comparison, as an ensembling method not using\nexpert knowledge. The shaded region denotes one standard deviation.\n30\n"}, {"page": 31, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nFigure 6: F1 score on clean data, plotted over expert correctnesses ∈{50%, 60%, 70%, 80%, 90%, 100%}.\nBayesys Model Avg is provided as a static baseline for comparison, as an ensembling method not\nusing expert knowledge. The shaded region denotes one standard deviation.\n31\n"}, {"page": 32, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nFigure 7: F1 score on noisy data, plotted over expert correctnesses ∈{50%, 60%, 70%, 80%, 90%, 100%}.\nBayesys Model Avg is provided as a static baseline for comparison, as an ensembling method not\nusing expert knowledge. The shaded region denotes one standard deviation.\n32\n"}, {"page": 33, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nFigure 8: Precision on clean data, plotted over expert correctnesses ∈{50%, 60%, 70%, 80%, 90%, 100%}.\nBayesys Model Avg is provided as a static baseline for comparison, as an ensembling method not\nusing expert knowledge. The shaded region denotes one standard deviation.\n33\n"}, {"page": 34, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nFigure 9: Precision on noisy data, plotted over expert correctnesses ∈{50%, 60%, 70%, 80%, 90%, 100%}.\nBayesys Model Avg is provided as a static baseline for comparison, as an ensembling method not\nusing expert knowledge. The shaded region denotes one standard deviation.\n34\n"}, {"page": 35, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nFigure 10: Recall on clean data, plotted over expert correctnesses ∈{50%, 60%, 70%, 80%, 90%, 100%}.\nBayesys Model Avg is provided as a static baseline for comparison, as an ensembling method\nnot using expert knowledge. The shaded region denotes one standard deviation.\n35\n"}, {"page": 36, "text": "Dynamic Expert-Guided Model Averaging for Causal Discovery\nFigure 11: Recall on noisy data, plotted over expert correctnesses ∈{50%, 60%, 70%, 80%, 90%, 100%}.\nBayesys Model Avg is provided as a static baseline for comparison, as an ensembling method\nnot using expert knowledge. The shaded region denotes one standard deviation.\n36\n"}]}