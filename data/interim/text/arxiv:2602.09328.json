{"doc_id": "arxiv:2602.09328", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2602.09328.pdf", "meta": {"doc_id": "arxiv:2602.09328", "source": "arxiv", "arxiv_id": "2602.09328", "title": "In-Hospital Stroke Prediction from PPG-Derived Hemodynamic Features", "authors": ["Jiaming Liu", "Cheng Ding", "Daoqiang Zhang"], "published": "2026-02-10T01:50:26Z", "updated": "2026-02-10T01:50:26Z", "summary": "The absence of pre-hospital physiological data in standard clinical datasets fundamentally constrains the early prediction of stroke, as patients typically present only after stroke has occurred, leaving the predictive value of continuous monitoring signals such as photoplethysmography (PPG) unvalidated. In this work, we overcome this limitation by focusing on a rare but clinically critical cohort - patients who suffered stroke during hospitalization while already under continuous monitoring - thereby enabling the first large-scale analysis of pre-stroke PPG waveforms aligned to verified onset times. Using MIMIC-III and MC-MED, we develop an LLM-assisted data mining pipeline to extract precise in-hospital stroke onset timestamps from unstructured clinical notes, followed by physician validation, identifying 176 patients (MIMIC) and 158 patients (MC-MED) with high-quality synchronized pre-onset PPG data, respectively. We then extract hemodynamic features from PPG and employ a ResNet-1D model to predict impending stroke across multiple early-warning horizons. The model achieves F1-scores of 0.7956, 0.8759, and 0.9406 at 4, 5, and 6 hours prior to onset on MIMIC-III, and, without re-tuning, reaches 0.9256, 0.9595, and 0.9888 on MC-MED for the same horizons. These results provide the first empirical evidence from real-world clinical data that PPG contains predictive signatures of stroke several hours before onset, demonstrating that passively acquired physiological signals can support reliable early warning, supporting a shift from post-event stroke recognition to proactive, physiology-based surveillance that may materially improve patient outcomes in routine clinical care.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2602.09328v1", "url_pdf": "https://arxiv.org/pdf/2602.09328.pdf", "meta_path": "data/raw/arxiv/meta/2602.09328.json", "sha256": "801cea7b2e4ed3e41669a9fc8d2f0ef9333b02f0d34b0bef8095650b9928ed53", "status": "ok", "fetched_at": "2026-02-18T02:19:27.166591+00:00"}, "pages": [{"page": 1, "text": "In-Hospital Stroke Prediction from PPG-Derived Hemodynamic\nFeatures\nJiaming Liu\nNanjing University of Aeronautics\nand Astronautics\nNanjing, Jiangsu, China\ngaming@nuaa.edu.cn\nCheng Dingâˆ—\nNanjing University of Aeronautics\nand Astronautics\nNanjing, Jiangsu, China\nchengding@nuaa.edu.cn\nDaoqiang Zhang\nNanjing University of Aeronautics\nand Astronautics\nNanjing, Jiangsu, China\ndqzhang@nuaa.edu.cn\nAbstract\nThe absence of pre-hospital physiological data in standard clinical\ndatasets fundamentally constrains the early prediction of stroke,\nas patients typically present only after stroke has occurred, leav-\ning the predictive value of continuous monitoring signals such as\nphotoplethysmography (PPG) unvalidated. In this work, we over-\ncome this limitation by focusing on a rare but clinically critical\ncohortâ€”patients who suffered stroke during hospitalization while\nalready under continuous monitoringâ€”thereby enabling the first\nlarge-scale analysis of pre-stroke PPG waveforms aligned to ver-\nified onset times. Using MIMIC-III and MC-MED, we develop an\nLLM-assisted data mining pipeline to extract precise in-hospital\nstroke onset timestamps from unstructured clinical notes, followed\nby physician validation, identifying 176 patients (MIMIC) and 158\npatients (MC-MED) with high-quality synchronized pre-onset PPG\ndata, respectively. We then extract hemodynamic features from\nPPG and employe a ResNet-1D model to predict impending stroke\nacross multiple early-warning horizons. The model achieves F1-\nscores of 0.7956, 0.8759, and 0.9406 at 4, 5, and 6 hours prior to onset\non MIMIC-III, and, without re-tuning, reaches 0.9256, 0.9595, and\n0.9888 on MC-MED for the same horizons. These results provide\nthe first empirical evidence from real-world clinical data that PPG\ncontains predictive signatures of stroke several hours before onset,\ndemonstrating that passively acquired physiological signals can\nsupport reliable early warning, supporting a shift from post-event\nstroke recognition to proactive, physiology-based surveillance that\nmay materially improve patient outcomes in routine clinical care.\nKeywords\nPPG, In-Hospital Stroke Prediction, Early Warning Systems\nACM Reference Format:\nJiaming Liu, Cheng Ding, and Daoqiang Zhang. 2026. In-Hospital Stroke\nPrediction from PPG-Derived Hemodynamic Features. In Proceedings of\nProceedings of the 32nd ACM SIGKDD Conference on Knowledge Discovery\nand Data Mining (KDD â€™26). ACM, New York, NY, USA, 11 pages.\n1\nIntroduction\nStroke is a catastrophic vascular event that demands immediate\nintervention[11, 31]. While the clinical community has long sought\nmethods for early prediction, progress has been severely limited by\na fundamental data paradox: patients typically present to the hos-\npital only post-onset[47]. Consequently, standard clinical datasets\nâˆ—Corresponding Author\nKDD â€™26, Jeju, Korea\n2026.\ncontain abundant post-stroke data but suffer from a complete ab-\nsence of pre-stroke physiological signals[21]. This \"blind spot\" has\nprecluded the validation of continuous monitoring technologies,\nsuch as Photoplethysmography (PPG), for effective stroke predic-\ntion prior to onset[22].\nFrom a biomedical engineering perspective, PPG is theoretically\nan ideal candidate for this task[61]. Stroke is driven by cerebrovas-\ncular hemodynamicsâ€”specifically, abrupt changes in vascular re-\nsistance and blood flow dynamics[43]. As PPG passively measures\nperipheral blood volume changes, it offers a direct window into\nthe systemic cardiovascular state. However, the efficacy of PPG for\nstroke prediction remains an unproven hypothesis[56, 59], primar-\nily attributable to the historical paucity of data documenting the\nphysiological transition from a baseline state to an acute stroke\nevent[7, 8, 26].\nIn this work, we overcome this barrier by targeting a unique and\nchallenging cohort: in-hospital stroke patients. These are patients\nwho were already under continuous physiological monitoring for\nother conditions when they suffered a stroke. This rare scenario\noffers a unique opportunity to capture \"pre-stroke\" waveform data\nunavailable in standard admission records. By retrospectively ana-\nlyzing these cases, we canâ€”for the first timeâ€”explore the feasibility\nof PPG-based early warning systems using real-world clinical data.\nTo operationalize this, we utilized two large-scale datasets, MIMIC-\nIII [40] and MC-MED [29]. However, identifying these rare cases\npresents a significant mining challenge. The timestamps available\nin structured EHR data represent documentation time rather than\nthe physiological onset of stroke, and therefore cannot be directly\ninterpreted as onset time. To address this, we developed a pipeline\nusing Gemini 3 Pro to extract exact onset timestamps from un-\nstructured clinical notes, which were subsequently validated by\nphysicians. This rigorous process allowed us to identify 176 patients\nin MIMIC-III and 158 patients in MC-MED who possess high-quality,\nsynchronized PPG waveforms leading up to the event.\nWith this unprecedented data, we developed a deep learning\nframework to test our hypothesis. Hemodynamic features extracted\nfrom pre-onset PPG signals were fed into a ResNet-1D model to iden-\ntify predictive signatures[23, 50, 55]. Across three early-warning\nhorizons, the model demonstrates progressively improved perfor-\nmance. When trained and validated on the internal MIMIC-III co-\nhort, F1-scores increase from 0.7956 at 4 hours to 0.8759 Â± 0.0105\nat 5 hours and 0.9406 at 6 hours prior to onset. Using the same\ntrained model without any re-tuning, external evaluation on the\nMC-MED cohort yields F1-scores of 0.9256, 0.9595, and 0.9888 for\nthe corresponding horizons. These results confirm the validity of\nPPG as a predictive signal for early stroke warning and demonstrate\nthat temporally aligned, passively acquired physiological data can\narXiv:2602.09328v1  [cs.LG]  10 Feb 2026\n"}, {"page": 2, "text": "KDD â€™26, August 2026, Jeju, Korea\nLiu et al.\nsupport reliable prediction with substantial lead time, beyond what\nis achievable through model-centric optimization alone.\n2\nRelated Work\n2.1\nStroke Prediction with EHR and ML\nTraditional stroke stratification has evolved from rule-based scoring\n(e.g., Framingham) to high-dimensional modeling using EHR[1, 2,\n12, 41, 54]. While early ML approaches (e.g., Random Forests, SVMs)\neffectively leveraged structured features like demographics and\ndiagnosis codes for population-level risk assessment [10, 20, 24, 25,\n34, 37, 46, 49, 52, 60], they rely on static snapshots.\nThese methods inherently lack the temporal granularity required\nfor acute, real-time physiological monitoring in clinical settings.\n2.2\nOccult Disease Detection via Physio-Signals\nAddressing EHR limitations, Deep Learning (DL) architectures now\nenable the identification of occult disease signatures from continu-\nous physiological signals, even absent explicit pathological events\n[5, 30, 39, 58]. A key area is extracting risk precursors from Normal\nSinus Rhythm in ECGs [28, 32, 45, 65]. Notably, Gadaleta et al. [16]\ndemonstrated that sub-clinical morphological features in AF-free\nintervals could accurately quantify near-term Atrial Fibrillation\nrisk. These findings validate the hypothesis that DL can extract\nlatent morphological biomarkers invisible to standard clinical in-\nterpretation [13, 18, 48, 53].\n2.3\nPPG Hemodynamics and the Label Gap\nPPG offers a complementary window into cerebrovascular hemody-\nnamics, reflecting vascular stiffness and aging [6, 9, 14, 38, 44].\nWhile recent end-to-end DL models successfully infer indirect\nstroke factors (e.g., cuffless blood pressure, AF) from raw pulse\nwaves [35, 42, 62], the direct prediction of acute in-hospital stroke\nremains unexplored [3]. Existing PPG research is predominantly\nretrospective or associative [33, 64], lacking predictive capability\nfor the critical pre-onset window.\nThis gap stems not from sensor limitations, but from a fundamen-\ntal \"label unavailability\" challenge: the scarcity of in-hospital stroke\ndatasets prevents the construction of aligned pre-stroke windows\nfor supervised learning [4, 51]. Our work addresses this bottleneck\nby establishing a reliable temporal reference via an LLM-enhanced\nwaveform anchoring method, enabling the first data-centric explo-\nration of PPG-based acute stroke prediction [57].\n3\nMethods\nTo validate the predictive value of continuous physiological moni-\ntoring for impending stroke, this work utilizes two large-scale criti-\ncal care databases: MIMIC-III [40] as the internal development set\nand MC-MED [29] for external evaluation. The core methodological\nchallenge addressed in this work is the absence of structured times-\ntamps for in-hospital stroke onset in standard EHR. To overcome\nthis, this work establishes a comprehensive data processing pipeline,\nas illustrated in Fig. 1, consisting of three primary stages: (1) Co-\nhort Identification and Temporal Anchoring, where we combine\nICD-based screening with an LLM-assisted extraction workflow to\npinpoint precise stroke onset timestamps from unstructured clinical\nnarratives; (2) Physiological Signal Preprocessing, involving the\nextraction, quality assessment, and windowing of high-frequency\nPPG waveforms aligned to the validated onset times; and (3) Deep\nLearning Modeling, employing a ResNet-1D architecture to capture\nhemodynamic precursors across varying prediction horizons.\n3.1\nData Source\nThis study leverages two distinct large-scale clinical databases to en-\nsure both robust model development and external generalizability:\nthe MIMIC-III [40] and the MC-MED [29].\nMIMIC-III (Internal Cohort): Sourced from the Beth Israel Dea-\nconess Medical Center in Boston, MA, this single-center database\nserves as our primary training and internal validation environment.\nIt comprises comprehensive de-identified health-related data asso-\nciated with over 40,000 patients who stayed in critical care units\nbetween 2001 and 2012. Our analysis focused on the subset of 38,548\npatients for whom sufficient waveform data was potentially retriev-\nable. Within this population, the identified stroke subset exhibited\na mean age of 66.9 years (SD 15.3), notably higher than the overall\ncohort mean of 63.8 years. Racial demographics within the stroke\nsubset largely mirrored the general MIMIC population, with 124\n(70.5%) identified as White, 13 (7.4%) as Black or African American,\nand 5 (2.8%) as Asian. Comorbidity profiles indicated significantly\nhigher rates of hypertension in the stroke group (76.7% vs. 56.8%)\nand hyperlipidemia (39.8% vs. 31.8%), consistent with established\nvascular risk factors.\nMC-MED (External Cohort): To rigorously test model transfer-\nability, we employed MC-MED, a large-scale multi-center database\naggregating EHR and physiological data from diverse hospital sys-\ntems across the West Coast. This dataset provides a substantially\nlarger general pool of 118,385 patients. The confirmed stroke subset\nin MC-MED presented a distinct demographic profile compared to\nMIMIC-III, with a higher mean age of 71.2 years (SD 15.0) versus\nthe general MC-MED population of 53.3 years. The racial composi-\ntion of the stroke subset in MC-MED differed from the internal set,\nwith a larger proportion of Asian patients (45 individuals, 28.5%)\ncompared to White (74 individuals, 46.8%) and Black or African\nAmerican patients (8 individuals, 5.1%).\nAs summarized in Table 1, both stroke subsets consistently\nskewed older and demonstrated a higher burden of vascular comor-\nbidities relative to their respective general populations, reinforcing\nthe clinical validity of the extracted cohorts despite the heterogene-\nity in data sources.\n3.2\nStroke Onset Time Extraction via LLM\nThe main obstacle to training supervised models for acute in-hospital\nstroke lies in the insufficient temporal resolution of the standard\nEHR. While structured data fields reliably identify the occurrence\nof a stroke, they inherently lack the granularity to pinpoint the pre-\ncise moment of symptom onsetâ€”a critical variable for defining the\npre-event window. Consequently, the crucial timestamp that marks\nthe physiological transition from baseline to pathology is typically\nembedded within unstructured free-text clinical narratives.\nTo bridge this gap efficiently, we implemented an automated\nNLP pipeline to parse unstructured clinical narratives from MIMIC-\nIII and MC-MED datasets. To ensure high-fidelity anchoring, the\n"}, {"page": 3, "text": "In-Hospital Stroke Prediction from PPG\nKDD â€™26, August 2026, Jeju, Korea\nâ‘  Pre-Stroke Window Selection\nâ‘¡ Feature Extraction\nâ‘¢Prediction & Evaluation\nClinical Notes\nA.Morphological Parsing & Fiducial Extraction\nSp\nPeak-to-Peak Interval(Tpp)\nSp\nTime Delay(â–³T)\nResNet-1D\nSystolic Peak\nAmplitude(A,)\nOn\ndp off\ndn\nMIMIC-Ill\nMIMIC-I MC-MED\nPulse Interval(Tp)\nSystolic Time(Tsts)\nDiastolic Time(Taia)\n(Internal)\nDiastolic Peak Time(Tap)\nSystolic Peak Time(Tsp)\nRecall,F1.\nB. Multi-Order Kinematic Decomposition\nU\na\nStroke Onset Extraction\nAccuracy, etc.\nP1\ne\nW\nCONV-1D\nLLM\nC\nP?\nV\nStroke Onset\nPPG\nPPG'\nPPG\"\nPPG'\"\nCONV-1D\nb\nMC-MED\näºŒäºŒäºŒäºŒ\näºŒäºŒ_äºŒ\nNormal\nBuffer Time\nWarning\nLead Time\nC. Risk Stratification\n   MMAAAAAMMAMMMAM\nStroke Onset\n(External,Zero-shot)\nNormal\nBuffer Time\nWarning\nLead Time\nRecall,F1l.\nVMA\nâ– Accuracy, etc.\n480\n(T+â–³me)\n(T-â–³m)\n-â–³ã€‚\n0\n-480\n-(Tw+â–³pre)\n-(Tw-â–³pre)\n-â–³o\n0\nReview Clinical Notes for Precise Stroke Onset Time\nExtract Key Hemodynamic Features\nApply 1D ResNet to Predict Stroke\nFrom Pre-stroke PPG Signals\nOnset 4-6 Hours in Advance\nt\nFigure 1: Overview of the proposed framework. The pipeline comprises three phases: (1) Temporal Anchoring: LLM-driven\nextraction of precise stroke onset timestamps from unstructured clinical notes; (2) Feature Engineering: Derivation of hemody-\nnamic biomarkers from PPG waveforms and their derivatives; and (3) Predictive Modeling: A ResNet-1D network for early\nstroke warning, validated on internal (MIMIC-III) and external (MC-MED) cohorts.\npipeline enforces a hierarchical temporal extraction strategy across\nboth cohorts. First, it prioritizes Explicit Semantic Alignment, scan-\nning for direct temporal markers (e.g., \"onset at 6:30 AM\") and\nresolving relative expressions against the noteâ€™s metadata to derive\nan absolute timestamp. In the absence of a specific onset description,\nthe system utilizes an Implicit Temporal Proxy if an acute event is\nconfirmed, defaulting to the noteâ€™s creation time as a conservative\nupper bound. Conversely, records describing unrelated patholo-\ngies or historical strokes without acute recurrence are flagged as\nnon-events and excluded.\nThis logic converts unstructured clinical notes into structured\ntemporal indices. We validated this method via a protocol involving\ntwo neurologists. On a stratified subset of 100 cases, the model\nachieved 95.0% concordance within a Â±15-minute tolerance of the\nground truth. This tolerance aligns with the labeling strategy de-\ntailed in Section 3.4, which defines the normal, warning, and buffer\nzones for stroke prediction.\n3.3\nHemodynamic Feature Engineering\nBased on the verified stroke onset timestamps, we implemented a\npipeline to derive standardized predictors of acute cerebrovascular\nevents. Utilizing the pyPPG toolbox [19], we extracted 74 morpho-\nlogical biomarkers per cardiac cycle from the raw PPG signal and\nits derivatives to capture hemodynamic dynamics. Recognizing the\nlimitations of absolute physiological measurements due to inter-\npatient heterogeneity, we applied a normalization technique to\nisolate pathological trajectories. Each metric ğ‘¥(ğ‘¡) was projected\ninto a relative deviation space to quantify the magnitude of di-\nvergence. Consequently, a Relative Displacement score (Fğ‘Ÿğ‘’ğ‘™) was\ncalculated relative to a subject-specific baseline ğœ‡ğ‘ğ‘ğ‘ ğ‘’, established\nas the mean value during the initial stable period:\n-480\n(Tw +\npre)\n(Tw\npre)\n0\n0\nNormal\nWarning\nBuffer Time\nLead Time\nStroke Onset\ntt\nFigure 2: Temporal Labeling Strategy. Timeline aligned to\nstroke onset (ğ‘¡= 0) with exclusion buffers to mitigate label\nnoise and prevent leakage.\nFğ‘Ÿğ‘’ğ‘™(ğ‘¡) = ğ‘¥(ğ‘¡) âˆ’ğœ‡ğ‘ğ‘ğ‘ ğ‘’\n|ğœ‡ğ‘ğ‘ğ‘ ğ‘’|\n(1)\nThis transformation doubles the feature space, capturing both in-\nstantaneous systemic states and temporal deviations from home-\nostasis.\n3.4\nTemporal Labeling Strategy\nThe integrity of these longitudinal signals was preserved via a\nrigorous, source-isolated preprocessing protocol. Because the raw\ndatasets aggregate heterogeneous recording sessions character-\nized by natural discontinuities (e.g., device re-attachments), we\nrestricted all artifact remediation and imputation operations to the\nboundaries of individual source files. This constraint precluded the\nartificial synthesis of temporal continuity between unrelated physi-\nological states. Following this source-specific standardization, the\nhigh-dimensional feature space was distilled into a refined set of\nrobust stroke precursors through a two-stage statistical filtering pro-\ncess. We first evaluated the discriminative capacity of each feature\n"}, {"page": 4, "text": "KDD â€™26, August 2026, Jeju, Korea\nLiu et al.\nTable 1: Baseline characteristics of the internal (MIMIC) and external (MC-MED) cohorts. Continuous variables are reported as\nmean (SD) and median [IQR]; categorical variables are reported as ğ‘›(%).\nCharacteristic\nSubgroup\nMIMIC (Internal)\nMC-MED (External)\nOverall\nStroke subset\nOverall\nStroke subset\nSample size (ğ‘)\nOverall / Stroke\n38,548\n176\n118,385\n158\nAge, years\nMean (SD)\n63.8 (17.5)\n66.9 (15.3)\n53.3 (20.4)\n71.2 (15.0)\nMedian [IQR]\n65.7 [52.4â€“77.9]\n68.8 [54.2â€“79.6]\n53.0 [35.0â€“70.0]\n75.0 [61.0â€“83.0]\nAge group\n< 65 years\n18,769 (48.7%)\n76 (43.2%)\n79,429 (67.1%)\n48 (30.4%)\nâ‰¥65 years\n19,779 (51.3%)\n100 (56.8%)\n38,956 (32.9%)\n110 (69.6%)\nAge group\n18â€“39 years\n4,075 (10.6%)\n9 (5.1%)\n36,814 (31.1%)\n4 (2.5%)\n40â€“59 years\n10,833 (28.1%)\n52 (29.5%)\n33,345 (28.2%)\n31 (19.6%)\n60â€“79 years\n15,775 (40.9%)\n75 (42.6%)\n33,434 (28.2%)\n71 (44.9%)\nâ‰¥80 years\n7,865 (20.4%)\n40 (22.7%)\n14,792 (12.5%)\n52 (32.9%)\nSex\nFemale\n16,732 (43.4%)\n88 (50.0%)\n64,272 (54.3%)\n76 (48.1%)\nMale\n21,816 (56.6%)\n88 (50.0%)\n54,077 (45.7%)\n82 (51.9%)\nUnknown\n0 (0.0%)\n0 (0.0%)\n36 (0.0%)\n0 (0.0%)\nRace\nWhite\n27,477 (71.3%)\n124 (70.5%)\n47,504 (40.1%)\n74 (46.8%)\nAsian\n911 (2.4%)\n5 (2.8%)\n19,430 (16.4%)\n45 (28.5%)\nBlack or African American\n2,943 (7.6%)\n13 (7.4%)\n7,653 (6.5%)\n8 (5.1%)\nPacific Islander\n11 (0.0%)\n0 (0.0%)\n2,468 (2.1%)\n2 (1.3%)\nAmerican Indian/Alaska Native\n20 (0.1%)\n0 (0.0%)\n309 (0.3%)\n0 (0.0%)\nOther\n2,294 (6.0%)\n21 (11.9%)\n39,951 (33.7%)\n28 (17.7%)\nDeclines to state\n0 (0.0%)\n0 (0.0%)\n551 (0.5%)\n0 (0.0%)\nUnknown\n4,892 (12.7%)\n13 (7.4%)\n143 (0.1%)\n1 (0.6%)\nComorbidities\nHypertension\n21,884 (56.8%)\n135 (76.7%)\n28,308 (23.9%)\n61 (38.6%)\nDiabetes\n10,312 (26.8%)\n39 (22.2%)\n15,457 (13.1%)\n22 (13.9%)\nHyperlipidemia\n12,267 (31.8%)\n70 (39.8%)\n21,578 (18.2%)\n43 (27.2%)\nChronic kidney disease\n4,896 (12.7%)\n14 (8.0%)\n10,094 (8.5%)\n15 (9.5%)\nIschemic heart disease\n13,686 (35.5%)\n30 (17.0%)\n12,332 (10.4%)\n28 (17.7%)\nby calculating Cohenâ€™s ğ‘‘between baseline and pre-stroke windows,\nexcluding non-informative metrics (ğ‘‘â‰¤0.05). Subsequently, to\nmitigate multicollinearity, we identified variable pairs with high\nPearson correlation (ğ‘Ÿ> 0.80) and eliminated redundant features.\nThis pipeline resulted in 17 definitive hemodynamic indicators, en-\nsuring that model inputs are both physiologically significant and\nstatistically efficient. The complete nomenclature, definitions, and\nphysiological relevance of these selected biomarkers are detailed\nin Appendix A.\nTo transform the continuous hemodynamic streams into a rigor-\nous supervised learning framework, we employed a retrospective\nlabeling protocol anchored to the verified stroke onset time (ğ‘¡= 0),\nas illustrated in Fig. 2. The labeling function ğ‘¦(ğ‘¡) is strictly defined\nas:\nğ‘¦(ğ‘¡) =\n(\n1,\nif âˆ’(ğ‘‡ğ‘¤âˆ’Î”ğ‘ğ‘Ÿğ‘’) â‰¤ğ‘¡â‰¤âˆ’Î”0\n(ğ‘Šğ‘ğ‘Ÿğ‘›ğ‘–ğ‘›ğ‘”)\n0,\nif âˆ’480 â‰¤ğ‘¡â‰¤âˆ’(ğ‘‡ğ‘¤+ Î”ğ‘ğ‘Ÿğ‘’)\n(ğ‘ğ‘œğ‘Ÿğ‘šğ‘ğ‘™)\n(2)\nTo ensure robust decision boundaries, we implemented a dual-\nexclusion strategy that discards indeterminate samples falling within\nthe transition zones. As depicted by the hatched regions in Fig. 2,\nthe exclusion set Tdrop is defined as:\nTdrop = [âˆ’(ğ‘‡ğ‘¤+ Î”ğ‘ğ‘Ÿğ‘’), âˆ’(ğ‘‡ğ‘¤âˆ’Î”ğ‘ğ‘Ÿğ‘’))\n|                                 {z                                 }\nBuffer Time\nâˆª(âˆ’Î”0, 0]\n|   {z   }\nLead Time\n(3)\nThe Buffer Time segregates the stable and pre-stroke phases, miti-\ngating the ambiguity inherent in gradual hemodynamic shifts and\npreventing boundary overfitting, a strategy compliant with estab-\nlished protocols for indeterminate physiological states [27]. Con-\ncurrently, the Lead Time (Î”0 = 15 min) enforces a strict \"blind spot\"\nto preclude feature leakage from imminent events. This 15-minute\ngap aligns with the minimum intervention window validated in\npivotal clinical trials [63], ensuring that predictions rely on latent\nprecursors rather than acute onset artifacts, thereby guaranteeing\nclinical actionability.\n3.5\nPredictive Modeling and Evaluation Strategy\nWe employed a ResNet-1D architecture to capture complex tem-\nporal dependencies within the hemodynamic feature space. To\neffectively mitigate the impact of class imbalance inherent in the\ndataset, we optimized the network using a Weighted Cross-Entropy\nLoss with a positive class weight of ğœ†pos = 3.0. All models were im-\nplemented using the PyTorch framework and trained on an NVIDIA\n"}, {"page": 5, "text": "In-Hospital Stroke Prediction from PPG\nKDD â€™26, August 2026, Jeju, Korea\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nFalse Positive Rate\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nTrue Positive Rate\n4h window\n5h window\n6h window\nInternal (MIMIC)\nExternal (MC-MED)\nMIMIC-III(Internal)\nMC-MED(External )\nFigure 3: ROC Analysis across internal and external cohorts.\nThe internal evaluation (solid lines) demonstrates a distinct\ntemporal gradient (6â„> 5â„> 4â„).\nRTX 3060 GPU. The training process utilized the Adam optimizer\nwith a learning rate of ğœ‚= 10âˆ’3 and a weight decay of 10âˆ’4 to\nensure robust and stable convergence.\nTo ensure patient independence and prevent data leakage, we im-\nplemented a stratified patient-level 5-fold cross-validation scheme\non the internal MIMIC-III cohort. In this configuration, all data seg-\nments associated with a specific patient were confined to a single\nfold, ensuring that the model is evaluated exclusively on unseen\nsubjects. Validation performance was monitored at each epoch, and\nthe optimal checkpoint was selected based on the maximal Macro\nF1-score. The final model was subsequently frozen and applied\nto the external MC-MED cohort for independent testing without\nfurther domain adaptation.\n4\nExperiments and Results\nIn this section, we evaluate the proposed framework using the inter-\nnal MIMIC-III cohort for development and the MC-MED cohort for\nexternal validation. We analyze the modelâ€™s predictive performance\nacross multiple horizons, interrogate the physiological plausibility\nof learned features, and conduct a rigorous fairness audit across\ndemographic and clinical subgroups.\n4.1\nMain Predictive Performance\nTemporal Window Analysis. We first evaluated the modelâ€™s pre-\ndictive capacity for impending stroke across observation windows\nof 4, 5, and 6 hours. Results from the internal MIMIC-III cohort (Ta-\nble 2) reveal a pronounced temporal gradient, where performance\nmaximized at the 6-hour window (AUC 0.7492, F1 0.9406). This\ntrend suggests that extended observation windows facilitate the\ncapture of latent hemodynamic dependencies essential for accurate\nearly warning, transcending a reliance on imminent physiologi-\ncal deterioration. Fig. 3 corroborates this finding across cohorts,\ndemonstrating robust zero-shot generalization to the MC-MED\ndataset with consistent monotonic improvement (6â„> 5â„> 4â„).\nFurther statistical decomposition of external performance and label\ndistribution shifts is provided in Section 5.\n4.2\nExplainable Physiological Insights\nWe utilized SHAP [36] to verify that predictive power stems\nfrom physiological mechanisms rather than artifacts. Fig. 4 reveals\nconsistent pre-stroke signatures across MIMIC-III and MC-MED co-\nhorts driven by a baseline-plus-deviation strategy. Relative Systolic\nPeak Time ğ‘‡ğ‘ ğ‘,ğ‘…ğ‘’ğ‘™yields the highest positive contribution to log-\nodds. Its absolute counterpart ğ‘‡ğ‘ ğ‘consistently ranks second. This\nhierarchy prioritizes patient-specific longitudinal trajectories ğ‘…ğ‘’ğ‘™\nover static thresholds to isolate acute pathological hardening. The\nmodel also integrates hemodynamic instability markers including\nrelative amplitude deviations ğ´ğ‘ ğ‘,ğ‘…ğ‘’ğ‘™and pulse timing variability.\nThe prominence of velocity features like ğ‘‡ğ‘£in the external cohort\nfurther confirms sensitivity to cardiac ejection efficiency degrada-\ntion.\nWe mapped the temporal evolution of high-impact features in\nFig. 5 to validate dynamic consistency. A distinct physiological\ndivergence appears in the critical warning zone. The leading pre-\ndictor, Relative Systolic Peak Time (ğ‘‡ğ‘ ğ‘,ğ‘…ğ‘’ğ‘™), exhibits a progressive\nupward drift. Conversely, absolute Systolic Peak Time (ğ‘‡ğ‘ ğ‘) and\nstroke volume proxies (ğ´ğ‘ ğ‘,ğ‘…ğ‘’ğ‘™) display a synchronized decline. This\ninverse relationship connects rising systolic timing deviations with\ndampening hemodynamic force. These patterns confirm that high\nSHAP scores correspond to tangible pre-stroke decompensation\nand reinforce clinical validity.\n4.3\nStratified Performance Evaluation\nWe evaluated generalizability using the external MC-MED cohort\nas depicted in Fig. 6. We assessed whether models trained on the\npredominantly White MIMIC-III population propagate bias to het-\nerogeneous datasets. The model maintains high utility across racial\ngroups with F1-scores of 0.944 for Black and 0.956 for White cohorts.\nPerformance variances are statistically significant at ğ‘< 0.001 but\nabsolute scores remain high. The model generalizes to the Asian\ncohort with an F1-score of 0.921 despite limited training data. This\nconsistency suggests extracted PPG precursors capture physiologi-\ncal features invariant to race. Female patients exhibit slightly higher\nperformance with an F1-score of 0.958 compared to 0.950 for males.\nWe further examined five comorbidities associated with vascular\nstiffness defined by specific ICD diagnostic codes. These conditions\ninclude Hypertension, Diabetes Mellitus, Hyperlipidemia, Chronic\nKidney Disease, and Ischemic Heart Disease. We categorized pa-\ntients into a Low Risk group with zero comorbidities, a Medium Risk\ngroup with one to two, and a High Risk group with three or more.\nPerformance remains strong across strata despite a slight decrease\nrelative to the baseline. F1-scores are 0.968 for Low Risk, 0.943 for\nMedium Risk, and 0.946 for High Risk groups. F1-scores above 0.94\nin complex pathology confirm clinical utility. Performance attenu-\nates in the Elderly cohort aged 65 and older with an F1-score of 0.938\ncompared to 0.981 in Non-Elderly patients. This significant drop\nat ğ‘< 0.001 likely results from arterial stiffness masking hemody-\nnamic signals. High performance confirms effective generalization\nagainst vascular aging and chronic comorbidities.\n"}, {"page": 6, "text": "KDD â€™26, August 2026, Jeju, Korea\nLiu et al.\nTable 2: Performance comparison of the same ResNet-1D model selection protocol under different early-warning windows on\ninternal (MIMIC) and external (MC-MED) validation cohorts. Results are reported as mean Â± standard deviation over five-fold\ncross-validation. For each cohort, the best performance across early-warning windows is highlighted in bold.\nWindow\nDataset\nAccuracy\nRecall\nPrecision\nF1-score\nF2-score\nAUC\n240 min\nMIMIC-III\n0.6654 Â± 0.0047\n0.9833 Â± 0.0106\n0.6681 Â± 0.0041\n0.7956 Â± 0.0027\n0.8985 Â± 0.0062\n0.6525 Â± 0.0530\nMC-MED\n0.8636 Â± 0.0350\n0.9341 Â± 0.0413\n0.9179 Â± 0.0020\n0.9256 Â± 0.0211\n0.9306 Â± 0.0332\n0.5595 Â± 0.1020\n300 min\nMIMIC-III\n0.7860 Â± 0.0129\n0.9647 Â± 0.0360\n0.8028 Â± 0.0125\n0.8759 Â± 0.0105\n0.9269 Â± 0.0243\n0.6924 Â± 0.0668\nMC-MED\n0.9229 Â± 0.0273\n0.9401 Â± 0.0294\n0.9802 Â± 0.0023\n0.9595 Â± 0.0151\n0.9478 Â± 0.0238\n0.5847 Â± 0.1560\n360 min\nMIMIC-III\n0.8880 Â± 0.0028\n0.9981 Â± 0.0025\n0.8894 Â± 0.0013\n0.9406 Â± 0.0015\n0.9743 Â± 0.0020\n0.7492 Â± 0.1147\nMC-MED\n0.9797 Â± 0.0192\n0.9804 Â± 0.0054\n0.9975 Â± 0.0008\n0.9888 Â± 0.0025\n0.9837 Â± 0.0042\n0.7079 Â± 0.1248\na\nb\n)\n(\n8\n4\n3.7\n5\n9\n1\n=\n)x(f\n9\n5\n2.4\n5\n9\n1\n=\n])\nX\n(f[\nE\n0.19\n0.13\n0.21\n0.25\n0.32\n+0.09\n+0.09\n+0.19\n+0.31\n+0.45\n+0.84\n+2.2\nle\nR\n,p\ns\nT\n \np\ns\nT\n \nle\nR\n,p\ns\nA\n \nip\n,\nT\nV\nC\n \nv\nT\n \nff\no\nA\n \nip\nT\nu\nT\n \ne\nd\nutilp\nm\nA\n,e\nslu\nP\nV\nC\n \nle\nR\n,ff\no\nA\n \nip\nT\n,a\nT\nu\nT\n \nle\nR\n,c\nT\n \n6 other features\nle\nR\n,p\ns\nT\n \n=\n \n2\n5\n5\n.\n1\np\ns\nT\n \n=\n \n1\n3\n5\n.\n1\nle\nR\n,p\ns\nA\n \n=\n \n3\n2\n2\n.\n0\nip\n,\nT\nV\nC\n \n=\n \n8\n0\n2\n.\n0\nv\nT\n \n=\n \n7\n8\n0\n.\n0\nff\no\nA\n \n=\n \n9\n1\n.\n0\nip\nT\nu\nT\n \n=\n \n5\n0\n0\n.\n0\ne\nd\nutilp\nm\nA\n,e\nslu\nP\nV\nC\n \n=\n \n6\n7\n1\n.\n0\nle\nR\n,ff\no\nA\n \n=\n \n9\n1\n.\n0\nip\nT\n,a\nT\nu\nT\n \n=\n \n6\n4\n0\n.\n0\nle\nR\n,c\nT\n \n=\n \n3\n0\n.\n0\n6 other features\n1957\n1956\n1955\n1954\n)\n(\n2\n3\n3.9\n5\n9\n1\n=\n)x(f\n9\n5\n2.4\n5\n9\n1\n=\n])\nX\n(f[\nE\n0.35\n0.37\n0.65\n1.38\n+0.11\n+0.11\n+0.14\n+0.15\n+0.79\n+0.85\n+1.86\n+3.84\nle\nR\n,p\ns\nT\n \np\ns\nT\n \nv\nT\n \nle\nR\n,p\ns\nA\n \ne\nd\nutilp\nm\nA\n,e\nslu\nP\nV\nC\n \nle\nR\n,c\nT\n \nff\no\nA\n \nI\nS\n \naid\nT\ns\ny\ns\nT\n \nle\nR\nI\nS\n \nle\nR\n,n\no\nA\n \n6 other features\nle\nR\n,p\ns\nT\n \n=\n \n5\n8\n5\n.\n1\np\ns\nT\n \n=\n \n2\n5\n5\n.\n1\nv\nT\n \n=\n \n9\n1\n4\n.\n0\nle\nR\n,p\ns\nA\n \n=\n \n5\n1\n4\n.\n0\ne\nd\nutilp\nm\nA\n,e\nslu\nP\nV\nC\n \n=\n \n5\n2\n4\n.\n0\nle\nR\n,c\nT\n \n=\n \n1\n2\n4\n.\n0\nff\no\nA\n \n=\n \n1\n8\n3\n.\n0\nI\nS\n \n=\n \n8\n0\n6\n.\n0\naid\nT\ns\ny\ns\nT\n \n=\n \n5\n0\n0\n.\n0\nle\nR\nI\nS\n \n=\n \n8\n0\n6\n.\n0\nle\nR\n,n\no\nA\n \n=\n \n1\n7\n3\n.\n0\n6 other features\n1959\n1958\n1957\n1956\n1955\n1954\n1953\nMC-MED(External Cohort)\nMIMIC-III(Internal Cohort)\nFigure 4: Cross-Dataset SHAP Analysis. Relative Systolic Peak Time (ğ‘‡ğ‘ ğ‘,ğ‘…ğ‘’ğ‘™) dominates prediction across cohorts, followed by\nğ¶ğ‘‰ğ‘‡,ğ‘ğ‘–and ğ´ğ‘ ğ‘,ğ‘…ğ‘’ğ‘™. (SHAP values scaled by 103).\n5\nDiscussion\nThis study demonstrates that stroke, traditionally regarded as an\nabrupt and clinically silent event until symptom onset, is preceded\nby detectable physiological alterations measurable through continu-\nous bedside monitoring. By leveraging PPG signals acquired during\nroutine inpatient care, we show that meaningful hemodynamic\nsignatures emerge several hours before clinically recognized stroke\nonset. Following are several key clinical discussion points.\nHemodynamic Timing Signatures Preceding In-Hospital\nStroke. A key physiological insight from this study is the consistent\ninvolvement of two PPG-derived systolic timing featuresâ€”Systolic\nRise Time (SRT) and Time to Maximum Velocity (TMV)â€”as early\nindicators of stroke risk. SRT reflects arterial compliance and wave\nreflection, while TMV, defined by the peak of the first derivative of\nthe PPG waveform, captures early systolic acceleration and ventric-\nularâ€“vascular coupling. SHAP analysis confirms that both features\nare among the dominant contributors to model predictions across\ninternal and external cohorts, indicating reliance on fundamen-\ntal hemodynamic mechanisms rather than site-specific artifacts.\nTheir temporal trajectories demonstrate progressive deviation from\npatient-specific baselines in the hours preceding stroke, suggesting\na gradual loss of systolic efficiency and arterial buffering capacity.\nFrom a cardiovascular perspective, these findings imply that stroke\nonset is preceded by systemic hemodynamic deterioration, in which\nimpaired flow acceleration and altered pulse propagation increase\ncerebrovascular vulnerability.\nClinical Generalizability and Demographic Equity. To as-\nsess clinical generalizability, we evaluated the proposed model\nacross diverse demographics and distributional shifts. The model\nmaintained statistical invariance across multi-ethnic cohorts and\nvarious comorbidities (e.g., hypertension, diabetes, and renal dis-\nease), suggesting that predictive signatures rely on universal hemo-\ndynamic mechanisms rather than demographic artifacts or sensor-\ninduced biases like skin pigmentation. Although geriatric vascular\nremodeling and arterial stiffness may slightly dampen acute signal\ndetection, individualized baselines preserve clinical efficacy and pre-\ndictive accuracy. The model demonstrated distributional robustness\nwith superior F1-scores during external validation (Table 2), par-\ntially attributable to saturated anomaly ratios (91.31%â€“99.74%) [15]\nin the external cohort. This generalization is further corroborated\nby the consistent discriminative performance maintained across co-\nhorts, confirming the extraction of domain-invariant hemodynamic\nfeatures.\n"}, {"page": 7, "text": "In-Hospital Stroke Prediction from PPG\nKDD â€™26, August 2026, Jeju, Korea\n0.0\n0.5\n1.0\nStroke Onset\nNormalized Hemodynamic Feature Trajectories\nTsp, Rel (HRV)\n0.0\n0.5\n1.0\nTsp \n0\n2\n4\n6\n8\n10\n12\nTime (h)\n0.0\n0.5\n1.0\nAsp, Rel (Stroke Volume)\nNormal\nBuffer\nWarning\nTimes(h)\n(Transmission)\n(Ejection Velocity)\nFigure 5: Trajectories of Leading Contributing Factors. Visual validation of the leading contributing factors identified by SHAP.\nApproaching Stroke Onset, the Relative Systolic Peak Time (ğ‘‡ğ‘ ğ‘,ğ‘…ğ‘’ğ‘™) exhibits an upward drift, while the absolute Systolic Peak\nTime (ğ‘‡ğ‘ ğ‘) and Relative Systolic Amplitude (ğ´ğ‘ ğ‘,ğ‘…ğ‘’ğ‘™) show a synchronized downward trend in the final phase. This inverse\nrelationship confirms that the model relies on multidimensional physiological deterioration to predict stroke onset.\nLow Risk\nMedium Risk\nHigh Risk\n0.85\n0.90\n0.95\n1.00\nF1-Score\nClinical Risk\n0.968\n0.943\n0.950\nWhite\nAsian\nBlack\n0.825\n0.850\n0.875\n0.900\n0.925\n0.950\n0.975\n1.000\nRace\n0.956\n0.921\n0.944\nElderly ( 65)\nNon-Elderly\n0.825\n0.850\n0.875\n0.900\n0.925\n0.950\n0.975\n1.000\nF1-Score\nAge\n0.938\n0.981\nMale\nFemale\n0.825\n0.850\n0.875\n0.900\n0.925\n0.950\n0.975\nGender\n0.950\n0.958\nSubgroup F1\nGroup Average\n***\n***\n***\n***\n***\n***\n***\n***\na\nb\nc\nd\n0.946\n***\n***\nFigure 6: Subgroup performance analysis on the External Cohort (MC-MED). The model demonstrates zero-shot generalization\nand maintains F1-scores exceeding 0.90 across all racial and clinical subgroups. While performance variances are statistically\nsignificant (ğ‘< 0.001), the consistently high baseline confirms equitable utility despite demographic shifts.\nEnabling a Clinically Actionable Pre-Stroke Warning Win-\ndow. A central clinical implication of this study is the demonstra-\ntion that stroke may be physiologically detectable several hours\nbefore overt neurological deterioration, using signals that are al-\nready routinely collected in hospitalized patients. Traditionally,\nstroke diagnosis and intervention are triggered only after the ap-\npearance of focal neurological deficits, at which point irreversible\nbrain injury may have already occurred. Our findings suggest that\ncontinuous PPG monitoring contains hemodynamic signatures that\nprecede clinically recognized stroke by up to six hours, defining a\n"}, {"page": 8, "text": "KDD â€™26, August 2026, Jeju, Korea\nLiu et al.\npreviously unrecognized pre-onset window that may be amenable\nto proactive clinical response. From a clinical standpoint, such an\nearly warning signal does not aim to replace neurological exami-\nnation or imaging-based diagnosis, but rather to function as a risk\nstratification and surveillance trigger. Patients flagged as high risk\ncould undergo intensified neurological observation, expedited neu-\nroimaging, tighter blood pressure and hemodynamic control, or\nearlier specialist consultation. Importantly, even modest delays in\nstroke recognition are known to worsen outcomes; therefore, shift-\ning clinical attention several hours earlierâ€”even without definitive\ndiagnosisâ€”has the potential to materially improve patient trajecto-\nries by reducing time-to-intervention once symptoms emerge.\nLimitations and Future Work. Despite the robust performance\nof the framework, several limitations remain. First, the current\nmodel lacks the granularity to stratify stroke by subtype, etiology,\nor severity due to the limited sample size of precisely annotated\nin-hospital cases. Future research requires larger, prospectively cu-\nrated datasets to move toward patient-tailored warning systems.\nSecond, while stroke serves as a proof-of-concept, the identified\nhemodynamic featuresâ€”such as arterial stiffness and pulse tim-\ningâ€”reflect systemic vascular dynamics rather than stroke-specific\npathology. This suggests a broad potential for extending this PPG-\nbased framework to other acute conditions involving hemodynamic\ndeterioration, such as sepsis or acute heart failure. Finally, the ret-\nrospective nature of this study necessitates prospective validation\nin real-time clinical workflows to evaluate its actual impact on\ndecision-making and patient outcomes. Integrating these alerts\nrequires a careful balance between diagnostic sensitivity and the\npractical management of alert burden at the bedside.\n6\nConclusion\nThis work bridges the critical \"blind spot\" in acute care informatics\nby introducing an LLM-Enhanced Waveform Anchoring frame-\nwork, which successfully transforms unstructured clinical narra-\ntives into precisely aligned physiological datasets. By unlocking the\nlatent predictive value of continuous PPG signals in confirmed in-\nhospital stroke cases, our data-centric approach demonstrates that\nperipheral hemodynamics harbor actionable warning signatures\nwell before onset. Specifically, utilizing a ResNet-1D architecture,\nthe proposed model achieves a clinically significant 6-hour lead\ntime on the internal MIMIC-III cohort with an F1-score of 0.9406\nand exhibits remarkable zero-shot generalization to the external\nMC-MED cohort, attaining an F1-score of 0.9888 without retrain-\ning. These findings validate the feasibility of passive, non-invasive\nmonitoring for early stroke detection, marking a pivotal shift from\nreactive diagnosis to data-driven, proactive prevention in clinical\nsettings.\nGenerative AI Declaration\nThis work utilized Gemini 3 Pro (Google) for two specific tasks.\nData Extraction: The model parsed stroke timestamps from un-\nstructured clinical notes. Physicians validated all outputs. See Sec-\ntion 3.2 for the methodology. Writing Assistance: The model pol-\nished the linguistic flow and grammar. We maintained full editorial\ncontrol throughout the writing process and take full responsibility\nfor the content.\nAcknowledgments\nThis work was supported in part by the National Natural Science\nFoundation of China under Grant 62136004, and in part by the\nNational Key R&D Program of China (Grant No. 2023YFF1204803).\n"}, {"page": 9, "text": "In-Hospital Stroke Prediction from PPG\nKDD â€™26, August 2026, Jeju, Korea\nReferences\n[1] V. Abedi, V. Avula, D. Chaudhary, S. Shahjouei, A. Khan, C.J. Griessenauer, J. Li,\nand R. Zand. 2021. Prediction of Long-Term Stroke Recurrence Using Machine\nLearning Models. Journal of Clinical Medicine 10, 6 (2021), 1286. https://doi.org/\n10.3390/jcm10061286\n[2] J.N. Acosta, G.J. Falcone, P. Rajpurkar, and E.J. Topol. 2022. Multimodal biomedical\nAI. Nature Medicine 28, 9 (Sep 2022), 1773â€“1784. https://doi.org/10.1038/s41591-\n022-01981-2\n[3] A. Alhakeem, B. Chaurasia, and M.M. Khan. 2025. Revolutionizing stroke predic-\ntion: a systematic review of AI-powered wearable technologies for early detection\nof stroke. Neurosurgical Review 48, 1 (May 2025), 458. https://doi.org/10.1007/\ns10143-025-03629-4\n[4] A.A. Armoundas, S.M. Narayan, D.K. Arnett, K. Spector-Bagdady, D.A. Bennett,\nL.A. Celi, P.A. Friedman, M.H. Gollob, J.L. Hall, A.E. Kwitek, et al. 2024. Use\nof Artificial Intelligence in Improving Outcomes in Heart Disease: A Scientific\nStatement From the American Heart Association. Circulation 149, 14 (Apr 2024),\ne1028â€“e1050. https://doi.org/10.1161/CIR.0000000000001201\n[5] Z.I. Attia, D.M. Harmon, E.R. Behr, and P.A. Friedman. 2021. Application of\nartificial intelligence to the electrocardiogram. European Heart Journal 42, 46\n(Dec 2021), 4717â€“4730. https://doi.org/10.1093/eurheartj/ehab649\n[6] K. Bayoumy, M. Gaber, A. Elshafeey, O. Mhaimeed, E.H. Dineen, F.A. Marvel, S.S.\nMartin, E.D. Muse, M.P. Turakhia, K.G. Tarakji, and M.B. Elshazly. 2021. Smart\nwearable devices in cardiovascular care: where we are and how to move forward.\nNature Reviews Cardiology 18, 8 (Aug 2021), 581â€“599. https://doi.org/10.1038/\ns41569-021-00522-7\n[7] B. Bent, O.M. Enache, B. Goldstein, W. Kibbe, and J.P. Dunn. 2021. Reply: Mat-\nters Arising â€˜Investigating sources of inaccuracy in wearable optical heart rate\nsensorsâ€™. npj Digital Medicine 4, 1 (Feb 2021), 39. https://doi.org/10.1038/s41746-\n021-00409-4\n[8] B. Bent, B.A. Goldstein, W.A. Kibbe, and J.P. Dunn. 2020. Investigating sources of\ninaccuracy in wearable optical heart rate sensors. npj Digital Medicine 3, 1 (Feb\n2020), 18. https://doi.org/10.1038/s41746-020-0226-6\n[9] P.H. Charlton, P.A. Kyriaco, J. Mant, V. Marozas, P. Chowienczyk, and J. Alas-\ntruey. 2022. Wearable Photoplethysmography for Cardiovascular Monitoring.\nProceedings of the IEEE 110, 3 (Mar 2022), 355â€“381. https://doi.org/10.1109/JPROC.\n2022.3149785\n[10] M. Chun, R. Clarke, B.J. Cairns, D.A. Clifton, D. Bennett, Y. Chen, Y. Guo, P. Pei,\nJ. Lv, C. Yu, L. Yang, L. Li, Z. Chen, and T. Zhu. 2021. Stroke risk prediction\nusing machine learning: a prospective cohort study of 0.5 million Chinese adults.\nJournal of the American Medical Informatics Association 28, 8 (2021), 1719â€“1727.\nhttps://doi.org/10.1093/jamia/ocab068\n[11] GBD 2021 Stroke Risk Factor Collaborators. 2024. Global, regional, and national\nburden of stroke and its risk factors, 1990-2021: a systematic analysis for the\nGlobal Burden of Disease Study 2021. Lancet Neurology 23, 10 (Oct 2024), 973â€“\n1003. https://doi.org/10.1016/S1474-4422(24)00369-7\n[12] E. Dritsas and M. Trigka. 2022. Stroke Risk Prediction with Machine Learning\nTechniques. Sensors (Basel) 22, 13 (Jun 2022), 4670. https://doi.org/10.3390/\ns22134670\n[13] J.E. Ebinger and S. Cheng. 2023. From Waveforms to Wisdom: Gleaning More\nFrom the ECG About Biological Aging. Circulation: Cardiovascular Quality and\nOutcomes 16, 7 (Jul 2023), e010176. https://doi.org/10.1161/CIRCOUTCOMES.123.\n010176\n[14] M. Elgendi, R. Fletcher, Y. Liang, N. Howard, N.H. Lovell, D. Abbott, K. Lim, and\nR. Ward. 2019. The use of photoplethysmography for assessing hypertension.\nNPJ Digital Medicine 2 (Jun 2019), 60. https://doi.org/10.1038/s41746-019-0136-7\n[15] Y. Fang, J. Xie, Y. Zhao, L. Chen, Y. Gao, and K. Zheng. 2024. Temporal-Frequency\nMasked Autoencoders for Time Series Anomaly Detection. In 2024 IEEE 40th\nInternational Conference on Data Engineering (ICDE). IEEE, Utrecht, Netherlands,\n1228â€“1241.\n[16] M. Gadaleta, P. Harrington, E. Barnhill, E. Hytopoulos, M.P. Turakhia, S.R. Stein-\nhubl, and G. Quer. 2023. Prediction of atrial fibrillation from at-home single-lead\nECG signals without arrhythmias. NPJ Digital Medicine 6, 1 (Dec 2023), 229.\nhttps://doi.org/10.1038/s41746-023-00966-w\n[17] M.A. Gianfrancesco, S. Tamang, J. Yazdany, and G. Schmajuk. 2018. Potential\nBiases in Machine Learning Algorithms Using Electronic Health Record Data.\nJAMA Internal Medicine 178, 11 (11 2018), 1544â€“1547. https://doi.org/10.1001/\njamainternmed.2018.3763\n[18] P.A. Gladding, W. Hewitt, and T.T. Schlegel. 2020. Going Deep With ECG and\nAortic Stenosis: Touchdown or Incomplete Pass? Journal of the American Heart\nAssociation 9, 7 (Apr 2020), e016193. https://doi.org/10.1161/JAHA.120.016193\n[19] M.A. Goda, P.H. Charlton, and J.A. Behar. 2023. pyPPG: A Python toolbox for\ncomprehensive photoplethysmography signal analysis. arXiv:2309.13767\n[20] Y. Guo. 2022. A New Paradigm of \"Real-Time\" Stroke Risk Prediction and Inte-\ngrated Care Management in the Digital Health Era: Innovations Using Machine\nLearning and Artificial Intelligence Approaches. Thrombosis and Haemostasis\n122, 1 (Jan 2022), 5â€“7. https://doi.org/10.1055/a-1508-7980\n[21] Y. Guo, H. Wang, H. Zhang, T. Liu, L. Li, L. Liu, M. Chen, Y. Chen, and G.Y.H. Lip.\n2021. Photoplethysmography-Based Machine Learning Approaches for Atrial\nFibrillation Prediction: A Report From the Huawei Heart Study. JACC Asia 1, 3\n(Dec 2021), 399â€“408. https://doi.org/10.1016/j.jacasi.2021.09.004\n[22] Y. Guo, H. Wang, H. Zhang, T. Liu, Z. Liang, Y. Xia, L. Yan, Y. Xing, H. Shi,\nS. Li, Y. Liu, F. Liu, M. Feng, Y. Chen, G.Y.H. Lip, and MAFA II Investigators.\n2019. Mobile Photoplethysmographic Technology to Detect Atrial Fibrillation.\nJournal of the American College of Cardiology 74, 19 (Nov 2019), 2365â€“2375.\nhttps://doi.org/10.1016/j.jacc.2019.08.019\n[23] K. He, X. Zhang, S. Ren, and J. Sun. 2016. Deep Residual Learning for Image\nRecognition. In 2016 IEEE Conference on Computer Vision and Pattern Recognition\n(CVPR 2016), Las Vegas, NV, USA, June 27-30, 2016. IEEE Computer Society, Las\nVegas, NV, USA, 770â€“778. https://doi.org/10.1109/CVPR.2016.90\n[24] J. Heo, J. Yoo, H. Lee, I.H. Lee, J.S. Kim, E. Park, Y.D. Kim, and H.S. Nam.\n2022. Prediction of Hidden Coronary Artery Disease Using Machine Learn-\ning in Patients With Acute Ischemic Stroke. Neurology 99, 1 (Jul 2022), e55â€“e65.\nhttps://doi.org/10.1212/WNL.0000000000200576\n[25] H.Y. Ho, K.Y. Liang, W.C. Lin, S. Kitanaka, and J.B. Wu. 2010. Regulation and\nimprovement of triterpene formation in plant cultured cells of Eriobotrya japonica\nLindl. Journal of Bioscience and Bioengineering 110, 5 (Nov 2010), 588â€“592. https:\n//doi.org/10.1016/j.jbiosc.2010.06.009\n[26] A. Hughes, M.M.H. Shandhi, H. Master, J. Dunn, and E. Brittain. 2023. Wearable\nDevices in Cardiovascular Medicine. Circulation Research 132, 5 (Mar 2023),\n652â€“670. https://doi.org/10.1161/CIRCRESAHA.122.322389\n[27] S.L. Hyland, M. Faltys, M. HÃ¼ser, X. Lyu, T. Gumbsch, C. Esteban, C. Bock,\nM. Horn, M. Moor, B. Rieck, M. Zimmermann, D. Bodenham, K. Borgwardt,\nG. RÃ¤tsch, and T.M. Merz. 2020. Early prediction of circulatory failure in the\nintensive care unit using machine learning. Nature Medicine 26, 3 (2020), 364â€“373.\nhttps://doi.org/10.1038/s41591-020-0789-4\n[28] Y. Jin, C. Qin, Y. Huang, W. Zhao, and C. Liu. 2020. Multi-domain modeling\nof atrial fibrillation detection with twin attentional convolutional long short-\nterm memory neural networks. Knowledge-Based Systems 193 (2020), 105460.\nhttps://doi.org/10.1016/J.KNOSYS.2019.105460\n[29] A. Kansal, E. Chen, T. Jin, P. Rajpurkar, and D. Kim. 2025. Multimodal Clinical\nMonitoring in the Emergency Department (MC-MED). PhysioNet. https://doi.\norg/10.13026/jz99-4j81 Version 1.0.0.\n[30] S. Khurshid, S. Friedman, C. Reeder, P. Di Achille, N. Diamant, P. Singh, L.X.\nHarrington, X. Wang, M.A. Al-Alusi, G. Sarma, A.S. Foulkes, P.T. Ellinor, C.D. An-\nderson, J.E. Ho, A.A. Philippakis, P. Batra, and S.A. Lubitz. 2022. ECG-Based Deep\nLearning and Clinical Risk Factors to Predict Atrial Fibrillation. Circulation 145,\n2 (Jan 2022), 122â€“133. https://doi.org/10.1161/CIRCULATIONAHA.121.057480\n[31] D.O. Kleindorfer, A. Towfighi, S. Chaturvedi, K.M. Cockroft, J. Gutierrez, D.\nLombardi-Hill, H. Kamel, W.N. Kernan, S.J. Kittner, E.C. Leira, O. Lennon, J.F.\nMeschia, T.N. Nguyen, P.M. Pollak, P. Santangeli, A.Z. Sharrief, S.C. Smith Jr.,\nT.N. Turan, and L.S. Williams. 2021. 2021 Guideline for the Prevention of Stroke\nin Patients With Stroke and Transient Ischemic Attack: A Guideline From the\nAmerican Heart Association/American Stroke Association. Stroke 52, 7 (Jul 2021),\ne364â€“e467. https://doi.org/10.1161/STR.0000000000000375\n[32] D. Kumar, A. Peimankar, K. Sharma, H. DomÃ­nguez, S. Puthusserypady, and J.E.\nBardram. 2022. Deepaware: A hybrid deep learning and context-aware heuristics-\nbased model for atrial fibrillation detection. Computers in Methods and Programs\nin Biomedicine 221 (Jun 2022), 106899. https://doi.org/10.1016/j.cmpb.2022.106899\n[33] Y. Li, H. Godwin, M. Cecelja, K. Oâ€™Gallagher, A. Shah, A. Douiri, and P.\nChowienczyk. 2025. Prediction of Cardiovascular Disease Events From the\nPhotoplethysmograph Waveform. Journal of the American Heart Association 14,\n24 (Dec 2025), e040237. https://doi.org/10.1161/JAHA.124.040237\n[34] G.Y.H. Lip, A. Genaidy, G. Tran, P. Marroquin, C. Estes, and S. Sloop. 2022.\nImproving Stroke Risk Prediction in the General Population: A Comparative\nAssessment of Common Clinical Rules, a New Multimorbid Index, and Machine-\nLearning-Based Algorithms. Thrombosis and Haemostasis 122, 1 (Jan 2022), 142â€“\n150. https://doi.org/10.1055/a-1467-2993\n[35] S.A. Lubitz, A.Z. Faranesh, C. Selvaggi, S.J. Atlas, D.D. McManus, D.E. Singer, S.\nPagoto, M.V. McConnell, A. Pantelopoulos, and A.S. Foulkes. 2022. Detection\nof Atrial Fibrillation in a Large Population Using Wearable Devices: The Fitbit\nHeart Study. Circulation 146, 19 (Nov 2022), 1415â€“1424. https://doi.org/10.1161/\nCIRCULATIONAHA.122.060291\n[36] S.M. Lundberg and S.-I. Lee. 2017. A Unified Approach to Interpreting Model\nPredictions. In Advances in Neural Information Processing Systems, I. Guyon,\nU. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett\n(Eds.), Vol. 30. Curran Associates, Inc., Long Beach, CA, USA.\n[37] M.E. Matheny, I. Ricket, C.A. Goodrich, R.U. Shah, M.E. Stabler, A.M. Perkins,\nC. Dorn, J. Denton, B.E. Bray, R. Gouripeddi, J. Higgins, W.W. Chapman, T.A.\nMacKenzie, and J.R. Brown. 2021. Development of Electronic Health Record-Based\nPrediction Models for 30-Day Readmission Risk Among Patients Hospitalized\nfor Acute Myocardial Infarction. JAMA Network Open 4, 1 (Jan 2021), e2035782.\nhttps://doi.org/10.1001/jamanetworkopen.2020.35782\n[38] A.C. Miller, J. Futoma, S. Abbaspourazad, C. Heinze-Deml, S. Emrani, I. Shapiro,\nand G. Sapiro. 2025. A wearable-based aging clock associates with disease and\nbehavior. Nature Communications 16, 1 (Oct 2025), 9264. https://doi.org/10.1038/\ns41467-025-64275-4\n"}, {"page": 10, "text": "KDD â€™26, August 2026, Jeju, Korea\nLiu et al.\n[39] A. MincholÃ© and B. Rodriguez. 2019. Artificial intelligence for the electrocardio-\ngram. Nature Medicine 25, 1 (Jan 2019), 22â€“23. https://doi.org/10.1038/s41591-\n018-0306-1\n[40] B. Moody, G. Moody, M. Villarroel, G.D. Clifford, and I. Silva. 2020. MIMIC-III\nWaveform Database Matched Subset. PhysioNet. https://doi.org/10.13026/c2294b\nVersion 1.0.\n[41] M. Moor, O. Banerjee, Z.S.H. Abad, H.M. Krumholz, J. Leskovec, E.J. Topol, and P.\nRajpurkar. 2023. Foundation models for generalist medical artificial intelligence.\nNature 616, 7956 (Apr 2023), 259â€“265. https://doi.org/10.1038/s41586-023-05881-4\n[42] R. Mukkamala, G.S. Stergiou, and A.P. Avolio. 2022. Cuffless Blood Pressure\nMeasurement. Annual Review of Biomedical Engineering 24 (Jun 2022), 203â€“230.\nhttps://doi.org/10.1146/annurev-bioeng-110220-014644\n[43] G. Nie, Q. Zhao, G. Tang, Y. Li, and S. Hong. 2025. Artificial intelligence-derived\nphotoplethysmography age as a digital biomarker for cardiovascular health.\nCommunications Medicine 5, 1 (Nov 2025), 481. https://doi.org/10.1038/s43856-\n025-01188-9\n[44] T. Pereira, N. Tran, K. Gadhoumi, M.M. Pelter, D.H. Do, R.J. Lee, R. Colorado, K.\nMeisel, and X. Hu. 2020. Photoplethysmography based atrial fibrillation detection:\na review. NPJ Digital Medicine 3 (Jan 2020), 3. https://doi.org/10.1038/s41746-\n019-0207-9\n[45] G. Petmezas, K. Haris, L. Stefanopoulos, V. Kilintzis, A. Tzavelis, J.A. Rogers, A.K.\nKatsaggelos, and N. Maglaveras. 2021. Automated Atrial Fibrillation Detection\nusing a Hybrid CNN-LSTM Network on Imbalanced ECG Datasets. Biomedical\nSignal Processing and Control 63 (2021), 102194. https://doi.org/10.1016/J.BSPC.\n2020.102194\n[46] X. Qin, S. Yi, J. Rong, H. Lu, B. Ji, W. Zhang, R. Ding, L. Wu, and Z. Chen. 2023. Iden-\ntification of anoikis-related genes classification patterns and immune infiltration\ncharacterization in ischemic stroke based on machine learning. Frontiers in Aging\nNeuroscience 15 (Mar 2023), 1142163. https://doi.org/10.3389/fnagi.2023.1142163\n[47] G. Quer, J.M. Radin, M. Gadaleta, K. Baca-Motes, L. Ariniello, E. Ramos, V. Kheter-\npal, E.J. Topol, and S.R. Steinhubl. 2021. Wearable sensor data and self-reported\nsymptoms for COVID-19 detection. Nature Medicine 27, 1 (Jan 2021), 73â€“77.\nhttps://doi.org/10.1038/s41591-020-1123-x\n[48] S. Raghunath, A.E. Ulloa Cerna, L. Jing, D.P. vanMaanen, J. Stough, D.N. Hartzel,\nJ.B. Leader, H.L. Kirchner, M.C. Stumpe, A. Hafez, A. Nemani, T. Carbonati, K.W.\nJohnson, K. Young, C.W. Good, J.M. Pfeifer, A.A. Patel, B.P. Delisle, A. Alsaid,\nD. Beer, C.M. Haggerty, and B.K. Fornwalt. 2020. Prediction of mortality from\n12-lead electrocardiogram voltage data using a deep neural network. Nature\nMedicine 26, 6 (Jun 2020), 886â€“891. https://doi.org/10.1038/s41591-020-0870-z\n[49] L. Rasmy, Y. Xiang, Z. Xie, C. Tao, and D. Zhi. 2021. Med-BERT: pretrained\ncontextualized embeddings on large-scale structured electronic health records\nfor disease prediction. NPJ Digital Medicine 4, 1 (May 2021), 86. https://doi.org/\n10.1038/s41746-021-00455-y\n[50] A.H. Ribeiro, M.H. Ribeiro, G.M.M. PaixÃ£o, D.M. Oliveira, P.R. Gomes, J.A.\nCanazart, M.P.S. Ferreira, C.R. Andersson, P.W. Macfarlane, W. Meira Jr, T.B.\nSchÃ¶n, and A.L.P. Ribeiro. 2020. Author Correction: Automatic diagnosis of the\n12-lead ECG using a deep neural network. Nature Communications 11, 1 (May\n2020), 2227. https://doi.org/10.1038/s41467-020-16172-1\n[51] N. Sambasivan, S. Kapania, H. Highfill, D. Akrong, P.K. Paritosh, and L. Aroyo.\n2021. \"Everyone wants to do the model work, not the data work\": Data Cascades\nin High-Stakes AI. In CHI â€™21: CHI Conference on Human Factors in Computing\nSystems, Virtual Event / Yokohama, Japan, May 8-13, 2021. ACM, New York, NY,\nUSA, 39:1â€“39:15. https://doi.org/10.1145/3411764.3445518\n[52] L.I. Santos, M.O. Camargos, M.F.S.V. Dâ€™Angelo, J.B. Mendes, E.E.C. de Medeiros,\nA.L.S. GuimarÃ£es, and R.M. Palhares. 2022. Decision tree and artificial immune\nsystems for stroke prediction in imbalanced data. Expert Systems with Applications\n191 (2022), 116221. https://doi.org/10.1016/j.eswa.2021.116221\n[53] K.C. Siontis, P.A. Noseworthy, A. Arghami, S.A. Weston, Z.I. Attia, J.A. Crestanello,\nP.A. Friedman, A.M. Chamberlain, and B.J. Gersh. 2021. Use of Artificial Intel-\nligence Tools Across Different Clinical Settings: A Cautionary Tale. Circula-\ntion: Cardiovascular Quality and Outcomes 14, 9 (Sep 2021), e008153. https:\n//doi.org/10.1161/CIRCOUTCOMES.121.008153\n[54] M.S. Sirsat, E. FermÃ©, and J. CÃ¢mara. 2020. Machine Learning for Brain Stroke:\nA Review. Journal of Stroke and Cerebrovascular Diseases 29, 10 (2020), 105162.\nhttps://doi.org/10.1016/j.jstrokecerebrovasdis.2020.105162\n[55] N. Strodthoff, P. Wagner, T. Schaeffter, and W. Samek. 2021. Deep Learning for\nECG Analysis: Benchmarks and Insights from PTB-XL. IEEE Journal of Biomedical\nand Health Informatics 25, 5 (May 2021), 1519â€“1528. https://doi.org/10.1109/JBHI.\n2020.3022989\n[56] E. Svennberg, L. Friberg, V. Frykman, F. Al-Khalili, J. Engdahl, and M. Rosen-\nqvist. 2021. Clinical outcomes in systematic screening for atrial fibrillation\n(STROKESTOP): a multicentre, parallel group, unmasked, randomised controlled\ntrial. The Lancet 398, 10310 (Oct 2021), 1498â€“1506. https://doi.org/10.1016/S0140-\n6736(21)01637-8\n[57] A.J. Thirunavukarasu, D.S.J. Ting, K. Elangovan, L. Gutierrez, T.F. Tan, and D.S.W.\nTing. 2023. Large language models in medicine. Nature Medicine 29, 8 (Aug 2023),\n1930â€“1940. https://doi.org/10.1038/s41591-023-02448-8\n[58] H.A. Tzou, S.F. Lin, and P.S. Chen. 2021. Paroxysmal atrial fibrillation prediction\nbased on morphological variant P-wave analysis with wideband ECG and deep\nlearning. Computers in Methods and Programs in Biomedicine 211 (Nov 2021),\n106396. https://doi.org/10.1016/j.cmpb.2021.106396\n[59] US Preventive Services Task Force, K.W. Davidson, M.J. Barry, C.M. Mangione, M.\nCabana, A.B. Caughey, E.M. Davis, K.E. Donahue, C.A. Doubeni, J.W. Epling Jr.,\nM. Kubik, L. Li, G. Ogedegbe, L. Pbert, M. Silverstein, J. Stevermer, C.W. Tseng,\nand J.B. Wong. 2022. Screening for Atrial Fibrillation: US Preventive Services\nTask Force Recommendation Statement. JAMA 327, 4 (Jan 2022), 360â€“367. https:\n//doi.org/10.1001/jama.2021.23732\n[60] A. Vodencarevic, M. WeingÃ¤rtner, J.J. Caro, D. Ukalovic, M. Zimmermann-\nRittereiser, S. Schwab, and P. Kolominsky-Rabas. 2022. Prediction of Recur-\nrent Ischemic Stroke Using Registry Data and Machine Learning Methods:\nThe Erlangen Stroke Registry.\nStroke 53, 7 (Jul 2022), 2299â€“2306.\nhttps:\n//doi.org/10.1161/STROKEAHA.121.036557\n[61] C. Wang, B. Qi, M. Lin, Z. Zhang, M. Makihata, B. Liu, S. Zhou, Y.H. Huang,\nH. Hu, Y. Gu, Y. Chen, Y. Lei, T. Lee, S. Chien, K.I. Jang, E.B. Kistler, and S. Xu.\n2021. Continuous monitoring of deep-tissue haemodynamics with stretchable\nultrasonic phased arrays. Nature Biomedical Engineering 5, 7 (Jul 2021), 749â€“758.\nhttps://doi.org/10.1038/s41551-021-00763-4\n[62] W.H. Weng, S. Baur, M. Daswani, C. Chen, L. Harrell, S. Kakarmath, M. Jabara,\nB. Behsaz, C.Y. McLean, Y. Matias, G.S. Corrado, S. Shetty, S. Prabhakara, Y. Liu,\nG. Danaei, and D. Ardila. 2024. Predicting cardiovascular disease risk using\nphotoplethysmography and deep learning. PLOS Global Public Health 4, 6 (Jun\n2024), e0003204. https://doi.org/10.1371/journal.pgph.0003204\n[63] M. Wijnberge, B.F. Geerts, L. Hol, N. Lemmers, M.P. Mulder, P. Berge, J. Schenk,\nJ. van der Hoeven, J.J. Vos, G. Scheffer, et al. 2020. Effect of a machine learning-\nderived early warning system for intraoperative hypotension vs standard care\non depth and duration of hypotension during elective noncardiac surgery: the\nHYPE randomized clinical trial. JAMA 323, 11 (2020), 1052â€“1060. https://doi.org/\n10.1001/jama.2020.0592\n[64] E. Yang, A.E. Schutte, G. Stergiou, F.S. Wyss, Y. Commodore-Mensah, A. Odili, I.\nKronish, H.Y. Lee, and D. Shimbo. 2025. Cuffless Blood Pressure Measurement\nDevices-International Perspectives on Accuracy and Clinical Use: A Narrative\nReview. JAMA Cardiology 10, 6 (Jun 2025), 624â€“631. https://doi.org/10.1001/\njamacardio.2025.0662\n[65] P. Zhang, Y. Chen, F. Lin, S. Wu, X. Yang, and Q. Li. 2022. Semi-Supervised Learn-\ning for Automatic Atrial Fibrillation Detection in 24-Hour Holter Monitoring.\nIEEE Journal of Biomedical and Health Informatics 26, 8 (Aug 2022), 3791â€“3801.\nhttps://doi.org/10.1109/JBHI.2022.3173655\nA\nHemodynamic Feature Definitions\nTable 3 provides a comprehensive reference for the 17 hemody-\nnamic features extracted in this study. To facilitate interpretation,\nbiomarkers are categorized into four groups: (I) Time-Domain &\nMorphological features representing the structural characteristics\nof a single cardiac cycle; (II) Derivative & Normalized features re-\nflecting internal flow dynamics; (III) Short-Term Variability features\nquantifying autonomic regulation; and (IV) Relative Deviation fea-\ntures capturing the kinematic trajectory of pathological evolution\nrelative to the patientâ€™s baseline.\n"}, {"page": 11, "text": "In-Hospital Stroke Prediction from PPG\nKDD â€™26, August 2026, Jeju, Korea\nTable 3: Detailed Definitions and Physiological Significance of Hemodynamic Features. Features are derived from the raw PPG\nsignal, Velocity Plethysmogram (VPG), and Acceleration Plethysmogram (APG).\nSymbol\nDefinition\nPhysiological Significance\nI. Time-Domain & Morphological Features (Structural Basis)\nğ‘‡sp\nTime to Systolic Peak: Time elapsed from pulse\nonset to the systolic peak.\nReflects velocity of blood ejection and wave transmission. Related to arterial compli-\nance; typically shortens with stiffening.\nSI\nStiffness Index: Ratio of pulse amplitude to systolic\ntime (ğ‘‡sys).\nRepresents average slope of systolic upstroke. Higher index indicates increased\narterial stiffness (vascular aging proxy).\nğ´off\nOffset Amplitude: Signal amplitude at the pulse offset\npoint.\nReflects vascular recoil at end-diastole, correlating with vessel elasticity and venous\nreturn.\nğ‘‡sys/ğ‘‡dia\nSystolic-Diastolic Ratio: Ratio of systolic duration to\ndiastolic duration.\nDescribes temporal balance of cardiac cycle. Imbalances indicate autonomic dysfunc-\ntion or abnormal resistance.\nII. Derivative & Normalized Features (Internal Dynamics)\nğ‘‡ğ‘¢ğ‘‡ğ‘ğ‘–\nNorm. Time to VPG Peak: Time to max velocity\n(u-wave) normalized by pulse interval (ğ‘‡ğ‘ğ‘–).\nReflects relative duration of rapid ejection phase. Associated with vascular impedance\nand flow inertia.\nğ‘‡ğ‘ğ‘‡ğ‘ğ‘–\nNorm. Time to APG b-wave: Time to b-wave in 2nd\nderivative normalized by ğ‘‡ğ‘ğ‘–.\nSensitive to vascular aging and augmentation of peripheral reflection waves (early\nhardening).\nğ‘‡v\nTime to VPG Valley: Time to VPG inflection point\n(v-wave) post-systole.\nCorrelates with timing of reflected wave return; reflects coupling of central and\nperipheral hemodynamics.\nğ‘‡ğ‘¢Ta,Tpi\nVPG-APG Peak Delay Ratio: Temporal difference\nbetween peak velocity and acceleration.\nDescribes decoupling between peak velocity and acceleration. Sensitive marker for\nneurovascular mismatch.\nIII. Short-Term Variability Features (Autonomic Regulation)\nğ¶ğ‘‰ğ‘‡,ğ‘ğ‘–\nPulse Interval Variability: Coefficient of Variation\n(CV) of the pulse interval.\nSurrogate for ultra-short-term HRV. Reductions indicate autonomic imbalance and\nloss of vagal tone.\nğ¶ğ‘‰PA\nAmplitude Variability: Coefficient of Variation of\npulse amplitudes.\nReflects sympathetic capacity to modulate peripheral tone. Reduced variability sug-\ngests rigid regulation.\nIV. Relative Deviation Features (Pathological Evolution)\nğ‘‡sp,Rel\nRelative ğ‘‡ğ‘ ğ‘: Deviation of current ğ‘‡ğ‘ ğ‘from individual\nbaseline.\nCaptures progressive drift in wave transmission time, robust to inter-subject baseline\nvariability.\nğ´sp,Rel\nRelative Systolic Amplitude: Deviation of systolic\npeak magnitude.\nHighly sensitive to acute changes in vascular compliance and stroke volume prior to\nevent.\nğ‘†ğ¼Rel\nRelative Stiffness Index: Deviation of the Stiffness\nIndex from baseline.\nTracks trajectory of arterial hardening (compliance degradation) leading up to stroke.\nğ·ğ‘†ğ¼Rel\nRelative Dynamic Stability: Deviation of the\nDynamic Stability Index from baseline.\nQuantifies shift in morphological proportions. Indicator of \"loss of homeostasis\" in\nhemodynamic system.\nğ‘‡c,Rel\nRelative APG c-wave: Shift in the late-systolic\nc-wave timing.\nRelates to late-systolic recoil; reveals acute abnormalities in arterial wall elasticity.\nğ´off,Rel\nRelative Offset Amp: Deviation in end-diastolic\namplitude.\nAssociated with shifts in venous return and diastolic regulation efficiency.\nğ´on,Rel\nRelative Onset Amp: Deviation in pulse onset nadir.\nSensitive to perfusion abnormalities in peripheral microcirculation.\n"}]}