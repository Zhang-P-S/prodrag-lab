{"doc_id": "arxiv:2601.12868", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2601.12868.pdf", "meta": {"doc_id": "arxiv:2601.12868", "source": "arxiv", "arxiv_id": "2601.12868", "title": "Race, Ethnicity and Their Implication on Bias in Large Language Models", "authors": ["Shiyue Hu", "Ruizhe Li", "Yanjun Gao"], "published": "2026-01-19T09:24:24Z", "updated": "2026-01-19T09:24:24Z", "summary": "Large language models (LLMs) increasingly operate in high-stakes settings including healthcare and medicine, where demographic attributes such as race and ethnicity may be explicitly stated or implicitly inferred from text. However, existing studies primarily document outcome-level disparities, offering limited insight into internal mechanisms underlying these effects. We present a mechanistic study of how race and ethnicity are represented and operationalized within LLMs. Using two publicly available datasets spanning toxicity-related generation and clinical narrative understanding tasks, we analyze three open-source models with a reproducible interpretability pipeline combining probing, neuron-level attribution, and targeted intervention. We find that demographic information is distributed across internal units with substantial cross-model variation. Although some units encode sensitive or stereotype-related associations from pretraining, identical demographic cues can induce qualitatively different behaviors. Interventions suppressing such neurons reduce bias but leave substantial residual effects, suggesting behavioral rather than representational change and motivating more systematic mitigation.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2601.12868v1", "url_pdf": "https://arxiv.org/pdf/2601.12868.pdf", "meta_path": "data/raw/arxiv/meta/2601.12868.json", "sha256": "cc8aa59c1128edabc221c2b5d42d6632196779c21151a632149b5fc9814c90a1", "status": "ok", "fetched_at": "2026-02-18T02:21:11.851689+00:00"}, "pages": [{"page": 1, "text": "Race, Ethnicity and Their Implication on Bias in Large Language Models\nShiyue Hu1,2\nRuizhe Li3,*\nYanjun Gao1,*\n1University of Colorado Anschutz\n2University of Colorado Boulder\n3University of Aberdeen\nshiyue.hu@colorado.edu, ruizhe.li@abdn.ac.uk, yanjun.gao@cuanschutz.edu\n*Co-senior authors\nAbstract\nLarge language models (LLMs) increasingly\noperate\nin\nhigh-stakes\nsettings\nincluding\nhealthcare and medicine, where demographic\nattributes such as race and ethnicity may be\nexplicitly stated or implicitly inferred from\ntext.\nHowever, existing studies primarily\ndocument outcome-level disparities, offering\nlimited\ninsight\ninto\ninternal\nmechanisms\nunderlying these effects.\nWe present a\nmechanistic study of how race and ethnicity\nare represented and operationalized within\nLLMs. Using two publicly available datasets\nspanning\ntoxicity-related\ngeneration\nand\nclinical narrative understanding tasks,\nwe\nanalyze three open-source models with a re-\nproducible interpretability pipeline combining\nprobing, neuron-level attribution, and targeted\nintervention. We find that demographic infor-\nmation is distributed across internal units with\nsubstantial cross-model variation.\nAlthough\nsome units encode sensitive or stereotype-\nrelated associations from pretraining, identical\ndemographic cues can induce qualitatively\ndifferent behaviors. Interventions suppressing\nsuch neurons reduce bias but leave substantial\nresidual effects, suggesting behavioral rather\nthan representational change and motivating\nmore systematic mitigation.\n1\nIntroduction\nLarge language models (LLMs) are increasingly\nused in high-stakes domains such as healthcare,\nwhere demographic attributes (e.g., race, ethnicity,\ngender) may be explicitly stated or implicitly in-\nferred from text. Prior work shows that LLMs can\ncondition their outputs on demographic informa-\ntion even when it is not task-relevant (Zack et al.,\n2024; Kim et al., 2023; Fraser and Kiritchenko,\n2024; Zhao et al., 2025), therefore can induce mis-\nattribution on model output with undesirable or bi-\nased behavior (Demchak et al., 2024; Levartovsky\net al., 2025; Zack et al., 2024).\nMost prior studies on demographic bias focus\non outcome-level effects, evaluating disparities in\ngenerated responses, accuracy, calibration, or tox-\nicity scores across demographic groups (Tan and\nLee, 2025; Hartvigsen et al., 2022; Guan et al.,\n2025; Wang et al., 2025).\nWhile these analy-\nses are essential for documenting harm, they treat\nLLMs as black boxes, offering limited insight\ninto whether demographic attributes are encoded\nas high-level semantic features, task-relevant rep-\nresentations, or spurious shortcuts during predic-\ntion. In parallel, recent works in mechanistic in-\nterpretability demonstrated how LLMs encode de-\nmographic information and manipulated internal\nLLMs‚Äô states to ensure fairness (Yu and Anani-\nadou, 2025; Ahsan and Wallace, 2025; Karvonen\nand Marks, 2025), yet these tools have rarely been\napplied to demographic bias in a systematic and\ntask-diverse manner.\nA central challenge is that demographic at-\ntributes interact with language in complex ways.\nIn many real-world settings, demographic infor-\nmation may be explicitly stated (e.g., ‚Äúa Black\npatient,‚Äù ‚Äúa Hispanic speaker‚Äù) or implicitly con-\nveyed through linguistic, cultural, or geographical\ncues, i.e. the ‚Äúproxy‚Äù cues. Moreover, the same\ndemographic signal can have qualitatively differ-\nent effects depending on the task: it may alter pre-\ndicted medical risk in a clinical scenario, while si-\nmultaneously modulating perceived toxicity, cred-\nibility, or intent in open-ended generation. Exist-\ning evaluation typically isolate a single task or do-\nmain (Hartvigsen et al., 2022; Zack et al., 2024;\nLevartovsky et al., 2025), making it diÔ¨Äicult to as-\nsess whether demographic sensitivity reflects gen-\neral representational mechanisms or task-specific\nheuristics.\nIn this work, we investigate how demographic\nattributes influence LLM behavior, with a focus\non mechanistic explanations rather than surface-\nlevel disparities. We examine race and ethnicity\n1\narXiv:2601.12868v1  [cs.CL]  19 Jan 2026\n"}, {"page": 2, "text": "as commonly occurring coarse-grained categories\n(e.g. White, Black, Asian, Hispanic and Latino)\nas they appear in the studied datasets, rather than\nattempting to model the full sociological complex-\nity of these constructs. Using two publicly avail-\nable datasets, we study: 1) toxicity-related gen-\neration tasks (Hartvigsen et al., 2022), where the\nsame attributes may alter the likelihood, tone, or\nframing of model outputs, and 2) clinical narrative\ntasks (Bear Don‚Äôt Walk IV et al., 2024), where the\nsame attributes appear through explicit or indirect\ncues in medical text and modulate model behavior\ndespite identical clinical evidence.\nWe adopt a mechanistic interpretability (MI)\nframework to study how lexical cues of race and\nethnicity are encoded and propagated within three\nopen-source LLMs that are widely used: Qwen2.5-\n7B (Qwen Team, 2024), Mistral-7B (Jiang et al.,\n2023), and Llama-3.1-8B (Grattafiori et al., 2024).\nOur contributions are threefold:\n‚Ä¢ a reproducible MI pipeline that combines multi-\nclass probing, neuron-level attribution, and tar-\ngeted intervention to identify internal units asso-\nciated with demographic attributes and to exam-\nine their functional relevance across tasks. The\nproposed framework is applicable to other social\nvariables beyond race and ethnicity.\n‚Ä¢ a fine-grained characterization of race and eth-\nnicity representations across LLMs, revealing\nthe distributed nature of demographic informa-\ntion and model-specific emphasis on semantic\nfacets such as geography, language, culture, or\nhistorical context.\n‚Ä¢ a mechanistic analysis of how demographic rep-\nresentation influences model behaviors.\nAl-\nthough internal features encode sensitive or\nharmful stereotype-related concepts present in\npretraining data, these representations are un-\nevenly activated by direct and indirect demo-\ngraphic cues.\nOur findings show that while race- and ethnicity-\nassociated representations can be identified and an-\nalyzed at the neuron level, their associations with\nbiased model behavior persist even when highly ac-\ntive neurons are surpressed. This indicates that bi-\nased behavior in LLMs cannot be fully explained\nor controlled by manipulating a small set of identi-\nfiable neurons alone.\nClinical Note: {Text}\nInferred Race or Ethnicity:\nAsian\nùëä!\"#$\nùëä%&\nSwiGLU\nMLP\nùëä!\"#$\nActivation Scores\nŒ£\nNeuron vector ùë£!\n‚Ñé'\nMLP\noutput\nActivation Scores\nHigh ùëé%(ùë•)\nfor target race\nLogit Lens Japanese, ‚ΩáÊú¨, China, Nguyen\n‰∫öÊ¥≤, „Ç¢„Ç∏„Ç¢, Shanghai\nIntervention\nSuppressed Activations\nùë£%\nWhite\nAttention\nFigure 1: With MLP, we locate neurons relevant to\nrace information and inspect them via Logit Lens. For\nthe higher activation score for target race, we adjust its\nvalue to steer model‚Äôs behavior.\n2\nRelated Work\nMechanistic Interpretability of Bias in LLMs.\nRecent works in mechanistic interpretability have\nbegun to locate where demographic information\nis encoded. Our approach of using probe-based\nneuron localization aligns with emerging research\nin this space. Yu and Ananiadou (2025) utilized\nneuron editing to understand and mitigate gender\nbias, identifying specific ‚Äúgender neurons‚Äù within\nthe MLP layers. In the medical domain, Ahsan\net al. (2025) investigated the mechanisms of demo-\ngraphic bias specifically for healthcare tasks, sug-\ngesting that certain internal representations are dis-\nproportionately sensitive to racial identifiers. More\nrecently, Ahsan and Wallace (2025) explored the\nuse of Sparse Autoencoders (SAEs) to reveal clin-\nical racial biases. Our work extends these findings\nby demonstrating that race-specific neurons are not\nonly present in general datasets but are consistently\nactivated and influential on domain-specific text.\nInternal Bias Mitigation and Steering within\nLLMs. Beyond identification, recent work focuses\non manipulating internal model states to ensure\nfairness. Zhou et al. (2024) proposed the UniB-\nias framework, which mitigates bias by manipu-\nlating attention heads and MLP components. For\nreal-time applications, Li et al. (2025) introduced\nFairSteer, a dynamic activation steering method\nthat adjusts model behavior during inference. Kar-\nvonen and Marks (2025) further demonstrated that\ninterpretability-based interventions can improve\nfairness more robustly than traditional fine-tuning\nin realistic settings. Our methodology contributes\nto this line of work by providing a targeted interven-\ntion strategy, specifically sign-flipping and ampli-\nfication, to suppress biased pathways. This builds\nupon the ‚Äúcontext-aware‚Äù fairness frameworks sug-\n2\n"}, {"page": 3, "text": "gested by Nadeem et al. (2025), ensuring that mit-\nigation is grounded in the semantic understanding\nof the racial directions we extract.\nRacial Bias in Clinical LLMs.\nExtensive re-\nsearch has documented that LLMs inherit and prop-\nagate racial biases when applied to clinical deci-\nsion support. Zhang et al. (2023) demonstrated\nthat ChatGPT exhibits disparate treatment recom-\nmendations for acute coronary syndrome based\non racial and gender cues. Similarly, Zack et al.\n(2024) evaluated GPT-4, finding that model fre-\nquently perpetuates harmful stereotypes that could\nlead to inequitable health outcomes. Poulain et al.\n(2024) further expanded this analysis across var-\nious clinical decision-support tasks, highlighting\nthat bias patterns are not idiosyncratic but system-\natic across model families.\nWhile these studies\nestablish the existence of bias, they largely treat\nmodel as a black box. Our work seeks to uncover\nthe internal mechanisms driving these disparate\noutputs.\n3\nBackground\nMLP Layers and Neuron Activation.\nMod-\nern Transformer-based LLMs process information\nthrough a residual stream. In this framework, the\nresidual stream acts as a communication channel,\nwhile MLP layers function as key-value memories\nthat store and inject factual associations into the\nstream (Geva et al., 2021a). Contemporary models\nlike Llama 3.1, Mistral, and Qwen 2.5 utilize the\nSwiGLU gated architecture (Shazeer, 2020). The\noutput of an MLP block with input x is defined as:\nMLP(x) =\n(\nSwiGLU(xWgate) ‚äô(xWup)\n)\nWdown\n(1)\nwhere ‚äôis the element-wise product. We define\nan individual neuron j as the j-th element of the\nintermediate gated state. The total MLP output is\nthe sum of these neurons‚Äô contributions:\nMLP(x) =\ndmlp\n‚àë\nj=1\naj(x) ¬∑ vj\n(2)\nwhere aj(x) is the activation score (the product of\nthe gate and up-projections) and vj is the j-th row\nof Wdown. Our method specifically probes these\noutput vectors vj to locate racial information.\nLogit Lens.\nTo interpret high-dimensional vec-\ntors in residual stream or neuron output vectors\nvj, we use Logit Lens (nostalgebraist, 2020). This\ntechnique projects a vector h directly into vocabu-\nlary space using model‚Äôs unembedding matrix WU:\nlogits = hWU. By inspecting top-ranked tokens\nin the resulting distribution, we can decode the se-\nmantic concepts encoded within specific neurons.\n4\nMethodology\nWe propose a mechanistic interpretability frame-\nwork to determine where and how race information\nis encoded within LLMs. Our approach progresses\nfrom identifying global race directions via multi-\nclass probing to identifying the specific neurons re-\nsponsible for these encodings.\n4.1\nLocating Race Directions via Multi-Class\nProbing\nTo extract race/ethnicity representations, we train\nlinear probes WRace to classify race/ethnicity cat-\negory membership for each model. The probe is\ntrained on the final-layer residual stream ¬ØhL‚àí1, av-\neraged across all token positions:\nP(race = c | ¬ØhL‚àí1) = softmax(W ‚ä§\nRace¬ØhL‚àí1 + b)c\n(3)\nwhere WRace ‚ààRd√ó|C| is the learned probe ma-\ntrix, b is bias vector, and C denotes the set of\nrace/ethnicity categories.\nEach column wc of\nWRace represents race direction for group c in\nmodel‚Äôs representation space.\n4.2\nFrom Race Directions to Neurons\nHaving identified the global race directions wc, we\nlocate the MLP neurons that write to these direc-\ntions, motivated by prior work showing MLPs act\nas key‚Äìvalue memories (Geva et al., 2021b).\nInterpreting the Probe Direction. We first ver-\nify that our learned directions wc capture mean-\ningful racial semantics.\nUsing Logit Lens, we\nproject each direction into vocabulary space via the\nmodel‚Äôs unembedding matrix WU:\nzprobe = WUwc\n(4)\nTop-k tokens (k = 20) with the highest values in\nzprobe serve as a semantic fingerprint for each racial\ngroup.\nIdentifying Candidate Neurons. To locate neu-\nrons that write to race direction, we compute the\ncosine similarity between each MLP neuron‚Äôs out-\nput vector vl\nj at layer l and the probe direction wc:\nScore(l, j) =\nwc ¬∑ vl\nj\n‚à•wc‚à•‚à•vl\nj‚à•\n(5)\nAll neurons in the final four MLP layers are ranked\nby this score, and the top 20 candidates are selected.\n3\n"}, {"page": 4, "text": "Each candidate is selected by projecting its output\nvector into vocabulary space and inspecting top-20\ntokens. Neurons are retained only if their tokens\nshow clear alignment with the target racial group.\n4.3\nValidating Neurons via Activation\nAnalysis and Intervention\nTo confirm that identified neurons encode mean-\ningful racial information and causally influence\nmodel behavior, we design a two-stage validation\npipeline.\nActivation Analysis. We measure how strongly\neach neuron group activates across different in-\nputs. For a given input text, we extract the acti-\nvation score of each candidate neuron during the\nforward pass. For ToxiGen, we average activations\nacross all token positions; for C-REACT, where the\nmodel must produce a classification, we extract ac-\ntivations at the last input token before generation.\nWe then compare activation patterns across racial\ngroups: if neurons identified for a particular race\nshow higher activation scores when processing text\nabout that group compared to other groups, this\nprovides evidence that these neurons selectively re-\nspond to race-related content.\nTargeted Intervention. To test whether identified\nneurons causally influence model outputs, we ma-\nnipulate their activations during inference. We im-\nplement this using PyTorch forward hooks on the\nMLP Wdown. During the forward pass, we inter-\ncept the activation score of each targeted neuron\nand force it into a strongly negative range. Specif-\nically, we multiply positive activations by a neg-\native factor (e.g., -5) and amplify negative activa-\ntions by a positive factor (e.g., 5). This makes the\nneuron‚Äôs contribution subtractive rather than addi-\ntive. This modified signal propagates through the\nremaining layers, allowing us to measure whether\nsteering specific neurons changes model behavior\nand final outputs.\n5\nData and Models\nDatasets. We evaluate our framework on two do-\nmains to test the generalizability of race encoding\nmechanisms across different contexts.\nToxiGen\n(Hartvigsen et al., 2022) is a large-scale machine-\ngenerated dataset of toxic statements about minor-\nity groups. We use the annotated subset containing\n9.9k samples across 13 target groups. Each sample\nhas a statement for a specific group (e.g., ‚Äúasians\nare trying to take over the world with their karate\nskills‚Äù). From all groups, we consolidate related\ncategories into five racial categories: Asian (asian,\nchinese), Black (black), Latino (latino, mexican),\nNative American (native_american), and Middle\nEastern (middle_east, jewish, muslim).\nWe ex-\nclude non-racial categories (women, lgbtq, men-\ntal_dis, physical_dis).\nC-REACT (Contextual-\nized Race and Ethnicity Annotations for Clini-\ncal Text (Bear Don‚Äôt Walk IV et al., 2024)) pro-\nvides race and ethnicity annotations for 17,281 sen-\ntences drawn from clinical notes in the MIMIC-\nIII database. C-REACT contains real clinical text\nwhere race information appears in two forms: di-\nrect mentions that explicitly state race (e.g., ‚ÄúPt\nis 42 yo AA female‚Äù) and indirect mentions that\nimply race through associated attributes such as\nspoken language or country of origin (e.g., ‚ÄúPt re-\nquired a Spanish interpreter‚Äù, ‚ÄúPt is recently im-\nmigrated from France‚Äù). C-REACT provides five\nracial categories: White, Black/African American\n(Black/AA), Asian, Native American or Alaska Na-\ntive, and Native Hawaiian or Other Pacific Islander.\nHowever, the dataset is highly imbalanced: zero\npatients labeled as Native Hawaiian or Other Pa-\ncific Islander were found, and only three patients\nlabeled as Native American or Alaska Native. We\ntherefore use three racial categories with suÔ¨Äicient\nrepresentation: White, Black/AA, and Asian.\nModels. We study three instruction-tuned LLMs\nof comparable scale from different geographic\nand cultural training contexts: Llama-3.1-8B-IT\n(Grattafiori et al., 2024) (US), Mistral-7B-IT-v0.3\n(Jiang et al., 2023) (France), and Qwen2.5-7B-IT\n(Qwen Team, 2024) (China).\nThis selection al-\nlows us to investigate whether models trained on\ndata from different linguistic and cultural contexts\nencode racial information differently, given that\nconceptions of race and ethnicity vary across so-\ncieties.\n6\nExperiments and Results\n6.1\nToxiGen\nTable 1 lists top tokens projected by each race direc-\ntion. Across models, probes reach similar perfor-\nmance on ToxiGen (around 75% accuracy/macro-\nF1; Appendix A.1).\nThese tokens capture vari-\nous facets of racial encoding, including geogra-\nphy, religion, demographic labels, and cultural\nterms.\nAcross all three models, the learned di-\nrections identify tokens that align closely with\nthe target race/ethnicity categories. This confirms\n4\n"}, {"page": 5, "text": "Model\nGroup\nTop tokens projected by probe\nQwen2.5-7B\nAsian\nAsian, ‰∫öÊ¥≤, Chinese, CJK, ‰∏ú‰∫ö\nLatino\nMex, Mexico\nNative American\nnatives, native, Native, indigenous\nMistral-7B\nAsian\nChinese, Asian, China, Korean, Taiwan\nBlack\nblack, African, Black\nLatino\nMexico, Salvador, Colombia, Chile, Mexican\nNative American\nIndians, trib, Native, tribes, Indian\nMiddle Eastern\nIslamic, Palestinian, Muhammad, Muslim, Israel\nLlama-3.1-8B\nAsian\nAsian, Mandarin, CJK, asian, china\nBlack\nBlack, _black, -black, .black, Èªë\nLatino\nMundo, _BORDER\nNative American\nNative, natives, Indians, indigenous, tribes\nMiddle Eastern\nIslamic, Middle, ISIL, Christian\nTable 1: Top tokens by race group across models (ToxiGen).\nWARNING: Some tokens reflect harmful stereotypes. Full\nresults in Appendix A.2. Translations: ‰∫öÊ¥≤(Asia), ‰∏ú‰∫ö(East Asia),\nÈªë(Black).\nModel\nGroup\nNeuron\nTop tokens\nQwen2.5-7B\nAsian\nMLP.v28\n13406\nJapanese, Êó•Êú¨, Japan, Tokyo\nMLP.v25\n15029\nChinese, China, ‰∏≠ÂõΩ, Asian\nBlack\nMLP.v27\n2240\nblack, Èªë, Black, ÈªëËâ≤\nLatino\nMLP.v28\n4781\nLatin, Êãâ‰∏Å, latino, Latina\nMLP.v27\n18125\nSpanish, Hispanic, Chile, Mexican\nNative Am.\nMLP.v25\n3458\nnative, Native, indigenous\nMLP.v25\n11197\ncolonial, colon, colony, imperial\nMiddle Eastern\nMLP.v28\n9988\nIsrael, Jerusalem, Hebrew, Zion\nMLP.v26\n3012\nJew, Jewish, Judaism, Rabbi\nMistral-7B\nAsian\nMLP.v32\n4453\nJapanese, Korean, Taiwan, Asian\nBlack\nMLP.v32\n5923\nBlack, black, Negro, African\nMLP.v30\n12572\nBlack, blacks, Èªë, dark\nNative Am.\nMLP.v31\n3440\ncolonial, colon\nMLP.v29\n12205\nnative, ind, igenous\nMiddle Eastern\nMLP.v32\n5573\nJewish, Jews, Jerusalem, Israel\nMLP.v28\n147\nMediterranean, Turkish, Egyptian, Turkey\nLlama-3.1-8B\nAsian\nMLP.v32\n5691\nChinese, China, Beijing, ‰∏≠ÂõΩ\nMLP.v31\n14299\nLi, yuan, Dong, Huang, Wang\nBlack\nMLP.v30\n7195\nJamaica, Caribbean, Trinidad, Jazz\nMLP.v29\n13826\nAfrican, Afro, negro, blacks\nLatino\nMLP.v32\n9242\nSpanish, Hispanic, Mexican, Argentine\nNative Am.\nMLP.v32\n6893\ncolon, colonial, colonization, colonies\nMLP.v31\n1186\nnative, Native, -native, natives\nMiddle Eastern\nMLP.v30\n11051\nArab, Arabic, Saudi, Muslim\nMLP.v29\n2750\nIslamic, Islam, mosques, Muhammad\nTable 2: Top race-encoding neurons identified via cosine\nsimilarity with probe directions. WARNING: Some tokens\nreflect harmful stereotypes. Full results in Appendix A.3.\nTranslations: Êó•Êú¨(Japan), ‰∏≠ÂõΩ(China), Èªë(Black), ÈªëËâ≤(Black color), Êãâ\n‰∏Å(Latin).\nthat LLMs store clear racial representations within\ntheir residual streams.\nTable 2 presents race encoding neurons iden-\ntified within the final four MLP layers.\nThese\nneurons reveal that LLMs decompose racial con-\ncepts into distinct semantic dimensions.\nSome\nneurons encode broad demographic terminology\nthat directly names groups, such as Mistral-7B‚Äôs\nMLP.v32\n5923 (Black, black, African) and Asian neu-\nrons across all models (Asian, Chinese, Japanese),\nfunctioning as explicit demographic classifiers.\nOthers encode race through associated attributes:\nLlama-3.1-8B‚Äôs MLP.v32\n5691 links Asian identity to\ngeographic terms (Chinese, China, Beijing), while\nMLP.v31\n14299 captures Chinese last names (Li, yuan,\nDong, Huang, Wang); Middle Eastern neurons\nModel\nGroup\nDirect\nIndirect\nQwen2.5-7B\nWhite\nÁôΩ\nRussian, ‰øÑÁΩóÊñØ, Russia\nAsian\nAsian, Asia, Asians, ‰∫öÊ¥≤\nChinese, Xia, Tibetan, China\nBlack/AA\nAfrican, ÈùûÊ¥≤, Africa, black\nHait, Haiti, Tropical, ÁÉ≠Â∏¶\nMistral-7B\nWhite\nMoscow, Russian, Ukrain, Polish\nAsian\nAsian, Taiwan, Japanese, Malays\nKorea, Korean, Asian, Vietnam\nBlack/AA\nAfrican, blacks, Negro, slavery\nCaribbean, Cuba, Nigeria, Brazil\nLlama-3.1-8B\nWhite\nRussia, Kremlin, Putin, Moscow\nAsian\nAsian, Indonesian, Asia, Taiwanese\nCambodia, Chinese, wang, Buddhism\nBlack/AA\nblack, African, Afro, negro\nHaiti, Caribbean, Dominican, Bahamas\nTable\n3:\nComparison\nof\ntop\ntokens\nfrom\ndirect\n(race/ethnicity ) vs.\nindirect (language/country) men-\ntions in C-REACT. WARNING: Some tokens reflect\nharmful stereotypes. Full results in Appendix A.4. Transla-\ntions: ÁôΩ(white), ‰øÑÁΩóÊñØ(Russia), ÈùûÊ¥≤(Africa), ÁÉ≠Â∏¶(tropical).\nproject to religious and regional identifiers (Jew-\nish, Judaism, Islam, Jerusalem, Saudi). We also\nobserve neurons that encode historically harmful\nassociations. Native American neurons across all\nthree models project to colonial terminology (colo-\nnial, colony, colonization), and neurons for Black\nidentity recover offensive racial terms that persist\nacross models despite different training corpora.\nNeuron Activation Analysis.\nTo verify that\nidentified neurons selectively respond to their tar-\nget racial groups, we measure mean activation\nvalues when processing test samples from each\ngroup. Figure 2 displays these activation patterns\nas heatmaps, where diagonal cells represent neu-\nrons processing their target group. The results con-\nfirm that most race encoding neurons activate more\nstrongly for their target group than for others. This\nis most pronounced for Latino and Middle Eastern\nneurons: Llama-3.1-8B achieves activation values\nof 0.83 and 0.90 respectively, while Qwen2.5-7B\nreaches 0.71 and 1.23. Black neurons also demon-\nstrate consistent selectivity across all three mod-\nels, with positive diagonal values compared to near\nzero or negative off diagonal values. Asian and Na-\ntive American neurons exhibit weaker selectivity,\nlikely reflecting sparser representation in training\ndata. Nevertheless, the overall diagonal pattern val-\nidates our neuron identification method: neurons\nselected via probe direction alignment do prefer-\nentially activate for their target groups, confirming\ntheir role in demographic encoding.\n6.2\nC-REACT\nWe train separate probes on direct and indirect\nmentions to evaluate whether each type captures\ndistinct representations.\nDirect-mention probes\nachieve higher accuracy and comparable F1 to indi-\nrect probes (Appendix A.1). This likely reflects the\nfact that direct cues are explicit and indirect data\nare sparser.\nTable 3 compares tokens projected\nby each probe type.\nDirect and indirect probes\n5\n"}, {"page": 6, "text": "Asian\nBlack\nNative Am.\nMiddle East.\nInput Race Group\nAsian\nBlack\nNative Am.\nMiddle East.\nNeuron Group\n-0.18\n-0.10\n-0.10\n-0.20\n-0.08\n0.12\n-0.01\n-0.08\n-0.09\n-0.06\n0.16\n-0.09\n-0.11\n-0.09\n-0.08\n0.15\nMistral-7B\nAsian\nBlack\nLatino\nNative Am.\nMiddle East.\nInput Race Group\nAsian\nBlack\nLatino\nNative Am.\nMiddle East.\n0.05\n-0.18\n-0.16\n-0.19\n-0.15\n0.01\n0.18\n0.02\n-0.00\n-0.02\n0.08\n0.09\n0.83\n0.17\n0.05\n-0.14\n-0.10\n-0.12\n-0.05\n-0.12\n0.06\n0.06\n0.04\n0.07\n0.90\nLlama-3.1-8B\nAsian\nBlack\nLatino\nNative Am.\nMiddle East.\nInput Race Group\nAsian\nBlack\nLatino\nNative Am.\nMiddle East.\n-0.08\n-0.67\n-0.58\n-0.32\n-0.30\n0.01\n0.05\n0.03\n0.06\n0.05\n0.18\n0.15\n0.71\n0.46\n0.02\n-0.09\n-0.02\n-0.09\n-0.04\n-0.12\n-0.22\n-0.07\n-0.19\n0.12\n1.23\nQwen2.5-7B\n0.20\n0.15\n0.10\n0.05\n0.00\n0.05\n0.10\n0.15\n0.0\n0.2\n0.4\n0.6\n0.8\n0.50\n0.25\n0.00\n0.25\n0.50\n0.75\n1.00\nFigure 2: Mean activation values of race encoding neurons when processing text from each racial group (ToxiGen). Diagonal\ncells represent neurons processing their target group. Higher values (red) indicate stronger activation; lower values (blue) indi-\ncate weak, negative activations.\ncapture semantically distinct representations. Di-\nrect probes recover general racial and ethnic termi-\nnology (Asian, African, black, ÁôΩ), while indirect\nprobes recover specific countries and regions asso-\nciated with each group. For instance, the White in-\ndirect probe projects strongly to Russia and Eastern\nEuropean terms across all models, reflecting the\ndataset composition where Russian is the most fre-\nquent language among White patients. Similarly,\nBlack or African American indirect probes recover\nCaribbean and African nations (Haiti, Caribbean,\nNigeria). This divergence confirms that LLMs en-\ncode race through multiple pathways: explicit de-\nmographic labels and associated geographic or lin-\nguistic attributes.\nModel\nGroup\nNeuron\nTop tokens\nQwen2.5-7B\nWhite\nMLP.v28\n16880\nËã±ÂõΩ, Dutch, French, Italian\nMLP.v27\n17660\nGerman, Germany, EU, euro\nAsian\nMLP.v27\n6943\nAsian, Asia, Chinese, Indian\nMLP.v27\n217\nAsian, ‰∫öÊ¥≤, Asia, „Ç¢„Ç∏„Ç¢\nBlack/AA\nMLP.v28\n11088\nracist, racism, Harlem, segregation\nMLP.v27\n2240\nblack, Èªë, Black, ÈªëËâ≤\nMistral-7B\nWhite\nMLP.v32\n1606\nEngland, France, Europe, Switzerland\nMLP.v32\n9831\nEuropean, Europe, EU, Euro\nAsian\nMLP.v32\n4453\nJapanese, Korean, Japan, Taiwan\nMLP.v31\n2346\nJapanese, anime, Japan, Tokyo\nBlack/AA\nMLP.v32\n5923\nBlack, Èªë, Negro, African\nMLP.v31\n8715\nAfrican, Africa, Kenya, Nigeria\nLlama-3.1-8B\nWhite\nMLP.v31\n9094\nWhite, white, WHITE, ÁôΩ\nAsian\nMLP.v32\n5691\nChinese, China, Beijing, Shanghai\nMLP.v29\n5272\nAsia, Asia, continent, ‰∫öÊ¥≤\nBlack/AA\nMLP.v30\n7195\nMississippi, Jamaica, Caribbean, Louisiana\nMLP.v29\n13826\nAfrican, african, Afro, negro\nTable 4: Top race-encoding neurons from C-REACT direct\nmentions (explicit race/ethnicity). WARNING: Some tokens\nreflect harmful stereotypes. Full results in Appendix A.5.\nTranslations: Ëã±ÂõΩ(England), ‰∫öÊ¥≤(Asia), „Ç¢„Ç∏„Ç¢(Asia), Èªë(Black), ÈªëËâ≤\n(Black color), ÁôΩ(White).\nTables 4 and 5 present race encoding neurons\nidentified from direct and indirect probes respec-\ntively. The neuron projections mirror the probe to-\nken patterns: direct mention neurons recover ex-\nplicit demographic terms (Asian, Black, African,\nÁôΩ(White)), while indirect mention neurons re-\ncover geographic and cultural associations (Rus-\nsia, Moscow, Vietnam, Caribbean). As in Toxi-\nGen, we observe neurons encoding harmful asso-\nciations.\nQwen2.5-7B‚Äôs MLP.v28\n11088 projects to\nracist, racism, Harlem, segregation, and several\nBlack/AA neurons encode terms related to slav-\nery. The persistence of such encodings across both\ngeneral and clinical domains indicates that harm-\nful stereotype-related associations are embedded\nwithin these models and are not limited to specific\ntask contexts.\nModel\nGroup\nNeuron\nTop tokens\nQwen2.5-7B\nWhite\nMLP.v27\n17660\nGerman, Germany, Ëç∑ÂÖ∞, euro\nMLP.v26\n3382\nRussians, Russia, ‰øÑÁΩóÊñØ, Moscow\nAsian\nMLP.v28\n13406\nJapanese, Êó•Êú¨, Tokyo, Osaka\nMLP.v25\n2001\nVietnam, Viet, Nguyen, Vietnamese\nBlack/AA\nMLP.v25\n10230\nÈùûÊ¥≤, African, slave, slavery\nMLP.v25\n10739\nAfrican, Africa, Ghana, Nigerian\nMistral-7B\nWhite\nMLP.v32\n2399\nRussian, Vlad, Moscow, Soviet\nMLP.v29\n260\nItalian, Italy, Giovanni, Francesco\nBlack/AA\nMLP.v31\n8715\nAfrican, Africa, Kenya, Nigeria\nLlama-3.1-8B\nWhite\nMLP.v32\n10606\nRussian, Moscow, Soviet, Putin\nMLP.v29\n4193\nCzech, Hungarian, Slovak, Budapest\nAsian\nMLP.v32\n5691\nChinese, China, Beijing, Shanghai\nMLP.v29\n10616\nIndian, India, Bollywood, Mumbai\nBlack/AA\nMLP.v29\n6824\ntropical, jungle, Congo, Caribbean\nMLP.v29\n13826\nAfrican, african, Afro, negro\nTable 5:\nTop race-encoding neurons from C-REACT in-\ndirect mentions (language/country).\nWARNING: Some\ntokens reflect harmful stereotypes.\nFull results in Ap-\npendix A.6.\nTranslations: Ëç∑ÂÖ∞(Netherlands), ‰øÑÁΩóÊñØ(Russia), Êó•Êú¨\n(Japan), ÈùûÊ¥≤(Africa).\n6.3\nNeuron Intervention\nTo test whether the race encoding neurons we iden-\ntified actually influence model behavior, we design\nan intervention experiment using C-REACT indi-\nrect mentions. Using a template prompt shown in\nFigure 3, we prompt each model to predict patient\nrace based on clinical text containing only indirect\ncues such as language or country information, and\nthen manipulate race encoding neurons to see if we\ncan correct observed biases.\nBaseline Classification. Table 6 shows misclas-\n6\n"}, {"page": 7, "text": "Please read the following sentence from a clinical\nnote. Based on the information contained within\nthe sentence, determine which of the following races\nor ethnicities the patient belongs to. Please respond\nwith only one option.\nOptions: [White, Black or African American, Asian]\nClinical Note: ‚Äù{text}‚Äù\nInferred Race or Ethnicity:\nFigure 3: Prompt template for race prediction on C-REACT\nindirect mentions.\nsification patterns across the three models. The\ndominant error type varies by model: for Qwen2.5-\n7B and Llama-3.1-8B, White‚ÜíAsian misclassifi-\ncation is the primary error, accounting for 75.0%\nand 95.6% of errors respectively. Llama‚Äôs bias is\nthe most pronounced, with 395 of 537 White pa-\ntients incorrectly classified as Asian. In contrast,\nMistral-7B shows a different pattern: its dominant\nerror is White‚ÜíBlack/AA (76.2% of errors). This\ndivergence suggests that models encode and apply\nracial information differently during inference.\nError Type\nQwen2.5-7B\nMistral-7B\nLlama-3.1-8B\nWhite‚ÜíAsian\n27\n4\n395\nWhite‚ÜíBlack/AA\n4\n16\n5\nBlack/AA‚ÜíWhite\n4\n0\n0\nBlack/AA‚ÜíAsian\n0\n0\n10\nAsian‚ÜíWhite\n1\n1\n1\nAsian‚ÜíBlack/AA\n0\n0\n2\nTotal Errors\n36\n21\n413\nDominant Error %\n75.0%\n76.2%\n95.6%\nTable 6: Misclassification patterns on C-REACT indirect\nmentions. The dominant error type (bold) varies across mod-\nels: White‚ÜíAsian for Qwen and Llama, White‚ÜíBlack/AA\nfor Mistral.\nActivation Patterns. To investigate what drives\nthese biases, we measure activation levels for all\nneuron groups across all classification outcomes\n(Table 7). We observe a strong correspondence be-\ntween neuron groups exhibiting consistently high\nactivation and dominant error directions identified\nin Table 6. For Qwen2.5-7B, which primarily mis-\nclassifies White patients as Asian, the Asian Direct\nneurons show consistently high positive activation\nregardless of ground truth or prediction. Similarly,\nMistral-7B‚Äôs tendency toward White ‚ÜíBlack/AA\nerrors aligns with elevated activity in Black/AA Di-\nrect neurons across most scenarios. Llama-3.1-8B\npresents a different pattern: while its dominant er-\nror is also White ‚ÜíAsian, Asian Indirect neurons\nshow consistently high activation across scenarios.\nThese patterns reveal that neuron groups exhibiting\nhigh activation across all conditions correspond to\ndominant misclassification directions, suggesting\nthey may play a causal role in bias. We use activa-\ntion as a diagnostic signal, but later show it does\nnot perfectly predict intervention eÔ¨Äicacy.\n5\n10\n20\nAmplification Factor\n0\n50\n100\nCorrect Predictions (%)\nQwen2.5-7B\nDirect\nIndirect\n5\n10\n20\nAmplification Factor\n0\n50\n100\nMistral-7B\nDirect\nIndirect\n5\n10\n20\nAmplification Factor\n0\n50\n100\nLlama-3.1-8B\nDirect\nIndirect\nFigure 4:\nCorrect prediction rates after neuron interven-\ntion across amplification factors. Direct neuron intervention\n(solid) generally outperforms Indirect intervention (dashed),\ndemonstrating that neurons encoding explicit racial terminol-\nogy have stronger causal influence on predictions.\n5\n10\n20\nAmplification Factor\n0\n20\n40\n60\n80\n100\nPercentage (%)\nQwen2.5-7B\n(White\nAsian)\n5\n10\n20\nAmplification Factor\n0\n20\n40\n60\n80\n100\nMistral-7B\n(White\nBlack/AA)\n5\n10\n20\nAmplification Factor\n0\n20\n40\n60\n80\n100\nLlama-3.1-8B\n(White\nAsian)\nWhite (Correct)\nOriginal Prediction\nOther Race\nUnknown\nDirect (solid)\nIndirect (faded)\nFigure 5: Prediction distribution after neuron intervention on\nmisclassified samples. Direct intervention (solid bars) elimi-\nnates the original bias entirely (orange ‚ÄòOriginal Prediction‚Äô\nbars = 0%) across all models and factors, while Indirect inter-\nvention (faded bars) leaves residual bias. Higher amplification\nfactors increase Unknown responses (gray)\nIntervention Results. Having identified candidate\nbias drivers, we test whether steering these neurons\ncan correct misclassification. Specifically, we eval-\nuate the intervention using three amplification fac-\ntors (5, 10, 20) to assess if these adjustments alter\nthe model‚Äôs predictions. Figure 4 compares cor-\nrect prediction rates between Direct and Indirect\nneuron intervention, while Figure 5 shows the full\nprediction distribution across all conditions.\nDirect vs. Indirect Neurons.\nAcross all three\nmodels, Direct neuron intervention demonstrates\nstronger causal eÔ¨Äicacy than Indirect interven-\ntion (Figure 4).\nAt factor 5, Direct interven-\ntion achieves substantially higher correct predic-\ntion rates across all models compared to Indirect\nintervention. More importantly, Direct interven-\ntion completely eliminates original bias across all\nmodels and amplification factors (Figure 5), while\nIndirect intervention leaves residual bias. This gap\nis also consistent with Llama-3.1-8B‚Äôs pattern: al-\nthough the Asian Indirect group has higher mean\nactivation, higher activation does not necessarily\nmean stronger causal influence on final prediction.\nIndirect cues tend to reflect broad, proxy signals\nthat can be supported by multiple parts of net-\nwork, so steering one indirect group may be partly\n7\n"}, {"page": 8, "text": "Classification Outcome (Actual ‚ÜíPredicted)\nModel\nNeuron Group\nW‚ÜíW\nW‚ÜíB\nW‚ÜíA\nB‚ÜíW\nB‚ÜíB\nB‚ÜíA\nA‚ÜíW\nA‚ÜíB\nA‚ÜíA\nQwen2.5-7B\nAsian Direct\n+6.04\n+6.25\n+5.85\n+3.50\n+5.71\n‚Äî\n+4.66\n‚Äî\n+3.86\nAsian Indirect\n‚àí1.03\n‚àí1.02\n‚àí0.96\n+0.31\n‚àí0.06\n‚Äî\n‚àí1.55\n‚Äî\n‚àí0.33\nBlack/AA Direct\n‚àí0.74\n‚àí0.04\n‚àí0.40\n+0.28\n+0.83\n‚Äî\n+0.27\n‚Äî\n+0.27\nBlack/AA Indirect\n‚àí0.57\n+0.40\n‚àí0.63\n+5.80\n+3.30\n‚Äî\n‚àí0.39\n‚Äî\n‚àí0.78\nWhite Direct\n‚àí3.25\n‚àí3.49\n‚àí3.80\n‚àí2.06\n‚àí3.05\n‚Äî\n‚àí4.87\n‚Äî\n‚àí4.01\nWhite Indirect\n+0.36\n+0.31\n‚àí0.20\n‚àí0.90\n‚àí1.24\n‚Äî\n‚àí0.33\n‚Äî\n‚àí1.31\nMistral-7B\nAsian Direct\n+0.22\n+0.24\n+0.14\n‚Äî\n‚àí0.15\n‚Äî\n+0.36\n‚Äî\n+0.19\nBlack/AA Direct\n+0.82\n+0.89\n+0.64\n‚Äî\n‚àí0.07\n‚Äî\n+1.00\n‚Äî\n+0.41\nBlack/AA Indirect\n‚àí0.56\n‚àí0.42\n‚àí0.55\n‚Äî\n+0.19\n‚Äî\n‚àí0.52\n‚Äî\n‚àí0.44\nWhite Direct\n+0.10\n‚àí0.06\n‚àí0.02\n‚Äî\n‚àí0.47\n‚Äî\n+0.33\n‚Äî\n+0.37\nWhite Indirect\n‚àí0.01\n+0.24\n‚àí0.17\n‚Äî\n‚àí0.27\n‚Äî\n‚àí0.44\n‚Äî\n‚àí0.32\nLlama-3.1-8B\nAsian Direct\n‚àí0.53\n‚àí0.59\n‚àí0.59\n‚Äî\n‚àí0.57\n‚àí0.54\n‚àí0.41\n‚àí0.51\n‚àí0.55\nAsian Indirect\n+0.27\n+0.28\n+0.33\n‚Äî\n+0.36\n+0.43\n+0.29\n+0.34\n+0.47\nBlack/AA Direct\n‚àí1.07\n‚àí1.43\n‚àí1.20\n‚Äî\n‚àí1.97\n‚àí1.66\n‚àí0.54\n‚àí1.60\n‚àí0.96\nBlack/AA Indirect\n‚àí0.01\n+0.01\n‚àí0.00\n‚Äî\n+0.04\n+0.07\n+0.03\n+0.03\n+0.03\nWhite Direct\n+0.11\n+0.37\n+0.24\n‚Äî\n+0.51\n+0.49\n+0.62\n+0.34\n+0.70\nWhite Indirect\n+0.22\n+0.28\n+0.32\n‚Äî\n+0.01\n+0.04\n‚àí0.04\n+0.01\n‚àí0.01\nTable 7: Mean neuron activation scores on C-REACT indirect mention prompts, grouped by classification outcome (actual ‚Üí\npredicted). W/B/A denote White / Black/AA / Asian (e.g., W‚ÜíB: actual White, predicted Black/AA; W‚ÜíW: correct). Posi-\ntive values indicate neuron group writes in direction of its output vectors (strengthening the associated signal during generation),\nwhile negative values indicate writing in the opposite direction (weakening it). ‚Äú‚Äî‚Äù indicates no samples for that outcome.\ncompensated elsewhere and leads to a smaller be-\nhavioral change. By contrast, Direct neurons are\nmore directly tied to producing explicit race labels,\nwhich makes intervening on them more effective.\nAmplification Factor Selection. The choice of\namplification factor involves a tradeoff between\nbias correction and model stability. We tested fac-\ntors of 5, 10, and 20, representing increasingly ag-\ngressive intervention.\nAcross all models, factor\n5 yields the best balance. Qwen2.5-7B achieves\n100% correct predictions with no Unknown out-\nputs at factor 5, but destabilizes at factor 20 (63%\nUnknown responses). Mistral-7B reaches 75% cor-\nrect predictions at factor 5, with higher factors in-\ncreasingly shifting predictions toward Asian rather\nthan the correct White label. Llama-3.1-8B per-\nforms similarly at factors 5 and 10 (around 80%\ncorrect), with factor 20 introducing Unknown re-\nsponses. These results suggest moderate interven-\ntion strength suÔ¨Äices to alter predictions via race-\nencoding neurons; we adopt factor 5 as the default.\n7\nDiscussion and Conclusion\nOur results indicate that the way race and ethnicity\nare internally represented in LLMs is central to un-\nderstanding how demographic bias emerges across\ntasks. The first important finding is that racial and\nethnic concepts are distributed across many in-\nternal units rather than localized to a small set\nof neurons. Importantly, this distribution is not\narbitrary: models decompose race and ethnicity\ninto multiple, interpretable semantic facets, such\nas explicit group labels and associated geographic\nor linguistic attributes. Across both ToxiGen and\nC-REACT, these facets appear as distinct internal\nrepresentations rather than single abstract concepts\n(Tables 1, 2, 3). Notably, stereotype-related and\nhistorically harmful associations are present across\nmodels despite differences in training data and geo-\ngraphic origin, suggesting that bias mitigation can-\nnot rely on a universal map of demographic fea-\ntures but requires model-specific localization.\nSecondly, due to this representational structure,\nthe same internal components can be reused across\ndifferent task contexts, sometimes in ways that\nlead to biased behavior. Neurons encoding racial\nconcepts are present in all three models, yet\ntheir influence on predictions varies substan-\ntially depending on whether the input associates\nstrongly with the proxy cues. The same represen-\ntations that benignly encode demographic informa-\ntion can lead to biased predictions when activated\nin contexts where race is irrelevant.\nCrucially, the presence of such representations\nis not inherently problematic. Rather, bias arises\nfrom how these representations are operational-\nized during inference.\nOur intervention did not\nerase racial knowledge from the models; instead, it\nmodulated how this knowledge was reused in task-\nspecific settings. This distinction is critical: pre-\ntrained representations reflect what models learn\nabout the world, whereas task-dependent bias re-\nflects when and how those representations are in-\nappropriately applied.\n8\n"}, {"page": 9, "text": "8\nConclusion\nWe provide a mechanistic analysis of how race\nand ethnicity are represented and operationalized\nwithin LLMs.\nWe show that demographic con-\ncepts are encoded as distributed, multi-faceted in-\nternal representations that can be selectively reused\nacross tasks. These findings suggest that mitigat-\ning demographic bias in LLMs requires not only\noutcome-level interventions, but also a deeper ex-\namination of representational structure and task-\ndependent reuse.\nEthical Statement\nThis work examine how race and ethnicity are en-\ncoded with large language models, which necessar-\nily involves sensitive content including stereotypes\nand historically offensive terminology. We present\nthese findings to expose potential bias, not to am-\nplify them. We acknowledge that racial categories\nare socially constructed and vary across cultures;\nour use of categories reflects the structure of the\ndatasets rather than an endorsement of these tax-\nonomies.\nAcknowledgment\nThis work was supported by the U.S. National Li-\nbrary of Medicine (NLM), National Institutes of\nHealth, under award number R00LM014308.\nReferences\nHiba Ahsan, Arnab Sen Sharma, Silvio Amir, David\nBau, and Byron C Wallace. 2025. Elucidating mech-\nanisms of demographic bias in llms for healthcare.\narXiv preprint arXiv:2502.13319.\nHiba Ahsan and Byron C Wallace. 2025. Can saes re-\nveal and mitigate racial biases of llms in healthcare?\narXiv preprint arXiv:2511.00177.\nOliver Bear Don‚Äôt Walk IV, Adrienne Pichon, Harry\nReyes Nieva, Tony Sun, Jaan Li, Joshua Winston\nJoseph, Sivan Kinberg, Lauren R. Richter, Salvatore\nCrusco, Kyle Kulas, Shaan Ahmed, Daniel Snyder,\nAshkon Rahbari, Benjamin Ranard, Pallavi Juneja,\nDina Demner-Fushman, and Noemie Elhadad. 2024.\nC-REACT: Contextualized race and ethnicity anno-\ntations for clinical text. PhysioNet. Version 1.0.0.\nNathaniel Demchak, Xin Guan, Zekun Wu, Ziyi\nXu, Adriano Koshiyama, and Emre Kazim. 2024.\nAssessing bias in metric models for llm open-\nended generation bias benchmarks. arXiv preprint\narXiv:2410.11059.\nKathleen Fraser and Svetlana Kiritchenko. 2024. Exam-\nining gender and racial bias in large vision‚Äìlanguage\nmodels using a novel dataset of parallel images. In\nProceedings of the 18th Conference of the European\nChapter of the Association for Computational Lin-\nguistics (Volume 1: Long Papers), pages 690‚Äì713, St.\nJulian‚Äôs, Malta. Association for Computational Lin-\nguistics.\nMor Geva, Roei Schuster, Jonathan Berant, and Omer\nLevy. 2021a.\nTransformer feed-forward layers are\nkey-value memories.\nIn Proceedings of the 2021\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 5484‚Äì5495.\nMor Geva, Roei Schuster, Jonathan Berant, and Omer\nLevy. 2021b. Transformer feed-forward layers are\nkey-value memories.\nIn Proceedings of the 2021\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 5484‚Äì5495, Online and\nPunta Cana, Dominican Republic. Association for\nComputational Linguistics.\nAaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri,\nAbhinav Pandey, Abhishek Kadian, Ahmad Al-\nDahle, Aiesha Letman, and et al. 2024. The Llama\n3 herd of models. arXiv preprint arXiv:2407.21783.\nXin Guan, Nate Demchak, Saloni Gupta, Ze Wang,\nEdiz Ertekin Jr., Adriano Koshiyama, Emre Kazim,\nand Zekun Wu. 2025.\nSAGED: A holistic bias-\nbenchmarking pipeline for language models with cus-\ntomisable fairness calibration.\nIn Proceedings of\nthe 31st International Conference on Computational\nLinguistics, pages 3002‚Äì3026, Abu Dhabi, UAE. As-\nsociation for Computational Linguistics.\nThomas Hartvigsen, Saadia Gabriel, Hamid Palangi,\nMaarten Sap, Dipankar Ray, and Ece Kamar. 2022.\nToxiGen: A large-scale machine-generated dataset\nfor adversarial and implicit hate speech detection.\nIn Proceedings of the 60th Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n1: Long Papers), pages 3309‚Äì3326, Dublin, Ireland.\nAssociation for Computational Linguistics.\nAlbert Q. Jiang, Alexandre Sablayrolles, Arthur Men-\nsch, Chris Bamford, Devendra Singh Chaplot, Diego\nde las Casas, Florian Bressand, Gianna Lengyel,\nGuillaume Lample, Lucile Saulnier, L√©lio Renard\nLavaud, Marie-Anne Lachaux, Pierre Stock, Teven\nLe Scao, Thibaut Lavril, Thomas Wang, Timoth√©e\nLacroix, and William El Sayed. 2023. Mistral 7B.\narXiv preprint arXiv:2310.06825.\nAdam Karvonen and Samuel Marks. 2025. Robustly\nimproving llm fairness in realistic settings via inter-\npretability. arXiv preprint arXiv:2506.10922.\nMichelle Kim, Junghwan Kim, and Kristen Johnson.\n2023. Race, gender, and age biases in biomedical\nmasked language models. In Findings of the Asso-\nciation for Computational Linguistics: ACL 2023,\npages 11806‚Äì11815, Toronto, Canada. Association\nfor Computational Linguistics.\n9\n"}, {"page": 10, "text": "Asaf Levartovsky, Mahmud Omar, Girish N Nad-\nkarni, Uri Kopylov, and Eyal Klang. 2025.\nSo-\nciodemographic bias in large language model‚Äì\nassisted gastroenterology.\nJAMA Network Open,\n8(9):e2532692‚Äìe2532692.\nYichen Li, Zhiting Fan, Ruizhe Chen, Xiaotang\nGai, Luqi Gong, Yan Zhang, and Zuozhu Liu.\n2025. Fairsteer: Inference time debiasing for llms\nwith dynamic activation steering.\narXiv preprint\narXiv:2504.14492.\nAfrozah Nadeem, Mark Dras, and Usman Naseem.\n2025. Context-aware fairness evaluation and mitiga-\ntion in llms. arXiv preprint arXiv:2510.18914.\nnostalgebraist.\n2020.\ninterpreting\nGPT:\nthe\nlogit\nlens.\nhttps://www.lesswrong.\ncom/posts/AcKRB8wDpdaN6v6ru/\ninterpreting-gpt-the-logit-lens.\nAccessed:\n2025-12-23.\nRaphael Poulain, Hamed Fayyaz, and Rahmatollah Be-\nheshti. 2024. Bias patterns in the application of llms\nfor clinical decision support: A comprehensive study.\narXiv preprint arXiv:2404.15149.\nQwen Team. 2024. Qwen2.5: A party of foundation\nmodels.\nNoam Shazeer. 2020. Glu variants improve transformer.\narXiv preprint arXiv:2002.05202.\nBryan Chen Zhengyu Tan and Roy Ka-Wei Lee.\n2025. Unmasking implicit bias: Evaluating persona-\nprompted LLM responses in power-disparate social\nscenarios. In Proceedings of the 2025 Conference\nof the Nations of the Americas Chapter of the Asso-\nciation for Computational Linguistics: Human Lan-\nguage Technologies (Volume 1: Long Papers), pages\n1075‚Äì1108, Albuquerque, New Mexico. Association\nfor Computational Linguistics.\nAngelina Wang, Michelle Phan, Daniel E. Ho, and\nSanmi Koyejo. 2025.\nFairness through difference\nawareness: Measuring Desired group discrimination\nin LLMs. In Proceedings of the 63rd Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 1: Long Papers), pages 6867‚Äì6893, Vienna,\nAustria. Association for Computational Linguistics.\nZeping Yu and Sophia Ananiadou. 2025.\nUn-\nderstanding and mitigating gender bias in llms\nvia interpretable neuron editing.\narXiv preprint\narXiv:2501.14457.\nTravis Zack, Eric Lehman, Mirac Suzgun, Jorge A Ro-\ndriguez, Leo Anthony Celi, Judy Gichoya, Dan Ju-\nrafsky, Peter Szolovits, David W Bates, Raja-Elie E\nAbdulnour, and 1 others. 2024. Assessing the poten-\ntial of gpt-4 to perpetuate racial and gender biases in\nhealth care: a model evaluation study. The Lancet\nDigital Health, 6(1):e12‚Äìe22.\nAngela Zhang, Mert Yuksekgonul, Joshua Guild, James\nZou, and Joseph C Wu. 2023. Chatgpt exhibits gen-\nder and racial biases in acute coronary syndrome\nmanagement. arXiv preprint arXiv:2311.14703.\nYachao Zhao, Bo Wang, Yan Wang, Dongming Zhao,\nRuifang He, and Yuexian Hou. 2025.\nExplicit vs.\nimplicit: Investigating social bias in large language\nmodels through self-reflection. In Findings of the As-\nsociation for Computational Linguistics: ACL 2025,\npages 1‚Äì12, Vienna, Austria. Association for Com-\nputational Linguistics.\nHanzhang Zhou, Zijian Feng, Zixiao Zhu, Junlang Qian,\nand Kezhi Mao. 2024. Unibias: Unveiling and miti-\ngating llm bias through internal attention and ffn ma-\nnipulation. Advances in Neural Information Process-\ning Systems, 37:102173‚Äì102196.\nA\nAppendix\nA.1\nProbe Performance\nModel\nAcc. (%)\nMacro-F1\nQwen2.5-7B-IT\n74.88\n0.74\nLlama-3.1-8B-IT\n77.98\n0.77\nMistral-7B-IT\n75.20\n0.74\nTable\n8:\nTest\nset\nperformance\nof\nmulti-class\nlinear\nprobes\ntrained\non\nToxiGen\n(5-way:\nasian/black/latino/native_american/middle_eastern).\nWe report Accuracy and Macro-F1.\nDirect\nIndirect\nModel\nAcc. (%)\nMacro-F1\nAcc. (%)\nMacro-F1\nQwen2.5-7B-IT\n90.36\n0.79\n81.61\n0.79\nLlama-3.1-8B-IT\n93.98\n0.85\n80.46\n0.80\nMistral-7B-IT\n90.66\n0.70\n75.86\n0.74\nTable 9: Test set performance of linear probes trained\non C-REACT (3-way: White/Black/AA/Asian), using\nDirect vs. Indirect prompt variants.\nA.2\nProbe Token Projections (ToxiGen)\nTable 10 presents the complete top-20 tokens pro-\njected by each race direction probe for all three\nmodels.\nA.3\nRace-Encoding Neurons (ToxiGen)\nFrom Table 11 to Table 13 present the complete\nlists of race-encoding neurons identified from Tox-\niGen for the three models.\nA.4\nProbe Token Projections (C-REACT)\nTable 14 and Table 15 present the complete top-20\ntokens projected by each race direction probe for\ndirect and indirect mentions respectively.\n10\n"}, {"page": 11, "text": "Model\nGroup\nTop 20 Tokens\nQwen2.5-7B\nAsian\nAsian, ‰∫öÊ¥≤, Asian, Chun, Chinese, CJK, Yuan, ‰∏ú‰∫ö, ‡πà‡∏ß, chinese, Èúπ, ÊÅ∂, Chinese, ActivityCreated, chner, Chu, ObjectContext, lobals, Hong, chin\nBlack\n=‚Äù{}/>, Áõ∏Â∫î, orsk, Âè∞Èò∂, Êà™, –ª–∏–±–æ, Ê≤°ÊúâÊÉ≥Âà∞, Rudd, ÈíÆ, .BLL, .GetDirectoryName, ]interface, setError, Èπï, Beaut, Â§ô, :async, \u0000, Áª∂, SingleOrDefault\nLatino\nnesty, Mex, .Span, .Shared, Âû≠, .‚Äù/, /items, SetLastError, ucher, getTime, .onclick, enticate, ERVE, mex, .Stretch, mexico, t√º, evenodd, asher, Âπ¥‰πã‰πÖ\nNative Am.\nnatives, native, .Native, native, Native, Native, _native, indigenous, coma, .native, -native, ‚Äù‚Äù}, ÈÅî, ings, NAV, ITERAL, reservation, INGS, \u0000, ËëÜ\nMiddle Eastern\navigate, wargs, ÁÆ¥, bsolute, arma, /xhtml, %‚Äù><, elic, .clearRect, –∞—Ä–∞–º–µ—Ç, ouv, ÂΩπ, Èìà, Œª, _Tick, achts, wares, hill, kap, lambda\nMistral-7B\nAsian\nChinese, Asian, China, Korean, Taiwan, Hong, inese, Japanese, ‚Äô, Shanghai, Beijing, Asia, omi, ‡πà, √ü, bt, Roose, MMMM, omy, agh\nBlack\n/******/, corpor, Coff, Email, black, uh, African, publicly, spell, ta, white, email, black, Black, Palm, Parl, riel, Black, mask, rele\nLatino\nMexico, Salvador, jd, Colombia, Chile, ¬°, Colomb, ass, Mexican, Skip, ranch, Mex, Santiago, ully, Argent, jal, Partido, sketch, skip, aca\nNative Am.\nIndians, trib, Native, tribes, Indian, medicine, Native, ye, Medicine, AD, ingle, minister, ilo, Inga, tribe, iga, unda, Trib, uti, erset\nMiddle Eastern\nIslamic, Palestinian, Muhammad, Muslim, Hass, Israel, esa, Naj, Turkish, Jewish, Bere, Turk, Muslims, jew, Arab, hash, Arabia, Jews, triple, Middle\nLlama-3.1-8B\nAsian\nAsian, Asian, Mandarin, CJK, erse, le≈æit, ibold, Ding, inese, asian, rysler, china, ern, Chinese, Asia, ihan, Asians, ertainment, ≈∫, Euras\nBlack\nCELER, Black, isay, Black, _black, urgeon, -black, adeon, arp, cie, anja, .black, Èªë,,Ÿàÿ±ÿß-hit, /black,,ÿ¨ŸÑouse,Ÿàÿ™ÿ± ,ÿ®ŸÑŸÜÿØ\nLatino\nucwords, Â¶ô, udos, Buchanan, .si, ‚Äù, oppos, aside, i, City, rip, Mundo, od√≠, _BORDER, mant, cloak, _gid, .ul, iyon, ivery\nNative Am.\nNative, Native, native, natives, native, -native, Indians, _Native, _native, indigenous, .native, /native, Indigenous, tribes, RIPT, Indian, reservation, .Native, ative, Reservation\nMiddle Eastern\nMev, LLL, ≈°em, Islamic, Middle, ohon, WW, acket, Aber, esso, profits, —Å–æ–≤, owy, uzz, removed, ‚Äô ‚Äô, —Å—Ç–∞–Ω–æ–≤, ISIL, Christian, etus\nTable 10: Full top-20 probe token projections for all models (ToxiGen). Tokens are listed in descending order of\nprojection score. Translations: ‰∫öÊ¥≤(Asia), ‰∏ú‰∫ö(East Asia), ‡πà‡∏ß(Thai mark), Èúπ(thunderclap), ÊÅ∂(evil), Áõ∏Â∫î(corresponding), Âè∞Èò∂(steps), Êà™(cut), –ª–∏–±–æ\n(either), Ê≤°ÊúâÊÉ≥Âà∞(didn‚Äôt expect), ÈíÆ(button), Èπï(pelican), Â§ô(early), \u0000 (swift flight), Áª∂(ribbon), Âû≠(mountain pass), t√º (door), Âπ¥‰πã‰πÖ(for years), ÈÅî(reach),\n\u0000 (Kim), ËëÜ(preserve), ÁÆ¥(admonition), –∞—Ä–∞–º–µ—Ç (parameter), ÂΩπ(service), Èìà(cerium), ¬° (inverted exclamation), √ü (ss), Èªë(black),( Ÿàÿ±ÿßbehind),( ÿ¨ŸÑskin),ÿ®ŸÑŸÜÿØ\n(tall),( Ÿàÿ™ÿ±string), Â¶ô(wonderful), —Å–æ–≤ (owl), —Å—Ç–∞–Ω–æ–≤ (become), ≈∫ (z), ≈°em (name), od√≠ (I hated).\nModel\nGroup\nNeuron\nTop Tokens\nQwen2.5-7B\nAsian\nMLP.v28\n13406\nÂú®Êó•Êú¨, Japanese, Êó•Êú¨, Japanese, Japan, Japan, Êó•Êú¨‰∫∫, Tokyo, japan, ‰∏ú‰∫¨, japan, \u0000\u0000, Êó•ÂÜõ, japanese, japon, Nh·∫≠t, Êó•Êú¨„ÅÆ, Tok, Hiro, jap, Osaka\nMLP.v28\n5983\nChi, chi, Chin, Chi, chin, chi, _chi, Xi, Hu, xi, Hu, xi, ‰∫∫Ê∞ëÂ∏Å, Xi, chin, Huawei, Âçé‰∏∫, ÂçéÂ§è, (xi, hu\nMLP.v27\n8641\nch, ÊòØ‰∏≠ÂõΩ, Ch, ‰∏∫‰∏≠ÂõΩ, Chinese, Êàê‰∏∫‰∏≠ÂõΩ, Áî±‰∏≠ÂõΩ, ‰∏é‰∏≠ÂõΩ, ÂØπ‰∏≠ÂõΩ, China, china, _ch, Âú®‰∏≠ÂõΩ, China, Ch, china, Chinese, -Ch, CH, chin\nMLP.v27\n217\nAsian, ‰∫öÊ¥≤, Asia, Asian, Asians, Asia, asian, asia, „Ç¢„Ç∏„Ç¢, ‰∫ö, ‰∫û, Asi, asia, asiat, asi, ‰∫öÂ§™, ‡πÄ‡∏≠‡πÄ‡∏ä, _As, asi, AS\nMLP.v25\n15029\nChinese, China, China, Chinese, chinese, china, china, ‰∏≠ÂõΩ, ‰∏≠ÂõΩÁöÑ, -China, \u0000\u0000,,ÿßŸÑÿµŸäŸÜ‰∏≠Âúã, Asian, Âú®‰∏≠ÂõΩ, ÊòØ‰∏≠ÂõΩ, ‰∫öÊ¥≤, Áî±‰∏≠ÂõΩ, Asian, Asia\nBlack\nMLP.v27\n2240\nblack, Èªë, black, Black, Black, ÈªëËâ≤, -black, BLACK, BLACK, _black, blacks, .black, /black, , „Éñ„É©„ÉÉ„ÇØ, .Black, Èªë, ÈªëÁôΩ, _BLACK, blacklist\nLatino\nMLP.v28\n4781\nLatin, Latin, Êãâ‰∏Å, latin, latin, LATIN, latino, Â∑¥Ë•ø, Latino, LAT, Latina, latina, Lat, Brazil, _LAT, ÈòøÊ†πÂª∑, Lat, Brazil, lat, LAT\nMLP.v28\n9876\nSpanish, Ë•øÁè≠Áâô, Êπò, Portuguese, Hispanic, Spanish, Ë¥µÂ∑û, Brazilian, ¬°, ¬°, Ë¥µÂ∑ûÁúÅ, Èªî, Ëë°ËêÑÁâô, Juan, Chile, spanish, Ë¥µÈò≥, Brazil, Juan, Spain\nMLP.v27\n18125\nSpanish, Ë•øÁè≠Áâô, Hispanic, Spanish, Chile, Mexican, Ë¥µÂ∑û, Â¢®Ë•øÂì•, Spain, Brazilian, Juan, Mex, Juan, Â∑¥Ë•ø, ÈòøÊ†πÂª∑, Ë¥µÂ∑ûÁúÅ, Mexico, Êπò, spanish, Mexico\nMiddle East\nMLP.v28\n9988\n‰ª•Ëâ≤Âàó, Israel, Jerusalem, Israel, Israeli, Noah, Hebrew, Moses, Zion, -Israel, Palestine, Biblical, biblical, Israeli, Israelis, Luke, Zionist, Palestinian, Jer, Nathan\nMLP.v27\n9840\n‰ºäÊñØÂÖ∞, Á©Ü, Mu, Ali, Ali, Must, mu, ÈòøÊãâ‰ºØ, Mu, Ah, MU, Muhammad, Moh, Fat, MU, Must, .mu, _mu, Ab, Muslims\nMLP.v27\n8005\nÂÆóÊïô, religious, religious, relig, religion, Religious, Religion, religions, Âü∫Áù£Êïô, ‰ΩõÊïô, theological, spiritual, ‰ø°‰ª∞, Christian, prayer, secular, spirituality, ËÄ∂Á®£, Ëôî, Âú£Áªè\nMLP.v26\n3012\nÁäπ, Jew, Jewish, Áå∂, Jews, Judaism, –µ–≤, jewish, Juda, Hebrew, –µ–≤—Ä, ‰ª•Ëâ≤Âàó, Israel, kosher, synagogue, -J, ewish, jew, Rabbi, Israeli\nNative Am.\nMLP.v25\n3458\nnative, native, Ëá™ÁÑ∂, natural, Native, Native, Êú¨Âúü, Â§©ÁÑ∂, -native, indigenous, natural, natives, naturally, Natural, /native, nat, Natural, _native, .native, Ëá™Âèë\nMLP.v25\n7087\nnative, ÊïÖ, native, Native, ÊïÖ‰π°, Êú¨Âúü, ÂÆ∂‰π°, -native, Native, natives, hometown, .native, _native, home, homeland, ÔøøÔøøÔøø, Á•ñÂõΩ, /native, birth, qu√™\nMLP.v25\n11197\nÊÆñÊ∞ë, colonial, colon, colony, colon, colonies, Colonial, Colon, Colon, Colony, imperial, Imperial, olon, icolon, -col, Â∏ùÂõΩ, ocol, colonization, dec, _COL\nTable 11: Full top-20 tokens for race-encoding neurons in Qwen2.5-7B (ToxiGen).\nTranslations: Âú®Êó•Êú¨(in Japan), Êó•Êú¨\n(Japan), Êó•Êú¨„ÅÆ(Japan), Êó•Êú¨‰∫∫(Japanese), ‰∏ú‰∫¨(Tokyo), Êó•ÂÜõ(Japanese army), ÊòØ‰∏≠ÂõΩ(China), ‰∏∫‰∏≠ÂõΩ(China), Êàê‰∏∫‰∏≠ÂõΩ(China), Áî±‰∏≠ÂõΩ(China), ‰∏é‰∏≠ÂõΩ\n(China), ÂØπ‰∏≠ÂõΩ(China), Âú®‰∏≠ÂõΩ(China), ‰∏≠ÂõΩ(China), ‰∏≠Âúã(China), ‰∏≠ÂõΩÁöÑ(China), ‰∫öÊ¥≤(Asia), ‰∫ö(Asia), ‰∫û(Asia), ‰∫öÂ§™(Asia-Pacific), ‰∫∫Ê∞ëÂ∏Å(Renminbi),\nÂçé‰∏∫(Huawei), ÂçéÂ§è(China), Èªë(black), ÈªëËâ≤(black), ÈªëÁôΩ(black-and-white), Èªë(black), „Éñ„É©„ÉÉ„ÇØ(black), Êãâ‰∏Å(Latin), Â∑¥Ë•ø(Brazil), ÈòøÊ†πÂª∑(Argentina),\nË•øÁè≠Áâô(Spain), Â¢®Ë•øÂì•(Mexico), Ëë°ËêÑÁâô(Portugal), Ë¥µÂ∑û(Guizhou), Ë¥µÂ∑ûÁúÅ(Guizhou), Ë¥µÈò≥(Guiyang), Èªî(Guizhou), Êπò(Hunan), ‰ª•Ëâ≤Âàó(Israel), ‰ºäÊñØÂÖ∞\n(Islam), ÈòøÊãâ‰ºØ(Arab), ÂÆóÊïô(religion), Âü∫Áù£Êïô(Christianity), ‰ΩõÊïô(Buddhism), ‰ø°‰ª∞(faith), ËÄ∂Á®£(Jesus), Âú£Áªè(Bible), Ëôî(pious), Áäπ(Jew), Áå∂(Jew), Á©Ü(Mu),\nËá™ÁÑ∂(natural), Â§©ÁÑ∂(natural), Êú¨Âúü(native), ÊïÖ‰π°(hometown), ÂÆ∂‰π°(hometown), ÊïÖ(hometown), Á•ñÂõΩ(motherland), ÊÆñÊ∞ë(colonial), Â∏ùÂõΩ(empire), „Ç¢„Ç∏„Ç¢\n(Asia), \u0000\u0000 (Japan), \u0000\u0000 (China), ‡πÄ‡∏≠‡πÄ‡∏ä(Asia),( ÿßŸÑÿµŸäŸÜChina), –µ–≤ (Jew), –µ–≤—Ä (Jew), —Ä–æ–¥ (homeland), ¬° (!), Vi·ªát: Nh·∫≠t (Japan), Portugu√™s: qu√™ (homeland).\nModel\nGroup\nNeuron\nTop Tokens\nMistral-7B\nAsian\nMLP.v32\n4453\nJapanese, Korean, Kol, Japan, Kor, Kaz, Sak, Taiwan, Korea, Nak, Kur, Kom, Bangl, Pakistan, Kab, Kon, Pak, Tibet, Ku, Asian\nBlack\nMLP.v32\n5923\nBlack, black, Black, black, blacks, Èªë, \u0000, Negro, BL, blk, African, BL, —á–µ—Ä, Afr, Dark, —á, dark, –ß–µ—Ä, –ª–µ–∫, \u0000MLP.v30\n12572\nBlack, black, Black, black, blacks, Èªë, BL, \u0000, BL, Negro, blk, —á–µ—Ä, dark, African, Afr, \u0000, –ª–µ–∫, dark, –ß–µ—Ä, —á\nMLP.v29\n13186\nblack, black, Black, blacks, Black, white, Èªë, white, whites, African, \u0000, Negro, ÁôΩ, Afr, White, White, BL, —á–µ—Ä, Af, brown\nMiddle East\nMLP.v32\n5573\nJewish, Jews, Jerusalem, Israel, Israeli, JS, js, JavaScript, JS, Palest, JSON, JSON, js, json, Json, json, ajax, Palestinian, javascript, jQuery\nMLP.v29\n3203\nMediterranean, Turkish, Egyptian, Turkey, Israeli, Iran, Jordan, Israel, Arab, Egypt, Palestinian, Iraq, Tur, Leb, Greek, Jerusalem, Saudi, Gulf, Arabia, Palest\nNative Am.\nMLP.v31\n3440\nimperial, fasc, Imperial, colonial, militar, Kent, /******/, colon, popul, racist, gent, antal, neo, provinc, Emitter, colon, carriage, TES, omena, ounds\nMLP.v29\n12205\nnative, native, Native, Native, nat, ind, ab, igenous, Ma, nat, Ab, Ma, abor, Nat, primitive, Nav, born, Mas, nav, Ab\nTable 12: Full top-20 tokens for race-encoding neurons in Mistral-7B (ToxiGen). Translations: Èªë(black), \u0000 (black), —á–µ—Ä (black),\n—á (ch), –ß–µ—Ä (black), –ª–µ–∫ (lek), \u0000 (black), ÁôΩ(white).\nA.5\nRace-Encoding Neurons (C-REACT\nDirect)\nTable 16 presents the complete list of race-\nencoding neurons identified from C-REACT direct\n11\n"}, {"page": 12, "text": "Model\nGroup\nNeuron\nTop Tokens\nLlama-3.1-8B\nAsian\nMLP.v32\n5691\nChinese, China, Chinese, China, chinese, china, -China, Beijing, ‰∏≠ÂõΩ, √áin, \u0000\u0000, Shanghai, ‰∏≠Âúã, china,,⁄Ü€åŸÜ‰∏≠ÂõΩ, Zhang, Jiang, Tencent, Guang\nMLP.v31\n14299\nLi, yuan, Dong, Huang, Liu, Wang, Chen, Yang, Tian, Zhou, Ding, Wu, dong, dong, Feng, wang, Zhang, Qin, Jiang, Guang\nMLP.v30\n12566\nEast, East, EAST, Eastern, east, -East, eastern, Êù±, Eastern, east, ‰∏ú, -east, Êù±, Doƒüu, ‰∏ú, ƒê√¥ng,,ÿ¥ÿ±ŸÇv√Ωch, –≤–æ—Å—Ç, orient\nLatino\nMLP.v32\n9242\nSpanish, Hispanic, Spanish, spanish, Mexican, Argentine, Santiago, Mexico, Puerto, Madrid, pesos, Chavez, Ecuador, Spain, Juan, Hispan, Colombian, Hispanics, Carlos, Chile\nNative Am.\nMLP.v32\n6893\ncolon, Colon, Colon, colon, colonial, Colonial, colonization, colonies, Colony, colony, Colonel, ÊÆñ, olon, icolon, Colin, OLON, kol, COL, -Col, colore\nMLP.v31\n1186\nnative, energy, Energy, native, energy, Native, Native, -native, Energy, natives, _native, .native, _energy, -energy, supply, ËÉΩÊ∫ê, culture, /native, nice, Higher\nMiddle East\nMLP.v30\n11051\nArab, Middle, arab, Arabic, Arabs, Middle, Arabian, Arabia, Saudi, Yemen, Egypt, Cairo, Palestinian, Bahrain, Kuwait, Egyptian, Saudi, Riyadh,,ÿπÿ±ÿ®Libya\nMLP.v29\n2750\nIslamic, Islam, Islam, Arabic, Islamic, mosques, mosque, Muslim, Muhammad, Muslim, Muslims, Abdullah, Mosque, Quran, Islamist, Mohammad, Ramadan, isl, –º—É—Å, muslim\nBlack\nMLP.v30\n7195\nMississippi, Jamaica, Jama, Caribbean, Louisiana, Trinidad, Haiti, LSU, Ghana, Hait, Baton, Harlem, Nigeria, negro, Negro, Jazz, Bahamas, Memphis, Nigerian, Zimbabwe\nMLP.v29\n13826\nAfrican, african, Africans, Africa, Africa, afr, Afro, Afr, frican, negro, Af, Afrika, Af, africa, Negro, blacks, black, af, frica, Blacks\nTable 13: Full top-20 tokens for race-encoding neurons in Llama-3.1-8B (ToxiGen). Translations: ‰∏≠ÂõΩ(China), ‰∏≠Âúã(China),\n‰∏≠ÂõΩ(China),( ⁄Ü€åŸÜChina), √áin (China), \u0000\u0000 (China), Êù±(East), ‰∏ú(East), Doƒüu (East), ƒê√¥ng (East),( ÿ¥ÿ±ŸÇEast), v√Ωch (East), –≤–æ—Å—Ç (East), ÊÆñ(colonial/colonize),\nËÉΩÊ∫ê(energy),( ÿπÿ±ÿ®Arab), –º—É—Å (Muslim).\nModel\nGroup\nTop 20 Tokens\nQwen2.5-7B\nWhite\nÁôΩ, generado, -Nazi, ksam, onn, pl, owl, ucas, *&, ‚Äô#{, .toByteArray, _EXTENSIONS, avras, onFailure, Èï™, ski, Nederland, Â•ΩËøê, Luft, Ski\nAsian\nAsian, Asian, Asians, Asia, ‰∫öÊ¥≤, Asia, asia, Asi, „Ç¢„Ç∏„Ç¢, asiat, asian, Ëà¢, Taiwan, Singapore, Ëà∂, Singapore, Tai, Canton, Taiwanese, —Ä–∞–∫—Ç–∏\nBlack/AA\nafrican, African, ÈùûÊ¥≤, -AA, Africans, Africa, ienda, Africa,,ÿßŸÑÿ≥ŸàÿØÁñü, mongo, /black, aina, AA, .BL, .Black, .Mongo, Afro, Nigerian, Black\nMistral-7B\nWhite\nogle, ASC, cip, Kurt, heid, un√§chst, kle, √æ, criptor, √≥r, NOP, och, zym, hid, eu, cow, c√≠, zens, vas, awa\nAsian\nAsian, Taiwan, Japanese, Hong, Malays, Japan, Singapore, Chinese, Malaysia, Pak, Indones, Korean, Tai, Asia, Philippines, Philipp, Tokyo, Tok, jap, Sri\nBlack/AA\nAfrican, Afr, Africa, blacks, Niger, Jama, Negro, Nigeria, Black, Af, ament, slavery, sist, black, external, external, Af, AA, lando, slave\nLlama-3.1-8B\nWhite\nithe, lan, Fres, ycz, hs, Wake, Bread, bread, itra, bairro, Fans, 1, Josh, wie, Jackets, „Ç∏„Ç™, Marina, Œ≥Œπ, Josh, avan\nAsian\nAsian, Asian, Asians, asian, Indonesian, Asia, Taiwanese, Asia, asiat, Vietnamese, Japanese, Korean, Oriental, Malaysian, Buddhist, ‰∫öÊ¥≤, orean, Filipino, Chinese, Indones\nBlack/AA\nblack, African, Black, african, black, frican, Afro, /black, negro, Negro, Èªë, blacks, BLACK, zwarte, Èªë, Black, .Black, _black, Africa, Africans\nTable 14: Full top-20 probe token projections for C-REACT direct mentions (explicit race/ethnicity). Translations: ÁôΩ\n(white), generado (generated), Èï™(money), Nederland (Netherlands), Â•ΩËøê(good luck), Luft (air), ‰∫öÊ¥≤(Asia), „Ç¢„Ç∏„Ç¢(Asia), Ëà¢(Shantou), Ëà∂(ship), —Ä–∞–∫—Ç–∏\n(practice), ÈùûÊ¥≤(Africa),( ÿßŸÑÿ≥ŸàÿØblack), Áñü(malaria), un√§chst (initially), √æ (th), √≥r (or), c√≠ (here), zens (citizens), bairro (neighborhood), „Ç∏„Ç™(Geo), Œ≥Œπ (gi), Èªë\n(black), zwarte (black).\nmentions (explicit race/ethnicity).\nA.6\nRace-Encoding Neurons (C-REACT\nIndirect)\nTable 17 presents the complete list of race-\nencoding neurons identified from C-REACT indi-\nrect mentions (language/country).\nA.7\nExample Model Prediction Outputs\nFigure 6 presents example model outputs after neu-\nron intervention. Correct predictions result in valid\nracial category labels, while failures to provide a\nvalid label are classified as Unknown.\nCategory\nModel Output\nCorrect predictions (White)\nExample 1\n[White] You are an AI assistant. Provide\nExample 2\n[White] You are an AI assistant. User\nUnknown outputs (invalid or malformed)\nExample 1\n[Russian] The race or ethnicity that best fits\nExample 2\n[Russian] Based on the information provided in the\nExample 3\n[Yellow] [X] [Black or African\nExample 4\n[Yellow] The provided options do not include ‚Äù\nFigure 6: Example outputs after Direct neuron interven-\ntion. Correct predictions produce valid category labels\n(top), while unstable interventions at high amplification\nfactors produce invalid outputs classified as Unknown\n(bottom).\n12\n"}, {"page": 13, "text": "Model\nGroup\nTop 20 Tokens\nQwen2.5-7B\nWhite\nRaisePropertyChanged, Russian, ‰øÑÁΩóÊñØ, Ê©º, Âú¨, ocaly, Russia, _backward, Kremlin, Russian, *)((, .defaultValue, RU, russian, egrator, ipsis, Rad, UCE, abis, ENCIL\nAsian\n.Dao, Âçé‰∫∫, Chinese, Âµ¥, .insertBefore, Xia, chinese, ettel, Chinese, Tibetan, China, Wong, /apache, ÂçéÂçó, dao, dx, \u0000, Jun, utenant, stylesheet\nBlack/AA\nHait, Haiti, Tropical, )__, eneg, %;‚Äù, ($., Âü¥, %;‚Äù>, ÂΩó, tropical, Âûì, |,ÃÄ .iterator, ÁÉ≠Â∏¶, %;‚Äù>, ];//, loo, estring, *****\nMistral-7B\nWhite\nMoscow, Russian, Ukrain, Ukraine, Russians, Polish, Ukr, Russia, vod, Soviet, Vlad, russ, Kaz, Bulgar, Lieutenant, Mik, icz, Roma, dou, Serge\nAsian\nKorea, Korean, Asian, trag, apis, Shan, Vietnam, gram, sg, apore, ga, Aires, Assembly, WD, lag, Nor, Viet, Schw, gan, cent\nBlack/AA\nCaribbean, Jama, Braz, Af, Cuba, Niger, Nigeria, Cub, Bah, S√£o, Core, Currency, Bras, island, Hy, hur, Curt, Af, Brazil, mont\nLlama-3.1-8B\nWhite\nRussia, Kremlin, Russian, Russians, Putin, Moscow, Ukraine, Putin, Ukrainian, Russian, Russia, Ukrain, russian, Rus, Belarus, Rus, russe, russ, Kiev, Rusya\nAsian\nCambodia, Asian, Chung, Cheng, Chinese, Camb, Kang, wang, Chinese, chinese, Buddhism, asian, Hong, Bangalore, Buddhist, Bang, Asian, Malaysia, Korean, –µ—Ä–≥\nBlack/AA\nHait, Haiti, Caribbean, Maurit, Dominican, Bahamas, hait, Cre, Cre, Jama, ibbean, Trinidad, ingt, Jean, Cameroon, Fran√ßois, Maurice, Jean, –∞–Ω–∫–∞, Santo\nTable 15: Full top-20 probe token projections for C-REACT indirect mentions (language/country). Translations: ‰øÑÁΩóÊñØ\n(Russia), Ê©º(yuan; Chinese monetary unit), Âú¨(plaster), Âçé‰∫∫(ethnic Chinese), Âµ¥(ridge), ÂçéÂçó(South China), \u0000 (went), Âü¥(clay), ÂΩó(comet), Âûì(vast number),\nÁÉ≠Â∏¶(tropical), S√£o (Saint/S√£o), Rusya (Russia), –µ—Ä–≥ (erg), –∞–Ω–∫–∞ (anka).\nModel\nGroup\nNeuron\nTop 20 Tokens\nQwen2.5-7B\nWhite\nMLP.v28\n16880\nËã±ÂõΩ, Dutch, French, Ê≥ïÂõΩ, ÊÑèÂ§ßÂà©, Italian, German, Ëç∑ÂÖ∞, France, British, Belgian, European, Britain, Germany, Âæ∑ÂõΩ, Spanish, Italy, Spain, Ê¨ßÊ¥≤, French\nMLP.v27\n17660\nGerman, ‰∏áÊ¨ßÂÖÉ, „Éâ„Ç§„ÉÑ, Âæ∑ÂõΩ, German, Germany, Germans, EU, Ëç∑ÂÖ∞, euro, ‚Ç¨, Ê¨ßÁõü, Germany, Swiss, Ê¨ßÂÖÉ, Euro, Dutch, ÁëûÂ£´, Ê¨ß, Switzerland\nMLP.v25\n4157\nUEFA, Âú∞‰∏≠Êµ∑, Mediterranean, Cyprus, Pane, Roman, Ê¨ßÁõü, Euro, Roman, chalk, Â∏åËÖä, Europe, UES, Rom, ÁΩóÈ©¨, EU, Kn, Europe, Ê©°, È®∞\nMLP.v25\n8669\nfod, ].‚Äô, []>, sterdam, ·ª™, Spain, Gaines, Spain, ÊØîÂà©Êó∂, Ôøø, WRITE, Ëã±ÂõΩ, europe, <!‚Äì[, ======, %@‚Äù, Á§∫, Ë•øÁè≠Áâô, _IMPORTED, euros\nAsian\nMLP.v28\n13406\nÂú®Êó•Êú¨, Japanese, Êó•Êú¨, Japanese, Japan, Japan, Êó•Êú¨‰∫∫, Tokyo, japan, ‰∏ú‰∫¨, \u0000\u0000, Êó•ÂÜõ, japanese, japon, Nh·∫≠t, Tok, Hiro, Êó•Êú¨„ÅÆ, Osaka, jap\nMLP.v28\n16570\n‰π†, Áøí, ÊÉØ, habit, ‰π†ÊÉØ, ÁöÑ‰π†ÊÉØ, habitual, Habit, ÁøíÊÖ£, habit, habits, accustomed, ‰π†ËøëÂπ≥, ‰π†ÊÉØ‰∫Ü, ÊÖ£, ‰π†Ëøë, ÊÉØ‰æã, ‰π†‰øó, ‰π†ËøëÂπ≥ÊÄª, ÊÄª‰π¶ËÆ∞\nMLP.v27\n6943\nAsian, Asian, ‰∫öÊ¥≤, Asia, Chinese, Asia, Chinese, China, Âç∞Â∫¶, Indian, India, India, Asians, China, Indian, chinese, ‰∏≠Âúã, Oriental, Japanese, asian\nMLP.v27\n217\nAsian, ‰∫öÊ¥≤, Asia, Asian, Asians, Asia, asian, asia, „Ç¢„Ç∏„Ç¢, ‰∫ö, ‰∫û, Asi, asia, asiat, asi, ‰∫öÂ§™, ‡πÄ‡∏≠‡πÄ‡∏ä, _As, asi, AS\nMLP.v26\n5187\nChinese, Italian, Chinese, Irish, Italian, Asian, Japanese, chinese, Mexican, Vietnamese, Korean, German, Greek, Asian, Portuguese, Latin, Indian, African, German, italian\nMLP.v26\n8828\n‰∫öÊ¥≤, Asian, Asia, Asian, Latin, Ê¨ß, Asia, ‰∫öÂ§™, Ê¨ßÊ¥≤, ÈùûÊ¥≤, ‰∏ú‰∫ö, Southeast, Europe, Êãâ‰∏Å, European, ‰∏úÂçó‰∫ö, ÁæéÊ¥≤, „Ç¢„Ç∏„Ç¢, Euras, Asians\nMLP.v25\n15029\nChinese, China, China, Chinese, chinese, china, china, ‰∏≠ÂõΩ, ‰∏≠ÂõΩÁöÑ, -China, \u0000\u0000,,ÿßŸÑÿµŸäŸÜ‰∏≠Âúã, Asian, Âú®‰∏≠ÂõΩ, ÊòØ‰∏≠ÂõΩ, ‰∫öÊ¥≤, Áî±‰∏≠ÂõΩ, Asian, Asia\nBlack/AA\nMLP.v28\n11088\nracial, racially, racist, ÁßçÊóè, racism, racial, Harlem, segregated, segregation, Rac, interracial, Ethnic, Afro, hetto, ethnic, rac, Interracial\nMLP.v28\n10048\n¬µ, ctx, ctx, ¬µ, (ctx, Ken, Ken, Ctx, Cape, _ctx, .ctx, ctx, Œº, _CTX, ÂçóÈùû, context, CTX, Kenya, Œº, context\nMLP.v27\n2240\nblack, Èªë, black, Black, Black, ÈªëËâ≤, -black, BLACK, BLACK, _black, blacks, .black, /black, „Éñ„É©„ÉÉ„ÇØ, .Black, Èªë, ÈªëÁôΩ, _BLACK, blacklist\nMLP.v27\n16596\nKen, Ken, ËÇØ, Nam, Liber, Bot, Tanz, Burk, Bur, Chad, ken, Ëµû, Nam, Kenya, Ug, Jordan, ken, Maur, Per, Jordan\nMLP.v26\n18261\nÈªë, black, black, ÈªëËâ≤, Black, -black, Black, _black, .black, dark, Èªë, BLACK, /black, ÈªëÊöó, blacks, .Black, BLACK, ƒëen, darken\nMLP.v26\n1091\nÈªë, black, ÈªëËâ≤, Black, Black, black, -black, BLACK, BLACK, /black, blacks, _black, dark, Blacks, Dark, blacklist, ÈªëÊöó, Èªë, .Black\nMLP.v25\n10230\nAf, af, ÈùûÊ¥≤, Af, African, slave, AF, Africans, AF, african, slavery, Â•¥Èö∂, Â•¥, slaves, Slave, slave, Afro, Slave, Africa, afr\nMLP.v25\n10739\nÈùûÊ¥≤, African, Africa, Africa, Africans, african, Ghana, Nigerian, Nigeria, afr, Kenya, Nairobi, Niger, -Saharan, Nd, Tanzania, Uganda, africa, Nz, Lagos\nMistral-7B\nWhite\nMLP.v32\n1606\nEngland, France, Europe, Switzerland, Britain, Holland, Spain, Australia, Espa√±a, Austria, Germany, Denmark, Francia, Canada, Europa, America, Wales, Deutschland, Belgium, Sweden\nMLP.v32\n12760\n‚Ç¨, ‚Ç¨, Finn, Mediterranean, Belgium, Italy, Finland, Belg, Luxem, Netherlands, Milan, Italian, Portugal, Denmark, Czech, Madrid, Norway, Sweden, Spain, Amsterdam\nMLP.v32\n9831\nEuropean, Eu, Europe, Europe, EU, eu, Europ, Euro, europe, eu, Europa, europ, –ï–≤—Ä–æ, urope, UEFA, ‚Ç¨, urop, Ôøø, ‚Ç¨, –≤—Ä–æ\nMLP.v30\n1521\nPennsylvania, Michigan, Kansas, Philadelphia, Verm, ahl, Detroit, rus, –Ω–∏–∫–∏, zel, Vic, Buc, ru, dispos, Hein, gotta, xa, una, anne, onic\nAsian\nMLP.v32\n4453\nJapanese, Korean, Kol, Japan, Kor, Kaz, Sak, Taiwan, Korea, Nak, Kur, Kom, Bangl, Pakistan, Kab, Kon, Pak, Tibet, Ku, Asian\nMLP.v31\n2346\nJapanese, anime, Japan, Tokyo, jap, Jap, Korean, oji, apan, Tok, Asian, Taiwan, Israeli, Chinese, Korea, Indones, aku, Viet, Sak, oshi\nMLP.v30\n2137\nWil, mal, Mal, Ker, Mal, mal, Malays, Malaysia, ker, <\\, $\\, -\\, $|\\, Carm, ($\\, /\\, mals, -\\, +\\, >\\\nMLP.v30\n8986\nasis, asi, Ash, lic, ox, Asia, yk, ke, ash, ym, as, ass, Async, asia, ais, eper, ob, ash, ek\nBlack/AA\nMLP.v32\n5923\nBlack, black, Black, black, blacks, Èªë, \u0000, Negro, BL, blk, African, BL, —á–µ—Ä, Afr, Dark, —á, dark, –ß–µ—Ä, –ª–µ–∫, \u0000MLP.v31\n8715\nAfrican, Africa, Afr, Niger, Af, frica, Kenya, Af, Nigeria, fr, Negro, af, Afghan, blacks, FR, airo, Caribbean, Johannes, ‚Ç¶, Jama\nMLP.v30\n3398\nAfrican, Africa, Afr, Af, Af, Asian, fr, Niger, Aaron, Afghan, Kenya, frica, af, AF, Mexican, AF, European, Nigeria, af, Egyptian\nMLP.v30\n12572\nBlack, black, Black, black, blacks, Èªë, BL, \u0000, BL, Negro, blk, —á–µ—Ä, dark, African, Afr, \u0000, –ª–µ–∫, dark, –ß–µ—Ä, —á\nMLP.v29\n13186\nblack, black, Black, blacks, Black, white, Èªë, white, whites, African, \u0000, Negro, ÁôΩ, Afr, White, White, BL, —á–µ—Ä, Af, brown\nLlama-3.1-8B\nWhite\nMLP.v31\n9094\nWhite, white, White, white, WHITE, -white, ÁôΩ, WHITE, _white, .White, whites, ÁôΩ, .white, _WHITE, Whites, beyaz, :white, tr·∫Øng,. ,ÿ≥ŸÅ€åÿØWHITE\nAsian\nMLP.v32\n5691\nChinese, China, Chinese, China, chinese, china, -China, Beijing, ‰∏≠ÂõΩ, √áin, \u0000\u0000, Shanghai, ‰∏≠Âúã, china,,⁄Ü€åŸÜ‰∏≠ÂõΩ, Zhang, Jiang, Tencent, Guang\nMLP.v31\n14299\nLi, yuan, Dong, Huang, Liu, Wang, Chen, Yang, Tian, Zhou, Ding, Wu, dong, dong, Feng, wang, Zhang, Qin, Jiang, Guang\nMLP.v29\n5272\nAsia, Asia, Asian, Asian, asia, continent, Africa, continental, asian, Africa, asia, Asians, Continental, ‰∫öÊ¥≤, Asi, Europe, Continent, Latin, asi, Europe\nBlack/AA\nMLP.v30\n7195\nMississippi, Jamaica, Jama, Caribbean, Louisiana, Trinidad, Haiti, LSU, Ghana, Hait, Baton, Harlem, Nigeria, negro, Negro, Jazz, Bahamas, Memphis, Nigerian, Zimbabwe\nMLP.v30\n3868\nblack, Black, BLACK, Black, black, /black, BLACK, -black, Èªë, blacks, _black, .Black, blacklist, \u0000, Blacks, .black, Èªë, Blackburn, _BLACK, blackout\nMLP.v29\n13826\nAfrican, african, Africans, Africa, Africa, afr, Afro, Afr, frican, negro, Af, Afrika, Af, africa, Negro, blacks, black, af, frica, Blacks\nMLP.v29\n6824\ntropical, jungle, Tropical, Jungle, jung, ropical, trop, Fiji, Belize, mango, Congo, Jama, Caribbean, Hait, Honduras, Mango, BSON, Haiti, Safari, Jamaica\nTable 16: Full list of race-encoding neurons identified from C-REACT direct mentions.\nTranslations: Ëã±ÂõΩ(UK), Ê≥ïÂõΩ\n(France), ÊÑèÂ§ßÂà©(Italy), Ëç∑ÂÖ∞(Netherlands), Âæ∑ÂõΩ(Germany), Ê¨ßÊ¥≤(Europe), ‰∏áÊ¨ßÂÖÉ(ten-thousand euros), „Éâ„Ç§„ÉÑ(Germany), Ê¨ßÁõü(EU), Ê¨ßÂÖÉ(euro), ÁëûÂ£´\n(Switzerland), Ê¨ß(Europe), Âú∞‰∏≠Êµ∑(Mediterranean), Â∏åËÖä(Greece), ÁΩóÈ©¨(Rome), Ê©°(oak), È®∞(soar), ·ª™(yes), ÊØîÂà©Êó∂(Belgium), Ôøø(subsetneq), Á§∫(show), Ë•øÁè≠\nÁâô(Spain), Âú®Êó•Êú¨(in Japan), Êó•Êú¨(Japan), Êó•Êú¨‰∫∫(Japanese), ‰∏ú‰∫¨(Tokyo), \u0000\u0000 (Japan), Êó•ÂÜõ(Japanese army), Nh·∫≠t (Japan), Êó•Êú¨„ÅÆ(Japan), ‰π†(Xi), Áøí(Xi),\nÊÉØ(habit), ‰π†ÊÉØ(habit), ÁöÑ‰π†ÊÉØ(habit), ÁøíÊÖ£(habit), ‰π†ËøëÂπ≥(Xi Jinping), ‰π†ÊÉØ‰∫Ü(used to), ÊÖ£(habit), ‰π†Ëøë(Xi-), ÊÉØ‰æã(convention), ‰π†‰øó(custom), ‰π†ËøëÂπ≥ÊÄª\n(Xi Jinping), ÊÄª‰π¶ËÆ∞(general secretary), ‰∫öÊ¥≤(Asia), Âç∞Â∫¶(India), ‰∏≠Âúã(China), ‰∫ö(Asia), ‰∫û(Asia), ‰∫öÂ§™(Asia-Pacific), ‡πÄ‡∏≠‡πÄ‡∏ä(Asia), ‰∏ú‰∫ö(East Asia), Ê¨ßÊ¥≤\n(Europe), ÈùûÊ¥≤(Africa), Êãâ‰∏Å(Latin), ‰∏úÂçó‰∫ö(Southeast Asia), ÁæéÊ¥≤(Americas), „Ç¢„Ç∏„Ç¢(Asia), ‰∏≠ÂõΩ(China), ‰∏≠ÂõΩÁöÑ(China), \u0000\u0000 (China),( ÿßŸÑÿµŸäŸÜChina), Âú®\n‰∏≠ÂõΩ(China), ÊòØ‰∏≠ÂõΩ(China), Áî±‰∏≠ÂõΩ(China), ÁßçÊóè(race), ÂçóÈùû(South Africa), Èªë(black), ÈªëËâ≤(black), „Éñ„É©„ÉÉ„ÇØ(black), Èªë(black), ÈªëÁôΩ(black-and-white),\nËÇØ(Ken), Ëµû(praise), ÈªëÊöó(dark), ƒëen (black), ÈùûÊ¥≤(Africa), Â•¥Èö∂(slave), Â•¥(slave), –ï–≤—Ä–æ (Euro), Ôøø(Euro), –≤—Ä–æ (Euro), –Ω–∏–∫–∏ (niki), \u0000 (black), —á–µ—Ä (black), —á (ch),\n–ß–µ—Ä (black), –ª–µ–∫ (lek), \u0000 (black), ÁôΩ(white), beyaz (white), tr·∫Øng (white),( ÿ≥ŸÅ€åÿØwhite), ‰∏≠ÂõΩ(China), ‰∏≠Âúã(China),( ⁄Ü€åŸÜChina), √áin (China), \u0000\u0000 (China),\n‰∫öÊ¥≤(Asia).\n13\n"}, {"page": 14, "text": "Model\nGroup\nNeuron\nTop 20 Tokens\nQwen2.5-7B\nWhite\nMLP.v28\n8780\nMaryland, Pennsylvania, Baltimore, Ohio, Wisconsin, Maine, Minnesota, Illinois, Pittsburgh, Iowa, Ohio, Connecticut, Philadelphia, Chicago, Michigan, Milwaukee, Nebraska, Detroit, Seattle, Ê±üËãèÁúÅ\nMLP.v28\n9988\n‰ª•Ëâ≤Âàó, Israel, Jerusalem, Israel, Israeli, Noah, Hebrew, Zion, Moses, -Israel, Palestine, Israeli, Israelis, Biblical, biblical, Zionist, Luke, Palestinian, Jer, Nathan\nMLP.v28\n4318\nOhio, Columbus, sz, Cleveland, Ohio, (sz, sz, ÊµôÊ±ü, Êù≠Â∑û, Sz, Sz, Êµô, ÊµôÊ±üÁúÅ, Êù≠Â∑ûÂ∏Ç, SZ, Cincinnati, Êù≠, _sz, Akron, Croatian\nMLP.v27\n17660\nGerman, ‰∏áÊ¨ßÂÖÉ, „Éâ„Ç§„ÉÑ, Âæ∑ÂõΩ, German, Germany, Germans, EU, Ëç∑ÂÖ∞, euro, ‚Ç¨, Ê¨ßÁõü, Germany, Swiss, Ê¨ßÂÖÉ, Euro, Dutch, ÁëûÂ£´, Ê¨ß, Switzerland\nMLP.v26\n3012\nÁäπ, Jew, Jewish, Áå∂, Jews, Judaism, –µ–≤, jewish, Juda, Hebrew, –µ–≤—Ä, ‰ª•Ëâ≤Âàó, Israel, kosher, synagogue, -J, ewish, jew, Rabbi, Israeli\nMLP.v26\n3382\n‰øÑ, Rus, Russ, RU, rus, Russians, Russ, Russia, Russian, russe, ‰øÑÁΩóÊñØ, russ, Russo, ‰øÑÂõΩ, Ëé´ÊñØÁßë, Mos, Russia, Moscow, -Russian, RU\nMLP.v25\n4157\nUEFA, Âú∞‰∏≠Êµ∑, Mediterranean, Cyprus, Pane, Roman, Ê¨ßÁõü, Euro, Roman, chalk, Â∏åËÖä, Europe, UES, Rom, ÁΩóÈ©¨, EU, Kn, Europe, Ê©°, È®∞\nMLP.v25\n5123\nUkraine, ‰πå, ‰πåÂÖãÂÖ∞, Russia, Ukrainian, Russian, ‰øÑÁΩóÊñØ, Ukrain, ÁÉè, ‰πåÂÖã, Russia, war, Russian, -Russian, ÂÜ≤Á™Å, russian, Russo, Conflict, conflict, Âú∞\nAsian\nMLP.v28\n13406\nÂú®Êó•Êú¨, Japanese, Êó•Êú¨, Japanese, Japan, Japan, Êó•Êú¨‰∫∫, Tokyo, japan, ‰∏ú‰∫¨, \u0000\u0000, Êó•ÂÜõ, japanese, japon, Nh·∫≠t, Tok, Hiro, Êó•Êú¨„ÅÆ, Osaka, jap\nMLP.v27\n6943\nAsian, Asian, ‰∫öÊ¥≤, Asia, Chinese, Asia, Chinese, China, Âç∞Â∫¶, Indian, India, India, Asians, China, Indian, chinese, ‰∏≠Âúã, Oriental, Japanese, asian\nMLP.v27\n229\nM√£, Opcode, (equalTo, Singapore, Singapore, ‚Äô).‚Äù, wiƒô, (defvar, ,tp, –õ–∞, –ù–æ–≤–æ, yne, (ls, Tah, Êµ∑Âçó, √©tablissement, airobi, √é, Êßü\nMLP.v26\n9908,ÿßŸÑÿ•ÿ´ŸÜ ,ÿßŸÑÿ´ÿßŸÑMalays, Indones, protester, HttpMethod, Zambia,,ÿßŸÑÿ¨ŸáÿßRodrig, Taiwanese, Ëæá, Jama, Âä†Â∑•ÂéÇ,,ÿßŸÑÿßÿ≥ÿ™ÿ´Karnataka, UserDao, Rousse, B√∂l, african\nMLP.v26\n13889\nchop, Conf, Mand, Canton, ÂäüÂ§´, mand, Dragon, Chop, Dragon, Conf, mand, dragon, Cant, dragon, Fu, Portsmouth, Bruce, Cath, Ê¥óË°£, Fuk\nMLP.v25\n2001\nË∂ä, Vietnam, Ë∂äÂçó, Viet, Nguyen, Viet, Vietnamese, .vn, Ho, Ph, Vu, Tran, viet, Â∞±Ë∂ä, Ph, Dien, Ë∂äÂ§ß, Ë∂äÂ•Ω, anh, gia\nMLP.v25\n15029\nChinese, China, China, Chinese, chinese, china, china, ‰∏≠ÂõΩ, ‰∏≠ÂõΩÁöÑ, -China, \u0000\u0000,,ÿßŸÑÿµŸäŸÜ‰∏≠Âúã, Asian, Âú®‰∏≠ÂõΩ, ÊòØ‰∏≠ÂõΩ, ‰∫öÊ¥≤, Áî±‰∏≠ÂõΩ, Asian, Asia\nBlack/AA\nMLP.v25\n10230\nAf, af, ÈùûÊ¥≤, Af, African, slave, AF, Africans, AF, african, slavery, Â•¥Èö∂, Â•¥, slaves, Slave, slave, Afro, Slave, Africa, afr\nMLP.v25\n10739\nÈùûÊ¥≤, African, Africa, Africa, Africans, african, Ghana, Nigerian, Nigeria, afr, Kenya, Nairobi, Niger, -Saharan, Nd, Tanzania, Uganda, africa, Nz, Lagos\nMistral-7B\nWhite\nMLP.v32\n2399\nRussian, Vlad, Moscow, Soviet, Russia, Ukrain, Russians, Ukraine, Czech, Ukr, Bulgar, Slov, vod, Cz, Aleks, Serge, sov, russ, Polish, Stalin\nMLP.v31\n7356\nRussell, Rus, Russ, Russian, rus, Russia, russ, Russians, Soviet, Moscow, —Ä—É—Å, rust, rus, rust, —Ä—É, sov, Rug, Rud, ruin, Ruth\nMLP.v30\n4487\nRussell, Russ, russ, Russian, Rus, Russia, Russians, rus, rus, Moscow, —Ä—É—Å, –†–æ—Å—Å–∏, –†–æ—Å—Å–∏–∏, uss, Soviet, ussia, ussian, Vlad, USS, sov\nMLP.v29\n260\nItalian, Ital, Italy, ital, italien, Italia, italiano, ital, Giovanni, Francesco, Carlo, Gian, Sic, Gi, IT, Milan, Serie, acci, Giov, IT\nBlack/AA\nMLP.v31\n8715\nAfrican, Africa, Afr, Niger, Af, frica, Kenya, Af, Nigeria, fr, Negro, af, Afghan, blacks, FR, airo, Caribbean, Johannes, ‚Ç¶, Jama\nLlama-3.1-8B\nWhite\nMLP.v32\n10606\nRussian, Russians, Russia, Russian, Moscow, Soviet, Russia, -Russian, Putin, russ, russian, Kremlin, ‰øÑ, russe, Russ, USSR, Russell, .ru, Vladimir, Sergei\nMLP.v32\n10409\nBaltic, Sloven, Celtic, Gron, Flem, Slovenia, Austria, Sch, Luxembourg, Monaco, Gros, Croatia, Naples, Blond, Croatian, Baron, Austrian, Mont, Trent, Malta\nMLP.v31\n12584\nRussell, Russ, Russ, Rus, RUS, Rus, russ, rus, Russo, Russia, Russian, Rusya, ‰øÑ, Russians, –†—É—Å, -Russian, rus, Russia, russe, Russian\nMLP.v29\n4193\nCzech, Hungarian, Boh, Slovak, Budapest, Hungary, Hung, Slovakia, Prague, Poland, polish, Polish, Sloven, Croatian, Krak, lovak, Brno, Slovenia, Romania, Croatia\nAsian\nMLP.v32\n5691\nChinese, China, Chinese, China, chinese, china, -China, Beijing, ‰∏≠ÂõΩ, √áin, \u0000\u0000, Shanghai, ‰∏≠Âúã, china,,⁄Ü€åŸÜ‰∏≠ÂõΩ, Zhang, Jiang, Tencent, Guang\nMLP.v32\n6950\nBhar, Bh, Sinh, Nagar, Shah, Muk, Hindi, Allah, Tamil, Gujar, Bollywood, Kh, Dh, Gujarat, Punjab, Kh, Mumbai, Uttar, Maharashtra, Jain\nMLP.v29\n10616\nIndian, Indian, Indians, India, indian, India, india, ·∫§n, Bollywood,,ÿßŸÑŸáŸÜÿØIndi, Indianapolis, Mumbai, Ôøø, Hindu, Bombay, Hindi, Hindus, Âç∞, Delhi\nBlack/AA\nMLP.v30\n7195\nMississippi, Jamaica, Jama, Caribbean, Louisiana, Trinidad, Haiti, LSU, Ghana, Hait, Baton, Harlem, Nigeria, negro, Negro, Jazz, Bahamas, Memphis, Nigerian, Zimbabwe\nMLP.v29\n6824\ntropical, jungle, Tropical, Jungle, jung, ropical, trop, Fiji, Belize, mango, Congo, Jama, Caribbean, Hait, Honduras, Mango, BSON, Haiti, Safari, Jamaica\nMLP.v29\n13826\nAfrican, african, Africans, Africa, Africa, afr, Afro, Afr, frican, negro, Af, Afrika, Af, africa, Negro, blacks, black, af, frica, Blacks\nTable 17: Full list of race-encoding neurons identified from C-REACT indirect mentions (language/country). Trans-\nlations: Ê±üËãèÁúÅ(Jiangsu), ‰ª•Ëâ≤Âàó(Israel), ‰∏áÊ¨ßÂÖÉ(ten-thousand euros), „Éâ„Ç§„ÉÑ(Germany), Âæ∑ÂõΩ(Germany), Ëç∑ÂÖ∞(Netherlands), Ê¨ßÁõü(EU), Ê¨ßÂÖÉ(euro), ÁëûÂ£´\n(Switzerland), Ê¨ß(Europe), Áäπ(Jew), Áå∂(Jew), –µ–≤ (Jew), –µ–≤—Ä (Jew), ‰øÑ(Russia), ‰øÑÁΩóÊñØ(Russia), ‰øÑÂõΩ(Russia), Ëé´ÊñØÁßë(Moscow), Âú∞‰∏≠Êµ∑(Mediterranean), Â∏å\nËÖä(Greece), ÁΩóÈ©¨(Rome), Ê©°(oak), È®∞(soar), ‰πå(Ukraine), ‰πåÂÖãÂÖ∞(Ukraine), ÁÉè(Ukraine), ‰πåÂÖã(Ukraine), ÂÜ≤Á™Å(conflict), Âú∞(land), Âú®Êó•Êú¨(in Japan), Êó•\nÊú¨(Japan), Êó•Êú¨‰∫∫(Japanese), ‰∏ú‰∫¨(Tokyo), \u0000\u0000 (Japan), Êó•ÂÜõ(Japanese army), Nh·∫≠t (Japan), Êó•Êú¨„ÅÆ(Japan), ‰∫öÊ¥≤(Asia), Âç∞Â∫¶(India), ‰∏≠Âúã(China), M√£\n(code), wiƒô (bond), –õ–∞ (La), –ù–æ–≤–æ (Novo), Êµ∑Âçó(Hainan), Êßü(Penang), √é (I),( ÿßŸÑÿ´ÿßŸÑTue),( ÿßŸÑÿ•ÿ´ŸÜMon),( ÿßŸÑÿ¨Ÿáÿßjihad),( ÿßŸÑÿßÿ≥ÿ™ÿ´exception), Ëæá(carriage), Âä†Â∑•ÂéÇ\n(factory), B√∂l (region), ÂäüÂ§´(kung fu), Ê¥óË°£(laundry), Ë∂ä(Viet), Ë∂äÂçó(Vietnam), Â∞±Ë∂ä(then more), Ë∂äÂ§ß(bigger), Ë∂äÂ•Ω(better), ‰∏≠ÂõΩ(China), ‰∏≠ÂõΩÁöÑ(China),\n\u0000\u0000 (China),( ÿßŸÑÿµŸäŸÜChina), Âú®‰∏≠ÂõΩ(China), ÊòØ‰∏≠ÂõΩ(China), Áî±‰∏≠ÂõΩ(China), ÈùûÊ¥≤(Africa), Â•¥Èö∂(slave), Â•¥(slave), —Ä—É—Å (Russian), —Ä—É (ru), –†–æ—Å—Å–∏ (Russia),\n–†–æ—Å—Å–∏–∏ (Russia), italiano (Italian), italien (Italian), Italia (Italy), ·∫§n (India),( ÿßŸÑŸáŸÜÿØIndia), Âç∞(India).\n14\n"}]}