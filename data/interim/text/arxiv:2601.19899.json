{"doc_id": "arxiv:2601.19899", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2601.19899.pdf", "meta": {"doc_id": "arxiv:2601.19899", "source": "arxiv", "arxiv_id": "2601.19899", "title": "Evaluation of Oncotimia: An LLM based system for supporting tumour boards", "authors": ["Luis Lorenzo", "Marcos Montana-Mendez", "Sergio Figueiras", "Miguel Boubeta", "Cristobal Bernardo-Castineira"], "published": "2026-01-27T18:59:38Z", "updated": "2026-01-27T18:59:38Z", "summary": "Multidisciplinary tumour boards (MDTBs) play a central role in oncology decision-making but require manual processes and structuring large volumes of heterogeneous clinical information, resulting in a substantial documentation burden. In this work, we present ONCOTIMIA, a modular and secure clinical tool designed to integrate generative artificial intelligence (GenAI) into oncology workflows and evaluate its application to the automatic completion of lung cancer tumour board forms using large language models (LLMs). The system combines a multi-layer data lake, hybrid relational and vector storage, retrieval-augmented generation (RAG) and a rule-driven adaptive form model to transform unstructured clinical documentation into structured and standardised tumour board records. We assess the performance of six LLMs deployed through AWS Bedrock on ten lung cancer cases, measuring both completion form accuracy and end-to-end latency. The results demonstrate high performance across models, with the best performing configuration achieving an 80% of correct field completion and clinically acceptable response time for most LLMs. Larger and more recent models exhibit best accuracies without incurring prohibitive latency. These findings provide empirical evidence that LLM- assisted autocompletion form is technically feasible and operationally viable in multidisciplinary lung cancer workflows and support its potential to significantly reduce documentation burden while preserving data quality.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2601.19899v1", "url_pdf": "https://arxiv.org/pdf/2601.19899.pdf", "meta_path": "data/raw/arxiv/meta/2601.19899.json", "sha256": "b9b435ebed57c3e03854369da1d3fc453ce678224a310fad64a7e896a4e8235e", "status": "ok", "fetched_at": "2026-02-18T02:20:18.882325+00:00"}, "pages": [{"page": 1, "text": "EVALUATION OF ONCOTIMIA: AN LLM-BASED SYSTEM FOR\nSUPPORTING TUMOUR BOARDS\nTECHNICAL REPORT\nLuis Lorenzo1, Marcos Montaña-Méndez1, Sergio Figueiras1, Miguel Boubeta1,∗, Cristóbal Bernardo-Castiñeira1,∗\n1 Innovation Department, Bahía Software SLU, Ames (A Coruña), Spain\n∗Corresponding author(s): miguel.boubeta@bahiasoftware.es, cristobal.bernardo@bahiasoftware.es\nJanuary 28, 2026\nABSTRACT\nMultidisciplinary tumour boards (MDTBs) play a central role in oncology decision-making but require\nmanual processes and structuring large volumes of heterogeneous clinical information, resulting in\na substantial documentation burden. In this work, we present ONCOTIMIA, a modular and secure\nclinical tool designed to integrate generative artificial intelligence (GenAI) into oncology workflows\nand evaluate its application to the automatic completion of lung cancer tumour board forms using large\nlanguage models (LLMs). The system combines a multi-layer data lake, hybrid relational and vector\nstorage, retrieval-augmented generation (RAG) and a rule-driven adaptive form model to transform\nunstructured clinical documentation into structured and standardised tumour board records. We assess\nthe performance of six LLMs deployed through AWS Bedrock on ten lung cancer cases, measuring\nboth completion form accuracy and end-to-end latency. The results demonstrate high performance\nacross models, with the best performing configuration achieving an 80% of correct field completion\nand clinically acceptable response time for most LLMs. Larger and more recent models exhibit best\naccuracies without incurring prohibitive latency. These findings provide empirical evidence that LLM-\nassisted autocompletion form is technically feasible and operationally viable in multidisciplinary\nlung cancer workflows and support its potential to significantly reduce documentation burden while\npreserving data quality.\nKeywords GenAI · LLMs · Vector database · Embeddings · RAG · Tumour boards · Lung cancer form autocompletion\n1\nIntroduction\nIn recent years, advances in transformer-based architectures have firmly established LLMs as a foundational technology\nin biomedical informatics. Early developments in general-purpose LLMs (e.g., GPT-3 and its successors) revealed\nemergent capabilities in clinical summarisation, question answering, report generation, coding support and contextual\nreasoning (Brown et al., 2020). Subsequent work has shown that domain-adapted models, such as BioGPT (Luo\net al., 2022), BioMedLM, PubMedBERT (Gu et al., 2021) and Med-PaLM (Singhal et al., 2023), achieve expert-\nlevel performance on diverse medical reasoning benchmarks. An expanding evidence base further demonstrates\nthat LLMs can reliably extract salient clinical information and support guideline-informed recommendations when\ndeployed with appropriate safeguards. Recent prospective evaluations in hospital settings indicate that LLM-assisted\nclinical documentation can meaningfully reduce clinician workload while maintaining high linguistic quality (Bracken\net al., 2025; Nori et al., 2023). Nevertheless, these systems continue to require rigorous oversight owing to risks of\nhallucinations, incomplete contextualisation and occasional misinterpretation of clinical guidelines.\nIn medicine, multidisciplinary management (MDM) offers cancer patients the advantage of having specialists from\ndifferent medical fields collaboratively involved in treatment planning. This approach is usually implemented through\nmultidisciplinary clinics, such as breast units, where various experts assess patients, perform physical examinations,\nrequest and conduct diagnostic tests efficiently, and jointly evaluate potential treatment options. MDM is also conducted\nthrough multidisciplinary tumour board (MDTB) meetings, which are structured sessions in which all relevant patient\narXiv:2601.19899v1  [cs.CL]  27 Jan 2026\n"}, {"page": 2, "text": "information is collected, and key specialists convene to discuss the diagnosis and management of cancer patients\n(El Saghir et al., 2014). However, studies show that clinicians spend significant effort managing and analysing\ninformation within electronic health records (EHRs), reducing the time for direct patient care, especially in high-\ncomplexity fields such as oncology (Arndt et al., 2017). MDTBs are particularly affected because each case requires the\npreparation of standardised summaries, structured staging information, pathology details, radiological interpretations,\nbiomarker data, allergy profiles and records of prior treatment, demands that are specially challenging in settings with\nlimited staff resources. The fragmentation of data across narrative notes, laboratory systems, pathology platforms and\nPACs often results in manual information retrieval and redundant re-entry of variables into MDTB case forms.\nAutomating pieces of this workflow is therefore both operationally compelling and clinically relevant. Early efforts\nusing traditional natural language processing (NLP) methods demonstrated benefit in extracting structured information\nfrom radiology or pathology reports (Wang et al., 2018). The transition from rule-based NLP to LLM-enabled generative\nsystems, in addition to extracting information, also allows it to be synthesised into coherent drafts aligned with medical\nguidelines.\nAutocompletion in clinical documentation has emerged as a promising application of LLMs. Initial experiments in\ngeneral EHR contexts have shown that LLMs can assist with automatic drafting of the main complaints, suggesting\nphrasing for assessment and plan sections, and generating templated texts conditioned on structured inputs Ayers et al.\n(2023). These systems have demonstrated that LLM-driven autocompletion improves efficiency and reduces repetitive\ntyping. However, studies explicitly examining autocompletion for oncology MDTB forms remain extremely limited.\nTo date, most published work in oncology has focused on information extraction (e.g., stage from clinical notes) or\nsummarisation of radiology reports. Some recent pilot studies have explored the use of LLMs to generate oncology\ncase summaries or harmonise staging descriptions Chen et al. (2025), but standardised autocompletion of MDTB forms,\nparticularly in lung cancer, has not yet been rigorously evaluated in prospective settings. This represents a critical\nevidence gap given the structured, repetitive and data-dense nature of these forms and their importance in treatment\ndecision making.\nLung cancer has been one of the earliest and most active oncology domains for AI research due to the abundance of\nimaging, molecular data and clinical texts. NLP and deep learning models have been applied to staging extraction,\nbiomarker result interpretation, automatic radiology summarisation and automated assessment of eligibility for targeted\ntherapy or clinical trials (Esteva et al., 2019; Hu et al., 2021; Aldea et al., 2025).\nIn this work, our objective is to describe and technically evaluate the performance of ONCOTIMIA, a modular and\nsecure LLM-based tool that integrates RAG and a rule-driven adaptive form model to automate the completion of lung\ncancer tumour board forms. We assess its performance in a realistic tumour board setting, using synthetic but clinically\nrepresentative cases. Six state-of-the-art LLMs are evaluated in terms of form-completion accuracy and end-to-end\nlatency. Through this study, we aim to provide empirical evidence on the technical and operational feasibility of\nGenAI-assisted autocompletion within oncology workflows, and to demonstrate its potential to reduce documentation\nburden while maintaining data quality.\nThe following Section 2 introduces the ONCOTIMIA platform, outlining its architecture, data ingestion pipeline, and\nthe design of lung cancer data schema. Section 3 summarises the methodology for generating medical data records, the\nRAG workflow and the selection criteria for LLMs. Section 4 reports the performance evaluation results, and Section 5\nconcludes by highlighting key findings, limitations, and directions for future work.\n2\nONCOTIMIA tool description\nONCOTIMIA is a modular system that integrates generative AI to support tumour board workflows and reduce\ndocumentation burden. Its core functionality focuses on the automatic autocompletion of standardised tumour board\nforms and the generation of structured patient summaries from heterogeneous clinical sources. The system also\nincorporates information retrieval and RAG-assisted reasoning modules to facilitate case preparation; these features are\nintended to support review and do not replace clinical judgment. In this section, we present the system architecture and\nclinical data ingestion process and the definition of lung cancer form used in tumour boards committee workflows.\n2.1\nSystem architecture\nThe architecture of ONCOTIMIA has been conceived as a modular, scalable, and secure infrastructure designed to enable\nthe seamless integration of GenAI into oncology workflows. Its design adheres to the principles of interoperability,\ntraceability, maintainability, and controlled evolution, thereby ensuring long-term sustainability in complex clinical\nenvironments undergoing continuous technological transformation. From a conceptual standpoint, the ONCOTIMIA\narchitecture (see Figure 1 for more details) is structured around a set of interconnected yet decoupled modules that\n2\n"}, {"page": 3, "text": "operate in a coordinated manner through standardised interfaces and secure communication protocols. This modular\narrangement enables the independent evolution of system components and the incremental incorporation of new\nfunctionalities without compromising overall system stability.\nFigure 1: ONCOTIMIA architecture. (i) Data ingestion layer, (ii) storage subsystem, (iii) backend services, (iv) LLM\nabstraction layer and (v) reverse proxy.\nIts design principles emphasise interoperability, traceability, maintainability and controlled evolution, ensuring robust-\nness in complex clinical environments undergoing continuous technological change. The ONCOTIMIA architecture\nis structured into five core modules: (i) data ingestion layer, (ii) storage subsystem, (iii) backend services, (iv) LLM\nabstraction layer and (v) reverse proxy.\nThe ingestion layer serves as the system’s entry point, acquiring and validating data from heterogeneous clinical sources,\nincluding electronic health records, structured and unstructured reports, laboratory results and administrative datasets.\nIt implements automated pipelines for extraction, cleaning and normalisation to guarantee data quality and consistency\nprior to downstream processing. The use of mature data-engineering ecosystems enables reproducible, auditable and\nstandard-compliant ingestion workflows, with native support for healthcare interoperability standards. The storage\nsubsystem provides persistent, secure and traceable management of clinical data. ONCOTIMIA adopts a multilayered\ndata lake structure comprising: (1) a landing layer for preserving source data in native formats, (2) a staging layer where\ndata are transformed into analytically consistent representations, and (3) a refined layer optimised for high-performance\nqueries and GenAI-driven retrieval tasks. The refined layer integrates both relational storages, suited for structured\nclinical variables, and vector databases supporting semantic search and embedding-based retrieval. The backend, built\naround a microservices paradigm, encapsulates the business logic required to support core tumour-board use cases. Key\nfunctionalities include:\n• Automatic summarisation of clinical histories, combining structured and unstructured inputs.\n• Autocompletion of tumour-specific forms, converting narrative text into semantically normalised representa-\ntions aligned with oncology terminologies.\n• A clinical assistant module, enabling question answering, hypothesis exploration and guideline-informed\ndecision support.\nAn intermediate abstraction layer mediates interactions between backend services and LLMs. It translates clinical\nrequests into model-compliant queries, enforces safety and audit constraints and standardises output formatting. This\nlayer enables model interchangeability and facilitates the integration of retrieval components and domain-specific\nknowledge bases. A reverse proxy manages traffic routing across system components. It enforces security policies, load\nbalancing and rate limiting, while supporting real-time monitoring and audit logging. This layer ensures controlled and\nsecure exposure of services to external and internal clients.\n3\n"}, {"page": 4, "text": "2.2\nData ingestion and ETL processes\nThe clinical data ingestion process constitutes the entry point of the data processing pipeline and relies on a data\nlake architecture designed to efficiently and securely manage the heterogeneity of hospital information sources.\nThis infrastructure supports the integration of both structured data (e.g., administrative records, laboratory results,\ndemographic variables) and unstructured data (e.g., radiological reports, medical notes, clinical guidelines, oncology\nprotocols, and supplementary documentation). The primary objective of this ingestion layer is to ensure complete\npreservation of the original content while enforcing quality-control mechanisms, format validation, and metadata\ngeneration to maintain full traceability of the information flow.\nThe data lake is organised into three functional layers (landing, staging and refined) which reflect the progressive\ntransformation of data from raw inputs to curated, analysis-ready outputs (see Figure 1 for more details). Documents\nreceived from hospital information systems or authorised external sources are stored in the landing layer, maintaining\ntheir original formats (e.g., .pdf, .docx or .txt) to preserve auditability and end-to-end traceability.\nData stored in the landing layer feeds a set of sequential ETL (Extract, Transform and Load) processes implemented\nin Python, which constitute the operational backbone of the pipeline. First ETL process validates formats, applies\nintegrity checks, and generates technical metadata during initial ingestion. The second ETL process extracts content\nand metadata from documents into the staging layer using specialised LangChain loaders (e.g., Docx2txtLoader and\nPyPDFLoader), followed by text cleaning (e.g., removal of line breaks or non-informative characters), tokenisation,\nlemmatisation, and stemming. The third and fourth ETL processes populate the refined layer by loading curated\nunstructured data into a vector storage system and structured patient information into a relational database. Unstructured\ntext is encoded as semantic embeddings using the Nomic model and stored in a Qdrant vector store, enabling contextual\nRAG-based pipelines, and AI-assisted reasoning. On the other hand, structured and normalised clinical variables (e.g.,\ndemographics, coded diagnoses, tumour staging, and treatments) are stored in a PostgreSQL database, which serves\nas the analytical source of truth. The coexistence of relational and vectorial storage provides a hybrid integration of\nexplicit clinical knowledge and contextual information derived from language models.\n2.3\nLung cancer form schema\nThe MDTB lung cancer data form is organised into seven blocks, defined as logical units that group multiple questions.\nTransitions between blocks follow a non-linear, rule-based logic, whereby responses to specific questions determine the\nactivation, omission, or redirection of subsequent sections. This adaptive structure allows the form to dynamically adjust\nto individual patient characteristics and the clinical context under evaluation. The form captures key clinical domains,\nincluding demographic information, smoking status and other risk factors, radiological and pathological findings,\nmolecular biomarkers relevant to precision oncology, and prior treatments with their therapeutic intent. The overall\nstructure is anchored by Block 1, which functions as the central node of the form. Block 1 consolidates core clinical\nvariables (risk factors, comorbidities, ongoing medication, diagnostic test results, and detailed tumour profiling), and\nconditionally activates the remaining blocks based on pivotal responses. The main components of this block include:\n• Patient characteristics and medical history: smoking status, comorbidities, allergies and prior malignancies.\n• Functional status and previous therapies: ECOG performance score, radiotherapy or chemotherapy, and\ndocumented treatment refusals.\n• Imaging and endoscopic assessment: free-text summaries of CT, PET-CT, bronchoscopy and other relevant\nprocedures.\n• Histopathological and molecular analysis: tumour histology, molecular biomarkers, PD-L1 expression,\ntumour mutational burden (TMB) and microsatellite status.\n• Tumour staging: standardised categories capturing local, locoregional and systemic disease spread.\nResponses collected in Block 1 conditionally determine the activation of subsequent blocks collected in Table 1,\nenabling an adaptive and patient-specific data collection workflow. A reported history of malignancy activates Block 2\nto capture details of earlier cancer diagnoses. Documentation of treatment refusal triggers Block 3 while indication of\ndisease recurrence activates Block 4 to record affected sites. When a rebiopsy has been performed, Block 5 is enabled\nto document updated histology and molecular markers. A history of radiotherapy activates Block 6, which captures\ntreatment intent, target lesions and timelines, whereas prior systemic therapy triggers Block 7 to document administered\nagents, therapeutic intent and treatment dates. This modular, conditionally driven design ensures that only clinically\nrelevant information is collected for each case, resulting in a structured yet flexible representation of patient data. Such\na context-aware data model supports downstream tasks including LLM-assisted summarisation, retrieval-augmented\nreasoning, and clinical decision support within multidisciplinary tumour board workflows.\n4\n"}, {"page": 5, "text": "Table 1: Description of the content of Blocks 2 to 7 derived from Block 1.\nBlock\nDescription\n2\nPrevious neoplasms\n3\nTreatment refusal\n4\nRecurrence\n5\nRebiopsy and new biomarkers\n6\nRadiotherapy\n7\nChemotherapy\nTable 2 summarises the core clinical variables included in the lung cancer form, organised into thematic sections that\nreflect the logical structure of the oncological assessment process. Each section groups related fields according to their\nclinical meaning and functional role within the data model, while explicitly specifying the corresponding data type to\nensure consistency, interpretability and suitability for downstream computational processing.\nThe medical history section includes key baseline variables that characterise the patient’s background and prior clinical\ncontext. This section records smoking status encoded as a categorical variable with three possible states (smoker,\nnon-smoker and ex-smoker), alongside binary indicators of previous neoplasia and documented treatment refusal. In\naddition, patient medication is represented as a categorical field, allowing for the structured documentation of the\ncurrent medication (e.g., oral anticoagulation, antiplatelet agents, etc.).\nThe performance status section captures the patient’s functional condition through the ECOG performance status core,\nencoded as an integer ranging from 0 (fully active) to 5 (dead). This variable is widely used in oncology to assess a\npatient’s ability to tolerate systemic treatments.\nTable 2: Subset of core clinical fields for the lung cancer form.\nSection\nField\nData type\nMedical history\nSmoking status\nCategorical\nPrevious neoplasia\nBoolean\nTreatment refusal\nBoolean\nPatient medication\nCategorical\nPerformance status\nECOG value\nInteger\nDiagnosis\nLocal location\nCategorical\nLocoregional location\nCategorical\nSystemic location\nCategorical\nHystology type\nCategorical\nMolecular marker\nCategorical\nPD-L1 value\nFloat\nRecurrence\nBoolean\nRebiopsy\nBoolean\nTreatment\nRadiotherapy\nBoolean\nChemotherapy\nBoolean\nThe diagnosis section constitutes the most extensive component of the table and encompasses variables describing\ndisease localisation, pathological characterisation and molecular profiling. Tumour extent is represented through cate-\ngorical fields capturing local, locoregional and systemic involvement (e.g., lung, bone, liver, etc.). Histological tumour\ntype is recorded as a categorical variable, enabling standardised classification of lung cancer subtypes (adenocarcinoma,\nsquamous cell carcinoma, large cell carcinoma and small cell carcinoma). Molecular characterisation is incorporated\nthrough a categorical molecular marker field complemented by a continuous PD-L1 expression value that records\n5\n"}, {"page": 6, "text": "quantitative immunohistochemical values, generally reported as the percentage of tumour cells expressing the marker.\nMolecular biomarkers are encoded as categorical variables that explicitly represent both the presence and absence of\nclinically actionable genomic alterations (e.g., EGFR, ALK, KRAS, BRAF, ROS1, etc.). The section also includes\nBoolean indicators for tumour recurrence and rebiopsy, which are essential for documenting disease evolution and the\navailability of updated pathological or molecular information.\nFinally, the treatment section records prior oncological interventions, specifically radiotherapy and chemotherapy, both\nencoded as Boolean variables. These fields provide a concise representation of previous treatment exposure and serve\nas key triggers for conditional workflows and more detailed treatment-specific documentation elsewhere in the system.\n3\nMaterials and methods\nDue to the highly sensitive nature of patient health data and the strict regulatory constraints governing its use, no\nreal patient records were directly employed in the experimental evaluation of the proposed system. Instead, a fully\nsynthetic dataset was constructed, using as a starting point a real clinical history that had been previously and irreversible\nanonymised in accordance with applicable data protection regulations. This reference case was used exclusively as a\nstructural and narrative template, without retaining any real patient-identifiable or clinically traceable information.\nA total of ten Spanish synthetic clinical histories were generated, reflecting the real operational language of the clinical\nenvironment. Given the exploratory nature of this study and the need to assess the performance of different LLMs under\ncontrolled conditions, this initial experiment was intentionally limited in scope as a proof of concept to future large-scale\ndeployment in real clinical settings. The synthetic cohort was generated using the Qwen3-14b LLM executed locally via\nthe Ollama framework. This choice was motivated by the need to ensure full data governance and prevent any external\ndata leakage. The model was prompted to produce multiple clinically plausible, internally consistent, and representative\nSpanish lung cancer patient histories that reflected the diversity of cases typically discussed in MDTBs, including\nvariations in staging, molecular profiles, prior treatments, and clinical evolution. Following this initial generation phase,\na two-step validation and refinement process was applied to ensure medical coherence and internal consistency. First,\nan automated reflection-based validation step was performed using GPT-OSS-120b model, which was tasked with\ncritically reviewing each synthetic clinical history to detect logical inconsistencies, missing information, temporal\ncontradictions, or medically implausible statements. The model was instructed to either confirm the coherence of the\ncase or propose corrective revisions, which were then applied to the dataset. Second, the resulting synthetic cases were\nsubjected to a final manual review by an expert in oncology, who assessed their clinical plausibility, internal consistency\nand suitability for use in a simulated tumour board setting. Only cases that passed this expert review were included in\nthe final evaluation dataset.\nThis multi-stage process ensures that the resulting dataset, preserves a high degree of clinical realism and complexity,\nmaking it suitable for a meaningful and rigorous assessment of the proposed system, based on a RAG architecture\nspecifically designed for the automatic completion of structured lung cancer tumour board forms from unstructured clin-\nical narratives in Spanish. The architecture integrates three main components: (i) document ingestion and preprocessing\npipeline, (ii) a hybrid storage and retrieval layer, and (iii) an LLM-based generation layer.\nClinical narratives are first segmented, normalised and embedded into a dense vector space using the Nomic embedding\nmodel. These embeddings are stored in a Qdrant database. At inference time, for each target form block, a query is\nconstructed and use to retrieve the most relevant textual fragments from the vector storage. These retrieval contexts are\nthen injected into a structured prompt template together with explicit instructions and the schema of the target form\nfields. This RAG-based approach also enables traceability, as each generated field can be linked back to the specific\nsource fragments that supported it.\nSix LLMs models were selected for the experimental evaluation: GPT-OSS-20b, GPT-OSS-120b, Mistral-large-2402-\nv1, Pixtral-large-2502-v1, Qwen3-32b and Qwen3-next-80b. This set was designed to provide a representative and\nmethodologically sound benchmark across different architectural families, parameter scales, and deployment profiles.\nGPT-OSS-20b and GPT-OSS-120b enable a controlled analysis of the impact of model scale within a single architectural\nlineage, isolating the effect of parameter count on extraction accuracy and reasoning stability. Mistral-Large-2402-v1\nwas included as a strong general-purpose model optimised for long-context understanding and complex reasoning,\nwhich is essential given the length and heterogeneity of the clinical narratives. Pixtral-Large-2502-v1 was selected\nfor its strengths in structured generation and schema-constrained reasoning, which closely match the requirements\nof mapping free text to a predefined clinical form. Finally, Qwen3-32b and Qwen3-Next-80b were selected as high-\nperforming open-weight models that combine strong predictive performance with operational feasibility, enabling\nreliable deployment in on-premise or tightly controlled infrastructures, as required in regulated clinical environments.\n6\n"}, {"page": 7, "text": "Each synthetic clinical case was processed independently by the system, and each of the six models was used as the\ngeneration component within the same RAG pipeline, ensuring that all other components of the system remained strictly\nidentical. This design isolates the effect of the language model itself on the quality and latency of the generated outputs.\nThe automatically completed forms were then compared against the ground-truth structured information associated with\neach synthetic case. Field-level accuracy metrics were computed, and latency measurements were recorded end-to-end\nfor each inference.\n4\nResults\nThe performance of the proposed form autocompletion tool was evaluated on the 10 synthetically generated lung cancer\nhistories using the 6 selected LLMs available through AWS Bedrock (GPT-OSS-20b, GPT-OSS-120b, Mistral-large-\n2402-v1, Pixtral-large-2502-v1, Qwen3-32b and Qwen3-next-80b). For each LLM, we have assessed two dimensions:\n(i) accuracy, quantified as the percentage of correctly completed fields and (ii) model latency, measured as end-to-end\nresponse time (in seconds) per form.\nFigure 2: Boxplots of accuracies in % (A) and latencies in seconds (B) computed over N = 10 clinical cases per model.\nBoxes represent the interquartile range (IQR), the central line indicates the median, and whiskers extend to the most\nextreme values within 1.5 × IQR. Dots denote outliers. The dotted line connects the mean values obtained for each\nmodel.\nFigure 2 (A) presents the boxplots of accuracy and the corresponding mean values across the ten lung cancer cases\ndiscussed by the tumour board for each evaluated model. As can be observed, the automatic lung cancer form completion\nsystem achieves consistently high accuracy levels, thereby demonstrating the practical feasibility of LLM-assisted\nform autocompletion in the context of multidisciplinary lung cancer tumour committees. Overall, larger models tend\nto exhibit superior performance. The highest mean accuracies were obtained with the Pixtral-large-2502-v1 model\n(80%) and with the GPT-OSS-120b, Qwen3-32b, and Qwen3-120b models, all of which reached a mean accuracy of\n79.3%. In contrast, the lowest mean accuracy was observed for the GPT-OSS-20b model (72.1%). Regarding result\nstability, the lowest standard deviations were achieved by Qwen3-32b (5.3), Qwen3-80b (6.3), Pixtral-large-2502-v1\n(6.6), and GPT-OSS-120b (7.1), indicating more consistent performance across cases, whereas the highest variability\nwas observed for GPT-OSS-20b, with a standard deviation of 10.4.\n7\n"}, {"page": 8, "text": "Latency distributions for the evaluated LLMs are shown in Figure 2 (B). Two clearly distinct behaviours can be\nidentified. Most models (GPT-OSS-120b, Mistral-large-2402-v1, Pixtral-large-2502-v1, Qwen3-32b and Qwen3-120b)\noperate within a narrow and homogeneous latency range with mean values concentrated around 20 −21 seconds.\nIn contrast, GPT-OSS-20b exhibits a markedly higher latency, with a mean of 54 seconds and substantially greater\nvariability. GPT-OSS-120b achieves a latency measure comparable to smaller models, indicating that inference time is\ndriven more by development and serving optimisations than by model size. Mistral family models show the lowest\nand most stable latency, while Qwen3 variants display similar performance. By contrast, GPT-OSS-20b constitutes an\noperational outlier and is poorly suited for time-sensitive workflows due to its excessive and unstable response times.\n5\nConclusions\nThis work demonstrates the feasibility, robustness and practical relevance of using LLMs to automate the completion of\nlung cancer tumour board forms within a clinical infrastructure. By integrating a modular data ingestion pipeline, a\nhybrid relational-vector storage layers and a rule-driven adaptive form model under a RAG architecture, ONCOTIMIA\nprovides a comprehensive and extensible tool for structured clinical documentation powered by GenAI.\nThe experimental evaluation across six LLMs provided by AWS Bedrock represents a promising step toward scalable\nAI-assisted clinical documentation in precision oncology and shows that LLM-assisted autocompletion can achieve\nhigh and stable accuracy, approaching 80% correct field completion in tumour board cases. The results also reveal that\ninference latency is not strictly correlated with model size, since the largest and modern LLMs can deliver response\ntimes comparable to smaller systems, making them suitable for clinical use in asynchronous or semi-interactive\nworkflows. From a care perspective, the proposed approach directly addresses one of the main operational bottlenecks in\nmultidisciplinary oncology, and particularly in the implementation of MDTB in hospitals with limited staff resources for\nthe preparation of cases. ONCOTIMIA reduces the manual, repetitive, and error-prone transcription of heterogeneous\nclinical information into structured forms frequently assigned to clinical staff. By automating a substantial portion of\nthis process, the system has the potential to reduce clinician workload, improve data consistency and accelerate case\npreparation without altering existing clinical decision workflows.\nNevertheless, several limitations remain. The current evaluation is based on a limited number of cases and focuses\nprimarily on technical performance metrics. Future work will include larger prospective studies, fine-grained error\nanalysis (e.g., by clinical category) and formal assessment of time savings and user acceptance in real tumour board\nsettings. Finally, further research is needed to strengthen safety guarantees, traceability and explainability, especially in\nthe presence of model hallucinations or incomplete source documentation.\nFunding sources\nThis work is part of project ONCOTIMIA (BAHIA SOFTWARE), that was supported by the IG408M-IA360 program\nunder grant number IG408M-2025-000-000021, funded by the Instituto Galego de Promoción Económica (IGAPE) and\ncofinanced by the Autonomous Community of Galicia (25%) and the European Union through the Recovery and Re-\nsilience Facility (75%), within the framework of the Recovery, Transformation and Resilience Plan-NextGenerationEU,\nComponent 16: National Artificial Intelligence Strategy.\nReferences\nAldea, M., Rotow, J. K., Arcila, M., Hatton, M., Sholl, L., Rolfo, C., Tagliamento, M., Radonic, T., Schalper, K. A.,\nSubbiah, V., Malapelle, U., Roden, A. C., Manochakian, R., Tsao, M.-S., Linardou, H., Hui, R., Novello, S.,\nGreystoke, A., Saqi, A., Lantuejoul, S., Hwang, D. M., Nevins, K., Wynes, M., Waqar, S., Han, Y., Yatabe, Y.,\nChang, W.-C., Hayashi, T., Kim, T.-J., Hofman, P., Tavora, F., Hirsch, F. R., Denninghoff, V., Leighl, N. B., Drilon,\nA., Cooper, W. A., Dacic, S., Mohindra, P., Pavlakis, N., and Lopez-Rios, F. (2025). Molecular tumor boards: A\nconsensus statement from the international association for the study of lung cancer. Journal of Thoracic Oncology,\n20(11):1594–1614.\nArndt, B. G., Beasley, J. W., Watkinson, M. D., Temte, J. L., Tuan, W. J., Sinsky, C. A., and Gilchrist, V. J. (2017). Teth-\nered to the ehr: Primary care physician workload assessment using ehr event log data and time-motion observations.\nAnnals of family medicine, 15(5):419–426.\nAyers, J. W., Poliak, A., Dredze, M., Leas, E. C., Zhu, Z., Kelley, J. B., Faix, D. J., Goodman, A. M., Longhurst, C. A.,\nHogarth, M., and Smith, D. M. (2023). Comparing physician and artificial intelligence chatbot responses to patient\nquestions posted to a public social media forum. JAMA Internal Medicine, 183(6):589–596.\n8\n"}, {"page": 9, "text": "Bracken, A., Reilly, C., Feeley, A., Sheehan, E., Merghani, K., and Feeley, I. (2025). Artificial intelligence (ai) –\npowered documentation systems in healthcare: A systematic review. J Med Syst, 49:28.\nBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G.,\nAskell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J.,\nWinter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S.,\nRadford, A., Sutskever, I., and Amodei, D. (2020). Language models are few-shot learners. CoRR, abs/2005.14165.\nChen, D., Rod, P., Karl, S., John-Jose, N., Andrew, C., S, B. D., Liu, F.-F., and Raman, S. (2025). Large language\nmodels in oncology: a review. BMJ Oncology, 4:e000759.\nEl Saghir, N. S., Keating, N. L., Carlson, R. W., Khoury, K. E., and Fallowfield, L. (2014). Tumor boards: optimizing\nthe structure and improving efficiency of multidisciplinary management of patients with cancer worldwide. American\nSociety of Clinical Oncology educational book. American Society of Clinical Oncology, Annual Meeting:e461–e466.\nEsteva, A., Robicquet, A., Ramsundar, B., Kuleshov, V., DePristo, M., Chou, K., Cui, C., Corrado, G., Thrun, S., and\nDean, J. (2019). A guide to deep learning in healthcare. Nat Med, 25:24–29.\nGu, Y., Tinn, R., Cheng, H., Lucas, M., Usuyama, N., Liu, X., Naumann, T., Gao, J., and Poon, H. (2021). Domain-\nspecific language model pretraining for biomedical natural language processing. ACM Trans. Comput. Healthcare,\n3(1).\nHu, D., Zhang, H., Li, S., Wang, Y., Wu, N., and Lu, X. (2021). Automatic extraction of lung cancer staging information\nfrom computed tomography reports: Deep learning approach. JMIR medical informatics, 9(7):e27955.\nLuo, R., Sun, L., Xia, Y., Qin, T., Zhang, S., Poon, H., and Liu, T.-Y. (2022). Biogpt: generative pre-trained transformer\nfor biomedical text generation and mining. Briefings in Bioinformatics, 23(6):bbac409.\nNori, H., King, N., McKinney, S. M., Carignan, D., and Horvitz, E. (2023). Capabilities of gpt-4 on medical challenge\nproblems. ArXiv, abs/2303.13375.\nSinghal, K., Azizi, S., Tu, T., Mahdavi, S. S., Wei, J., Chung, H. W., Scales, N., Tanwani, A., Cole-Lewis, H., Pfohl, S.,\nPayne, P., Seneviratne, M., Gamble, P., Kelly, C., Scharli, N., Chowdhery, A., Mansfield, P., y Arcas, B. A., Webster,\nD., Corrado, G. S., Matias, Y., Chou, K., Gottweis, J., Tomasev, N., Liu, Y., Rajkomar, A., Barral, J., Semturs,\nC., Karthikesalingam, A., and Natarajan, V. (2023). Large language models encode clinical knowledge. Nature,\n620:172–180.\nWang, Y., Wang, L., Rastegar-Mojarad, M., Moon, S., Shen, F., Afzal, N., Liu, S., Zeng, Y., Mehrabi, S., Sohn, S., and\nLiu, H. (2018). Clinical information extraction applications: A literature review. Journal of biomedical informatics,\n77:34–49.\n9\n"}]}