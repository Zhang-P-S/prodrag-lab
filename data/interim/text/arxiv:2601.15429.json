{"doc_id": "arxiv:2601.15429", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2601.15429.pdf", "meta": {"doc_id": "arxiv:2601.15429", "source": "arxiv", "arxiv_id": "2601.15429", "title": "Domain-Specific Knowledge Graphs in RAG-Enhanced Healthcare LLMs", "authors": ["Sydney Anuyah", "Mehedi Mahmud Kaushik", "Hao Dai", "Rakesh Shiradkar", "Arjan Durresi", "Sunandan Chakraborty"], "published": "2026-01-21T19:55:12Z", "updated": "2026-01-21T19:55:12Z", "summary": "Large Language Models (LLMs) generate fluent answers but can struggle with trustworthy, domain-specific reasoning. We evaluate whether domain knowledge graphs (KGs) improve Retrieval-Augmented Generation (RAG) for healthcare by constructing three PubMed-derived graphs: $\\mathbb{G}_1$ (T2DM), $\\mathbb{G}_2$ (Alzheimer's disease), and $\\mathbb{G}_3$ (AD+T2DM). We design two probes: Probe 1 targets merged AD T2DM knowledge, while Probe 2 targets the intersection of $\\mathbb{G}_1$ and $\\mathbb{G}_2$. Seven instruction-tuned LLMs are tested across retrieval sources {No-RAG, $\\mathbb{G}_1$, $\\mathbb{G}_2$, $\\mathbb{G}_1$ + $\\mathbb{G}_2$, $\\mathbb{G}_3$, $\\mathbb{G}_1$+$\\mathbb{G}_2$ + $\\mathbb{G}_3$} and three decoding temperatures. Results show that scope alignment between probe and KG is decisive: precise, scope-matched retrieval (notably $\\mathbb{G}_2$) yields the most consistent gains, whereas indiscriminate graph unions often introduce distractors that reduce accuracy. Larger models frequently match or exceed KG-RAG with a No-RAG baseline on Probe 1, indicating strong parametric priors, whereas smaller/mid-sized models benefit more from well-scoped retrieval. Temperature plays a secondary role; higher values rarely help. We conclude that precision-first, scope-matched KG-RAG is preferable to breadth-first unions, and we outline practical guidelines for graph selection, model sizing, and retrieval/reranking. Code and Data available here - https://github.com/sydneyanuyah/RAGComparison", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2601.15429v1", "url_pdf": "https://arxiv.org/pdf/2601.15429.pdf", "meta_path": "data/raw/arxiv/meta/2601.15429.json", "sha256": "19bd132364aa85f15af3a39b0c9ecb39dd12daf7a63f27b12c1aa5a0651acad9", "status": "ok", "fetched_at": "2026-02-18T02:20:51.282468+00:00"}, "pages": [{"page": 1, "text": "Domain-Specific Knowledge Graphs in\nRAG-Enhanced Healthcare LLMs\nSydney Anuyah*, Mehedi Mahmud Kaushik*, Hao Dai‡, Rakesh Shiradkar†, Arjan Durresi*, Sunandan Chakraborty*\n*Luddy School of Informatics, Computing, and Engineering, Indiana University, Indianapolis, IN, USA\n‡School of Medicine, Indiana University, Indianapolis, IN, USA\n†Department of Biomedical Engineering and Informatics, Indiana University, Indianapolis, IN, USA\nEmails: {sanuyah, mekaush, daihao, rshirad, adurresi, sunchak}@iu.edu\nAbstract—Large Language Models (LLMs) generate fluent\nanswers but can struggle with trustworthy, domain-specific rea-\nsoning. We evaluate whether domain knowledge graphs (KGs)\nimprove Retrieval-Augmented Generation (RAG) for healthcare\nby constructing three PubMed-derived graphs: G1 (T2DM),\nG2 (Alzheimer’s disease), and G3 (AD+T2DM). We design\ntwo probes: Probe 1 targets merged AD–T2DM knowledge,\nwhile Probe 2 targets the intersection of G1 and G2. Seven\ninstruction-tuned LLMs are tested across retrieval sources {No-\nRAG, G1, G2, G1+G2, G3, G1+G2+G3} and three decoding\ntemperatures. Results show that scope alignment between probe\nand KG is decisive: precise, scope-matched retrieval (notably\nG2) yields the most consistent gains, whereas indiscriminate\ngraph unions often introduce distractors that reduce accuracy.\nLarger models frequently match or exceed KG-RAG with a\nNo-RAG baseline on Probe 1, indicating strong parametric\npriors, whereas smaller/mid-sized models benefit more from well-\nscoped retrieval. Temperature plays a secondary role; higher\nvalues rarely help. We conclude that precision-first, scope-\nmatched KG-RAG is preferable to breadth-first unions, and\nwe outline practical guidelines for graph selection, model siz-\ning, and retrieval/reranking. Code and Data available here -\nhttps://github.com/sydneyanuyah/RAGComparison\nI. INTRODUCTION\nAlzheimer’s disease (AD) and type 2 diabetes mellitus\n(T2DM) represent two of the most pressing chronic health\nchallenges we face today [1], [2], each carrying its own\nsignificant public health burden while also sharing surprising\nconnections with one another [3]. Today, AD stands as the\nprimary cause of dementia in older adults [4], [5]. More than\n55 million people worldwide are living with dementia, and\nexperts predict this could surge to somewhere between 139\nand 150 million by 2050 [6], [7]. T2DM shows a similarly\nalarming trend, with roughly 589 million adults as of 2024\n(that’s about 11.1% of the adult population) living with the\ncondition, and projections suggest we could see around 853\nmillion cases by mid-century [8]. What is particularly striking\nis that over 90% of all diabetes cases are type 2 [8], [9], largely\ndriven by our ageing populations and modern lifestyle factors.\nAs life expectancy continues to climb, there are statistically\nmore people dealing with both metabolic and neurodegenera-\ntive diseases simultaneously [10], which makes understanding\nthe relationship between AD and T2DM increasingly urgent\nfor biomedical AI development.\nEpidemiological research has consistently shown that hav-\ning diabetes substantially increases the risk of cognitive de-\ncline and dementia, including AD [11]. A recent 2024 meta-\nanalysis showed that diabetic patients face about 59% higher\ndementia risk compared to people without diabetes [11],\n[12], which reinforces what earlier studies had found that\nT2DM increases an individual’s risk of cognitive disorders\nby roughly 1.3 to 1.9 times [13]. When we dig into the\nmolecular details, the picture gets even more interesting. The\nchronic high blood sugar and insulin resistance that defines\nT2DM actually mirrors some of the same pathophysiological\nprocesses we see in AD [14]. This similarity has led some\nresearchers to provocatively label AD as “type 3 diabetes\"\nthough this remains controversial [15]–[18]. The idea empha-\nsizes the overlapping features: impaired insulin signaling in the\nbrain, chronic inflammation, and oxidative stress [13]. Both\nconditions also share common risk factors such as midlife\nobesity and high blood pressure [13].\nDespite the wealth of published research on AD–T2DM\nconnections, Large Language Models (LLMs) on their own\nhave real trouble delivering reliable medical answers [19].\nToday’s state-of-the-art (SOTA) LLMs can certainly generate\nimpressively fluent responses, but they frequently hallucinate\nfacts or fabricate citations that do not exist, which is a serious\nsafety concern in healthcare settings [20]. Even powerful mod-\nels like GPT-4 have inherent knowledge limitations that mean\nthey might miss crucial domain-specific details or misrepre-\nsent the latest findings. This is where Retrieval-Augmented\nGeneration (RAG) has become the go-to solution, helping\nground LLM outputs in external, verified knowledge [21]. By\npulling in relevant documents or facts when answering a query,\nRAG significantly improves factual accuracy [21]. However,\nconventional RAG systems that retrieve free-text passages can\nstill drag in irrelevant or contradictory information, which\nthe LLM might then mistakenly weave into its answer [21].\nThis becomes especially problematic for knowledge-intensive\nquestions that require multiple reasoning steps, where models\nneed to piece together complex biomedical relationships.\nStructured knowledge bases offer a more promising al-\nternative. Knowledge graphs (KGs) organize facts as sub-\nject–relation–object triples (E1, R, E2) as seen in Table I,\nwhere E1 is the subject entity, E2 is the object entity, and\narXiv:2601.15429v1  [cs.CL]  21 Jan 2026\n"}, {"page": 2, "text": "TABLE I: Examples of triples used for the knowledge graphs\nKG\nExample\nG1\n[\"Entity 1\": \"T2DM\", \"Relationship\": \"was associated with\", \"Entity 2\":\n\"decreased forced expiratory volume in 1s (FEV1)\"]\nG2\n[\"Entity 1\": \"Alzheimer’s disease CSF\", \"Relationship\": \"is associated\nwith\", \"Entity 2\": \"neuroinflammation\"]\nG3\n[\"Entity 1\": “Insulin-like growth factor \", \"Relationship\": \"influences\",\n\"Entity 2\": “cognitive functions\"]\nR represents their relationship. This structured representation\nprovides clear semantics and traceable origins, making it easier\nto verify how an answer was constructed. Yet, critical ques-\ntions remain about how best to leverage KGs in healthcare AI:\nDoes curating domain-specific KGs from biomedical literature\nactually improve answer quality in RAG-enhanced LLMs?\nShould we build narrow, disease-focused graphs or broader\ncross-domain ones? And how do these design choices interact\nwith model parameters like decoding temperature?\nIn this research, we investigate the role of domain-specific\nKGs curated from PubMed abstracts in RAG-enhanced health-\ncare LLMs. We ask whether such KGs improve the factual\naccuracy and evidential support of answers compared to no-\nRAG baselines (RQ1). We further examine how curation scope\naffects question answering: do focused, disease-specific KGs\n(G1 for T2DM, G2 for AD) outperform a broader merged\nKG (G3) on single-hop and multi-hop probes, or vice versa\n(RQ2)? We also investigate the robustness of RAG gains\nacross different decoding temperatures (0, 0.2, 0.5) and test\nfor statistical significance of improvements (RQ3). Finally,\nwe explore whether we can enhancing the components of the\nCoDe-KG pipeline to yield higher-quality graphs that translate\ninto better downstream QA performance (RQ4).\nA. Contributions\nIn this research, we investigate the role of domain-specific\nKGs curated from abstracts on PubMed for RAG-enhanced\nhealthcare LLMs.\n• We build three abstract-derived KGs with a common\nschema: G1 (T2DM-focused), G2 (AD-focused), and G3\n(combined AD+T2DM).\n• We\nintroduce\nprobe\nsets\nspanning\nsingle-hop\nclinical\nfacts\n(e.g.,\ndrug→outcome,\ngene→disease)\nand\nmulti-hop\nmechanisms\n(e.g.,\ninsulin\nsignaling→neuroinflammation→cognition)\n• We evaluate 7 LLMs with and without KG-RAG across\nvarying temperatures 0, 0.2, and 0.5, measuring F1score,\nand accuracy across the probes, and we test for signif-\nicance of RAG gains and of curation scope (G1/G2 vs.\nG3)\n• We improve the co-reference of the CoDe-KG pipeline.\nII. BACKGROUND\nA. Pathophysiological Links Between AD and T2DM\nAD and T2DM share several disease mechanisms that play\nout at both the molecular and whole-body at scales. Chronic\ninsulin resistance, the defining feature of T2DM, contributes\nto AD by interfering with how neurons take up glucose and\nrespond to insulin signals in the brain [13]. This neurode-\ngenerative change: the combination of excess glucose and\ndisrupted insulin signaling fuels inflammation and oxidative\nstress, which then accelerates the formation of β-amyloid\nplaques and tau tangles (the signature brain abnormalities we\nsee in AD) [13].\nAs established by the KG, Apolipoprotein ϵ4 (APOE ϵ4)\noffers a genetic link between these two diseases, example of\na triple that shows this link is \"Individuals with T2DM have\nAPOE4-related cognitive and olfactory impairment\". While we\nknow APOE ϵ4 as the strongest genetic risk factor for late-\nonset AD, its influence extends beyond just amyloid process-\ning; it’s also tied to how our bodies handle fats and glucose\n[22]. People with diabetes who carry APOE ϵ4 experience\nfaster mental decline and face higher dementia risk than\ndiabetics without this gene variant, suggesting that the allele\nand metabolic stress amplifies each other’s effects [13], [23].\nInflammation represents another critical connection point\nbetween T2DM and AD. In T2DM, visceral fat and insulin-\nresistant tissues pump out elevated levels of adipokines and in-\nflammatory cytokines. These molecules can breach the blood-\nbrain barrier, adding fuel to the neuroinflammation already\npresent in AD. From a clinical standpoint, T2DM patients\ncarry roughly twice the risk of developing vascular dementia\nand show higher rates of Alzheimer’s dementia across many\nstudies [13], [24].\nB. Knowledge Graphs in Biomedical Research\nThe complex web of relationships in biomedicine has\npushed researchers to develop knowledge graphs (KGs) as a\nway to organize factual information in a structured, queryable\nformat. Unlike traditional text documents, KGs represent\nbiomedical entities like genes, diseases, drugs, proteins as\nnodes or entities in a network, with their relationships depicted\nas labelled edges. For example, an edge might connect a\ngene node to a disease node with the label “associated with,\"\nmaking the relationship explicit and machine-readable. Large-\nscale biomedical KGs like SPOKE show how they created\nKGs by integrating over 40 curated databases, including\nDrugBank and GWAS catalogs, resulting in a comprehensive\nnetwork of approximately 42 million nodes across 28 entity\ntypes and 160 million relationships [25]. CoDe-KG [26] is\nanother SOTA pipeline built with open-source LLMs. What\nsets KGs apart from text-based resources is their built-in\ntraceability. While bioinformaticians have traditionally used\nKGs for drug repurposing and gene discovery, we leverage\nthem as knowledge sources for question answering (QA).\nGiven this context, we propose to leverage CoDe-KG [26],\nan automated KG construction pipeline, to build focused\nbiomedical knowledge graphs and evaluate their impact on\ntrustworthy domain-specific questions. CoDe-KG is an open-\nsource framework that extracts structured facts from text by\ncombining robust co-reference resolution with syntactic de-\ncomposition. This approach breaks down complex statements\nand resolves pronouns, thereby capturing more complete and\ncontext-rich relations. According to the authors, CoDe-KG\n"}, {"page": 3, "text": "achieved an increase of ∆= 8% F1 when compared to prior\nmethods on the REBEL relation extraction dataset [26], and\nintegrating co-reference + decomposition increased recall on\nrare relations by over 20% [26]. We harness this pipeline to\ndistil knowledge from biomedical abstracts into three KGs of\nvarying scope: G1, G2 and G3 for the combined AD+T2DM\ndomain. We then use these graphs in an LLM-driven RAG\nsetup to answer questions. By comparing performance across\nG1, G2, and G3, we examine whether a targeted disease-\nspecific KG yields better answers than a broader cross-domain\nKG, or vice versa. We further probe how the structure and\nscope of knowledge graphs affect the LLM’s ability to deliver\ncorrect, well-supported answers. While RAG models often out-\nperform non-RAG approaches, this is not always guaranteed.\nAs [27], [28] point out, earlier KG-RAG frameworks with\nfixed search parameters could retrieve redundant trivial facts or\nmiss important multi-hop connections, ultimately weakening\nthe LLM’s reasoning capabilities and making RAG-enhanced\nsystems perform worse than their non-RAG counterparts.\nC. Our Approach\nIn this work, we built three different knowledge graphs\n(G1, G2 and G3) to investigate how the scope of knowledge\naffects QA performance in this domain. We detail the curation\nof Probe1 and Probe2 in the subsequent sections. In Probe1,\nformulated on G3 and Probe2, formulated on G1 ∩G2, we\ntested different combinations of LLMs built on the different\nRAG systems. Our hypothesis going in was that the focused\nKG (G1 and G2) might perform better on questions specif-\nically about the AD-T2DM intersection, since it provides\ndenser, more concentrated context for that particular overlap.\nMeanwhile, the merged KG (G3) should theoretically handle a\nwider range of questions about either disease or their connec-\ntions more effectively. However, there’s a potential downside\nto the merged approach as it could introduce distractors (facts\nrelevant to one disease but not the question at hand), which\nmight confuse the LLM. By testing the same set of questions\nagainst both knowledge graphs, we can observe any trade-offs\nbetween having a highly focused knowledge source versus a\nmore comprehensive one.\nIII. METHODOLOGY\nIn this section, we cover the development of the three KGs,\n(G1 (T2DM-focused), G2 (AD-focused), and G3 (combined\nAD+T2DM)), the creation of the probes and the experimen-\ntation of the seven LLMs with different combinations of the\nknowledge graphs, shown in Figure 1.\nA. Abstract Selection and Filtration\nSearch queries used to build the KG sets\nQT 2DM (T2DM-only).\n(T2DM OR \"Type 2 Diabetes\" OR \"Type\nII Diabetes\" OR \"Type-2 Diabetes\" OR\n\"Diabetes Mellitus, Type 2\" OR NIDDM\nOR \"non insulin dependent diabetes\"\nOR \"non-insulin-dependent diabetes\" OR\n\"adult-onset diabetes\" OR (diabet* AND\n(\"type 2\" OR T2DM)))\nQAD (AD-only).\n(AD OR \"Alzheimer’s disease\" OR\n\"Alzheimer disease\" OR \"Alzheimers\ndisease\" OR Alzheimers OR Alzheime*\nOR Alzhiemer* OR \"dementia of the\nAlzheimer type\" OR DAT OR LOAD OR\n\"late-onset Alzheimer*\")\nQT 2DM+AD (AD & T2DM together).\n((AD OR \"Alzheimer* disease\" OR\nAlzheime* OR Alzhiemer* OR DAT OR LOAD)\nAND (T2DM OR \"Type 2 Diabetes\" OR \"Type\nII Diabetes\" OR \"Diabetes Mellitus,\nType 2\" OR NIDDM))\nAfter\napplying\nthe\nQT 2DM/QAD/QAD+T 2DM\nsearch\nstrings, we created a simple, reproducible filter to rank ab-\nstracts and kept the most relevant per group. The aim is to\nbias toward causal and mechanistic content while still covering\nphenotypes and biomarkers that matter for AD, T2DM, and\ntheir intersection. We remove short-worded abstracts (less than\n180 words) to avoid editorials or thin notes:\nkeep(i) = ⊮\n\u0002\nwords(Abstracti) ≥180\n\u0003\n.\nWe then join title and abstract into one text string xi, and\nbuild a TF–IDF matrix on unigrams and bigrams (English\nstopwords, min_df=2):\nX ∈Rn×V ,\nXi = tfidf(xi),\ni = 1 . . . n.\nWe create three query vectors by TF–IDF, transforming the\ncurated term lists:\nqcaus, qpheno, qbiom ∈RV ,\nrepresenting\nCAUSALITY_TERMS,\nPHENOTYPE_TERMS,\nand BIOMARKER_TERMS respectively. For each abstract, we\ncompute three cosine similarities:\ns(caus)\ni\n= cos(Xi, qcaus),\ns(pheno)\ni\n= cos(Xi, qpheno),\ns(biom)\ni\n= cos(Xi, qbiom).\nWe reward abstracts that explicitly name crucial elements\n(e.g., “Mendelian randomization,” “longitudinal,” “p-tau-217,”\n“APOE4,” “insulin resistance phenotype,” “HbA1c”).\nk(caus)\ni\n, k(pheno)\ni\n, k(biom)\ni\n∈N,\nk(tot)\ni\n= k(caus)\ni\n+k(pheno)\ni\n+k(biom)\ni\n.\nPer-feature normalization.: Each signal is min–max nor-\nmalized to [0, 1] to keep ranges comparable:\n˜s(·)\ni\n=\ns(·)\ni\n−min s(·)\nmax s(·) −min s(·) ,\n˜ki =\nk(tot)\ni\n−min k(tot)\nmax k(tot) −min k(tot) .\nWe then produce a single value that we use only to rank\nabstracts:\nRi = wcaus˜s(caus)\ni\n+ wpheno˜s(pheno)\ni\n+ wbiom˜s(biom)\ni\n"}, {"page": 4, "text": "+ wkw˜ki.\nThe final KGs were created from the top 1000 selected\nabstracts.\nB. Pipeline replication and coref upgrade\nWe start from the selected abstracts D = {d1, . . . , dN} and\ntreat each abstract as a set of sentences S(d) = {s1, . . . , s|d|}.\nThe extraction loop in CODE-KG is\nT\n=\n[\nd∈D\n[\ns∈S(d)\nREψ(decomp(corefθ(s))) ,\n(1)\nwhere s (coref) →is resolving abstract co-reference, i.e\n“T2DM\" = “Type 2 Diabetes Mellitus\" = “t2dm\"; then de-\ncompose complex sentences into simpler ones (decomp), then\nextract triples (E1, R, E2) with a simple source tag π(t) that\nnotes (paper id, sentence id, clause id). This tag lets us always\npoint back to the exact sentence that created a triple. We\nfirst matched the original authors’ inference setting (temp\n= 0.7) and reproduced similar relation extraction behavior.\nWe replaced the coreference backbone with Qwen 32B coder\nand kept all other steps the same.\ncorefθ⋆reaches F1 = 61% vs. 58% before,\nThis test was done on the authors dataset. In practice, better\ncoref means fewer broken heads or tails later, so the KG has\ncleaner nodes and more usable causal links.\nC. KG build, cleanup, and naming rules\nRaw extraction gives a multi-set of triples T . For our study,\nwe want edges that point in a clear causal direction, so we kept\nonly a small relation set.\nRc = {causes, because, ...}.\nFormally,\nTc = { (E1, R, E2, π) ∈T\n: r ∈Rc }.\n(2)\nNext, we remove vague heads/tails. A simple mask M drops\nitems like “it”, “this”, or “this study”:\nM(x) = ⊮[x /∈{it, this, this study}] ,\nT clean\nc\n= {t ∈Tc : M(E1) = M(E2) = 1}.\nWe manually normalize names so variants collapse to a\nsingle label: “T2DM” and “Type 2 Diabetes” should be treated\nas one thing. We rewrite each edge by\nΦ : (E1, R, E2, π) 7→\n\u0000m(E1), R, m(E2), π\n\u0001\n,\nand obtain the canonical set bTc = {Φ(t) : t ∈T clean\nc\n}.\nD. Probe Creation\nWe created two types of Probes: the first built on G3 and the\nsecond built on the intersection of G1 and G2 →(G1 ∩G2)\n1) Probe 1: Containing 100 multiple-choice questions, this\nprobe tests the joint AD+T2DM query. The questions are\nframed to cover single hop, multi-hop and fill in the blank\n(FITB). Let A ∈{0, 1}| bE3|×| bE3| be the adjacency over Rc.\n• Single-hop. Choose (u, r, v)∈bTc,3 and create one correct\noption and three distractors from N −(u) = {x : Ax,u =\n1} that match type/frequency. This checks one clean link.\n• Multi-hop, pair-selection. For a target x, the set of direct\ncauses is P1(x) = {u : Au,x = 1}. The correct answer\nis an unordered pair {u, v} ⊆P1(x). Distractors come\nfrom P2(x) = {u : (A2)u,x = 1} or close neighbors that\nlook right but are not immediate parents. This stresses\nreal 2-hop reasoning.\n• FITB. Mask one canonical token in (u, r, v); only the\ncanonical label passes. This drills precision under syn-\nonyms.\nWe ensure synonym control explicitly, as options must be\ndistinct in canonical space (m(ci) ̸= m(cj)), so there are no\nduplicate answers under different spellings.\n2) Probe 2: This probe targets G1 ∩G2. We embed the\ntriple with an encoder s(·) ∈Rd and use cosine similarity to\nscreen for intersection candidates I\nI =\nn\n(τ1, τ2) ∈bTc,1×bTc,2 : cos(s(τ1), s(τ2)) ≥0.65\no\n. (3)\nYielding |I|\n=\n424. After stop-word removal and de-\nduplication in canonical space, we keep |bI| = 193 items. We\nthen form questions from this intersection subgraph:\n• Single-hop, FITB: Same as Probe 1 but restricted to bI.\n• Multi-hop with direction. If the true edge is u→x, then\nthe option x→u is wrong even though it uses the same\nnames. We present four atomic options (1–4) and ask for\nthe correct pair among A–E (the 2-combinations). Exactly\ntwo pairs are correct; both must point into the target.\n0.65 was chosen as the cosine similarity value because it kept\nthe same causal theme in both diseases (e.g., insulin signaling,\ninflammation) without having too loose matches.\nE. RAG setups Prompting and Answer Generation\nWe compare six retrieval setups:\nK ∈\n\b\n∅, G1, G2, G1+G2, G3, G1+G2+G3\n\t\n.\nWhere ∅\n→(No-RAG). For each value of K, we run\nthe same LLM with and without this context. For QA we use\nT ∈{0, 0.2, 0.5}; Lower T sticks closer to retrieved facts;\nhigher T can add details but risks drift. All the prompts were\nzero-shot instruction based.\nYou are answering a multiple-choice\nquestion.\nReturn ONLY one uppercase letter from\nthis set: {allowed_str}.\nDo not include explanations or extra\ntext.\n"}, {"page": 5, "text": "Step 1a: Query PubMed \nand filter by length\nStep 3b: Canonicalize\nStep 3a: Filter causal\nrelations\nFinal output: \nThree Knowledge Graphs\nStep 1b: Rank and\nselect top K abstracts\nPipeline replication \nand coref upgrade\nKG build, cleanup, and naming rules\nAbstract Selection and Filtration\nStep 2: Extract raw triples\nProbe Creation\nProb 1: Query PubMed \nand filter by length\nProb 2: Intersection\n(110 questions)\nEvaluation\nRAG setups Prompting and\nAnswer Generation\nFig. 1: Overview of the methodology for constructing domain-specific knowledge graphs and evaluating their impact on RAG-\nenhanced healthcare LLMs. The pipeline includes abstract selection, knowledge graph construction, probe generation, and\nsystematic evaluation across multiple models and retrieval configurations. Detailed explanation is provided in Section III.\nTABLE II: QA items formatted as fill-in-the-gap, multi-hop, and single-hop examples.\nQuestion type\nQuestion\nOptions\nAnswer choices\nFill-in-the-gap\nType 2 diabetes increases Alzheimer’s risk through\nand\n.\n1. Neuroinflammation\n2. Amyloid degradation\n3. Insulin resistance\n4. Tau dephosphorylation\nA: 1 and 2\nB: 3 and 4\nC: 3 and 2\nD: 2 and 4\nE: 3 and 1\nMulti-hop\nWhich two are direct precursors of neuroinflammation\nescalation?\n1. Aβ oligomers\n2. Peripheral infection\n3. Aerobic fitness\n4. Microglial priming\nA: 1 and 2\nB: 1 and 4\nC: 2 and 3\nD: 3 and 4\nSingle-hop\nAbnormal insulin signaling in the brain primarily results in:\nA: Lower GSK3β activity\nB: Reduced oxidative damage\nC: Enhanced mitochondrial function\nD: Higher synaptic resilience\nE: Reduced Aβ degradation and increased tau phosphorylation\n—\nSince all questions were multiple-choice, we incorporated\ncommon distractors in the options. For questions with multiple\nanswers, we tested the macro and micro F1 in those cases.\nIV. RESULTS\nA. Effect of Varying Temperature\nFor each Model×Probe×Graph configuration, we compared\nmacro-F1 across temperatures using pairwise Welch’s t-tests\n(unequal variances) for the three temperature values: 0 vs. 0.2,\n0.2 vs. 0.5, and 0 vs. 0.5. Within each configuration we applied\nHolm–Bonferroni correction across the three tests; statistical\nsignificance is denoted as * (padj<.05), ** (padj<.01), and ***\n(padj<.001). Effect sizes (Cohen’s d) were computed for all\ncomparisons.\nBecause each temperature condition is represented by a\nsingle run per configuration (i.e., n=1 per temperature),\ninferential tests were of low statistical power and produced no\nadjusted p-values below .05; consequently, no cells received a\nsignificance marker after Holm correction. We therefore report\ndirectional patterns descriptively. Across all 84 configurations,\nincreasing temperature from 0→0.5 reduced macro-F1 in 52\ncases, increased it in 23, and left it unchanged in 9 (median\n∆= −0.02). The attenuation with higher T was more\npronounced on Probe 1 (28 decreases, 9 increases; median\n"}, {"page": 6, "text": "TABLE III: Temperature sensitivity by graph (macro-F1).\nCounts across all Model×Probe settings; ∆is median change\nfrom T=0 to 0.5.\nGraph\n# Increases\n# Decreases\n# No change\nMedian ∆(0→0.5)\nG1\n7\n7\n0\n0.00\nG1+G2\n3\n10\n1\n-0.03\nG1+G2+G3\n3\n9\n2\n-0.03\nG2\n3\n10\n1\n-0.03\nG3\n3\n8\n3\n-0.02\nNo-RAG\n4\n8\n2\n-0.02\n∆= −0.03) than Probe 2 (24 decreases, 14 increases; median\n∆= −0.01). By graph condition, G1 was most temperature-\nstable (balanced 7 increases/7 decreases; median ∆≈0),\nwhereas G2, G3, and G1+G2(+G3) skewed toward decreasing\nvalues, however, it was small (median ∆∈[−0.03, −0.015]).\nBy model, Anthropic.Claude-3-Haiku showed the\nmildest tendency to improve with temperature (median\n∆= + 0.005),\nwhile\nMistral-7B-Instruct-v0.3\nexhibited the largest typical drop (median ∆= −0.12).\nIllustratively,\nthe\nlargest\ndecrease\noccurred\nfor\nMistral-7B-Instruct-v0.3\non\nProbe\n1\nacross\nseveral graphs (∆0→0.5\n∈\n[−0.25, −0.21]), whereas a\nnotable increase was observed for Mixtral-8x7B-v0.1\n(No-RAG, Probe 2; ∆0→0.5= + 0.09).\nOn the domain of single-run estimations (no stars beyond\nthe Holm adjustment), on the graphs of macro-F1, the trend\nof higher decoding temperature is, in most cases, downward,\nparticularly Probe 1 and non-G1 graphs. When stability is\npreferred, T=0 is the safest default; small exploration at\nT=0.2 may be helpful in some environments, but T=0.5 tends\nto worsen the accuracy. Accordingly, we take an averaged\nvalue of each of these temperatures.\nB. Model Performance\nThe\nmodels\nwhich\nperform\nwell\non\nboth\nprobes\nare: Anthropic Claude-3-Haiku, (which is the only non-\nopen source model), Qwen-2.5-32B-Instruct, Llama-3.1-8B-\nInstruct, Llama-3.3-70B-Instruct, and GPT-OSS-20B. Llama-\n3.3-70B-Instruct scores the highest macro F1 on the probe\n1, while Qwen-2.5-32B-Instruct has the highest macro F1 in\nprobe 2, beating the Anthropic Claude-3-Haiku model. An\nobservation is that these models which are particularly large in\nsize are already trained to contain large amounts of biomedical\nknowledge and therefore adding external information in the\nshape of a domain-specific KG is likely to have very minimal\nvalue and can even cause a model to become confused and\nconfused by irrelevant or contradictory information, shown by\nthe dip in the results, in Table IV and V. From the results, we\nsee that normal RAG might lure in erroneous or conflicting\nfacts, which is likely the reason why G1 and G3 fell in\nperformance in these models. On probe 2, the image is a bit\ndifferent - RAG occasionally helps. For example, the combined\ngraph (G1 + G2 + G3) slightly improves Anthropic Haiku from\n0.61 to 0.63 and GPT-OSS-20B from 0.46 to 0.57, suggesting\nthat even large models can benefit from external knowledge\nwhen tackling more complex, multi-hop reasoning tasks.\nSmall models benefit from G2. The baseline scores of\nmistral-7B and Mixtral-8X7B are moderate (0.69 and 0.80)\nin probe 1 and (0.29 and 0.39) in probe 1. The performance\nof both probes is significantly improved when they retrieve\nout of the AD-oriented KG (G2). On probe 1 for Mixtral-\n8X7B, F1 is increased by 0.80 to 0.89, and probe 2 F1 is\nalso increased by 0.39 to 0.51. Mistral-7B exhibited a similar\nbehavior, from 0.69 to 0.74 for probe 1 and 0.29 to 0.33 in\nprobe 2. Interestingly, G1 + G2 is slightly worse than G2\nalone, indicating that the most valuable information in these\nmodels is the AD graph instead of being part of the union\nwith T2DM knowledge. The above improvements suggest that\nsmaller models that possess less built-in biomedical knowledge\ncan benefit meaningfully in terms of structured biomedical\nknowledge to fill in the gaps in their parameter knowledge.\nPerformance in G3 showed a downward spike, even though\nthere was no conclusive evidence as to why. In the models,\nexcept in Mistral and Mixtral, the G3 graph reduces the F1.\nAn interesting case of the Llama-3.1-8B Instruct model shows\nthat the combined larger graph: G1 + G2 + G3 dropped the\nperformance from 0.85 to 0.65 on probe 1. 0.65 was the same\nvalue as when using G2 alone, and was even less (0.62) on\nG1 alone. Probe 2 was quite similar, as we saw a drop in the\ncombined graph of G1 + G2 + G3 fom 0.50 to 0.40 macro F1.\nWe hypothesized that a larger KG may add irrelevant relations,\nand our findings validate this, meaning that the broader graph\nmay mislead LLMs, exposing them to unfounded relations.\nUpon adding up the improvement over the No-RAG baseline\nacross all the models and all the probes, one can easily see that\nG2 is positive (mean improvement +0.006 F1) and G1, G3 and\nthe combination of graphs have negative mean improvements\n(–0.04 to -0.01). Therefore, the graph on AD (G2) is the only\ndomain-specific KG that was helpful.\nV. DISCUSSION\nIt is experimentally demonstrated that the source of the\nretrieval and the scope of retrieval G1, G2, G3, and their\ncombinations directly influence the quality of answers. Since\nProbe 1 is derived out of G3, the resulting merged KG is\nlikely to include the accurate facts sought by a large number\nof questions; whereas Probe 2 is created out of G1 ∩G2, thus\nsignals that are similar across the two domains of diseases have\na stronger influence. In both probes, the addition of additional\nsources (G1, G2, G3) does not assure higher accuracy: the\naddition of breadth raises recall but may introduce many other\nunrelated distracting facts that reduce precision.\nA. Significance\nWe provide statistical significance of each condition (three\nindependent runs each model-probe-system) (paired with\npaired two-sample t-tests against No-RAG):\n∗p\n<\n0.05,\n∗∗p < 0.01, ∗∗∗p < 0.001. Table VI and VII only indicate\ndifferences that are of significance at these values; non-stars\nwould not be statistically different to the baseline at α=0.05.\n"}, {"page": 7, "text": "TABLE IV: Results of Probe 1, Averaged across the three temperatures (0.0, 0.2 and 0.5)\nSystems\nModel\nMetric\nG1\nG1+G2\nG1+G2+G3\nG2\nG3\nNo-RAG\nAnthropic.Claude-3-Haiku\nAcc/ F1Micro\n0.84 / 0.84\n0.92 / 0.92\n0.93 / 0.93\n0.93 / 0.93\n0.89 / 0.89\n0.96 / 0.96\nMacro P/R/F1\n0.87 / 0.84 / 0.84\n0.93 / 0.93 / 0.93\n0.94 / 0.93 / 0.93\n0.94 / 0.94 / 0.93\n0.91 / 0.90 / 0.90\n0.91 / 0.91 / 0.91\nGPT-OSS-20B\nAcc/ F1Micro\n0.87 / 0.87\n0.85 / 0.85\n0.82 / 0.82\n0.82 / 0.82\n0.84 / 0.84\n0.91 / 0.91\nMacro P/R/F1\n0.88 / 0.87 / 0.87\n0.87 / 0.86 / 0.86\n0.85 / 0.83 / 0.82\n0.84 / 0.82 / 0.82\n0.87 / 0.85 / 0.85\n0.92 / 0.92 / 0.91\nLlama-3.1-8B-Instruct\nAcc/ F1Micro\n0.69 / 0.69\n0.63 / 0.63\n0.65 / 0.65\n0.66 / 0.66\n0.67 / 0.67\n0.83 / 0.83\nMacro P/R/F1\n0.76 / 0.66 / 0.67\n0.69 / 0.62 / 0.62\n0.74 / 0.63 / 0.65\n0.71 / 0.65 / 0.65\n0.74 / 0.65 / 0.66\n0.85 / 0.82 / 0.83\nLlama-3.3-70B-Instruct\nAcc/ F1Micro\n0.86 / 0.86\n0.91 / 0.91\n0.92 / 0.92\n0.91 / 0.91\n0.92 / 0.92\n0.95 / 0.95\nMacro P/R/F1\n0.72 / 0.71 / 0.71\n0.91 / 0.91 / 0.91\n0.93 / 0.92 / 0.92\n0.91 / 0.90 / 0.90\n0.92 / 0.92 / 0.92\n0.96 / 0.96 / 0.96\nMistral-7B-Instruct-v0.3\nAcc/ F1Micro\n0.67 / 0.67\n0.68 / 0.68\n0.69 / 0.69\n0.73 / 0.73\n0.72 / 0.72\n0.67 / 0.67\nMacro P/R/F1\n0.79 / 0.67 / 0.70\n0.75 / 0.69 / 0.70\n0.77 / 0.70 / 0.71\n0.78 / 0.73 / 0.74\n0.78 / 0.72 / 0.73\n0.78 / 0.66 / 0.69\nMixtral-8x7B-v0.1\nAcc/ F1Micro\n0.83 / 0.83\n0.83 / 0.83\n0.87 / 0.87\n0.88 / 0.88\n0.84 / 0.84\n0.79 / 0.79\nMacro P/R/F1\n0.86 / 0.83 / 0.84\n0.82 / 0.80 / 0.80\n0.88 / 0.87 / 0.87\n0.90 / 0.89 / 0.89\n0.86 / 0.85 / 0.84\n0.85 / 0.79 / 0.80\nQwen2.5-32B-Instruct\nAcc/ F1Micro\n0.85 / 0.85\n0.90 / 0.90\n0.89 / 0.89\n0.89 / 0.89\n0.87 / 0.87\n0.91 / 0.91\nMacro P/R/F1\n0.84 / 0.84 / 0.84\n0.90 / 0.89 / 0.89\n0.89 / 0.88 / 0.88\n0.89 / 0.87 / 0.88\n0.87 / 0.87 / 0.87\n0.92 / 0.90 / 0.91\nTABLE V: Results of Probe 2, Averaged across the three temperatures (0.0, 0.2 and 0.5)\nSystems\nModel\nMetric\nG1\nG1+G2\nG1+G2+G3\nG2\nG3\nNo-RAG\nAnthropic.Claude-3-Haiku\nAcc/ F1Micro\n0.58 / 0.58\n0.60 / 0.60\n0.62 / 0.62\n0.61 / 0.61\n0.53 / 0.53\n0.61 / 0.61\nMacro P/R/F1\n0.53 / 0.52 / 0.50\n0.57 / 0.57 / 0.55\n0.60 / 0.60 / 0.57\n0.56 / 0.55 / 0.54\n0.50 / 0.49 / 0.47\n0.54 / 0.55 / 0.55\nGPT-OSS-20B\nAcc/ F1Micro\n0.46 / 0.46\n0.50 / 0.50\n0.48 / 0.48\n0.50 / 0.50\n0.44 / 0.44\n0.43 / 0.43\nMacro P/R/F1\n0.56 / 0.45 / 0.45\n0.56 / 0.47 / 0.46\n0.57 / 0.47 / 0.46\n0.63 / 0.51 / 0.48\n0.54 / 0.46 / 0.41\n0.49 / 0.42 / 0.39\nLlama-3.1-8B-Instruct\nAcc/ F1Micro\n0.53 / 0.53\n0.51 / 0.51\n0.48 / 0.48\n0.56 / 0.56\n0.54 / 0.54\n0.61 / 0.61\nMacro P/R/F1\n0.44 / 0.41 / 0.41\n0.47 / 0.41 / 0.42\n0.40 / 0.38 / 0.37\n0.52 / 0.44 / 0.45\n0.45 / 0.41 / 0.40\n0.51 / 0.50 / 0.50\nLlama-3.3-70B-Instruct\nAcc/ F1Micro\n0.58 / 0.58\n0.54 / 0.54\n0.54 / 0.54\n0.59 / 0.59\n0.52 / 0.52\n0.56 / 0.56\nMacro P/R/F1\n0.52 / 0.51 / 0.51\n0.47 / 0.47 / 0.47\n0.51 / 0.50 / 0.49\n0.53 / 0.52 / 0.52\n0.48 / 0.49 / 0.48\n0.52 / 0.49 / 0.49\nMistral-7B-Instruct-v0.3\nAcc/ F1Micro\n0.36 / 0.36\n0.40 / 0.40\n0.39 / 0.39\n0.44 / 0.44\n0.35 / 0.35\n0.38 / 0.38\nMacro P/R/F1\n0.32 / 0.26 / 0.23\n0.46 / 0.31 / 0.29\n0.36 / 0.28 / 0.25\n0.46 / 0.34 / 0.33\n0.38 / 0.27 / 0.24\n0.40 / 0.31 / 0.29\nMixtral-8x7B-v0.1\nAcc/ F1Micro\n0.47 / 0.47\n0.58 / 0.58\n0.57 / 0.57\n0.56 / 0.56\n0.47 / 0.47\n0.46 / 0.46\nMacro P/R/F1\n0.44 / 0.43 / 0.42\n0.55 / 0.54 / 0.54\n0.51 / 0.50 / 0.50\n0.52 / 0.51 / 0.51\n0.45 / 0.44 / 0.43\n0.47 / 0.39 / 0.39\nQwen2.5-32B-Instruct\nAcc/ F1Micro\n0.56 / 0.56\n0.56 / 0.56\n0.55 / 0.55\n0.64 / 0.64\n0.51 / 0.51\n0.65 / 0.65\nMacro P/R/F1\n0.60 / 0.60 / 0.54\n0.59 / 0.61 / 0.55\n0.53 / 0.55 / 0.52\n0.62 / 0.65 / 0.61\n0.51 / 0.53 / 0.48\n0.61 / 0.63 / 0.60\nG\nG +G\nG +G +G\nG\nG\nNo-RAG\nSystem Configuration\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00\nScore\nProbe 1 (Avg. across T = 0.0, 0.2, 0.5): Trend across RAG Configurations\nF1 Micro (mean)\nMacro F1 (mean)\n(a) Probe 1\nG\nG +G\nG +G +G\nG\nG\nNo-RAG\nSystem Configuration\n0.30\n0.35\n0.40\n0.45\n0.50\n0.55\n0.60\n0.65\n0.70\nScore\nProbe 2 (Avg. across T = 0.0, 0.2, 0.5): Trend across RAG Configurations\nF1 Micro (mean)\nMacro F1 (mean)\n(b) Probe 2\nFig. 2: Trends across RAG configurations for the averaged F1 scores of the models in Table IV and V (averaged over\nT = {0.0, 0.2, 0.5}).\nB. How RAG scope interacts with each probe\na) Probe 1: This probe was constructed out of direct\nexisting knowledge, and systems that used G3 directly, ac-\ncessed a single graph that happened to answer all Probe 1\nfacts; however, these did not help these systems, but rather\nintroduced extraneous context, which caused failure:\n• Large generalist models (Llama-3.3-70B). Adding ad-\nditional, tangential evidence, on the basis of G1 only,\ngenerated a huge, significant decline (∗∗∗), smaller, but\nsignificant, declines in the case of G2, G3, and G1+G2\n(∗–∗∗). The model already captures a lot of knowledge\nthat is required to respond to health-based questions.\n• Mid-sized mixture models (Mixtral-8×7B). G2 yields a\nsignificant gain (∗∗) and G1+G2+G3 a smaller gain (∗),\nsuggesting that well-scoped AD evidence helps when\nmerged facts are relevant but not memorized.\n• Smaller instruction models (Llama-3.1-8B). Against all\nKG-RAG settings, the performance is significantly low.\nOne-sample t-test incorrect on Probe 1 (∗–∗∗∗): Sensitive\nto distractors in the case of retrieval of multiple seman-\ntically related facts.\n• Other models. Mistral-7B shows no reliable change on\nProbe 1 (mostly unstarred), while Qwen-2.5-32B shows\nsmall but significant drops for G1 and G3 (∗).\n"}, {"page": 8, "text": "TABLE VI: RAG system comparison on Probe 1: Macro-F1 and significance vs. No-RAG\nModel\nNo-RAG\nG1\nG2\nG1+G2\nG3\nG1+G2+G3\nLlama-3.1-8B-Instruct\n0.83\n0.67∗∗∗\n0.65∗∗\n0.62∗∗∗\n0.66∗∗∗\n0.65\nMistral-7B-Instruct-v0.3\n0.69\n0.70\n0.74\n0.70\n0.73\n0.71\nMixtral-8×7B-v0.1\n0.80\n0.84\n0.89∗∗\n0.80\n0.84\n0.87∗\nQwen-2.5-32B-Instruct\n0.91\n0.84∗\n0.88\n0.89\n0.87∗\n0.88\nGPT-OSS-20B\n0.91\n0.87\n0.82∗\n0.86∗\n0.85∗\n0.82\nAnthropic Claude-3-Haiku\n0.91\n0.84\n0.93\n0.93\n0.90\n0.93\nLlama-3.3-70B-Instruct\n0.96\n0.71∗∗∗\n0.90∗∗\n0.91∗\n0.92∗\n0.92∗∗\nNotes: Stars denote Welch two-sample t-test vs. No-RAG using the three replicates per condition:\n∗p<.05,\n∗∗p<.01,\n∗∗∗p<.001.\nTABLE VII: RAG system comparison on Probe 2: Macro-F1 and significance vs. No-RAG\nModel\nNo-RAG\nG1\nG2\nG1+G2\nG3\nG1+G2+G3\nLlama-3.1-8B-Instruct\n0.50\n0.41∗\n0.45\n0.42∗\n0.40∗\n0.37∗∗\nMistral-7B-Instruct-v0.3\n0.29\n0.23∗\n0.33\n0.29\n0.24∗\n0.25\nMixtral-8×7B-v0.1\n0.39\n0.42\n0.51∗\n0.54∗\n0.43\n0.50∗\nQwen-2.5-32B-Instruct\n0.60\n0.54∗∗\n0.61\n0.55∗\n0.48∗∗\n0.52∗∗\nGPT-OSS-Bb\n0.39\n0.45\n0.48∗\n0.46\n0.41\n0.46\nAnthropic Claude-3-Haiku\n0.55\n0.50∗\n0.54\n0.55\n0.47∗∗\n0.57∗\nLlama-3.3-70B-Instruct\n0.49\n0.51\n0.52\n0.47\n0.48\n0.49\nNotes: Stars denote Welch two-sample t-test vs. No-RAG using the three replicates per condition:\n∗p<.05,\n∗∗p<.01,\n∗∗∗p<.001.\nWhy this pattern? Probe 1 questions reflect the merged\nspace in existing literature, (AD + T2DM) i.e. different from\njust naively joining G1 and G2. When retrieval comes from\na narrower domain (G1 or G2) or an over-broad union\n(G1+G2+G3) the context either misses key merged relations\nor dilutes them with near-miss facts (e.g., disease-specific\nmechanisms that are irrelevant to the asked relation). High\nlevel models, with their substantial common-sense and medical\nknowledge inherent in them, can be readily diverted by near-\nmisses. On the contrary, mid-sized models take advantage of\nfocused AD signal (G2) when it coincides with merged facts\nof a probe.\nb) Probe 2 (formulated on G1 ∩G2).: In this case,\nconsistent evidence between the two diseases will be of\ngreatest importance:\n• Mixtral-8×7B. All of G2, G1+G2, G1+G2+G3 are im-\nproving significantly (∗), a fact that implies that AD-\ncentric cues and their combination with T2DM are quite\nconsistent with the intersection facts.\n• Qwen-2.5-32B.\nThe\nseveral\nsettings\nof\nRAG\n(G1,\nG1+G2, G3, G1+G2+G3) result in important drops (∗–∗∗)\nand G2 is not statistically different to baseline. This indi-\ncates accuracy rather than breadth: AD-specific retrieval\nis less risky than the domain mixture of this probe.\n• Mistral-7B. G1 and G3 indicate minor yet significant\ndeclines (∗); other settings are not significant.\n• Llama-3.1-8B. The vast majority of KG-RAG environ-\nments impair performance (∗–∗∗), which once more indi-\ncates susceptibility to distractors in smaller models.\n• GPT-OSS-20B & Claude-Haiku. Mixed outcomes: some\nmodest gains (e.g., Haiku with G1+G2+G3, ∗) and several\nsignificant drops where the added context conflicts with\nthe intersection signal.\n• Llama-3.3-70B. None of the significant differences is\nobserved- in keeping with a strong prior which is neither\naided nor injured by the retrieved snippets.\nC. Explaining the patterns of stars\nWe want to consider if the RAG is useful or harmful. There\nare three typical processes that we see:\n1) Models are more potential to assist in the event that the\nconstruction space of the probe equals the retrieval space\n(Probe 1 with G3, Probe 2 with G2 or G1+G2). False\npositive (e.g. Probe 2 and G3) enhances contradictions\nand off-target cues and produces ∗/∗∗drops.\n2) The\nrecall\nis\naugmented\nby\nunions\nof\n(G1+G2),\nG1+G2)+G3) but it bring heterogeneous evidence to it.\nOtherwise, the models will overfittingly adapt to spurious\nbut fluent responses, and will produce large drops even\nwith truthful facts.\n3) Larger models tolerate imperfect retrieval better, (as we\nsee in Table VI and VII where we have often unstarred or\nmixed effects. However, these models are also susceptible\nto highly plausible distractors; smaller models rely more\nheavily on retrieved text and thus amplify retrieval noise,\nleading to frequent ∗–∗∗∗drops.\nD. Temperature effects\nSystem-to-system changes in temperature (0, 0.2, 0.5) had\nlittle influence on the conclusions of the RAG type: most in-\nsystem patterns were statistically insignificant, and significant\nones were small compato system differences. In practice, these\nprobes are mainly tuned by RAG choice; temperature tuning\nmust always come second after a well-scoped graph is chosen\nand a strong retriever is selected.\nE. Frontier LLMs and Non-expert Baseline\nWe also posed both probes to two general-purpose LLMs\nand a non-expert human being.\n"}, {"page": 9, "text": "TABLE VIII: Gemini, ChatGPT, and non-expert human per-\nformance on Probe 1 and Probe 2.\nAgent\nProbe 1 (100)\nProbe 2 (110)\nGemini 2.5 Pro\n99/100 (99%)\n69/110 (62.7%)\nChatGPT 5 Thinking\n98/100 (98%)\n77/110 (70.0%)\nNaive Human (no medical knowledge)\n38/100 (38%)\n30/110 (27.3%)\nTable VIII contrasts the accuracy of Gemini, ChatGPT, and\na non-expert human across Probe 1 and Probe 2. Both frontier\nmodels achieve near-ceiling performance on Probe 1 (99%\nand 98%, respectively), revealing that the initial probe tasks\nare largely saturated. In contrast, Probe 2 introduces greater\nconceptual and retrieval difficulty, producing a notable accu-\nracy decline—Gemini drops by 36.3% points, while ChatGPT\nfalls by 28%. The naive human baseline shows only a modest\nrelative decline, but its overall accuracy remains far below\nthat of the models. The naive human baseline is a test for\nrandom guessing, as the people who took the test did not\nhave prior knowledge of the field and were encouraged to\nguess randomly.\nWhen compared with the open-weight counterparts in\nTables IV and V, the frontier models display markedly\nhigher stability and consistency. Anthropic Claude-3-Haiku,\nthe strongest among the smaller systems, achieved accuracies\naround 96% on Probe 1 but fell to roughly 61% on Probe\n2, a pattern mirrored by all the other models. This shows\nthat Probe 2 acts as a discriminative benchmark, separating\nmodels with generalizable reasoning (ChatGPT and Claude-\ntier systems) from those whose performance is more retrieval-\nanchored or domain-fragile.\nChatGPT’s smaller degradation indicates stronger robust-\nness to task complexity and class imbalance, aligning with\nits narrower gap between Micro and Macro F1 in Probe 2.\nGemini’s sharper fall suggests sensitivity to rare or ambiguous\ncases, reinforcing that Probe 2 better exposes differential rea-\nsoning depth rather than surface-level recall. Overall, frontier\nLLMs far exceed human baselines, yet their relative separation\non Probe 2 highlights the probe’s discriminative power for\nevaluating balanced generalization.\nF. Error Analysis\nWe covered the following errors shown in Table IX: (1)\nDirectionality flips (picked B →A instead of A →B), (2)\nTwo-hop chain order errors (mis-ordered A →B →C pairs),\n(3) Negation/exception misreads (e.g., “is not associated” /\n“pick the exception”), (4) Immediate vs. downstream cause\n(selected a true but non-proximal effect), (5) Undefined token\nguesswork (e.g., ambiguous labels like “FX protein”) and (6)\nOverweighting canonical AD triad (Aβ/tau/neuroinflammation\nselected when vascular/metabolic was targeted)\nG. Recommendations\n• When adding several graphs, do so conditionally: by\nputting in a ranker that favors off-topic passages being\ndemoted and evidence being given precedence that is\nfound in both domains of the disease.\nTABLE IX: Miss classification on Probe 2 (33 total errors).\nCategory\nCount\nPercent\nDirectionality flips\n9\n27.27%\nTwo-hop chain order\n8\n24.24%\nNegation/exception\n6\n18.18%\nImmediate vs. downstream\n5\n15.15%\nUndefined token guesswork\n3\n9.09%\nAD-triad overweighting\n2\n6.06%\nTotal\n33\n100%\n• Smaller models benefit most from clean, highly relevant\npassages, while larger models need less context overall\nbut require stricter filtering to avoid distractors.\n• Given\nthree\nruns\nper\ncondition,\nusing\nstar-coding\n(∗/∗∗/∗∗∗) is essential to avoid over-interpreting small\ndifferences in mean values that might not be statistically\nmeaningful.\na) Threats to validity: (1) Only three replicates per cell\nlimit power; results marked unstarred could still harbor small\neffects. (2) Factual mix reproducible by our KG construction\ndecisions (entity normalization, relation filtering, and co-\nreference backbone) determines the factual mix that can be\naccessed, and any improvement or error in this regard directly\ntranslates into the results of QA. (3) Prompting and re-ranking\nwere held fixed; stronger retrieval/re-ranking may change the\nbalance between precision and recall.\nVI. CONCLUSION\nThis work studied domain-specific KG-RAG for healthcare\nLLMs under realistic design choices: graph scope (G1/G2/G3),\nprobe definition (merged vs. intersection), model capacity, and\ndecoding temperature. Three consistent lessons emerged.\n(1) Match retrieval scope to task scope. Probe 1 (merged\nAD -T2DM relations) is best served by retrieval that is to\na large extent coincidental with the relations (e.g. G3 or\nmore specific union of G2), whereas Probe 2 (intersection-\nstyle questions) is best served by G2 or G1+G2 rather than\nexcessively broad unions.\n(2) Favor precision over breadth. Uniting graphs increases\nrecall but also injects heterogeneous evidence; without strong\nranking/filters, distractors lower accuracy. Precision-first re-\ntrieval with scope-matched graphs is more reliable.\n(3) Right-size KG-RAG to model capacity. Smaller and\nmid-sized models gain the most from clean, well-scoped\nretrieval (notably with G2). Larger models often match or\nsurpass KG-RAG with No-RAG on merged-scope questions,\nreflecting strong parametric knowledge and a higher sensitivity\nto noisy context.\nPractically, teams should: (i) choose graphs that match\ntheir question distribution; (ii) deploy rankers/filters that shed\noff-topic spans and reward corroborated evidence; and (iii)\ntailor retrieval strictness to model size. Future work includes\nrisk-aware reranking, dynamic graph selection conditioned\non query intent, and multi-hop reasoning that exploits KG\nstructure without flooding prompts with near-miss facts.\n"}, {"page": 10, "text": "VII. LIMITATIONS\nWe highlight key limitations and threats to validity of this\nstudy.\n1) Our graphs are centered on T2DM (G1), AD (G2) and\nAD+T2DM (G3) space. Findings might not be related to\nother conditions, specialities, non-PubMed corpora, and\nmultilingual environments\n2) Although co-reference and canonicalization have been\nimproved, the errors in entity connecting, synonym merg-\ning, and relation extracting may be carried over to the\nretrieval to produce plausible yet off-target evidence\nthat diminishes accuracy. We used rule-based filtering to\nreduce false positives, but the graph is not 100% perfect.\n3) We did not actively search retriever depth, hybrid lexical\nneural retrieval or learning-to-rank rerankers. A more\npowerful ranking stack that has the potential to minimize\ndistractors, particularly on union graphs.\n4) Accuracy, Macro P/R/F1, and Micro F1 fail to reflect on\ncalibration, factual grounding to primary sources and clin-\nical harm potential. The fact-checking based on human\njudgment and reference was out of the question.\n5) The findings on smaller vs. larger models might not be\ngeneralizable to other architectures, tokenizer selection,\nalignment processes or domain-trained checkpoints.\n6) Our setup omits latency, cost, privacy, and PHI-handling\nconstraints crucial in clinical workflows in this pilot\nstudy. Deployment-time retrieval drift, updates to liter-\nature, and governance requirements are not modeled.\n7) Since we had to run on a few resources, we did not\ncarry out large multi-seed reruns, ablations of KG pre-\nprocessing steps, or confidence-interval reporting over\nall settings; here, some of the effects may be due to\nstochasticity.\nACKNOWLEDGMENT\nThe authors would like to thank Paul Josiah, Toluwalase Kunle-\nJohn and Elizabeth Oyegoke for volunteering to take the test for the\nnaive human baseline.\nREFERENCES\n[1] A. Vb, D. K. Jha, and S. Bhattacharjee, “Global trends and burden\nof diabetes: A comprehensive review of global insights and emerging\nchallenges,” Current Journal of Applied Science and Technology, vol. 44,\nno. 7, pp. 134–150, 2025.\n[2] R. López-Antón, “Recent advances in alzheimer’s disease research: from\nbiomarkers to therapeutic frontiers,” Biomedicines, vol. 12, no. 12, p.\n2816, 2024.\n[3] M. A Kamal, S. Priyamvada, A. N Anbazhagan, N. R Jabir, S. Tabrez,\nand N. H Greig, “Linking alzheimer’s disease and type 2 diabetes\nmellitus via aberrant insulin signaling and inflammation,” CNS &\nNeurological Disorders-Drug Targets (Formerly Current Drug Targets-\nCNS & Neurological Disorders), vol. 13, no. 2, pp. 338–346, 2014.\n[4] A. Association, “2015 alzheimer’s disease facts and figures,” Alzheimer’s\n& Dementia, vol. 11, no. 3, pp. 332–384, 2015.\n[5] M. D. Mezey, E. L. Mitty, M. M. Bottrell, G. C. Ramsey, and T. Fisher,\n“Advance directives: Older adults with dementia,” Clinics in Geriatric\nMedicine, vol. 16, no. 2, pp. 255–268, 2000.\n[6] M. Schwarzinger and C. Dufouil, “Forecasting the prevalence of demen-\ntia,” The Lancet Public Health, vol. 7, no. 2, pp. e94–e95, 2022.\n[7] G. Logroscino, “Prevention of alzheimer’s disease and dementia: the\nevidence is out there, but new high-quality studies and implementation\nare needed,” 2020.\n[8] R. R. Kalyani, J. J. Neumiller, N. M. Maruthur, and D. J. Wexler,\n“Diagnosis and treatment of type 2 diabetes in adults: A review,” JAMA,\n2025.\n[9] Y. Zheng, S. H. Ley, and F. B. Hu, “Global aetiology and epidemiology\nof type 2 diabetes mellitus and its complications,” Nature reviews\nendocrinology, vol. 14, no. 2, pp. 88–98, 2018.\n[10] C. Procaccini, M. Santopaolo, D. Faicchia, A. Colamatteo, L. Formisano,\nP. de Candia, M. Galgani, V. De Rosa, and G. Matarese, “Role of\nmetabolism in neurodegenerative disorders,” Metabolism, vol. 65, no. 9,\npp. 1376–1390, 2016.\n[11] M. Barbagallo and L. J. Dominguez, “Type 2 diabetes mellitus and\nalzheimer’s disease,” World journal of diabetes, vol. 5, no. 6, p. 889,\n2014.\n[12] C. Bellia, M. Lombardo, M. Meloni, D. Della-Morte, A. Bellia, and\nD. Lauro, “Diabetes and cognitive decline,” Advances in clinical chem-\nistry, vol. 108, pp. 37–71, 2022.\n[13] M. Kciuk, W. Kruczkowska, J. Gał˛eziewska, K. Wanke, ˙Z. Kałuzi´nska-\nKołat, M. Aleksandrowicz, and R. Kontek, “Alzheimer’s disease as\ntype 3 diabetes: Understanding the link and implications,” International\nJournal of Molecular Sciences, vol. 25, no. 22, p. 11955, 2024.\n[14] E. Blázquez, E. Velázquez, V. Hurtado-Carneiro, and J. M. Ruiz-\nAlbusac, “Insulin in the brain: its pathophysiological implications for\nstates related with central insulin resistance, type 2 diabetes and\nalzheimer’s disease,” Frontiers in endocrinology, vol. 5, p. 161, 2014.\n[15] E. Abdelgadir, R. Ali, F. Rashid, and A. Bashier, “Effect of metformin\non different non-diabetes related conditions, a special focus on malignant\nconditions: review of literature,” Journal of clinical medicine research,\nvol. 9, no. 5, p. 388, 2017.\n[16] S. M. De la Monte, “Type 3 diabetes is sporadic alzheimer’s disease:\nmini-review,” European neuropsychopharmacology, vol. 24, no. 12, pp.\n1954–1960, 2014.\n[17] Z. Kroner, “The relationship between alzheimer’s disease and diabetes:\nType 3 diabetes?” Alternative Medicine Review, vol. 14, no. 4, p. 373,\n2009.\n[18] J. Leszek, E. Trypka, V. V Tarasov, G. Md Ashraf, and G. Aliev, “Type\n3 diabetes mellitus: a novel implication of alzheimers disease,” Current\ntopics in medicinal chemistry, vol. 17, no. 12, pp. 1331–1335, 2017.\n[19] A. Lacerda, G. Pappa, A. C. M. Pereira, W. M. Jr, and A. G.\nde Almeida Barros, “Evaluation of medical large language models:\nTaxonomy, review, and directions.”\n[20] Y. Wang, R. E. Mercer, F. Rudzicz, S. S. Roy, P. Ren, Z. Chen, and\nX. Wang, “Trustworthy medical question answering: An evaluation-\ncentric survey,” arXiv preprint arXiv:2506.03659, 2025.\n[21] W. Wu, H. Wang, B. Li, P. Huang, X. Zhao, and L. Liang, “Multirag:\na knowledge-guided framework for mitigating hallucination in multi-\nsource retrieval augmented generation,” in 2025 IEEE 41st International\nConference on Data Engineering (ICDE). IEEE, 2025, pp. 3070–3083.\n[22] H. N. Yassine and C. E. Finch, “Apoe alleles and diet in brain aging and\nalzheimer’s disease,” Frontiers in aging neuroscience, vol. 12, p. 150,\n2020.\n[23] K. Jabeen, K. Rehman, and M. S. H. Akash, “Genetic mutations of\napoeε4 carriers in cardiovascular patients lead to the development of in-\nsulin resistance and risk of alzheimer’s disease,” Journal of biochemical\nand molecular toxicology, vol. 36, no. 2, p. e22953, 2022.\n[24] L. Exalto, R. Whitmer, L. Kappele, and G. Biessels, “An update on type\n2 diabetes, vascular dementia and alzheimer’s disease,” Experimental\ngerontology, vol. 47, no. 11, pp. 858–864, 2012.\n[25] K. Soman, P. W. Rose, J. H. Morris, R. E. Akbas, B. Smith, B. Peetoom,\nC. Villouta-Reyes, G. Cerono, Y. Shi, A. Rizk-Jackson et al., “Biomed-\nical knowledge graph-optimized prompt generation for large language\nmodels,” Bioinformatics, vol. 40, no. 9, p. btae560, 2024.\n[26] S. Anuyah, M. M. Kaushik, K. Dwarampudi, R. Shiradkar, A. Durresi,\nand S. Chakraborty, “Automated knowledge graph construction using\nlarge language models and sentence complexity modelling,” arXiv\npreprint arXiv:2509.17289, 2025.\n[27] Z. Gao, Y. Cao, H. Wang, A. Ke, Y. Feng, X. Xie, and S. K. Zhou, “Frag:\nA flexible modular framework for retrieval-augmented generation based\non knowledge graphs,” arXiv preprint arXiv:2501.09957, 2025.\n[28] J. Linders and J. M. Tomczak, “Knowledge graph-extended re-\ntrieval augmented generation for question answering,” arXiv preprint\narXiv:2504.08893, 2025.\n"}]}