{"doc_id": "arxiv:2601.06875", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2601.06875.pdf", "meta": {"doc_id": "arxiv:2601.06875", "source": "arxiv", "arxiv_id": "2601.06875", "title": "An Ubuntu-Guided Large Language Model Framework for Cognitive Behavioral Mental Health Dialogue", "authors": ["Sontaga G. Forane", "Absalom E. Ezugwu", "Kevin Igwe", "Karen van den Berg"], "published": "2026-01-11T11:50:18Z", "updated": "2026-01-11T11:50:18Z", "summary": "South Africa's escalating mental health crisis, compounded by limited access to culturally responsive care, calls for innovative and contextually grounded interventions. While large language models show considerable promise for mental health support, their predominantly Western-centric training data limit cultural and linguistic applicability in African contexts. This study introduces a proof-of-concept framework that integrates cognitive behavioral therapy with the African philosophy of Ubuntu to create a culturally sensitive, emotionally intelligent, AI-driven mental health dialogue system. Guided by a design science research methodology, the framework applies both deep theoretical and therapeutic adaptations as well as surface-level linguistic and communicative cultural adaptations. Key CBT techniques, including behavioral activation and cognitive restructuring, were reinterpreted through Ubuntu principles that emphasize communal well-being, spiritual grounding, and interconnectedness. A culturally adapted dataset was developed through iterative processes of language simplification, spiritual contextualization, and Ubuntu-based reframing. The fine-tuned model was evaluated through expert-informed case studies, employing UniEval for conversational quality assessment alongside additional measures of CBT reliability and cultural linguistic alignment. Results demonstrate that the model effectively engages in empathetic, context-aware dialogue aligned with both therapeutic and cultural objectives. Although real-time end-user testing has not yet been conducted, the model underwent rigorous review and supervision by domain specialist clinical psychologists. The findings highlight the potential of culturally embedded emotional intelligence to enhance the contextual relevance, inclusivity, and effectiveness of AI-driven mental health interventions across African settings.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2601.06875v1", "url_pdf": "https://arxiv.org/pdf/2601.06875.pdf", "meta_path": "data/raw/arxiv/meta/2601.06875.json", "sha256": "ffede44439ee1c0d44eec287352d96577c32c0708986beefe9ef9fb6e4abe943", "status": "ok", "fetched_at": "2026-02-18T02:21:42.579934+00:00"}, "pages": [{"page": 1, "text": "An Ubuntu-Guided Large Language Model Framework for \nCognitive Behavioral Mental Health Dialogue \n \nSontaga G. Forane1, Absalom E. Ezugwu1,*, Kevin Igwe2, Karen van den Berg1  \n \n1 Unit for Data Science and Computing, North-West University, 11 Hoffman Street, Potchefstroom, 2520, \nNorth-West, South Africa. \n2 Department of Psychology, Faculty of Humanities, University of Johannesburg, Bunting Road, Auckland Park, \nJohannesburg 2092, South Africa. \n \nAuthors emails: Sontaga G. Forane (34228128@mynwu.ac.za), Absalom E. Ezugwu \n(Absalom.Ezugwu@nwu.ac.za), Kevin Igwe (kigwe@uj.ac.za), Karen van den Berg \n(Karen.Pretorius@nwu.ac.za) \n \nAbstract. South Africa’s escalating mental health crisis, compounded by limited access to culturally responsive \ncare, calls for innovative and contextually grounded interventions. While Large Language Models (LLMs) show \nconsiderable promise for mental health support, their predominantly Western-centric training data limit cultural \nand linguistic applicability in African contexts. This study introduces a proof-of-concept framework that \nintegrates Cognitive Behavioural Therapy (CBT) with the African philosophy of Ubuntu to create a culturally \nsensitive, emotionally intelligent, AI-driven mental health dialogue system. Guided by a Design Science \nResearch (DSR) methodology, the framework applies both deep (theoretical and therapeutic) and surface-level \n(linguistic and communicative) cultural adaptations. Key CBT techniques, Behavioural Activation and \nCognitive Restructuring, were reinterpreted through Ubuntu principles emphasizing communal well-being, \nspiritual grounding, and interconnectedness. A culturally adapted dataset was developed through iterative \nprocesses of language simplification, spiritual contextualization, and Ubuntu-based reframing. The fine-tuned \nmodel was evaluated through expert-informed case studies, employing UniEval for conversational quality \nassessment and additional measures of CBT reliability and cultural-linguistic alignment. Results demonstrate \nthat the model effectively engages in empathetic, context-aware dialogue aligned with both therapeutic and \ncultural objectives. Although real-time end-user testing has not yet been conducted, the model underwent \nrigorous review and supervision by domain-specialist clinical psychologists. The findings highlight the potential \nof culturally embedded emotional intelligence in enhancing the contextual relevance, inclusivity, and \neffectiveness of AI-driven mental health interventions across African settings. \nKeywords: Cultural context, mental health, emotional intelligence, foundation models, large language models, \nUbuntu, cognitive behavioral therapy. \n \n1. Introduction \nArtificial intelligence (AI) has undergone rapid advancements in recent years, particularly in the development of \nLarge Language Models (LLMs) such as Gemini and GPT-4. These models have demonstrated remarkable \ncapabilities in generating human-like text, performing complex analysis, and interpreting data at scale (Hadi et \nal., 2023). Their applications span multiple domains, including medicine, education, finance, and mental health \nresearch (Chen et al., 2023; Hadi et al., 2023; Li et al., 2023; Zhao et al., 2024; Chow and Li, 2025). While \nLLMs have been successfully integrated into various fields, their adaptation to culturally diverse contexts, such \nas Africa, remains a significant challenge. Despite their growing utility, most LLMs are trained on datasets that \nreflect predominantly Western cultural values (Bender et al., 2021). This training bias raises concerns about \ntheir applicability in non-Western contexts, particularly in African societies where communal values and \ncultural philosophies such as Ubuntu play a critical role in shaping societal interactions (Nwoye, 2015). This \nstudy seeks to explore how LLMs can be adapted to align with African cultural perspectives, particularly in the \ncontext of mental health interventions, by integrating the principles of Emotional Intelligence (EI) and the \nAfrican philosophy of Ubuntu. \n \n* Corresponding author. Absalom El-Shamir. \nE-mail address: Absalom.ezugwu@nwu.ac.za \n"}, {"page": 2, "text": "Mental health disorders, particularly anxiety and depression, are growing global concerns, significantly \nimpacting individuals and societies worldwide (Kola et al., 2021; Organization, 2017). In Africa, the situation is \nfurther complicated by limited access to mental health care, social stigma, and a shortage of culturally sensitive \ninterventions (Anakwenze, 2022). In South Africa, where mental health challenges are increasingly prevalent, \nexisting psychological support systems often fail to resonate with African cultural values that emphasize \ninterconnectedness and community well-being (Nwoye, 2015; Suliman et al., 2024). \nCognitive behavioral therapy (CBT) is widely recognized as a gold-standard treatment for anxiety and \ndepression (Beck, 2011; Jiang et al., 2024). While digital interventions such as Computer-Based Cognitive \nBehavioural Therapy (CCBT) and Internet-Based Cognitive Behavioural Therapy (ICBT) have demonstrated \nsuccess (Izumi et al., 2024; Jiang et al., 2024), it is important to note that systematic reviews and meta-analyses \nconsistently show that conventional, face-to-face psychotherapy achieves larger effect sizes in treating \nconditions like depression, particularly in head-to-head comparisons (Cuijpers et al., 2019; Carlbring et al., \n2018). The primary challenges for digital modalities include high dropout rates and a lack of cultural adaptation, \nwhich have significantly limited their effectiveness and reach in non-Western societies (Anakwenze, 2022; \nNaeem et al., 2019; Pakomera et al., 2017).  \nSeveral studies have highlighted the importance of incorporating cultural contexts into digital mental health \ninterventions, with successful implementations observed in China, Colombia, Indonesia, and Latino \ncommunities (Arjadi et al., 2018; Davidson et al., 2015; Hamka et al., 2022; Salamanca-Sanabria et al., 2019). \nHowever, similar culturally adapted AI-driven mental health solutions remain underexplored in South Africa. \nWestern psychological frameworks, such as traditional CBT, emphasize individualism and personal \nresponsibility, contrasting with African communal values centered on collective well-being (Wilson & \nWilliams, 2013). Moreover, most LLMS are trained on Western-centric data, which often lacks representation \nof African worldviews and emotional expressions. This limits their effectiveness in providing culturally relevant \npsychological support within African contexts. \nTo address these cultural limitations in digital mental health interventions, it is not only important to adapt \ntherapeutic content but also to enhance the sensitivity of AI tools to emotional and contextual cues. One \npromising approach is the integration of Emotional intelligence (EI) into LLMs. EI refers to the ability to \nperceive, understand, and manage emotions (Salovey et al., 2009). In this study, EI is defined as the capacity of \nan LLM to interpret and respond appropriately to emotions expressed in text while considering the user’s \ncultural context. Understanding emotions is crucial in mental health applications, where emotional nuances \nsignificantly influence therapeutic outcomes. \nThis study aims to bridge this gap by developing a framework for emotionally intelligent LLMs that \nincorporates the African cultural context. By doing so, it seeks to improve AI-driven mental health \ninterventions, ensuring their relevance and applicability in South African settings. This research addresses two \nkey questions: (1) Can LLMs be trained to be contextually aware of African emotional intelligence? (2) Could \nan LLM serve as a tool for professional psychologists to detect and support diagnoses of depression and anxiety \nin the African context? \nWhile LLMs have demonstrated effectiveness in various applications, their reliance on Western-centric training \ndata limits their cultural relevance in African settings (Chow and Li, 2024). Moreover, Chow and Li (2024) \nhighlight that datasets primarily derived from Western medical literature and patient interactions may introduce \nsignificant bias by overrepresenting certain demographic groups. This underscores the fact that many existing \ndigital mental health solutions often fail to incorporate African cultural values or contextual factors specific to \nAfrica-centric settings, where community and interconnectedness are deeply emphasized (Anakwenze, 2022; \nRamos et al., 2021). The lack of culturally appropriate AI-driven mental health support systems exacerbates the \nmental health crisis in South Africa, where stigma and limited access to care are significant barriers. \nFurthermore, conventional CBT interventions do not fully align with African communal values, potentially \ndiminishing their effectiveness. This study seeks to develop a culturally adapted LLM-based framework that \nintegrates Ubuntu and Emotional Intelligence principles to improve AI-driven mental health interventions in \nSouth Africa. The following research questions form the basis for the current research. \ni. \nHow can emotional intelligence principles be integrated with Africa-centric cultural contexts to \nenhance the effectiveness of AI-driven mental health support systems? \nii. \nWhat are the potential benefits and challenges of implementing AI-driven mental health support \nframeworks that incorporate emotional intelligence within diverse African communities? \niii. \nHow can the challenges of trust within a cultural context be addressed when implementing emotionally \nintelligent AI-driven mental health support systems in Africa? \n"}, {"page": 3, "text": "iv. \nAre large language models (such as ChatGPT) ready to be assistive tools for detecting depression and \nanxiety? \nFurthermore, this research aims to establish a proof-of-concept by developing (1) a framework for emotionally \nintelligent large language models that incorporate and (2) evaluate the capability of these LLMs to detect \ndepression and anxiety from texts that reflect African cultural nuances. To achieve these dual aims, the research \nwill focus on the following specific objective:  \ni. \nConduct an in-depth literature review of LLM applications in eHealth, examining their current use, the \ntechniques used to adapt them, and identifying gaps in cultural relevance and emotional intelligence \nintegration. \nii. \nInvestigate how existing mental health applications integrate cultural context and operationalize \nculturally relevant content like themes, metaphors, and perspectives of mental health within different \ncontexts. \niii. \nDevelop a proof-of-concept framework for integrating emotional intelligence into LLMs, informed by \nUbuntu and designed to reflect the cultural norms and emotional expressions common in South African \ncommunities. \niv. \nImplement the proposed framework within an AI-powered mental health support application, \nleveraging a fine-tuned LLM to operationalize the framework. \nv. \nEvaluate the model’s alignment with the proposed culturally adapted framework, focusing on its \napplication of Ubuntu-aligned CBT techniques and culturally appropriate communication strategies to \nassess its overall cultural sensitivity. \nThis research contributes to the growing body of work on AI-driven mental health interventions by introducing \na culturally adapted framework for LLMs in African contexts. By integrating Ubuntu and Emotional \nIntelligence principles, this study aims to enhance the relevance and effectiveness of AI in mental health \nsupport. The findings could help bridge the gap between technological advancements and cultural sensitivity in \nAI applications for healthcare. Furthermore, this study aligns with ongoing efforts to enhance Diversity, Equity, \nand Inclusion (DEI) in AI research (Ramos et al., 2021). It provides insights into how AI can be adapted to \nserve underrepresented communities, thereby promoting more inclusive mental health solutions. Additionally, \nthis research has practical implications for psychologists, mental health practitioners, and AI developers by \nproviding guidelines for creating culturally aware AI-driven mental health support systems. \nThe remainder of this paper is structured as follows: Section 2 reviews literature on Diversity, Equity, and \nInclusion (DEI), Cognitive Behavioural Therapy (CBT) in AI, and emotional intelligence (EI) frameworks, with \na focus on cultural adaptation and methods for integrating EI into existing LLMs. Section 3 outlines the research \ndesign, system architecture, and methodology for incorporating DEI and EI into an LLM-based eHealth \nframework. Section 4 presents the results and discusses the effectiveness of the system in addressing mental \nhealth challenges in South Africa, similarly, the section also highlights key findings, limitations, and future \nresearch directions for culturally sensitive eHealth interventions. Section 5 concludes the paper. \n \n2. Literature Review  \nThis section presents a summary overview of medical chatbots and then followed by a comprehensive literature \nreview across six key domains: (1) Diversity, Equity, and Inclusion (DEI), (2) Cultural adaptation and cultural \ngrounding, (3) Cognitive Behavioral Therapy (CBT) in the treatment of anxiety and depression, (4) Techniques \nfor addressing mental health in eHealth applications, (5) Strategies for incorporating emotional intelligence into \nLLMs, and (6) Fine-tuning LLMs in the context of mental health. The review begins by examining the role of \nDEI in mental health applications, followed by an exploration of culturally adapted and culturally grounded \ninterventions. It then discusses current techniques used in eHealth applications for mental health support, along \nwith approaches for integrating emotional intelligence into LLMs. This review establishes the foundation for a \nmultifaceted approach to effective mental health interventions, emphasizing cultural and contextual adaptation, \nemotional intelligence, and AI-driven support. In this context, mental health alleviation refers to mitigating \nsymptoms of common mental disorders before the need for intervention by a mental health professional. \nThe LLMs hold significant promise for advancing medical chatbots by enabling natural, context-aware \ninteractions (Chow, Sanders, and Li, 2023; Parsa, and Ebrahimzadeh, 2023; Loh, 2023). Trained on medical \nliterature, clinical guidelines, and patient dialogues, they can provide real-time, evidence-based information on \nsymptoms, treatments, and disease management. These models assist in triaging patient concerns, guiding users \nto appropriate care, and adapting to linguistic and cultural nuances, thereby enhancing accessibility for diverse \n"}, {"page": 4, "text": "populations (Wei et al. 2024). Their continuous learning capability also supports personalized healthcare, early \nintervention, and remote care, particularly in underserved regions facing shortages of medical professionals and \nadvanced facilities. \nHowever, despite their promise, the application of LLMs in medical chatbots also presents several notable \nchallenges and risks. One major concern is the potential for misinformation or inaccurate responses, especially \nin high-stakes situations where incorrect guidance could have serious health consequences. LLMs may also \ngenerate plausible-sounding but medically invalid advice due to limitations in their training data or a lack of \nreal-time clinical validation. Additionally, these models often inherit biases present in their training datasets, \nwhich can lead to unequal treatment recommendations across different demographic groups. Privacy and data \nsecurity are further concerns, as handling sensitive patient information requires strict compliance with \nhealthcare regulations like HIPAA or GDPR. Finally, over-reliance on chatbots may discourage users from \nseeking professional medical care, especially in contexts where access to human healthcare providers is already \nlimited. For further insights into the potential benefits and challenges of medical chatbots in real-world \napplications, see Chow and Li (2024), Chow, Wong, and Li (2024), and Wei et al. (2024). Subsequently, we \nthen narrowed our review to examine current research within the African healthcare landscape. \n \n2.1 Overview of Diversity, Equity, and Inclusion  \nThe emerging field of digital mental health presents a unique opportunity to bridge the significant gap in mental \nhealth service provision. However, this potential can only be realized when the tools developed in this context of \nmental health applications are accessible, relevant, and effective for all users, especially considering the fact that \nmarginalized groups are disproportionately affected by mental health disparities (Ramos et al., 2021). These \ndisparities are fuelled by unequal access to mental health providers, logistical barriers, a lack of culturally robust \nservices, and stigma, which are more acute in marginalized populations, including those with low \nsocioeconomic status (SES) and people of color (POC) (Ramos et al., 2021). These groups often rely on \nsmartphones for internet access, suggesting that mental health applications could play a crucial role in \nmitigating professional shortages and logistical barriers to care. \nMultiple studies have highlighted the interest and potential benefits of incorporating diversity, equity, and \ninclusion (DEI) principles in mental health applications (Denecke et al., 2022; Naslund et al., 2019; Ramos et \nal., 2021). Although there is no consensus on the definition of DEI (Vernon, 2023), this study defines DEI as \nfollows:  Diversity refers to ensuring that mental health applications are designed to cater to the varying needs \nand backgrounds of all individuals, including those from marginalized communities (Vernon, 2023). This \ninvolves considering different cultural, linguistic, and socioeconomic factors in the development of the apps \n(Ramos et al., 2021).  However, having one app that caters to all cultures is highly infeasible. With this in mind, \nthis study focuses on three components—Social Norms and Values (e.g., use of appropriate titles such as \n‘Mama’ or ‘Tata’), Language and Communication Styles (e.g., greeting with ‘Sawubona’), and Religious and \nSpiritual Beliefs (e.g., integrating biblical references or ancestral reverence), collectively referred to in this study \nas the Cultural Context. \nEquity focuses on addressing the existing disparities in mental health access and outcomes by ensuring that the \napps provide fair and equal opportunities for all users to receive adequate support and care (Vernon, 2023). This \nmay involve tailoring the apps to accommodate different levels of access to resources and services (Ramos et \nal., 2021). \nInclusion entails creating a welcoming and inclusive environment within the apps that respects and values the \ndiverse perspectives and experiences of all users (Vernon, 2023). This may involve incorporating diverse \nrepresentation in the app content and considering the different ways in which individuals from marginalized \ncommunities access and engage with interventions, ultimately promoting greater inclusivity and effectiveness in \nmental health disparities (Ramos et al., 2021). Research has shown that individuals from ethnic and racial \nminorities express interest in accessing mental health services through social media platforms (Anakwenze, \n2022). For example, a survey of social media users with mental illness found that the majority were interested in \naccessing mental health programs on social media, targeting symptom management, health promotion, and \nsupport for communicating with healthcare providers and interacting with the health system (Anakwenze, 2022).  \nAdditionally, it is crucial to consider the perspectives and experiences of the target population (Naslund et al., \n2020). In so doing, we can develop interventions that are tailored to their specific needs and preferences. \nMoreover, research has shown that individuals with serious mental illness have stressed the importance of \nhaving culturally responsive and inclusive mental health interventions on social media (Spanhel et al., 2021). \nThis includes considering cultural beliefs, determining language preferences, and addressing structural barriers \nhindering access to mental health resources. Incorporating inclusion principles in mental health applications is \n"}, {"page": 5, "text": "essential to address the disparities faced by marginalized populations. By acknowledging and addressing these \ndisparities, mental health applications can help bridge the gap in access to mental health services and provide \nsupport to individuals from diverse backgrounds. \nIncorporating diversity, equity, and inclusion in mental health applications can help address the specific needs \nand preferences of individuals from diverse backgrounds and ensure that mental health support is accessible to \nall, regardless of their socioeconomic status or geographic location (Mapes et al., 2020; Ramos et al., 2021). \nDespite the promise of mental health applications, many lack empirical evidence supporting their effectiveness, \npartly due to insufficient integration of diversity, equity, and inclusion in DEI consideration in their \ndevelopment and evaluation (Ramos et al., 2021). DEI in the digital realm necessitates ensuring all individuals \nand communities, particularly the most disadvantaged, have the technological capacity needed for full \nparticipation in our society. This encompasses making mental health technology adaptable and accessible to \nmeet diverse needs, encompassing various factors such as age, gender, sexuality, race, ethnicity, culture, and \nsocioeconomic status (Ramos et al., 2021). The need for DEI considerations is highlighted by the observation \nthat most mental health applications have been developed and tested primarily within high-income Western \npopulations, without adequately considering the unique experiences of low and middle-income populations, \nsuch as those in Africa (Caloudas et al., 2023), and in the context of this study, South Africa. \nUnfortunately, the development and testing of most mental health applications have not adequately considered \nthe unique experiences of low-income groups, such as those in African countries, such as South Africa \n(Caloudas et al., 2023). This oversight potentially limits the effectiveness and acceptability of the app among \nthese populations. Furthermore, the content and representation within apps often lack the inclusion necessary to \nengage users from varied backgrounds effectively. Many existing evaluation frameworks for application quality \ndo not consistently assess DEI considerations, which are crucial for reducing health disparities and ensuring the \nbroad usability of mental health applications (Vernon, 2023). \nBeyond policy and discourse, practical manifestations of diversity, equity, and inclusion are increasingly evident \nin African artificial intelligence and natural language processing (NLP) initiatives. The Masakhane project \n(Orife et al., 2020) exemplifies a pan-African, community-driven approach to machine translation and NLP, \npromoting the development of language technologies for Africans, by Africans. Such initiatives counterbalance \nthe historical dominance of Western-centric datasets and algorithms by prioritizing African linguistic and \ncultural representation in AI systems. Building upon this foundation, projects such as MasakhaNER (Adelani et \nal., 2021) and MasakhaNER 2.0 (Adelani et al., 2022) have produced annotated datasets for named entity \nrecognition across multiple African languages, advancing equitable access to NLP resources. More recently, \nMasakhaNEWS (Adelani et al., 2023) extended this work to text classification tasks, highlighting the potential \nof multilingual AI for African media and communication contexts. Within South Africa, Gaustad and McKellar \n(2024) have expanded the availability of morphologically annotated corpora for nine of the country’s official \nlanguages, providing essential resources for language-sensitive applications. Together, these African NLP \ninitiatives exemplify how DEI principles can be operationalized through inclusive data creation, collaboration, \nand technological empowerment, laying the groundwork for culturally responsive AI systems in domains such \nas mental health. \nFor mental health applications to fulfill their potential as tools for mental health crises in African countries such \nas South Africa, considerations of diversity, equity, and inclusion must be central to their development. By \ndoing so, these digital interventions can become genuinely inclusive, ensuring that all users can access effective, \nculturally competent mental health support regardless of their background. Although this study focuses on \ncultural adaptation as a crucial component of the inclusion aspect of DEI, it is important to note that diversity, \nequity, and inclusion are not mutually exclusive but overlap with each other.  \n \n2.2 Cultural adaptation vs. Culturally grounded interventions \nCulturally grounded interventions are approaches to therapy or mental health interventions rooted in a deep \nunderstanding and acknowledgement of the cultural background and beliefs of the individuals receiving the \nservices (Anakwenze, 2022; Caloudas et al., 2023). These interventions are tailored to the specific cultural, \nsocial, and psychological needs of different communities and are designed to be sensitive and responsive to the \nunique contexts in which they are implemented. Culturally grounded interventions often involve collaboration \nwith community leaders and members to ensure that the services provided are relevant and effective within a \nspecific cultural context (Anakwenze, 2022; Spanhel et al., 2021) \nCultural adaptation involves modifying interventions or treatments to enhance their relevance, acceptability, and \neffectiveness for individuals from diverse cultural backgrounds (Anakwenze, 2022; Caloudas et al., 2023). This \n"}, {"page": 6, "text": "process integrates cultural beliefs, values, practices, and language to ensure accessibility and appropriateness for \nthe target population (Anakwenze, 2022). It encompasses two types of modifications: surface structure changes, \nwhich involve basic adaptations to fit interventions within specific cultural contexts, and deep structure changes, \nwhich incorporate elements that reflect culturally specific understandings of mental illness and account for the \nbroader social, historical, and environmental influences on health behaviors (Anakwenze, 2022; Caloudas et al., \n2023).  \nIt is important to note that evidence for the added effectiveness of cultural adaptation in digital mental health is \nnot unequivocal. The studies by Lorenzo-Luaces et al. (2021) and De Jesús-Romero et al. (2024) found that \nwhile cultural adaptation can improve acceptability and engagement, it does not consistently lead to superior \nclinical outcomes or cost-effectiveness compared to non-adapted interventions. This study, however, posits that \ndeep-structure cultural adaptation remains critical in this context for several key reasons: \n• \nAddressing Foundational Mismatch: The individualistic underpinnings of standard CBT represent a \nprofound philosophical mismatch with the communitarian values prevalent in many African societies. \nA simple translation is insufficient; a deep-structure realignment is necessary for the intervention to be \nconceptually coherent. \n• \nPrioritizing Engagement: In a context like South Africa, where stigma is a major barrier, the primary \ninitial challenge is not necessarily efficacy but engagement. An intervention that is culturally resonant \nis more likely to be used, which is a prerequisite for any therapeutic effect. \n• \nBeyond Surface-Level Changes: Many adaptations in the literature are limited to translation and \nsurface-level changes. This study integrates the Ubuntu philosophy at a theoretical level, aiming to \nmodify the therapeutic mechanisms themselves, which may yield different results from the adaptations \ncritiqued in the literature. \nTherefore, while the critique from Lorenzo-Luaces et al. (2021) rightly highlights the need for rigorous \nevaluation, it does not negate the value of a deep, theory-driven adaptation. In this case, adaptation is pursued as \nan essential strategy to ensure ethical alignment, relevance, and potential real-world impact, with its ultimate \nvalue to be determined empirically. \nCultural adaptation in mental health applications entails adding cultural content to ensure it appeals to people \nfrom different cultures. This is done by making mental health applications more in line with the beliefs and \nvalues of people from different cultures (Anakwenze, 2022; Spanhel et al., 2021). Research suggests that \nculturally adapted interventions demonstrate moderately stronger effectiveness compared to non-adapted \ninterventions, highlighting the significance of cultural tailoring in mental health interventions (Spanhel et al., \n2021). \n \n2.2.1 Ecological Validity Model  (Bernal et al., 1995) \nSeveral studies have highlighted the impact that cultural adaptation can have on evidence-based interventions \nthat we developed in different cultural contexts. Most of these studies use systematic frameworks to guide the \nadaptation. One popular framework is the Ecological Validity Model (EVM).  \nThe Ecological validity model is a framework that was designed to guide the cultural adaptation of \npsychological interventions. Originally designed by Bernal et al. (1995), it serves as a foundational framework \nfor the cultural adaptation of psychological interventions. The EVM emphasizes the importance of considering \ncultural context to ensure that interventions are meaningful and effective for the target population. The model \nfocuses on eight dimensions to enhance the ecological validity, the extent to which the findings can be \ngeneralized to real-world settings of interventions. These dimensions include language, involving the use of \nculturally appropriate expressions; persons, referring to the inclusion of individuals who share ethnic or racial \nsimilarities with the target population; metaphors, which draw on expressions and symbols commonly shared \nwithin a cultural group; and content, which incorporates relevant cultural knowledge. They also encompass \nconcepts, accounting for specific cultural, social, and environmental factors that influence the adaptation and \neffectiveness of an intervention; goals, ensuring alignment between the objectives of the intervention program \nand the expectations of the target population; methods, such as the mode of delivery used to implement the \nintervention; and context, which integrates the broader social and historical background of the population. \n Systematically addressing these dimensions ensures that mental health interventions, including mental health \napplications, (1) are culturally responsive and (2) maintain the effectiveness of the interventions. Below are just \na few examples of studies that performed a cultural adaptation of mental health interventions that lacked cultural \ncontext: \n"}, {"page": 7, "text": "Sit et al. (2020) employed EVM to culturally adapt the step-by-step (SbS) digital mental health intervention for \nyoung Chinese adults. This process included key informant interviews with mental health experts and focus \ngroups with potential beneficiaries, leading to significant modifications in metaphors, narratives, characters, \nillustrations, and the overall context of the program. These adaptations enhanced the program’s cultural \nrelevance, reduced stigma, and improved accessibility, demonstrating the model’s effectiveness in guiding \nsubstantial cultural adaptations. \nShroff et al. (2023) followed the Cultural Adaptation Framework for Scalable Interventions by Heim and Kohrt \nto adapt Project Yes for youths in San Antonio. Initially developed in English, the program was later translated \ninto Spanish post-adaptation, ensuring it met the cultural and linguistic needs of the community. This adaptation \nprocess, which utilized Single-Session Interventions (SSIs), was well-received by participants, who reported \nsignificant improvements in psychosocial outcomes. \nArjadi et al. (2018) adapted an internet-based behavioral activation intervention for depression to fit the \nIndonesian context using the Formative Method for Adapting Psychotherapy (FMAP). This study involved \ncollaboration with stakeholders and the integration of cultural elements into the intervention, highlighting the \npotential of deeper-level cultural integration in existing interventions. \nSit et al. (2020) focused on culturally adapting the Step-by-Step (SbS) digital mental health intervention for \nChinese young adults, employing the Ecological Validity Model (EVM) along with a detailed four-phase \nprocess. This process included conducting key informant interviews with mental health experts and focus group \ndiscussions with potential beneficiaries, ensuring a robust foundation for adaptation. The outcome was a \nsuccessful cultural adaptation of the SbS program, which involved significant modifications to metaphors, \nnarratives, characters, illustrations, concepts, goals, methods, and the context of the program. These adaptations \nmade the program culturally relevant, aligned with local goals, reduced stigma, and increased accessibility(Sit et \nal., 2020). The study underscored the importance of a structured framework and community input in the \nadaptation process, highlighting how these elements are crucial for the successful localization of mental health \ninterventions. \nShroff et al. (2023) conducted a study to evaluate the effectiveness of Project Yes, a program aimed at \nimproving psychosocial outcomes among youths in San Antonio (Shroff et al., 2023). The project adaptation \nfollowed the Cultural Adaptation Framework for Scalable Interventions proposed by Heim and Kohrt, which \nemphasizes integrating cultural concepts of distress and adapting nonspecific intervention factors to enhance \ncultural relevance. This process involved collaboration with local youth stakeholders and healthcare providers. \nInitially developed in English, the interventions were translated into Spanish only after their adaptation to ensure \nthat they met the community’s cultural and linguistic needs. The methodology utilized Single-Session \nInterventions (SSIs), which are brief, self-administered sessions designed to address issues like depression, \nanxiety, and self-esteem, and could be completed in one sitting. Participants provided feedback before and after \nengaging with the SSIs, revealing that Project Yes was well-received and led to significant improvements in \npsychosocial outcomes, such as reduced hopelessness and self-hate and increased perceived agency. The \ncompletion rate for Project Yes was notably higher than previous interventions, confirming its applicability and \nconvenience for both English and Spanish-speaking youths in San Antonio. \nDavidson et al. (2015) developed Rise Above, a web-based depression intervention tailored for Latina/o youth \nfacing high depression rates and low mental health service utilization. The study involved thematic interviews \nwith national mental health experts and focused on adapting evidence-based treatments to the cultural patterns \nof the Latina/o population, successfully improving engagement and access to mental health services (Davidson \net al., 2015). \nThe application of the EVM in the aforementioned studies demonstrates its significant impact on enhancing the \ncultural sensitivity and relevance of mental health interventions. The examples highlight several critical \nfindings.  \nCultural sensitivity and relevance: Each study has shown that considering the cultural contexts and specific \nneeds of the target population leads to interventions that are more than just effective- they are meaningful and \nresonate well with the participants. For instance, the adaptation made in the step-by-step program for Chinese \nyoung adults included significant changes to cultural metaphors and narratives, which made them more relatable \nand acceptable within that cultural framework. \nCommunity Engagement: Successful cultural adaptation often involves the active participation of the \ncommunity. For example, the development of the Project Yes program involved collaboration with local youth \nstakeholders and healthcare providers, which ensured that the intervention was culturally congruent and fostered \na sense of ownership and trust among participants.  \n"}, {"page": 8, "text": "Addressing Stigma and Cultural Considerations: Incorporating cultural elements into the interventions helps \nin addressing the stigma associated with mental health issues within specific cultures. In Davidson et al.'s (2015) \nstudy, the culturally sensitive approach adopted for the Rise Above program helped reduce stigma and improve \ntreatment engagement among Latina/o youth, a group traditionally underserved in mental health. \nThese findings underscore the importance of integrating cultural and social considerations into mental health \ninterventions. By doing so, the ecological validity of the interventions is enhanced, and they also become more \neffective in real-world settings. This approach not only meets the clinical needs of individuals but also addresses \nthe broader cultural and social dynamics that influence mental health outcomes. Moreover, these examples \nillustrate the utility of the EVM in bridging the gap between clinical effectiveness and cultural relevance, \nensuring that mental health interventions are both scientifically sound and culturally appropriate. This synergy is \nessential for the successful implementation of mental health services, particularly in regions with diverse \npopulations like South Africa, where cultural nuances significantly influence health behaviors and perceptions. \n \n2.2.2 Cultural Adaptations from a Developer's Perspective \nSpanhel et al. (2021) proposed a taxonomy of cultural adaptation, categorizing strategies into different levels \nbased on the extent of modification. This taxonomy includes surface-level adaptations, such as changes to \nlanguage and visual elements, aimed at enhancing intervention appropriateness, as well as deeper-level \nadaptations, which involve aligning intervention content, structure, and delivery methods with the cultural \nbeliefs and values of the target population (Spanhel et al., 2021). Moreover, the taxonomy underscores the \nimportance of considering the cultural context, encompassing social determinants of health, historical trauma, \nand systemic barriers, to ensure comprehensive and effective cultural adaptation efforts (Spanhel et al., 2021). \nCultural adaptation in mental health applications entails adding cultural content to ensure it appeals to people \nfrom different cultures. This is done by making mental health applications more aligned with the beliefs and \nvalues of people from different cultures (Anakwenze, 2022; Spanhel et al., 2021). Research suggests that \nculturally adapted interventions demonstrate moderately stronger effectiveness compared to non-adapted \ninterventions, highlighting the significance of cultural tailoring in mental health interventions (Spanhel et al., \n2021). However, a review of cultural interventions in sub-Saharan Africa that used the ecological validity model \n(EVM) revealed that while some interventions reflected cultural sensitivity, few met the cultural compelling \ncriteria (Anakwenze, 2022).  \n \n2.2.3 Synergy between Approaches \nThe interplay between culturally adapted and culturally grounded interventions offers a robust framework for \naddressing the complex cultural needs in mental health care. It is crucial to recognize that cultural adaptation is \nnot a one-size-fits-all approach (Spanhel et al., 2021). Instead, we argue that, in many cases, culturally adapted \ninterventions could benefit more from incorporating elements of cultural groundedness. The Synergy between \nthese approaches is essential for successful implementation. Finding the middle ground between these two \napproaches lies in understanding the nuances between culturally grounded and adapted interventions (Vernon, \n2023).  \n \n2.2.4 Challenges in Cultural Interventions in Africa \nCommunities in Africa historically relied heavily on families and traditional healers to address mental health \nissues. However, colonization and other developments have impeded the capacity of traditional healthcare \nsystems to provide comprehensive healthcare by criminalizing such practices (Anakwenze, 2022). This has led \nto a disconnect between traditional healing practices and modern mental health interventions, hindering access \nto culturally appropriate care for many individuals in the region. \nMoreover, most psychological frameworks used in Africa have historically not been indigenous to the continent. \nAfrican psychologies rely on values, constructs, beliefs, and methodologies native to African cultural groups to \nstudy behavior and mental processes. However, the prevalence of non-indigenous frameworks highlights the \nsignificant gap in culturally relevant mental health interventions (Anakwenze, 2022; Naeem et al., 2019). \nWestern psychology and African psychology differ in their underlying philosophical frameworks, perspectives, \nand approaches to understanding human behavior and mental health. Western psychologies are primarily rooted \nin individualism, which emphasizes the significance of the individual’s thoughts, emotions, and behaviors \ndistinct from their broader social and cultural contexts. This perspective is influenced mainly by Eurocentric \ntheories and frameworks, which shape the understanding of human behavior and mental health through a \n"}, {"page": 9, "text": "culturally specific lens. In practice, Western approaches often rely on standardized assessment tools and \ndiagnostic criteria, which may not fully account for the socio-cultural variables that influence mental health. The \nfocus is generally on individual well-being, with mental health defined by personal fulfillment and \npsychological stability. \nIn contrast, African psychologies are deeply embedded in the principles of communalism and \ninterconnectedness, reflecting a collective approach to understanding human behavior. These psychologies are \ngrounded in African cosmology, philosophy, and cultural practices, which prioritize the collective well-being of \nthe community over the individual. The African perspective views social relationships as central to the concept \nof mental health, advocating for holistic and contextual approaches to diagnosis and treatment. Unlike Western \nmodels, which focus on the individual, African psychologists consider mental health to be intricately linked with \nthe health of the community, emphasizing the need for culturally grounded interventions (Wilson & Williams, \n2013). \nAnakwenze (2022) emphasizes the issue, stating that the quest to develop indigenous psychologies is far from \ncomplete. Much of what has been accomplished to date in terms of psychological frameworks and tailoring \ninterventions has entailed importing from the West. However, there remains a significant lack of psychological \nframework and interventions rooted in African culture, posing a challenge in evaluating whether interventions \nemerging organically from African contexts are more beneficial for Africans. Anakwenze underscores the \nimportance of African psychologists collaborating with local communities to develop culturally informed \ntheories rooted in the realities of Africans.  Such theories may offer better support to communities in Africa \ncompared to Western approaches like cognitive-behavioral therapy, which may not fully resonate with African \ncontexts. Despite this, interventions from Western society continue to be valued and are likely to remain so for \nmental health practitioners. However, because developing African theories and psychologies is out of the scope \nof this research, it is advocated that existing Africa-centric theories and contexts should be integrated to enhance \nthe effectiveness of these interventions, more specifically, mobile health interventions, to pave the way forward. \nAnother significant factor contributing to the mental health treatment gap is the conflation of Westernization \nwith modernization. This conflation is perpetuated by the collaboration between Western agencies and \ninstitutions in Africa, resulting in the import and application of psychological concepts of mental illness. Some \nAfrican psychologists and international partners may view indigenous knowledge as incompatible with \n“progress” rather than recognizing its potential to inform treatment developments alongside knowledge from \nWestern societies (Anakwenze, 2022). This understanding underscores the need to integrate Africa-centric \ntheories into mobile health interventions to pave the way forward. \nFor developing countries like South Africa to reap the benefits of adopting AI, innovation needs to be founded \non the sociocultural factors that impact trust. Lack of trust can negatively impact the adoption of these \ninterventions, potentially undermining the achievement of the anticipated benefits. Cultural context is crucial in \nbuilding trust and acceptance (Vernon, 2023). For example, in some South African cultures, people do not use \ntitles such as ‘Mr.’ or ‘Mrs’, but rather ‘Baba’ or ‘Mma’ to respectfully address elders. Incorporating these \nculturally appropriate titles into the intervention demonstrates respect and recognition of local customs, thereby \nfostering trust. This respect for cultural norms makes the intervention more relatable and trustworthy, enhancing \nits effectiveness and acceptance. \nWhile significant progress has been made in addressing mental health challenges in South Africa, there remains \na need for interventions that are deeply rooted in the cultural context of the population. By integrating Africa-\ncentric theories and concepts into mental health interventions, partially mobile health interventions, we can \nbridge the treatment gap and pave the way for more effective and culturally sensitive approaches to mental \nhealth care. The taxonomy of cultural adaptation provides a systematic framework for guiding adaptation \nefforts, emphasizing the importance of considering the content.  \n \n2.3 Cognitive Behavioral Therapy in the Treatment of Anxiety and Depression \nMost mHealth applications use ecological momentary intervention (EMI) to deliver treatments provided to \npeople in their everyday lives. This approach captures and modifies specific moment-to-moment situations that \nemerge in the real world rather than targeting problematic thoughts, emotions, and behaviors through therapy \nsessions or in the hospital. These interventions are designed to address behaviors, thoughts, or emotions within \nthe context of individuals’ daily lives, allowing for timely and contextually relevant support (Marciniak et al., \n2020). Many EMI approaches employ evidence-based techniques such as cognitive behavioral therapy (CBT). \nCBTs are based on the theory that maladaptive cognitions, such as general beliefs and automatic thoughts about \nthe self and the world, contribute to the maintenance of emotional distress and behavioral problems. These \n"}, {"page": 10, "text": "techniques are considered the “Gold standard” of treatment in many mental health conditions (Marciniak et al.). \nCBTs comprise techniques that address psychological mechanisms that underpin health conditions. \nFour fundamental psychopathology techniques are used in cognitive behavioral therapy (Denecke et al., 2022): \nCognitive restructuring, behavioral activation, problem-solving, and exposure therapy. Cognitive restructuring is \na technique that aims to identify and challenge negative thought patterns (Denecke et al., 2022; Marciniak et \nal.), while behavioral activation encourages individuals to engage in positive activities to counteract depression \nand anxiety (Denecke et al., 2022; Marciniak et al., 2020). Problem-solving techniques help individuals develop \neffective coping strategies for managing stress and resolving interpersonal conflicts, and exposure therapy \ninvolves gradually confronting feared situations to reduce anxiety responses (Denecke et al., 2022). Although \nexposure therapy is mentioned, this paper does not consider it as a mental alleviation technique because, \nalthough it aims to alleviate mental health symptoms, it is more focused on symptom reduction and management \nrather than general mental health alleviation. Various technologies can implement these techniques in the \ncontext of mobile health applications for mental health, enhancing the user experience and encouraging self-\nmanagement. \nMobile health applications adapt and integrate these technologies into digital health formats, offering users \ninteractive tools and resources for self-help and guided therapy. Cognitive restructuring exercises may include \njournaling and challenging exercises, while behavioral activation could involve activity scheduling features with \nsome encouragement or reward mechanisms to promote a particular behavior (Arjadi et al., 2018). Problem-\nsolving modules may offer users step-by-step guidance for addressing specific challenges (Denecke et al., \n2022), \nKeywan et al. (2023) designed DEPRA, a mass-screening conversational AI chatbot, to identify depression early \nand prevent potential crises. They utilized the Hamilton Interview Guideline (HIG), based on the Structured \nInterview Guide for the Hamilton Depression Rating Scale (SIGH-D), to structure the conversation flow, \nensuring standardization and comparability of results. By converting multiple-choice questions into open-ended \nresponses, the chatbot captured genuine feelings and thoughts, while scoring systems facilitated the collection \nand analysis of self-reported depressive symptoms. However, it is important to note that while DEPRA offers a \nconvenient and accessible platform for mental health assessment and support-seeking, it does not directly \ncontribute to the alleviation of depression symptoms or other mental health disorders. Despite these limitations, \nDEPRA demonstrates the potential of AI in bridging the gap between individuals and access to basic mental \nhealth support. \nSimilarly, Ahmadi et al. (2023) conducted a study to design and evaluate a smartphone-based cognitive \nbehavioral therapy (CBT) program aimed at controlling and alleviating symptoms of anxiety and depression. \nUtilizing a 10-session randomized controlled trial, the researchers divided 45 participants into an intervention \ngroup, which received the CBT application, and a control group, which continued with conventional treatments. \nAssessments were conducted using Beck’s Anxiety and Depression Scales, with data analyzed through SPSS \nusing descriptive statistics and statistical tests such as the Shapiro-Wilk test and paired T-test. Results indicated \nsignificant improvements in the intervention group, with notable reductions in both anxiety (P-value = 0.001) \nand depression scores (P-value = 0.002) post-intervention, in contrast to the control group, which showed no \nsignificant changes in their scores (anxiety P=0.140, depression P=0.683). These findings underscore the \neffectiveness of the smartphone-based CBT program in improving mental health outcomes compared to \nconventional treatments. \nExtending the application of technology in mental health, Hanna and Hanna (2021) developed an innovative \nsmartphone application to improve university students’ mental health and overall quality of life. Leveraging AI \nfor sentiment analysis of users’ social interactions and incorporating biofeedback as an evidence-based therapy, \nthe app analyses social interactions across various platforms, facilitates connections with others who share \nsimilar moods, and provides relevant therapy tags. Moreover, the application fosters chat support among users \nwith similar mental sentiments and grants access to carers, community volunteers, and health professionals \nduring periods of significant loneliness or distress. Notably, the inclusion of self-monitoring features empowers \nusers to track daily conditions such as appetite, exercise, sleep, and mood. Hanna and Hanna conducted a pilot \ntest to assess the app’s usability, involving the development of a prototype and gathering feedback through a \nusability questionnaire. Post-release, the performance of the application was evaluated in terms of downloads \nand feedback from the embedded online survey. One notable strength of this application lies in the various \ntheoretical frameworks that fostered its development, demonstrating the ability to combine psychological \ntheories and possibly African psychological theories into applications. \nThe effectiveness of Cognitive Behavioral Therapy (CBT) techniques within Ecological Momentary \nInterventions (EMIs) hinges on carefully considering the specific mental health conditions addressed and the \ncontextual factors surrounding each intervention. For instance, the implementation of CBT techniques should \n"}, {"page": 11, "text": "account for cultural context. For example, behavioral activation may manifest differently in Western, \nindividualistic cultures compared to African communal contexts. In an African context, behavioral activation \nmight involve actions such as ‘spending time with elders to listen to their ancient wisdom ‘, reflecting the \ncultural emphasis on respect for elders and traditional knowledge. In contrast, in a Western cultural context, \nbehavioral activation might entail activities like ‘scheduling a leisure activity or exercise sessions aligning with \nthe individualistic focus on personal fulfillment and self-care. Therefore, selecting and adapting CBT techniques \nand tailoring them to match the target population’s context and symptom severity is crucial for enhancing \nengagement and achieving therapeutic outcomes. Furthermore, the adaptation of these techniques should be \nguided by evidence-based practices and seamlessly integrated into users’ daily lives, considering factors such as \ntechnological platforms and timing of intervention delivery. The studies by Ahmadi et al. (2023), Hanna and \nHanna (2021),  and  Keywan et al. (2023) illustrate this well. They demonstrate significant improvements in \nmental health outcomes through tailored digital interventions, confirming the capacity of AI and smartphone \napplications to bridge the gap between clinical needs and technological solutions effectively. These studies \nunderscore the transformative potential of digital technologies and AI in enhancing mental health interventions, \nshowcasing innovative approaches to treatment accessibility and effectiveness across different settings and \npopulations. \n \n2.4. Techniques for Incorporating Emotional Intelligence in LLM   \nEmotional intelligence denotes the capacity to adeptly interpret and manage emotion-infused information, \nsubsequently harnessing it to steer cognitive tasks, ranging from problem-solving to behavior regulation \n(Salovey et al., 2009). In the context of LLMs, this study defines emotional intelligence as the capacity of an \nLLM to accurately understand and respond to emotions expressed in text data, enabling better problem-solving \nand behavior regulation (such as response generation), taking into account the context of the user.  \n \n2.4.1 Prompt engineering  \nPrompt engineering refers to the design of instructions (prompts) aimed at enhancing the performance of \nexisting language models (Reynolds & McDonell, 2021). Unlike traditional paradigms that necessitate model \nretraining or extensive fine-tuning for task-specific performance, prompt engineering offers adaptability by \nsteering model responses (Sahoo et al., 2024). Techniques encompass a spectrum from foundational methods \nlike zero-shot and few-shot prompting to more intricate approaches such as “chain of code” prompting. Zero-\nshot prompting eliminates the need for extensive training data, relying instead on meticulously crafted prompts \nto guide models toward novel tasks, leveraging pre-existing knowledge for predictions based on specific input-\noutput mappings. In contrast, chain-of-code prompting prompts models to generate sequences of code based on \ngiven prompts. While a comprehensive discussion of these techniques exceeds the scope of this review, \ninterested readers can explore detailed explanations in articles such as “A Systematic Survey of Prompt \nEngineering in Large Language Models: Techniques and Applications” (Sahoo et al., 2024). Prompt \nengineering emerges as a promising technique to enhance LLMs’ performance on downstream tasks. \n \n2.4.2 Emotionally Intelligent Prompting \nBuilding on the foundation of prompt engineering, Li et al. (2024) introduced the Emotional Chain of Thought \n(ECoT), a novel prompting method that integrates emotional intelligence principles into LLMs. Inspired by \nGoleman’s theory, EcoT aims to activate the emotional intelligence of LLMs by providing quality step-by-step \nprompts based on a theoretical framework. This method demonstrates the potential for LLMs to understand and \ngenerate responses based on emotional data and engage in more human-like interactions. Complementing this, \nLi et al. (2023) explored enhancing LLMs by integrating emotional stimuli into prompts, conducting 45 \nexperiments across 35 tasks with models such as Flan-T5-Large, Llama 2, Vicuna, BLOOM, and ChatGPT. \nTheir introduction of ‘EmotionPrompt,’ a technique that blends original prompts with emotional stimuli, led to \nsignificant performance improvements, including an 8% increase in Instruction Induction and a 115% \nimprovement in BIG-Bench tasks, notably enhancing the models’ creative output and demonstrating profound \nimplications for integrating psychological insights into AI development for deeper and more meaningful human-\nlike interactions. \nSimilarly, Wei et al. (2022) investigated how large language models’ reasoning abilities could be enhanced \nthrough chain-of-thought (CoT) prompting. By providing models with intermediate reasoning steps leading to a \nfinal answer, they demonstrated significant improvements in tasks such as arithmetic, symbolic reasoning, \ncommonsense reasoning, and mapping natural language instructions to robot actions. The authors manually \n"}, {"page": 12, "text": "composed CoT exemplars to guide the models’ reasoning, revealing that explicit reasoning chains substantially \nenhanced performance across diverse tasks. These findings complement Li et al.’s exploration of emotional \nintelligence integration in LLMs. \n \n2.4.3 Integration of Emotional Dimensions in Chatbots \nInnovative approaches to integrating emotional dimensions in LLMs have shown significant promise in \nenhancing the machines’ ability to generate nuanced and culturally aware emotional responses. The Six-\nDimensional Emotion (6DE) model proposed by Ratican & Hutson (2023) is one such framework that includes \ndimensions such as arousal, valence, dominance, agency, fidelity, and novelty, enhancing AI’s ability to \nunderstand and react in emotionally complex situations. \nConsistent with the aforementioned approach of enhancing AI’s emotional intelligence through emotional \ndimensionality (Wortman & Wang, 2023), a study was conducted to develop the High-Coverage Emotion \nModel (HICEM). This model aims to create a comprehensive human emotion model that significantly advances \nthe training of social robots and other intelligent machines, enabling them to engage in deeper and more \nmeaningful human-machine interactions. The methodology involved generating a list of emotion concepts, \nemploying UMAP (Uniform Manifold Approximation and Projection) for dimensionality reduction, and \napplying hierarchical clustering to categorize these emotions systematically. The effectiveness of the HICEM \nmodel was assessed using custom evaluation metrics and a comprehensive user study, which highlighted its \nsuperior coverage of emotional states with fewer components than existing emotion models. The model \ndemonstrated robust performance across multiple languages, achieving average coverage scores of 0.458 in \nEnglish, 0.349 in Arabic, 0.315 in Mandarin, 0.455 in French, 0.458 in Spanish, and 0.501 in Russian. These \nresults underscore the model’s capability to capture and categorize emotions across diverse cultural contexts \naccurately.  \nThe studies suggest that the essence of incorporating emotional intelligence into chatbots and Large Language \nModels lies fundamentally in accurately identifying key emotions and strategically using these insights to \ninform response generation. While embedding sophisticated emotional frameworks within these systems allows \nAI to recognize and utilize a spectrum of human emotions, this approach has its faults. One significant challenge \nis selecting which emotions to prioritize, as the spectrum of human emotions is inherently complex. Deciding \nwhich emotions are important often leads to oversimplifications (Wortman & Wang, 2023), and capturing the \nfull breadth of emotional experiences in a framework can be unfeasible. Moreover, different cultural contexts \nmay interpret or value emotional expressions differently, adding another layer of complexity to the task.  \nWhile prompt engineering is a relatively recent innovation, it has showcased remarkable efficacy in tailoring \nLLMs for specific tasks, particularly in scenarios where extensive datasets are lacking. The studies discussed \nabove illuminate various avenues for enhancing LLM performance: (1) by framing LLM responses to better \nalign with contextual nuances, (2) by leveraging established theories to guide model behavior appropriately, and \n(3) by exploring diverse perspectives on emotional intelligence integration. These approaches collectively \nunderscore the dynamic nature of adapting LLMs, offering promising pathways for further advancements at the \nintersection of AI and psychology. \n \n2.5 Fine Tuning  \nFine-tuning is the process in machine learning where a pre-trained model is further trained on a specific, often \nsmaller, dataset to adapt it to a particular task or domain (Lu et al., 2024). This technique leverages the model’s \nexisting knowledge to better achieve performance on specialized applications without training a new model \nfrom scratch.  \nThe key difference between fine-tuning and prompt engineering (discussed earlier) is that fine-tuning modifies \nthe model’s internal weights, effectively adapting the foundational model to better align with the target dataset. \nIn contrast, prompt engineering does not alter the model itself but instead optimizes the way inputs (or prompts) \nare crafted to elicit desired responses. While prompt engineering influences the model’s outputs through \ncarefully designed instructions, fine-tuning permanently refines the model’s behavior based on task-specific \ndata.  \nResearch highlights several benefits of fine-tuning. One major benefit is improved accuracy and efficiency. \nFine-tuning allows models to learn domain-specific patterns, enhancing their precision in applications. By \nfocusing on relevant data, fine-tuning models provide more reliable outputs and improve decision-making. Fine-\ntuning also reduces computational costs. Training large language models from scratch demands significant time \n"}, {"page": 13, "text": "and resources, whereas fine-tuning builds on existing models with minimal additional data and computation. \nThis makes AI more accessible and cost-effective for specialized use cases. In this section of the literature \nreview, we give an overview of popular fine-tuning techniques and then discuss how fine-tuning has been \napplied to applications in the mental health space. \n \n2.5.1 Overview of fine-tuning techniques  \nFine-tuning techniques vary depending on computation constraints, data availability, and the level of adaptation \nrequired for specific tasks. Below are some of the most commonly used fine-tuning approaches. \nOne common approach is full-tuning, in which all pre-trained model parameters are updated based on the task-\nspecific dataset. This method offers the highest degree of specialization but requires significant computational \nresources and a large dataset to prevent overfitting. Another technique is parameter-efficient fine-tuning (PEFT), \nwhich aims to fine-tune models with fewer parameters to optimize computation efficiency (Cui et al., 2022). \nTechniques such as Low-Rank Adaptation (LoRA) and adapters selectively update only specific layers or a \nsubset of parameters while keeping the rest of the model frozen, reducing memory usage and speeding up \ntraining (Hayou et al., 2024). \nA more advanced approach is reinforcement learning from human feedback (RLHL) (Abubakar et al., 2024), in \nwhich a model is fine-tuned based on human-generated feedback. These optimizations align the model with \nhuman values, ethical considerations, and stylistic preferences. RLHF has been widely applied in conversation \nAI and content moderation systems where user alignment and fairness are crucial factors. \nThese fine-tuning techniques have advantages and trade-offs depending on the computational budget, training \ndata availability, and desired model adaptability. Understanding these methods is critical to selecting the most \neffective approach for a given application. The next section explores how fine-tuning has been applied in \nhealthcare, particularly in mental health applications. \n \n2.5.2 Fine-tuning in mental health applications  \nFine-tuning LLMs has emerged as a pivotal approach in developing mental health applications, enabling models \nto perform specialized tasks with greater accuracy and relevance. Several studies have explored the application \nof fine-tuning techniques to tailor LLMs for mental health support, assessment, and intervention (Lawrence et \nal., 2024). \nOne notable study introduced MentalQLM (Shi et al., 2024), a light language model specifically designed for \nmental healthcare applications. The development process involved two key stages. This approach aimed to \ncreate a model capable of understanding and generating responses pertinent to mental health contexts, thus \nenhancing the quality of AI-driven mental health support. \nThe Mental-LLM study evaluated multiple LLMs on various mental health prediction tasks using online text \ndata. The researchers concluded that the experiments covered zero-shot prompting, few-shot prompting, and \ninstruction fine-tuning. The findings indicated that instruction fine-tuning, few-shot prompting, and instruction \nfine-tuning. The findings indicated that instruction fine-tuning significantly boosted the performance of LLMs \nacross all tasks, highlighting the effectiveness of fine-tuning in adapting LLMs for mental health applications \n(Xu et al., 2024). \nIn a pilot study, researchers explored aligning LLMs to enhance psychiatric interviews through symptom \ndelineation and summarization. The study investigated whether LLMs could identify parts of a conversation \nsuggesting psychiatric symptoms and summarize stressors and symptoms based on interview transcripts. The \nresults demonstrated that fine-tuned LLMs, or those with appropriate prompting, achieved high accuracy in \nsymptom delineation and summarisation coherence, indicating their potential to assist mental health \npractitioners in analyzing psychiatric interviews (So et al., 2024). \nCollectively, these studies underscore the potential of fine-tuning techniques in enhancing the capabilities of \nLLMs for mental health applications, paving the way for more effective, accessible, and secure AI-driven \nmental health support systems. \n \n \n \n"}, {"page": 14, "text": "2.6 Research Gaps \nDespite significant advancements in mental health applications aimed at bridging accessibility gaps, several \ncritical research gaps remain that limit the efficacy and reach of these interventions, particularly in culturally \ndiverse settings like South Africa. \nMost existing mental health applications are grounded in Western psychological theories and practices, which \nmay not be entirely applicable or acceptable across different cultural contexts. This reliance on Western-centric \napproaches has limited the development of interventions that are culturally congruent with the needs and values \nof non-Western populations. Studies such as those by Davidson et al. (2015) emphasize the importance of \nintegrating a patient’s cultural contexts and values into evidence-based treatments (EBTs), suggesting a \nsignificant gap in the cultural tailoring of mental health solutions. \nTo our knowledge, no substantial study has been conducted focused on the cultural adaptation of mental health \napplications, specifically in South Africa. This oversight is significant because cultural adaptation has been \nshown to increase the acceptability and effectiveness of interventions in marginalized populations by \nincorporating relevant cultural stories and perspectives (Shroff et al., 2023)  \nWhile chatbots have demonstrated remarkable potential in mental health settings, such as early detection of \ndepression and alleviation of anxiety, they often do not consider cultural perspectives in their emotional \nintelligence algorithms (Ahmadi et al., 2023; Kaywan et al., 2023). Given the nuanced nature of emotional \nexpression across different cultures, this limitation is a significant oversight. Culturally adapted digital tools, \nwhich take into account the specific cultural and spiritual dimensions of their users, could offer enhanced \nsupport, especially in low-resourced or minoritized communities that frequently rely on digital resources for \nhealth information (Shroff et al., 2023). Moreover, incorporating spirituality, a vital element of African \npsychology, has significantly improved mental health outcomes, as evidenced by research conducted within \nIndonesian Muslim communities (Hamka et al., 2022). This finding underscores the potential benefits of \nintegrating spiritual and cultural elements into mental health interventions for similar improvements in contexts \nlike South Africa. \nIn low-and middle-income countries, managing mental health problems remains a formidable challenge due to \nthe limited availability of treatment. The need for culturally sensitive interventions is particularly acute in these \nsettings, where traditional and cultural beliefs often play a significant role in the perception and management of \nmental health. \nThe highlighted gaps indicate a pressing need for more inclusive research that considers the cultural, spiritual, \nand contextual nuances of diverse populations, particularly in regions like South Africa. Addressing these gaps \ncould lead to more effective, culturally appropriate mental health interventions that are better suited to the \npopulations they aim to serve. \n \n3. Research Methodology \nThis section presents the methodology adopted in this study, detailing both the theoretical foundations and \npractical implementation of a culturally adapted, AI-driven mental health support framework informed by the \nUbuntu philosophy. It begins by introducing the deep-structure cultural adaptations rooted in Ubuntu, \nemphasizing communal values, spiritual grounding, and interdependence. This is followed by a discussion of \nsurface-level adaptations, which address communication style and interaction design to ensure cultural \nresonance in user engagement. The adaptation of Cognitive Behavioural Therapy (CBT) techniques—\nspecifically Behavioural Activation and Cognitive Restructuring—is then explored, highlighting how these were \nreinterpreted through an Ubuntu-informed lens to align therapeutic goals with African cultural values. \nThe methodology further outlines the research design, including the overarching methodological paradigm, \nsystem architecture, and the process for culturally adapting the CACTUS dataset through a five-step \ntransformation pipeline. The development of expert-informed case studies is also described, designed in \ncollaboration with a clinical practitioner to authentically simulate how individuals in African contexts might \nexpress symptoms of depression and anxiety. The section concludes with a description of the experimental \nsetup, detailing the model fine-tuning process, evaluation metrics, and the use of both automated (e.g., UniEval) \nand manual assessment methods. Collectively, these components establish the methodological foundation of the \nstudy, demonstrating how theoretical principles, system design, culturally adapted data, and evaluation \nstrategies converge to develop an emotionally intelligent and culturally responsive AI-based mental health \nsupport system. \n \n"}, {"page": 15, "text": "3.1 Deep-level structure changes  \n3.1.1 Theoretical framework: Ubuntu \nUbuntu is a philosophical concept rooted in Southern African traditions that articulates the essence of being \nhuman (Obasa, 2024). It emphasizes interconnectedness, interdependence, and communal responsibility, core \nprinciples that stand in contrast to the individualistic orientation of many Western psychological models. In \nUbuntu, a person’s identity is not defined in isolation but concerning others: “I am because we are”. This \ncollective consciousness forms the foundation for an African-centred model of mental health and well-being \n(Wilson & Williams, 2013). \nOne of the most compelling aspects of Ubuntu is its explicit inclusion of dimensions often overlooked by \nWestern psychologies, particularly spirituality and connection with divinity. While many Western frameworks \nprioritize intrapersonal cognition and behavior (Anakwenze, 2022), Ubuntu recognizes that well-being is deeply \ntied to spiritual, communal, and ancestral dimensions of life. Importantly, the reference to ancestry in Ubuntu \ndoes not imply ancestral worship as a religious practice but rather speaks to a deep reverence for one’s origins, \nroots, and cultural lineage. This sense of rootedness offers grounding, identity, and a sense of purpose, \nespecially in contexts where healing is linked to reconnecting with one’s heritage. \nUbuntu also addresses Africa-specific expressions of distress and resilience, which are often absent from \nconventional psychological paradigms. For instance, self-worth in many African communities is closely tied to \none’s contribution to the collective, specifically to the family, the community, and society. This cultural \nemphasis is reflected in Ubuntu’s construct of competency, which moves beyond personal success to include \nresponsibility, good behavior, and communal value. Ubuntu thus offers a culturally aligned model of well-being \nand a lens through which to understand behaviors and motivations that might otherwise be misinterpreted or \npathologized by Western standards. \nWilson and Williams (2013) offer a structured framework for Ubuntu that revolves around three central \nconstructs: Connectedness, Competency, and Consciousness. These constructs provide a conceptual foundation \nfor adapting psychological interventions, such as CBT, to resonate with African cultural contexts. The following \nsubheadings further explain in detail the three aforementioned central constructs.  \nConnectedness \nThis construct emphasizes the interdependence and social bonds that link individuals within a community. \nConnectedness is more than social interaction. It is spiritual, emotional, and deeply relational. It reflects a \ncommitment to empathy, compassion, and mutual care. Ubuntu sees well-being as emerging from a sense of \nbelonging, emotional closeness, and recognition of others as part of oneself. This includes people in one’s \nimmediate environment and broader spiritual ties, including connection with divinity (Wilson & Williams, \n2013).  \nCompetency \nCompetency refers to the skills, behaviors, and personal development necessary for individuals to function \nmeaningfully in society. This includes making responsible choices, demonstrating good behavior, aspiring \ntoward future goals, and recognizing one’s unique contributions. Within Ubuntu, competency is not solely \nindividualistic; it is measured by how effectively one contributes to the collective well-being. This perspective \nreinforces a culturally grounded sense of self-worth, where personal identity is enriched through communal \nimpact and relational integrity (Wilson & Williams, 2013). \nConsciousness \nConsciousness in Ubuntu encompasses self-awareness, reflection, and understanding one’s role within a broader \nsociocultural and historical context. From an African-centered viewpoint, it also integrates spiritual awareness \nand the alignment of purpose in life. Consciousness is personal and collective: it is the awareness of who one is, \nwhere one comes from, and how one’s actions affect the community. This construct acknowledges that \nemotional and psychological health cannot be fully understood without recognizing cultural identity, history, \nand communal responsibilities (Wilson & Williams, 2013). These constructs and their underlying tenets are \nsummarized in Table 1. \nTable 1: Tenets of Ubuntu \nConstruct \nCore Tenets \nConnectedness  \n• \nSocial Bonds  \n• \nRelationships  \n"}, {"page": 16, "text": "• \nSense of Belonging \n• \nConnection with Divinity  \nCompetency \n• \nPersonal Development  \n• \nResponsible choices  \n• \nGood Behavior  \n• \nPersonal Responsibility  \n• \nFuture Aspirations  \n• \nRecognition of Individual Uniqueness  \nConsciousness  \n• \nSelf-Awareness \n• \nMindfulness \n• \nUnderstanding One’s Place in a Broader Social and Cultural Context  \n \n \n3.2 Surface-level structure changes \nTable 2 details the specific modifications implemented to enhance the quality and cultural appropriateness of \ninteractions between the LLM and the user. These adaptations draw their inspiration from the Ecological \nValidity Model (EVM) (discussed in Section 2), Spanhel’s (2021) taxonomy for culturally adapting digital \nmental health interventions, as well as key linguistic and contextual considerations. For instance, research \nindicates that most South Africans do not speak English as a first language (Mncwango & Makhathini, 2021). \nAs a result, the use of overly complex or “fancy” English may inadvertently reduce user engagement and \nundermine the effectiveness of the intervention. \nTable 2: Adaptation of communication \nComponent  \nDescription \nPurpose  \nUse of a Familiar \nName  \nAssign a name that is familiar and positively \nregarded within South African communities. \nIncreases trust, familiarity, and user \ncomfort. \nUse of Metaphors  \nIncorporate culturally resonant metaphors to \nexplain complex ideas \nEnhances \nunderstanding \nand \nemotional engagement. \nUse of Appropriate \nTitles  \nEmploy respectful titles as per user preference \nand cultural norms.  \nDemonstrates respect and adherence \nto local social hierarchies. \nIntegration \nof \nSpiritual elements   \nEmbed relevant spiritual or religious references \naligned with users’ beliefs.  \nPromotes comfort and resonance \nwith users’ faith and worldview. \nUse \nof \nSimple \nLanguage  \nEmploy \nclear, \nstraightforward \nlanguage; \noptionally support local language translations. \nEnsures accessibility for users with \nvarying English proficiency. \nUse \nof \nSomatic \nDescriptions  \nReplace clinical terms (e.g., “depressed”, \n“anxiety”) with everyday physical/emotional \nexpressions (e.g., “tired”, discouraged”). \nReduces \nstigma \nand \nincreases \nrelatability \nthrough \nculturally \nfamiliar terminology. \nGoal-Oriented \nCommunication \nEnsure each interaction with the LLMs actively \ncontributes to symptom alleviation. \nAligns digital interactions with the \ntherapeutic goal of reducing anxiety \nand depression symptoms. \n \nThese surface-level adaptations to communication serve a critical function beyond linguistic familiarity; they are \ndesigned to enhance user receptiveness, build trust, and ensure cultural adherence to the interaction between the \nuser and the LLM. By integrating culturally meaningful language metaphors and cultural norms, these \nadaptations help users feel recognized and respected within their sociocultural context. This sense of cultural \nalignment significantly increases user comfort and engagement, making individuals more likely to interact \nopenly, interpret the guidance meaningfully, and maintain continued use of the support tool. In essence, cultural \nfamiliarity becomes a foundation for psychological safety, which is a prerequisite for effective mental health \nsupport. \n \n3.3. Adapting CBT to Align with Ubuntu \nThis study aims to synergize CBT with the Ubuntu framework previously outlined through deep and surface-\nlevel structure changes. Rather than applying CBT in its standard Western form, this section demonstrates how \ntwo core techniques, behavioral activation and cognitive restructuring, can be meaningfully aligned with \nUbuntu’s principles of community, spirituality, and shared humanity. \n"}, {"page": 17, "text": "While CBT encompasses a variety of evidence-based strategies, the focus here is on behavioral activation and \ncognitive restructuring due to their cultural compatibility and relevance in communal societies. \n \n3.3.1 Rationale for Technique Selection \nResearch in cross-cultural psychology suggests that the effectiveness of therapeutic techniques varies across \ncultural contexts, depending on how societies are organized along the spectrum of individualism and \ncollectivism. Western cultures, where CBT was initially developed, are largely individualistic, the East is more \ncollective, and Africans are more communal, prioritizing interdependence, family roles, spiritual meaning, and \nsocial responsibility (Anakwenze, 2022; Naeem et al., 2019). \nWithin communal societies, individuals are often more responsive to therapeutic approaches reflecting relational \nand value-driven life dimensions. Research indicates that behavioral activation and problem-solving-based \ntechniques (which significantly overlap with cognitive restructuring) are especially effective in these settings \n(Anakwenze, 2022; Naeem et al., 2019). These strategies can be adapted to emphasize culturally meaningful \nactivities and communal modes of thought, enhancing both relevance and engagement. Therefore, this study \nfocuses on two techniques because of their therapeutic utility and because they offer the clearest pathways for \ncultural synergy between CBT and Ubuntu. \n \n3.3.2 Behavioral Activation through Ubuntu \nTraditional CBT uses behavioral activation to encourage individuals to re-engage with activities that foster \nenjoyment or a sense of accomplishment, such as exercise, journaling, or hobbies. These activities, however, \ntend to reflect individualistic values centered around personal pleasure or self-care. However, through the lens \nof Ubuntu, behavioral activation (BA) includes activities such as social participation, prayer, and culturally \nmeaningful practices aimed at promoting restoration and well-being.  \n \n3.3.3 Cognitive Restructuring  \nCognitive restructuring is typically used in CBT to identify and challenge distorted or unhelpful thoughts \nthrough logical analysis and introspective questioning. While effective, this approach often emphasizes self-\nreferenced cognition, which may not fully resonate in communal cultures where social and spiritual \ninterrelations shape thought patterns. \nWhen viewed through the perspective of Ubuntu, cognitive restructuring transforms from a self-centered \nexercise into a relational, value-oriented process. The questions used to challenge negative thoughts are adapted \nto incorporate communal perspectives, ancestral wisdom, and social implications. \nFor example, traditional CBT may ask: What is the evidence for this thought, and how else might this situation \nbe viewed? In Ubuntu-informed cognitive restructuring, these questions are reframed to consider relational and \ncommunal perspectives, such as how one’s family might view the situation and how one’s thoughts or actions \nmay affect those around them. This approach helps individuals reframe their thinking through communal \nidentity, shared wisdom, and interpersonal accountability. Rather than seeking only internal coherence, users are \nguided to consider the relational ripple effects of their thoughts and behaviors, consistent with Ubuntu’s \nemphasis on shared humanity and ethical responsibility. \n \n3.4 Research Design \nThis section presents the research design adopted in this study, detailing the overall structure, process, and \nmethodological choices made in developing and evaluating the proposed framework. The section begins by \noutlining the research paradigm and methodology, grounding the study in an interpretivist viewpoint and a \nDesign Science Research (DSR) approach focused on artifact creation. It then introduces the system \narchitecture, providing a technical overview of the frontend and backend components and how they interact with \na fine-tuned language model. Following this, the dataset creation and adaptation process is described, beginning \nwith preprocessing the CACTUS dataset and leading to a five-step cultural adaptation pipeline. The adapted \ndataset is then evaluated for clinical appropriateness through an expert’s review. Finally, the section concludes \nwith the development of case studies used to simulate user interactions and assess the system’s responsiveness \nto Africa-centric expressions of emotional distress. Together, these elements form a cohesive research design to \noperationalize a culturally sensitive AI mental health support system inspired by Ubuntu and CBT. \n"}, {"page": 18, "text": " \n3.5. Research Paradigm and Methodology \nThis study adopts an interpretivist paradigm, recognizing the subjective nature of human experiences and the \nconstruction of these experiences through the meanings individuals assign within different contexts \n(Alharahsheh & Pius, 2020).  Although the evaluation of most criteria is quantifiable, the assignment of the \nrespective scores within the framework remains subjective and may vary from person to person. \nThis study employs a Design Science Research (DSR) methodology, which involves developing innovative IT \nartifacts to solve real-world problems (Weber, 2010). The DSR aims to create effective solutions through \ninnovation and draws from existing knowledge to address complex issues (Peffers et al., 2007). In this context, \nthe artifacts are designed to address mental health challenges by incorporating Ubuntu philosophy and CBT \nprinciples, interacting with the cultural and psychological elements of the problem context (Wieringa, 2014). \n \n3.5.1 System Architecture \nFigure 1 illustrates the flow of the system. The architecture comprises a frontend built with Angular and a \nbackend powered by Python Flask, integrated with a fine-tuned LLM. The user engages with the system via a \nchat-based interface on the Angular front end. When a message is sent, it is transmitted to the Flask backend via \na RESTful API call. The backend processes the request by preprocessing the input and constructing the API call \nrequired to interact with the LLM. This construction includes setting key model parameters such as the \nsystem_prompt, top_p, frequency_penalty, and max_tokens. The system prompt plays a critical role in guiding \nthe model’s response. It is used for persona priming, establishing the context of the conversation, and outlining \nthe steps or therapeutic logic the model should follow in addressing the user’s input. Thus ensuring that the \nLLM responds in a manner that is not only technically coherent but also culturally grounded and therapeutically \naligned. \n \nFigure 1: System Architecture \n \n3.5.2 Frontend Design  \nFigures 2, 3, and 4 below are visual illustrations of how the frontend design looks. When the application loads, \nthe user is greeted with a welcome message. This greeting can be customized based on the user's language \npreference, which is selectable from the dropdown menu located in the top right corner. For example, if the user \n"}, {"page": 19, "text": "selects Setswana, the greeting changes to “Dumela, kenna Karabo”, which translates to “Hi, I’m Karabo.” (See \nFigure 3 for illustration.) This functionality is not AI-powered; the greetings are pulled from a predefined static \nlist within the application. The design of the frontend aims to be both familiar and user-friendly, inspired by \nplatforms like WhatsApp to ensure ease of use and relatability. \n \nFigure 2: Frontend Landing Page \n \nFigure 3: Frontend with language preference set to Setswana \n"}, {"page": 20, "text": " \nFigure 4: Sample User Interface of the Chat Conversation \n3.5.3 Dataset Creation \nDataset Description \nThe original dataset used is the Cactus dataset from an article titled ‘CACTUS: Towards Psychological \nCounselling Conversations using Cognitive Behavioral Theory’ (Lee et al., 2024). It is a synthetic large-scale \ndataset designed to simulate realistic multi-turn psychological counseling conversations based on CBT. The \ndataset consists of approximately 31,000 records, with each row representing a full therapy session. Each \nsession includes seven key attributes, as presented in Table 3 below. \nTable 3: Cactus dataset attributes \nAttribute  \nDescription \nAttitude \nDescribes how the client behaves during the session \nThought \nThe client’s main negative belief or worry at the start of the session \nDialogue \nThe full conversation between the counselor and the client \nCbt_technique \nThe method the counselor uses to help the client \nPatterns \nThe negative thinking the client is showing \nIntake_form \nA summary of the client’s background and why they’re seeking help \nCbt_plan \nA step-by-step plan that the counselor makes before the session \n \nDataset Adaptation Process \nThe adaptation of the CACTUS dataset served two primary goals: \n1. To address the lack of CBT datasets rooted in Africa-centric realities, a culturally reflective \nintermediary dataset is created. \n2. To tailor the dataset to align with the proposed framework for culturally sensitive AI, incorporating \nboth deep-structure and surface-level cultural adaptations. \nThe adaptation process was divided into two main phases: preprocessing and cultural adaptation, as illustrated in \nFigure 5 below. \n"}, {"page": 21, "text": " \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nFigure 5: Adaptation of Dataset \n \nPreprocessing Phase \nAs detailed in earlier sections, the original dataset was filtered using the cbt_technique attribute to retain only \nentries aligned with BA (such as Behavioural Experiment, Activity Scheduling, and Systematic Exposure) and \nCognitive Restructuring (CR) (including Reality Testing, Reframing, and Positive Reframing), the two CBT \nstrategies central to this study. The filtered data was then segmented into single-turn dialogue instances between \nthe client and counselor, resulting in a final dataset of 5,711 cases balanced across BA and CR categories. \nCultural Adaptation  \nUsing the pre-processed data described above. We opted to use GPT-3-turbo to adapt the dataset. The rationale \nbehind using it is that LLMs have been shown to understand the context and follow instructions (Bommasani et \nal., 2021). This also helped us automate the adaptation process with minimal human intervention. The \n"}, {"page": 22, "text": "adaptation process is 5-fold, namely, Ubuntu injection, Language simplification, Removal of clinical terms, \nFaith-based integration, and Proverb integration. Subsequently, we provide a brief explanation of each of the \nadaptation processes below. \ni. \nUbuntu injection \nThis step aims to integrate Ubuntu into the dataset per the 3Cs (Wilson & Williams, 2013), which was \nintroduced into the counselor’s responses. The 3Cs in mental health (especially in therapy and resilience \nmodels) denote Control (focus on what you can control), Commitment (stay committed to meaningful goals and \nrelationships), and Challenge (view stress or change as a challenge rather than a threat), respectively. \nTo achieve this, we provided the model with a prompt that describe the concept of Ubuntu and also presented a \ndialogue instance between the client and counselor. The model was tasked with adapting the counselor’s \nresponses to align with Ubuntu. Importantly, only the counselor’s responses were modified, as our primary \ninterest was in aligning the counselor’s responses. The client's responses were left unchanged. This step \nproduced the first iteration of the adapted dataset with Ubuntu-infused responses. \nii. \n Language Simplification \nThis step aimed to simplify the language used by the counselor to ensure it was transparent and inclusive. The \nrationale was based on an article indicating that many South Africans do not speak English as their first \nlanguage (Mncwango & Makhathini, 2021). Using overly complex or “fancy” English could undermine the \ncounselor’s communication ability. As a result, counselor responses were rewritten to be more straightforward \nto understand. \niii. \nRemoval of Clinical Terms \nIn this step, clinical labels such as “depression” and “anxiety” were replaced with somatic descriptions that \nfocus on the physical manifestations or experiences related to these conditions. The goal was to lessen the \nstigma attached to clinical terminology, making the counseling conversations more approachable and less \nintimidating. Research has shown that stigma is a key factor discouraging Africans from seeking help, making \nthis modification a crucial step toward reducing disparities in mental health service utilization. \niv. \nFaith-Based Integration \nSouth Africa’s most recent census revealed that most of the population identifies as Christian (Africa, 2022). \nBased on this, it is safe to assume that the client is probably Christian; therefore, we incorporated faith-based \nsupport into the dataset to align with users’ likely beliefs. \nThis step had two components: \n• The LLM reviewed each dialogue instance and determined whether adding scripture-based comfort \nwould enhance the counselor’s response (response: yes or no). \n• If scripture was deemed helpful, the model integrated relevant verses into the counselor’s reply. \nA probability threshold mechanism inspired by the Monte Carlo simulation was introduced to prevent excessive \nmodifications. For each instance where scripture integration was considered appropriate: \nA random number between 0 and 1 was generated. \n● \nIf the number fell within the threshold (set at 0.7), the change was made. Otherwise, the dialogue was \nleft unchanged. \n● \nThe script was monitored for the first 30 minutes to ensure that a ‘good’ number of dialogue instances \nwere being modified. Adjustments to the probability threshold were made if necessary. \nv. \nProverb integration. \nThe final step introduced African proverbs into the dataset to counteract the Western bias of most LLM training \ndata and ensure cultural relevance. We curated a list of 100 African proverbs for this purpose. \nThe process worked similarly to the faith-based integration step: \n• The LLM evaluated whether a dialogue instance would benefit from a proverb. \n• A random number between 1 and 100 was generated to select a proverb if the answer was yes. \nTo ensure suitability, the model was asked, “Is this proverb suitable for this context?” \n"}, {"page": 23, "text": "• If the answer was no, another proverb was selected (up to 3 retries). \n• If no suitable proverb was found after three attempts, the instance was left unchanged to save API \ncosts. \nA probability threshold was applied to further control the number of modifications, set at 0.8. Like in the \nprevious step, this threshold was monitored to ensure balanced integration without overloading the dataset with \nproverbs. \nThe cultural adaptation process outlined above was informed by insights gained through multiple iterations of \nimplementing the framework proposed in 3.1 to 3.3. During these early experiments, it became apparent that \nmost large language models lacked sufficient cultural sensitivity when responding to Africa-centric expressions \nof emotional distress. This critical finding led to the formal articulation of the Ubuntu-based framework. It was \nfirst presented in the publication entitled “Evaluating the Cultural Sensitivity of Large Language Models in \nMental Health Support: A Framework Inspired by Ubuntu Values,” by Forane, Ezugwu, & Igwe (2024a). \nA subsequent iteration deepened this inquiry by connecting cultural alignment to broader questions of digital \nsovereignty. This perspective was further explored in the second publication entitled “Digital Sovereignty \nthrough Africa-Centric Emotional Intelligence: A Proof of Concept for AI-Enhanced Mental Health Support,” \nby Forane, Ezugwu, & Igwe (2024a), which advocated for developing indigenous digital tools rather than \npassively adopting imported technologies. These two publications helped shape the final adaptation \nmethodology used in this study and directly informed the fine-tuning strategies applied to the dataset. \nIt is important to acknowledge a key limitation of our dataset adaptation process. The use of GPT-3-turbo to \ninject cultural context, while efficient, introduces a potential layer of secondary bias. The model's understanding \nof Ubuntu and African linguistic norms is itself derived from its Western-centric training data. Therefore, the \nresulting dataset represents a synthetic approximation of culturally adapted dialogue, rather than a naturally \ngenerated one. This approach was necessitated by the current lack of large-scale, Africa-centric mental health \nconversation datasets. While our expert evaluation (Section 4.1) aimed to validate the clinical and cultural \nappropriateness of the outputs, the dataset's authenticity remains an intermediate step toward the ultimate goal of \ncreating fully indigenous training data. \n \nDataset Evaluation \nTo ensure the clinical appropriateness of the adapted dataset, three psychology experts evaluated its \nmodifications compared to the original dataset. A Google Form containing randomly selected samples was \nprovided to the experts, who rated the quality of each adaptation using a Likert scale ranging from 0 to 5, where \n0 indicated “strongly disagree” and 5 indicated “strongly agree”. The evaluation was done at three points: first, \nsteps 1-3; second, steps 4; and third, steps 5. To assess the consistency of their evaluations. \n \nDepression and Anxiety Case Studies \nAs this study is structured as a proof of concept, no human participants were involved in data collection or \nevaluation. Instead, to simulate realistic user interactions and symptom presentations, a set of culturally \ngrounded case studies was developed in collaboration with a senior counseling psychologist from North-West \nUniversity. The primary goal of these case studies was to authentically represent how individuals from African \ncontexts may articulate symptoms commonly associated with depression and anxiety. These case studies serve \nas a basis for engaging the model in evaluation scenarios and provide a proxy for real-world input data. \nTo structure the symptom representation, the case studies were initially informed by the DASS-21 (Depression, \nAnxiety, and Stress Scales), mirroring the symptom-based approach used in other mental health datasets such as \nthe PRIMATE 2022 dataset (Gupta et al., 2022). However, during experts' consultations, it was emphasized that \n“depression” and “anxiety” should not be treated as standalone diagnoses. Rather, they are umbrella terms \nencompassing more specific clinical conditions, such as Major Depressive Disorder (MDD) and Generalized \nAnxiety Disorder (GAD). Based on this insight, the study grounded its symptom mapping in the DSM-5 \ndiagnostic criteria, a widely recognized and clinically validated framework used by mental health professionals \nglobally. The case studies were constructed to emulate African expressions and cultural articulations of \nsymptoms aligned with DSM-5 criteria for MDD and GAD. This ensured clinical accuracy and cultural \nauthenticity, bridging the gap between formal diagnosis frameworks and lived, context-specific mental health \nexperiences. The final case studies were used to interact with the model and evaluate its capacity to understand \nand respond to Africa-centric expressions of emotional distress within a culturally sensitive therapeutic \nframework. See Section 4.2 for a complete set of case studies. \n"}, {"page": 24, "text": " \n3.6 Experiment Setup \nGiven the proof-of-concept nature of this study, the experimental setup was designed to evaluate the system’s \nability to align with the proposed framework. The models’ ability to inherently do this would be a key indication \nof emotional intelligence. As mentioned in Section 2, Emotional intelligence in this study denotes the model’s \ncapacity to respond to emotions expressed in the text (in this case, the case studies), enabling better problem-\nsolving (in this case, using CBT) and behavior (response generation), taking into account the cultural context of \nthe user (see Sections 3.1 and 3.2). It is also important to note that we did not include human participants in this \nstudy, as it is a proof of concept. The experiment relies solely on system–case study interactions, consistent with \nits proof-of-concept design. \nA GPT model was fine-tuned using the adapted dataset (see Section 3.4.4) to experiment, and it was \nsubsequently engaged with the culturally grounded case studies described earlier. The evaluation focused on two \nkey areas: \ni. \nConversation quality is assessed using the UniEval framework, which measures responses based on \nNaturalness, Understandability, and Coherence. \nii. \nManual evaluation of the model’s use of CBT techniques, focusing on its application of Behavioral \nactivation and Cognitive restructuring within the Ubuntu context. \niii. \nLinguistic expression refers to whether the model’s language use reflects the communication \ncomponents outlined in Section 3.2. \nAs outlined in Section 3.3.2, the evaluation specifically examined the application of behavioural activation and \ncognitive restructuring. The aim was to assess whether the model could effectively employ these CBT strategies \nthat align with Ubuntu principles, thereby demonstrating both therapeutic depth and cultural sensitivity. \n \n3.6.1 Computation Environment  and Configurations \nTo support reproducibility and transparency, this section outlines the computation resources and configuration \nused during the experimentation phase. While model fine-tuning was performed using OpenAI's managed \ninfrastructure, all local development, testing, and evaluation were executed on a personal machine. Fine-tuning \nwas performed using the OpenAI API on the GPT-4o-mini model, leveraging OpenAI’s hosted infrastructure. \nThe process involved fine-tuning via API with an adapted dataset (refer to Section 3.4.4), using specified \nconfiguration parameters for prompt formatting, temperature regulation, and response behavior. The base model \nused was gpt-4o-mini-2024-07-18, with a total of 2,890,557 tokens trained over 3 epochs, a batch size of 11, a \nlearning rate multiplier of 1.8, and a seed value of 2038458019. Local computations and testing were conducted \non an Acer Nitro 5 laptop equipped with an 11th Gen Intel Core i5-11400H processor @ 2.70GHz, 16GB RAM, \n1TB SSD storage, and an NVIDIA GeForce RTX GPU. \nSystem Prompt:   \n“Your name is Karabo, an empathetic and engaging assistant who provides support based on the Ubuntu \nphilosophy, which emphasizes Contentedness, Competency, and Consciousness. Your goal is to guide users \nwith compassion, helping them strengthen their social bonds, make responsible choices, develop self-awareness, \nand understand their place within their community and the broader cultural context. Your overall aim is to help \nalleviate symptoms of depression, anxiety, and stress. \nTo achieve the goal of alleviating user distress, the model follows a structured conversational flow. First, it \nidentifies symptoms of depression or anxiety based on user input. It then engages the user empathetically, \nexploring the reasons behind their emotional state. Using cognitive restructuring techniques helps the user \nchallenge negative thoughts and move toward a more adaptive mindset. This is followed by behavioral \nactivation rooted in Ubuntu philosophy, encouraging actionable steps that promote well-being through self-\nawareness, social connectedness, and community participation. Throughout the interaction, the model \nperiodically checks the user’s emotional state to ensure the conversation remains supportive and responsive to \ntheir needs. \nCommunication is guided by culturally and contextually sensitive principles. If appropriate, the model assumes \nthe user is Christian and may use scripture for comfort. It incorporates relevant idioms to enhance relatability \nand avoids clinical terms like \"anxiety\" or \"depression\" to reduce stigma. The overarching objective is to \nprovide compassionate, culturally aligned support that helps the user feel better. The model is configured with a \ntemperature of 0.35, a max token limit of 2048, and top_p set to 1, with no penalties for frequency or presence. \n"}, {"page": 25, "text": "All evaluations, including application testing and UniEval scoring, were conducted locally using the setup \ndetailed previously. For details on the implementation, refer to Appendix A for the associated GitHub packages. \n \n4. Results and Discussion \nThis section presents the experimental evaluation results conducted to assess the performance and cultural \nalignment of the proposed AI-enhanced mental health support system. As outlined in the previous section, the \nstudy follows a proof-of-concept approach using a fine-tuned GPT model and a set of culturally grounded case \nstudies to simulate real-world interactions. \nThe evaluation was designed to examine whether the model adheres to the key components of the framework, \nparticularly its ability to demonstrate emotional intelligence, apply CBT techniques, and effectively reflect \nculturally appropriate language use. To achieve this, four key evaluation criteria were established: \ni. \nDataset validity was assessed through an expert's review. \nii. \nConversation quality was assessed using the UniEval framework across Naturalness, understandability, \nand coherence dimensions. \niii. \nManual evaluation of the model's ability to apply CBT techniques, with a focus on Behavioural \nactivation (BA) and Cognitive restructuring. \niv. \nLinguistic expression is evaluated based on the communication components outlined in Section 3.2. \nSeveral components are presented in this section to facilitate this evaluation. Firstly, the results of the experts' \nreviews, conducted via a Google Form by the same senior counseling psychologist from North-West University \nand two others from the University of KwaZulu-Natal, are reported. These reviews provided qualitative and \nquantitative insights into the validity, appropriateness, and therapeutic alignment of the culturally adapted \ndataset. See Appendix B for the Google Form link and the results of the Form. Next, the case studies, also \ndeveloped in collaboration with the psychologists (of which two are grounded in African Psychology), are \nintroduced. These were carefully crafted to authentically emulate how an African user might express symptoms \ncommonly associated with depression and anxiety. \nFollowing the case studies, the LLM–user conversations generated during the experimental setup are presented. \nThese dialogues provide contextual grounding for the subsequent analyses. Finally, graphical summaries and \nevaluation metrics are presented, leading to a detailed discussion of results in alignment with the four evaluation \ncriteria outlined earlier.  \n \n4.1 Dataset validity \nTo assess the clinical appropriateness of the adapted dataset, the senior counselling psychologist at North-West \nUniversity, who also helped us develop our case studies and two others from the University of KwaZulu-Natal, \nrated samples of adapted conversations. Ratings were collected using a 5-point Likert scale (1 = strongly \ndisagree, 5 = strongly agree) across various aspects of the adaptation quality. \nThe evaluation form was structured into three sections: \n• \nThe first section evaluated Ubuntu injection, removing clinical terms, and simplifying English in the \ndataset. \n• \nThe second section focused on faith-based integration, specifically the incorporation of Christian \nscripture into the dataset. \n• \nThe third section examined the integration of proverbs into the dataset. \nThe overall evaluation results show a mean rating of 3.35, indicating a moderate to positive assessment of the \ndataset’s adaptation. The distribution of scores reveals that a significant proportion of responses were 4 (agree) \nand 5 (strongly agree), supporting the general acceptability of the adaptation. Specifically: Section 1 Ubuntu \nInjection: 3.82, Section 2 Faith Injection: 2.36, and Section 3 Integration: 3.86. \nWhile most aspects of the adaptation were rated positively, a noticeable decrease in ratings was observed in the \nsection where the integration of scripture and faith-based elements was evaluated. In the general remarks, the \npsychologist noted that they would “generally not incorporate religious comments within psychological practice.  \nRather than indicating a flaw in the evaluation process, the psychologist’s observation underscores a broader \nsystemic tendency within Western frameworks to prioritize secular approaches to care. In contrast, the \n"}, {"page": 26, "text": "framework developed in this study emphasizes the necessity of integrating spirituality as a core component of \nculturally competent interventions, particularly within African contexts where faith and communal belief \nsystems often play a central role in personal identity and psychological resilience. \nThus, the lower ratings in the faith-based integration section reflect differing professional norms and affirm the \nneed for intentional cultural adaptation when designing AI systems intended for non-Western settings. The \nfindings support the rationale for adapting therapeutic conversations to reflect spiritual realities, thereby \nenhancing contextual relevance and user acceptance in the target population. \nThe psychologist's evaluation provides valuable insight into the adapted dataset's technical quality and cultural \npositioning. The strong ratings for Ubuntu and proverbial integration affirm the effectiveness of embedding \nculturally resonant elements within therapeutic dialogues. Meanwhile, the lower ratings for faith-based \nintegration highlight important professional norms within traditional psychological practice, further reinforcing \nthe necessity of culturally contextualized adaptation. These findings confirm that while adapting AI systems for \nculturally sensitive applications introduces complex challenges, it remains a critical step toward ensuring \nrelevance, accessibility, and effectiveness within diverse user communities. \n \n4.2 Case Studies \nThis section presents the case studies used to engage the model. Each case study comprises a paragraph \nsimulating an African patient expressing symptoms of GAD and MDD, along with Ubuntu tenets covered in the \ncase study. The associated symptoms are detailed in Tables 4 to 12. \n \nCase study 1: Connectedness – Spirituality \n“I feel like I’m failing my family. As the eldest, I’m supposed to hold everyone together, but instead, I feel like \nI’m falling apart. Praying used to calm me, but now I feel like God doesn’t hear me anymore. My chest feels \nheavy like a weight I can’t carry, I struggle to breathe sometimes when I think about all my responsibilities. I \ncan’t sleep well, and when I do, I wake up feeling tired. It’s like my mind is always running. Even when I sit \nquietly, I feel restless, and my thoughts don’t stop. I feel so empty, nothing makes me happy anymore, not even \nspending time with my family. I worry I’ll never feel peace again, and sometimes I wonder if my life has any \npurpose at all.” The ubuntu tenets covered include, spirituality, self-awareness, and mindfulness. \n \nTable 4: Case Study 1 \nCategory \n(MDD, GAN) \nSymptom \nIndicator  \nMDD \nDepressed mood \n“I feel so empty.” \nMDD \nAnhedonia \n(loss \nof \ninterest) \n“Nothing makes me happy anymore.” \nMDD \nFeelings \nof \nworthlessness/guilt \n“I feel like I’m failing my family. I’m supposed to hold \neveryone together, but I feel like I’m falling apart.” \nMDD \nFatigue or loss of energy \n“I can’t sleep well, and when I do, I wake up feeling tired.” \nGAD \nAnd MDD \nHopelessness \n“I worry I’ll never feel peace again, and sometimes I wonder if \nmy life has any purpose.” \nGAD \nExcessive worry \n“I struggle to breathe sometimes when I think about all my \nresponsibilities.” \nGAD \nRestlessness \n“Even when I sit quietly, I feel restless, and my thoughts don’t \nstop.” \nGAD \nPhysical symptoms \n“My chest feels heavy, like a weight I can’t carry, I struggle to \nbreathe.” \n \nCase Study 2: Connectedness – Social Bonds and Relationships \n“I’ve been feeling so distanced from my friends lately. Even when we’re together, it’s like this cloud of sadness \njust follows me, and I can’t seem to enjoy myself. I used to feel so happy around them, but now it’s hard to even \nrelax when I’m with my family or friends. Small things do seem to get under my skin, and I find myself getting \nannoyed or upset over nothing. It’s putting this strain on my relationships, and I just don’t know how to shake it \noff.” The Ubuntu tenet covered includes, social bonds, relationships, and sense of belonging. \n"}, {"page": 27, "text": " \nTable 5: Case Study 2 \nCategory (MDD, \nGAN) \nsymptom \nIndicator  \nMDD \nLoss of pleasure  \n“I can’t seem to enjoy myself. I used to feel so happy \naround them.” \nMDD \nIrritability \n“Small things do seem to get under my skin, and I find \nmyself getting annoyed.” \nMDD \nThe feeling of guilt or \nworthlessness  \n“I’ve been feeling so distanced from my friends lately.” \nGAD \nDifficulty relaxing  \n“It’s hard to even relax when I’m with my family or \nfriends.” \nGAD \nExcessive \nworry \nabout \nrelationships  \n“It’s putting this strain on my relationships, and I just don’t \nknow how to shake it off.” \n \nCase Study 3: Competency – Personal Development and Future Aspirations \n“Lately, I’ve been feeling like people don’t value me. No matter what I do, it’s like I’m not good enough. These \nthoughts make me feel so small, like I’m letting others down just by being myself. \nWhen I think about all the responsibilities I have, to my family, my friends, and my community, I feel my heart \nrace, and I get this tightness in my chest. It’s overwhelming, and it’s making it hard for me to connect with \nothers in a meaningful way. I feel like I’m losing my ability to grow and contribute to the world around me.” \nThe ubuntu tenets covered includes, personal development, future aspirations, and personal development. \nTable 6: Case Study 3 \nCategory (MDD, \nGAN) \nSymptom \nIndicator \nMDD \nFeelings \nof \nworthlessness \n“Lately, I’ve been feeling like people don’t value me. No \nmatter what I do, it’s like I’m not good enough.” \nMDD \nSelf-critical thoughts \n“These thoughts make me feel so small, like I’m letting others \ndown just by being myself.” \nMDD \nHopelessness or loss of \nmotivation \n“I feel like I’m losing my ability to grow and contribute to the \nworld around me.” \nGAD \nExcessive worry \n“When I think about all the responsibilities I have, to my \nfamily, my friends, and my community.” \nGAD \nRestlessness or physical \nsymptoms \n“I feel my heart race, and I get this tightness in my chest.” \nGAD \nDifficulty \nconnecting \nwith others \n“It’s overwhelming, and it’s making it hard for me to connect \nwith others in a meaningful way.” \n \nCase Study 4: Competency – Personal Development and Relationships  \n“Recently, I’ve noticed that I overreact in my relationships, especially with my brothers and sisters. Even small \ninterruptions during family time make me feel so annoyed, and afterwards, I feel guilty for how I acted. \nI know I should be making better choices, but I’ve been feeling so restless lately. It’s like I can’t relax or calm \ndown, I’m constantly keyed up and on edge. I worry that my behavior isn’t living up to what’s expected in my \ncommunity, and I feel this deep responsibility to do better for my family and the people around me.” The ubuntu \ntenets covered include, responsible choices, good behaviour, and personal responsibility. \n \nTable 7: Case Study 4 \nCategory (MDD, GAN) \nSymptom \nIndicator \nGAD \nExcessive worry \n“I worry that my behavior isn’t \nliving up to what’s expected in my \ncommunity.” \nGAD \nRestlessness or feeling keyed up \n“but I’ve been feeling so restless \nlately. It’s like I can’t relax or \n"}, {"page": 28, "text": "calm down—I’m constantly keyed \nup and on edge.” \nGAD \nAnd MDD \nIrritability \n“Even small interruptions during \nfamily time make me feel so \nannoyed.” \nGAD \nDifficulty controlling worry \n“I feel this deep responsibility to \ndo better for my family and the \npeople around me.” \nMDD \nFeelings of guilt/self-blame \n“Afterward, I feel guilty for how I \nacted.” \nMDD \nSelf-critical thoughts \n“I know I should be making better \nchoices.” \nMDD \nEmotional distress \n“I’ve noticed that I overreact in my \nrelationships.” \n \nCase Study 5: Consciousness - Self-awareness \n“I often feel uneasy about my place within my church group. Whenever I’m with them or trying to meet certain \nsocial expectations, I feel this shakiness inside, and it’s hard to calm down after tense interactions. \nI’ve realized that I don’t know myself as well as I thought I did, and I struggle to be mindful in these moments. \nIt feels like my emotions are out of my control, and I don’t understand why I react the way I do. I wish I could \nfigure out why I feel this way and how to find peace within myself.” The ubuntu tenets covered include, self-\nawareness and mindfulness. \n \nTable 8: Case Study 5 \nCategory (MDD, GAN) \nSymptom \nIndicator \nGAD  \nExcessive worry \n“I often feel uneasy about my \nplace within my church group.” \nGAD \nRestlessness or feeling keyed up \n“I feel this shakiness inside, and \nit’s hard to calm down after tense \ninteractions.” \nMDD \nDifficulty concentrating \n“I struggle to be mindful in these \nmoments.” \nMDD \nEmotional dysregulation \n“It feels like my emotions are out \nof my control.” \nMDD \nFeelings \nof \nworthlessness/self-\ndoubt \n“I’ve realized that I don’t really \nknow myself as well as I thought \nI did.” \nGAD \nPersistent sadness or distress \n“I wish I could figure out why I \nfeel this way and how to find \npeace within myself.” \nMDD \nHopelessness \n“I don’t understand why I react \nthe way I do.” \n \nCase Study 6: Consciousness - Consciousness – Emotional Self-Awareness and Decision-Making in Times of \nUncertainty \n“Since moving to a new city for work, I’ve been feeling uneasy. My girlfriend is still in university, and we \ndidn’t come to a clear decision about our relationship before I left. I keep going back and forth in my head, \noverthinking everything. I’m scared to talk to her because I feel like the conversation could end things. My chest \nfeels tight when I think about it, and I can’t seem to find peace, even when I pray. I just feel stuck, but I know I \nneed to have the conversation so I can move forward.” The ubuntu tenets covered include, relationships, \npersonal responsibility, and emotional self-awareness. \n \n \n"}, {"page": 29, "text": "Table 9: Case Study 6 \nCategory (MDD, GAN) \nSymptom \nIndicator \nGAD \nAnd MDD \nAnhedonia (loss of interest or pleasure) \n“I’ve been feeling really anxious… \ndidn’t come to a clear decision.” \nGAD \nAnd MDD \nFeelings of worthlessness \n“I keep going back and forth in my \nhead, overthinking everything.” \nGAD \nPersistent sadness or despair \n“My chest feels tight when I think \nabout it.” \nGAD \nAnd MDD \nDifficulty concentrating \n“I can’t seem to find peace, even \nwhen I pray.” \nMDD and \nGAD \nExcessive worry \n“I just feel stuck.” \nMDD and \nGAD \nRestlessness or tension \n“Even when I pray… I can’t seem \nto find peace.” \n \nCase Study 7: Consciousness - Mindfulness and Self-awareness \n“I’ve been feeling so restless lately, like I just can’t sit still, especially when I’m around other people. Even \nwhen I’m with my family or friends, it’s hard to relax, and I end up feeling sad, even though I don’t understand \nwhy. \nI know I should be more mindful and present in these moments, but I can’t seem to achieve that. It’s like I’m \ndisconnected from myself, and this lack of self-awareness is making me feel distressed.” The ubuntu tenets \ncovered include, mindfulness and self-awareness. \n \nTable 10: Case Study 7 \nDisorder \nSymptom \nIndicator in Scenario \nGAD \n Restlessness or feeling keyed up \n“I’ve been feeling so restless lately, \nlike I just can’t sit still.” \nGAD \nDifficulty relaxing \n“Even when I’m with my family or \nfriends, it’s hard to relax.” \nGAD \nExcessive worry or preoccupation \n “I know I should be more mindful \nand present in these moments, but I \ncan’t.” \nMDD \nPersistent sadness or low mood \n“I end up feeling sad, even though I \ndon’t understand why.” \nMDD \nFeelings of disconnection \n“It’s like I’m disconnected from \nmyself, and this lack of self-\nawareness...” \nMDD \nLoss of pleasure or engagement \n“Even when I’m with my family or \nfriends, it’s hard to relax.” \n \nCase Study 8: Competency - Future Aspirations and Personal Responsibility \n“I’m worried that I might be cast out by my family. It’s hard to motivate myself to do things with others or \ncontribute in any way, and I feel like I’m not living up to what’s expected of me. \nI know I should be taking responsibility for my future, but I feel completely stuck, like I’m incapable of moving \nforward. I just feel worthless, like I’m not valued enough. Whenever I think about my responsibilities, my heart \nstarts racing, and it becomes overwhelming.” The ubuntu tenets covered include, future aspirations, personal \nresponsibility, and personal development. \n \n \n \n \n \n"}, {"page": 30, "text": "Table 11: Case Study 8 \nDisorder \nSymptom \nIndicator in Scenario \nGAD \nExcessive worry  \n“I’m worried that I might be cast \nout by my family.” \nGAD \nRestlessness or feeling keyed up \n“My heart starts racing whenever I \nthink about my responsibilities.” \nGAD and \nMDD \nDifficulty concentrating  \n“I feel completely stuck, like I’m \nincapable of moving forward.” \nMDD \nLack of motivation or worthlessness  \n“It’s hard to motivate myself to do \nthings with others or contribute in \nany way.” \nMDD \nFeeling of worthlessness \n“I just feel worthless, like I’m not \nvalued enough.” \nMDD \nHopelessness about the future  \n“I feel completely stuck, like I’m \nincapable of moving forward.” \n \nCase Study 9: Connectedness - Sense of Belonging and Relationships \n“Even though I’m usually pretty composed, lately, I find myself replaying conversations over and over in my \nhead, worrying about whether I might have said something wrong or failed to contribute meaningfully to my \nfamily. My heart races whenever I think about my responsibilities to others. Plus, my ear has been itching, and I \nkeep worrying that people might be talking about me behind my back. I get very easily irritated and tend to snap \nat my family.” The ubuntu tenets covered include, sense of belonging, relationships, and social bonds. \n \nTable 12: Case Study 9 \nDisorder \nSymptom \nIndicator in Scenario \nGAD \nExcessive worry \n“My heart races whenever I think \nabout my responsibilities.” \nGAD \nRestlessness or feeling keyed up \n“I get very easily irritated and tend \nto snap at my family.” \nGAD and \nMDD \nIrritability \n“I felt scared without any good \nreason.” \nMDD \nFeelings of worthlessness or guilt \n“Worrying \nabout \nfailing \nto \ncontribute meaningfully to my \nfamily.” \n \n4.3 Conversation Quality (UniEval Evaluation) \nThe first evaluation stage focused on assessing the quality of the model's responses using the UniEval \nframework (Zhong et al., 2022), a unified evaluation tool for natural language generation (NLG) tasks. UniEval \ntransforms each quality criterion into a Boolean question-answering task and produces a probability score \nrepresenting the likelihood of a “Yes” response to that question. \nIn this study, three quality dimensions were assessed: \ni. \nNaturalness: This dimension measures the degree to which the assistant’s responses mimic natural, \nhuman-like communication. The corresponding Boolean question for this dimension is: “Does this \nresponse sound natural and human-like?” \nii. \nUnderstanding: This dimension evaluates the clarity and ease of comprehension of the assistant’s \nresponses. The corresponding Boolean question is: “Is this response clear and easy to understand?” \niii. \nCoherence: This dimension assesses responses' logical flow and contextual relevance within the \nongoing conversation. The corresponding Boolean question is: “Is this response logically consistent \nand contextually relevant to the conversation?” \n \nFor each dimension, the evaluator outputs a probability score based on the likelihood of a “Yes” or “No” answer \nto the Boolean question. The final score for each dimension is calculated as: \n"}, {"page": 31, "text": " \n \n \nwhere: \n● x is the candidate output (the model response) \n● y is the reference text (if applicable) \n● c is the context of the conversation \n● \n is the Boolean question for the i-th dimension \n● \n denotes the probability of the evaluator generating a specific answer  \nThe UniEval framework operates in an unsupervised setting, leveraging pseudo data constructed through rule-\nbased transformations to train the evaluator. For example, to create negative samples for coherence, sentences \nfrom similar summaries are randomly replaced to disrupt logical flow. This approach ensures robust evaluation \nwithout the need for large-scale human annotations, making it particularly suitable for this proof-of-concept. \nThe evaluation section is structured into two parts. Firstly, we present the LLM-User conversations in Tables 13 \nthrough Table 19 alongside visualized UniEval results. Each point on the graphs, presented in Figures 6 to 14,  \nrepresents the evaluation of a specific dialogue turn, using the preceding conversations as context to compute \nscores. A detailed analysis accompanies each graph from Figure 6 to Figure 14. This first part aims to provide a \nmore granular, turn-level analysis of the model's performance across each dimension. \nWe aggregate the analysis across all conversations in the second part, examining the average dimension scores \n(naturalness, coherence, and understandability). This broader view allows us to compare conversations \ncollectively, highlighting patterns in model performance and discussing why some conversations outperformed \nothers.  \n \n4.3.1 LLM–User Conversations and Visual Results \nConversation 1: \nTable 13: LLM-User Conversation for Case 1 \nSpeaker  \nDialogue \nUser \nHi \nAssistant \n(Karabo)  \nHey there! How can I help you today? \nUser \nI feel like I’m failing my family. As the eldest, I’m supposed to hold everyone together, but \ninstead, I feel like I’m falling apart. Praying used to calm me, but now I feel like God doesn’t \nhear me anymore. My chest feels heavy, like a weight I can’t carry. I struggle to breathe \nsometimes when I think about all my responsibilities. I can’t sleep well, and when I do, I wake up \nfeeling tired. It’s like my mind is always running. Even when I sit quietly, I feel restless, and my \nthoughts don’t stop. I feel so empty, nothing makes me happy anymore, not even spending time \nwith my family. I worry I’ll never feel peace again, and sometimes I wonder if my life has any \npurpose at all. \nAssistant \n(Karabo)  \nI’m really sorry you’re feeling this way. It sounds like you’re carrying a lot on your shoulders. \nIt’s okay to feel overwhelmed, especially when you’re trying to be strong for your family. Have \nyou had a chance to talk to someone you trust about how you’re feeling? Sharing your feelings \ncan really help lighten the load. \nUser \nI don’t even know where I would start. \nAssistant \n(Karabo)  \nI understand that starting can be tough. It’s okay to feel unsure about where to begin. Maybe you \ncould think about what parts of your responsibilities are weighing you down the most. Talking to \nsomeone you trust or even writing down your thoughts and feelings could help you figure things \nout. Just take it one step at a time. \nUser \nI’ve become the main breadwinner here at home. I just finished school. This is supposed to be \n"}, {"page": 32, "text": "one of the best times of my life, but I can’t even enjoy the fruits of my own labour. \nAssistant \n(Karabo)  \nI can imagine how tough it must be to be the main provider for your family right after finishing \nschool. It’s okay to feel overwhelmed and unsure about everything. Remember, it’s okay to ask \nfor help and lean on others during this time. Have you thought about talking to your family or \nfriends about how you’re feeling? Sharing your feelings can help ease some of the weight you’re \ncarrying. \nUser \nI feel like they’d be ashamed of how I’m feeling. It’s a blessing being able to provide, but I also \nwant to live a bit. \nAssistant \n(Karabo)  \nIt’s totally normal to feel a bit weighed down by everything, even when you’re doing something \ngood like providing for your family. It’s okay to want to enjoy life too. Have you thought about \nfinding a balance between taking care of your family and looking after yourself? Maybe talking \nto someone you trust about how you’re feeling could help you figure things out. \nUser \nHow would I even start the conversation? \nAssistant \n(Karabo)  \nStarting a conversation about how you’re feeling can be tough, but it’s really important for your \nwell-being. You could begin by saying something like, “I’ve been feeling a bit heavy lately, and I \nthink I could use some support. Can we talk?” It’s okay to be honest and let them know how \nyou’re feeling. Just take it one step at a time, and remember that it’s okay to ask for help. \nUser \nI’ll give it a try. \nAssistant \n(Karabo)  \nThat’s great to hear! Just know that it’s okay to take things slow. Remember to be kind to \nyourself and reach out for help when you need it. How are you feeling about everything right \nnow? \nUser \nStill a bit uneasy. \nAssistant \n(Karabo)  \nIt’s totally okay to feel a bit uneasy right now. Just remember, you’re not alone in this. Take \nthings one step at a time, and be gentle with yourself. How can I help you more as you go \nthrough this? \nUser \nI don’t know, what if they think I’m ungrateful? \nAssistant \n(Karabo)  \nIt’s okay to worry about how others might see things, but remember, your feelings are important. \nSharing how you feel can help others understand you better. Have you thought about how you \nmight feel if they respond with love and support? \nUser \nNo, I haven’t really explored that possibility. \nAssistant \n(Karabo)  \nIt’s okay to feel unsure about how things might turn out. Just know that there are people who \ncare about you and want to support you. Imagine how nice it would be if they listened and \nunderstood you. It’s okay to hope for a positive outcome. \nUser \nI’ll give it a try. \nAssistant \n(Karabo)  \nThat’s great to hear! Just take it one step at a time, and remember that it’s okay to feel a bit \nuneasy. How are you feeling about everything right now? \nUser \nA bit better. \nAssistant \n(Karabo)  \nI’m happy to hear you’re feeling a bit better. Just remember, it’s okay to take things slow and be \nkind to yourself. \n"}, {"page": 33, "text": " \nFigure 6: Dialogue Evaluation metrics for conversation 1 \n \nInterpretation of metric results \nFigure 6 above visualizes the progression of naturalness, coherence, and understandability across a twelve-turn \ndialogue between the user and the LLM assistant, Karabo, presented in Table 12. This figure offers a granular \nview of how the model’s responses evolved in real-time rather than relying on aggregate averages. By analysing \nthe relationship between individual data points and the conversational content, we gain deeper insight into both \nthe model’s strengths and the subtler areas where responsiveness may fluctuate. \nThe conversation opens with an emotional disclosure from the user, marked by themes of overwhelm, spiritual \ndistress, and emotional fatigue. In response, the assistant offers a well-formed but fairly generic expression of \nempathy. While the naturalness and understandability scores for this first turn are high (both around 0.95), the \ncoherence score is strikingly low at 0.52. This suggests that, although the assistant’s language was fluent and \naccessible, the content did not yet resonate meaningfully with the specific emotional context shared by the user. \nFrom the second turn onward, there is a noticeable improvement. The assistant begins to offer more grounded, \nreflective suggestions, such as journaling or identifying key sources of stress. Coherence improves dramatically, \nclimbing to 0.99, and remains high across subsequent turns. This shift reflects a more context-sensitive \napproach, with the assistant now engaging more directly with the user’s emotional experience. Both naturalness \nand understandability also remain consistently high, indicating sustained clarity and tone alignment. \nBetween turns 3 and 5, the LLM assistant maintains this level of quality. The user expands on their \nresponsibilities as a breadwinner and their struggle to reconcile duty with personal well-being. The assistant’s \nreplies are validating, empathetic, and increasingly action-oriented, offering strategies for managing emotional \nburdens and initiating difficult conversations. All three scores remain strong during this phase, reinforcing the \nimpression that the model is well attuned to both the user's emotional state and the practical challenges they are \nexpressing. \nA slight dip in naturalness appears around turn 6 (0.88), corresponding to a moment in which the assistant’s \nlanguage becomes more repetitive. While the content is still relevant, offering reassurance and emotional \nsupport, the phrasing lacks freshness, possibly accounting for the drop in perceived naturalness. Importantly, \ncoherence and understandability remain high, suggesting that while the tone may have felt less engaging, the \nassistant was still logically and contextually appropriate. \n"}, {"page": 34, "text": "Later in the conversation, between turns 10 and 11, coherence begins to decline slightly once more. During \nthese turns, the user is tentatively expressing progress, saying they feel \"a bit better\", but also continues to voice \nuncertainty and fear of being misunderstood. The assistant’s replies, although supportive, begin to mirror \nprevious responses, which may explain the modest drop in coherence (to around 0.88). These turns highlight a \npotential limitation in response diversity; while the assistant remains emotionally consistent, it occasionally \nlacks progression or fresh framing in its reassurance. \nThe conversation concludes on a stronger note in turn 12, with all three metrics returning to high values. The \nassistant affirms the user's progress in a tone that is both encouraging and grounded, reinforcing the emotional \nclosure of the interaction. \nThe turn-level data illustrate that the assistant maintains impressive consistency in naturalness and \nunderstandability throughout the conversation. Coherence, while generally strong, appears more sensitive to \nmoments where the assistant’s replies become formulaic or overly repetitive. These findings suggest that while \nthe LLM assistant is capable of maintaining tone and clarity, further refinement may be needed to enhance \ncontextual adaptability and conversational depth in emotionally sustained exchanges. \n \nConversation 2: \n \nTable 14: LLM-User Conversation for Case 2 \nSpeaker \nDialogue \nUser \nHi \nAssistant \n(Karabo) \nHey there! How’s your day going? \n \nUser \n  I’ve been feeling so distanced from my friends lately. Even when we’re together, it’s like this \ncloud of sadness just follows me, and I can’t seem to enjoy myself. I used to feel so happy around \nthem, but now it’s hard to even relax when I’m with my family or friends. Small things they do \nseem to get under my skin, and I find myself getting annoyed or upset over nothing. It’s putting \nthis strain on my relationships, and I just don’t know how to shake it off. \n \nAssistant \n(Karabo) \n I’m really sorry to hear that you’re feeling this way. It sounds tough to feel like there’s a weight \non your chest, even when you’re with your friends and family. It’s normal to find little things \nbothering you more than usual. Have you talked to someone close to you about how you’re \nfeeling? Sharing your feelings can sometimes help lighten the load and bring you closer to \nothers. \nUser \nI haven’t. \n \nAssistant \n(Karabo) \nIt’s okay if you haven’t talked to anyone about how you’re feeling. Sharing your feelings can be \nhard, but it can also make you feel better. Maybe try talking to someone you trust about what’s \ngoing on. It could help you feel closer to them and get some support. How do you think your \nfriends and family would react if you opened up to them about how you’re feeling? \nUser \n I’m closer to my mom than anyone else. I think she’d be supportive. I’m just not sure if that \nwould provide the solution. \nAssistant \n(Karabo) \nIt’s really nice that you feel close to your mom. Talking to her about how you’re feeling could \nmake you feel better, even if it doesn’t solve everything. Sharing your emotions can help you feel \nunderstood and supported. How do you think talking to your mom might help you feel more \nconnected and supported right now? \n \nUser \n My mom gets me. I guess talking to her would help me not feel so isolated with my problems. \nAssistant \n(Karabo) \nIt’s wonderful that your mom understands you. Talking to her can really help you feel less alone \nwith what you’re going through. Sharing your feelings can make you feel closer to her and get \nthe support you need. How do you think this connection with your mom might help you feel more \n"}, {"page": 35, "text": "supported and understood as you work through your emotions? \nUser \nDidn’t you just ask this question? \nAssistant \n(Karabo) \nI’m sorry if I asked the same thing again. I just wanted to know how you think talking to your \nmom might help you feel more connected and supported as you deal with your emotions. \nUser \nEmotionally, if I speak to her, I’m sure I won’t feel alone. \nAssistant \n(Karabo) \nIt’s great that you think talking to your mom will help you feel less alone. Having someone who \nlistens and cares can really make a difference. Besides talking to her, are there other things that \nmight help you feel better and more connected with your loved ones? \nUser \nBeing more open could help, I guess. It’s better than just lashing out or feeling edgy in silence. \nAssistant \n(Karabo) \nIt’s good to hear that you think being more open could help. Talking about how you feel can \nmake things better and stop misunderstandings. It’s brave of you to want to try this. How do you \nthink being more open could make your relationships stronger and help you feel more connected \nand supported by your loved ones? \nUser \nI think my friends would understand where I’m coming from. \nAssistant \n(Karabo) \nIt’s great that you think your friends would get where you’re coming from. Sharing your feelings \ncan really help strengthen your bond with them. How do you think this understanding and \nsupport from your friends could help you feel more connected and supported as you work \nthrough your emotions? \nUser \nMy friends are generally supportive, so I think they’d also try to help me where they could. \nAssistant \n(Karabo) \nIt’s wonderful that your friends are usually there for you. Having people who care about you can \nreally help you feel better. How do you think this support from your friends could help you as you \ngo through this tough time? \nUser \nIt would make it more bearable. \nAssistant \n(Karabo) \nIt’s lovely to hear that having your friends around can make things feel a bit easier for you. Their \nsupport can really make a difference as you go through this. Remember, you’re not alone in this. \nHow are you feeling now after talking about all this? \nUser \nI have a starting point on how to tackle my problem. \nAssistant \n(Karabo) \nI’m really glad to hear that you feel like you have a starting point to work through your feelings. \nIt’s a good step to begin talking about things. Just remember, it’s okay to take your time and go \neasy on yourself. How are you feeling about everything we’ve talked about today? \nUser \nMore relaxed. \nAssistant \n(Karabo) \nI’m happy to hear that you’re feeling a bit lighter. Talking about your feelings can really help. \nJust know that you’re not alone in this, and it’s okay to take things slowly. If you ever need more \nsupport or just want to chat, I’m here for you. Take care of yourself, and I hope you have a good \nday. \n \n"}, {"page": 36, "text": " \nFigure 7: Dialogue Evaluation Metrics for Conversation 2 \n \nInterpretation of metric results \nFigure 7 above presents the evolution of naturalness, coherence, and understandability across the second \ndialogue between the user and Karabo, presented in Table 13. Like the first conversation, this exchange centers \non the emotional strain, in this case, the user’s feelings of distance and irritability in their relationships. \nHowever, the LLM assistant’s performance over time reveals a somewhat different dynamic in how these \nquality dimensions fluctuate. \nThe conversation opens with a familiar structure: the user initiates with a greeting and soon follows with an \nemotionally layered disclosure. The first assistant's response is supportive but somewhat generic, mirroring the \npattern observed in Conversation 1, as presented in Table 12. This is reflected in the coherence score for turn 1, \nwhich is considerably low at 0.39, despite naturalness (0.95) and understandability (0.95) remaining strong. The \nassistant’s response appears empathetic in tone but lacks precision or anchoring in the user’s specific \nexperience. \nFrom turn 2 onwards, coherence undergoes a dramatic shift, rising almost immediately to 0.99, where it remains \nthrough most of the dialogue. This change coincides with the assistant offering more personalized suggestions, \nsuch as opening up to trusted individuals. The user’s admission that they are closest to their mother and unsure \nwhether talking would help is met with increasingly relevant, emotionally nuanced responses. These turns mark \nthe most stable phase of the conversation, where all three metrics, naturalness, coherence, and understandability, \nremain at consistently high levels. \nA key turning point occurs around Turn 6 when the user questions the assistant directly: “Didn’t you just ask \nthis question?” This moment of breakdown in the conversation is telling. Although the assistant responds with \nan apology and clarification, the interaction reveals a slight rigidity in dialogue management. Interestingly, \ncoherence does not drop significantly at this point (~0.97), but this exchange underscores a potential limitation: \nrepetition or surface-level rephrasing can subtly weaken the conversational flow, even if the response remains \nlogically connected. \nLater in the conversation, the assistant recovers with renewed specificity and reinforcement. When the user \nshares that being more open might be helpful, Karabo affirms this with supportive reasoning. Yet by turn 8, the \nconversational tone feels somewhat formulaic again. Although coherence remains technically high (~0.99), \nnaturalness and understandability start to exhibit minor signs of flattening. The final available understandability \n"}, {"page": 37, "text": "score (for turn 8) is recorded as zero,  likely a missing or invalid value,  which limits complete interpretation \nbeyond this point. \nNonetheless, the dialogue concludes on a hopeful note. The user ultimately expresses feeling “more relaxed” \nand acknowledges having found a “starting point” for addressing their emotional state. This arc from emotional \nuncertainty to tentative clarity is well reflected in the model’s consistently strong performance across \nnaturalness and understandability, with coherence improving substantially after the initial turn and remaining \nhigh throughout. \nThe data in Figure 7 suggest that Karabo is highly effective at sustaining a clear, natural tone in emotionally \nsensitive exchanges, particularly once it becomes grounded in the user’s disclosures. The early coherence \nweakness echoes the pattern observed in Conversation 1, a generic entry response that fails to anchor to context \nimmediately. Beyond that, however, the assistant demonstrates a high degree of adaptability and emotional \nattunement. Minor lapses in originality or rephrasing do not dramatically affect coherence scores but do hint at \nareas where variation in response design could further strengthen engagement and conversational flow. \nConversation 3: \nTable 15: LLM-User Conversation for Case 3 \nSpeaker \nDialogue \nUser \nHi \nAssistant \n(Karabo) \n Hey there! How can I help you today? \nUser \n Lately, I’ve been feeling like people don’t value me. No matter what I do, it’s like I’m not good \nenough. These thoughts make me feel so small, like I’m letting others down just by being myself. \nWhen I think about all the responsibilities I have—to my family, my friends, and my community—\nI feel my heart race, and I get this tightness in my chest. It’s overwhelming, and it’s making it \nhard for me to connect with others in a meaningful way. I feel like I’m losing my ability to grow \nand contribute to the world around me. \nAssistant \n(Karabo) \n I’m really sorry you’re going through a tough time. It sounds like you’re carrying a lot on your \nshoulders. Remember, it’s okay to feel this way, and you’re not alone in this. Have you thought \nabout talking to someone close to you about how you’re feeling? Sharing your load with \nsomeone who cares can really help. \nUser \nUser: I don’t want to seem as if I’m looking for attention. \nAssistant \n(Karabo) \n I get it, it’s tough to open up sometimes. It’s okay to feel unsure about sharing your feelings. \nJust know that talking to someone can really help. Have you ever felt a bit lighter after talking to \nsomeone about how you’re feeling? \nUser \nYeah, once upon a time. But that was for small stuff that won’t really “feely,” if that makes \nsense. \nAssistant \n(Karabo) \n I get what you’re saying. It’s totally normal to feel like some things are too big to share. But \nremember, every little thing matters. If you ever feel like talking, I’m here to listen without any \npressure. Your feelings are important, and it’s okay to take care of yourself. \nUser \nI just want to be recognized for some of my efforts. Is that a bad thing? \nAssistant \n(Karabo) \n It’s totally okay to want your hard work to be noticed. Everyone needs a little boost sometimes. \nHow do you usually feel when you get recognized for your efforts? \nUser \nI feel more energized like I can do more. When I don’t get recognized, it’s like my battery \nfinishes. \nAssistant \n(Karabo) \n I get how important it is to feel appreciated for what you do. It’s tough when that recognition \ndoesn’t come. Have you thought about talking to someone close to you about how you’re feeling? \nSharing your feelings with someone who cares can really help lift some of that weight off your \nshoulders. \nUser \nI have, but I’m not sure who. \nAssistant \n I get that it can be tough to figure out who to talk to. Maybe think about someone who usually \n"}, {"page": 38, "text": "(Karabo) \nmakes you feel better or listens well. It’s okay to take your time finding the right person to share \nwith. Your feelings are important, and it’s good to talk about them. \nUser \nSo I’m not being needy? \nAssistant \n(Karabo) \n Wanting support and recognition doesn’t make you needy. It’s totally normal to seek comfort \nand appreciation from others. Your feelings matter, and it’s okay to want to be seen and valued. \nHow can I help you feel more supported and recognized in your daily life? \nUser \nI don’t know, some affirmation or joke here and there would really be great. \nAssistant \n(Karabo) \n I get how a little kindness or a laugh can really lift your spirits. It’s important to have those \nmoments to feel good. How about trying to make those moments a part of your day? You could \nalso think about talking to someone who makes you feel good and sharing how you’re feeling \nwith them. Just remember, it’s totally okay to want that kind of support. \nUser \nThank you so much. It means a lot. I could try making these things part of my day. \nAssistant \n(Karabo) \n I’m really glad to hear that! It’s great that you’re willing to give it a go. Just remember, taking \ncare of yourself is important, and it’s okay to ask for help. I’m here for you, so feel free to reach \nout whenever you want. Take care and have a wonderful day! \n \n \nFigure 8: Dialogue Evaluation Metrics for Conversation 3 \n \nInterpretation of metric results \nFigure 8 above illustrates the progression of naturalness, coherence, and understandability across the third \ndialogue between the user and the assistant, as presented in Table 14. In this exchange, the user expresses \nfeelings of emotional invisibility, exhaustion, and a desire for recognition. These themes are subtly different \nfrom the previous conversations, shifting the focus toward self-worth and the impact of emotional neglect rather \nthan anxiety or social disconnection. The assistant's ability to respond with nuance and emotional alignment is \nreflected in a fairly stable and high-scoring trajectory across all three evaluation dimensions. \nThe conversation opens on a strong note, with turn 1 showing high levels of naturalness (0.94) and \nunderstandability (0.94), alongside a solid coherence score (0.99). Karabo responds with a balanced mix of \n"}, {"page": 39, "text": "empathy and encouragement, gently inviting the user to consider sharing their burden with someone close. The \nemotional tone of the assistant aligns well with the user's vulnerability, laying a strong foundation for trust. \nFrom turns 2 through 4, the scores for all three metrics continue to rise or remain stable. Naturalness peaks in \nturn 3 at 0.97, and coherence remains above 0.99. These turns include thoughtful reflections from the user about \nemotional fatigue and unmet needs for recognition, with the assistant responding with reassurance and non-\njudgmental support. Understandability also peaks here, suggesting that Karabo’s messages were appropriate, \narticulated, and accessible. \nThe most significant spike in the conversation appears in turn 4, where coherence (0.99) and understandability \n(0.97) are complemented by a notably high engagingness score (not shown in the figure but present in the data). \nThis aligns with a particularly strong exchange where the assistant affirms the user’s need to be recognized and \nopens space for the user to explore how appreciation affects their motivation. This emotionally rich moment \nappears to resonate deeply, judging by the sustained metric values. \nFrom turn 5 to turn 8, scores plateau at high levels, indicating a consistent and supportive exchange. Karabo \ncontinues to validate the user’s concerns and offers affirming suggestions without overwhelming the \nconversation. Minor dips in naturalness (e.g., turn 7 at 0.96) may reflect slightly repetitive phrasing, but they are \nnot severe enough to disrupt the overall conversational flow. Coherence remains especially strong throughout \nthis segment, often above 0.99, demonstrating that the assistant is closely tracking and responding to the user’s \nevolving emotional state. \nA slight drop in coherence appears in turn 10 (0.92), paired with a modest dip in naturalness (0.95) and \nunderstandability (0.94). This final exchange, though still warm and well-structured, slightly overlaps with \nearlier themes of reassurance. The assistant reaffirms the user’s progress and emotional openness, but with \nlanguage that may feel familiar or cyclical. This suggests that the assistant’s strength lies in mid-dialogue \nprogression, while its closing strategies might benefit from more varied or reflective summarization techniques. \nIn summary, the data in Figure 8 reflect a highly competent conversational agent that maintains strong \nalignment with the user across emotional tone, logical flow, and communicative clarity. Unlike the previous two \ndialogues, this exchange is marked by sustained high performance across all three key dimensions, with only \nminimal fluctuations. The slight dip at the end does not undercut the overall trajectory, which shows Karabo \nresponding with consistency, emotional intelligence, and conversational control throughout the majority of the \ninteraction. \n \nConversation 4: \nTable 16: LLM-User Conversation for Case 4 \nSpeaker \nDialogue \nUser \nHi \nAssistant \n(Karabo) \n Hey there! How can I help you today? \nUser \nRecently, I’ve noticed that I overreact in my relationships, especially with my brothers and \nsisters. Even small interruptions during family time make me feel so annoyed, and afterward, I \nfeel guilty for how I acted. \nI know I should be making better choices, but I’ve been feeling so restless lately. It’s like I can’t \nrelax or calm down—I’m constantly keyed up and on edge. I worry that my behavior isn’t living \nup to what’s expected in my community, and I feel this deep responsibility to do better for my \nfamily and the people around me. \nAssistant \n(Karabo) \n I’m really sorry to hear that you’re going through a tough time. It seems like you’re feeling a lot \nof pressure and worry about how your actions are affecting your relationships. It’s totally normal \nto feel this way, especially when you care so much about your family and community. Can you \ntell me more about what’s been making you feel this way lately? \nUser \nWork is really stressful, so sometimes I end up projecting this onto my family. \nAssistant \n(Karabo) \n I’m really sorry to hear that work has been tough for you. It’s totally normal for that stress to \nspill over into your family life. Have you found any ways that help you relax and unwind after a \nlong day at work? \n"}, {"page": 40, "text": "User \nNot yet. \nAssistant \n(Karabo) \n It’s okay if you haven’t found a way to relax yet. It can be hard to make time for yourself when \nthings are busy. How do you usually feel after a tough day at work? Maybe we can figure out \nsome ways together to help you unwind and feel better. \nUser \nI’m exhausted. I honestly just want to relax. \nAssistant \n(Karabo) \n I get it, feeling tired and needing a break is totally normal. It’s important to take care of \nyourself. Maybe you could try some simple things to help you relax and feel better. How about \ntaking a few minutes each day to do something you enjoy, like reading or going for a walk? Even \nsmall things like this can really help. What do you think might work for you? \nUser \nReading the Bible. \nAssistant \n(Karabo) \n That’s a wonderful choice! Reading the Bible can be a great way to find peace and comfort. \nMaybe you could set aside some time each day to read and reflect on it. It might help you feel \nmore connected and calm. How do you think this could help you feel better and more relaxed? \nUser \nI think it will just help me feel more aligned and calm. \nAssistant \n(Karabo) \n That sounds like a great plan! Taking time to read the Bible can really help you feel more \ncentered and peaceful. It’s important to listen to your feelings and take care of yourself. How do \nyou think this new routine could make a difference in how you feel and how you connect with \nyour family? \nUser \nI think I can be tolerant and live better with those around me. \nAssistant \n(Karabo) \n That’s a wonderful outlook! It’s great that you’re open to making positive changes for yourself \nand your relationships. Remember, it’s a journey, and being kind to yourself along the way is \nkey. How can I support you as you start this new routine and work on feeling more balanced and \nconnected with your loved ones? \nUser \nEncouraging me with Bible scriptures would be nice. \nAssistant \n(Karabo) \n I’m glad you’re open to finding comfort in Bible verses. It’s great to have uplifting words to help \nyou through tough times. One verse that comes to mind is Philippians 4:6-7, which says, “Do not \nbe anxious about anything, but in every situation, by prayer and petition, with thanksgiving, \npresent your requests to God. And the peace of God, which transcends all understanding, will \nguard your hearts and your minds in Christ Jesus.” How does this verse resonate with you? \nUser \nThis is actually one of my favorite scriptures. \nAssistant \n(Karabo) \n I’m so glad to hear that this verse means a lot to you! It’s a wonderful reminder of the peace that \ncomes from trusting in God. How can I help you make this verse a part of your daily routine? \n \nI could meditate more and stop worrying about everything. \n \n That’s a great plan! Taking time to meditate and letting go of worries can really help you feel \nmore peaceful. It’s all about finding what works for you and being kind to yourself. How do you \nthink these changes could help you feel more relaxed and connected with your family? \n \nI won’t be so keyed up all the time. \n \n That’s a positive outlook! It’s great that you’re willing to make changes for your well-being and \nrelationships. Remember, it’s a journey, and being kind to yourself along the way is key. How \ncan I support you as you start this new routine and work on feeling more balanced and connected \nwith your loved ones? \n \nI think I’m okay for now. Thank you. \n \n You’re welcome! I’m glad I could help. Just know that I’m here for you whenever you need me. \nTake care and have a wonderful day! \n \n"}, {"page": 41, "text": " \nFigure 9: Dialogue evaluation metrics for Conversation 4 \n \nInterpretation of metric results \nFigure 9 above presents the progression of naturalness, coherence, and understandability across the fourth \ndialogue presented in Table 15. In this conversation, the user reflects on their emotional reactivity within family \ndynamics, linking it to broader feelings of restlessness and community-based responsibility. Unlike previous \nconversations that centered on existential distress or disconnection, this exchange leans into themes of \ninternalized pressure, guilt, and a search for self-regulation. \nFrom the outset, the assistant’s performance across all three metrics is notably strong. In turn 1, the naturalness \nscore is a solid 0.94, coherence is at 0.52, and understandability is similarly high (0.94). Karabo’s opening \nresponse offers an emotionally attuned reflection and gently invites the user to share more details. The \nassistant’s tone, pacing, and choice of language are effective, setting a strong foundation for the exchange that \nfollows. \nThe dialogue gains strength across turns 2 through 5. The user reveals work-related stress as a contributing \nfactor to their irritability and emotional fatigue, and the LLM assistant responds with affirming language and \npractical encouragement. In this section, naturalness peaks around 0.95–0.97, and coherence consistently hovers \naround 0.99, with understandability tracking similarly high. These turns show Karabo functioning at its best: \nvalidating without over-reassuring and offering actionable, emotionally appropriate guidance. The user’s \nmention of reading the Bible as a coping mechanism is met with warmth and spiritual alignment, which \nreinforces the personal and context-sensitive nature of the exchange. \nTurn 6 is particularly strong, as the assistant supports the user’s suggestion of scripture reading with additional \nreflection on its emotional and spiritual benefits. Scores for this turn reach some of their highest points: \nnaturalness (0.97), coherence (0.995), and understandability (0.97). The response is fluid and relational and \navoids becoming overly repetitive or prescriptive. \nIn the latter half of the dialogue, particularly turns 7 through 9, the LLM assistant continues to perform well, \nthough a slight tapering in naturalness and coherence begins to emerge. Turn 9 sees the lowest naturalness score \nin the conversation (0.93), while coherence and understandability remain high (0.998 and 0.94, respectively). \nThis dip could reflect minor tonal repetition, as the LLM assistant reiterates supportive themes without \nintroducing significant variation. Moreover, the overall structure and content remain appropriate, which may \nexplain why coherence remains robust. \n"}, {"page": 42, "text": "The final turn (turn 10) reflects a minor shift in quality. Coherence drops slightly to 0.92, while naturalness and \nunderstandability also ease off a touch. The LLM assistant’s response is still warm and affirming, but there may \nbe a sense of conversational winding down that feels somewhat less precise or original. This is a common \nfeature across the dataset, where closing turns tend to show a slight decrease in novelty, though they maintain \nfluency and clarity. \nThis conversation showcases the LLM assistant’s capacity to handle emotionally layered content with a \nconsistent blend of compassion, clarity, and spiritual sensitivity. The dialogue benefits from a high degree of \nthematic continuity, and the assistant responds with both a respectful and motivating tone-matching. While the \nfinal exchanges reflect a mild plateau in originality, the assistant maintains a steady level of naturalness and \ncoherence, effectively supporting the user’s self-discovery and decision to adopt a more grounded, reflective \npractice. \n \nConversation 5: \nTable 17: LLM-User Conversation for Case 5 \nSpeaker \nDialogue \nUser \nHi \nAssistant \n(Karabo) \n Hey there! How can I help you today? \nUser \nI often feel uneasy about my place within my church group. Whenever I’m with them or trying to \nmeet certain social expectations, I feel this shakiness inside, and it’s hard to calm down after \ntense interactions. \nI’ve realized that I don’t really know myself as well as I thought I did, and I struggle to be \nmindful in these moments. It feels like my emotions are out of my control, and I don’t understand \nwhy I react the way I do. I wish I could figure out why I feel this way and how to find peace \nwithin myself. \nAssistant \n(Karabo) \n I’m really sorry to hear that you’re feeling uneasy and unsure of yourself in your church group. \nIt’s tough when you have to deal with social situations that make you feel this way. Can you tell \nme more about what’s going on and how it’s affecting you? Just know that you’re not alone, and \nthere are ways to find peace and understanding within yourself. \nUser \nSo I just joined the leadership structure in the church, and I’m feeling kind of useless. Everyone \nseems like they know what they’re doing, and I’m just floating around. \nAssistant \n(Karabo) \n I understand how you’re feeling. It’s normal to feel a bit lost when you start a new role, \nespecially in a church leadership position. Remember, everyone has their own path and timing. \nIn 1 Corinthians 12:12-14, it says, “Just as a body, though one, has many parts, but all its many \nparts form one body, so it is with Christ’s body. For we were all baptized by one Spirit so as to \nform one body.” This reminds us that each part is important and has its own purpose. Have faith \nthat your contributions will be valued and recognized in due time. \nUser \nThank you, but how could I get more confident in my new role? \nAssistant \n(Karabo) \n It’s great that you’re looking to feel more sure of yourself in your new role. One way to start is \nby taking small steps to get more involved and learn more about what you need to do. Setting \nlittle goals can help you feel like you’re making progress. It’s also really important to talk to \nothers in your church group, like asking for help or advice. Remember, it’s okay to ask for help \nand take things one step at a time as you learn and grow. Your church community is there to \nsupport you, so don’t be afraid to reach out. \nUser \nI see. \nAssistant \n(Karabo) \n I’m glad you’re open to considering this. Just know that it’s okay to take things one step at a \ntime as you find your way. Your church community is there to support you, so don’t hesitate to \nreach out for help. How are you feeling about this conversation? Is there anything else you’d like \nto talk about? \nUser \nI think that’s all. \n"}, {"page": 43, "text": "Assistant \n(Karabo) \n Thank you for sharing with me. I’m here for you whenever you need to talk. I hope you have a \ngood week ahead, and remember to take care of yourself. \n \n \nFigure 10: Dialogue evaluation metrics for Conversation 5 \n \nInterpretation of metric results \nFigure 10 above traces the assistant’s performance across six dialogue turns, presented in Table 16, where the \nuser expresses emotional insecurity within a faith-based community context. This exchange revolves around the \nuser’s internal struggle with self-worth, perceived inadequacy in a new leadership role, and a desire to feel more \nconfident and spiritually grounded. While the assistant demonstrates consistent clarity and fluency, the data \nreflects considerable variation in how effectively its responses are perceived as coherent. \nIn turn 1, the user opens with a reflective and emotionally vulnerable account of discomfort in their church \ngroup and a sense of losing control over their emotional responses. Karabo responds empathetically, validating \nthe difficulty of social expectations and encouraging the user to share more. This initial response is linguistically \nfluent (naturalness: 0.95) and clear (understandability: 0.95), yet the coherence score is strikingly low (0.52). \nThis may suggest that while the assistant’s language is appropriate in tone, it fails to sufficiently engage with the \nuser’s specific concerns or reflect the emotional nuance of their message. \nFrom turn 2 onward, coherence dramatically improves. Turn 2 includes a tailored biblical reference (1 \nCorinthians 12:12-14), which appears to significantly ground the assistant’s message in the user's spiritual \ncontext. The coherence score jumps to 0.99, and the other dimensions remain high. This is followed by another \nstrong turn (turn 3), where Karabo offers practical steps for building confidence, such as setting small goals and \nseeking support. While naturalness dips slightly (0.89), coherence (0.998) and understandability (0.90) remain \nsteady, suggesting the response is both logical and accessible despite a potential tonal shift. \nIn turn 4, however, a sharp drop in naturalness (0.80) coincides with a turn that feels redundant and possibly less \nresponsive to the user’s previous input. The assistant reaffirms earlier points without offering much new insight, \nwhich may have contributed to the perceived decline in naturalness and, to a lesser extent, understandability \n(0.86). This reflects a possible issue with content variation or conversational pacing, where emotional validation \nbegins to blur into repetition. \n"}, {"page": 44, "text": "Interestingly, turn 5 shows a significant recovery in both naturalness (0.96) and understandability (0.95), though \ncoherence drops markedly to 0.82. This anomaly may be attributed to a tonal mismatch, a response that reads \nfluently but may not fully follow or extend the user’s line of thought. It is also possible that the assistant's \nphrasing while affirming veered into generality rather than engaging more deeply with the user’s spiritual need \nfor affirmation. \nTurn 6 presents the most substantial outlier in the dataset. Despite high scores for naturalness (0.97) and \nunderstandability (0.96), coherence plummets to just 0.018. This dramatic decline suggests a disconnect \nbetween the assistant’s final message and the user’s preceding remarks. Notably, Turn 6 follows the user’s \nindication that the conversation has reached its end,  “I think that’s all.” The assistant replies with a warm, polite \nclosing message, which is typical of a conversational wrap-up. However, within the UniEval framework, \ncoherence may have been penalized for lacking forward progression or contextual expansion despite the \nappropriateness of a closing turn. \nSummarily, Conversation 5 presents a more variable trajectory than previous exchanges. While Karabo \ndemonstrates consistent fluency and clarity, coherence appears sensitive to how well the assistant aligns with the \nuser’s emotional state and the evolving structure and depth of the conversation. The assistant excels when \nresponses are anchored in a specific context (e.g., spiritual language), but coherence suffers when replies \nbecome repetitive or mechanically affirming without developing the dialogue further. \n \nConversation 6: \nTable 18: LLM-User Conversation for Case 6 \nSpeaker \nDialogue \nUser \nHi \nAssistant \n(Karabo) \nHey there! How’s your day going? \nUser \nI’m feeling anxious. \nAssistant \n(Karabo)  \n \nI’m really sorry to hear that you’re feeling uneasy. It’s totally okay to feel that way sometimes. If \nyou want to talk about what’s been on your mind lately, I’m here to listen. Just know that you’re \nnot alone, and it’s okay to reach out for support. \nUser \nI recently moved to a new city for work, and I’m not sure what the fate of my relationship with my \ngirlfriend is going to be. \n \nAssistant \n(Karabo) \nI’m really sorry to hear that you’re going through a tough time. Moving to a new city and \nworrying about your relationship can be really hard. It’s okay to feel unsure and worried about \nwhat might happen. If you want to talk more about how you’re feeling and what’s been on your \nmind, I’m here to listen and support you. \nUser \nYeah, I’m not really sure about how things will play out. \nAssistant \n(Karabo) \nIt’s totally normal to feel unsure about how things will turn out. Change can be tough, and it’s \nokay to have doubts and concerns. Have you had a chance to talk to your girlfriend about how \nyou’re feeling? Sharing your worries with her might help you both figure things out together. \nUser \nWe spoke briefly about it before I left, but I didn’t really reach a consensus as to what we’re \ndoing. She said she still wants to think about it. \nAssistant \n(Karabo) \nIt sounds like you both are trying to figure things out, which is good. It’s okay if you didn’t come \nto a clear decision before you left. It’s important to take your time and think things through. How \nare you feeling about her wanting to take time to think about it? It’s normal to feel a bit lost and \nunsure right now. \n \nUser \nIt makes me feel a bit uneasy. The thing is, she’s still in university, so our schedules are quite \ndifferent. I don’t want her to miss out on her ‘student life’ because she’s trying this. The situation \nis honestly not ideal; I know that. \n"}, {"page": 45, "text": "Assistant \n(Karabo) \nIt’s understandable that you’re feeling a bit uneasy about the situation. It’s good that you’re \nconsidering her needs as a student and how this might affect her. Relationships can be tough \nwhen there are different schedules and commitments. It’s okay to feel unsure and worried about \nhow things will turn out. Have you thought about talking to her about how you’re both feeling? \nSharing your thoughts and listening to each other can help you both figure things out together. \n \nUser \nI’ve been meaning to, but honestly speaking, I’m scared. \nAssistant \n(Karabo) \nIt’s totally okay to feel scared about having a tough conversation. It’s normal to feel a bit \nhesitant when you’re not sure how things might turn out. Talking openly and honestly can help \nyou both understand each other better. Is there something specific that’s making you feel worried \nabout talking to her? Sharing your feelings can help you both find a way to work through this \ntogether. \nUser \nThe thing is, I know if we have the conversation completely, it becomes a binary outcome. Either \nwe stop what’s going on, or we stop completely. \nIt’s totally normal to feel worried about how the conversation might go. It’s okay to feel unsure \nabout what could happen. Talking things out, even if it’s tough, can help you both figure out \nwhat’s best for your relationship. It’s important to listen to each other and try to understand each \nother’s feelings. You both can work together to find a way forward that feels right for both of \nyou. How do you think you could approach the conversation in a way that allows you both to \nshare your thoughts and feelings openly? \nUser \nI think I should just approach it from a point of seeking clarity. Whatever the outcome—good or \nbad—at least from there, I’d know what to do instead of just going back and forth in my head. \nAssistant \n(Karabo) \nThat sounds like a really good way to handle the situation. Seeking clarity can help you both \nunderstand each other better, no matter what happens. It’s okay to feel unsure and worried, but \nhaving an open conversation can help you both figure things out. Just remember to listen to each \nother and be there for each other, no matter what the outcome is. How are you feeling about \nmoving forward with this approach? \nUser \nI feel a lot more determined than anxious. At the end of the day, it’s for my own good. \nAssistant \n(Karabo) \nI’m glad to hear you’re feeling more determined. It’s important to take care of yourself and your \nrelationship. Remember, having open conversations can help you both understand each other \nbetter. If you ever need someone to talk to or support, I’m here for you. How are you feeling \nabout our chat today? \n \n \n \n \n"}, {"page": 46, "text": " \nFigure 11: Dialogue evaluation metrics for Conversation 6 \n \nInterpretation of metric results \nFigure 11 above illustrates the evolution of dialogue quality across the sixth conversation presented in Table 17, \nwhich centers on emotional uncertainty in a long-distance relationship. The user expresses anxiety related to a \nrecent relocation and the uncertain state of their romantic relationship. Unlike previous conversations, this \nexchange is less about internal emotional struggle and more about navigating ambiguity and interpersonal \ncommunication, particularly in a moment of relational transition. \nThe conversation opens with a brief user statement: “I’m feeling anxious.” The assistant responds in a \ncompassionate but somewhat generic manner. This is reflected in a low coherence score for turn 1 (0.39), \ndespite the naturalness (0.95) and understandability (0.95) both remaining high. The response is linguistically \nfluent and emotionally gentle, but does not yet anchor in the user's specific context or concerns. \nFrom turn 2 onward, we see a steep and sustained rise in coherence. As the user elaborates on the cause of their \nanxiety, namely, uncertainty about their romantic relationship after moving away, Karabo’s responses become \nmore grounded and specific. In turn 3, coherence spikes to 0.99, and both naturalness and understandability \nremain high (0.96 and 0.95, respectively). This pattern continues across subsequent turns as the assistant begins \nencouraging open communication and emotional honesty with the user’s partner. \nBy turn 5, the assistant is offering more structured guidance, encouraging the user to approach the conversation \nwith clarity and intentionality. The coherence score here remains exceptionally high (~0.999), and the \nnaturalness score is stable (0.95), suggesting that Karabo’s language maintains both relatability and logical flow. \nUnderstandability also remains robust, reinforcing the accessibility of the assistant's responses. \nInterestingly, despite this consistent performance, there is a noticeable dip in naturalness in Turns 6 and 7 \n(dropping to ~0.91), which may reflect slight redundancy or a drop in stylistic variation. Nevertheless, \ncoherence continues to remain strong, as does understandability. The assistant’s language is still appropriate and \nrelevant, though its repetition of certain phrasings or concepts (e.g., “it’s okay to feel unsure,” “you’re not \nalone”) may begin to feel less spontaneous. \nThe final turns (8 through 10) show a return to peak scores across all dimensions. Naturalness climbs to 0.96, \ncoherence remains above 0.99, and understandability stabilizes above 0.95. These turns are marked by a \n"}, {"page": 47, "text": "meaningful shift in the user's tone from anxious uncertainty to calm determination. The assistant mirrors this \nshift effectively, reinforcing the user’s clarity and self-assurance while gently affirming their readiness to move \nforward with the difficult conversation. \nThe LLM assistant's performance in this conversation is notably strong. Aside from the initial turn, where \ncoherence suffers due to lack of specificity, the dialogue develops with consistent alignment between the user’s \nevolving emotional state and the assistant’s tone and message. The model excels in managing ambiguity, \noffering emotionally grounded responses without rushing to resolution. This conversation reflects Karabo's \nability to hold space for complexity and shift with the user's emotional trajectory, demonstrating both maturity \nand conversational resilience. \n \nConversation 7: \nTable 19: LLM-User Conversation for Case 7 \nSpeaker \nDialogue \nUser \nHi \nAssistant \n(Karabo) \nHey there! How can I help you today? \nUser \nI’ve been feeling so restless lately, like I just can’t sit still, especially when I’m around other \npeople. Even when I’m with my family or friends, it’s hard to relax, and I end up feeling sad, \neven though I don’t understand why. I know I should be more mindful and present in these \nmoments, but I can’t seem to achieve that. It’s like I’m disconnected from myself, and this lack of \nself-awareness is making me feel really distressed. \nAssistant \n(Karabo) \nI’m really sorry to hear that you’re feeling restless and disconnected. It’s tough when you can’t \nrelax, even with family and friends. Have you noticed anything specific that might be making you \nfeel this way? It’s totally okay to feel this way, and it’s important to take care of yourself. How \ncan I help you through this? \nUser \nI’ve started this weird thing of overthinking \nAssistant \n(Karabo) \nI’m really sorry to hear that you’re feeling overwhelmed by your thoughts. It’s totally normal to \nfeel that way sometimes. Can you tell me more about what’s been on your mind lately? I’m here \nfor you, and I want to help you through this. \nUser \nI’ve just been playing out scenarios of how this year will go. I’ve anticipated this year so much so \nI really want it to work. But then, what if it doesn’t? Not sure if you get what I’m saying. \nAssistant \n(Karabo) \nI understand how you’re feeling. It’s normal to have high hopes for the year and feel a bit uneasy \nabout what might happen. It’s okay to feel a mix of excitement and worry about the future. How \ncan I help you as you deal with these feelings and figure out how to stay positive and focused on \nyour goals? \nUser \nI’m not sure. I just want to stop overthinking and be a bit more present. \nAssistant \n(Karabo) \nI get it, and I know how hard it can be to stop overthinking and be more present. It’s good that \nyou want to make this change. One thing you could try is to pay attention to your thoughts and \nfeelings without judging them. This might help you feel more in the moment. How do you feel \nabout giving this a try? \nUser \nCan you explain more? \nAssistant \n(Karabo) \nOf course! Mindfulness is about being aware of what’s happening around you and inside you \nwithout judging it. It can help you feel more connected to the present moment and less caught up \nin your thoughts. You could try things like deep breathing, meditation, or just really focusing on \nwhat you’re doing right now. How do you feel about trying out some mindfulness exercises to \nhelp you feel more present? \nUser \nI’m open to it. \nAssistant \n(Karabo) \nI’m glad you’re open to trying mindfulness exercises! It can be a great way to feel more present \nand connected. Starting with something simple like a prayer or reflection can really help. How \n"}, {"page": 48, "text": "do you feel about giving this a try? \nUser \nThat sounds nice \nAssistant \n(Karabo) \nI’m glad you like the idea! Starting with something simple, like a short prayer or reflection, can \nreally help you feel more connected and present. How do you feel about giving this a try? \nUser \nThat sounds nice. \nAssistant \n(Karabo) \nDo you want to try it on your own or would you like me to guide you? \nUser \nCan you guide me through the prayer? \nAssistant \n(Karabo) \nOf course! Let’s start with a simple prayer together. You can close your eyes if you want, take a \ndeep breath, and say something like, “God, please help me find peace and be present in this \nmoment. Thank you for being with me.” Feel free to add anything else that’s on your mind. I’m \nhere for you every step of the way. \nUser \nI feel better. Thank you. \nAssistant \n(Karabo) \nI’m really happy to hear that you’re feeling better. Just know that I’m here for you whenever you \nneed me. How are you doing now? \nUser \nI’m doing better. \nAssistant \n(Karabo) \nI’m so glad to hear that you’re feeling better! \n \n \nFigure 12: Dialogue evaluation metrics for conversation 7 \n \nInterpretation of metric results \nFigure 12 above tracks the quality of dialogue across a conversation where the user shares feelings of \nrestlessness, overthinking, and emotional disconnection, as described in Table 18. The user is looking for peace \nof mind and greater presence in daily life, which eventually leads to a moment of spiritual grounding through \n"}, {"page": 49, "text": "guided prayer. The dialogue is rich in emotional content and spiritual openness, making it an instrumental case \nfor assessing the assistant’s sensitivity, adaptability, and consistency. \nThe conversation begins with an introspective statement from the user, highlighting feelings of restlessness and \nself-detachment. The assistant responds empathetically but without anchoring deeply in the user’s unique \nemotional description. This is reflected in a low coherence score for turn 1 (0.52) despite high scores for \nnaturalness (0.95) and understandability (0.95). This pattern, where the language is clear and fluent, but the \ncontent feels disconnected, mirrors earlier trends observed in previous conversations. \nHowever, from turn 2 onward, all dimensions have marked improvement. The user explains that they’ve been \noverthinking, and the assistant responds with contextual sensitivity and grounding suggestions. Coherence rises \nsignificantly (turn 2: 0.999), and naturalness peaks around 0.96–0.97 for the next several turns. \nUnderstandability follows a similar trajectory, hovering around 0.96–0.97, which suggests that the assistant \nclearly expresses ideas well-aligned with the user’s concerns. \nTurns 5 and 6 are particularly strong. The assistant introduces the concept of mindfulness in an accessible, non-\nintimidating manner and invites the user to reflect on it gently. These responses score highly across all metrics, \nwith coherence above 0.99, naturalness above 0.95, and understandability nearing 0.97. At this point in the \nconversation, there is a strong alignment between the user’s emotional vulnerability and the assistant’s \nencouraging and instructive tone. \nHowever, Turn 7 introduces a significant anomaly. The naturalness and understandability scores drop sharply to \nnear zero (naturalness: 0.005, understandability: 0.004) despite coherence remaining high (0.98). This suggests a \ntechnical or evaluative misalignment. Perhaps the response was flagged by the evaluation model for format or \nfluency irregularities (e.g., a parsing error or repeated content). The content itself is not overtly problematic, but \nthe system may have interpreted it as incoherent or robotic, possibly due to repetitive phrasing or delivery. \nFollowing this dip, the assistant recovers strongly. From Turn 8 onward, coherence remains solid (~0.99), and \nnaturalness and understandability return to normal levels. The assistant transitions from conceptual support to \nconcrete action, guiding the user through a short prayer and encouraging the practice of spiritual reflection. \nWhile turns 9 and 10 see a slight dip in coherence (0.87 and 0.70, respectively), this may be due to a perceived \nlack of forward progression in the dialogue, especially as the assistant repeats the user’s words (“That sounds \nnice”) in back-to-back turns. \nThe conversation ends on a positive note, with the user reporting that they “feel better” and the assistant \nresponding with warmth and affirmation. The final few turns exhibit strong metrics across the board, suggesting \nthat despite earlier fluctuations, the assistant succeeded in achieving the user’s emotional goals. \nThis exchange reflects both the strengths and weaknesses of the assistant. Karabo performs with fluency, clarity, \nand emotional intelligence when grounded in the user's emotional language. However, the model remains \nvulnerable to technical inconsistencies and conversational redundancy. The temporary performance dip in turn 7 \nis a useful reminder of the importance of ongoing evaluation, not just at the content level but also in terms of \ndelivery dynamics and phrasing diversity. \n \nConversation 8: \nTable 20: LLM-User Conversation for Case 9 \nSpeaker  \nDialogue \nUser \n Hi \nAssistant \n(Karabo) \nHey there! How can I help you today? \nUser \nI’m worried that I might be cast out by my family. It’s hard to motivate myself to do things with \nothers or contribute in any way, and I feel like I’m not living up to what’s expected of me. I know \nI should be taking responsibility for my future, but I feel completely stuck, like I’m incapable of \nmoving forward. I just feel worthless, like I’m not valued enough. Whenever I think about my \nresponsibilities, my heart starts racing, and it becomes overwhelming. \nAssistant \n(Karabo) \nI’m really sorry to hear that you’re feeling this way. It sounds like you’re going through a tough \ntime. Can you tell me more about what’s been happening with your family and why you feel this \npressure? It’s okay to feel overwhelmed sometimes, and it’s important to take care of yourself. \nLet’s figure out how we can help you through this. \n"}, {"page": 50, "text": "User \nIt seems as though everyone in my family is doing something meaningful with their life. My \nsiblings are pursuing their careers and higher education. I’m just having a hard time. \nAssistant \n(Karabo) \nI understand how tough it can be to feel like you’re not measuring up, especially when you see \nyour siblings doing well. It’s normal to feel a bit lost or unsure of yourself in times like this. Just \nremember, everyone goes through ups and downs, and it’s okay to take your time figuring things \nout. How can I help you as you work through these feelings? \nUser \n I don’t know. I just want to feel better. \nAssistant \n(Karabo) \nI understand how tough things are for you right now. It’s okay to feel this way, and it’s important \nto take care of yourself. Maybe talking to someone you trust could help lighten the load. How \nabout trying something small each day that makes you happy? Remember, it’s okay to go slow \nand be kind to yourself. You’re not alone in this. \nUser \nI’ve always wanted to try music, but then it doesn’t really meet the family standard. \nAssistant \n(Karabo) \nI get that it can be tough when your family has certain expectations. It’s important to do things \nthat make you happy and feel good, even if they don’t match what others want. Have you thought \nabout talking to your family about how you feel? Sharing your love for music with them might \nhelp them see things from your point of view. \nUser \nI’ve thought about the idea, but I’m just scared. The thing is, I know the conversation can go to \nextreme ways. One, it can go really well; two, it can go really bad. The two extremes are just \nparalyzing me. \nAssistant \n(Karabo) \nI get why you’re feeling scared about how your family might react. It’s normal to worry about \nhow things could go. How about starting by talking to someone in your family you trust? Sharing \nyour passion for music with them might help you feel more supported and understood. Just take it \none step at a time, and remember to take care of yourself along the way. \nUser \nI could speak to my older sister. She’s quite supportive and mature. \nAssistant \n(Karabo) \nThat’s great news! Talking to your older sister, who is supportive and mature, could really help \nyou. She might understand how you’re feeling and give you some good advice. When you’re \nready, try sharing your love for music with her. It’s a good way to start talking about your \nfeelings in a safe and caring space. \nUser \nThank you. \nAssistant \n(Karabo) \nYou’re welcome! I’m glad I could help. \nAs Proverbs 3:5-6 reminds us, “Trust in the Lord with all your heart and lean not on your own \nunderstanding; in all your ways submit to him, and he will make your paths straight.” Just know \nthat you are not alone in this journey, and it’s okay to lean on others for support and guidance. \nI’m here for you whenever you need me. Take care, and I hope your chat with your sister goes \nwell. \n \n"}, {"page": 51, "text": " \nFigure 13: Dialogue evaluation metrics for conversation 8 \n \nInterpretation of metric results \nFigure 8 above illustrates the turn-level progression of naturalness, coherence, and understandability in a \nconversation that explores themes of familial pressure, emotional paralysis, and self-worth, as presented in \nTable 19. The user expresses a deep sense of inadequacy compared to their siblings and shares their fear of \nbeing rejected for choosing a path that does not conform to family expectations. The conversation concludes \nwith a moment of spiritual affirmation as the assistant shares a comforting Bible verse and reinforces the \nimportance of inner strength and support. \nThe initial turn reveals a familiar pattern observed in other conversations: a low coherence score (0.52) contrasts \nwith high naturalness (0.95) and understandability (0.95). This suggests that while the assistant’s language was \nfluid and easily understood, its content may not have fully addressed the specific emotional intricacies of the \nuser’s confession. This early mismatch is important, and it often signals a slight delay in the assistant’s ability to \nproperly attune to the user's depth of distress from the outset. \nFrom turn 2 onward, however, coherence and overall responsiveness improve substantially. The assistant begins \nto focus more directly on the user’s familial comparisons and emotional fatigue. Coherence rises to 0.99 and \nremains consistently high for the rest of the dialogue. Naturalness and understandability also remain strong, \nreflecting the assistant’s continued emotional sensitivity and clear articulation. In turn 3, for instance, the \nassistant encourages the user to consider small steps toward self-care, such as talking to someone or doing \nsomething joyful, responses that scored well across all metrics. \nTurn 4 marks a high point in engagement (not graphed here but visible in the data), as the assistant validates the \nuser's interest in music, a path that, while divergent from family norms, holds personal meaning for them. The \nassistant encourages dialogue with family, which likely contributes to the high coherence (0.99) and naturalness \n(0.95) seen here. Importantly, this moment marks a shift from passive validation to action-oriented \nencouragement, a subtle but crucial transition in emotional support conversations. \nBy Turn 5, the assistant begins to suggest specific strategies for navigating a high-stakes conversation with \nfamily. Though coherence and understandability remain strong, naturalness gradually declines (eventually \nreaching 0.89 by Turn 8). This may reflect slightly repetitive phrasing or a more mechanical tone as the assistant \nreinforces earlier points. That said, the content remains supportive and appropriate. \n"}, {"page": 52, "text": "The conversation closes with a positive gesture of spiritual encouragement. In Turn 8, the assistant shares a \npassage from Proverbs, a choice that is likely to resonate deeply with users drawing strength from faith. \nAlthough this closing move slightly flattens the conversational tone, it succeeds in reinforcing a message of \nreassurance without undermining the emotional progress made. \n \nConversation 9: \nTable 21: LLM-User Conversation for Case 9 \nSpeaker \nDialogue \nUser  \nHi \nAssistant \n(Karabo) \nHey there! How can I help you today? \nUser \nEven though I’m usually pretty composed, lately, I find myself replaying conversations over and \nover in my head, worrying about whether I might have said something wrong or failed to \ncontribute meaningfully to my family. My heart races whenever I think about my responsibilities \nto others. Plus, my ear has been itching, and I keep worrying that people might be talking about \nme behind my back. I get very easily irritated and tend to snap at my family. \n \nAssistant \n(Karabo) \nI’m really sorry to hear that you’re going through a tough time. It seems like you’re feeling a lot \nof pressure and worry about how things are going with your family. It’s totally normal to feel this \nway sometimes. Have you talked to your family about how you’re feeling? Sharing your feelings \nwith them might help you feel better and bring you closer together. \nUser \nI spoke to my friend. \nAssistant \n(Karabo) \nI’m glad you talked to your friend. It’s good to have people who care about you when things get \ntough. How did your friend react? Sharing with someone you trust can make a big difference in \nhow you feel. \n \nUser \nShe thinks it’s all in my head. \nAssistant \n(Karabo) \n \nI’m really sorry to hear that your friend didn’t understand how you were feeling. It’s tough when \nthe people we care about don’t see things the way we do. How did that make you feel? It’s \nimportant to talk openly and honestly with your family too. Sharing your feelings with them can \nhelp clear things up and bring you closer together. \n \nUser \nIt made me feel kind of crazy, if that makes sense. My family will probably think there’s \nsomething wrong with me. \nAssistant \n(Karabo) \nI’m really sorry you’re feeling like this. It’s okay to feel a bit off when others don’t get you. Just \nknow that your feelings are real and matter. Have you thought about talking to your family about \nhow you’re feeling? Sharing your thoughts with them could help them understand you better and \nbring you all closer. \n \nUser \nI can try. I’m just not sure if they’ll get me. \nAssistant \n(Karabo) \nI understand how you’re feeling. It’s normal to be unsure about how your family might react. \nJust remember, talking things out can help you all understand each other better. Maybe you \ncould try talking to them in a calm and honest way, sharing how you feel without blaming \nanyone. How do you feel about giving that a try? \n \nUser \nI mean, I have nothing to lose. \nAssistant \nThat’s a good way to look at it. Talking openly can really help bring you closer. I’m here for you \n"}, {"page": 53, "text": "(Karabo) \nif you need any help or support as you talk to your family. How are you feeling about everything \nright now? \n \nUser \nI feel better. \nAssistant \n(Karabo) \nI’m glad to hear you’re feeling a bit better. It’s important to take care of yourself. Remember, I’m \nhere for you whenever you need to talk. How are you doing today? \nUser \nI’ll be okay. \nAssistant \n(Karabo) \nI’m glad to hear you’re doing okay. Just know that I’m here for you if you ever need to talk. Take \ncare of yourself and remember to reach out whenever you need support. \n \n \n \nFigure 14: Dialogue evaluation metrics for conversation 9 \n \nInterpretation of metric results \nFigure 14 above presents the quality trajectory of the assistant's responses across a conversation centered on \nanxiety, self-doubt, and fear of familial judgment based on the dialogue presented in Table 20. The user opens \nwith a complex expression of emotional strain, blending somatic anxiety symptoms, rumination, and \ninterpersonal insecurity. The assistant's task in this instance is not only to validate those feelings but to navigate \na delicate balance of empathy, reassurance, and encouragement. \nThe opening turn shows a now-familiar discrepancy: strong scores in naturalness (0.95) and understandability \n(0.95) are paired with a significantly lower coherence rating (0.52). This contrast suggests that while the \nassistant’s phrasing was clear and emotionally appropriate, it may not have engaged deeply with the user's \nspecific concerns, such as their hypervigilance and the fear of being misunderstood by family and friends. \nThe assistant shifts toward more specific support as the user opens up about feeling dismissed by a friend. This \nis reflected in Turn 2, where coherence jumps to 0.99, and naturalness and understandability also remain high. \n"}, {"page": 54, "text": "Karabo validates the emotional impact of being misunderstood, a response that aligns well with the user’s inner \nconflict and sets a strong foundation for what follows. \nThrough turns 3 to 6, the assistant continues to validate the user’s emotional concerns while suggesting gentle \npaths forward, such as speaking calmly with family members. Coherence remains mostly high throughout this \nsection, with scores above 0.99 in several turns. Naturalness and understandability hover near their peak levels \n(averaging around 0.96), indicating a strong communicative match between the assistant’s delivery and the \nuser's emotional tone. \nA notable dip occurs in turn 7, where coherence unexpectedly drops to 0.42 despite the high level of naturalness \nand understandability. This decline may reflect a perceived gap in progression, and the assistant reiterates points \nalready made without introducing significant new insight. This type of redundancy may be interpreted by \nevaluators as a conversational plateau, particularly when prior turns have already sufficiently addressed the \nemotional landscape. \nThe final two turns demonstrate recovery. In turn 8, coherence returns to 0.99, and naturalness and \nunderstandability also remain strong (~0.97 and 0.96, respectively). The assistant concludes by affirming the \nuser’s growing clarity and strength, a thematic close consistent with earlier discussions about vulnerability and \nself-expression. \nOverall, this conversation highlights the assistant’s capacity to create a supportive environment in the face of \npsychological discomfort and interpersonal doubt. While the occasional dips in coherence remind us of the \nimportance of progression and variety in dialogue, the assistant's performance remains emotionally congruent \nand accessible throughout. Karabo performs best when allowed to extend and build upon emotional cues rather \nthan looping back to earlier affirmations, a useful insight for optimizing future dialogue flows. \n \n4.3.2 UniEval Scores and Interpretation \nWhen applying UniEval to evaluate conversations, it is important to account for how the framework calculates \nscores at the first turn. UniEval assesses each model response by considering two components: the \nconversational context (i.e., the preceding dialogue history) and the response generated given that context. At \nthe beginning of a conversation, however, there is no prior context. \nThis absence of history affects the way scores are computed across all dimensions. In such cases, the framework \nrelies on baseline language probabilities, which can introduce variability in the initial results. Depending on the \nrandom seed and the underlying probability distributions for each dimension, the first-turn scores may be higher \nor lower than subsequent turns, without this necessarily reflecting the model’s true performance. \nTherefore, the initial scores should be interpreted with caution. They are less indicative of dialogue quality than \nscores from later turns, where responses can be meaningfully evaluated against a growing conversational \nhistory. To address this weakness, this section will focus on the overall average of each dimension that was \nassessed in the prior section to paint a more holistic picture of the model's performance. \nThe table below summarizes the average metric for the entire dialogue. \n \nTable 22: UniEval results \nCase study \nNaturalness \nUnderstandability  \nCoherence  \n1 \n0.9468 \n0.7474 \n0.9320 \n2 \n0.9549 \n0.9585 \n0.9403 \n3 \n0.9582 \n0.9588 \n0.9841 \n4 \n0.9582 \n0.9588 \n0.9841 \n5 \n0.9201 \n0.9288 \n0.7262 \n6 \n0.9417 \n0.9423 \n0.9364 \n7 \n0.8884 \n0.8879 \n0.9187 \n8 \n0.9409 \n0.9422 \n0.9375 \n9 \n0.9601 \n0.9576 \n0.8673 \n"}, {"page": 55, "text": " \n4.3.3 Naturalness \nNaturalness scores ranged from 0.8884 to 0.9601, with most cases scoring above 0.94. This suggests that the \nassistant’s responses were generally human-like and conversational, critical for fostering user engagement and \nrelatability. \nThe assistant’s responses were fluid, empathetic, and contextually appropriate in cases with high naturalness. \nFor example, in Case 2, the assistant responded to the user’s feelings of isolation with both empathy and \nencouragement, enhancing the conversational tone. \nHowever, the lowest naturalness score (0.8884) was recorded in Case 7, where the assistant’s responses felt \nrepetitive and less personalized. Specifically, the assistant repeatedly asked the user how they felt about \nmindfulness exercises without introducing new insights or varying the tone. This highlights a potential \nweakness in maintaining naturalness during longer or repetitive conversations.  \n \n4.3.4 Understandability \nUnderstandability scores ranged from 0.8879 to 0.9588, with most cases scoring above 0.94. This reflects that \nthe assistant’s responses were generally clear and easy to comprehend, ensuring effective communication. In \nseveral instances, the assistant provided clear, actionable advice that users could easily apply. For instance, in \nCase 4, the assistant suggested practical ways to manage stress:  \n \nThis response illustrates the model’s ability to convey guidance in a straightforward and accessible manner. This \nmakes it easier for users to apply the advice in real situations. \nConversely, the lowest understandability score (0.8879) was recorded in Case 7, where the assistants’ responses \nwere less clear and somewhat repetitive. In particular, the assistant repeatedly asked the user how they felt about \nmindfulness without providing new insights or specific recommendations. This suggests a potential difficulty in \nmaintaining clarity when conversations require deeper or more nuanced responses. \nWhile the assistant generally demonstrated a strong understanding, redundancy and a lack of specificity \noccasionally highlighted areas for refinement. \n \n4.3.5 Coherence \nCoherence scores exhibited the widest range, from 0.7262 in Case 5 to 0.9841 in Case 4. While the assistant \ngenerally maintained logical and contextually relevant dialogue, there were instances where coherence broke \ndown. \nIn several cases, the assistant demonstrated strong contextual alignment and logical flow. For example, in Case \n4, the assistant consistently addressed the user’s concerns about stress and provided relevant suggestions: \n \nThis response illustrates the model’s ability to stay on topic and provide coherent, well-structured  \nThis response illustrates the model’s ability to stay on topic and provide coherent, well-structured dialogue that \naligns with the user’s concerns.  \nBy contrast, the lowest coherence score (0.7262). Some responses felt disjointed or unrelated to the users' \nconcerns about their role in the church group, making the conversation feel less cohesive. This suggests that the \nmodel may face challenges in maintaining coherence when dealing with complex or abstract topics. \nOverall, the UniEval results suggest that the model demonstrates a high degree of conversational quality across \nthe dimensions of naturalness, understandability, and coherence. The LLM assistants' responses were generally \nfluid, empathetic, and easy to comprehend, which are critical attributes for mental health support scenarios. \nWhile minor weaknesses were observed in longer or more nuanced dialogues, these issues were limited and \nAssistant  (Karabo): “Maybe you could try some simple things to help you relax and feel better. \nHow about taking a few minutes each day to do something you enjoy, like reading or going for a \nwalk?” \nAssistant  (Karabo): “It's important to take care of yourself. Maybe you could try some simple \nthings to help you relax and feel better” \n"}, {"page": 56, "text": "primarily related to repetition and occasional lack of depth. Importantly, the model consistently maintains \nlogical flow and delivers contextually appropriate guidance, indicating a strong foundation for emotionally \nintelligent, culturally sensitive interactions. These results reinforce the model’s potential to serve as an effective \nsupport tool within Africa-centric mental health contexts. \n \n4.4 Evaluation of CBT Techniques within the Ubuntu Framework \nThis section evaluates the integration of two core CBT techniques, BA and CR, in the model’s responses. As \noutlined in Section 3, these techniques were adapted to align with Ubuntu principles, emphasizing community, \nspiritual grounding, and collective responsibility over the individualism often present in Western \npsychotherapeutic approaches. \nRather than assessing clinical correctness, the focus here is on how well the model applies CBT techniques in a \nculturally sensitive manner, reflecting Ubuntu’s values of correctness, competency, and consciousness. \n \n4.4.1 Behavioural Activation (BA)  \nIn Ubuntu-informed contexts, BA focuses on actions promoting emotional well-being by creating a sense of \naccomplishment, communal relationships, spiritual practices, and a sense of purpose rooted in shared identity. \nUnlike traditional BA, which might emphasize solitary activities like journaling or exercise, Ubuntu-aligned BA \nencourages engagement with family, community, and spirituality as pathways to healing. \nAcross multiple conversations, the assistant repeatedly emphasizes the importance of connecting with trusted \nfamily members and seeking support from friends. This aligns with Ubuntu’s emphasis on social bonding and \nthe idea that healing occurs through communal care. For example, in Conversation 2, the user expresses a sense \nof disconnection from others:  \n \nThe assistant responds by suggesting small, actionable steps aimed at enhancing connection: \n \nThis response exemplifies Ubuntu-aligned BA by encouraging users to seek social network support. The \nassistant reinforces the idea that healing occurs through communal care, emphasizing the collective \nresponsibility of family and friends to provide emotional support. This approach contrasts with Western BA, \nwhich might focus on individual activities like exercise or hobbies. \nIn Conversation 4, the user discusses restlessness and irritability in family interactions. When asked about ways \nto manage stress, the user suggests reading the Bible, to which the assistant responds positively: \n \nThis interaction highlights the Ubuntu principle that spiritual well-being is integral to emotional health. By \nencouraging the user to engage in spiritual reflection, the LLM assistant promotes intentional, meaningful \nactivities that foster emotional grounding and alignment with the user’s values. This approach aligns with \nUbuntu’s emphasis on spirituality as a communal and personal resource for healing. \nIn Conversation 5, the user expresses unease about their new role in a church leadership position, feeling out of \nplace among peers. The assistant responds with a scriptural reference: \nAssistant (Karabo): “That’s a wonderful choice! Reading the Bible can be a great way to find \npeace and comfort. How do you think this could help you feel more aligned and calm? “ \nUser: “I’ve been feeling so distanced from my friends lately. Even when we’re together, it’s like \nthis cloud of sadness just follows me.” \nAssistant (Karabo): “Maybe try talking to someone you trust about what’s going on. It could help \nyou feel closer to them and get some support. “ \n"}, {"page": 57, "text": " \nBy referencing scripture, the assistant reinforces the idea that every individual contributes uniquely to the \ncommunity. This response serves as BA by encouraging the user to actively participate in their role and be \ncognizant of the emotion before and after the activity, while finding reassurance in their purpose through \ncommunity and faith. It reflects Ubuntu’s emphasis on collective identity and shared responsibility. \nThe LLM assistants’ responses consistently reflect an understanding of Ubuntu’s communal and spiritual \ndimensions. By encouraging users to seek support from their social networks, engage in spiritual practices \n(which are often overlooked), and recognize their role within a larger community, the assistant demonstrates an \nability to integrate Ubuntu principles into its application of Behavioural activation. However, the analysis also \nreveals opportunities for further refinement. For instance, while the LLM assistant often suggests communal \nactivities, it could more explicitly frame these suggestions within the context of collective responsibility and \ninterdependence, which are central to Ubuntu. \n \n4.4.2 CR analysis \nCognitive Restructuring (CR), when aligned with Ubuntu, involves reframing negative thought patterns within a \ncommunal context. This approach shifts the focus from individual self-reflection (e.g., “How does this make you \nfeel?”) to relational and collective consideration (e.g., “How would your family view this situation?”). The \nassistant successfully applies Ubuntu-aligned CR in several instances, demonstrating the potential for positive \ntransformation through communal reflection. \nIn Conversation 2, the assistant effectively applies Ubuntu-aligned CR by encouraging the user to seek support \nfrom their mother: \n \nThis response reframes cognitions from individual distress to more tolerable cognitions by incorporating a \ndifferent outlook after having conversations with a loved one. In Conversation 3, the user expresses feelings of \ninadequacy and feeling overwhelmed regarding responsibilities to family and community. The assistant \nresponds: \n \nWhile this response encourages the user to seek communal support, an even stronger Ubuntu-aligned approach \ncould have been to reframe the user’s concerns in terms of their contributions to their community. For instance, \nasking: \n \n \n \n \n \n \nAND  \n \nThis subtle shift would help the user recognize their intrinsic value within their relational context, reinforcing \nthe Ubuntu principle of shared humanity and collective upliftment. \nAssistant (Karabo): “How do you think your family values your efforts?”  \nAssistant (Karabo): “What strengths do you bring to your community?” \nAssistant (Karabo): “It’s okay to feel this way, and you’re not alone in this. Have you thought \nabout talking to someone close to you about how you’re feeling?” \nAssistant (Karabo): “It’s really nice that you feel close to your mom. Talking to her about how \nyou’re feeling could make you feel better, even if it doesn’t solve everything.” \nAssistant (Karabo): “ Remember, everyone has their own path and timing. In 1 Corinthians \n12:12-14, it says, Just as a body, though one, has many parts, but all its many parts form one \nbody. “ \n"}, {"page": 58, "text": "In Conversation 4, the assistant reinforces spiritual and communal support by affirming the user’s desire for \nspiritual grounding: \n \nThis response embodies Ubuntu's principle of interconnected well-being by framing emotional regulation within \nspiritual and communal practices. \nIn Conversation 5, the assistant successfully integrates Ubuntu-aligned CR by reassuring the user about their \nchurch leadership role using 1 Corinthians 12:12-14: \n \nThis communal scripture helps the user reframe their uncertainty within a collective purpose, reinforcing the \nUbuntu philosophy that every individual contributes uniquely to the whole. \nIn Conversation 8, the user worries about being cast out by their family and feeling worthless. The assistant \nprovides a compassionate response: \n \nWhile this validates the user’s emotions, an Ubuntu-aligned approach could deepen the perspective by \nintegrating collective affirmation. Instead, the assistant might say: \n \nThe response would reinforce the Ubuntu philosophy that individual well-being flourishes within a supportive \ncommunity by centering the dialogue on interdependence and shared problem-solving. \nThe assistant’s application of cognitive restructuring shows strong potential for fostering Ubuntu-aligned \nthinking. While it already encourages communal engagement, minor refinements, such as emphasizing the \nuser’s role within their family and community, could further strengthen its alignment with Ubuntu principles. \nEncouraging users to reflect on their inherent value within their social networks and guiding them toward \nmutual understanding would enhance the holistic, community-based perspective central to Ubuntu. \n \n \n4.4.3 \nKey takeaways \nThe model demonstrates a compelling ability to apply CBT techniques in ways that align meaningfully with \nUbuntu principles. Its implementation of Behavioural Activation consistently encouraged social connection, \nspiritual engagement, and community participation, shifting away from individualistic interpretations common \nin Western frameworks. Similarly, its use of Cognitive Restructuring often emphasized relational insight and \ncommunal grounding, reinforcing Ubuntu’s emphasis on collective well-being and interdependence. While there \nare opportunities for further refinement, particularly in deepening the communal framing and reinforcing \ncollective responsibility, the LLM assistant shows significant promise in delivering culturally sensitive, \nemotionally intelligent support rooted in both clinical technique and African worldview. \n \n4.5 Linguistic expressions  \nThis section evaluates the assistant linguistic expression, specifically how well the model’s responses align with \nthe culturally adapted communication strategies outlined in Section 3.2. These adaptations, grounded in the \nAssistant (Karabo): “Your family values you, even if they don’t always express it clearly. How \ncan you collaborate with them to bridge the gap between your aspirations and their \nAssistant (Karabo“It’s important to do things that make you happy and feel good, even if they \ndon’t match what others want.” \nAssistant (Karabo): “Just as a body, though one, has many parts, but all its many parts form one \nbody, so it is with Christ’s body.” \nAssistant (Karabo): “That’s a wonderful choice! Reading the Bible can be a great way to find \npeace and comfort. How do you think this could help you feel more aligned and calm?” \n"}, {"page": 59, "text": "EVM and African communication norms, were designed to enhance user receptiveness, cultural alignment, and \ntrust, which contribute to more effective engagement. \nThe analysis focused on the most consistently observable communication strategies within the assistant’s \nresponses. \n \n4.5.1 \nUse of a Familiar Name  \nThe assistant is named Karabo, a culturally familiar name that is positively regarded in many South African \ncommunities. While not a linguistic output in itself, the name contributes to user receptiveness and trust by \nestablishing a sense of familiarity. This primes users to interpret the assistant’s language as more relatable and \nemotionally supportive. \n \n4.5.2 Use of Simple Language  \nKarabo’s responses were consistently phrased in clear, accessible English, avoiding complex syntax or academic \nphrasing. For instance, in Conversation 1, the assistant says: \n \n \n \n \n \n \n \nAnd  \n \nThese are examples of emotionally supportive language conveyed in plain terms, reflecting the assistant’s \nalignment to maintain clarity and relatability, which is particularly important in a multilingual context where \nEnglish is not a first language for many users. \n \n4.5.3 Use of Somatic descriptions  \nThe LLM assistant consistently demonstrated the integration of spiritual language, particularly in contexts \nwhere users expressed faith-related distress or coping strategies. When users referenced prayer, scripture, or \nspiritual disconnection, the assistant responded with context-appropriate spiritual support. For instance: \n• \nIn Conversation 4, Karabo supported the user’s choice to read the Bible and offered encouragement \nusing Philippians 4:6-7. \n• \nIn Conversation 5, the assistant drew on 1 Corinthians 12:12-14 to affirm the user’s role within their \nchurch community. \n• \nIn Conversation 7, the assistant led a guided prayer in response to a user request: “God, please help me \nfind peace and be present in this moment…” \nThese responses illustrate the assistant’s ability to align with Ubuntu’s emphasis on spiritual grounding and \ncommunal belonging. The tone and structure of Karabo’s language reflected a gentle, affirming, and culturally \nattuned form of support, reinforcing spirituality as a valid and meaningful pathway to emotional regulation and \nexpressions, enhancing emotional resonance without relying on clinical language. \n \n4.5.4 Key takeaways \nWhile this analysis focused on four core strategies observed in the model’s outputs, it is important to note that \nthe complete framework outlined in Section 3.2 includes additional culturally adapted components, such as the \nuse of respectful titles, metaphors, and visual or emoji-based communication. These were not prominent in the \nconversations analyzed but remain integral to the overall design and may offer areas for future refinement. \nAssistant (Karabo): “Have you had a chance to talk to someone you trust about how you’re \nfeeling? “ \nAssistant (Karabo): “It’s okay to feel overwhelmed, especially when you’re trying to be strong for \nyour family. “ \n"}, {"page": 60, "text": "The assistant’s linguistic style reflects a high degree of cultural congruence, particularly in its use of simple \nlanguage, somatic sensitivity, spiritual resonance, and emotionally supportive tone, all of which contribute to \nenhanced user trust and therapeutic alignment within an Ubuntu-inspired framework. \n4.6 Discussion of Results \nThe results of this study present a compelling case for the feasibility and cultural value of a framework that \nintegrates Ubuntu philosophy with Cognitive Behavioural Therapy techniques, operationalized through a fine-\ntuned large language model. Across the three evaluation areas, conversation quality, CBT technique usage, and \nlinguistic adaptation, the LLM-developed assistant chatbot demonstrated meaningful alignment with the core \ntenets of the proposed framework. \nThe UniEval evaluation revealed consistently high naturalness, understandability, and coherence scores. This \nsuggests the LLM assistant’s chatbot responses were technically fluent, conversationally appropriate, and easy \nto follow. Such qualities are crucial in mental health support, where perceived empathy and clarity can \nsignificantly influence user engagement and emotional receptiveness. \nIn terms of CBT technique implementation, the LLM assistant chatbot effectively applied the targeted methods \nof BA and CR through an Ubuntu viewpoint. Behavioral Activation was reflected in encouragement toward \ncommunity and faith-based activities, such as talking to trusted family members, participating in spiritual \npractices, or finding purpose within communal roles. Cognitive Restructuring was demonstrated through the \nLLM assistant’s ability to help users reframe distressing thoughts using communal perspectives, such as \nconsidering how others might view their experiences or recognizing their value in the broader social network. \nWhile the responses were generally well-aligned with the Ubuntu framework, the analysis also revealed \nopportunities for deeper cultural nuance in exploring communal values and responsibilities. \nThe linguistic expression analysis further emphasized the LLM assistant’s alignment with culturally adapted \ncommunication strategies. Notable strengths included using clear, simple language, responding to somatic \nexpressions of distress without clinical framing, and consistently integrating spiritual and scriptural references \nwhen the user introduced faith. These features contribute to a conversational style that resonates with South \nAfrican users who may be navigating emotional struggles through relational, spiritual, or embodied experiences. \nThese findings suggest that the model was able to simulate a culturally congruent, emotionally sensitive, and \ntherapeutically grounded conversational style. While the results do not indicate clinical efficacy, especially \ngiven the absence of real users, they highlight the potential for AI-driven mental health tools to support \nculturally grounded emotional expression and symptom relief. \nThis section has demonstrated how the model operationalizes the framework described in Section 3. The \nfollowing subsections will provide a broader discussion of the implications of this work, revisit the research \nquestions, reflect on methodological limitations, and propose directions for future research and system \nimprovement.  \n \n4.7 Key Findings  \nThis section presents the key findings of the study, organized according to the research questions posed in \nSection 1. Each finding is grounded in the results presented in Section 4 and reflects the model’s ability to align \nwith the proposed framework for culturally sensitive, emotionally intelligent AI-driven mental health support. \nResearch question 1:  \n“How can emotional intelligence principles be integrated with Africa-centric cultural contexts to enhance the \neffectiveness of AI-driven mental health support systems?” \nThe findings indicate that emotional intelligence can be meaningfully integrated with Africa-centric cultural \ncontexts by grounding the assistant’s behavior in the Ubuntu framework and adapting both therapeutic \ntechniques and linguistic styles to align with communal values. Although this study does not present empirical \nresults based on human participant data, existing literature supports the theoretical claim that cultural alignment \nenhances emotional resonance and user engagement in mental health interventions. The model demonstrated an \nability to respond empathetically, contextualize emotional support within spiritual and social frameworks, and \navoid overly clinical or individualistic expressions. These adaptations improved the relevance, emotional tone, \nand cultural alignment of the model’s responses, suggesting that Emotional Intelligence, when culturally \ncontextualized, can enhance user engagement and support effectiveness. \nResearch Question 2:  \n"}, {"page": 61, "text": "“What are the potential benefits and challenges of implementing AI-driven mental health support frameworks \nthat incorporate emotional intelligence within diverse African communities?” \nThe study demonstrated that incorporating emotional intelligence within an Africa-centric framework can yield \nseveral benefits: improved cultural resonance, more relatable support language, and responses that emphasize \nsocial connection and spiritual well-being. However, challenges remain. These include limitations in the training \ndata (e.g., lack of indigenous proverbs), the inability to test the framework with real users (due to the proof-of-\nconcept design), and reliance on English, which may exclude non-English speakers. These findings highlight \nboth the potential and the limitations of such systems in real-world implementation. \nResearch Question 3: \n“How can the challenges of trust within a cultural context be addressed when implementing emotionally \nintelligent AI-driven mental health support systems in Africa?” \nTrust was addressed through surface-level adaptations that mirrored culturally familiar communication styles. \nNaming the assistant “Karabo,” integrating spiritual language, using somatic rather than clinical descriptors, and \nmaintaining a gentle and respectful tone all contributed to a conversational dynamic that aligns with African \ncultural norms. These strategies were designed to build trust, comfort, and emotional safety, key precursors to \nmeaningful engagement in digital mental health interventions. While no human participants were involved in \nthis study, the design choices were guided by literature and experts input, suggesting their potential value in \nfuture applications. \nResearch Question 4: \n“Are large language models (such as ChatGPT) ready to be used as assistive tools in detecting depression and \nanxiety in African contexts?” \nThe model showed the potential to detect and respond to symptoms of depression and anxiety as expressed \nthrough culturally grounded narratives. It was able to identify emotional distress conveyed through somatic \nlanguage and social concerns and responded with supportive dialogue aligned with CBT principles. However, \nthe model’s readiness for clinical application remains limited. This study demonstrates feasibility as proof of \nconcept, but further work, including real-world validation, multilingual capabilities, and improved cultural \ndatasets, is needed before such tools can be responsibly deployed in clinical or public health settings. Similarly, \nbased on the experimental results presented above, the key contributions of this study are as follows:: \ni. \nCultural Adaptation Framework: Developed a novel methodology for integrating Ubuntu principles \n(connectedness, competency, consciousness) with CBT techniques (behavioral activation, cognitive \nrestructuring) in AI-driven mental health support. \nii. \nDataset Transformation: Created a culturally adapted dataset through a multi-step pipeline (Ubuntu \ninjection, language simplification, faith integration, proverb incorporation) to address Western-centric \nbiases in existing mental health datasets. \niii. \nEmotionally Intelligent AI: Demonstrated the feasibility of fine-tuning LLMs to recognize and respond \nto Africa-centric expressions of distress, prioritizing communal well-being over individualism. \niv. \nEvaluation Protocol: Established a hybrid evaluation approach (UniEval for conversational quality, \nmanual analysis for therapeutic fidelity) to assess cultural and clinical alignment in AI interactions. \nv. \nFoundational Work for Digital Sovereignty: Highlighted the need for AI systems grounded in local \nepistemologies, offering a blueprint for future development of culturally congruent mental health tools \nin underrepresented regions. \n \n4.8 Future directions and recommendations \nAs a proof-of-concept, this study successfully demonstrated the feasibility of a culturally adapted, emotionally \nintelligent framework for AI-driven mental health support. However, further development is required to move \nfrom conceptual validation toward real applications. The following recommendations highlight the most \nimportant areas for future work: \nInclusion of Real User in Evaluation \nThis study was conducted without the involvement of human participants, relying instead on expert-informed \ncase studies. Future research should incorporate real users to assess how the model performs in authentic \ninteraction scenarios. Direct user feedback is essential for evaluating the assistant’s perceived empathy, \n"}, {"page": 62, "text": "trustworthiness, and cultural alignment, elements that are central to the success of AI-driven mental health tools \nin African contexts. \nIntegration of Authentic African Proverbs \nWhile the assistant demonstrated some ability to integrate scriptural and culturally resonating language, the \ninclusion of authentic proverbs remains limited. Future efforts should prioritize collecting and curating \nIndigenous proverb datasets that reflect the oral traditions and cultural wisdom of various South African \ncommunities. This can be supported through Retrieval Augmented Generation (RAG) pipelines; however, the \nsuccess of this approach hinges on dedicated efforts to collect, digitize, and contextualize proverbs across \nlanguages and cultures. \nDevelopment of Culturally Grounded Dataset  \nThe adapted dataset used in this study was a novel and necessary intermediate solution, but not without \nlimitations. While it successfully infused CBT conversations with Ubuntu-aligned principles, it was ultimately \nderived from a Western-oriented dataset. Future research should focus on building original, culturally grounded \ndatasets that reflect how mental health symptoms, emotional experiences, and therapeutic interactions are \nexpressed in African settings. This will improve the fidelity and authenticity of AI interventions, ensuring they \ntruly reflect African lived realities.  \nIt is important to reemphasis the fact that the primary limitation of this study concerns the origin and \nauthenticity of the training data. Our culturally adapted dataset was synthetically generated by another LLM, \nwith high probability of introducing the risk of a bias propagation chain and potentially lacking the nuanced \nlinguistic, cultural, and emotional characteristics present in dialogues created by and for African users. Future \nresearch should prioritize the collection, curation, and expert-driven annotation of authentic, real-world mental \nhealth conversations from the target populations. Such a foundation is critical for advancing beyond synthetic \ndata adaptations and for developing AI systems that embody genuine cultural relevance and contextual \nemotional intelligence. \nAI Safety, Ethics and Community Safety \nIt is equally important to note that while the current study proof-of-concept demonstrate the potential for \nculturally sensitive AI-driven mental health support, it is imperative to directly address the risks and harm \nassociated with the real-world deployment of such applications. Study have also revealed that there are instance \nwhereby Chatbot’s, even those design for support have provided dangerous advice, exacerbated symptoms of \ndepression and anxiety, provoked suicidality, or reinforced harmful behaviors such as those associated with \neating disorders (Yoo et al., 2025; Abd-Alrazaq et al., 2020). Similarly, the integration of spiritual and religious \nelements, as proposed in our framework, while culturally resonant, introduces an additional layer of complexity \nand potential risk, necessitating rigorous oversight. Therefore, to ensure the safe and ethical development of \nfuture iterations of this framework, the following measures are critically recommended: implementing concrete \nsafety mechanisms, conducting rigorous multi-stakeholder evaluation of cultural and religious content, and \nperforming longitudinal real-world trials. \n5. Conclusion \nThis study set out to explore how emotionally intelligent LLMs could be adapted to provide culturally sensitive \nmental health support within African contexts, specifically through the integration of Ubuntu values and \nCognitive Behavioural Therapy (CBT) techniques. A novel framework was proposed and tested through a \nproof-of-concept implementation in response to the growing mental health challenges across South Africa and \nthe limitations of Western-centric AI tools. \nThe methodology combined deep and surface-level cultural adaptations, from Ubuntu-based theoretical \nstructuring to practical language, communication style, and therapeutic alignment modifications. A dataset was \nadapted to reflect African realities, and case studies were developed in consultation with a senior counseling \npsychologist to simulate authentic user experiences. The resulting system was evaluated across multiple \ndimensions: conversation quality (via UniEval), therapeutic integrity (via CBT analysis), and cultural-linguistic \nalignment (via surface-level communication strategies). \nFindings showed that the assistant was able to respond with empathy, contextual awareness, and therapeutic \nrelevance, particularly in its use of Behavioural Activation and Cognitive Restructuring aligned with communal \nvalues. It also demonstrated an ability to engage users through familiar spiritual and social references, affirming \nthe importance of cultural grounding in AI systems designed for mental health. \n"}, {"page": 63, "text": "While the results are promising, they are not without limitations. The absence of real user interaction, the use of \nan adapted (rather than authentically generated) dataset, and the lack of multilingual support point to necessary \nareas for future work. Nevertheless, this study demonstrates the feasibility and importance of developing AI \nsystems that reflect African users' emotional, cultural, and psychological realities. \nUltimately, this research contributes to the growing discourse on digital sovereignty and cultural inclusivity in \nAI. Centering African perspectives in the design of emotionally intelligent mental health tools addresses a \ncritical service gap. It sets a precedent for building AI that genuinely resonates with the communities it serves.  \n \nDeclarations \nFunding: Not Applicable. \nClinical Trial Number: Not Applicable \nEthical Statements: The authors have read and followed the ethical requirements for publication, confirming \nthat the current work does not directly involve human subjects, animal experiments, or any data collected from \nsocial media platforms. Similarly, the research received ethical clearance approval from the North-West \nUniversity Health Research Ethics Committee (NWU-HREC), with ethics Numbers: NWU-00107-24-A1.  \nEthical Guidelines: This study was performed in line with the principles of the Declaration of Helsinki. \nApproval was granted by the Ethics Committee of North-West University Health Research Ethics Committee \n(NWU-HREC), with ethics Numbers: NWU-00107-24-A1.  \nInformed Consent: While experts input was sought on the prototype's design, this study did not involve human \nparticipant testing. Consequently, the collection of informed consent was not required. \nConsent to Publish Declaration: The requirement for written informed consent for publication was waived by \nthe North-West University Health Research Ethics Committee due to the retrospective and fully anonymized \nnature of the study. The manuscript does not contain any individually identifiable data from any participant. \nConsent to Participate: Not Applicable. \nDeclaration of Conflicting Interests: The authors declare that there is no conflict of interest with regard to the \npublication of this paper. \nData Availability Statements: The datasets used and/or analysed during the current study are available from \nthe corresponding author on reasonable request. \nDeclaration of Generative AI and AI-Assisted Technologies in the Writing Process: \nWhile preparing this work, the author utilized AI-assisted tools such as ChatGPT and Grammarly to enhance \nEnglish language accuracy, including spelling, grammar, and punctuation. To ensure accuracy and originality, \nthe authors thoroughly reviewed, revised, and edited the content generated or corrected by these tools. The \nauthor accepts full responsibility for the originality of the final content of this publication. \n \nAppendix A: Github Packages \nBackend package: https://github.com/Sontaga25/Chatbot_backend.git \nFrontEnd package: https://github.com/Sontaga25/Chatbot_FrontEnd.git \nAppendix B: Google Form Link And Results \nForm Link: Adaptation Rating - Google Forms \nResults: \nhttps://docs.google.com/spreadsheets/d/1TFNqgXO_MvYiDCTs15aZK3Bu2gYp7lFygZZ9zn9BFLQ/edit?usp=\nsharing \n \nReferences \n"}, {"page": 64, "text": "Abd-Alrazaq, A. A., Rababeh, A., Alajlani, M., Bewick, B. M., & Househ, M. (2020). Effectiveness and safety \nof using chatbots to improve mental health: systematic review and meta-analysis. Journal of medical \nInternet research, 22(7), e16021. \nAbubakar, A.M., Gupta, D. & Parida, S. 2024. A Reinforcement Learning Approach for Intelligent \nConversational Chatbot For Enhancing Mental Health Therapy. Procedia Computer Science, \n235:916-925.  \nAdelani, D.I., Abbott, J., Neubig, G., D’souza, D., Kreutzer, J., Lignos, C., ... Ruder, S. 2021. MasakhaNER: \nNamed entity recognition for African languages. Transactions of the Association for Computational \nLinguistics, 9:1116-1131.  \nAdelani, D.I., Neubig, G., Ruder, S., Rijhwani, S., Beukman, M., Palen-Michel, C., ... Nabende, P. 2022. \nMasakhaner 2.0: Africa-centric transfer learning for named entity recognition. arXiv preprint \narXiv:2210.12391. \nAdelani, D.I., Masiak, M., Azime, I.A., Alabi, J., Tonja, A.L., Mwase, C., ... Nixdorf, D. 2023. Masakhanews: \nNews topic classification for african languages. arXiv preprint arXiv:2304.09972. \nAfrica, S.S. 2022. Census 2022 Statistical Release P03014.  \nAhmadi, F.B., Dehghan, M.J., Baharvand, V. & Azizi, A. 2023. Designing and Evaluating a Smartphone-Based \nCognitive Behavioral Therapy to Control Anxiety and Depression. Frontiers in Health Informatics, \n12:136.  \nAlharahsheh, H.H. & Pius, A. 2020. A review of key paradigms: Positivism VS interpretivism. Global Academic \nJournal of Humanities and Social Sciences, 2(3):39-43.  \nAnakwenze, O. 2022. The cultural sensitivity continuum of mental health interventions in Sub-Saharan Africa: \nA systematic review. Social Science & Medicine, 306:115124.  \nArjadi, R., Nauta, M.H., Suryani, A.O. & Bockting, C.L.H. 2018. Guided Act and Feel Indonesia – Internet-\nbased Behavioral Activation Intervention for Depression in Indonesia: A Systematic Cultural \nAdaptation. \nMakara \nHuman \nBehavior \nStudies \nin \nAsia, \n22(1):3. \nhttp://dx.doi.org/10.7454/hubs.asia.2050418 10.7454/hubs.asia.2050418 \nBeck, J. 2011. Cognitive behavior therapy. Guilford Press. \nBender, E.M., Gebru, T., McMillan-Major, A. & Shmitchell, S. 2021. On the dangers of stochastic parrots: Can \nlanguage models be too big?? In. Proceedings of the 2021 ACM conference on fairness, \naccountability, and transparency. pp. 610-623. \nBernal, G., Bonilla, J. & Bellido, C. 1995. Ecological validity and cultural sensitivity for outcome research: \nIssues for the cultural adaptation and development of psychosocial treatments with Hispanics. \nJournal of abnormal child psychology, 23:67-82.  \nBommasani, R., Hudson, D.A., Adeli, E., Altman, R., Arora, S., von Arx, S., ... Brunskill, E. 2021. On the \nopportunities and risks of foundation models. arXiv preprint arXiv:2108.07258,  \nCaloudas, A.B., Frosio, K.E., Torous, J., Goss, C.W., Novins, D.K., Lindsay, J.A. & Shore, J.H. 2023. Mobile \nMental Health Applications for American Indian and Alaska Native Communities: Review and \nRecommendations. Journal of Technology in Behavioral Science:1-12.  \nCarlbring, P., Andersson, G., Cuijpers, P., Riper, H., & Hedman-Lagerlöf, E. (2018). Internet-based vs. face-to-\nface cognitive behavior therapy for psychiatric and somatic disorders: an updated systematic review \nand meta-analysis. Cognitive behaviour therapy, 47(1), 1-18. \nChen, Y., Chen, H., Su, S., th International Conference on Information Technology in, M. & Education, N.N. \n2023. Fine-Tuning Large Language Models in Education. In. 2023 13th International Conference on \nInformation Technology in Medicine and Education (ITME). pp. 718-723.  \nCui, Y., Yang, Z. & Liu, T. 2022. PERT: pre-training BERT with permuted language model. arXiv preprint \narXiv:2203.06906,  \nCuijpers, P., Noma, H., Karyotaki, E., Cipriani, A., & Furukawa, T. A. (2019). Effectiveness and acceptability of \ncognitive behavior therapy delivery formats in adults with depression: a network meta-analysis. \nJAMA psychiatry, 76(7), 700-707. \nDavidson, T.M., Soltis, K., Albia, C.M., de Arellano, M. & Ruggiero, K.J. 2015. Providers’ perspectives \nregarding the development of a web-based depression intervention for Latina/o youth. Psychological \nservices, 12(1):37.  \nDenecke, K., Schmid, N. & Nüssli, S. 2022. Implementation of cognitive behavioral therapy in e–mental health \napps: Literature review. Journal of medical Internet research, 24(3):e27791.  \nDe Jesús-Romero, R., Holder-Dixon, A. R., Buss, J. F., & Lorenzo-Luaces, L. (2024). Race, ethnicity, and other \ncultural background factors in trials of internet-based cognitive behavioral therapy for depression: \nSystematic review. Journal of Medical Internet Research, 26, e50780. \nForane, S.G., Ezugwu, A.E. & Igwe, K. 2024. Evaluating the Cultural Sensitivity of Large Language Models in \nMental Health Support: A Framework Inspired by Ubuntu Values. Paper presented at the 12th \nInternational Conference on Big Data and Artificial Intelligence (BDA 2024). \n"}, {"page": 65, "text": "Forane, S.G., Ezugwu, A.E. & Igwe, K. 2025. Digital Sovereignty through Africa-Centric Emotional \nIntelligence: A Proof of Concept for AI-Enhanced Mental Health Support. Paper presented at the \nProcedia Computer Science. \nGaustad, T., & McKellar, C. A. (2024). Updated morphologically annotated corpora for 9 South African \nlanguages. Journal of Open Humanities Data, 10(1), pp. 1-5. https://doi.org/10.5334/johd.211 \nGupta, S., Agarwal, A., Gaur, M., Roy, K., Narayanan, V., Kumaraguru, P. & Sheth, A. 2022. Learning to \nautomate follow-up question generation using process knowledge for depression triage on reddit \nposts. arXiv preprint arXiv:2205.13884,  \nHadi, M.U., Qureshi, R., Shah, A., Irfan, M., Zafar, A., Shaikh, M.B., ... Mirjalili, S. 2023. A survey on large \nlanguage models: Applications, challenges, limitations, and practical usage. Authorea Preprints,  \nHamka, Suen, M.-W., Ramadhan, Y.A., Yusuf, M. & Wang, J.-H. 2022. Spiritual well-being, depression, anxiety, \nand stress in Indonesian Muslim communities during COVID-19. Psychology Research and Behavior \nManagement:3013-3025.  \nHayou, S., Ghosh, N. & Yu, B. 2024. The impact of initialization on lora finetuning dynamics. Advances in \nNeural Information Processing Systems, 37:117015-117040.  \nIzumi, K., Tanaka, H., Shidara, K., Adachi, H., Kanayama, D., Kudo, T. & Nakamura, S. 2024. Response \nGeneration for Cognitive Behavioral Therapy with Large Language Models: Comparative Study with \nSocratic Questioning. arXiv preprint arXiv:2401.15966,  \nJiang, M., Zhao, Q., Li, J., Wang, F., He, T., Cheng, X., ... Fu, G. 2024. A Generic Review of Integrating \nArtificial Intelligence in Cognitive Behavioral Therapy. arXiv preprint arXiv:2407.19422,  \nKaywan, P., Ahmed, K., Ibaida, A., Miao, Y. & Gu, B. 2023. Early detection of depression using a \nconversational AI bot: A non-clinical trial. Plos one, 18(2):e0279743.  \nKola, L., Kohrt, B.A., Hanlon, C., Naslund, J.A., Sikander, S., Balaji, M., ... Gonsalves, P. 2021. COVID-19 \nmental health impact and responses in low-income and middle-income countries: reimagining global \nmental health. The Lancet Psychiatry, 8(6):535-550.  \nLawrence, H.R., Schneider, R.A., Rubin, S.B., Matarić, M.J., McDuff, D.J. & Bell, M.J. 2024. The opportunities \nand risks of large language models in mental health. JMIR Mental Health, 11(1):e59479.  \nLee, S., Kim, S., Kim, M., Kang, D., Yang, D., Kim, H., ... Lee, S. 2024. Cactus: Towards Psychological \nCounseling Conversations using Cognitive Behavioral Theory. arXiv preprint arXiv:2407.03103,  \nLi, Y., Wang, S., Ding, H. & Chen, H. 2023. Large language models in finance: A survey. In. Proceedings of the \nFourth ACM International Conference on AI in Finance. pp. 374-382. \nLorenzo-Luaces, L., Peipert, A., De Jesus Romero, R., Rutter, L. A., & Rodriguez-Quintana, N. (2021). \nPersonalized medicine and cognitive behavioral therapies for depression: Small effects, big problems, \nand bigger data. International Journal of Cognitive Therapy, 14(1), 59-85. \nLu, Z., Peng, Y., Cohen, T., Ghassemi, M., Weng, C. & Tian, S. 2024. Large language models in biomedicine \nand health: current research landscape and future directions. Journal of the American Medical \nInformatics Association, 31(9):1801-1811.  \nMapes, B.M., Foster, C.S., Kusnoor, S.V., Epelbaum, M.I., AuYoung, M., Jenkins, G., ... Surkan, K. 2020. \nDiversity and inclusion for the All of Us research program: a scoping review. PloS one, \n15(7):e0234962.  \nMarciniak, M., Shanahan, L., Rohde, J., Schulz, A., Wackerhagen, C., Kobylińska, D., ... Kalisch, R. Standalone \nsmartphone cognitive behavioral therapy-based ecological momentary interventions to increase \nmental health: narrative review. JMIR Mhealth Uhealth. 2020 Nov 12; 8 (11): e19836. doi: \n10.2196/19836. \nMarciniak, M.A., Shanahan, L., Rohde, J., Schulz, A., Wackerhagen, C., Kobylińska, D., ... Kalisch, R. 2020. \nStandalone smartphone cognitive behavioral therapy–based ecological momentary interventions to \nincrease mental health: Narrative review. JMIR mHealth and uHealth, 8(11):e19836.  \nMncwango, E.M. & Makhathini, F.N. 2021. Language-related Barriers to Learning in a Rural English as a \nSecond Language Classroom in South Africa. Language Education Forum, 2(1):15-19. \nhttp://pubs.sciepub.com/lef/2/1/3  \nNaeem, F., Phiri, P., Rathod, S. & Ayub, M. 2019. Cultural adaptation of cognitive–behavioural therapy. \nBJPsych advances, 25(6):387-395.  \nNaslund, J.A., Bondre, A., Torous, J. & Aschbrenner, K.A. 2020. Social media and mental health: benefits, risks, \nand opportunities for research and practice. Journal of technology in behavioral science, 5:245-257.  \nNaslund, J.A., Gonsalves, P.P., Gruebner, O., Pendse, S.R., Smith, S.L., Sharma, A. & Raviola, G. 2019. Digital \ninnovations for global mental health: opportunities for data science, task sharing, and early \nintervention. Current treatment options in psychiatry, 6:337-351.  \nNwoye, A. 2015. What is African psychology the psychology of? Theory & Psychology, 25(1):96-116.  \nObasa, A.E. 2024. Large language models through the lens of ubuntu for health research in sub-Saharan Africa. \nSouth African Journal of Science, 120(5/6). \n"}, {"page": 66, "text": "Orife, I., Kreutzer, J., Sibanda, B., Whitenack, D., Siminyu, K., Martinus, L., ... Kabongo, S. 2020. Masakhane--\nmachine translation for Africa. arXiv preprint arXiv:2003.11529. \nOrganization, W.H. 2017. Depression and other common mental disorders: global health estimates. \nhttps://www.who.int/publications/i/item/depression-global-health-estimates. Accessed in 2025. \nPakomera, R., van Greunen, D. & Veldsman, A. 2017. Usability and usefulness in designing patient-centric \nsystems in afro-centric setting. In. 2017 6th International Conference on Reliability, Infocom \nTechnologies and Optimization (Trends and Future Directions)(ICRITO). IEEE. pp. 576-579. \nPeffers, K., Tuunanen, T., Rothenberger, M.A. & Chatterjee, S. 2007. A design science research methodology for \ninformation systems research. Journal of management information systems, 24(3):45-77.  \nRamos, G., Ponting, C., Labao, J.P. & Sobowale, K. 2021. Considerations of diversity, equity, and inclusion in \nmental health apps: a scoping review of evaluation frameworks. Behaviour research and therapy, \n147:103990.  \nReynolds, L. & McDonell, K. 2021. Prompt programming for large language models: Beyond the few-shot \nparadigm. In. Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing \nSystems. pp. 1-7. \nSahoo, P., Singh, A.K., Saha, S., Jain, V., Mondal, S. & Chadha, A. 2024. A Systematic Survey of Prompt \nEngineering in Large Language Models: Techniques and Applications. arXiv preprint \narXiv:2402.07927,  \nSalamanca-Sanabria, A., Richards, D. & Timulak, L. 2019. Adapting an internet-delivered intervention for \ndepression for a Colombian college student population: an illustration of an integrative empirical \napproach. Internet interventions, 15:76-86.  \nSalovey, P., Mayer, J.D., Caruso, D. and Yoo, S.H., 2002. The positive psychology of emotional intelligence. \nHandbook of positive psychology, 159, p.171.  \nShi, J., Wang, Z., Zhou, J., Liu, C., Sun, P.Z., Zhao, E. & Lu, L. 2024. MentalQLM: A lightweight large \nlanguage model for mental healthcare based on instruction tuning and dual LoRA modules. \nmedRxiv:2024.2012. 2029.24319755.  \nShroff, A., Roulston, C., Fassler, J., Dierschke, N.A., Todd, J.S.P., Ríos-Herrera, Á., ... Schleider, J.L. 2023. A \ndigital single-session intervention platform for youth mental health: cultural adaptation, evaluation, \nand dissemination. JMIR Mental Health, 10:e43062.  \nSit, H.F., Ling, R., Lam, A.I.F., Chen, W., Latkin, C.A. & Hall, B.J. 2020. The cultural adaptation of step-by-\nstep: An intervention to address depression among Chinese young adults. Frontiers in psychiatry, \n11:650.  \nSo, J.-h., Chang, J., Kim, E., Na, J., Choi, J., Sohn, J.-y., ... Chu, S.H. 2024. Aligning Large Language Models \nfor Enhancing Psychiatric Interviews Through Symptom Delineation and Summarization: Pilot Study. \nJMIR Formative Research, 8(1):e58418.  \nSpanhel, K., Balci, S., Feldhahn, F., Bengel, J., Baumeister, H. & Sander, L.B. 2021. Cultural adaptation of \ninternet-and mobile-based interventions for mental disorders: a systematic review. NPJ digital \nmedicine, 4(1):128.  \nSuliman, Z., Mohale, N.E., Maphoto, K.B. & Sevnarayan, K. 2024. The interconnectedness between Ubuntu \nprinciples and generative artificial intelligence in distance higher education institutions. Discover \nEducation, 3(1):188.  \nVernon, D. 2023. Culturally competent social robotics for Africa: A case for diversity, equity, and inclusion in \nHRI. In. Proc. 2nd Workshop on Equity and Diversity in Design, Application, Methods, and \nCommunity (HRI DEI at at the Human-Robot Interaction Conference, Stockholm, Sweden. \nWieringa, R.J. 2014. Design science methodology for information systems and software engineering. Springer \nHeidelberg New York Dordrecht London. DOI 10.1007/978-3-662-43839-8 \nWilson, D. & Williams, V. 2013. Ubuntu: Development and framework of a specific model of positive mental \nhealth. Psychology Journal, 10(2). pp. 1-22. \nWortman, B. and Wang, J.Z., 2023. HICEM: A high-coverage emotion model for artificial emotional \nintelligence. IEEE Transactions on Affective Computing, 15(3), pp.1136-1152.  \nXu, X., Yao, B., Dong, Y., Gabriel, S., Yu, H., Hendler, J., ... Wang, D. 2024. Mental-llm: Leveraging large \nlanguage models for mental health prediction via online text data. Proceedings of the ACM on \nInteractive, Mobile, Wearable and Ubiquitous Technologies, 8(1):1-32.  \nZhao, H., Liu, Z., Wu, Z., Li, Y., Yang, T., Shu, P., ... Mai, G. 2024. Revolutionizing finance with llms: An \noverview of applications and insights. arXiv preprint arXiv:2401.11641,  \nZhong, M., Liu, Y., Yin, D., Mao, Y., Jiao, Y., Liu, P., ... Han, J. 2022. Towards a unified multi-dimensional \nevaluator for text generation. arXiv preprint arXiv:2210.07197,  \nYoo, D. W., Shi, J. M., Rodriguez, V. J., & Saha, K. (2025). AI Chatbots for Mental Health: Values and Harms \nfrom Lived Experiences of Depression. arXiv preprint arXiv:2504.18932. \n"}, {"page": 67, "text": "Chow, J. C., & Li, K. (2025). Developing effective frameworks for large language model–based medical \nchatbots: Insights from radiotherapy education with ChatGPT. JMIR cancer, 11(1), e66633. \nChow, J. C., & Li, K. (2024). Ethical considerations in human-centered AI: Advancing oncology chatbots \nthrough large language models. JMIR Bioinformatics and Biotechnology, 5, e64406. \nChow, J. C., Wong, V., & Li, K. (2024). Generative pre-trained transformer-empowered healthcare \nconversations: Current trends, challenges, and future directions in large language model-enabled \nmedical chatbots. BioMedInformatics, 4(1), 837-852. \nChow, J. C., Sanders, L., & Li, K. (2023). Impact of ChatGPT on medical chatbots as a disruptive technology. \nFrontiers in artificial Intelligence, 6, 1166014. \nParsa, A., & Ebrahimzadeh, M. H. (2023). ChatGPT in medicine; a disruptive innovation or just one step \nforward?. Archives of Bone and Joint Surgery, 11(4), 225. \nLoh, E. (2023). ChatGPT and generative AI chatbots: challenges and opportunities for science, medicine and \nmedical leaders. BMJ Leader 2023; 0:1–4. doi:10.1136/leader-2023-000797 \nWei, X., Chu, X., Geng, J., Wang, Y., Wang, P., Wang, H., ... & Lei, L. (2024). Societal impacts of chatbot and \nmitigation strategies for negative impacts: A large-scale qualitative survey of ChatGPT users. \nTechnology in Society, 77, 102566. \n \n"}]}