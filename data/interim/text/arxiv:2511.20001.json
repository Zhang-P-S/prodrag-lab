{"doc_id": "arxiv:2511.20001", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2511.20001.pdf", "meta": {"doc_id": "arxiv:2511.20001", "source": "arxiv", "arxiv_id": "2511.20001", "title": "A Machine Learning Approach for Detection of Mental Health Conditions and Cyberbullying from Social Media", "authors": ["Edward Ajayi", "Martha Kachweka", "Mawuli Deku", "Emily Aiken"], "published": "2025-11-25T07:12:09Z", "updated": "2026-01-23T17:53:12Z", "summary": "Mental health challenges and cyberbullying are increasingly prevalent in digital spaces, necessitating scalable and interpretable detection systems. This paper introduces a unified multiclass classification framework for detecting ten distinct mental health and cyberbullying categories from social media data. We curate datasets from Twitter and Reddit, implementing a rigorous \"split-then-balance\" pipeline to train on balanced data while evaluating on a realistic, held-out imbalanced test set. We conducted a comprehensive evaluation comparing traditional lexical models, hybrid approaches, and several end-to-end fine-tuned transformers. Our results demonstrate that end-to-end fine-tuning is critical for performance, with the domain-adapted MentalBERT emerging as the top model, achieving an accuracy of 0.92 and a Macro F1 score of 0.76, surpassing both its generic counterpart and a zero-shot LLM baseline. Grounded in a comprehensive ethical analysis, we frame the system as a human-in-the-loop screening aid, not a diagnostic tool. To support this, we introduce a hybrid SHAPLLM explainability framework and present a prototype dashboard (\"Social Media Screener\") designed to integrate model predictions and their explanations into a practical workflow for moderators. Our work provides a robust baseline, highlighting future needs for multi-label, clinically-validated datasets at the critical intersection of online safety and computational mental health.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2511.20001v3", "url_pdf": "https://arxiv.org/pdf/2511.20001.pdf", "meta_path": "data/raw/arxiv/meta/2511.20001.json", "sha256": "64147aaacacbdb8894f7533fb06dab27b0f48408db3a1d5194288deb61a72aa7", "status": "ok", "fetched_at": "2026-02-18T02:26:22.820070+00:00"}, "pages": [{"page": 1, "text": "A MACHINE LEARNING APPROACH FOR DETECTION OF MENTAL\nHEALTH CONDITIONS AND CYBERBULLYING FROM SOCIAL\nMEDIA ∗\nEdward Ajayi, Martha Kachweka, Mawuli Deku, Emily Aiken\nCarnegie Mellon University Africa\nKigali, Rwanda\n{eaajayi, mkachwek, mdeku, eaiken}@andrew.cmu.edu\nABSTRACT\nMental health challenges and cyberbullying are increasingly prevalent in digital spaces, necessitating\nscalable and interpretable detection systems. This paper introduces a unified multiclass classification\nframework for detecting ten distinct mental health and cyberbullying categories from social media\ndata. We curate datasets from Twitter and Reddit, implementing a rigorous ’split-then-balance’\npipeline to train on balanced data while evaluating on a realistic, held-out imbalanced test set. We\nconduct a comprehensive evaluation comparing traditional lexical models, hybrid approaches, and\nseveral end-to-end fine-tuned transformers. Our results demonstrate that end-to-end fine-tuning is\ncritical for performance, with the domain-adapted MentalBERT emerging as the top model, achieving\nan accuracy of 0.92 and a Macro F1 score of 0.76, surpassing both its generic counterpart and a\nzero-shot LLM baseline. Grounded in a comprehensive ethical analysis, we frame the system as a\nhuman-in-the-loop screening aid, not a diagnostic tool. To support this, we introduce a hybrid SHAP-\nLLM explainability framework and present a prototype dashboard (\"Social Media Screener\") designed\nto integrate model predictions and their explanations into a practical workflow for moderators. Our\nwork provides a robust baseline, highlighting future needs for multi-label, clinically-validated datasets\nat the critical intersection of online safety and computational mental health.\nKeywords Natural language processing · Mental health · Cyberbullying · Machine Learning\n1\nIntroduction\nMental health disorders are a growing global concern, affecting one in eight people worldwide [1]. Common mental\nhealth conditions like anxiety, depression, bipolar disorder, and stress-related illnesses contribute substantially to the\nglobal burden of disease. Despite the availability of effective prevention and treatment options, access to mental health\ncare remains a major challenge, exacerbated by stigma, discrimination, and inadequate resources [1].\nSocial media platforms contribute to and mediate mental health conditions in an increasingly digital world. While\nsocial media sites have been shown to increase connection in some settings [2], they have also amplified mental health\nrisks by exposing users to cyberbullying [3], emotionally charged content [4], and negative sentiment [5]. Social media\nalso provides a valuable opportunity for scalable screening and content moderation, with the possibility of automated\ndetection of signs of distress through natural language processing (NLP) techniques [6]. While existing research has\nmade substantial progress in predicting mental health conditions from social media posts, most studies focus on binary\nclassification (e.g., classifying posts as depression or not depression) [7], overlooking the interconnected nature of\nmental health conditions [1]. Moreover, existing research often focuses on narrow subsets of harmful content, failing to\naddress the diverse range of mental health expressions and cyberbullying behaviors encountered online.\n∗Oral Presentation at the AAAI-26 Bridge Program on AI for Medicine and Healthcare (AIMedHealth). To appear in\nProceedings of Machine Learning Research (PMLR).\narXiv:2511.20001v3  [cs.CL]  23 Jan 2026\n"}, {"page": 2, "text": "Oral Presentation at AAAI AIMedHealth Bridge 2026 (To appear in PMLR)\nThis study aims to fill this gap by developing and evaluating a unified multiclass classification framework for detecting\nten distinct categories of mental health conditions and cyberbullying from public social media data. We aggregate\ndatasets from Reddit and Twitter, comparing lexical (TF-IDF) and contextual (e.g., BERT) modeling approaches. We\nexplicitly frame this framework not as a diagnostic tool, but as a human-in-the-loop screening aid intended for trained\nmoderators. To support this practical integration, we introduce a hybrid SHAP-LLM explainability system and present\na prototype dashboard (\"Social Media Screener\") to visualize how our model’s outputs can be safely and transparently\noperationalized.\nWe propose a dual-purpose application: (1) as a content flagging tool for acute-risk classes like ’Suicide’ that require\nurgent human review, and (2) as a component in longitudinal analysis tools to help practitioners identify linguistic\npatterns over time for nuanced conditions like ’Bipolar Disorder’. This human-in-the-loop framework serves as a\ndirect parallel to clinical support systems, where similar AI tools can assist therapists in reviewing high volumes of\npatient-generated data. Our evaluation, conducted on a held-out, imbalanced test set, demonstrates the effectiveness\nof end-to-end fine-tuning, with the domain-adapted MentalBERT [8] showing clear superiority. By integrating\nthese technical findings with a concrete and ethically-grounded application, this study provides a comprehensive\nmethodological baseline. Our analysis also highlights the critical limitations of existing public, weakly-labeled, single-\nlabel datasets, demonstrating the urgent need for future work in developing multi-label benchmarks sourced from\nconsented, clinically-assessed cohorts for computational mental health.\n2\nRelated Work\n2.1\nMental Health Detection from Social Media\nA large and growing body of research leverages natural language processing (NLP) to identify mental health conditions\nfrom social media platforms such as Twitter and Reddit [4, 6, 20–22]. Early studies often focused on binary classification\ntasks distinguishing between depressed and non-depressed users [7]. More recent papers have incorporated deep learning\nto capture nuanced emotional patterns [12]. Transformer-based architectures, particularly BERT [9], have become the\nde facto standard for text classification due to their capacity to capture contextual dependencies and semantics at a\nfine-grained level. [8] introduced MentalBERT and MentalRoBERTa, domain-adapted versions of BERT fine-tuned on\nReddit mental health forums, showing notable improvements in classifying user mental health status. However, most of\nthese studies rely on label sets with limited numbers of classes, failing to capture the complex and interrelated nature of\nmental health conditions in the real world.\n2.2\nCyberbullying Detection\nCyberbullying detection on social media has also received considerable attention from researchers in the recent years\n[11, 14]. Most relevantly to our work, [13] developed SOSNet, a domain-specific neural network architecture for\ndistinguishing types of cyberbullying such as those based on gender, ethnicity, and religion. We build on the dataset\ncurated by [13] in this paper.\n3\nData and methods\n3.1\nData\nThis study aggregates a number of datasets from Twitter and Reddit to analyze and classify various mental health\nconditions, including suicidal ideation, personality disorders, stress, anxiety, and bipolar disorder. We also work with\ndata on cyberbullying data from Twitter. All datasets were sourced from Kaggle.\n3.1.1\nMental health data\nThe mental health data are sourced from various social media platforms, primarily Twitter and specific subreddits\ndedicated to mental health conversations [15, 16]. The dataset is categorized into four conditions: anxiety, stress, bipolar\ndisorder, and personality disorder, totaling 53,043 posts. The anxiety data was gathered from Facebook and Twitter\nand subsequently manually annotated by four undergraduate English-speaking students. The data for bipolar disorder\nand personality disorder were collected from their respective subreddits. Similarly, the stress data was sourced from\nrelevant subreddits; however, the specific annotation guidelines for this subset were not detailed by the original authors.\n2\n"}, {"page": 3, "text": "Oral Presentation at AAAI AIMedHealth Bridge 2026 (To appear in PMLR)\n3.1.2\nCyberbullying data\nThe cyberbullying dataset was adopted from [13], who developed a model to detect cyberbullying based on age,\ngender, ethnicity, and religion on Twitter. The dataset labels each post as one of five types of cyberbullying (gender,\nreligion, ethnicity, age, other) or as not containing cyberbullying content. The fine-grained labels were initially created\nthrough a manual annotation process on a subset of the data. To expand the dataset, the authors [13] then employed a\nsemi-supervised method, Dynamic Query Expansion (DQE), to increase the number of samples for each class. The\nfinal curated dataset contains a total of 47,692 posts.\n3.1.3\nSuicide and depression detection data\nOur third and final dataset focuses on detecting depression and suicidal ideation, with data collected from the Suicide-\nWatch and depression subreddits [17]. The dataset also includes posts from the teenagers subreddit for non-suicidal and\nnon-depression content. The dataset includes 232,074 posts in total, each labeled as suicidal or non-suicidal content.\n3.1.4\nData cleaning\nAll text entries were standardized to lowercase strings. Unwanted elements such as URLs, user mentions, and non-\nalphanumeric characters were removed using regular expressions, and extraneous whitespace was stripped to ensure\ndata uniformity.\n3.1.5\nDataset Curation, Splitting, and Balancing\nTo ensure a robust evaluation and prevent data leakage, we implemented a strict \"split-then-balance\" pipeline. First, all\nten datasets were merged into a master dataset of 274,150 posts. We then performed post-level deduplication to prevent\nidentical posts from appearing in both training and test sets. After deduplication, the dataset was split into a training\npool (80%) and a held-out test pool (20%) using a stratified split to preserve the original, imbalanced class distribution\nin both pools. The final test set was sampled from the held-out test pool and retained its original, highly imbalanced\ndistribution to reflect real-world data.\nThe final training set was constructed exclusively from the 80% training pool using a multi-step balancing process.\nThis process, summarized in Table 1, involved downsampling (DS) high-resource classes (e.g., Non-Suicide, Suicide)\nand applying deduplication (DD) and EDA-based oversampling (a technique that generates synthetic text by applying\none of four random operations: synonym replacement, random insertion, random swap, or random deletion)[19] to\nlow-resource classes (e.g., Personality Disorder, Stress). Table 1 shows the class distribution after each step and the\nfinal test set.\n3.2\nData Label Verification\nTo evaluate the reliability of the dataset’s weak labels, we performed a manual annotation study on a randomly selected\nsubset of 300 posts (1% of the dataset), balanced across all ten classes. Two authors independently annotated the posts\nwhile blinded to the original labels. Inter-annotator agreement achieved a Cohen’s Kappa of κ = 0.76, indicating\nsubstantial consistency between annotators. We further compared each annotator’s labels with the original dataset\nlabels, yielding Cohen’s Kappa scores of κ = 0.71 and κ = 0.94, respectively. These results demonstrate that the weak\nlabels are highly aligned with human judgment, supporting the reliability of the dataset for our experiments.\n3.3\nFeaturization\nWe experiment with two methods to extract numerical features from the preprocessed text:\n• TF-IDF Vectorization: The Term Frequency-Inverse Document Frequency (TF-IDF) approach [18, 20] was\nimplemented using the TfidfVectorizer from scikit-learn, configured to extract the top 5000 features. This\ntransformation generated a sparse matrix of TF-IDF scores, emphasizing words that are important relative\nto their document frequency across datasets. We clarify that stopwords were removed only for exploratory\nlexical analysis, for all model training (both TF-IDF and BERT embeddings-based), stopwords were kept to\npreserve full semantic context and ensure a fair comparison.\n• BERT Embeddings: For deeper semantic representation, BERT embeddings [23] were obtained using the\nbert-base-uncased model from the Hugging Face Transformers library. Each text sample was tokenized\nwith a maximum length of 128 tokens.\n3\n"}, {"page": 4, "text": "Oral Presentation at AAAI AIMedHealth Bridge 2026 (To appear in PMLR)\nTable 1: Class distribution across training preprocessing steps and final test set. DS = Downsampling, DD = Deduplica-\ntion, CB = Cyberbullying.\nClass\nBefore DS\nAfter DS\nAfter EDA & DD\nFinal Test Set\nAge CB\n7,992\n2,400\n2,400\n175\nAnxiety\n3,841\n2,400\n2,400\n80\nBipolar\n2,777\n2,001\n2,400\n55\nEthnicity CB\n7,955\n2,400\n2,400\n172\nGender CB\n7,916\n2,400\n2,400\n167\nNon-Suicide\n115,983\n2,400\n2,400\n2,549\nPersonality Disorder\n1,077\n714\n2,387\n20\nReligion CB\n7,997\n2,400\n2,400\n175\nStress\n2,585\n1,832\n2,396\n50\nSuicide\n116,027\n2,400\n2,400\n2,557\nThese feature extraction strategies allowed the study to experiment with both lexical (TF-IDF) and contextual (BERT)\nrepresentations.\n3.4\nMachine learning approaches\nWe test several distinct families of machine learning models for our 10-class classification task. All models were trained\non the balanced training set (Table 1) and evaluated on the held-out, imbalanced test set. Specific hyperparameters\n(Appendix A) were selected based on standard practices.\n3.4.1\nLexical Baseline Models\nTo establish a non-contextual baseline, we trained two classical models on TF-IDF features. As described in Section\n3.2, we used the top 5000 features (unigrams and bigrams), with stopwords preserved.\n• TF-IDF + Logistic Regression: We used scikit-learn’s LogisticRegressionCV with the saga solver, a\nmultinomial setting, and cv=5 (5-fold cross-validation) on the training set to select the best regularization\nstrength.\n• TF-IDF + Support Vector Machine (SVM): We used scikit-learn’s GridSearchCV with cv=5 to find the\noptimal regularization parameter for a linear SVC class, maximizing for macro F1 score.\n3.4.2\nStatic Embedding Baseline Models\nTo test the performance of static contextual embeddings, we fed pre-computed BERT embeddings into classical\nand neural classifiers. For these models, sentence-level embeddings were extracted using the CLS token from the\nbert-base-uncased model.\n• BERT Embeddings + Logistic Regression:\nThe static CLS embeddings were fed into the same\nLogisticRegressionCV model used in the lexical baseline to ensure a fair comparison.\n• BERT Embeddings + RNN: A simple Recurrent Neural Network (RNN) with one hidden layer of 128 units\nwas built using PyTorch. The model was trained for five epochs using the Adam [30] optimizer (learning rate\n= 0.001) on the static embeddings.\n• BERT Embeddings + DNN: A feed-forward Deep Neural Network (DNN) was constructed with two hidden\nlayers (256 and 128 units) with ReLU activations and dropout. This model was also trained for five epochs\nwith the Adam optimizer (learning rate = 0.001) on the static embeddings.\n3.4.3\nEnd-to-End Fine-Tuned Transformer Models\nThis group represents our primary end-to-end models, where the entire transformer architecture is updated during\ntraining. For these, we used a 90/10 split on our main training set for training and validation, respectively. All models\nwere fine-tuned using the AdamW optimizer [29] with a learning rate of 2e-5 and a batch size of 16. We compared four\ndifferent architectures:\n4\n"}, {"page": 5, "text": "Oral Presentation at AAAI AIMedHealth Bridge 2026 (To appear in PMLR)\n• Finetuned BERT-base: The bert-base-uncased model [10], fine-tuned end-to-end. This serves as our\nprimary contextual model.\n• Finetuned MentalBERT: A domain-adapted model [8] pre-trained on text from Reddit mental health forums.\n• Finetuned MentalRoBERTa: A RoBERTa-base model also pre-trained on the same domain-specific mental\nhealth corpus as MentalBERT[8].\n• Finetuned ModernBERT: We benchmark ModernBERT [26] to test whether recent architectural improve-\nments offer performance gains over standard BERT on our task, even without domain-specific pre-training.\n3.4.4\nZero-Shot LLM Baseline\nAs a modern, non-finetuned baseline, we evaluated a powerful Large Language Model (GPT-OSS 120B)[25] in a\nzero-shot setting[27]. We prompted the model to classify samples from our test set into one of the ten categories. This\napproach required a post-processing step to map the model’s textual outputs to our valid class labels; approximately\n31.6% of responses did not map to a valid label and were excluded from the LLM’s performance calculation.\n3.5\nEvaluation Metrics\nAll performance metrics are reported on the held-out, imbalanced test set (Table 1). This ensures our evaluation\nrealistically assesses model performance on the original, real-world class distribution.\nWe report the following metrics of model performance:\n• Accuracy: Overall proportion of correct predictions.\n• Macro F1: The unweighted average of all F1 scores across classes. The macro F1 score treats all classes\nequally, which is critical for highlighting performance on our rare, low-resource classes.\n• Weighted F1: The average of the per-class F1 scores, weighted by the size (support) of the class in the dataset.\nWe additionally assess the performance of each ML model in each class, to identify which classes are more and less\nchallenging to predict. We report the following per-class metrics of model performance:\n• Precision & Recall: Precision is the proportion of correct positive predictions; recall is the proportion of\nactual positives identified as positive.\n• Per-Class F1: F1 score reported individually per class. The F1 score is the harmonic mean of precision and\nrecall.\n• AUPRC: For the high-risk Suicide class, we additionally report the Area Under the Precision–Recall Curve [28],\nwhich is more informative under class imbalance.\n• Calibration Plot: We also provide a calibration analysis for the ’Suicide’ class to assess whether the models’\npredicted confidence scores are reliable.\n4\nExploratory data analysis\nWe conducted both raw word frequency analysis and TF-IDF (Term Frequency–Inverse Document Frequency) analysis\nto identify representative words within each dataset. While the raw frequency approach consistently surfaced high-\nfrequency function words such as “I”, “the”, “to”, and “my”, TF-IDF assigns higher importance to words that are\ncharacteristic of a specific category but rare in others. This approach enabled us to uncover more semantically\nmeaningful and category-specific terms such as bipolar (bipolar class), rape (gender cyberbullying class), and bullied\n(age cyberbullying class). Figure 1 presents the top ten most frequent words associated with each class label in the\ndataset.\nTo examine the lexical similarity between classes, we performed a correlation analysis of the TF-IDF features. Inspired\nby past natural language processing work taking similar approaches to compare classes [6, 31], we computed the\nmean TF-IDF vector by averaging across all its documents. The Pearson correlation coefficient was then computed\nbetween the mean TF-IDF vectors of each dataset pair to assess the degree of lexical similarity. The resulting heatmap\nis presented in Figure 2. High positive correlations indicate shared vocabulary patterns, while low correlations suggest\ndistinct linguistic structures. Strong correlations are observed among mental health-related classes such as stress,\nbipolar, and personality Disorder. In contrast, cyberbullying classes exhibit much lower correlations with mental health\ndatasets, indicating distinct linguistic patterns.\n5\n"}, {"page": 6, "text": "Oral Presentation at AAAI AIMedHealth Bridge 2026 (To appear in PMLR)\nFigure 1: Table showing top 10 TF-IDF words for each class label\n5\nResults\nThis section presents the empirical results of our experiments. We first provide a comparative analysis of the overall\nperformance of all models, followed by a detailed per-class breakdown to identify specific strengths and weaknesses.\nFinally, we conduct a focused analysis on the critical task of suicide detection, evaluating model reliability through\nAUPRC and calibration plots.\n5.1\nOverall Model Performance\nOur results demonstrate a clear performance advantage for end-to-end fine-tuned transformer models over both\ntraditional machine learning (ML) methods and hybrid approaches that use static BERT embeddings. As shown in Table\n2, Finetuned MentalBERT emerged as the top-performing model, achieving an accuracy of 0.92 and a Macro F1 score\nof 0.76. The other fine-tuned variants, including the generic BERT-base, RoBERTa, and ModernBERT, also delivered\nstrong performance, with Macro F1 scores ranging from 0.70 to 0.71. The competitive performance of the generic\nfine-tuned BERT highlights the effectiveness of our data curation and balancing pipeline in adapting a general-purpose\nmodel to this specific task.\nIn contrast, the traditional and hybrid ML models exhibited lower performance (Table 3). The best-performing ML\nmodel, TF-IDF_LogReg, achieved a Macro F1 score of 0.67. Models using static BERT embeddings as features for\nclassical classifiers (BERT_LogReg, BERT_RNN, BERT_DNN) performed the poorest, with Macro F1 scores between\n0.53 and 0.58. This significant gap underscores the necessity of fine-tuning the entire transformer architecture to capture\nthe complex contextual nuances present in the data.\nTable 2: Overall Model Performance Comparison for Finetuned BERT variants.\nModel\nAccuracy\nMacro F1\nWeighted F1\nPrecision\nRecall\nBERT\n0.87\n0.70\n0.88\n0.64\n0.88\nMentalBERT\n0.92\n0.76\n0.93\n0.70\n0.89\nRoBERTa\n0.88\n0.70\n0.90\n0.64\n0.90\nModernBERT\n0.89\n0.71\n0.91\n0.64\n0.88\n5.2\nPer-Class Performance Analysis\nA granular, per-class analysis reveals significant performance disparities across the ten categories, reflecting the\nchallenges posed by our realistic, imbalanced test set (Table 4). The fine-tuned models, particularly MentalBERT,\nexcelled on high-signal categories with explicit lexical cues. For instance, MentalBERT achieved outstanding F1-scores\n6\n"}, {"page": 7, "text": "Oral Presentation at AAAI AIMedHealth Bridge 2026 (To appear in PMLR)\nFigure 2: Plot of correlation of TF-IDF embeddings across different class labels\nTable 3: Overall ML Model Performance Comparison.\nModel\nAccuracy\nMacro F1\nWeighted F1\nPrecision\nRecall\nTF-IDF_LogReg\n0.82\n0.67\n0.84\n0.61\n0.82\nTF-IDF_SVM\n0.80\n0.64\n0.83\n0.58\n0.81\nBERT_LogReg\n0.75\n0.55\n0.79\n0.49\n0.76\nBERT_RNN\n0.68\n0.53\n0.74\n0.48\n0.74\nBERT_DNN\n0.77\n0.58\n0.80\n0.51\n0.76\non cyberbullying classes like Age CB (0.95) and Religion CB (0.96), as well as the critical mental health class Suicide\n(0.96).\nConversely, performance was substantially lower for nuanced mental health conditions that were sparsely represented\nin the imbalanced test set and are characterized by greater lexical ambiguity. The F1-scores for Personality Disorder\n(0.32), Stress (0.46), and Bipolar (0.70) were markedly lower for MentalBERT. This outcome is not an indication of\nmodel failure but rather a realistic reflection of the inherent difficulty of detecting these conditions from isolated posts\nwithout longitudinal context. The severe class imbalance in the test set, which mirrors real-world data distribution,\ncorrectly penalizes models for misclassifying these rare but important cases, leading to lower but more credible Macro\nF1 scores. The traditional ML models followed a similar trend but with uniformly lower scores across all classes (Table\n5).\n7\n"}, {"page": 8, "text": "Oral Presentation at AAAI AIMedHealth Bridge 2026 (To appear in PMLR)\nTable 4: Per-Class F1, Precision, and Recall – Fine-tuned Models.\nModel\nAge CB\nAnx.\nBip.\nEth. CB\nGen. CB\nNon-Su.\nPers. Dis.\nRel. CB\nStr.\nSuic.\nF1-Score\nBERT\n0.92\n0.71\n0.62\n0.87\n0.64\n0.85\n0.19\n0.93\n0.30\n0.96\nMentalBERT\n0.95\n0.65\n0.70\n0.91\n0.74\n0.93\n0.32\n0.96\n0.46\n0.96\nRoBERTa\n0.92\n0.60\n0.40\n0.89\n0.68\n0.88\n0.17\n0.94\n0.56\n0.96\nModernBERT\n0.91\n0.66\n0.61\n0.87\n0.71\n0.90\n0.24\n0.94\n0.33\n0.96\nPrecision\nBERT\n0.88\n0.61\n0.50\n0.79\n0.48\n0.98\n0.11\n0.89\n0.18\n0.96\nMentalBERT\n0.96\n0.52\n0.62\n0.86\n0.61\n0.97\n0.21\n0.95\n0.32\n0.99\nRoBERTa\n0.88\n0.45\n0.26\n0.83\n0.52\n0.98\n0.10\n0.91\n0.46\n0.98\nModernBERT\n0.86\n0.52\n0.48\n0.78\n0.57\n0.97\n0.14\n0.91\n0.22\n0.99\nRecall\nBERT\n0.97\n0.86\n0.82\n0.97\n0.95\n0.75\n0.75\n0.98\n0.82\n0.96\nMentalBERT\n0.95\n0.89\n0.80\n0.97\n0.93\n0.89\n0.70\n0.97\n0.82\n0.94\nRoBERTa\n0.97\n0.91\n0.87\n0.95\n0.97\n0.79\n0.90\n0.98\n0.74\n0.94\nModernBERT\n0.97\n0.90\n0.84\n0.98\n0.95\n0.84\n0.65\n0.98\n0.74\n0.93\nNote: CB—Cyberbullying, Anx.—Anxiety, Bip.—Bipolar, Eth.—Ethnicity, Gen.—Gender, Non-Su.—Non-Suicidal, Pers. Dis.—Personality Disorder, Rel.—Religion,\nStr.—Stress, Suic.—Suicide.\nTable 5: Per-class F1, Precision, and Recall for ML Models.\nModel\nAge CB\nAnx.\nBip.\nEth. CB\nGen. CB\nNon-Su.\nPers. Dis.\nRel. CB\nStr.\nSuic.\nF1-Score\nTF-IDF_LogReg\n0.89\n0.57\n0.44\n0.86\n0.67\n0.85\n0.43\n0.93\n0.19\n0.87\nTF-IDF_SVM\n0.92\n0.56\n0.39\n0.86\n0.62\n0.83\n0.28\n0.93\n0.17\n0.85\nBERT_LogReg\n0.73\n0.43\n0.26\n0.72\n0.52\n0.78\n0.14\n0.89\n0.17\n0.85\nBERT_RNN\n0.70\n0.45\n0.30\n0.68\n0.41\n0.73\n0.20\n0.88\n0.09\n0.81\nBERT_DNN\n0.73\n0.52\n0.30\n0.71\n0.62\n0.79\n0.25\n0.81\n0.16\n0.86\nPrecision\nTF-IDF_LogReg\n0.84\n0.43\n0.32\n0.80\n0.54\n0.89\n0.31\n0.89\n0.11\n0.93\nTF-IDF_SVM\n0.88\n0.41\n0.27\n0.78\n0.48\n0.88\n0.18\n0.91\n0.10\n0.93\nBERT_LogReg\n0.62\n0.30\n0.17\n0.60\n0.37\n0.91\n0.08\n0.83\n0.10\n0.93\nBERT_RNN\n0.59\n0.31\n0.21\n0.55\n0.27\n0.93\n0.13\n0.83\n0.05\n0.95\nBERT_DNN\n0.61\n0.40\n0.20\n0.58\n0.49\n0.91\n0.17\n0.69\n0.09\n0.93\nRecall\nTF-IDF_LogReg\n0.95\n0.88\n0.71\n0.94\n0.87\n0.80\n0.70\n0.97\n0.58\n0.82\nTF-IDF_SVM\n0.96\n0.89\n0.71\n0.97\n0.89\n0.79\n0.65\n0.96\n0.52\n0.79\nBERT_LogReg\n0.89\n0.76\n0.65\n0.89\n0.87\n0.68\n0.50\n0.96\n0.60\n0.79\nBERT_RNN\n0.87\n0.81\n0.56\n0.90\n0.92\n0.60\n0.40\n0.95\n0.72\n0.71\nBERT_DNN\n0.91\n0.74\n0.58\n0.91\n0.83\n0.71\n0.50\n0.97\n0.64\n0.81\nNote: CB—Cyberbullying, Anx.—Anxiety, Bip.—Bipolar, Eth.—Ethnicity, Gen.—Gender, Non-Su.—Non-Suicidal, Pers. Dis.—Personality Disorder, Rel.—Religion,\nStr.—Stress, Suic.—Suicide.\n5.3\nAnalysis on Suicide Detection: AUPRC and Calibration\nFor the high-stakes task of suicide detection, we evaluated model reliability. All fine-tuned models demonstrated\nexcellent discriminative power, achieving near-perfect AUPRC scores (≥0.992), with MentalBERT and ModernBERT\nreaching 0.994 (Figure 3). This confirms their ability to identify suicidal content with high precision.\nBeyond discrimination, the calibration analysis (Figure 4) identifies MentalBERT as the most trustworthy model. Its\nconfidence scores are well-calibrated, in contrast to the under-confident standard BERT and over-confident ModernBERT.\nThis superior reliability makes MentalBERT the most suitable model for this critical screening task.\n5.4\nImpact of Data Balancing Strategy\nTo evaluate the effectiveness of our dual data balancing approach, we compared model performance before and after\nits application. The results confirm a crucial improvement in overall robustness. For our top-performing model,\nMentalBERT, the Macro F1 score, the most significant metric for imbalanced classes, increased from 0.73 to 0.76,\nwhile accuracy rose from 0.90 to 0.92. This demonstrates the value of our pipeline in creating a more equitable and\neffective classifier.\nThe strategy’s primary benefits are most evident at the per-class level, validating its targeted impact. The most substantial\ngain occurred in the Bipolar class, where the F1-score rose dramatically from 0.49 to 0.70. Notable improvements were\nalso observed for other underrepresented mental health classes like Anxiety (0.59 to 0.65) and Personality Disorder\n(0.28 to 0.32). Interestingly, the strategy did not improve all rare classes equally; the F1-score for Stress remained\nunchanged, suggesting its lexical ambiguity presents a challenge that oversampling alone cannot solve. Overall, these\nresults justify our methodological choice, confirming that the balancing strategy provides a targeted performance lift for\nkey underrepresented classes.\n8\n"}, {"page": 9, "text": "Oral Presentation at AAAI AIMedHealth Bridge 2026 (To appear in PMLR)\nFigure 3: Precision-Recall Curve for the ’Suicide’ class, showing near-perfect AUPRC scores for all fine-tuned models.\nFigure 4: Calibration Curve for the ’Suicide’ class. MentalBERT demonstrates the best calibration, with its predicted\nprobabilities closely matching the observed frequencies.\n9\n"}, {"page": 10, "text": "Oral Presentation at AAAI AIMedHealth Bridge 2026 (To appear in PMLR)\n5.5\nError Analysis\nAn analysis of the confusion matrix for our top model, MentalBERT (Figure 5), reveals key learning behaviors. The\nmodel demonstrates high performance on well-represented classes with clear lexical signals, such as Suicide and the\ncyberbullying categories, as indicated by the strong diagonal.\nMore importantly, the off-diagonal error patterns provide strong evidence that the model is learning true semantic\nrelationships, not superficial domain cues. Misclassifications are concentrated between semantically coherent categories,\nsuch as the confusion between Anxiety and Stress. In contrast, cross-domain errors between the mental health (primarily\nReddit-based) and cyberbullying (primarily Twitter-based) categories are minimal: only 2.3% (123 out of 5,311) of\nmental health posts were misclassified as a cyberbullying class, while a mere 1.5% (10 out of 689) of cyberbullying\nposts were misclassified as mental health. This pattern refutes the hypothesis of the model learning spurious platform\nheuristics and confirms it is addressing the intended nuanced classification task.\nFigure 5: Confusion matrix for Fine-tuned MentalBERT. The model’s primary errors occur between semantically\nrelated classes (e.g., Anxiety and Stress), confirming that it learns content over platform-specific artifacts.\n6\nEthical Considerations\nThe development of AI for mental health screening requires a rigorous ethical framework to ensure responsible\ninnovation. Our work is therefore grounded in a framework designed to proactively address the critical challenges of\nmodel application, data provenance, and fairness.\n10\n"}, {"page": 11, "text": "Oral Presentation at AAAI AIMedHealth Bridge 2026 (To appear in PMLR)\n6.1\nIntended Application and Limitations\nA primary ethical risk is the misinterpretation of model outputs as clinical diagnoses. We explicitly state that our model\nis not a diagnostic tool. Instead, we propose its use as a screening assistant for trained human moderators within a\ndual-purpose framework:\n• For Immediate Risk Flagging: For high-signal classes like Suicide, the model can effectively flag content for\nurgent human review, helping to prioritize potentially life-saving interventions.\n• Nuanced Pattern Analysis: For conditions like Bipolar Disorder that require longitudinal assessment, the\nmodel supports a broader decision-support tool by highlighting linguistic shifts over time. For example,\ntracking changes in language associated with mood episodes can offer an early signal for clinical intervention,\nrather than labeling individual posts in isolation.\nIn all cases, the system is designed to inform, not replace, professional human judgment.\n6.2\nData Privacy and Provenance\nOur work uses anonymized, publicly available data from Kaggle. All datasets were curated in accordance with platform\nterms and community research standards. The data were further processed to remove any personally identifiable\ninformation, ensuring compliance with ethical use guidelines. Our label verification study (Section 3.2) served as an\nadditional quality assurance step to validate labeling consistency and dataset integrity.\n6.3\nAccountability and Misuse\nThis framework is designed for a strictly supportive purpose, operationalized through a human-in-the-loop system\nwhere trained professionals verify all automated flags. The intended application of the resulting tool is to assist content\nmoderation and connect individuals with resources. Consequently, any use for surveillance, censorship, or punitive\naction would constitute a misuse and falls outside the tool’s ethical scope.\n6.4\nModel Explainability\nTo ensure our framework is transparent and trustworthy for real-world applications, we developed a hybrid explainability\nsystem. This approach combines results from SHAP (SHapley Additive exPlanations)[24] with the narrative clarity of a\nLarge Language Model (GPT-OSS 20B)[25]. First, SHAP is used to identify the precise mathematical contribution of\neach word to the model’s prediction. This quantitative evidence is then synthesized by the LLM to generate a coherent,\nhuman-readable explanation.\nTo demonstrate how this system is integrated into our proposed human-in-the-loop application, Figure 6 shows a\nprototype of the \"Social Media Screener\" dashboard.\nThis prototype visualizes how a human moderator interacts with the system. Instead of a raw plot, the SHAP analysis\nis rendered as simple red highlights on the most impactful words (e.g., \"help me kill,\" \"myself,\" \"tired of\"). This\nquantitative data is paired with the LLM Explainability Analysis in the green box, which provides a narrative summary.\nThis interface also includes the critical ethical safeguard (\"This is not a clinical diagnosis.\") and the \"Moderator Action\"\npanel, which requires a human to verify every flag, completing the human-in-the-loop framework. Additional examples\ncan be found in Appendix C.\n6.5\nAnalysis of Performance Disparities and Domain Cues\nOur per-class results show performance variations across categories, which our analysis attributes to the inherent\ncharacteristics of the data rather than model artifacts. As confirmed by our error analysis (Section 5.5), the model does\nnot rely on superficial platform cues (e.g., Reddit vs. Twitter) but instead learns from the content’s semantic properties.\nPerformance differences are primarily driven by two factors:\n• Lexical Specificity: Cyberbullying classes, typically sourced from shorter Twitter posts, often contain explicit,\nhigh-signal keywords. This results in higher classification accuracy due to the clear and consistent linguistic\nmarkers.\n• Narrative Complexity: Mental health classes, often from longer, narrative-style Reddit posts, express distress\nin more nuanced and varied ways. The critical signal may be diffused within a larger volume of text, creating a\n11\n"}, {"page": 12, "text": "Oral Presentation at AAAI AIMedHealth Bridge 2026 (To appear in PMLR)\nFigure 6: The proposed \"Social Media Screener\" prototype. This interface integrates the hybrid explainability system\ndirectly for a human moderator. The SHAP-derived token importance is shown via red highlights in the ’Post Content’\nsection, while the ’LLM Explainability Analysis’ is presented in a clear text box below the model’s flag.\ngreater challenge for the model. This aligns with our observation that the most common errors occur between\nsemantically related mental health classes like Anxiety and Stress.\nThese findings demonstrate the model’s ability to adapt to diverse text styles and confirm that performance disparities\nare a function of the task’s complexity, not a reliance on spurious correlations.\n6.6\nLimitations and Future Work\nOur work provides a robust framework for multi-class mental health screening, but we acknowledge limitations that\npave the way for future research.\n6.6.1\nLimitations\n• Data Provenance and Generalizability: While we verified label quality using a sample of the datasets, our\nuse of aggregated Kaggle datasets limits broad claims of generalizability. The model’s performance on datasets\nfrom different platforms, time periods, or demographic groups remains untested.\n• Single-Label Task Framing: Our multi-class framework treats each post as having a single, primary label.\nThis simplifies the clinical reality where mental health conditions and cyberbullying can co-occur (e.g., a\npost expressing suicidal ideation within a narrative about Bipolar Disorder). As shown in our error analysis\n(Example 1, Appendix), the model sometimes correctly identifies a high-risk secondary theme (Suicide) while\nmisclassifying the primary label (Bipolar Disorder). A multi-label framework is a critical next step to capture\nthis co-morbidity and provide a more clinically nuanced output.\n• Scope of Evaluation: The current study is limited to English-language text, excluding the rich signals available\nin multilingual and multimodal (e.g., images, videos) content.\n6.6.2\nFuture Work\nBased on these limitations, this work highlights several key directions for future research in this domain:\n12\n"}, {"page": 13, "text": "Oral Presentation at AAAI AIMedHealth Bridge 2026 (To appear in PMLR)\n• Curation of a Multi-Label Benchmark: The most critical next step for the field is the creation of a new,\nethically sourced, and expertly annotated benchmark dataset. Such a dataset should feature multi-label\nannotations to enable the study of co-occurring conditions, reflecting a more clinically realistic scenario.\n• Validating Utility with Human-in-the-Loop Studies: The promising results of our prototype pave the way for\nformal Human-Computer Interaction (HCI) studies. Future work should engage trained moderators in a user\nstudy to quantitatively validate the real-world impact of our hybrid explainability system on decision-making\naccuracy, efficiency, and trust in AI-assisted workflows.\n• Advanced Model Architectures: The availability of a multi-label benchmark would enable the exploration of\nmulti-task learning architectures. These models could feature a shared encoder with separate classification\nheads to explicitly model the interplay between different mental health and cyberbullying phenomena.\n• Robustness and Multimodal Evaluation: Future research should prioritize rigorous cross-domain and tempo-\nral generalization tests to ensure models are robust in real-world environments. Furthermore, expanding these\nframeworks to incorporate multilingual and multimodal analysis is essential for building more comprehensive\nand inclusive screening tools.\nReferences\n[1] World\nHealth\nOrganization.\nMental\nDisorders.\n2025.\nURL:\nhttps://www.who.int/news-room/\nfact-sheets/detail/mental-disorders. (Accessed: April 22, 2025).\n[2] Á. Zsila and M. E. S. Reyes. Pros & cons: impacts of social media on mental health. BMC Psychology, 11(1):201,\n2023. DOI: 10.1186/s40359-023-01243-x.\n[3] J. Naslund, A. Bondre, J. Torous and K. Aschbrenner. Social Media and Mental Health: Benefits, Risks, and Op-\nportunities for Research and Practice. Journal of Technology in Behavioral Science, 5, 2020. DOI: 10.1007/s41347-\n020-00134-x.\n[4] S. Poddar, R. Mukherjee, A. Samad, N. Ganguly and S. Ghosh. MuLX-QA: Classifying Multi-Labels and\nExtracting Rationale Spans in Social Media Posts. ACM Transactions on Information Systems, 42(3), 2024.\n[5] M. Wu, J. Chang, Z. Epstein and D. Rand. Beyond Friends: Exploring the Effects of Unknown Users’ Social\nMedia Posts on Individuals’ Perceptions and Behaviors. HICSS, 2025. DOI: 10.24251/HICSS.2025.281.\n[6] Md. I. Mobin, A. F. M. S. Akhter, M. F. Mridha, S. M. H. Mahmud and Z. Aung. Social Media as a Mirror:\nReflecting Mental Health Through Computational Linguistics. IEEE Access, 12:130143–130164, 2024. DOI:\n10.1109/ACCESS.2024.3454292.\n[7] P. Kumar, P. Samanta, S. Dutta, M. Chatterjee and D. Sarkar. Feature Based Depression Detection from Twit-\nter Data Using Machine Learning Techniques. Journal of Scientific Research, 66(02):220–228, 2022. DOI:\n10.37398/JSR.2022.660229.\n[8] Z. Ji, T. Reddy, A. Nagda and H. Singh. MentalBERT: Publicly available pretrained transformer-based model for\nmental healthcare social media text mining on Reddit. Proceedings of LREC, 2022.\n[9] J. Devlin, M.-W. Chang, K. Lee and K. Toutanova. BERT: Pre-training of deep bidirectional transformers for\nlanguage understanding. Proceedings of NAACL-HLT, 2019.\n[10] J. Devlin, M.-W. Chang, K. Lee and K. Toutanova. BERT: Pre-training of deep bidirectional transformers for\nlanguage understanding. Proceedings of NAACL-HLT, 2019.\n[11] B. Mathew, P. Saha, S. M. Yimam, C. Biemann, P. Goyal and A. Mukherjee. HateXplain: A Benchmark Dataset\nfor Explainable Hate Speech Detection. arXiv:2012.10289, 2020.\n[12] Y. Jiang. Problematic Social Media Usage and Anxiety Among University Students During the COVID-19\nPandemic: The Mediating Role of Psychological Capital and the Moderating Role of Academic Burnout. Frontiers\nin Psychology, 12:612007, 2021. DOI: 10.3389/fpsyg.2021.612007.\n[13] J. Wang, K. Fu and C.-T. Lu. SOSNet: A Graph Convolutional Network Approach to Fine-Grained Cyberbullying\nDetection. In 2020 IEEE International Conference on Big Data (Big Data), pages 1699–1708, 2020. DOI:\n10.1109/BigData50022.2020.9378065.\n[14] D. Antypas and J. Camacho-Collados. Robust Hate Speech Detection in Social Media: A Cross-Dataset Empirical\nEvaluation. In The 7th Workshop on Online Abuse and Harms (WOAH), Toronto, Canada, Jul 2023, pages\n231–242. DOI: 10.18653/v1/2023.woah-1.25.\n[15] S. Sarkar. Sentiment Analysis for Mental Health. Kaggle dataset, 2024.\n[16] N. Ghoshal. Reddit Mental Health Data. Kaggle dataset, 2025.\n13\n"}, {"page": 14, "text": "Oral Presentation at AAAI AIMedHealth Bridge 2026 (To appear in PMLR)\n[17] N. Komati. Suicide and Depression Detection. Kaggle dataset, 2021.\n[18] S. Robertson. Understanding Inverse Document Frequency: On Theoretical Arguments for IDF. Journal of\nDocumentation, 60(10):503–520, 2004. DOI: 10.1108/00220410410560582.\n[19] J. Wei and K. Zou. EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification\nTasks. arXiv:1901.11196, 2019.\n[20] A. Nweke, M. Khan and Y. Pei. Explainable Multi-Label Classification Framework for Behavioral Health Based\non Domain Concepts. IEEE Transactions on Artificial Intelligence, 15:89–105, 2024.\n[21] M. Abdullah and N. Negied. Detection and Prediction of Future Mental Disorder From Social Media Data Using\nMachine Learning, Ensemble Learning, and Large Language Models. IEEE Access, 12:120553–120569, 2024.\nDOI: 10.1109/ACCESS.2024.3406469.\n[22] F. de Arriba-Pérez and S. García-Méndez. Detecting anxiety and depression in dialogues: a multi-label and\nexplainable approach. arXiv:2412.17651, 2024.\n[23] Y. Zhang and J. Liu. Depression Detection on Social Media with Large Language Models. arXiv:2403.10750,\n2024.\n[24] S. Lundberg and S.-I. Lee. A Unified Approach to Interpreting Model Predictions. arXiv:1705.07874, 2017.\n[25] S. Agarwal et al. gpt-oss-120b & gpt-oss-20b model card. arXiv preprint arXiv:2508.10925, 2025.\n[26] B. Warner et al. Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and\nLong Context Finetuning and Inference. arXiv:2412.13663, 2024.\n[27] T. Kojima, S. Gu, M. Reid, Y. Matsuo and Y. Iwasawa. Large language models are zero-shot reasoners. Advances\nin Neural Information Processing Systems, 35:22199–22213, 2022.\n[28] M. McDermott, H. Zhang, L. Hansen, G. Angelotti and J. Gallifant. A closer look at AUROC and AUPRC under\nclass imbalance. Advances in Neural Information Processing Systems, 37:44102–44163, 2024.\n[29] I. Loshchilov and F. Hutter. Decoupled Weight Decay Regularization. arXiv:1711.05101, 2019.\n[30] D. P. Kingma and J. Ba. Adam: A Method for Stochastic Optimization. arXiv:1412.6980, 2017.\n[31] Z. Liu, Y. Lin and M. Sun. Sentence Representation. In Representation Learning for Natural Language Processing,\nSpringer Nature, 2020, pages 59–89. DOI: 10.1007/978-981-15-5573-2_4.\n14\n"}, {"page": 15, "text": "Oral Presentation at AAAI AIMedHealth Bridge 2026 (To appear in PMLR)\n7\nAppendix\nA\nModel Hyperparameters\nThis section details the hyperparameters used for all feature extraction methods and machine learning models evaluated\nin this study. For models trained using cross-validation or grid search, the search space is specified.\nTable 6: Hyperparameters for Feature Extraction and Trained Models\nComponent\nModel / Method\nHyperparameters\nFeature Extraction\nTF-IDF Vectorizer\nMax Features: 5000\nStop Words: None (preserved for training)\nN-gram Range: (1, 2)\nBERT Embeddings\nModel: bert-base-uncased\nMax Sequence Length: 128\nLexical Based Models\nLogistic Regression (CV)\nSolver: ’saga’, Setting: ’multinomial’\nMax Iterations: 1000\nRegularization Strengths (C): [0.1, 1, 10]\nCross-Validation Folds: 5\nSupport Vector Machine (Grid Search)\nKernel: ’linear’\nRegularization Strengths (C): [0.01, 0.1, 1, 10]\nCross-Validation Folds: 5\nStatic BERT Embedding\nLogistic Regression (CV)\nSolver: ’saga’, Setting: ’multinomial’\nBased Models\nMax Iterations: 1000, CV Folds: 5\nFeedforward NN (DNN)\nHidden Layers: [256, 128]\nActivation Function: ReLU, Dropout: 0.3\nOptimizer: Adam, Learning Rate: 0.001\nBatch Size: 64, Epochs: 5\nRecurrent Neural Network (RNN)\nHidden Layer Dimension: 128\nOptimizer: Adam, Learning Rate: 0.001\nBatch Size: 64, Epochs: 5\nEnd-to-End\nFinetuned BERT-base\nOptimizer: AdamW\nFine-Tuned Models\nFinetuned MentalBERT\nLearning Rate: 2e-5\nFinetuned MentalRoBERTa\nBatch Size: 16\nFinetuned ModernBERT\nTraining/Validation Split: 90/10\nB\nModel Performances Before Oversampling\nThe performance of the models was evaluated before applying any oversampling. The overall and per-class metrics are\nreported below.\nTable 7: Overall ML Model Performance on Non-Oversampled Data\nModel\nAccuracy\nMacro F1\nWeighted F1\nPrecision\nRecall\nTF-IDF_LogReg\n0.82\n0.67\n0.84\n0.61\n0.82\nTF-IDF_SVM\n0.81\n0.64\n0.83\n0.58\n0.81\nBERT_LogReg\n0.75\n0.55\n0.79\n0.49\n0.76\nBERT_RNN\n0.78\n0.58\n0.81\n0.52\n0.76\nBERT_DNN\n0.72\n0.55\n0.77\n0.51\n0.74\n15\n"}, {"page": 16, "text": "Oral Presentation at AAAI AIMedHealth Bridge 2026 (To appear in PMLR)\nTable 8: Per-Class Metrics for ML Models on Non-Oversampled Data\nModel\nAge CB\nAnx.\nBip.\nEth. CB\nGen. CB\nNon-Su.\nPers. Dis.\nRel. CB\nStr.\nSuic.\nF1-Score\nTF-IDF_LogReg\n0.89\n0.57\n0.45\n0.86\n0.67\n0.85\n0.43\n0.93\n0.19\n0.87\nTF-IDF_SVM\n0.92\n0.56\n0.39\n0.86\n0.63\n0.84\n0.29\n0.93\n0.17\n0.85\nBERT_LogReg\n0.73\n0.43\n0.26\n0.72\n0.52\n0.78\n0.13\n0.89\n0.17\n0.85\nBERT_RNN\n0.72\n0.46\n0.24\n0.81\n0.54\n0.81\n0.29\n0.86\n0.22\n0.87\nBERT_DNN\n0.77\n0.47\n0.24\n0.79\n0.47\n0.80\n0.19\n0.91\n0.12\n0.79\nPrecision\nTF-IDF_LogReg\n0.84\n0.43\n0.33\n0.80\n0.54\n0.89\n0.31\n0.89\n0.11\n0.93\nTF-IDF_SVM\n0.88\n0.41\n0.27\n0.78\n0.49\n0.88\n0.18\n0.91\n0.10\n0.93\nBERT_LogReg\n0.62\n0.30\n0.16\n0.60\n0.37\n0.92\n0.08\n0.84\n0.10\n0.93\nBERT_RNN\n0.59\n0.34\n0.15\n0.77\n0.39\n0.91\n0.20\n0.78\n0.14\n0.92\nBERT_DNN\n0.68\n0.34\n0.15\n0.73\n0.31\n0.88\n0.12\n0.90\n0.06\n0.96\nRecall\nTF-IDF_LogReg\n0.95\n0.88\n0.71\n0.94\n0.87\n0.81\n0.70\n0.97\n0.58\n0.82\nTF-IDF_SVM\n0.96\n0.89\n0.71\n0.97\n0.89\n0.79\n0.65\n0.96\n0.52\n0.79\nBERT_LogReg\n0.89\n0.76\n0.65\n0.89\n0.87\n0.68\n0.50\n0.96\n0.60\n0.79\nBERT_RNN\n0.91\n0.74\n0.71\n0.85\n0.87\n0.73\n0.50\n0.96\n0.46\n0.82\nBERT_DNN\n0.87\n0.78\n0.58\n0.87\n0.93\n0.73\n0.45\n0.91\n0.66\n0.68\nCB—Cyberbullying; Anx.—Anxiety; Bip.—Bipolar; Eth.—Ethnicity; Gen.—Gender; Non-Su.—Non-Suicidal; Pers. Dis.—Personality Disorder; Rel.—Religion;\nStr.—Stress; Suic.—Suicide.\nTable 9: Overall Fine-tuned Model Performance on Non-Oversampled Data\nModel\nAccuracy\nMacro F1\nWeighted F1\nPrecision\nRecall\nFine-tuned BERT\n0.89\n0.71\n0.91\n0.66\n0.89\nFine-tuned MentalBERT\n0.90\n0.73\n0.92\n0.66\n0.89\nFine-tuned RoBERTa\n0.89\n0.73\n0.91\n0.67\n0.90\nFine-tuned ModernBERT\n0.88\n0.69\n0.90\n0.63\n0.88\nTable 10: Per-Class Metrics for Fine-tuned Models on Non-Oversampled Data\nModel\nAge CB\nAnx.\nBip.\nEth. CB\nGen. CB\nNon-Su.\nPers. Dis.\nRel. CB\nStr.\nSuic.\nF1-Score\nFine-tuned BERT\n0.94\n0.58\n0.52\n0.91\n0.84\n0.90\n0.16\n0.96\n0.38\n0.95\nFine-tuned MentalBERT\n0.94\n0.59\n0.49\n0.90\n0.78\n0.91\n0.28\n0.97\n0.46\n0.96\nFine-tuned RoBERTa\n0.97\n0.59\n0.52\n0.82\n0.79\n0.89\n0.17\n0.94\n0.62\n0.96\nFine-tuned ModernBERT\n0.95\n0.53\n0.55\n0.86\n0.81\n0.89\n0.22\n0.91\n0.27\n0.96\nPrecision\nFine-tuned BERT\n0.91\n0.42\n0.38\n0.87\n0.77\n0.97\n0.09\n0.95\n0.26\n0.98\nFine-tuned MentalBERT\n0.92\n0.44\n0.34\n0.85\n0.65\n0.98\n0.17\n0.95\n0.32\n0.98\nFine-tuned RoBERTa\n0.98\n0.44\n0.37\n0.71\n0.69\n0.98\n0.09\n0.91\n0.54\n0.97\nFine-tuned ModernBERT\n0.94\n0.37\n0.41\n0.77\n0.73\n0.97\n0.13\n0.84\n0.16\n0.99\nRecall\nFine-tuned BERT\n0.96\n0.93\n0.82\n0.95\n0.93\n0.84\n0.90\n0.97\n0.72\n0.92\nFine-tuned MentalBERT\n0.95\n0.88\n0.84\n0.94\n0.97\n0.85\n0.70\n0.99\n0.72\n0.95\nFine-tuned RoBERTa\n0.95\n0.93\n0.87\n0.97\n0.92\n0.81\n0.90\n0.98\n0.72\n0.95\nFine-tuned ModernBERT\n0.97\n0.94\n0.82\n0.97\n0.90\n0.81\n0.65\n0.98\n0.71\n0.92\nCB—Cyberbullying; Anx.—Anxiety; Bip.—Bipolar; Eth.—Ethnicity; Gen.—Gender; Non-Su.—Non-Suicidal; Pers. Dis.—Personality Disorder; Rel.—Religion;\nStr.—Stress; Suic.—Suicide.\n16\n"}, {"page": 17, "text": "Oral Presentation at AAAI AIMedHealth Bridge 2026 (To appear in PMLR)\nC\nExplainability Examples\nBelow are some examples of our hybrid explainability framework in action. These instances demonstrate how the\nsystem provides clear rationales for its predictions.\nC.1\nPrototype Interface Walkthrough\nThe “Social Media Screener” interface shown in each example is designed for a human-in-the-loop workflow. The key\ncomponents are:\n• Post Content: The original text of the post. Words identified by SHAP as having the highest impact on the\nmodel’s prediction are highlighted in red, providing immediate, quantitative evidence.\n• AI Analysis (Screening Aid Only): Displays the model’s predicted label and confidence score. It includes a\ncritical disclaimer that this is not a clinical diagnosis.\n• LLM Explainability Analysis: A human-readable narrative, synthesized by an LLM from the SHAP values,\nexplaining why the model made its decision in plain language.\n• Moderator Action: A required action panel where the human user must confirm, dismiss, or re-categorize the\nflag, ensuring no decision is fully automated.\nC.2\nExample 1: Misclassification Highlighting Model Nuance\nText: “everything warning i legitimately want to kill myself just to spite my father i lived on my own for many years and\nabout years ago i was guilted into ...”\nActual Label: Bipolar Disorder\nPredicted Label: Suicidal (Confidence:\n1.000)\nFigure 7: Hybrid explainability output for a text labeled ’Bipolar Disorder’ but classified as ’Suicidal’ due to strong\nself-harm intent. This highlights the model’s ability to detect co-occurring high-risk language.\nC.3\nExample 2: Age-based Cyberbullying\nText: “my yo daughter has had so much trouble at school being left out bullied and the final straw she was jumped by\ngirls on high street of town we live in ...”\n17\n"}, {"page": 18, "text": "Oral Presentation at AAAI AIMedHealth Bridge 2026 (To appear in PMLR)\nActual Label: Age-based CB\nPredicted Label: Age-based CB (Confidence:\n1.000)\nFigure 8: Hybrid explainability output for a text correctly classified as Age-based Cyberbullying. The LLM identifies\nterms like ’bullied’ and ’jumped’ as key indicators.\nC.4\nExample 3: Suicidal Ideation (Explicit)\nText: “nearly eleven months clean but i want to cut it short by bleeding myself dry in the bathroom fuck i really want to\nescape whatever the fuck i am whatev...”\nActual Label: Suicidal\nPredicted Label: Suicidal (Confidence:\n0.999)\nFigure 9: Hybrid explainability output for a text correctly classified as Suicidal, showing explicit self-harm language\n(’bleeding myself dry’, ’slice my arms’).\n18\n"}, {"page": 19, "text": "Oral Presentation at AAAI AIMedHealth Bridge 2026 (To appear in PMLR)\nC.5\nExample 4: Non-Suicidal Content\nText: “does anyone write stories does anyone here write stories with characters is it tough in my experience i feel like i\ndont know enough about people to write characters who arent just like me...”\nActual Label: not suicidal\nPredicted Label: not suicidal (Confidence:\n0.444)\nFigure 10: Hybrid explainability output for a text correctly classified as ’not suicidal’. The LLM notes the absence of\nself-harm indicators and the focus on creative discussion.\nC.6\nExample 5: Suicidal Ideation (Nuanced)\nText: “i might do this would be the best time considering i lost my closest friends and i have very few people that care\nabout me”\nActual Label: suicidal\nPredicted Label: suicidal (Confidence:\n0.996)\nFigure 11: Hybrid explainability output for a text correctly classified as ’suicidal’. The model identifies nuanced\nindicators of isolation and hopelessness (’lost’, ’few people’, ’care about me’) as contributing to the risk profile.\n19\n"}]}