{"doc_id": "arxiv:2601.09717", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2601.09717.pdf", "meta": {"doc_id": "arxiv:2601.09717", "source": "arxiv", "arxiv_id": "2601.09717", "title": "SALP-CG: Standard-Aligned LLM Pipeline for Classifying and Grading Large Volumes of Online Conversational Health Data", "authors": ["Yiwei Yan", "Hao Li", "Hua He", "Gong Kai", "Zhengyi Yang", "Guanfeng Liu"], "published": "2025-12-25T01:52:46Z", "updated": "2025-12-25T01:52:46Z", "summary": "Online medical consultations generate large volumes of conversational health data that often embed protected health information, requiring robust methods to classify data categories and assign risk levels in line with policies and practice. However, existing approaches lack unified standards and reliable automated methods to fulfill sensitivity classification for such conversational health data. This study presents a large language model-based extraction pipeline, SALP-CG, for classifying and grading privacy risks in online conversational health data. We concluded health-data classification and grading rules in accordance with GB/T 39725-2020. Combining few-shot guidance, JSON Schema constrained decoding, and deterministic high-risk rules, the backend-agnostic extraction pipeline achieves strong category compliance and reliable sensitivity across diverse LLMs. On the MedDialog-CN benchmark, models yields robust entity counts, high schema compliance, and accurate sensitivity grading, while the strongest model attains micro-F1=0.900 for maximum-level prediction. The category landscape stratified by sensitivity shows that Level 2-3 items dominate, enabling re-identification when combined; Level 4-5 items are less frequent but carry outsize harm. SALP-CG reliably helps classify categories and grading sensitivity in online conversational health data across LLMs, offering a practical method for health data governance. Code is available at https://github.com/dommii1218/SALP-CG.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2601.09717v1", "url_pdf": "https://arxiv.org/pdf/2601.09717.pdf", "meta_path": "data/raw/arxiv/meta/2601.09717.json", "sha256": "78c651bda5fe8080f9fc998fc8c9d7f31f5da6f4897112b9154f02a0b31df535", "status": "ok", "fetched_at": "2026-02-18T02:23:50.343839+00:00"}, "pages": [{"page": 1, "text": "SALP-CG: Standard-Aligned LLM Pipeline for\nClassifying and Grading Large Volumes of Online\nConversational Health Data\nYiwei Yan1, Hao Li2, Hua He3, Kai Gong4, Zhengyi Yang5, and Guanfeng Liu1\n1 School of Computing, Macquarie University, Australia\n2 Department of Biomedical Engineering, National University of Singapore\n3 School of Mathematics and Statistics, Shandong University of Technology, China\n4 Digital Intelligence Center, Fuzhou University Affiliated Provincial Hospital, China\n5 School of Computer Science and Engineering, UNSW, Australia\nAbstract. Online medical consultations generate large volumes of con-\nversational health data that often embed protected health information,\nrequiring robust methods to classify data categories and assign risk lev-\nels in line with policies and practice. However, existing approaches lack\nunified standards and reliable automated methods to fulfill sensitivity\nclassification for such conversational health data. This study presents\na large language model-based extraction pipeline, SALP-CG, for clas-\nsifying and grading privacy risks in online conversational health data.\nWe concluded health-data classification and grading rules in accordance\nwith GB/T 39725-2020. Combining few-shot guidance, JSON Schema\nconstrained decoding, and deterministic high-risk rules, the backend-\nagnostic extraction pipeline achieves strong category compliance and\nreliable sensitivity across diverse LLMs. On the MedDialog-CN bench-\nmark, models yields robust entity counts, high schema compliance, and\naccurate sensitivity grading, while the strongest model attains micro-\nF1=0.900 for maximum-level prediction. The category landscape strat-\nified by sensitivity shows that Level 2-3 items dominate, enabling re-\nidentification when combined; Level 4-5 items are less frequent but carry\noutsize harm. SALP-CG reliably helps classify categories and grading\nsensitivity in online conversational health data across LLMs, offering\na practical method for health data governance. Code is available at\nhttps://github.com/dommii1218/SALP-CG.\nKeywords: Data classification and grading · Online conversational health\ndata · Large language model · Information Extraction Pipeline.\n1\nIntroduction\nThe pervasive digitization of health data has propelled healthcare delivery and\ntechnological innovation [1]. Meanwhile, significant privacy concerns have been\nraised due to the high sensitivity and complexity of health data, which requires\na thoughtful balance between innovation and patient privacy security [2, 3]. This\narXiv:2601.09717v1  [cs.CL]  25 Dec 2025\n"}, {"page": 2, "text": "2\nY. Yan et al.\nconcern is shared globally; the U.S. The Health Insurance Portability and Ac-\ncountability Act (HIPAA) mandates that 18 types of re-identifiable information\nmust be removed from medical records before sharing. The General Data Pro-\ntection Regulation (GDPR) in the European Union requires the anonymization\nor pseudonymization of re-identifiable personal data [4, 5]. Specifically, China’s\nData Security Law, Cybersecurity Law, and Personal Information Protection\nLaw establish the data graded protection obligations and define key concepts\nsuch as “important data” and “sensitive personal information” [6, 7, 8]. For cross-\nindustry implementation, GB/T 43697-2024 provides general rules, principles,\nand processes for data classification and grading, which are aligned with data\nattributes and sensitivity [9].\nIn healthcare, the national standard “Information Security Technology –\nGuide for Health Data Security” (GB/T 39725-2020) sets scenario-oriented rules\nthat divide health data into six categories (personal attributes, health status,\nmedical applications, medical payment, health resources and public health) and\nfive ascending sensitivity levels (1-5), lacking detailed and operational criteria for\nclassification and grading [10]. Moreover, GB/T 39725-2020 focuses primarily on\nelectronic medical record (EMR) security and offers limited guidance for online\nconversational health data. With the rise of Internet hospitals in China, health-\ncare delivery has been shifted from in-person visits to online consultations. The\nresulting online health data preserve original and conversational interactions be-\ntween patients and doctors, and commonly contain large amounts of protected\nhealth information (PHI). Accordingly, data classification and grading tailored\nto online medical services are urgently needed, with principled rules and practical\nprocedures.\nNatural language processing (NLP) is widely used for information-extraction\ntasks to discover critical knowledge in unstructured data [11]. In practice, work-\nflows rely on manual annotation to build gold-standard datasets and on named-\nentity recognition (NER) systems for automated entity identification. However,\nrule- and metadata-based NER depends on fixed rules and labeled data, limiting\nits capacity to capture complex contextual relationships and generalize to new\ndomains [12]. By contrast, accurate classification and grading critically depends\non context-aware understanding. For instance, data related to special diseases\n(e.g., sexually transmitted infections (STD), infectious disease) is graded as level\n5 under GB/T 39725-2020 [10]. In fact, patients may simply inquire about spe-\ncial diseases in online consultations, without actually having them. Assigning\n“level 5” labels to suspected or explicitly ruled-out mentions of special diseases is\ninappropriate. Recently, large language models (LLMs) have shown remarkable\nability to process diverse text and capture complex entity relationships through\ndeep context understanding and pre-trained knowledge. For instance, OpenAI’s\nChatGPT achieved passing grades in the United States Medical Licensing Exam-\ninations, evidencing its robust medical knowledge and reasoning [13, 14]. Recent\nresearches have revealed the potential of LLMs to identify private information\nin medical data. DeID-GPT, a medical text de-identification model based on\nGPT-4, has shown high accuracy and reliability in masking private information\n"}, {"page": 3, "text": "Title Suppressed Due to Excessive Length\n3\nwithin unstructured medical text [15]. The LLM-Anonymizer, developed using\nLlama-3 70B, demonstrates effective performance in removing personal identifi-\nable information from text [16].\nMotivated by the strong capabilities of LLMs, this study explores the LLM-\nbased methods for data classification and grading to address these challenges,\nespecially for online conversational health data. Our main contributions are as\nfollows.\n1. We conclude classification and grading rules for online conversational health\ndata, aligned with national laws and GB/T 39725-2020, addressing the ab-\nsence of unified standards for conversational health data sensitivity classifi-\ncation.\n2. We present, SALP-CG, a standard-aligned LLM pipeline for classifying and\ngrading online conversational health data, providing solutions to automated\nand rule-consistent data governance.\n3. We propose three metrics to evaluate the performance of SALP-CG across\nmultiple models, solving the lacking tailored evaluation measures for sensitivity-\naware entity extraction.\n4. We assess risks of sensitive information exposure from online conversational\nhealth data in the MedDialog-CN-2020 dataset, helping to quantify privacy\nrisks in real-world datasets.\n2\nRelated Work\nIn the literature, recent studies have increasingly explored the use of LLMs for\nprivacy protection in healthcare data.\nMedical Text De-identification. LLMs have been used to anonymize elec-\ntronic health records (EHRs). DeID-GPT uses GPT-4 to reliably mask PHIs\nin unstructured medical text, achieving high precision in de-identification tasks\n[15]. Similarly, the LLM-Anonymizer based on LLaMA-3 70B demonstrates the\nfeasibility of local deployment for privacy-preserving anonymization in clinical\nsettings [16]. As a framework, RedactOR combines rules with LLM inference to\nhandle both textual and audio clinical data [17]. These efforts highlight the po-\ntential of LLMs to outperform traditional rule-based or NER-based systems by\ncapturing nuanced context and reducing annotation burdens.\nUtility-Preserving Anonymization. Beyond de-identification, several stud-\nies address the challenge of balancing privacy with data utility. Yang et al. pro-\nposed a robust anonymization framework where LLMs act as both privacy and\nutility assessors, optimizing replacements to preserve downstream task perfor-\nmance [18]. Kim et al. introduced SEAL, a self-refining anonymization model\ntrained via adversarial distillation, enabling effective anonymization while trans-\nferring capabilities to smaller models [19]. Sarkar et al. explored hybrid ap-\nproaches that integrate synthetic text generation with selective anonymization,\nproviding more flexible privacy–utility trade-offs for clinical note sharing [20].\n"}, {"page": 4, "text": "4\nY. Yan et al.\nPrivacy Risks. In addition to protective mechanisms, researchers have ex-\namined the risks LLMs themselves introduce. Staab et al. argued that privacy\nviolations extend beyond memorization, as LLMs may infer sensitive attributes\nthrough contextual reasoning even when such attributes are not explicitly present\n[21]. This line of work underscores the limitations of current anonymization\nstrategies and calls for more robust safeguards against inference-based privacy\nleakage. Furthermore, DIRI is an LLM used to re-identify the patient in the\ndataset [22]. Xu et al. focus on the security of biomedical multimodal LLMs\nusing machine unlearning [23].\n3\nMethods\n3.1\nStandard-aligned Health Data Classification and Grading\nGB/T 39725-2020 defines “health data” as “personal health data and health-\nrelated electronic data obtained after processing personal health data”, which\ncan be divided into six categories: personal attributes, health status, medical\napplications, medical payment, health resource and public health [10]. Then,\nhealth data is recommended to be classified into five ascending sensitivity levels\nbased on privacy risk, with each level corresponding to specific restrictions and\ncontrol measures [10]:\n(a) Level 1 (Public data): Data openly available on the Internet. This data may\nbe fully used for public access.\n(b) Level 2 (General sensitivity data): Data that is not directly identifiable but\nmay still pose risks to public health interests. Access may be granted to a rel-\natively broad audience (e.g., for research or analysis by clinicians) following\napplication and approval.\n(c) Level 3 (relatively high sensitivity data): Data that may remain re-identifiable\neven after partial de-identification and could impact the work or daily life of\npatients and healthcare personnel. Access is limited to a defined group, such\nas an authorized project team.\n(d) Level 4 (High sensitivity data): Data that directly identifies an individual\nand could harm the interests of an institution or the data subject. Access\nis restricted to a small scope under strict controls, typically, to the relevant\nmedical staff.\n(e) Level 5 (Special disease data): Data detailing specific diseases (e.g., STD)\nthat could adversely affect public health interests or individual rights if dis-\nclosed. Access is permitted only to a very limited set of attending healthcare\nprofessionals and is subject to stringent safeguards.\nOn this basis, we concluded the classification and grading rules (Table 1) for\nhealth data with the assistance of the legal advisory team, referencing to the Data\nSecurity Law, Cybersecurity Law[22], Personal Information Protection Law[23],\nthe Administrative Measures for Internet Diagnosis and Treatment (Trial) and\nother three documents[24] [6, 7, 8, 24].\n"}, {"page": 5, "text": "Title Suppressed Due to Excessive Length\n5\nTable 1. Data Classification and Grading Rules for Online Conversational Health Data\nCategory\nSubcategory\nContent (examples; level mapping)\nLevel\nPersonal At-\ntribute Data\nDemographic\ninfo\nL4: patient name; address–house/village/township; family\nmember name; emergency contact; hobby; religion. L3:\npatient surname; gender; date of birth; age; employer;\noccupation; address–district. L2: month of birth; ethnicity;\nnationality; income; marital status; address–province/city.\n4/3/2\nID/Credit\nL4: ID card; work permit; residence permit; social-security\ncard; health card; phone number; email; bank account;\nAlipay; WeChat; inpatient card; driver’s license; vehicle\nplate; tax ID; IP; device ID; credit file/score/report.\n4\nHealth\nSta-\ntus Data\nDisease\nL5: special diseases (STD, infectious, psychiatric, ma-\nlignant, genetic, anorectal, rare, incurable). L2: disease;\ndisease–suspected; disease–ruled out.\n5/2\nVital signs\ntemperature; pulse; respiration; heart rate; blood pressure;\noxygen saturation; height; weight\n3\nGeneral clinical chief complaint; allergy history; family history; lifestyle\n2\nMedical Ap-\nplication\nData\nDate\nL3: date; L2: month, year\n3/2\nInternal identi-\nfiers\nL4: lab/imaging report ID; inpatient number; outpa-\ntient/emergency number; L3: bed number; ward number;\noperating room number\n4/3\nMedical service L4: doctor name; L3: doctor surname; L2: hospital; de-\npartment; ward\n4/3/2\nTest/exam\nL5: sensitive test result (e.g., HIV/hepatitis, HR-HPV+);\nL3: test/exam result; L2: test/exam name\n5/3/2\nMedication\nname; type; regimen; frequency; dose unit; single dose;\ntotal dose\n2\nSurgery\nsurgery name; anesthesia method\n2\nMedical Pay-\nment Data\nTransactions\nregistration fee; payment info; expenditure; transaction\nrecords\n3\nInsurance\naccount no.; status; insured amount\n4\nHealth\nRe-\nsource Data\nHospital\nbasic\ndata\norganization type; clinical disciplines; number of beds;\naddress; phone\n1\nHospital opera-\ntions\nHR; finance; supplies; logistics; infrastructure operations\n2\nPublic\nHealth Data\nPublic\nhealth\ndata\nenvironmental sanitation; outbreaks; surveillance; preven-\ntion; birth/mortality\n2\n3.2\nLLM-based Extraction Pipeline\nProblem Setup We consider a set of N patients and their online conversational\nhealth data X. We use a LLM fθ to produce, for each patient i ∈N, a sequence\nof Dij = (Pij, Cij, Lij), where Pij is the extracted PHI entity, Cij is its category\nand Lij ∈{1, 2, 3, 4, 5} is the assigned sensitivity level.\nWe are interested in LLMs to produce all Dij = (Pij, Cij, Lij) for patient i,\nremoving exact duplicates. Our goals are (i) to maximize recall of district PHI\nentities Pij present in Xi; (ii) enforce schema compliance so that each Cij ∈C,\nwhere C is the predefined category set; (iii) minimize level-assignment error for\nLij, with special emphasis on error-prone entities (e.g., special disease).\nLLM-based extraction pipeline To achieve the above goals, we developed\nan extraction pipeline, SALP-CG, a standard-aligned LLM pipeline for clas-\nsifying and grading. This pipeline combines (i) few-shot guidance, (ii) JSON\n"}, {"page": 6, "text": "6\nY. Yan et al.\nFig. 1. Information Extraction Pipeline for SALP-CG. The upper section represents\nthe structure of the pipeline, while the lower section demonstrates the implementation\nof classifying and grading online medical consultations.\nSchema-constrained output, and (iii) deterministic high-risk rules tailored for\nonline conversational health data. (Figure 1)\nSpecifically, at the generation layer, we prompt an instruction-tuned LLM\nwith a task description, classification and grading rules, few-shot exemplars,\nand a JSON Scheme. First, we set the model as a “clinical privacy extraction\nengine” that outputs JSON only (no prose), using short Chinese spans as entities.\nSecond, we specify the task, schema compliance, and grading rules for the model.\nThe task is to extract triples (P, C, L) from online conversational health data,\nwhich is (entity, category, level); the schema compliance is that field C must\nbe drawn from a predefined set; and the grading rules are concretely listed as\nwell as some key points. Third, the JSON schema enumerates all legal fields\nand constrains the level ∈[1, 5] via strict structured outputs, which yields near-\n"}, {"page": 7, "text": "Title Suppressed Due to Excessive Length\n7\nzero format errors and minimal post-editing. Fourth, we include 10 high-quality\nexemplars from a labeled corpus, covering common entities (general symptoms,\ndiseases, etc.), high-risk cases (special diseases, names, etc.), as well as negation\nand uncertainty edge cases.\nAt the rule layer, we applied deterministic high-risk rules that override the\nmodel when certain patterns are present. For instance, high-risk HPV geno-\ntypes (16/18/31/33/35/39/45/51/52/56/58/59/68/73/82) with “positive” will\nbe mapped to “Sensitive test result” (level 5). We also promote disease men-\ntions to “Special disease” (infectious disease, malignancy, genetic, reproduc-\ntive/STD, anal disease, rare disease, incurable) via curated regex lists. In con-\ntrast, suspected/ruled-out mentions are downgraded to level 2. Furthermore,\nthe orchestration layer handles long inputs by chunking and merging with de-\nduplication, sorting by risk level.\n4\nExperiments\n4.1\nDatasets\nMedDialog-CN-2020 We benchmark our method on MedDialog-CN (Zeng\net al., 2020), a large-scale collection of Chinese medical dialogues crawled from\nthe online consultation platform haodf.com [25]. The corpus spans from 2010\nto 2020, providing ID, URL, hospital, department, and description (including\ndescription, dialogue, Diagnosis, and suggestions, etc.) for each case. All patient\nnames were de-identified. The dialogues span 29 broad clinical specialties(e.g.,\ninternal medicine, pediatrics, dentistry) and 172 fine-grained specialties (e.g.,\nincluding cardiology, neurology, gastroenterology, urology). For our experiments,\nwe use only the 2020 subset of MedDialog-CN, comprising 69,550 cases.\n4.2\nImplementation Details\nWe generated synthetic names using the Python Faker library (Faraglia 2019),\nto complete missing patient names in the original dataset. Following the data\nclassification and grading rules (Table 1), a prompt including a task description,\nclassification and grading rules, few-shot exemplars, and a JSON Scheme was\nformulated. A total of 1,000 data entries were sampled from the entire dataset as\nbenchmarks. The data was both manually labeled according to the data classifi-\ncation and grading rules by a trained researcher and double-checked by another\nresearcher. The project was overseen by a team of other three researchers: one\nspecialized in law, one in medicine, and one in computer science. Any disagree-\nment in the procedure were resolved through discussion and voting. Among them,\n10 high-quality data from labeled corpus were chosen as few-shot exemplars.\nSince the extraction pipeline is designed to be backend-agnostic, we inter-\nfaced with multiple providers via HTTP API, including OpenAI, Groq, and\nDeepSeek. We created accounts on each platform, obtained API keys, and au-\nthenticated all requests against the providers’ official endpoints. The models\n"}, {"page": 8, "text": "8\nY. Yan et al.\nevaluated were gpt-4o-mini, gpt-5-nano, gpt-5-mini and gpt-5 in OpenAI; llama-\n3.1-8b-instant, llama-3.3-70b-versatile, qwen3-32b, kimi-k2-instruct-0905, and\nDeepSeek-R1-Distill-Llama-70B in Groq; and deepseek-chat in DeepSeek. In-\nput data were stored in an .xlsx file with a single column named Description,\nand few-shot exemplars were kept in a .jsonl file. After configuring run-time pa-\nrameters and submitting prompts to the selected backend, predicted extractions\nwere serialized and exported to .xlsx. The detailed implementation is available\non our GitHub https://github.com/dommii1218/SALP-CG.\n4.3\nEvaluation\nTo assess the performance of SALP-CG, choose four metrics for model eval-\nuation. For patient i, the golden set of tuples is Di = {(P, C, L)}, while the\npredicted set is ˆ\nDi = {( ˆP, ˆC, ˆL)}.\n(i) Mean Count Inflation Factor (MCIF) Mean Count Inflation Factor\n(MCIF) measures the predicted count of distinct entities D. An MCIF of 1\nindicates that the predicted count matches the gold standard. Values greater\nthan 1 indicate over-extraction (inflated counts), while values less than 1 indicate\nunder-extraction (deflated counts).\nMCIF =\n1\nN\nN\nX\ni=1\n| ˆ\nDi|\n|Di|\n(1)\n(ii) Mean Category-Compatibility Rate (MCCR) Mean Category-Compatibility\nRate (MCCR) evaluates whether the predicted category of each entity is com-\npatible with the predefined schema set.\nMMCR = 1\nN\nN\nX\ni=1\nP\nd∈b\nDi 1(Cij ∈C)\n| ˆ\nDi|\n(2)\n(iii) Mean Sensitivity Grading Quality (MSGR) Mean Sensitivity Grad-\ning Quality (MSGR) measures the accuracy of sensitivity levels, L ∈{3, 4, 5}.\nMSGQ =\nP\ni #{(p, c) ∈Si : bLi(p, c) = Li(p, c)}\nP\ni |Si|\n(3)\n, where Si = {(p, c) ∈Mi : Li(p, c) ∈{3, 4, 5} ∪ˆLi(p, c) ∈{3, 4, 5}}\n(iv) Micro-F1 Additionally, the Micro-F1 score evaluates the correctness of\neach record’s maximum sensitivity level by casting it as a 5-class classification\ntask (levels 1–5).\n"}, {"page": 9, "text": "Title Suppressed Due to Excessive Length\n9\nF1micro = 2 Pmicro Rmicro\nPmicro + Rmicro\n(4)\nwhere TP = P\nℓTPℓ, FP = P\nℓFPℓ, FN = P\nℓFNℓ, Pmicro =\nT P\nT P +F P ,\nRmicro =\nT P\nT P +F N\nBy using the 1000 labeled data as benchmarks, we compared the results\nproduced by 10 LLMs, including gpt-4o-mini, gpt-5-nano, gpt-5-mini, gpt-5,\nllama-3.1-8b-instant, llama-3.3-70b-versatile, qwen3-32b, kimi-k2-instruct-0905,\nDeepSeek-R1-Distill-Llama-70B, and deepseek-chat. Ablation study for SALP-\nCG was conducted to show the degrees of performance degradation for each com-\nponent. Error analysis was performed to examine incorrect predictions generated\nby various LLMs. Moreover, we conducted a quantitative analysis to assess the\nsensitive information exposures in the 1,000-sample online medical consultation\ndataset. Records were stratified by category and sensitivity levels, and the over-\nall distribution (top 10 categories for each sensitivity level) was visualized with\na histogram. The data generation and analysis were conducted using Microsoft\nExcel 2021 and Python 3.11.13.\n4.4\nExperimental Results and Analysis\nLLM Methods Comparison We evaluated SALP-CG across multiple LLMs\n(e.g., gpt-4o-mini, gpt-5-nano, gpt-5-mini, gpt-5, etc.) using four metrics: MCIF,\nMCCR, MSGR, and micro-F1. Overall, all models performed well under the\npipeline. The result indicates that SALP-CG is backend-agnostic and generalizes\nwell across divers LLMs, which may also generalizes to other domains. (Table 2)\n1. Entity count inflation (MCIF): DeepSeek-R1-Distill-Llama-70B is the\nclosest to 1 (0.063, |∆| = 0.063), followed by kimi-k2-instruct-0905 (0.929, |∆| =\n0.071) and deepseek-chat (1.073, |∆| = 0.073), suggesting balanced recall and\nhallucination. gpt-4o-mini (0.811) and gpt-5-nano (0.869) tend to under-\nextract, whereas gpt-5-mini (1.282) and gpt-5 (1.162) tend to over-extract.\n2. Schema category compliance (MCCR): Scores are uniformly high (≥\n0.984), with llama-3.1-8b-instant achieving 1.000, suggesting that the JSON-\nSchema constraint effectively normalizes categories.\n3. Sensitivity-level accuracy (MSGR): gpt-4o-mini (0.995) tops the list,\nseveral others are ≥0.970. llama-3.1-8b-instant (0.866) lags, likely reflecting\nits smaller parameter count. The over MSGR supports our design choice of\ndeterministic high-risk rules.\n4. Maximum level correctness (Micro-F1): gpt-5-mini and gpt-5 both\nreach 0.900. deepseek-chat (0.880), qwen3-32b (0.840) and kimi-k2-instruct-\n0905 (0.830) are competitive. llama-3.1-8b-instant (0.640) and llama-3.3-70b-\nversatile (0.670) are notably lower, indicating difficulties in picking the max-\nimum level correctly for each record.\n"}, {"page": 10, "text": "10\nY. Yan et al.\nTable 2. Performance of LLMs. MCIF, MCCR, MSGR, Micro-F1 of various LLMs\n(e.g. gpt-4o-mini, gpt-5-nano, gpt-5-mini, gpt-5, etc.) on the 1000 labeled data were\ncompared.\nNo. Model\nMCIF MCCR MSGR Micro-F1\n1\ngpt-4o-mini\n0.811\n0.976\n0.995\n0.890\n2\ngpt-5-nano\n0.869\n0.992\n0.993\n0.720\n3\ngpt-5-mini\n1.282\n0.984\n0.990\n0.900\n4\ngpt-5\n1.162\n0.991\n0.984\n0.900\n5\nllama-3.1-8b-instant\n0.917\n1.000\n0.866\n0.640\n6\nllama-3.3-70b-versatile\n0.909\n0.995\n0.973\n0.670\n7\nqwen3-32b\n1.082\n0.991\n0.978\n0.840\n8\nkimi-k2-instruct-0905\n0.929\n0.997\n0.990\n0.830\n9\nDeepSeek-R1-Distill-Llama-70B 1.063\n0.997\n0.987\n0.680\n10\ndeepseek-chat\n1.073\n0.997\n0.989\n0.880\nAblation Study The ablation results show that removing each component\nleads to distinct performance degradation. We evaluate the contributions of key\ncomponents in SALP-CG, including (i) few-shot guidance (row 2), (ii) JSON\nSchema constrained output (row 3), (iii) deterministic high-risk rule (row 4),\nand their combinations (row 5). Specifically, removing few-shot yields the largest\ndrops of 0.344 in MCIF and 0.560 in micro-F1 score, suggesting that few-shot\nis the primary driver of recall and over-reliability. Removing schema makes the\nmodel less disciplined, while MCCR decreases 0.165, showing that schema con-\nstrain chiefly secure category correctness. Removing rules mainly affects high-\nrisk grading and max-level accuracy, with 0.030 lower MSGR and 0.070 lower\nmicro-F1. Zero-shot, no-schema, no-rules setting performs worst overall. (Table\n3)\nTable 3. Ablation over pineline on 1,000-sample benchmark using gpt-4o-mini. Per-\nformance of MCIF, MCCR, MSGR, and Micro-F1 for multiple ablation cases on the\n1000 labeled data was compared.\nNo. Model\nMCIF MCCR MSGR Micro-F1\n1\nFull (Few-shot+Schema+Rules) 0.811\n0.976\n0.995\n0.890\n2\nw/o Few-shot\n0.477\n0.976\n0.986\n0.330\n3\nw/o Schema\n0.951\n0.811\n0.995\n0.810\n4\nw/o Rules\n0.811\n0.975\n0.965\n0.820\n5\nZero (none)\n0.555\n0.902\n0.981\n0.430\nError Analysis We conducted an error analysis by examining the incorrect pre-\ndictions across models. First, extraction errors depress MCIF, including missed\nentities (e.g., “HPV16” embedded in a longer clause, expressed using synonyms\nand abbreviations) and over-extraction of generic phrases. Second, category as-\nsignment errors reduce MCCR, most commonly confusing test/exam name vs.\nresults, and full name vs. surname. Third, sensitivity grading errors affect MSGR\nand micro-F1, while uncertain and ruled-out special diseases are graded as Level\n"}, {"page": 11, "text": "Title Suppressed Due to Excessive Length\n11\n5; missed upgrades for sensitive positive results (e.g., High-risk HPV genotypes\nwith positive); and date granularity is misread (day vs. month). Overall, most\nerrors arise from boundary cases (negation/uncertainty disease, long-distance\ncontext, and label granularity) rather than instruction following issues.\nCategory Landscape by Sensitivity Levels The primary factors contribut-\ning to Level 2 categories in online conversational health data were “Chief com-\nplaint” (3, 536, 30.75%) and “Medication Name” (1, 385, 12.05%). For Level 3\ncategories, the most common health data were “Date” (1, 385, 12.05%), “Test/exam\nresult” (1, 191, 46.34%), and “Age” (737, 28.68%), collectively accounting for al-\nmost 70%. The most influential factor for Level 4 categories was “Patient’s name”\n(79, 44.13%) and “Doctor’s name” (75, 41.90%), which can directly identify in-\ndividuals. For Level 5 categories, the most significant contributing factors were\n“Special disease” including (235, 12.05%) (e.g., infectious disease, STD, malig-\nnancy, psychiatric disorder, anal disease, genetic disease, and rare disease ), and\n“Sensitive test result” (17, 6.75%)(e.g., HPV positive, HPV16 positive). (Figure\n2)\nThe sensitivity level distribution is dominated by Level 2 (general sensitivity)\nand Level 3 (relatively high sensitivity) items, which may appear innocuous in\nisolation but can be combined and cross-linked to re-identify individuals from\nfragmented information [26]. For instance, date (L3) and hospital/department\n(l2) can be pieced to clinic schedules about visits on that day. DIRI, an LLM\nto re-identify the patient, can be further used to explore potential combinations\n[22]. Although the proportions of data at Level 4 (high sensitivity) and Level 5\n(special diseases) were relatively small, their impact is outsized. When leaked on\nthe Internet hospital contexts, a few pieces can harm patients in practical ways\n[29]. Direct identifiers are rare in the MedDialog dataset, with all patient names\nde-identified[30]. However, special disease signals (e.g., HIV/STD, malignancy,\npsychiatric disorders, genetic and rare diseases, anorectic disease) and sensitive\ntest results can cause stigma, social exclusion, relationship strain, employment\nscreening or subtle workplace discrimination, housing discrimination, higher in-\nsurance underwriting or exclusions, targeted scams, and potential blackmail for\npatients.\nIn summary, by combining few-shot guidance, JSON Schema-constrained\noutput, and deterministic high-risk rules, SALP-CG delivers high category dis-\ncipline and stable level assignment across diverse LLMs. Most models sustain\nhigh MCCR and MSGR, while the stronger models reach micro-F1 up to 0.90\nfor maximum-level prediction. This design thus balances precision, recall, and\ngovernance needs under real-world constraints. Furthermore, the distribution\nof health data stratified by sensitivity level highlights the sensitive information\nrisks for online conversational health data. Although Level 4-5 items are less fre-\nquent, they can cause outsize harms, while seemingly Level 2-3 items can enable\nre-identification when combined.\n"}, {"page": 12, "text": "12\nY. Yan et al.\nFig. 2. Top 10 terms of health data stratified by sensitivity on 1000 labeled data.\n5\nConclusion and Future Work\nThis study presents a practical and standards-aligned pipeline, SALP-CG, for\nclassifying and grading risks in online conversational health data. We summarize\nhealth data classification and grading rules, aligned with the GB/T 39725-2020.\nCombining few-shot guidance, JSON schema-constrained output, and determin-\nistic high-risk rules, this extration pipeline achieves strong category compli-\nance and reliable sensitivity grading across diverse LLMs on the MedDialog-CN\nbenchmark. The stratification of health data by sensitivity level demonstrates\nthe risks associated with sensitive information. The findings emphasize the ne-\ncessity and feasibility of LLM-based data classification and grading for future\ndata governance and circulation.\nIn future work, we intend to improve SALP-CG by dealing with some limi-\ntations. First, our benchmark concentrates on a single language, platform, and\ntime period, with extension to a broader dataset. Second, the primary concern\nof this study is the risk of individual re-identification, requiring more considera-\ntion of actual harms to personal life, such as employment or marriage. Third, as\n"}, {"page": 13, "text": "Title Suppressed Due to Excessive Length\n13\npatient data are often stored within hospital intranet environments, open-source\nLLMs with local deployment capabilities may offer a practical solution.\nReferences\n[1]\nJunaid Bajwa et al. “Artificial intelligence in healthcare: transforming the\npractice of medicine”. In: Future healthcare journal 8.2 (2021), e188–e194.\n[2]\nKaiYu Wan and Vangalur Alagar. “Characteristics and classification of\nbig data in health care sector”. In: 2016 12th International Conference on\nNatural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-\nFSKD). IEEE. 2016, pp. 1439–1446.\n[3]\nAmen Faridoon and M Tahar Kechadi. “Healthcare data governance, pri-\nvacy, and security-a conceptual framework”. In: EAI International Confer-\nence on Body Area Networks. Springer. 2024, pp. 261–271.\n[4]\nLatanya Sweeney et al. “Re-identification Risks in HIPAA Safe Harbor\nData: A study of data from one environmental health study”. In: Technol-\nogy science 2017 (2017), p. 2017082801.\n[5]\nFormerly Data Protection. “General data protection regulation (GDPR)”.\nIn: Intersoft Consulting, Accessed in October 24.1 (2018).\n[6]\nJihong Chen and Jiabin Sun. “Understanding the chinese data security\nlaw”. In: International Cybersecurity Law Review 2.2 (2021), pp. 209–221.\n[7]\nRogier Creemers. “Cybersecurity law and regulation in China: Securing\nthe smart state”. In: China Law and Society Review 6.2 (2023), pp. 111–\n145.\n[8]\nIgor Calzada. “Citizens’ data privacy in China: The state of the art of the\nPersonal Information Protection Law (PIPL)”. In: Smart Cities 5.3 (2022),\npp. 1129–1150.\n[9]\nChina Information Security Standardization Technical Committee. Data\nSecurity Technology—Rules for Data Classification and Grading (GB/T\n43697-2024). 2024.\n[10]\nStandardization Administration of China. Information Security Technology\n- Guide for Health Data Security (GB/T 39725-2020). 2020.\n[11]\nShervin Malmasi et al. “Extracting healthcare quality information from\nunstructured data”. In: AMIA Annual Symposium Proceedings. Vol. 2017.\n2018, p. 1243.\n[12]\nSomayeh Ghaffari Heshajin et al. “A framework for health information\ngovernance: a scoping review”. In: Health Research Policy and Systems\n22.1 (2024), p. 109.\n[13]\nTiffany H Kung et al. “Performance of ChatGPT on USMLE: potential\nfor AI-assisted medical education using large language models”. In: PLoS\ndigital health 2.2 (2023).\n[14]\nHarsha Nori et al. “Capabilities of gpt-4 on medical challenge problems”.\nIn: arXiv preprint arXiv:2303.13375 (2023).\n[15]\nZhengliang Liu et al. “Deid-gpt: Zero-shot medical text de-identification\nby gpt-4”. In: arXiv preprint arXiv:2303.11032 (2023).\n"}, {"page": 14, "text": "14\nY. Yan et al.\n[16]\nIsabella C Wiest et al. “Anonymizing medical documents with local, pri-\nvacy preserving large language models: The LLM-Anonymizer”. In: medRxiv\n(2024), pp. 2024–06.\n[17]\nGeon Heo and Steven Euijong Whang. “Redactor: A data-centric and indi-\nvidualized defense against inference attacks”. In: Proceedings of the AAAI\nConference on Artificial Intelligence. Vol. 37. 12. 2023, pp. 14874–14882.\n[18]\nTianyu Yang, Xiaodan Zhu, and Iryna Gurevych. “Robust utility-preserving\ntext anonymization based on large language models”. In: arXiv preprint\narXiv:2407.11770 (2024).\n[19]\nKyuyoung Kim, Hyunjun Jeon, and Jinwoo Shin. “Self-Refining Language\nModel Anonymizers via Adversarial Distillation”. In: arXiv preprint arXiv:\n2506.01420 (2025).\n[20]\nBikash Kanti Sarkar and Shib Sankar Sana. “A hybrid approach to design\nefficient learning classifiers”. In: Computers & Mathematics with Applica-\ntions 58.1 (2009), pp. 65–73.\n[21]\nRobin Staab et al. “Beyond memorization: Violating privacy via inference\nwith large language models”. In: arXiv preprint arXiv:2310.07298 (2023).\n[22]\nJohn X Morris et al. “Diri: Adversarial patient reidentification with large\nlanguage models for evaluating clinical text anonymization”. In: AMIA\nSummits on Translational Science Proceedings 2025 (2025), p. 355.\n[23]\nDunyuan Xu et al. “From Learning to Unlearning: Biomedical Security\nProtection in Multimodal Large Language Models”. In: arXiv preprint\narXiv:2508.04192 (2025).\n[24]\nNational Health Commission, National Administration of Traditional Chi-\nnese Medicine, and National Administration of Disease Control and Pre-\nvention. The Administrative Measures for Internet Diagnosis and Treat-\nment (Trial) and Other Three Documents. 2023.\n[25]\nXuehai He et al. “Meddialog: Two large-scale medical dialogue datasets”.\nIn: arXiv preprint arXiv:2004.03329 (2020).\n[26]\nCJ Carey et al. “Measuring re-identification risk”. In: Proceedings of the\nACM on Management of Data 1.2 (2023), pp. 1–26.\n"}]}