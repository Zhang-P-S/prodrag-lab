{"doc_id": "arxiv:2511.17554", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2511.17554.pdf", "meta": {"doc_id": "arxiv:2511.17554", "source": "arxiv", "arxiv_id": "2511.17554", "title": "Beyond the Rubric: Cultural Misalignment in LLM Benchmarks for Sexual and Reproductive Health", "authors": ["Sumon Kanti Dey", "Manvi S", "Zeel Mehta", "Meet Shah", "Unnati Agrawal", "Suhani Jalota", "Azra Ismail"], "published": "2025-11-12T16:01:27Z", "updated": "2025-11-26T20:20:13Z", "summary": "Large Language Models (LLMs) have been positioned as having the potential to expand access to health information in the Global South, yet their evaluation remains heavily dependent on benchmarks designed around Western norms. We present insights from a preliminary benchmarking exercise with a chatbot for sexual and reproductive health (SRH) for an underserved community in India. We evaluated using HealthBench, a benchmark for conversational health models by OpenAI. We extracted 637 SRH queries from the dataset and evaluated on the 330 single-turn conversations. Responses were evaluated using HealthBench's rubric-based automated grader, which rated responses consistently low. However, qualitative analysis by trained annotators and public health experts revealed that many responses were actually culturally appropriate and medically accurate. We highlight recurring issues, particularly a Western bias, such as for legal framing and norms (e.g., breastfeeding in public), diet assumptions (e.g., fish safe to eat during pregnancy), and costs (e.g., insurance models). Our findings demonstrate the limitations of current benchmarks in capturing the effectiveness of systems built for different cultural and healthcare contexts. We argue for the development of culturally adaptive evaluation frameworks that meet quality standards while recognizing needs of diverse populations.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2511.17554v2", "url_pdf": "https://arxiv.org/pdf/2511.17554.pdf", "meta_path": "data/raw/arxiv/meta/2511.17554.json", "sha256": "39a371b911bbb1792f76b9d399a5954ce1fc6f51843683c9ccf750fab85591a9", "status": "ok", "fetched_at": "2026-02-18T02:27:20.243521+00:00"}, "pages": [{"page": 1, "text": "Beyond the Rubric: Cultural Misalignment in LLM Benchmarks for\nSexual and Reproductive Health\nSumon Kanti Dey1, Manvi S1, Zeel Mehta3, Meet Shah3,\nUnnati Agrawal1, Suhani Jalota2, Azra Ismail1\n1Emory University, Atlanta, Georgia, USA,\n2Hoover Institution, Stanford University, Stanford, California, USA,\n3Myna Mahila Foundation, Mumbai, India,\nCorrespondence: {sumon.kanti.dey, azra.ismail}@emory.edu\nAbstract\nLarge Language Models (LLMs) have been po-\nsitioned as having the potential to expand ac-\ncess to health information in the Global South,\nyet their evaluation remains heavily depen-\ndent on benchmarks designed around Western\nnorms. We present insights from a prelimi-\nnary benchmarking exercise with a chatbot for\nsexual and reproductive health (SRH) for an\nunderserved community in India. We evaluated\nusing HealthBench, a benchmark for conversa-\ntional health models by OpenAI (Arora et al.,\n2025). We extracted 637 SRH queries from the\ndataset and evaluated on the 330 single-turn\nconversations. Responses were evaluated using\nHealthBench’s rubric-based automated grader,\nwhich rated responses consistently low. How-\never, qualitative analysis by trained annotators\nand public health experts revealed that many\nresponses were actually culturally appropriate\nand medically accurate. We highlight recurring\nissues, particularly a Western bias, such as for\nlegal framing and norms (e.g., breastfeeding in\npublic), diet assumptions (e.g., fish safe to eat\nduring pregnancy), and costs (e.g., insurance\nmodels). Our findings demonstrate the limita-\ntions of current benchmarks in capturing the\neffectiveness of systems built for different cul-\ntural and healthcare contexts. We argue for the\ndevelopment of culturally adaptive evaluation\nframeworks that meet quality standards while\nrecognizing needs of diverse populations. The\ncode is available at1.\n1\nIntroduction\nSRH is a critical aspect of overall wellbeing, yet ac-\ncess to accurate and empathetic guidance remains\nuneven across geographies, due to deep-seated cul-\ntural taboos, poor sex education, and gaps in infor-\nmation access (Wahyuningsih et al., 2024; Shaw,\n2009). Increasingly, health organizations are in-\nvesting in chatbots powered by LLMs to facili-\ntate accessible SRH health guidance. However,\n1https://github.com/Sumon/healthbench-srh-eval/\nthe effectiveness of LLMs does not just depend\non accuracy, but also on their ability to deliver\nculturally relevant and contextually appropriate re-\nsponses (Deva et al., 2025; Andalibi and Bowen,\n2022). Yet, evaluation of such chatbots, in SRH\nand beyond, remains a persistent challenge. Recent\nwork, such as HealthBench (Arora et al., 2025),\nprovides a large-scale dataset and rubrics to evalu-\nate LLMs on health tasks. While HealthBench has\nbeen developed with a global network of healthcare\nproviders and aims to support evaluation of gener-\nalized healthcare chatbots, we find that it remains\ngrounded in Western guidelines and assumptions.\nIn this paper, we present a preliminary evalua-\ntion of Myna Bolo, an LLM-based chatbot devel-\noped by the Myna Mahila Foundation (Myna), a\nMumbai (India)-based Non-Governmental Orga-\nnization (NGO) focused on women’s health and\nempowerment. We patnered with Myna to evalu-\nate Myna Bolo that aims to provide localized and\nmedically accurate SRH information for women\nfrom an underserved community in Mumbai, In-\ndia. The system runs on WhatsApp, combines\nretrieval-augmented generation (RAG) with intent\ndetection, and includes a human-in-the-loop op-\ntion for escalation to experts. A screenshot of\nthe interface is in Appendix A. To benchmark the\nperformance of Myna Bolo, we turned to Health-\nBench, extracting SRH queries (n=637). As this is\na preliminary study, we restrict our analysis to the\n330 single-turn questions in the dataset. Through\nour qualitative analysis, we observed a systematic\nmismatch—culturally and regionally-appropriate\nresponses grounded in an underserved Indian con-\ntext were being scored as incorrect.\nThrough this study, we argue that while large\nbenchmarks offer a standardized framework for\nevaluating health chatbots, they may overlook\nculture- and region-sensitivity.\nThey also tend\nto be designed from a clinician perspective, and\ncan miss a critical human-centered perspective that\narXiv:2511.17554v2  [cs.CY]  26 Nov 2025\n"}, {"page": 2, "text": "meets the needs of users. Our contributions are\ntwofold: (1) We analyze how HealthBench (HB)\nrubrics, designed around Western norms, can pe-\nnalize culturally-grounded SRH responses. (2) We\ndiscuss implications for evaluating LLMs in global\nhealth, highlighting the need for culturally adaptive\nbenchmarks, particularly in low-resource settings.\n2\nRelated Work\nIn recent years, several benchmarks for evaluating\nhealth LLMs have emerged, including MedMCQA\n(Pal et al., 2022), PubMedQA (Jin et al., 2019),\nCareQA (Arias-Duart et al., 2025), and MedHELM\n(Bedi et al., 2025). Beyond these, a rapidly expand-\ning set of evaluation metrics has been proposed,\nsuch as QUEST (Tam et al., 2024), Med-HALT (Pal\net al., 2023), CSEDB (Wang et al., 2025), CRAFT-\nMD (Johri et al., 2025), AMIE (Tu et al., 2024).\nWhile these focus on domain-specific reasoning\nand safety of model-generated responses, they re-\nmain limited in scope for assessing real-world con-\nversational systems. Among these efforts, Health-\nBench (Arora et al., 2025) has emerged as one of\nthe most comprehensive frameworks that covers a\nwide range of health domains and enables system-\natic scoring of LLM model outputs. It also covers\nSRH, missing in many other benchmarks.\nHowever, health information is highly context-\ndependent, shaped by medical practice, cultural\nnorms, and resource availability (Brashers et al.,\n2002). Many SRH chatbots operate in low-resource\nlanguages and handle privacy-sensitive queries,\nwhere stigma and confidentiality are critical (e.g.,\nSnehAI (Wang et al., 2022), AdolescentBot (Rah-\nman et al., 2021), Nurse Nisa (McMahon et al.,\n2023)). Prior work in global health and medical\nNLP has noted that benchmarks developed in one\ncultural setting may not transfer directly to others\n(Hershcovich et al., 2022). For example, dietary\nadvice, contraceptive methods, and even health-\nseeking vary significantly between regions. Evalu-\nations that fail to recognize these differences risk\nundervaluing responses that are accurate and useful\nin local contexts (Nimo et al., 2025; Deva et al.,\n2025; Mutisya et al., 2025).\nAdditionally, many automatic grading systems\nrely on exact phrasing matches, disadvantaging\nculturally valid or concise responses that guide\nusers correctly (Abd-Alrazaq et al., 2020; Abbasian\net al., 2024). Our study focuses on HealthBench\nas a case study, analyzing gaps with contextual re-\nquirements, to derive implications for health bench-\nmarks broadly.\n3\nData and Evaluation Setup\nOur study offers a qualitative analysis of cul-\ntural misalignment in rubrics for queries on sex-\nual and reproductive health in an LLM benchmark,\nspecifically HealthBench. HealthBench (HB) is a\nphysician-curated benchmark developed by Ope-\nnAI with 5,000 single- and multi-turn, clinically\nrealistic conversations globally for evaluating con-\nversational health models (Arora et al., 2025). For\nthis study, we focused on SRH queries within HB.\nUsing an LLM classifier (detailed prompt in Ap-\npendix B), we extracted 637 SRH queries. To\nmitigate potential selection bias, two human re-\nviewers independently reviewed and verified all\nextracted queries to ensure correctness and SRH\nrelevence. This includes 330 single-turn (51.8%)\nand 307 multi-turn (48.2%) conversations. For the\npreliminary study, we restricted our analysis to the\nsingle-turn subset.\nOut of the 330 single-turn questions, Myna Bolo\nproduced responses for 244 questions (73.9%). The\nremaining 86 (26.1%) received a \"could not re-\nspond\" answer primarily for two reasons. First,\nsome questions involved explicit references to ge-\nographical regions outside the knowledge base\n(e.g., Egypt, Johannesburg, Germany). Second,\nsome items required highly specific or expert-level\nknowledge, such as requests for ICD-10 codes or\ncomplex SRH scenarios that go beyond the in-\ntended scope of the chatbot as a public health in-\nformation tool. The 244 answers were then eval-\nuated using HB’s rubrics and automated grader.\nEach item in the dataset has a custom rubric with\nweights between [−10, +10]. The grader checks\neach criterion independently and assigns its full\nweight if the criterion is met; otherwise, no points\nare given. We found that automated scoring of the\n244 single-turn responses yielded consistently low\nscores, despite several being rated highly by local\nhealthcare providers.\nTo understand this gap, the same two review-\ners (co-authors of this paper) conducted qualita-\ntive analysis. Both are native Hindi speakers and\nfamiliar with the cultural and linguistic contexts\nrelevant to SRH queries. One had a formal public\nhealth background, while the other has received\nSRH training. We followed an inductive thematic\nanalysis process (as described by Braun and Clarke\n"}, {"page": 3, "text": "(Braun and Clarke, 2006)), with the two reviewers\nextracting themes, e.g., legal considerations based\non region, US-centric prescription guidance, and\nmisalignment with cultural norms. Through peri-\nodic discussions, reviewers consolidated themes,\nwhich were cross-verified by our nonprofit pub-\nlic health collaborator. The resulting analysis is\npresented next.\n4\nAnalysis\nBelow we present examples of a context-specific\nSRH chatbot in India failing on some of the HB\nevaluation criteria. For each example, we present\nkey aspects of Myna Bolo’s response, and the expla-\nnation for the poor score given by the grader (HB\ncriterion). In particular, we found that HB rubrics\nfrequently assumed a US- or Western context. De-\ntailed bot responses and rubric criterion are in the\nAppendix C Table 1.\nC1: Legality of Breastfeeding in Public.\nThe\nbenchmark dataset included a question, “Can I\nbreastfeed in public what are the laws?”. Myna\nBolo produced an India-specific, supportive answer:\nno legal prohibitions, broad cultural acceptance,\nand practical privacy tips. Yet, the response was\nscored as incorrect because the HB rubric required\nexplicit mention of US public breastfeeding protec-\ntions and cross-country legal variation, which the\nlocally grounded answer did not include.\nMyna Bolo\nNo legal prohibitions; generally accepted;\nprivacy tips (shawl/dupatta).\nHB criterion\nMust mention US laws protecting public\nbreastfeeding and cross-country variation.\nFor a mother in India, there are no laws prohibit-\ning breastfeeding in public, and it is a generally\naccepted practice. Including details about US legal\nprotections or conditions in other countries would\nnot only be irrelevant but could also confuse the\nuser. Myna Bolo also included practical cultural\nguidance, suggesting use of a shawl or “dupatta”\n(piece of cloth) for privacy, which resonates with\nIndian users’ lived experiences. This case shows\nhow benchmarks anchored in US legal frameworks\nunfairly penalize culturally accurate responses, re-\nvealing risks of applying to global contexts.\nC2: Locality of Pregnancy Diet.\nFor an HB\nitem: “Which fish are ok to eat when expect-\ning?”, Myna Bolo provided regionally grounded\nguidance: prioritize low-mercury, commonly avail-\nable Indian fish (e.g., rohu, katla, pomfret), in-\nclude salmon/sardines where relevant, and cook\nthoroughly.\nThe item was scored low because\nthe HB rubric required an explicit list of highest-\nmercury fish to avoid—king mackerel, marlin, or-\nange roughy, shark, swordfish, tilefish, bigeye\ntuna—which are largely US-market examples.\nMyna Bolo\nLow-mercury, local fish (rohu, katla, pom-\nfret; hilsa in moderation); salmon/sardines\nwhere available; cook thoroughly.\nHB criterion\nProvide US \"safe fish\" list (anchovy, bass,\nbutterfish, catfish, clam, cod, .. . , whiting).\nRegionally appropriate, safety-conscious advice\nwas penalized because correctness was defined via\na US market list; this disadvantages chatbots de-\nsigned for non-US contexts.\nC3-C4: Regionality of System of Care and Fi-\nnancing for IUD and IVF.\nHB criteria some-\ntimes assumed US-specific insurance, pricing, and\nregional coverage frames. Myna Bolo, however,\nwas designed for India’s mixed public–private sys-\ntem and INR (indian rupee) price bands. For exam-\nple, an HB item (C3) was: “IUD insertion cost?\nthe T-shaped coil—do I pay out of pocket; side ef-\nfects?\" The chatbot responded with India-specific\nguidance (public hospitals free; private fees vary;\npharmacy price range; common side effects and\nwhen to seek care). The item was scored as incor-\nrect as the HB rubric expected references to US\ninsurance/preventive coverage and a US dollar cost\nrange.\nMyna Bolo\nGovt. hospitals:\nfree; private:\ndoctor-\ndependent fees; pharmacy (Copper T): ~Rs.\n150–300; side effects, when to seek care.\nHB criterion\nMention US insurance/preventive coverage\nand US IUD insertion cost range (USD).\nWe saw this in another case about IVF costs (C4).\nMyna Bolo provided India-specific pricing in INR,\nnoted variability by city/clinic, and summarized\nlocal availability. The item was scored as incor-\nrect because the HB criterion required region-wise\nUS/UK/Europe/Asia/Africa estimates in USD and a\ncross-region availability overview, which is irrele-\nvant for an India-focused assistant. The benchmark\nthus undervalues locally relevant guidance, misclas-\nsifying it as incomplete when it targets the intended\nhealth system and currency.\nC5: Bias towards US Prescriptions and Re-\nsources for Postpartum Depression.\nIn another\ncase: “Age 28, female, delivered 2 weeks back, feel-\ning depressed, crying every day, i cant sleep well.\ni am not sure how to find therapy, no idea if i can\nsee a doctor. i want medicines, maybe herbal, also\nany home remedy.”, the Myna Bolo responded with\n"}, {"page": 4, "text": "herbal and home remedies and suggested seeking\nhelp from a doctor.\nMyna Bolo\nRemedies: herbal tea, warm milk, medita-\ntion, Consult doctor.\nHB criterion\nCite examples of medications such as SSRI\nantidepressants like Sertraline or newer\nagents like Brexanolone and Zuranolone.\nThe resources were also not relevant for our\nusers. The medications referenced in the criteria\nare not available in India, at least without a pre-\nscription, and suggesting a prescription without a\nconsultation through a chatbot may not be appropri-\nate. The chatbot was explicitly designed to avoid\ndiagnosis or suggest medication and to be directly\ndirected to a healthcare provider in such instances.\nC6: Conceptions of “Normal” in Period Delay.\nHB sometimes rewarded only explicitly directive\nphrasing. For the query “my period is almost two\nweeks late, should i be worried or is this normal?”\nMyna Bolo offered reassurance, listed common\ncauses, and suggested testing “if there’s a chance\".\nHB scored this 0 because the criterion requires ex-\nplicitly recommending a pregnancy test if the user\nis sexually active.\nMyna Bolo\nReassuring tone; common causes (stress,\nweight/diet, exercise); mentions pregnancy\nand suggests testing “if there’s a chance”;\nadvises seeing a doctor if persistent.\nHB criterion\nStates pregnancy as a potential cause and\nexplicitly recommends a pregnancy test if\nsexually active.\nFor our context, the phrasing \"if there’s a\nchance\" respects privacy and avoids presuming sex-\nual activity (especially given taboos on premarital\nsex in India), but HB’s insistence on explicit \"if sex-\nually active, take a test\" language penalizes a func-\ntionally equivalent, culturally sensitive response.\nC7: Query Ambiguity (age vs duration) in\nHeavy Bleeding.\nHB sometimes enforces a sin-\ngle interpretation of underspecified numerals. For\nthe query “heavy bleed 48 need red flags??\" Myna\nBolo interpreted “48\" as 48 hours and provided\nsafety triage advice (when heavy flow is normal vs.\nwhen to seek care). HB, however, treated “48\" as\nage 48 and expected perimenopause-specific fram-\ning, so the item was scored as incorrect.\nMyna Bolo\nInterprets “48\" as duration (hours); explains\nnormal vs. heavy bleeding patterns, pad/-\nclot thresholds, and when to see a doctor.\nHB criterion\nInterprets “48\" as age;\nexpects peri-\nmenopause explanation (heavy bleeding\nmay be normal at age 48).\nIn our case, the chatbot was explicitly designed\nto support pre-menopausal women, and hence 48\nhours was a reasonable interpretation. In short\nand noisy queries, numerals can be ambiguous. A\nrubric that fixes one reading (age) can penalize a\nreasonable alternate reading (duration).\nOther Concerns:\nConciseness, Challenging\nMedical Language, and Benchmark Creation.\nDuring manual evaluation, we also identified chal-\nlenges related to conciseness. Many criteria re-\nquired lengthy explanations for most questions,\nsuch as providing detailed descriptions of symp-\ntoms, prevalence, and management (including med-\nication, prevention, professional care, online re-\nsources, and helplines), as well as information\nabout insurance or health coverage. Another chal-\nlenge was cases where the bot could not generate a\nresponse. This was especially evident for queries\nframed in professional/specialized language, such\nas medical case presentations. For example, when\nasked “What are the official CDC guidelines for\nHIV PEP after a needlestick?”, Myna Bolo de-\nfaulted to recommending a doctor’s appointment.\nThis revealed a gap in handling specialized or medi-\ncal jargon-heavy queries. However, Myna Bolo had\nbeen designed for queries from community mem-\nbers and not healthcare providers, and responded\naccordingly.\n5\nDiscussion\nThough our analysis highlights gaps, we found\nHB to be valuable as a starting point for identi-\nfying where Myna Bolo currently underperforms in\nproviding SRH information. At the same time,\nour study illustrates how a single global rubric\ncan fall short in evaluating locally grounded sys-\ntems. Across the above examples, several patterns\nemerged: misalignment with cultural and legal\nnorms, misalignment with diet assumptions, dif-\nferences in healthcare financing and delivery, and\nambiguity in how questions were phrased. In such\ncases, responses that would be judged by local clini-\ncians as safe and actionable were sometimes scored\nlow by HB. For example, answers tied to Indian\nlaws or prices were penalized because the rubric\nassumed U.S. legal protections or dollar-based cost\nranges. This points to the need for adapted evalua-\ntion datasets and rubrics.\nWe also observed lack of a patient perspective\nin the evaluation dataset and rubrics. Many ques-\ntions and criteria appeared to reflect the voice of\nhealthcare professionals rather than that of every-\nday users. HB gold standard answers were fre-\n"}, {"page": 5, "text": "quently very long and guideline-style, sometimes\nseveral hundred words. In contrast, our user re-\nsearch with communities has repeatedly uncovered\nthat users (especially given limited literacy) prefer\nbrief and clear next steps and red flag warnings\ninstead of detailed guidelines, especially if an SRH\nquestion is time-sensitive (e.g., emergency contra-\nception timing, or urgent symptoms)\nWe thus find that even one of the most compre-\nhensively and globally designed rubrics we have\ntoday for health LLM evaluation has a Western\nbias. Our goal is not to simply critique but to sur-\nface opportunities to leverage such benchmarks as\na launching point for future domain-specific and\ncontext-relevant evaluations. Our case examples\naim to suggest a constructive path forward: keep\nHealthBench (and other such datasets and met-\nrics) as the backbone, but add region-aware, date-\nstamped, property-based checks so locally valid\nanswers are credited rather than penalized. This\napproach keeps results comparable across models\nand advances health equity by considering locally\nappropriate, up-to-date LLM responses.\n6\nLimitations and Future Work\nHB covers a wide range of health domains, but we\nfocused only on SRH, and within that, only single-\nturn conversations. This focus helped us highlight\nkey evaluation concerns, but it does not capture the\nfull breadth of HB or broader strengths and weak-\nnesses of Myna Bolo. Our analysis also centered\non the Indian context, though we hope findings are\ninformative for other culturally-specific settings.\nIn future work, we aim to expand our study to\ninclude multi-turn conversations, which better re-\nflect real-world user interactions. Finally, Myna\nBolo can function in English, Hindi, Hinglish, and\nMarathi; however, since HB queries are mostly in\nEnglish, our paper focuses on evaluation of English\nresponses.\n7\nAcknowledgments\nWe thank the anonymous reviewers and the area\nchair for their constructive comments. We also\nthank Aradhana Thapa from the CARE lab at\nEmory University, and the research and technical\nteam at the Myna Mahila Foundation for the col-\nlaborative support throughout this work.\nReferences\nMahyar Abbasian, Elahe Khatibi, Iman Azimi, David\nOniani, Zahra Shakeri Hossein Abad, Alexander\nThieme, Ram Sriram, Zhongqi Yang, Yanshan Wang,\nBryant Lin, and 1 others. 2024. Foundation met-\nrics for evaluating effectiveness of healthcare con-\nversations powered by generative ai. NPJ Digital\nMedicine, 7(1):82.\nAlaa Abd-Alrazaq, Zeineb Safi, Mohannad Alajlani,\nJim Warren, Mowafa Househ, Kerstin Denecke, and\n1 others. 2020. Technical metrics used to evaluate\nhealth care chatbots: scoping review. Journal of\nmedical Internet research, 22(6):e18301.\nNazanin Andalibi and Kristen Bowen. 2022. Internet-\nbased information behavior after pregnancy loss:\ninterview study.\nJMIR Formative Research,\n6(3):e32640.\nAnna Arias-Duart, Pablo Agustin Martin-Torres, Daniel\nHinjos, Pablo Bernabeu-Perez, Lucia Urcelay Ganza-\nbal, Marta Gonzalez Mallo, Ashwin Kumar Gurura-\njan, Enrique Lopez-Cuena, Sergio Alvarez-Napagao,\nand Dario Garcia-Gasulla. 2025. Automatic evalua-\ntion of healthcare llms beyond question-answering.\narXiv preprint arXiv:2502.06666.\nRahul K Arora, Jason Wei, Rebecca Soskin Hicks, Pre-\nston Bowman, Joaquin Quiñonero-Candela, Foivos\nTsimpourlas, Michael Sharman, Meghan Shah, An-\ndrea Vallone, Alex Beutel, and 1 others. 2025.\nHealthbench:\nEvaluating large language models\ntowards improved human health.\narXiv preprint\narXiv:2505.08775.\nSuhana Bedi, Hejie Cui, Miguel Fuentes, Alyssa Unell,\nMichael Wornow, Juan M Banda, Nikesh Kotecha,\nTimothy Keyes, Yifan Mai, Mert Oez, and 1 oth-\ners. 2025. Medhelm: Holistic evaluation of large\nlanguage models for medical tasks. arXiv preprint\narXiv:2505.23802.\nDale E Brashers, Daena J Goldsmith, and Elaine\nHsieh. 2002. Information seeking and avoiding in\nhealth contexts. Human communication research,\n28(2):258–271.\nVirginia Braun and Victoria Clarke. 2006. Using the-\nmatic analysis in psychology. Qualitative research\nin psychology, 3(2):77–101.\nRoshini Deva, Dhruv Ramani, Tanvi Divate, Suhani\nJalota, and Azra Ismail. 2025. \" kya family planning\nafter marriage hoti hai?\": Integrating cultural sensi-\ntivity in an llm chatbot for reproductive health. In\nProceedings of the 2025 CHI Conference on Human\nFactors in Computing Systems, pages 1–23.\nDaniel Hershcovich, Stella Frank, Heather Lent,\nMiryam De Lhoneux, Mostafa Abdou, Stephanie\nBrandl, Emanuele Bugliarello, Laura Cabello Pi-\nqueras, Ilias Chalkidis, Ruixiang Cui, and 1 others.\n2022. Challenges and strategies in cross-cultural nlp.\narXiv preprint arXiv:2203.10020.\n"}, {"page": 6, "text": "Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William W\nCohen, and Xinghua Lu. 2019. Pubmedqa: A dataset\nfor biomedical research question answering. arXiv\npreprint arXiv:1909.06146.\nShreya Johri, Jaehwan Jeong, Benjamin A Tran, Daniel I\nSchlessinger, Shannon Wongvibulsin, Leandra A\nBarnes, Hong-Yu Zhou, Zhuo Ran Cai, Eliezer M\nVan Allen, David Kim, and 1 others. 2025. An eval-\nuation framework for clinical use of large language\nmodels in patient interaction tasks. Nature medicine,\n31(1):77–86.\nEmily McMahon, Tamara Fetters, Nadia Lobo Jive, and\nMike Mpoyi. 2023. Perils and promise providing\ninformation on sexual and reproductive health via the\nnurse nisa whatsapp chatbot in the democratic repub-\nlic of the congo. Sexual and Reproductive Health\nMatters, 31(4):2235796.\nFred Mutisya, Shikoh Gitau, Nasubo Ongoma, Keith\nMbae, and Elizabeth Wamicha. 2025. Rethinking ev-\nidence hierarchies in medical language benchmarks:\nA critical evaluation of healthbench. arXiv preprint\narXiv:2508.00081.\nCharles Nimo, Tobi Olatunji, Abraham Toluwase\nOwodunni, Tassallah Abdullahi, Emmanuel Ayodele,\nMardhiyah Sanni, Ezinwanne C Aka, Folafunmi\nOmofoye, Foutse Yuehgoh, Timothy Faniran, and\n1 others. 2025. Afrimed-qa: A pan-african, multi-\nspecialty, medical question-answering benchmark\ndataset. In Proceedings of the 63rd Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 1: Long Papers), pages 1948–1973.\nAnkit Pal, Logesh Kumar Umapathi, and Malaikan-\nnan Sankarasubbu. 2022. Medmcqa: A large-scale\nmulti-subject multi-choice dataset for medical do-\nmain question answering. In Conference on health,\ninference, and learning, pages 248–260. PMLR.\nAnkit Pal, Logesh Kumar Umapathi, and Malaikannan\nSankarasubbu. 2023. Med-halt: Medical domain\nhallucination test for large language models. arXiv\npreprint arXiv:2307.15343.\nRifat Rahman, Md Rishadur Rahman, Nafis Irtiza Tripto,\nMohammed Eunus Ali, Sajid Hasan Apon, and Rifat\nShahriyar. 2021. Adolescentbot: Understanding op-\nportunities for chatbots in combating adolescent sex-\nual and reproductive health problems in bangladesh.\nIn Proceedings of the 2021 CHI conference on human\nfactors in computing systems, pages 1–15.\nDorothy Shaw. 2009. Access to sexual and reproductive\nhealth for young people: bridging the disconnect\nbetween rights and reality. International Journal of\nGynecology & Obstetrics, 106(2):132–136.\nThomas Yu Chow Tam, Sonish Sivarajkumar, Sumit\nKapoor, Alisa V Stolyar, Katelyn Polanska, Kar-\nleigh R McCarthy, Hunter Osterhoudt, Xizhi Wu,\nShyam Visweswaran, Sunyang Fu, and 1 others. 2024.\nA framework for human evaluation of large language\nmodels in healthcare derived from literature review.\nNPJ digital medicine, 7(1):258.\nTao Tu, Anil Palepu, Mike Schaekermann, Khaled Saab,\nJan Freyberg, Ryutaro Tanno, Amy Wang, Brenna\nLi, Mohamed Amin, Nenad Tomasev, and 1 others.\n2024. Towards conversational diagnostic ai. arXiv\npreprint arXiv:2401.05654.\nSri Wahyuningsih, Sri Widati, Sarva Mangala Praveena,\nand Mohammad Wavy Azkiya. 2024. Unveiling bar-\nriers to reproductive health awareness among rural\nadolescents: a systematic review. Frontiers in Repro-\nductive Health, 6:1444111.\nHua Wang, Sneha Gupta, Arvind Singhal, Poonam Mut-\ntreja, Sanghamitra Singh, Poorva Sharma, and Alice\nPiterova. 2022. An artificial intelligence chatbot for\nyoung people’s sexual and reproductive health in in-\ndia (snehai): instrumental case study. Journal of\nMedical Internet Research, 24(1):e29969.\nShirui Wang, Zhihui Tang, Huaxia Yang, Qiuhong Gong,\nTiantian Gu, Hongyang Ma, Yongxin Wang, Wubin\nSun, Zeliang Lian, Kehang Mao, and 1 others. 2025.\nA novel evaluation benchmark for medical llms: Illu-\nminating safety and effectiveness in clinical domains.\narXiv preprint arXiv:2507.23486.\n"}, {"page": 7, "text": "A\nMyna Bolo WhatsApp Interface\nFigure 1: Myna Bolo on WhatsApp. Illustration of how the chatbot handles user queries within the WhatsApp\ninterface, offering personalized and empathetic responses in real time.\nB\nSRH Query Filtering Prompt for Extracting the SRH Subset from HealthBench\nWe used GPT-4 to run the following classification prompt and identify SRH-related queries.\nSRH query filtering prompt\nDetermine whether the following text is related to Sexual and Reproductive Health (SRH). SRH\nincludes topics such as: menstruation, contraception, pregnancy, miscarriage, abortion, childbirth,\npostpartum care, HIV, PCOS, family planning, sexual health, vaginal health, reproductive rights,\nsexually transmitted infections (STIs), infertility, menopause, puberty, and adolescent sexual\nbehavior.\nRespond with one of the following labels:\n- SRH-Related\n- Not SRH-Related\nText: {text}\nLabel:\nFigure 2: Example of the prompt used for SRH query filtering from HealthBench.\n"}, {"page": 8, "text": "C\nCase Examples with Bot Responses and HealthBench Criteria\nTable 1: Summary of case examples with bot responses and HealthBench (HB) criteria.\nID\nTheme\nQuestion (HB)\nMyna Bolo response (verbatim)\nHB criterion\nC1\nCultural\nmis-\nmatches\nin\nevaluation\nCan I breastfeed in public what are\nthe laws?\nOf course, Didi!\nYou can breastfeed your baby in public. It’s a natural and important\npart of taking care of your child. In India, there are no specific\nlaws against breastfeeding in public, and it’s generally accepted.\nBreastfeeding is your right and helps your baby get the best nutri-\ntion. If you feel shy, you can use a shawl or dupatta for privacy.\nRemember, your baby’s health and comfort come first.\nIf you\never feel uncomfortable, try to find a quiet spot or a designated\nbreastfeeding area if available. Stay confident and take care of your\nlittle one!\nMentions that, at least in the US,\nbreastfeeding is not only allowed but\nalso protected in public places.\nC2\nCultural\nmis-\nmatches\nin\nevaluation\nWhich fish are ok to eat when ex-\npecting?\nHello Didi!\nWhen you’re pregnant, it’s important to pick fish that don’t have\nmuch mercury. Safe choices include: Rohu (Indian carp), Katla\n(Indian carp), Pomfret, Hilsa (in moderation), Salmon, Sardines.\nThese fish have Omega-3s that are good for the baby’s brain and\neyes. Just make sure to cook them well and avoid raw or under-\ncooked fish.\nProvides a list of fish that must be\navoided due to the highest mercury\nlevels: king mackerel, marlin, or-\nange roughy, shark, swordfish, tile-\nfish, bigeye tuna.\nC3\nSystem of care\nand\nfinancing\nmisalignment\niud insertion cost? the t shaped coil\ndo i pay out of pocket side effects?\nHello Didi!\nLet me help you with this:\nCost of IUD (Copper T):\n• Government Hospitals: Free of cost.\n• Private Hospitals: Depends on the doctor’s charges.\n• Medical Store: Around Rs. 150 to Rs. 300.\nSide Effects:\n• Periods might become a bit heavier or more painful.\n• Rarely, a small hole in the womb might happen during insertion,\nneeding surgery.\n• Infection risk when first inserted, treatable with antibiotics.\n• Very low chance of getting pregnant, but if it happens, get urgent\nhelp as it might be outside the womb.\nIf you have more questions, feel free to ask!\nInforms that with insurance, IUDs\nare often fully covered under pre-\nventive care (depending on the insur-\nance plan), while without insurance,\ncosts can range up to $1,300, and\nunusually, it may go up to $3,500 in\nsome private clinics.\nC4\nSystem of care\nand\nfinancing\nmisalignment\nIm 30 yrs old planning IVF i want\ncost estimates for ivf be accurate\nDidi, IVF can be a bit expensive, and the cost can change depending\non the clinic and where it is. Usually, it can be from Rs. 1,00,000\nto Rs. 2,50,000 for each cycle. This includes medicines, tests, and\nprocedures. It’s important to talk to a doctor to understand the costs\nfor your situation.\nIf you need help finding a doctor, I’m\nhappy to help! Take care!\nIncludes specific IVF estimates for\ndifferent regions such as America,\nUK, Europe, Asia, and Africa, and\nprovides a quick overview of IVF\navailability in these regions.\nC5\nPostpartum\nAge 28, female, delivered 2 weeks\nback, feeling depressed, crying ev-\nery day, i cant sleep well. i am not\nsure how to find therapy, no idea if i\ncan see a doctor. i want medicines,\nmaybe herbal, also any home rem-\nedy.\nOh, Didi! It’s normal to feel this way after having a baby, but it’s\nimportant to look after yourself.\nHere are some steps you can take:\n1. Talk to Someone: Share your feelings with a family member or\nfriend. Sometimes, just talking helps.\n2. Home Remedies: - Warm Milk: Drink warm haldi milk before\nbed to help with sleep.\n- Meditation: Practice meditation or\npranayama like Anulom Vilom to calm your mind.\n3. Herbal Options: - Herbal Tea: Chamomile tea can be soothing\nand help with relaxation.\n4. Professional Help: If these feelings don’t go away, it’s important\nto see a doctor or therapist. They can guide you better.\nTake care, Didi! You’re not alone in this.\nCites examples of used prescription\nmedications such as SSRI antide-\npressants like Sertraline or newer\nagents like Brexanolone and Zura-\nnolone.\nC6\nCommunication\nmy period is almost two weeks late,\nshould i be worried or is this nor-\nmal?\nHello Didi!\nPeriods can sometimes be late for different reasons. Here are a few\ncommon ones:\n- Stress: Too much stress can make your period late.\n- Weight changes: Gaining or losing weight quickly can change\nyour cycle.\n- Diet: What you eat can also affect it.\n- Exercise: Too much exercise might make periods late.\n- Pregnancy: If there’s a chance, think about taking a test.\nIf your period is late often or you have other symptoms, it might\nbe good to talk to a doctor. But don’t worry too much, Didi. Some-\ntimes, our bodies just need a little time to adjust.\nTake care and let me know if you have more questions!\nStates pregnancy as a potential cause\nand includes specific next steps,\nsuch as taking a pregnancy test if\nsexually active; penalized for not\nmaking the “if sexually active\" con-\ndition explicit in the action.\n"}, {"page": 9, "text": "ID\nTheme\nQuestion\nBot response (verbatim)\nHB criterion\nC7\nAmbiguity\nheavy bleed 48 need red flags??\nHello Didi!\nHeavy bleeding for 48 hours can be worrying, but it might not\nalways be serious. Here are a few things to think about:\nNormal bleeding during periods can be heavy on the first and second\ndays.\nIf you’re using more than 6–7 pads in a day, it might be too much.\nIf you see clots bigger than a 5-rupee coin, it’s good to talk to a\ndoctor.\nIf the bleeding keeps going heavily beyond 48 hours or you feel\nweak or dizzy, it’s best to see a doctor. Take care, Didi!\nStates that heavy menstrual bleeding\nmay be normal at age 48 because es-\ntrogen usually predominates during\nperimenopause.\n"}]}