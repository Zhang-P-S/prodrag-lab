{"doc_id": "arxiv:2602.11391", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2602.11391.pdf", "meta": {"doc_id": "arxiv:2602.11391", "source": "arxiv", "arxiv_id": "2602.11391", "title": "Advancing AI Trustworthiness Through Patient Simulation: Risk Assessment of Conversational Agents for Antidepressant Selection", "authors": ["Md Tanvir Rouf Shawon", "Mohammad Sabik Irbaz", "Hadeel R. A. Elyazori", "Keerti Reddy Resapu", "Yili Lin", "Vladimir Franzuela Cardenas", "Farrokh Alemi", "Kevin Lybarger"], "published": "2026-02-11T21:53:18Z", "updated": "2026-02-11T21:53:18Z", "summary": "Objective: This paper introduces a patient simulator designed to enable scalable, automated evaluation of healthcare conversational agents. The simulator generates realistic, controllable patient interactions that systematically vary across medical, linguistic, and behavioral dimensions, allowing annotators and an independent AI judge to assess agent performance, identify hallucinations and inaccuracies, and characterize risk patterns across diverse patient populations. Methods: The simulator is grounded in the NIST AI Risk Management Framework and integrates three profile components reflecting different dimensions of patient variation: (1) medical profiles constructed from electronic health records in the All of Us Research Program; (2) linguistic profiles modeling variation in health literacy and condition-specific communication patterns; and (3) behavioral profiles representing empirically observed interaction patterns, including cooperation, distraction, and adversarial engagement. We evaluated the simulator's effectiveness in identifying errors in an AI decision aid for antidepressant selection. Results: We generated 500 conversations between the patient simulator and the AI decision aid across systematic combinations of five linguistic and three behavioral profiles. Human annotators assessed 1,787 medical concepts across 100 conversations, achieving high agreement (F1=0.94, \\k{appa}=0.73), and the LLM judge achieved comparable agreement with human annotators (F1=0.94, \\k{appa}=0.78; paired bootstrap p=0.21). The simulator revealed a monotonic degradation in AI decision aid performance across the health literacy spectrum: rank-one concept retrieval accuracy increased from 47.9% for limited health literacy to 69.1% for functional and 81.6% for proficient.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2602.11391v1", "url_pdf": "https://arxiv.org/pdf/2602.11391.pdf", "meta_path": "data/raw/arxiv/meta/2602.11391.json", "sha256": "807e9eb87abea42f65669693bfa892814ac945521f7c51f14aae4a125f901f59", "status": "ok", "fetched_at": "2026-02-18T02:19:24.678053+00:00"}, "pages": [{"page": 1, "text": " \n \n \nAdvancing AI Trustworthiness Through Patient Simulation: Risk Assessment of \nConversational Agents for Antidepressant Selection  \n \nMd Tanvir Rouf Shawon* \nGeorge Mason University (GMU), Computer Science (CS), mshawon@gmu.edu   \nMohammad Sabik Irbaz \nGMU, Information Sciences and Technology (IST), mirbaz@gmu.edu  \nHadeel R. A. Elyazori \nGMU, IST, helyazor@gmu.edu \nKeerti Reddy Resapu \nGMU, Health Administration and Policy (HAP), kresapu@gmu.edu  \nYili Lin \nGMU, HAP, ylin26@gmu.edu  \nVladimir Franzuela Cardenas \nGMU, HAP, vcarden@gmu.edu  \nFarrokh Alemi \nGMU, HAP, fa3277@gmu.edu  \nKevin Lybarger \nGMU, IST klybarge@gmu.edu  \nCCS CONCEPTS ‚Ä¢ Artificial intelligence ‚Ä¢ Natural language generation ‚Ä¢ Natural language interfaces ‚Ä¢ Consumer \nhealth ‚Ä¢ Health informatics ‚Ä¢ \nAdditional Keywords and Phrases: Patient simulation, conversational agents, AI risk management, trustworthy AI, large \nlanguage models, depression management \n \n \n \n* Corresponding author.  \n"}, {"page": 2, "text": " \n \n \nABSTRACT \nObjective: This paper introduces a patient simulator designed to enable scalable, automated evaluation of healthcare \nconversational agents. The simulator generates realistic, controllable patient interactions that systematically vary across \nmedical, linguistic, and behavioral dimensions, allowing annotators and an independent AI judge to assess agent \nperformance, identify hallucinations and inaccuracies, and characterize risk patterns across diverse patient populations.   \nMethods: The simulator is grounded in the NIST AI Risk Management Framework and integrates three profile \ncomponents reflecting different dimensions of patient variation: (1) medical profiles constructed from electronic health \nrecords in the All of Us Research Program, where patient features are combined using risk-ratio gating to produce coherent, \noutcome-relevant clinical histories; (2) linguistic profiles modeling variation in health literacy and condition-specific \ncommunication patterns derived from psycholinguistic and clinical research; and (3) behavioral profiles representing \nempirically observed interaction patterns, including cooperation, distraction, and adversarial engagement. We evaluated \nthe simulator's effectiveness in identifying errors in an AI decision aid for antidepressant selection.  \nResults: We generated 500 conversations between the patient simulator and the AI decision aid across systematic \ncombinations of five linguistic and three behavioral profiles. Human annotators assessed 1,787 medical concepts across \n100 conversations, achieving high agreement (F1=0.94, Œ∫=0.73), and the LLM judge achieved comparable agreement with \nhuman annotators (F1=0.94, Œ∫=0.78; paired bootstrap p=0.21). Behavioral profiles were reliably distinguished by \nannotators (Œ∫=0.93), and linguistic profiles showed moderate agreement (Œ∫=0.61), consistent with the intended gradient \nstructure across health literacy levels. The simulator revealed a monotonic degradation in AI decision aid performance \nacross the health literacy spectrum: rank-one concept retrieval accuracy increased from 47.9% for limited health literacy \nto 69.1% for functional and 81.6% for proficient, with corresponding downstream effects on antidepressant \nrecommendation accuracy (weighted F1 ranging from 0.34 to 0.90 across profile combinations). \nConclusions: The patient simulator effectively generates diverse, coherent, and realistic conversations that expose \nmeasurable performance risks in conversational healthcare AI. The LLM judge provides scalable annotations comparable \nto human experts, supporting large-scale risk assessment. Health literacy emerged as a primary risk factor for AI decision \naid performance, with direct implications for equitable system design. \n1 \nINTRODUCTION \nRapid advancements in artificial intelligence (AI), particularly large language models (LLMs), are creating new \ninnovative ways to interact with patients and clinicians through conversational agents [39, 55, 56]. For patients, these \nagents can increase engagement, improve accessibility to care, and provide personalized interactions in an empathetic tone \n[25]. For clinicians, conversational agents can reduce administrative burdens, support clinical decision-making, facilitate \nreal-time patient monitoring, and support patient communication [29]. LLMs support prompt-based approaches that \nintegrate multiple agents, tools, and resources without requiring extensive model fine-tuning or bespoke development [30]. \nWhile these advancements substantially lower barriers to developing AI systems, they also heighten the need for rigorous \nmethods to assess and mitigate AI risks, ensuring reliability, safety, and patient-centered alignment. \nEvaluation of conversational agents in healthcare is particularly challenging due to their dynamic nature, involving \ncomplex, multi-turn dialogues where static evaluation benchmark datasets are insufficient [18, 26]. Realistic user \nsimulations provide systematic, controlled environments for evaluating conversational agents and identifying \nvulnerabilities [4]. Within health applications, simulated users may represent patients or clinicians, enabling \ncomprehensive characterization and management of risks for AI-driven conversational agents [23]. The National Institute \nof Standards and Technology (NIST) AI Risk Management Framework (AI RMF) provides structured, domain-agnostic \n"}, {"page": 3, "text": " \n \n \nguidance for identifying, assessing, and managing AI risks [54]. This work introduces a patient simulator framework to \noperationalize the AI RMF, providing an empirically grounded approach to systematically identifying risks and evaluating \nconversational agent performance in realistic healthcare scenarios. \nThis paper presents a comprehensive patient simulator grounded in real-world clinical data and relevant literature. \nWhile we focus on a conversational patient decision aid for selecting antidepressant medications for major depressive \ndisorder (MDD), the simulator framework generalizes a wide array of healthcare tasks and target medical conditions. The \nsimulator integrates three profile components defining medical, linguistic, and behavioral characteristics. The medical \nprofile employs a novel Medical Artificial General Intelligence (MAGI) algorithm to incorporate electronic health record \n(EHR) datasets, such as the All of Us initiative [3], to generate realistic and extensible medical histories. The linguistic \nprofile models health literacy variation [22, 40] and condition-specific communication patterns [43, 72] derived from \nliterature and systematically mapped to identified AI risks. The behavioral profile incorporates empirically derived \nbehavioral attributes reflective of patient interactions, addressing identified conversational risks through systematic risk \nmapping [46, 52]. Together, these profiles are integrated as a unified, realistic simulated patient capable of robust, \ncomprehensive assessment of conversational agents. Building on prior work in patient simulation and NIST-aligned risk \ngovernance, this study explores the following research questions:  \nRQ1. How effectively can structured healthcare data be transformed into coherent and risk-aware medical profiles \naligned with trustworthy AI principles? \nRQ2. How can simulated patients that combine medical, linguistic, and behavioral information demonstrate realistic \nand consistent conversational behavior? \nRQ3. How can simulated patient evaluation reveal the quality, reliability, and potential risks of such systems? \nThis work contributes (1) a risk-aligned patient simulator integrating medical, linguistic, and behavioral profiles, (2) the \nMAGI approach for generating coherent medical histories from EHR data, and (3) systematic evaluation demonstrating \nsimulator effectiveness for risk assessment. The code, source data, and simulated interactions are publicly available to \nfacilitate broader use and adaptation1. \n2 OPERATIONALIZING AI RISK ASSESSMENT FOR CONVERSATIONAL HEALTHCARE SYSTEMS \nThe AI RMF defines four core functions: (1) GOVERN ‚Äì accountability and oversight, (2) MAP ‚Äì risk identification, \n(3) MEASURE ‚Äì risk assessment, and (4) MANAGE ‚Äì risk mitigation [54]. Operationalizing these for conversational \nhealthcare AI requires moving beyond static benchmarks, which cannot capture dynamic risks in multi-turn clinical \ndialogues where medical complexity, communication patterns, and patient behaviors interact. We developed a \nmultidimensional patient simulator integrating medical, linguistic, and behavioral profiles to operationalize MAP and \nMEASURE functions and inform MANAGE strategies. \n2.1 Medical Profile Generation: Foundational Risk Assessment \nMedical profile generation provides the clinical foundation for risk assessment. Without realistic, diverse medical \ncontexts, evaluation cannot assess performance across clinical heterogeneity. Generating profiles from structured EHR \ndata faces interconnected challenges: high-dimensional feature spaces (10‚Åµ-10‚Å∂ concept codes) with sparse task-relevant \nsignals, data quality issues (missingness, inconsistent coding), and medically implausible feature combinations [32, 49, \n53]. These challenges risk obscuring vulnerabilities through noise or missing them through narrow profiles. Medical profile \n \n1 GitHub link to be provided upon acceptance. \n"}, {"page": 4, "text": " \n \n \ngeneration must surface: (1) performance risks such as brittleness and poor generalization, (2) safety risks such as \nimplausible or unsafe recommendations, and (3) bias risks such as subgroup disparities.  \nOur design adheres to five AI RMF-aligned trustworthiness requirements. Controllability: Emphasize task-relevant \nfeatures while maintaining outcome diversity for robust assessment. Coherence: Maintain clinical plausibility across \ndiagnoses, treatments, and temporal events, including rare but valid scenarios. Variability: Capture heterogeneous \ncomorbidities and contextual factors to expose brittleness and subgroup bias. Efficiency: Balance clinical completeness \nwith computational tractability for large-scale testing that reflects plausible patient disclosure. Transparency: Maintain \ntraceable feature lineage to source distributions for targeted risk analysis. Table 1 maps these requirements to data \nchallenges and mitigated risks. \nTable 1. Medical profile generation requirements: NIST alignment, challenges addressed, and risks mitigated. \nRequirement  \n(NIST Functions) \nData Challenge \nAI Risk \nControllability  \n(MAP, MEASURE) \nHigh-dimensional feature space with \nsparse task-relevant signal \nSpurious associations and overfitting; \ninflated performance estimates \nCoherence  \n(MAP, MEASURE) \nCoding inconsistencies and implausible \nfeature combinations \nMedically contradictory profiles \nmasking safety vulnerabilities \nVariability  \n(MAP, MEASURE) \nSkewed distributions and \nunderrepresentation \nSubgroup disparities and incomplete \nrisk detection \nEfficiency  \n(GOVERN, MEASURE) \nExcessive record density limiting \nevaluation scale \nEvaluation bottlenecks and reduced \noversight capacity \nTransparency \n(GOVERN, MEASURE) \nObscured feature provenance and latent \ninteractions \nLimited auditability and hidden bias \npropagation \n2.2 Linguistic and Behavioral Profiles: Layered Risk Detection \nMedical profiles establish clinical context but cannot capture communication-dependent and interaction-dependent \nrisks, requiring two additional profile dimensions [34].  \nCommunication-dependent risks emerge from heterogeneity in patient expression. Agents must maintain safety and \ncomprehensibility across health literacy levels, condition-specific patterns, and vernacular variations. Without systematic \nlinguistic variation, evaluation cannot assess whether agents interpret diverse expressions and respond appropriately [14]. \nLinguistic profiles enable controlled assessment grounded in health literacy and psycholinguistic research [51]. \nInteraction-dependent risks emerge when patients manipulate information, test boundaries, or withhold details [69]. \nAgents must maintain safety across adversarial behaviors including goal hijacking, information withholding, and boundary \ntesting. Without behavioral variation, evaluation cannot assess safety mechanism robustness under adversarial conditions. \nBehavioral profiles enable systematic resilience assessment grounded in clinical and human-computer interaction research. \n2.3 Framework Integration \nMedical, linguistic, and behavioral profiles comprehensively implement MAP by systematically documenting clinical \nscope, communication risks, and adversarial vulnerabilities to enable MEASURE across diverse contexts and inform \nMANAGE strategies.  \n"}, {"page": 5, "text": " \n \n \n3 RELATED WORK \nUser simulation provides methodology for evaluating conversational agents across domains while patient simulation \nadapts these methods for clinical dialogue, diagnostic reasoning, and virtual patient construction. \n3.1 USER SIMULATION \nUser simulation enables controlled, scalable evaluation of interactive systems without requiring human trials. Surveys \non information access and dialogue modeling provide a foundation for current developments [5, 17], while \nrecommendation research demonstrates how simulation reveals long-term behavioral shifts and reinforcement cycles [63, \n70]. Dialogue research has advanced with LLM-based simulators that generate context-aware behavior through dual-model \narchitectures combining generators and verifiers [38, 48]. Information retrieval studies model search behavior through \nsession-level simulation [28, 68]. Healthcare applications use synthetic users with clinical profiles to evaluate decision \nsupport and coaching systems [66]. These contributions establish user simulation as a critical method for evaluating \nreliability, safety, and performance in modern AI systems. \n3.2 PATIENT SIMULATION \nPatient simulation involves construction of virtual patients that engage in interactive clinical dialogues with human or \nautomated clinicians [12]. These systems model patient behavior across multi-turn interactions to support diagnostic \nreasoning, history taking, and communication training in a safe, privacy-preserving environment [27]. Simulation \nframeworks vary widely in patient state representation, ranging from hand-crafted profiles to EHR-grounded models, and \nin controlling disclosure, tone, and clinical accuracy [29, 35]. Prior work often treats patient simulation as a single unified \nproblem, but it involves two distinct technical challenges: (1) constructing clinically valid patient representations and (2) \nsimulating interactive dialogue that expresses those representations over time [35]. Recent systems have integrated LLMs \nto enhance expressiveness and flexibility [21], constructed structured knowledge bases from clinical notes to support \nmedical intake tasks [37], and embedded risk-aware feedback mechanisms [12]. These systems pursue realistic clinical \ndialogue with varying emphasis on each challenge. We review approaches to medical profile construction and \nconversational expression separately, then identify knowledge gaps in integrating these components. \n3.2.1 Data-Driven Medical Realism  \nThis work focuses on creating structured patient medical histories that provide the clinical foundation for simulation. \nEarly systems employed deterministic state machines encoding disease progression logic. Synthea [57] simulates patient \ntimelines through state transitions across medical events, generating complete medical histories in standardized formats, \nwhile SynSys [13] uses hierarchical hidden Markov models to capture event timing and sequence realism. These systems \nare scalable and transparent but generate population-level epidemiological models rather than learning from real patient \ndistributions. \nRecent approaches use real-world EHR data to improve realism. Generative Adversarial Networks (GANs) have \nemerged as a dominant approach [62], with variants addressing EHR-specific challenges including missing features, \nvariable sequence lengths, and mixed data types [64]. SimSUM [45] combines Bayesian networks with prompted GPT \nmodels to generate synthetic notes. Benchmarking studies on MIMIC-III/IV reveal that GAN methods achieve higher \nfidelity and utility with rule-based methods excel in privacy protection [11]. Recent systems integrate EHR grounding with \nconversational capabilities: Luo et al. [37] build patient simulators from structured ophthalmology EHRs enabling \nretrieval-augmented dialogue, while Yu et al. [65] employ multi-agent knowledge graph pipelines grounded in MIMIC-III \n"}, {"page": 6, "text": " \n \n \nand CORAL datasets. However, although these methods ensure clinical grounding, they treat the encounter as a \ntransactional data exchange rather than a dynamic, rapport-dependent interaction. \n3.2.2 Behavioral and Linguistic Modeling \nBeyond medical profile generation, systems must express profiles through natural dialogue with appropriate \ncommunication style, personality patterns, and conversational dynamics [8, 27]. Cognitive and persona-based approaches \nmodel psychological states to generate behaviorally coherent conversation. PATIENT Œ® [58] uses expert-designed \ncognitive schemas and conversational styles with GPT-4 to reproduce emotional fluctuations and resistant behaviors \ncharacteristic of mental health patients in therapy sessions, while SFMSS [6] embeds Big Five traits to shape personality-\ndriven dialogue tone. These systems achieve improved linguistic and emotional realism in therapeutic contexts but remain \ncondition-specific (e.g., mental health) and lack medical grounding for clinical evaluation. In contrast, prompt-based \napproaches offer scalability. Cook et al. [12] generate patient profiles for chronic conditions using structured GPT prompts \nvalidated through clinician feedback. Holderried et al. [21] develop GPT-4 chatbots with automated feedback for history-\ntaking practice. However, though cost-effective and rapidly deployable, these approaches lack persistent patient state \ntracking across multi-turn interactions and offer limited systematic control over linguistic and behavioral variation.  \n3.2.3 Procedural and Workflow Control \nOther approaches prioritize procedural fidelity over representational or linguistic realism, modeling clinical workflows \nthrough discrete agent roles and actions. Bao et al. [6] coordinate patient, nurse, and supervisor agents to simulate outpatient \ntriage with supervisory feedback for procedural validation. iPDG [60] relies on rule-based, constraint-driven construction \nin which clinical plausibility is preserved through manually defined domain rules. These systems achieve procedural \ncoherence but sacrifice conversational flexibility and behavioral depth. \n3.2.4 Limitations and Gaps \nExisting patient simulation systems exhibit two critical gaps that constrain trustworthy AI evaluation. First, no \nframework comprehensively integrates medical realism, behavioral variation, and linguistic diversity within a unified \narchitecture. Recent systems pair two dimensions - medical grounding with behavioral modeling or behavioral depth with \nlinguistic variation - but this fragmentation creates evaluation blind spots. Systems cannot systematically test whether \nagents maintain diagnostic accuracy when confronting patients with complex comorbidities, Limited Health Literacy, and \nadversarial behavior simultaneously, yet multi-turn failures such as context loss and inconsistent safety emerge precisely \nat these interaction boundaries. Second, existing approaches prioritize medical outcomes over systematic risk management \naligned with frameworks like the NIST AI RMF. They lack explicit risk mapping connecting simulation parameters to AI \nrisk categories, transparent auditability enabling traceable lineage to source data, and controllable risk probing through \nsystematic variation. This prevents detection of consequential failures: agents may exhibit linguistic bias by recommending \ndifferent treatments when patients express identical medical facts at different health literacy levels, or safety mechanisms \nmay fail under adversarial conditions without systematic behavioral variation to expose these vulnerabilities. We address \nthese gaps through a framework integrating medical (All of Us EHR via risk-ratio selection), linguistic (health literacy \ngradients and condition-specific communication patterns), and behavioral (empirically derived interaction patterns) \nprofiles that operationalize MAP and MEASURE functions, enabling comprehensive risk assessment across medical \naccuracy, communication appropriateness, and behavioral robustness. \n"}, {"page": 7, "text": " \n \n \n4 METHODS \n4.1 Overview \nThe proposed framework integrates a patient simulator with an AI Decision Aid to enable systematic evaluation of \nconversational clinical decision-making. The patient simulator produces controlled, profile-driven responses by combining \nmedical, linguistic, and behavioral characteristics, while the AI Decision Aid conducts a structured conversational intake \nto elicit clinical history and generate antidepressant recommendations. A high-level schematic of this interaction is shown \nin Figure 1. The remainder of this section details the patient simulator design, the AI Decision Aid architecture and \nconversational workflow, and the evaluation methodology, including the role of an LLM-based judge. \n \nFigure 1: A schematic diagram of the conversation between patient simulator and the AI Decision Aid system. \n4.2 Data \nBoth the patient simulator medical profiles and the AI Decision Aid prediction models are derived from the All of Us \nResearch Program Registered Tier v8 dataset. All of Us is a national longitudinal cohort study collecting diverse health \ndata from participants across the U.S. [3]. All of Us provide structured EHR data including conditions, medications, \nprocedures, and demographics. \nCohort Selection: We extracted data from All of Us participants with major depressive disorder (SNOMED CT Code \n370143000 and its descendants).  The resulting cohort includes 58,446 participants, contributing 466,752 antidepressant \ntrials, with 18,471 diagnoses, 2,642 medications, 5,001 procedures, and care outcomes including responses to 14 \nantidepressants and one additional antidepressant category recorded as of the dataset cut-off date of October 1, 2023. \nAntidepressant response outcomes were defined as taking the antidepressant for at least 10 weeks and the patient did not \nswitch or augment with another antidepressant [1].   \nData Application: For patient simulator medical profiles, the dataset provides feature distributions, risk-ratio \ncalculations for outcome-relevant predictor selection, and demographic distributions for age and gender initialization. The \npatient simulator was evaluated based on response to the four commonly prescribed antidepressants: fluoxetine, sertraline, \ntrazodone, and duloxetine [75]. For the AI Decision Aid, the same data trains prediction models that evaluate patient \nprofiles and compute antidepressant response associations to generate treatment recommendations focusing on the fourteen \nantidepressants. All data use complies with All of Us data use and dissemination policies. . \n"}, {"page": 8, "text": " \n \n \n4.3 Patient Simulator Design \nThe patient simulator integrates three profiles: medical profiles that model clinical history and risk factors using \nprobabilistic generation aligned with EHR data and NIST principles, linguistic profiles that capture variation in health \nliteracy and condition-specific expression, and behavioral profiles that represent patient engagement and interaction \npatterns. Profiles are operationalized through structured LLM prompting with hierarchical indexing for traceability. Figure \n2 shows an abbreviated version of the prompt structure (complete prompt structure in Appendix 10.1.1). \n \nFigure 2. Prompt Structure of Patient Simulator, abbreviated here for clarity. A more complete example prompt is presented in \nAppendix 10.1. \n4.3.1 Medical Profiles \nThe medical profile generation process consists of two sequential phases. Phase 1 generates patient profiles that are \noutcome-relevant, coherent, and diverse across clinical characteristics. Phase 2 applies probabilistic selection using a \nbinomial distribution derived from All of Us antidepressant response data, ensuring the final cohort reflects realistic \npopulation-level variability. \nPhase 1: Medical Profile Generation. Profile generation employs three core design principles to ensure clinical \nrealism and statistical stability [19, 20]: (1) prioritize outcome-relevant features, (2) enforce statistical independence among \nselected features, and (3) inject controlled diversity from residual features. These principles are implemented through a \nfour-stage process: (1) relevance filtering, (2) demographic initialization, (3) independence screening, and (4) diversity \nexpansion. \nStage 1: Top-K Filtering for Outcome Relevance. The algorithm restricts feature candidates to the top K predictors of \nthe antidepressant response outcome, ùëí‚ÇÄ (K = 500). This relevance filter improves sample efficiency and focuses selection \non features with demonstrated individual association to the target outcome aligning with the max‚Äërelevance component of \nminimum‚Äëredundancy‚Äëmaximum‚Äërelevance (mRMR) feature selection [20]. \nPatient Simulator Prompt Structure (Abbreviated) \n \nYou are simulating a patient based on three profiles: \n \n1. Medical Profile (hierarchical indices for traceability): \n   1.1: Age: 34 \n   2.1: Generalized Anxiety Disorder \n   3.2: Individual Psychotherapy \n   [... additional diagnoses, medications, procedures ...] \n \n2. Linguistic Profile: \n   Style: Concrete, informal \n   Tone: Hesitant, conversational \n   [... vocabulary, structure specifications ...] \n \n3. Behavioral Profile: \n   Adherence: High | Engagement: High | Focus: On-topic | Adversarial: Minimal \n \nResponse Generation: \n   Step 1: Identify relevant facts by index [e.g., 3.2] \n   Step 2: Apply linguistic style transfer \n   Step 3: Construct natural response with traceable references \n \nExample Output: \n   \"relevant_medical_history\": [\"[3.2] Individual Psychotherapy\"] \n   \"style_transferred\": [\"[3.2] talked to someone\"] \n   \"response\": \"<\\s>talked to someone</\\s> [3.2] for my anxiety\" \n"}, {"page": 9, "text": " \n \n \nStage 2: Demographic Seeding. Each patient profile ùëÜ is initialized with age and gender sampled from All of Us \ndemographic distributions, grounding profiles in realistic population characteristics. \nStage 3: Independence-Screened Selection. Features are added iteratively, with each candidate v screened for statistical \nindependence from already-selected features. The risk ratio ùëÖùëÖ(ùë†, ùë£) quantifies the association strength between features \ns and v with respect to antidepressant response: \nùëÖùëÖ(ùë†, ùë£) = ùëÉ(ùëüùëíùë†ùëùùëúùëõùë†ùëí|ùë†‚ãÇùë£)\nùëÉ(ùëüùëíùë†ùëùùëúùëõùë†ùëí|ùë†)  \nwhere values near 1 indicate independence, values > 1.5 indicate positive association, and values < 0.67 indicate negative \nassociation. Each candidate must satisfy the acceptance condition: \n1\n1.5 <  ùëÖùëÖ(ùë†, ùë£) ‚â§‚Ñéùëñùëî‚Ñé, ‚àÄùë†‚ààùëÜ \nThis symmetric band around unity excludes near-deterministic couplings (RR > high) that introduce redundancy and strong \nanticorrelations (RR < 1/1.5) that create unstable compensations, ensuring statistically independent and clinically coherent \nfeature combinations [20]. The upper threshold (high) was set to 7 for patient generation. \n    Stage 4: Diversity Expansion. After establishing a coherent set of features related to the target outcome, residual \ncandidate features ùë¢ from features outside the top K are added if they show meaningful association with at least one selected \nfeature: \nùëÖùëÖ(ùë†, ùë¢) >  1.5,‚àÉùë† ‚àà ùëÜ \nThis captures latent contextual variables that enrich patient heterogeneity without compromising coherence, ensuring \nprofiles reflect realistic complexity while remaining clinically plausible. This mechanism introduces bounded \nheterogeneity through correlated residual features, enriching diversity while maintaining clinical plausibility [19, 20]. An \nabbreviated version of the algorithm can be seen in Figure 3. Complete pseudocode, helper routines, and algorithmic details \nare provided in Appendix 10.1.2. \n \n"}, {"page": 10, "text": " \n \n \n \nFigure 3.  Abbreviated medical profile generation algorithm. Complete algorithm details in Appendix 10.1.2. \n \nPhase 2: Probabilistic Patient Selection. Phase 2 selects patients whose response probabilities collectively reproduce \nthe population-level distribution observed in the All of Us dataset. Each patient from Phase 1 has a predicted antidepressant \nresponse probability between 0 and 1. To ensure the final cohort matches realistic population variability, the probability \nrange is divided into seven sigma-bands of a binomial distribution ùêµ(ùëõ, ùëù), where ùëõ is the target cohort size and ùëù is the \npopulation mean response rate. Each generated patient is assigned to a band based on their predicted probability, and \nsampling is weighted to match expected binomial frequencies. For example, with n=100 and p=0.4 (Œº=40, œÉ‚âà4.9), \napproximately 64% of patients fall within (ùúá‚àíùúé, ùúá+ ùúé], 15% in each adjacent band (ùúá¬± 1ùúé ùë°ùëú ùúá¬± 2ùúé], and <3% in the \ntails beyond ùúá¬± 2ùúé. This stratified sampling preserves both central tendency and natural variability while avoiding over- \nor under-representation of extreme responders. Detailed sigma-band allocations appear in Appendix 10.1.2. \nAI RMF Alignment: This two-phase approach operationalizes the AI RMF requirements from Table 1. Outcome-\nfocused generation enables controllability by systematically diversifying profiles across response outcomes, risk-ratio \ngating ensures coherence through statistically independent feature combinations, binomial sampling provides variability, \nand explicit feature selection rules maintain transparency for targeted risk analysis and auditing. \n4.3.2 Linguistic Profiles \nLinguistic variation is essential for risk assessment, as conversational agents must maintain safety and \ncomprehensibility across diverse patient expression styles [10, 61]. The simulator implements distinct linguistic profiles \nto test agent robustness across different communication patterns. Such variation exposes blind spots, reveals failure modes, \nand informs system updates [31, 44].  \nAlgorithm: Medical Profile Generation  \n \nInput: Target outcome e‚ÇÄ, number of patients N, top-K=500  \n \nFor each patient i = 1 to N:  \n \n    Stage 1: Top-K Filtering for Outcome Relevance  \n    V ‚Üê Top-K predictors of antidepressant response e‚ÇÄ  \n \n    Stage 2: Demographic Seeding Initialize  \n    S ‚Üê {age, gender} sampled from population distributions  \n \n    Stage 3: Independence-Screened Selection  \n    For each candidate v in V:  \n        If ‚àÄs ‚àà S: 1/1.5 < RR(s,v) ‚â§ high:  \n            Add v to S  \n     \n    Stage 4: Diversity Expansion  \n    R ‚Üê residual features (outside top-K)  \n    For candidate u in R:  \n        If ‚àÉs ‚àà S: RR(s,u) > 1.5:  \n            Add u to S  \n    Compute p ‚Üê predicted response probability for profile S  \n \nOutput: N patient profiles with associated response probabilities \n"}, {"page": 11, "text": " \n \n \nThe simulator implements a dual-axis linguistic framework with profiles along two independent dimensions: (1) a \nhealth literacy gradient capturing variation in comprehension, terminology, and discourse structure [9, 40, 41, 51] and (2) \ncondition-specific communication reflecting linguistic patterns characteristic of depression and anxiety disorders derived \nfrom Linguistic Inquiry and Word Count (LIWC)-based clinical analyses [73]. Health literacy generalizes across clinical \ntasks as comprehension barriers affect patient-agent interaction regardless of medical condition. Condition-specific profiles \ncapture diagnostic patterns (here depression and anxiety) adaptable to other conditions. These complementary axes \ndistinguish general communicative capacity from condition-linked expression. Table 2 specifies five linguistic profiles \nused in this study. \nTable 2: Linguistic user profiles across multiple dimensions. \nProfile \nKey Linguistic Attributes \nExample Response \nHealth Literacy \n \n \nLimited \nStyle: Concrete, informal, sometimes vague. \nTone: Hesitant, uncertain, conversational. \nVocab: Everyday terms, slang, vague quantities. \nStructure: Short, fragmented sentences; frequent fillers. \nPatterns: Minimal elaboration unless prompted. \n‚ÄúUh, just my morning pill‚Ä¶ you \nknow, the one for my nerves.‚Äù \nFunctional \nStyle: Clear, basic descriptions of symptoms or routines. \nTone: Cooperative, open. \nVocab: Mix of common and medical terms. \nStructure: Simple narratives; occasional causal reasoning. \nPatterns: Provides coherent answers; asks clarifying questions. \n‚ÄúI take Prozac every morning. It helps \nmy mood, but I still have trouble \nsleeping.‚Äù \nProficient \nStyle: Precise, clinical, well-organized. \nTone: Confident, analytical. \nVocab: Technical terms; qualifiers such as ‚Äúlikely‚Äù or ‚Äúseems \nimproved.‚Äù \nStructure: Multi-clause, logically sequenced sentences. \nPatterns: References timelines; anticipates follow-up questions. \n‚ÄúI‚Äôm on fluoxetine, 20 milligrams \ndaily. It‚Äôs effective, though I‚Äôve \nnoticed mild insomnia.‚Äù \nCondition-specific \n \n \nDepression \nStyle: Brief, muted, sometimes resigned. \nTone: Flat, pessimistic, self-critical. \nVocab: Negative emotion words; self-focused phrasing. \nStructure: Short, often past-tense statements. \nPatterns: Withdrawn responses; dismisses reassurance. \n‚ÄúBarely sleeping. My head won‚Äôt shut \noff.‚Äù \nIllness Anxiety Disorder Style: Symptom-focused and repetitive. \nTone: Anxious, urgent. \nVocab: Symptom terms; ‚Äúwhat if‚Äù speculation; absolutist wording. \nStructure: Mix of run-on sentences and abrupt alarms. \nPatterns: Reassurance-seeking cycles; future-oriented worry. \n‚ÄúI felt a flutter‚Ä¶ what if it‚Äôs heart \nfailure even though the test was \nnormal?‚Äù \n \nAI RMF Alignment: This framework operationalizes Table 1 requirements through systematic, literature-grounded \nvariation [9, 40, 41, 51, 73] , enabling controllable assessment of communication-dependent risks through transparent \nprofiles. \n"}, {"page": 12, "text": " \n \n \n4.3.3 Behavioral Profiles \nConversational agents trained on ideal dialogues struggle when patients often go off-topic, respond vaguely, or withhold \ninformation [15, 16]. Systematic behavioral variation is essential for stress-testing agent robustness under diverse \ninteraction patterns and assessing recovery from conversational breakdowns [33, 47]. Behavioral profiles model patient \nengagement, topical focus, and cooperative versus adversarial interaction patterns. We organized the 13 commonly \nobserved patient behaviors documented by Simpson et al. [50] into five higher-level behavioral categories: structured and \ncooperative, inquisitive and open-ended, Reserved & Minimalist, Distracted & Unfocused, and Adversarial & Combative \n(complete mapping in Appendix 10.1.3). Based on these categories, this study operationalizes three profiles: Distracted & \nUnfocused and Adversarial & Combative to capture challenging dynamics, with Structured & Cooperative as a baseline. \nEach profile varies along four dimensions: conversational adherence, engagement, topical focus, and adversarial behavior, \nas detailed in Table 3.Table 3Table 3: Behavioral user profiles with corresponding conversational adherence, engagement, \ntopical focus, adversarial behavior. \nProfile \nKey Linguistic Attributes \nExample Response \nStructured & \nCooperative \nAdherence: High \nEngagement: High \nTopical Focus: High \nAdversarial / Toxic Behavior: Minimal \n‚ÄúYes, I take 20 mg of fluoxetine every \nmorning around 8 AM. I haven‚Äôt \nmissed a dose in the last three \nweeks.‚Äù \nDistracted & \nUnfocused \nAdherence: Low \nEngagement: Sporadic \nTopical Focus: Off-topic \nAdversarial / Toxic Behavior: Inadvertent derailment of conversation \n‚ÄúI was‚Ä¶ wait, which one? Oh right, \nyeah I think? But yesterday I forgot ‚Äî \nalso my dog wouldn‚Äôt eat.‚Äù \nAdversarial & \nCombative \nAdherence: Variable \nEngagement: Variable \nTopical Focus: Variable \nAdversarial / Toxic Behavior: Overtly confrontational or hostile \n‚ÄúWhat kind of dumb question is that? \nMaybe if your system worked better, I \nwouldn‚Äôt have to answer this again.‚Äù \n \nAI RMF Alignment: Operationalizes Table 1 requirements through empirically grounded behavioral variation [50] \nenabling controlled assessment of interaction-dependent risks including adversarial scenarios with transparent lineage. \n \nTogether, these three profile dimensions provide comprehensive MAP and MEASURE coverage for conversational \nhealthcare AI risk assessment. \n4.4  CoT Prompting Strategy  \nWe employ a Chain-of-thought (CoT) prompting [59] as a strategy to generate psychologically realistic patient \nresponses through a structured, multi-step process. For each question posed by the AI Decision Aid, the prompt directs the \nmodel to identify relevant indexed medical facts, apply controlled term-level linguistic transformations, and construct a \nnatural language response that embeds these facts with explicit references. Behavioral constraints are enforced as strict \nrules governing interaction behavior and progression, with linguistic constraints shaping the form of expression while \npreserving behavioral intent. All outputs are produced in a fixed JSON schema, enabling clear traceability, consistent \nannotation, and systematic evaluation of simulated medical intake interactions. \n"}, {"page": 13, "text": " \n \n \n4.5 AI Decision Aid \nThe AI Decision Aid is a multi-agent conversational platform for antidepressant selection, serving as the system under \nevaluation in this black-box assessment approach. The system conducts structured intake through six sequential stages: \nestablishing rapport, collecting illness history, gathering antidepressant history, documenting current medications, \nrecording clinical procedures, and generating personalized recommendations. Each stage employs LLM-guided dialogue \nto elicit clinical information, uses a Retrieval-Augmented Generation (RAG) based system for normalizing identified \nmedical concepts that are incorporated into an analytical advice system for estimating antidepressant response. The \nanalytical advice system used in this work is the Medical Artificial General Intelligence Algorithm (MAGI) [2], which is \nan inference framework that estimates dependent Bayesian relationships among medical concepts to support clinical \nreasoning when only partial patient data are available. System specifications and code are publicly available2. \n4.6 Evaluation Framework \nThe evaluation framework examines patient simulator performance across medical, linguistic, and behavioral \ndimensions using three complementary approaches. Medical profiles are assessed through human and LLM-based \nannotation applying a three-label schema (accurate, inaccurate, unsupported) to verify factual correctness. Linguistic \nprofiles are evaluated through human annotation, quantitative metrics, and visual clustering to assess profile \ndistinctiveness. Behavioral profiles are evaluated through human annotation, quantitative metrics, and visual clustering. \nThis multi-method approach validates both simulator compliance with specified profile characteristics and clinical realism \nof generated responses while maintaining interpretability and scalability. \n4.7 Human Annotation \nThe expressed medical concepts, linguistic and behavioral profiles are independently annotated by two human \nannotators with complementary domain expertise: one annotator holds a graduate degree in Psychology, and the other is a \nlicensed Nurse Practitioner with clinical experience. Each sample was doubly annotated to ensure reliability, and any \ndisagreements were discussed and resolved through collective adjudication by the annotators to arrive at a final consensus \nlabel. \n4.7.1 Medical Profile Evaluation \nAs previously described, the patient simulator generates responses through a chain-of-thought process: (1) identify \nmedical facts relevant to the current question, (2) rephrase each fact according to the linguistic profile, and (3) construct a \nnatural language response integrating both linguistic and behavioral characteristics. This structured generation enables \ntargeted evaluation of expression accuracy. \nFor each conversational turn, annotators assess whether medical concepts identified by the simulator as relevant are \naccurately expressed in the final response. The simulator outputs both the set of concepts it selected (with numerical \nreferences, e.g., [2.3]) and its natural language response. Table 4 summarizes the labels used to evaluate each medical \nconcept as Accurate, Inaccurate, or Unsupported. Minor colloquialisms (e.g., \"happy pills\" for \"Prozac\") are acceptable if \ncore meaning is preserved. This approach evaluates expression fidelity conditioned on correct concept retrieval. Concept \nrecall, defined as the proportion of patient profile concepts successfully expressed during the conversation, is computed \n \n2 GitHub link to be provided upon acceptance. \n"}, {"page": 14, "text": " \n \n \nprogrammatically from the simulator‚Äôs traced outputs, with approximately 95% of concept codes appearing at least once \nin the generated conversations.  \nTable 4. Labels for evaluating the medical profile in patient simulator \nLabel \nDefinition \nAccurate \nMedical fact present in the reference medical history and correctly expressed with realistic phrasing. Minor \nconversational simplifications (e.g., \"happy pills\" for \"Prozac\") permitted if core clinical meaning is preserved. \nInaccurate \nMedical fact present in the reference medical history but misrepresented, distorting critical clinical details or \nusing implausible phrasing. \nUnsupported \nMedical fact not present in the reference medical history; fabricated, speculative, or unrelated to the provided \nprofile. \n \nControlled Error Injection for System Validation. Preliminary investigation revealed that the patient simulator \nexpresses nearly all retrieved medical concepts accurately. Without errors present, annotators could achieve artificially \nhigh accuracy and agreement by labeling all concepts as Accurate, and LLM judge validation would similarly lack \ndiscriminative power. To enable rigorous evaluation, we introduce controlled semantic perturbations into a subset of \nmedical profiles by replacing original clinical concepts with semantically similar but clinically distinct alternatives. For \nexample, \"hypertension\" might be replaced with \"prehypertension\" or \"diabetes mellitus\" with \"prediabetes,\" conditions \nthat are semantically related but clinically distinct enough for trained annotators to detect as inaccurate. \nPerturbations are selected through a two-stage filtering process. First, semantic search over a vector database of \nSNOMED CT and CPT4 concepts identifies the top 20 semantically similar candidates. Second, candidates are randomly \nordered and evaluated sequentially: ontology-based filtering removes hierarchical ancestors or descendants (for SNOMED \nCT and CPT4) and enforces minimum hierarchical distance, with the first candidate satisfying both constraints selected as \nthe perturbation. If no candidate qualifies, the similarity threshold is relaxed or the candidate pool is expanded. The \nresulting perturbed profiles maintain linguistic realism while introducing subtle clinical inaccuracies suitable for evaluating \nboth human annotation quality and LLM judge performance. \n4.7.2 Linguistic Profile Evaluation \nLinguistic profiles are evaluated through human annotation and quantitative metrics in which annotators categorize each \nconversation by assigning it to one of five predefined linguistic profiles as a classification task. Five automated metrics are \nused to characterize the linguistic profile effectiveness. \n     1. Reading Level: Measuring using Flesch‚ÄìKincaid Grade Level (FKGL) [24], which estimates the U.S. school grade \nlevel required to comprehend text based on word and sentence length. FKGL is calculated per response turn and averaged \nacross each simulated conversation..  \n2. Average Response Length: Average number of words per turn using NLTK‚Äôs English  tokenizer [36].. \n3. Medical Term:   Counts clinical terms in patient responses using concept names from the database we use as the \nmedical lexicon, applying greedy n-gram matching up to 6-grams. \n4. Depression Score: Estimates the degree to which each response reflects depressive symptomology using a XLM-\nRoBERTa based classifier [71] that outputs a probability score. We average across turns to produce a conversation-level \nscore.  \n5. t-SNE: Visualizes by projecting high-dimensional linguistic features to two dimensions using cosine distance, with \npoints colored by profile. Multiple random seeds are tested, reporting the run with lowest KL divergence. \n"}, {"page": 15, "text": " \n \n \n4.7.3 Behavioral Profile Evaluation \nBehavior profiles are evaluated through human annotation in which annotators categorize each conversation by \nassigning it to one of three predefined behavioral profiles as a classification task and quantitative metrics for adherence, \ntopical focus, and adversarial behavior. Three automatic metrics quantify behavioral patterns.  \n1. On-topic similarity: Measured as average cosine similarity between OpenAI‚Äôs text-embedding-3-small embeddings \nof each AI Decision Aid output and the associated patient simulator response. \n2. Toxicity or impoliteness: Quantifies hostile or disrespectful language using an existing XLM-RoBERTa based \ntoxicity classifier [74]. Conversation-level toxicity is summarized as the mean of turn-level toxicity probabilities produced \nby the classifier.  \n3. t-SNE: Analogous to linguistic t-SNE, but projecting behavioral features and color-coding by behavioral profile.  \n4.7.4 LLM Judge Evaluation \nLLM-based judges have demonstrated strong performance in healthcare evaluation tasks [7, 42, 67]. We employ a \nseparate model (Claude Opus 4.6) as an automated judge, applying the same annotation schema across medical, linguistic, \nand behavioral dimensions. The prompt is prepared on a separate set of 45 conversations. Evaluation follows two stages. \nFirst, an alignment validation phase where the LLM‚Äôs judgments are compared against human annotations on a selected \nsubset of conversations to assess agreement. Second, large-scale annotation where the validated model evaluates the full \ndataset, enabling scalable evaluation. \n4.7.5 Experimental Paradigm \nExperiments used 60 medical profiles evaluated across the four antidepressants (Sertraline 17%, Trazodone 15%, \nFluoxetine 13%, and Duloxetine 11%) selected to reflect common clinical practice [75]. Medical profiles were \nsystematically combined with linguistic and behavioral configurations to evaluate variation in expression characteristics.  \nThe design comprises three evaluation settings: (1) linguistic variation ‚Äì five linguistic profiles with fixed Structured \n& Cooperative behavior (300 conversations), (2) behavioral variation ‚Äì three behavioral profiles with fixed Functional \nHealth Literacy (180 conversations), and (3) intersectional analysis ‚Äì combined linguistic-behavioral variation across a \nrepresentative subset (150 conversations). After accounting for shared profiles across settings, the design yields 500 unique \nsimulated conversations. The patient simulator and AI Decision Aid are powered by GPT-4.1, while Claude Opus 4.6 is \nused as the LLM-based judge for evaluation. For RAG-based data extraction, we use OpenAI‚Äôs text-embedding-3-small \nembedding model, and the conversational AI Decision Aid and Simulator are implemented as separate agents within the \nLangGraph framework. \n5 RESULTS \n5.1 Medical Profile Validation \nMedical profile fidelity was assessed through 1,787 medical concepts across 100 conversations, including 292 perturbed \nconcepts, as described in Section 4.3.1. Table 5 shows agreement between human annotators and the LLM judge. For \nunperturbed concepts, annotators achieved high agreement (F1=0.94, Œ∫=0.73), indicating reliable identification of \naccurately expressed medical concepts. Agreement decreased for perturbed samples (F1=0.76, Œ∫=0.30), reflecting the \nchallenge of detecting subtle semantic substitutions, which is the intended purpose of controlled perturbations. Agreement \nbetween human annotators and the LLM judge was high for unperturbed concepts (F1 = 0.94, Œ∫ = 0.78), computed over \n"}, {"page": 16, "text": " \n \n \nthe set of concepts identified by human annotators. Agreement decreased for perturbed samples (F1 = 0.77, Œ∫ = 0.24), with \nthe LLM judge additionally assigning 76 Unsupported labels not identified by human annotators, corresponding to \nincidental medication mentions (e.g., Tylenol, ibuprofen) and minor symptom references (e.g., headache, neck pain) that \nwere not explicitly encoded in the structured relevant items. These agreement levels validate that the simulator reliably \nexpresses specified medical profiles and that both human annotators and LLM judges can consistently assess expression \naccuracy. We also performed a paired bootstrap test [76] with 10,000 resamples. We found that human‚Äìhuman agreement \n(Œ∫ = 0.73) was slightly higher than agreement between individual human annotators and the LLM (Œ∫ = 0.70‚Äì0.71), but \nthese differences were not statistically significant (p = 0.21 and p = 0.32). Agreement between the LLM and each annotator \nalso did not differ significantly (p = 0.63), indicating no systematic annotator-specific bias. Overall, LLM‚Äìhuman \nagreement was comparable to human‚Äìhuman agreement within sampling variability.  \nTable 5. Agreement metrics for unperturbed and perturbed medical concept labels. \nConcept Type \nn \nHuman Agreement \nHuman-LLM Judge Agreement \nF1 (micro) \nCohen‚Äôs Œ∫ \nF1 (micro) \nCohen‚Äôs Œ∫ \nUnperturbed Concepts \n1,495 \n0.94 \n0.73 \n0.95 \n0.78 \nPerturbed Concepts  \n292 \n0.76 \n0.30 \n0.77 \n0.24 \n \nLLM Judge Evaluation of Medical Profile.  The LLM judge annotated a total of 8,210 expressed concepts, of which \n96.61% were labeled Accurate, 1.07% Inaccurate, and 2.31% Unsupported, indicating that the vast majority of extracted \nconcepts were assessed as correct, with only a small fraction reflecting factual errors or unsupported assertions. Table 6 \nshows LLM judge evaluation of medical profiles across the linguistic profile under a fixed Structured & Cooperative \nbehavioral condition. Results align closely with intended linguistic profile definitions. Information density increases across \nthe literacy gradient, peaking with the Proficient Health Literacy profile. However, error types diverge by profile: the \nProficient Health Literacy profile is most prone to unsupported claims due to its linguistic complexity, while the Illness \nAnxiety Disorder profile generates the maximum volume of inaccuracies due to its repetitive and urgent tone. Conversely, \nthe Depressed profile produces the sparsest data output with minimal error interference. \nTable 6: LLM Judge Evaluation of Medical profile across the linguistic profiles under a Structured & Cooperative behavioral condition \nProfile Name \\ Evaluation Metrics \nAccurate \nInaccurate \nUnsupported \nHealth Literacy \nLimited \n849 \n11 \n3 \nFunctional \n935 \n13 \n4 \nProficient \n968 \n3 \n10 \nCondition-specific \nDepression \n826 \n9 \n7 \nIllness Anxiety Disorder \n1146 \n30 \n16 \n \nTable 7 reveals that behavioral variation acts as a primary catalyst for reliability shifts within the Functional Health \nLiteracy profile. While the Structured & Cooperative baseline ensures stability, the Distracted & Unfocused behavior \nrepresents a critical reliability gap characterized by frequent unsupported outputs. Conversely, the Adversarial & \nCombative condition maximizes information extraction and minimizes logic errors, likely due to the intense topical focus \ninherent in combative engagement. \n"}, {"page": 17, "text": " \n \n \nTable 7: LLM Judge Evaluation of Medical Profile across the behavioral profiles under a Functional Health Literacy linguistic \ncondition. \nBehavioral Profile \nAccurate \nInaccurate \nUnsupported \nStructured & Cooperative \n935 \n13 \n4 \nDistracted & Unfocused \n884 \n5 \n99 \nAdversarial & Combative \n1087 \n0 \n8 \n \nFigure 4 shows that the intersection of linguistic and behavioral profiles dictates the specific type of system failure. \nWhile behavioral distraction primarily triggers unsupported claims in literacy-focused profiles, adversarial interaction \ntends to drive inaccuracies in more complex or urgent linguistic profiles. Ultimately, the Structured & Cooperative \ncondition remains the only environment where accuracy is maintained across the entire linguistic spectrum with minimal \nerror interference. \n \nFigure 4: Results from the intersection of Linguistic and Behavioral Profiles \n5.2 Linguistic Profile Validation \nHuman annotators showed moderate agreement on linguistic profile classification: Cohen‚Äôs Œ∫=0.61 and 0.7 micro F1. \nHuman annotators and the LLM exhibit similar agreement scores ( Œ∫=0.63 and micro F1=0.7) in linguistic profile \nclassification. When adjudicated labels were compared to the simulator‚Äôs predefined linguistic profiles, profile \nidentification achieved 0.87 micro F1, indicating consistent expression of intended linguistics profiles. We then computed \nthe accuracy of the LLM judge across 500 conversations against the predefined linguistic profiles, yielding a micro F1 \nscore of 0.96. \n"}, {"page": 18, "text": " \n \n \nTable 8 shows linguistic variation under a fixed Structured & Cooperative behavioral condition, with quantitative \ndifferences aligning with the intended profile definitions. Reading level increases monotonically across the literacy \ngradient from Limited (FKGL=3.59) to Proficient (FKGL=11.90). Responses similarly vary from shorter and less technical \nat Limited (34.34 words, 4.33 medical terms) to longer and more technical at Proficient (38.90 words, 11.68 medical \nterms). The Depression profile produces the shortest responses (18.20 words) and the highest depression score (0.74), \nwhile Illness Anxiety Disorder responses are longer (65.05 words) with highest density of medical terms (14.27 medical \nterms).  \nTable 8 Evaluation of linguistic profiles under a Structured & Cooperative behavioral condition. \nProfile Name \\ Evaluation Metrics \nReading Level \nResponse Length \n# Medical Terms \nDepression Score \nHealth Literacy \nLimited \n3.59 \n34.34 \n4.33 \n0.0075 \nFunctional \n7.63 \n28.70 \n9.83 \n0.0044 \nProficient \n11.90 \n38.91 \n11.68 \n0.0014 \nCondition-specific \nDepression \n4.49 \n21.48 \n6.17 \n0.2039 \nIllness Anxiety Disorder \n8.11 \n65.05 \n14.27 \n0.25 \n \nFigure 6 shows t-SNE clustering where linguistic profiles form distinct neighborhoods. Profiles with similar \ncharacteristics show proximity, notably the Functional and Proficient Health Literacy. The Depression profile overlaps \npartially with lower literacy profiles, while Illness Anxiety Disorder forms a more distinct cluster. Overall, the combined \nnumerical metrics and embedding separation demonstrate that the simulator expresses graded and interpretable linguistic \nvariation while maintaining realistic continuity across profiles. The simulator expresses distinct linguistic profiles, \nvalidated by human judgments, quantitative metrics, and visual clustering. \n \n"}, {"page": 19, "text": " \n \n \n \n \nFigure 5: t-SNE visualization of response embeddings for linguistic profiles under a Structured & Cooperative behavioral condition. \n5.3 Behavioral Profile Validation \nHuman annotators showed high agreement on behavioral profile classification: Cohen‚Äôs Œ∫=0.93 and 0.96 micro F1. \nHuman annotators and the LLM exhibit similar agreement scores ( Œ∫=0.93 and micro F1=0.96) in behavioral profile \nclassification. When adjudicated labels from annotators were compared to the simulator‚Äôs predefined behavioral profiles, \nidentification achieved 0.98 micro F1, indicating consistent expression of the intended profiles.  \nTable 9 shows behavioral variation under a fixed Functional Health Literacy linguistic profile. Structured & \nCooperative achieves a comparable on-topic similarity (0.51) and the lowest toxicity score (0.0003). Distracted & \nUnfocused shows reduced on-topic similarity (0.50), consistent with conversational drift, while maintaining low toxicity \n(0.0035). In contrast, Adversarial & Combative exhibits substantially higher toxicity or impoliteness (0.064), while \nretaining the highest topical relevance (0.52). \nTable 9. Evaluation of behavioral profiles under a Functional Health Literacy linguistic condition. \nProfile \nOn-topic Similarity \nToxicity or Impoliteness \nStructured & Cooperative \n0.5133 \n0.0003 \nDistracted & Unfocused \n0.4975 \n0.0035 \nAdversarial & Combative \n0.5219 \n0.0564 \n \nFigure 6 shows t-SNE clustering with clear separation among behavioral profiles, indicating that behavioral differences \nare consistently reflected in system responses despite a fixed linguistic expression profile. The simulator produces distinct \nbehavioral profiles, supported by human judgments, quantitative metrics, and visual clustering. \n"}, {"page": 20, "text": " \n \n \n \nFigure 6:  t-SNE visualization of response embeddings showing clear separation among behavioral profiles under a fixed Functional \nHealth Literacy condition. \n5.4 Profile Interactions \nFigure 7 presents intersectional evaluation across linguistic and behavioral profile combinations. Linguistic profiles \nappear in columns and behavioral profiles in rows for direct comparison across metrics. Key interaction patterns emerge: \nbehavioral profiles modulate response length substantially, with Distracted & Unfocused consistently producing the \nlongest responses across all linguistic profiles (61-82 words vs. 21-66 for Structured & Cooperative). Toxicity shows the \nstrongest behavioral dominance, with Adversarial & Combative profiles exhibiting elevated toxicity (0.03-0.011) \nregardless of linguistic profile. In contrast, reading level and depression scores remain largely determined by linguistic \nprofiles, with minimal behavioral modulation. On-topic similarity shows modest behavioral effects, with Structured & \nCooperative profiles achieving slightly higher alignment than Distracted & Unfocused across most linguistic conditions. \nThese patterns demonstrate that the simulator maintains profile independence where intended (linguistic features preserved \nacross behaviors) while capturing realistic interactions (behavioral effects on engagement and tone). \n"}, {"page": 21, "text": " \n \n \n \nFigure 7 Intersection Table for Linguistic and Behavioral Profiles. \n5.5 AI Decision Aid Performance: Risk Measurement Across Patient Variation \nThis section evaluates the AI Decision Aid performance across the 500 simulated conversations spanning diverse \nmedical, linguistic, and behavioral profiles, systematically identifying performance variation and risk patterns. \nConcept Retrieval Coverage. Table 10 shows intake system recall against simulator-generated reference concepts. \nOverall recall reached 93%, with diagnoses showing the highest coverage (94%) and medications the lowest (84%). The \nsystem introduced 151 medical history concepts not in the predefined medical profiles, primarily medications (84) and \nprocedures (57), reflecting conversational elaboration. These patterns reveal strong baseline coverage with medication \nretrieval as a relative vulnerability. \nTable 10: Intake System Concept Retrieval Performance Using Simulator-Generated Reference Concepts \nMetric \nOverall \nDiagnosis \nMedication \nProcedure \nSimulator-Generated Reference Concepts \n2,819 \n2,077 \n173 \n569 \nReference Concepts Retrieved by Intake System \n2,622 \n1,958 \n146 \n518 \nReference Concepts Missed by Intake System \n197 \n119 \n27 \n51 \nIntake System Recall (%) \n93.01 \n94.27 \n84.39 \n91.03 \nMedical History Concepts Outside Simulator Reference Set \n151 \n10 \n84 \n57 \n"}, {"page": 22, "text": " \n \n \nRetrieval Accuracy and Health Literacy Effects. Table 11 reports the concept retrieval performance from the RAG \ndatabase using simulator-generated reference concepts. The results show that a substantial proportion of concepts are \ncorrectly retrieved at the highest rank, indicating that the system frequently aligns generated references with the most \nrelevant database entries. However, a notable share of concepts are retrieved at lower ranks (Top - 15) rather than at rank \none, reflecting ranking imprecision rather than complete retrieval failure. This distribution suggests that while the RAG \ncomponent provides broad semantic coverage, it does not consistently prioritize the correct concept as the top-ranked \nresult. \nRisk Synthesis. Retrieval accuracy increases with the level of health literacy expressed in the responses. Rank-one \nretrieval is lowest for the Limited Health Literacy profile at 47.9%, improves for Functional Health Literacy at 69.1%, \nand reaches its highest level for Proficient Health Literacy at 81.6%. Profiles dominated by affective expression show \nintermediate performance, with Depression at 62.2% and Illness Anxiety Disorder at 63.4%. This monotonic improvement \nacross health literacy levels reflects the intake system‚Äôs reliance on precise terminology, explicit clinical structure, and \nwell-formed descriptions to correctly prioritize concepts during retrieval, while less structured, emotionally driven, or \nvague expressions reduce ranking accuracy. \nTable 11: Intake System Concept Retrieval Performance Using Simulator-Generated Reference Concepts \nMetric \nValue \nTotal Conversations Evaluated \n500 \nSimulator-Generated Reference Concepts \n2,819 \nRank-1 Concept Retrieval Accuracy from RAG (%) \n65.87 % (1,857) \nConcepts Retrieved Beyond Rank-1 (%) \n27.14 % (765) \nCorrect Concept Appears Within Top-20 RAG Candidates (% of Non‚ÄìRank-1) \n82.75% (428) \nReference Concepts Not Retrieved from RAG (%) \n6.99 % (197) \nMean Retrieval Rank in RAG Database (Non‚ÄìTop-1) \n11.22 \n \nFigure 8 shows a critical retrieval risk rooted in linguistic variance: the system‚Äôs ability to extract correct clinical \nconcepts is fundamentally compromised by the communication style. Patients with Limited Health Literacy or Depression \noften use colloquial, fragmented, or affect-heavy language that fails to map onto the canonical medical concepts required \nfor accurate retrieval. This creates a conceptual misalignment where the system searches for technical descriptors while \nthe user provides noisy or vague input, leading to severe Rank-1 failures. Because even deep retrieval (Rank-20) cannot \nbridge this gap for marginalized profiles, the system poses a structural bias: it remains reliable for articulate, proficient \nspeakers while leaving vulnerable populations at a higher risk of misinterpretation or clinical omission. \n"}, {"page": 23, "text": " \n \n \n \nFigure 8: Rank-1 and Rank-20 accuracy for linguistic profiles, behavioral profiles, and their intersections. \nDownstream Risk to Antidepressant Recommendation. Table 12 reports weighted precision, recall, and F1 scores \nfor antidepressant recommendation before and after AI Decision Aid processing across combinations of linguistic and \nbehavioral profiles. Recommendations are produced by the MAGI algorithm over a fixed set of 15 antidepressants plus a \nNo Recommendation category, making downstream predictions sensitive to information loss introduced during intake. \nPerformance improves with higher health literacy, with Proficient Health Literacy achieving the strongest weighted F1 \nscores, while Limited Health Literacy shows consistently lower performance, indicating elevated risk under less explicit \nexpression. Behavioral style further modulates this risk: Structured & Cooperative interactions yield more stable outcomes, \nwhereas Distracted and Adversarial exchanges are associated with reduced precision and recall. Overall, the results identify \nlinguistic ambiguity and interactional disruption as key risk factors affecting the robustness of antidepressant \nrecommendation through the intake system. \n"}, {"page": 24, "text": " \n \n \nTable 12: Scores for antidepressant recommendation before and after AI Decision Aid processing across linguistic and behavioral \nprofile combinations. \nBehavioral Profile \nLinguistic Profile  \nNo. of Conversation \nPrecision \nRecall \nF1 \nStructured & \nCooperative \nLimited HL \n60 \n0.47 \n0.61 \n0.48 \nFunctional HL \n60 \n0.58 \n0.70 \n0.59 \nProficient HL \n60 \n0.72 \n0.80 \n0.73 \nDepression \n60 \n0.60 \n0.69 \n0.61 \nIllness Anxiety Disorder \n60 \n0.67 \n0.78 \n0.69 \nDistracted & \nUnfocused \nLimited HL \n10 \n0.33 \n0.40 \n0.34 \nFunctional HL \n60 \n0.63 \n0.58 \n0.59 \nProficient HL \n10 \n0.75 \n0.70 \n0.71 \nDepression \n10 \n0.78 \n0.80 \n0.77 \nIllness Anxiety Disorder \n10 \n0.43 \n0.60 \n0.50 \nAdversarial & \nCombative \nLimited HL \n10 \n0.63 \n0.50 \n0.49 \nFunctional HL \n60 \n0.74 \n0.68 \n0.70 \nProficient HL \n10 \n0.95 \n0.90 \n0.90 \nDepression \n10 \n0.73 \n0.70 \n0.69 \nIllness Anxiety Disorder \n10 \n0.68 \n0.80 \n0.73 \n6 DISCUSSION \nWe developed a patient simulator integrating medical, linguistic, and behavioral profiles to operationalize the NIST AI \nRMF for evaluating conversational healthcare AI. Across 500 simulated conversations, the framework produced coherent, \ndistinguishable, and controllable simulations that exposed measurable performance variability in the target AI Decision \nAid. We validated the simulator using independent expert annotation, automated linguistic and behavioral metrics, and an \nLLM-based judge for scalable deployment. \n6.1 Medical Profile Generation \nThe MAGI algorithm generates clinically coherent profiles through risk-ratio gating and independent screening rather \nthan generative modeling. By prioritizing interpretability over distributional fidelity, we ensure profiles possess explicit \nfeature lineage traceable to source EHR data. This transparency offers a practical advantage over black-box generative \nmethods for risk assessment, where auditors must trace specific feature origins. Evaluation confirmed the patient simulator \nmaintained high fidelity to the defined medical profiles. To validate the simulator and the LLM judge, we used a controlled \nerror injection methodology. Semantically similar but clinically distinct perturbations (e.g., replacing hypertension with \npre-hypertension) increased sensitivity to subtle distinctions. Lower annotator agreement on perturbed samples (0.75 F1) \ncompared to unperturbed samples (0.94 F1) reflects the intended challenge of approximating real-world concept ambiguity. \n6.2 Linguistic and Behavioral Profile Effectiveness \nThe simulator produced measurably distinct profiles across both linguistic and behavioral dimensions. Behavior profiles \nachieved high annotator agreement (Œ∫ = 0.93), while the linguistic profiles achieved moderate agreement (Œ∫ = 0.61). \nBehavior profiles produced categorically different conversational dynamics, while the linguistic profiles yielded a more \ncontinuous gradient across health literacy levels. Functional and Proficient Health Literacy profiles overlap because they \nare genuinely similar along this continuum, not because of poor specification.  \nCross-dimensional analysis validated the compositional design combining linguistics and behaviors. Linguistic features \n(reading level, depression scores) remained stable across behavioral conditions, and behavioral features (toxicity, response \nlength) remained stable across linguistic conditions. We noted two interaction effects: Distracted & Unfocused behavior \n"}, {"page": 25, "text": " \n \n \nconsistently increased response length, reflecting digressions. Adversarial & Combative behavior increased toxicity scores, \nregardless of the linguistic profile.  \n6.3 Health Literacy as Risk Factor for Clinical AI \nThe patient simulator revealed a monotonic decrease in AI Decision Aid performance across the health literacy gradient. \nRank-one concept retrieval increased across from 47.9% (Limited) to 69.% (Functional) to 81.6% (Proficient). This pattern \npersisted in the downstream antidepressant recommendation task, exposing a concrete equity risk. The gradient reflects the \nsystem‚Äôs reliance on precise terminology. When a patient described ‚Äúmy morning pill for my nerves‚Äù rather than ‚Äú20 mg \nof fluoxetine for generalized anxiety disorder,‚Äù the retrieval system must resolve a larger semantic distance. This implies \nthe MANAGE function of the AI RMF requires interventions, such as the need for clarification prompting, terminology \nnormalization, or multi-pass retrieval to maintain equitable performance. The condition-specific profiles showed \nintermediate retrieval performance (Depression 62.2%, Illness Anxiety Disorder 63.4%), suggesting affective expression \nalso degrades performance, though less severely than low health literacy.  \n6.4 LLM judge Viability \nThe LLM judge aligned strongly with human annotators for unperturbed concepts (Œ∫ = 0.94) but showed lower \nagreement for perturbed concepts (Œ∫ = 0.24) mirroring the divergence among human annotators. The judge also identified \n76 Unsupported labels for incidental medications and symptoms absent from the structured profile, indicating a stricter \ninterpretation of the annotation schema. These results support deploying the LLM judge for large-scale screening, reserving \nhuman review for edge cases. \n6.5 Limitations \nOur study has several limitations. First, we have not validated the simulated conversations against real patient \ninteractions. While profiles are grounded in clinical data and literature, ecological validity remains untested and will be \nevaluated in a planned real-world trial. Second, we evaluated a single clinical task (intake for depression management); \nhealth literacy effects may manifest differently in other domains. Third, the AI Decision Aid selected from only four \nantidepressants, though many additional antidepressants are available in clinical practice. Finally, medical profiles relied \nexclusively on structured EHR data. This excludes unstructured narratives that often contain nuanced context. Due to \nindependence screening criterion, medical profiles may exclude valid coupled comorbidities (e.g., diabetes and diabetic \nneuropathy), potentially underrepresenting patients with strongly correlated conditions. \n6.6 Future Directions \nThis work explored the MAP and MEASURE functions of the AI RMF. Future studies will integrate the MANAGE \nfunction to mitigate the identified AI risks in the AI Decision Aid. \n7 CONCLUSION \nThis work presents a patient simulator integrating medical, linguistic, and behavioral profiles to support systematic \nevaluation of conversational healthcare AI within the NIST AI RMF framework. The system produced 500 coherent, \ncontrollable, and distinguishable simulations validated by human annotation and an LLM-based judge. The study revealed \nfindings with direct implications for the target AI Decision Aid, particularly the monotonic degradation in concept retrieval \n"}, {"page": 26, "text": " \n \n \nand medication accuracy across health literacy levels. The patient simulator code, source data, and conversation logs are \npublicly available to facilitate reuse across clinical evaluation settings3. \n8 ACKNOWLEDGMENTS \n      Research reported in this article was funded through a Patient-Centered Outcomes Research Institute (PCORI) Award \n(ME-2024C1-36732). The views in this article are solely the responsibility of the authors and do not necessarily represent \nthe views of the PCORI, its Board of Governors or Methodology Committee. \n      The study used data from the All of Us Research Program‚Äôs Registered Tier Dataset v8, available to all authorized \nusers on the Researcher Workbench. We gratefully acknowledge All of Us participants for their contributions, without \nwhom this research would not have been possible. We also thank the National Institutes of Health‚Äôs All of Us Research \nProgram for making available the participant data examined in this study. \n      IRB review:  This project was examined by George Mason University‚Äôs Institutional Review Board (study 2154028-1 \nfor work on All-of-Us database and study 00000437‚ÄØfor evaluation of text of the advice through annotation) was considered \n‚Äúnot research‚Äù in the context of the definition of research on human subjects by the United States Department of Health \nand Human Services. \n9 HISTORY DATES \nREFERENCES \n[1] Farrokh Alemi, Mai Aljuaid, Naren Durbha, Melanie Yousefi, Hua Min, Louisa G. Sylvia, and Andrew A. \nNierenberg. 2021. A surrogate measure for patient reported symptom remission in administrative data. BMC \nPsychiatry 21, (March 2021), 121. https://doi.org/10.1186/s12888-021-03133-1 \n[2] Farrokh Alemi, Yili Lin, Hadeel R. A. Elyazori, Vladimir Franzuela Cardenas, Niloofar Ramezani, and Kevin \nLybarger. 2025. Medical Artificial General Intelligence Algorithm: Estimation of Dependent Bayes through Causal \nNetworks. https://doi.org/10.2139/ssrn.5749483 \n[3] All of Us Research Program Investigators, Joshua C. Denny, Joni L. Rutter, David B. Goldstein, Anthony Philippakis, \nJordan W. Smoller, Gwynne Jenkins, and Eric Dishman. 2019. The ‚ÄúAll of Us‚Äù Research Program. N. Engl. J. Med. \n381, 7 (August 2019), 668‚Äì676. https://doi.org/10.1056/NEJMsr1809937 \n[4] Krisztian Balog and ChengXiang Zhai. 2023. User Simulation for Evaluating Information Access Systems. In \nProceedings of the Annual International ACM SIGIR Conference on Research and Development in Information \nRetrieval in the Asia Pacific Region (SIGIR-AP ‚Äô23), November 26, 2023. Association for Computing Machinery, \nNew York, NY, USA, 302‚Äì305. https://doi.org/10.1145/3624918.3629549 \n[5] Krisztian Balog and ChengXiang Zhai. 2023. User Simulation for Evaluating Information Access Systems. In \nProceedings of the Annual International ACM SIGIR Conference on Research and Development in Information \nRetrieval in the Asia Pacific Region (SIGIR-AP ‚Äô23), November 26, 2023. Association for Computing Machinery, \nNew York, NY, USA, 302‚Äì305. https://doi.org/10.1145/3624918.3629549 \n[6] Zhijie Bao, Qingyun Liu, Xuanjing Huang, and Zhongyu Wei. 2025. SFMSS: Service Flow aware Medical Scenario \nSimulation for Conversational Data Generation. In Findings of the Association for Computational Linguistics: \nNAACL 2025, April 2025. Association for Computational Linguistics, Albuquerque, New Mexico, 4586‚Äì4604. \nhttps://doi.org/10.18653/v1/2025.findings-naacl.259 \n[7] Savita Bhat and Vasudeva Varma. 2023. Large Language Models As Annotators: A Preliminary Evaluation For \nAnnotating Low-Resource Language Content. In Proceedings of the 4th Workshop on Evaluation and Comparison \nof NLP Systems, November 2023. Association for Computational Linguistics, Bali, Indonesia, 100‚Äì107. \nhttps://doi.org/10.18653/v1/2023.eval4nlp-1.8 \n \n3 Link to be provided upon acceptance. \n"}, {"page": 27, "text": " \n \n \n[8] Anna Bodonhelyi, Christian Stegemann-Philipps, Alessandra Sonanini, Lea Herschbach, Marton Szep, Anne \nHerrmann-Werner, Teresa Festl-Wietek, Enkelejda Kasneci, and Friederike Holderried. 2025. Modeling Challenging \nPatient Interactions: LLMs for Medical Communication Training. ArXiv E-Prints (March 2025), arXiv:2503.22250. \nhttps://doi.org/10.48550/arXiv.2503.22250 \n[9] CDC. 2024. National Action Plan to Improve Health Literacy. Health Literacy. Retrieved November 4, 2025 from \nhttps://www.cdc.gov/health-literacy/php/develop-plan/national-action-plan.html \n[10] Kevin E. Cevasco, Rachel E. Morrison Brown, Rediet Woldeselassie, and Seth Kaplan. 2024. Patient Engagement \nwith Conversational Agents in Health Applications 2016‚Äì2022: A Systematic Review and Meta-Analysis. J. Med. \nSyst. 48, 1 (2024), 40. https://doi.org/10.1007/s10916-024-02059-x \n[11] Xingran Chen, Zhenke Wu, Xu Shi, Hyunghoon Cho, and Bhramar Mukherjee. 2025. Generating synthetic electronic \nhealth record data: a methodological scoping review with benchmarking on phenotype data and open-source software. \nJ. Am. Med. Inform. Assoc. 32, 7 (July 2025), 1227‚Äì1240. https://doi.org/10.1093/jamia/ocaf082 \n[12] David A Cook, Joshua Overgaard, V Shane Pankratz, Guilherme Del Fiol, and Chris A Aakre. 2025. Virtual Patients \nUsing Large Language Models: Scalable, Contextualized Simulation of Clinician-Patient Dialogue With Feedback. \nJ. Med. Internet Res. 27, (April 2025), e68486. https://doi.org/10.2196/68486 \n[13] Jessamyn Dahmen and Diane Cook. 2019. SynSys: A Synthetic Data Generation System for Healthcare Applications. \nSensors 19, 5 (January 2019), 1181. https://doi.org/10.3390/s19051181 \n[14] Jan Deriu, Alvaro Rodrigo, Arantxa Otegi, Guillermo Echegoyen, Sophie Rosset, Eneko Agirre, and Mark Cieliebak. \n2021. Survey on evaluation methods for dialogue systems. Artif. Intell. Rev. 54, 1 (January 2021), 755‚Äì810. \nhttps://doi.org/10.1007/s10462-020-09866-x \n[15] David DeVault, Ron Artstein, Grace Benn, Teresa Dey, Kallirroi Georgila, Jon Gratch, Arno Hartholt, Margaux \nLhommet, Gale Lucas, Stacy Marsella, Fabrizio Morbini, Angela Nazarian, Stefan Scherer, Giota Stratou, Apar Suri, \nDavid Traum, Rachel Wood, Yuyu Xu, Albert Rizzo, and Louis-Philippe Morency. SimSensei Kiosk: A Virtual \nHuman Interviewer for Healthcare Decision Support.  \n[16] Kathleen Kara Fitzpatrick, Alison Darcy, and Molly Vierhile. 2017. Delivering Cognitive Behavior Therapy to Young \nAdults With Symptoms of Depression and Anxiety Using a Fully Automated Conversational Agent (Woebot): A \nRandomized Controlled Trial. JMIR Ment. Health 4, 2 (June 2017), e7785. https://doi.org/10.2196/mental.7785 \n[17] Chen Gao, Xiaochong Lan, Nian Li, Yuan Yuan, Jingtao Ding, Zhilun Zhou, Fengli Xu, and Yong Li. 2024. Large \nlanguage models empowered agent-based modeling and simulation: a survey and perspectives. Humanit. Soc. Sci. \nCommun. 11, 1 (September 2024), 1259. https://doi.org/10.1057/s41599-024-03611-3 \n[18] Shengyue Guan, Haoyi Xiong, Jindong Wang, Jiang Bian, Bin Zhu, and Jian-guang Lou. 2025. Evaluating LLM-\nbased Agents for Multi-Turn Conversations: A Survey. https://doi.org/10.48550/arXiv.2503.22458 \n[19] Isabelle Guyon and Andr√© Elisseeff. 2003. An introduction to variable and feature selection. J Mach Learn Res 3, \nnull (March 2003), 1157‚Äì1182. \n[20] Hanchuan Peng, Fuhui Long, and C. Ding. 2005. Feature selection based on mutual information criteria of max-\ndependency, max-relevance, and min-redundancy. IEEE Trans. Pattern Anal. Mach. Intell. 27, 8 (August 2005), \n1226‚Äì1238. https://doi.org/10.1109/TPAMI.2005.159 \n[21] Friederike Holderried, Christian Stegemann-Philipps, Anne Herrmann-Werner, Teresa Festl-Wietek, Martin \nHolderried, Carsten Eickhoff, and Moritz Mahling. 2024. A Language Model‚ÄìPowered Simulated Patient With \nAutomated Feedback for History Taking: Prospective Study. JMIR Med. Educ. 10, (August 2024), e59213. \nhttps://doi.org/10.2196/59213 \n[22] Institute of Medicine (US) Committee on Health Literacy. 2004. Health Literacy: A Prescription to End Confusion. \nNational \nAcademies \nPress \n(US), \nWashington \n(DC). \nRetrieved \nFebruary \n8, \n2026 \nfrom \nhttp://www.ncbi.nlm.nih.gov/books/NBK216032/ \n[23] Mark Kalinich, James Luccarelli, Frank Moss, and John Torous. 2025. Leveraging simulation to provide a practical \nframework for assessing the novel scope of risk of LLMs in healthcare. 2025.11.10.25339903. \nhttps://doi.org/10.1101/2025.11.10.25339903 \n[24] J. P. Kincaid, Jr Fishburne, Richard L. Rogers, and Brad S. Chissom. 1975. Derivation of New Readability Formulas \n(Automated Readability Index, Fog Count and Flesch Reading Ease Formula) for Navy Enlisted Personnel. (February \n1975). Retrieved February 10, 2026 from https://apps.dtic.mil/sti/html/tr/ADA006655/ \n[25] Ahmet Baki Kocaballi, Shlomo Berkovsky, Juan C. Quiroz, Liliana Laranjo, Huong Ly Tong, Dana Rezazadegan, \nAgustina Briatore, and Enrico Coiera. 2019. The Personalization of Conversational Agents in Health Care: Systematic \nReview. J. Med. Internet Res. 21, 11 (November 2019), e15360. https://doi.org/10.2196/15360 \n"}, {"page": 28, "text": " \n \n \n[26] Wai-Chung Kwan, Xingshan Zeng, Yuxin Jiang, Yufei Wang, Liangyou Li, Lifeng Shang, Xin Jiang, Qun Liu, and \nKam-Fai Wong. 2024. MT-Eval: A Multi-Turn Capabilities Evaluation Benchmark for Large Language Models. In \nProceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, 2024. Association for \nComputational Linguistics, Miami, Florida, USA, 20153‚Äì20177. https://doi.org/10.18653/v1/2024.emnlp-main.1124 \n[27] Daeun Kyung, Hyunseung Chung, Seongsu Bae, Jiho Kim, Jae Ho Sohn, Taerim Kim, Soo Kyung Kim, and Edward \nChoi. \n2025. \nPatientSim: \nA \nPersona-Driven \nSimulator \nfor \nRealistic \nDoctor-Patient \nInteractions. \nhttps://doi.org/10.48550/arXiv.2505.17818 \n[28] Sahiti Labhishetty. 2023. Models and evaluation of user simulation in information retrieval. Thesis. University of \nIllinois at Urbana-Champaign. Retrieved November 29, 2025 from https://hdl.handle.net/2142/120103 \n[29] Liliana Laranjo, Adam G Dunn, Huong Ly Tong, Ahmet Baki Kocaballi, Jessica Chen, Rabia Bashir, Didi Surian, \nBlanca Gallego, Farah Magrabi, Annie Y S Lau, and Enrico Coiera. 2018. Conversational agents in healthcare: a \nsystematic \nreview. \nJ. \nAm. \nMed. \nInform. \nAssoc. \nJAMIA \n25, \n9 \n(July \n2018), \n1248‚Äì1258. \nhttps://doi.org/10.1093/jamia/ocy072 \n[30] Gibbeum Lee, Volker Hartmann, Jongho Park, Dimitris Papailiopoulos, and Kangwook Lee. 2023. Prompted LLMs \nas Chatbot Modules for Long Open-domain Conversation. In Findings of the Association for Computational \nLinguistics: ACL 2023, 2023. 4536‚Äì4554. https://doi.org/10.18653/v1/2023.findings-acl.277 \n[31] Seanie Lee, Minsu Kim, Lynn Cherif, David Dobre, Juho Lee, Sung Ju Hwang, Kenji Kawaguchi, Gauthier Gidel, \nYoshua Bengio, Nikolay Malkin, and Moksh Jain. 2025. LEARNING DIVERSE ATTACKS ON LARGE \nLANGUAGE MODELS FOR ROBUST RED-TEAMING AND SAFETY TUNING. (2025). \n[32] Abigail E Lewis, Nicole Weiskopf, Zachary B Abrams, Randi Foraker, Albert M Lai, Philip R O Payne, and Aditi \nGupta. 2023. Electronic health record data quality assessment and tools: a systematic review. J. Am. Med. Inform. \nAssoc. 30, 10 (October 2023), 1730‚Äì1740. https://doi.org/10.1093/jamia/ocad120 \n[33] Yusheng Liao, Yutong Meng, Yuhao Wang, Hongcheng Liu, Yanfeng Wang, and Yu Wang. 2024. Automatic \nInteractive \nEvaluation \nfor \nLarge \nLanguage \nModels \nwith \nState \nAware \nPatient \nSimulator. \nhttps://doi.org/10.48550/arXiv.2403.08495 \n[34] Ernest Lim, Yajie Vera He, Jared Joselowitz, Kate Preston, Mohita Chowdhury, Louis Williams, Aisling Higham, \nKatrina Mason, Mariane Melo, Tom Lawton, Yan Jia, and Ibrahim Habli. 2025. MATRIX: Multi-Agent simulaTion \nfRamework \nfor \nsafe \nInteractions \nand \nconteXtual \nclinical \nconversational \nevaluation. \nhttps://doi.org/10.48550/arXiv.2508.19163 \n[35] Lei Liu, Xiaoyan Yang, Junchi Lei, Yue Shen, Jian Wang, Peng Wei, Zhixuan Chu, Zhan Qin, and Kui Ren. 2024. \nA Survey on Medical Large Language Models: Technology, Application, Trustworthiness, and Future Directions. \nhttps://doi.org/10.48550/arXiv.2406.03712 \n[36] Edward Loper and Steven Bird. 2002. NLTK: The Natural Language Toolkit. In Proceedings of the ACL-02 \nWorkshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational \nLinguistics, July 2002. Association for Computational Linguistics, Philadelphia, Pennsylvania, USA, 63‚Äì70. \nhttps://doi.org/10.3115/1118108.1118117 \n[37] Ming-Jie Luo, Shaowei Bi, Jianyu Pang, Lixue Liu, Ching-Kit Tsui, Yunxi Lai, Wenben Chen, Yahan Yang, Kezheng \nXu, Lanqin Zhao, Ling Jin, Duoru Lin, Xiaohang Wu, Jingjing Chen, Rongxin Chen, Zhenzhen Liu, Yuxian Zou, \nYangfan Yang, Yiqing Li, and Haotian Lin. 2025. A large language model digital patient system enhances \nophthalmology history taking skills. Npj Digit. Med. 8, 1 (August 2025), 502. https://doi.org/10.1038/s41746-025-\n01841-6 \n[38] Xiang Luo, Zhiwen Tang, Jin Wang, and Xuejie Zhang. 2024. DuetSim: Building User Simulator with Dual Large \nLanguage Models for Task-Oriented Dialogues. In Proceedings of the 2024 Joint International Conference on \nComputational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), May 2024. ELRA and \nICCL, Torino, Italia, 5414‚Äì5424. Retrieved August 14, 2025 from https://aclanthology.org/2024.lrec-main.481/ \n[39] Subhankar Maity and Manob Jyoti Saikia. 2025. Large Language Models in Healthcare and Medical Applications: A \nReview. Bioengineering 12, 6 (June 2025), 631. https://doi.org/10.3390/bioengineering12060631 \n[40] Don Nutbeam. 2000. Health literacy as a public health goal: a challenge for contemporary health education and \ncommunication strategies into the 21st century. Health Promot. Int. 15, 3 (September 2000), 259‚Äì267. \nhttps://doi.org/10.1093/heapro/15.3.259 \n[41] Michael K. Paasche-Orlow and Michael S. Wolf. 2007. The causal pathways linking health literacy to health \noutcomes. Am. J. Health Behav. 31 Suppl 1, (2007), S19-26. https://doi.org/10.5555/ajhb.2007.31.supp.S19 \n[42] Maja Pavlovic and Massimo Poesio. 2024. The Effectiveness of LLMs as Annotators: A Comparative Overview and \nEmpirical Analysis of Direct Representation. In Proceedings of the 3rd Workshop on Perspectivist Approaches to \n"}, {"page": 29, "text": " \n \n \nNLP (NLPerspectives) @ LREC-COLING 2024, May 2024. ELRA and ICCL, Torino, Italia, 100‚Äì110. Retrieved \nFebruary 11, 2026 from https://aclanthology.org/2024.nlperspectives-1.11/ \n[43] James W. Pennebaker, Matthias R. Mehl, and Kate G. Niederhoffer. 2003. Psychological Aspects of Natural \nLanguage Use: Our Words, Our Selves. Annu. Rev. Psychol. 54, Volume 54, 2003 (February 2003), 547‚Äì577. \nhttps://doi.org/10.1146/annurev.psych.54.101601.145041 \n[44] Ethan Perez, Saffron Huang, Francis Song, Trevor Cai, Roman Ring, John Aslanides, Amelia Glaese, Nat McAleese, \nand Geoffrey Irving. 2022. Red Teaming Language Models with Language Models. In Proceedings of the 2022 \nConference on Empirical Methods in Natural Language Processing, 2022. Association for Computational \nLinguistics, Abu Dhabi, United Arab Emirates, 3419‚Äì3448. https://doi.org/10.18653/v1/2022.emnlp-main.225 \n[45] Paloma Rabaey, Stefan Heytens, and Thomas Demeester. 2025. SimSUM: Simulated Benchmark with Structured \nand Unstructured Medical Records. https://doi.org/10.48550/arXiv.2409.08936 \n[46] Debra Roter and Judith A. Hall. 2006. Doctors Talking with Patients/Patients Talking with Doctors. (2006), 1‚Äì256. \n[47] Ruvini Sanjeewa, Ravi Iyer, Pragalathan Apputhurai, Nilmini Wickramasinghe, and Denny Meyer. 2024. Empathic \nConversational Agent Platform Designs and Their Evaluation in the Context of Mental Health: Systematic Review. \nJMIR Ment. Health 11, 1 (September 2024), e58974. https://doi.org/10.2196/58974 \n[48] Jost Schatzmann, Karl Weilhammer, Matt Stuttle, and Steve Young. 2006. A survey of statistical user simulation \ntechniques for reinforcement-learning of dialogue management strategies. Knowl. Eng. Rev. 21, 2 (June 2006), 97‚Äì\n126. https://doi.org/10.1017/S0269888906000944 \n[49] Yuqi Si, Jingcheng Du, Zhao Li, Xiaoqian Jiang, Timothy Miller, Fei Wang, W. Jim Zheng, and Kirk Roberts. 2021. \nDeep representation learning of patient data from Electronic Health Records (EHR): A systematic review. J. Biomed. \nInform. 115, (March 2021), 103671. https://doi.org/10.1016/j.jbi.2020.103671 \n[50] Scott Simpson and Anna McDowell. 2019. The Clinical Interview: Skills for More Effective Patient Encounters. \nRoutledge, New York. https://doi.org/10.4324/9780429437243 \n[51] Kristine S√∏rensen, Stephan Van den Broucke, James Fullam, Gerardine Doyle, J√ºrgen Pelikan, Zofia Slonska, Helmut \nBrand, and (HLS-EU) Consortium Health Literacy Project European. 2012. Health literacy and public health: a \nsystematic review and integration of definitions and models. BMC Public Health 12, (January 2012), 80. \nhttps://doi.org/10.1186/1471-2458-12-80 \n[52] Richard L. Street, Gregory Makoul, Neeraj K. Arora, and Ronald M. Epstein. 2009. How does communication heal? \nPathways linking clinician‚Äìpatient communication to health outcomes. Patient Educ. Couns. 74, 3 (March 2009), \n295‚Äì301. https://doi.org/10.1016/j.pec.2008.11.015 \n[53] Rehan Syed, Rebekah Eden, Tendai Makasi, Ignatius Chukwudi, Azumah Mamudu, Mostafa Kamalpour, Dakshi \nKapugama Geeganage, Sareh Sadeghianasl, Sander J. J. Leemans, Kanika Goel, Robert Andrews, Moe Thandar \nWynn, Arthur Ter Hofstede, and Trina Myers. 2023. Digital Health Data Quality Issues: Systematic Review. J. Med. \nInternet Res. 25, (March 2023), e42615. https://doi.org/10.2196/42615 \n[54] Elham Tabassi. 2023. Artificial Intelligence Risk Management Framework (AI RMF 1.0). NIST (January 2023). \nRetrieved October 28, 2025 from https://www.nist.gov/publications/artificial-intelligence-risk-management-\nframework-ai-rmf-10 \n[55] Arun James Thirunavukarasu, Darren Shu Jeng Ting, Kabilan Elangovan, Laura Gutierrez, Ting Fang Tan, and Daniel \nShu Wei Ting. 2023. Large language models in medicine. Nat. Med. 29, 8 (August 2023), 1930‚Äì1940. \nhttps://doi.org/10.1038/s41591-023-02448-8 \n[56] Tao Tu, Mike Schaekermann, Anil Palepu, Khaled Saab, Jan Freyberg, Ryutaro Tanno, Amy Wang, Brenna Li, \nMohamed Amin, Yong Cheng, Elahe Vedadi, Nenad Tomasev, Shekoofeh Azizi, Karan Singhal, Le Hou, Albert \nWebson, Kavita Kulkarni, S. Sara Mahdavi, Christopher Semturs, Juraj Gottweis, Joelle Barral, Katherine Chou, \nGreg S. Corrado, Yossi Matias, Alan Karthikesalingam, and Vivek Natarajan. 2025. Towards conversational \ndiagnostic artificial intelligence. Nature 642, 8067 (June 2025), 442‚Äì450. https://doi.org/10.1038/s41586-025-08866-\n7 \n[57] Jason Walonoski, Mark Kramer, Joseph Nichols, Andre Quina, Chris Moesel, Dylan Hall, Carlton Duffett, \nKudakwashe Dube, Thomas Gallagher, and Scott McLachlan. 2018. Synthea: An approach, method, and software \nmechanism for generating synthetic patients and the synthetic electronic health care record. J. Am. Med. Inform. \nAssoc. 25, 3 (March 2018), 230‚Äì238. https://doi.org/10.1093/jamia/ocx079 \n[58] Ruiyi Wang, Stephanie Milani, Jamie C. Chiu, Jiayin Zhi, Shaun M. Eack, Travis Labrum, Samuel M Murphy, Nev \nJones, Kate V Hardy, Hong Shen, Fei Fang, and Zhiyu Chen. 2024. PATIENT-œà: Using Large Language Models to \nSimulate Patients for Training Mental Health Professionals. In Proceedings of the 2024 Conference on Empirical \n"}, {"page": 30, "text": " \n \n \nMethods in Natural Language Processing, November 2024. Association for Computational Linguistics, Miami, \nFlorida, USA, 12772‚Äì12797. https://doi.org/10.18653/v1/2024.emnlp-main.711 \n[59] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and \nDenny Zhou. 2022. Chain-of-thought prompting elicits reasoning in large language models. In Proceedings of the \n36th International Conference on Neural Information Processing Systems (NIPS ‚Äô22), November 28, 2022. Curran \nAssociates Inc., Red Hook, NY, USA, 24824‚Äì24837. \n[60] Janusz Wojtusiak. TOWARDS INTELLIGENT PATIENT DATA GENERATOR.  \n[61] Michael S. Wolf and Stacy Cooper Bailey. 2009. The Role of Health Literacy in Patient Safety. Role Health Lit. \nPatient Saf. (March 2009). Retrieved February 11, 2026 from https://psnet.ahrq.gov/perspective/role-health-literacy-\npatient-safety \n[62] Chao Yan, Ziqi Zhang, Steve Nyemba, and Zhuohang Li. 2024. Generating Synthetic Electronic Health Record Data \nUsing Generative Adversarial Networks: Tutorial. JMIR AI 3, (April 2024), e52615. https://doi.org/10.2196/52615 \n[63] Sirui Yao, Yoni Halpern, Nithum Thain, Xuezhi Wang, Kang Lee, Flavien Prost, Ed H. Chi, Jilin Chen, and Alex \nBeutel. \n2021. \nMeasuring \nRecommender \nSystem \nEffects \nwith \nSimulated \nUsers. \nhttps://doi.org/10.48550/arXiv.2101.04526 \n[64] Jinsung Yoon, Michel Mizrahi, Nahid Farhady Ghalaty, Thomas Jarvinen, Ashwin S. Ravi, Peter Brune, Fanyu Kong, \nDave Anderson, George Lee, Arie Meir, Farhana Bandukwala, Elli Kanal, Sercan √ñ Arƒ±k, and Tomas Pfister. 2023. \nEHR-Safe: generating high-fidelity and privacy-preserving synthetic electronic health records. Npj Digit. Med. 6, 1 \n(August 2023), 141. https://doi.org/10.1038/s41746-023-00888-7 \n[65] Huizi Yu, Jiayan Zhou, Lingyao Li, Shan Chen, Jack Gallifant, Anye Shi, Xiang Li, Jingxian He, Wenyue Hua, \nMingyu Jin, Guang Chen, Yang Zhou, Zhao Li, Trisha Gupte, Ming-Li Chen, Zahra Azizi, Yongfeng Zhang, Yanqiu \nXing, Themistocles L. Danielle S. Bitterman, Themistocles L. Assimes, Xin Ma, Lin Lu, and Lizhou Fan. 2025. \nSimulated patient systems are intelligent when powered by large language model-based AI agents. \nhttps://doi.org/10.48550/arXiv.2409.18924 \n[66] Taedong Yun, Eric Yang, Mustafa Safdari, Jong Ha Lee, Vaishnavi Vinod Kumar, S. Sara Mahdavi, Jonathan Amar, \nDerek Peyton, Reut Aharony, Andreas Michaelides PhD, Logan Douglas Schneider, Isaac Galatzer-Levy, Yugang \nJia, John Canny, Arthur Gretton, and Maja Mataric. 2025. Sleepless Nights, Sugary Days: Creating Synthetic Users \nwith Health Conditions for Realistic Coaching Agent Interactions. In Findings of the Association for Computational \nLinguistics: ACL 2025, July 2025. Association for Computational Linguistics, Vienna, Austria, 14159‚Äì14181. \nhttps://doi.org/10.18653/v1/2025.findings-acl.729 \n[67] Ruoyu Zhang, Yanzeng Li, Yongliang Ma, Ming Zhou, and Lei Zou. 2023. LLMaAA: Making Large Language \nModels as Active Annotators. https://doi.org/10.48550/arXiv.2310.19596 \n[68] Yinan Zhang, Xueqing Liu, and ChengXiang Zhai. 2017. Information Retrieval Evaluation as Search Simulation: A \nGeneral Formal Framework for IR Evaluation. In Proceedings of the ACM SIGIR International Conference on Theory \nof Information Retrieval (ICTIR ‚Äô17), October 01, 2017. Association for Computing Machinery, New York, NY, \nUSA, 193‚Äì200. https://doi.org/10.1145/3121050.3121070 \n[69] Xuhui Zhou, Hyunwoo Kim, Faeze Brahman, Liwei Jiang, Hao Zhu, Ximing Lu, Frank Xu, Bill Yuchen Lin, Yejin \nChoi, Niloofar Mireshghallah, Ronan Le Bras, and Maarten Sap. 2025. HAICOSYSTEM: An Ecosystem for \nSandboxing Safety Risks in Human-AI Interactions. https://doi.org/10.48550/arXiv.2409.16427 \n[70] 2004. EVALUATION OF RECOMMENDER SYSTEMS THROUGH SIMULATED USERS: In Proceedings of the \n4th International Workshop on Pattern Recognition in Information Systems, 2004. SciTePress - Science and and \nTechnology Publications, Porto, Portugal, 303‚Äì308. https://doi.org/10.5220/0002622703030308 \n[71] 2023. malexandersalazar/xlm-roberta-base-cls-depression ¬∑ Hugging Face. Retrieved February 11, 2026 from \nhttps://huggingface.co/malexandersalazar/xlm-roberta-base-cls-depression \n[72] Language use of depressed and depression-vulnerable college students: Cognition and Emotion: Vol 18 , No 8 - Get \nAccess. \nCogn. \nEmot. \nRetrieved \nFebruary \n8, \n2026 \nfrom \nhttps://www.tandfonline.com/doi/abs/10.1080/02699930441000030 \n[73] The Psychological Meaning of Words: LIWC and Computerized Text Analysis Methods - Yla R. Tausczik, James \nW. \nPennebaker, \n2010. \nRetrieved \nAugust \n12, \n2025 \nfrom \nhttps://journals.sagepub.com/doi/abs/10.1177/0261927x09351676?casa_token=wzGmLA6oIH8AAAAA:0nd4mwP\nrFbV2NNJZzAyEo_oKUoWknPfRTg791lRQuxoXwWfOkF_DKTh56XX-l_Qw-umu5PxSRbyAAw \n[74] Overview of the Multilingual Text Detoxification Task at PAN 2024.  \n[75] Top 10 Most Common Antidepressants Dispensed in the U.S. Retrieved November 11, 2025 from \nhttps://www.definitivehc.com/resources/healthcare-insights/top-antidepressants-by-prescription-volume \n"}, {"page": 31, "text": " \n \n \n[76] Speech and Language Processing. Retrieved February 11, 2026 from https://web.stanford.edu/~jurafsky/slp3/ \n \n10  APPENDICES \n10.1 Patient Simulator  \nWe present the detailed system architecture and the core system prompt, which follows a Chain-of-thought driven \nreasoning mechanism to integrate three distinct profiles and enable structured interaction with the AI decision aid. \n10.1.1 Architecture and System Prompt \nThe Patient Simulator architecture operationalizes the generation of psychologically realistic patient responses through \nthe coordinated integration of medical, linguistic, and behavioral profiles. This modular design ensures that each simulated \ninteraction remains clinically grounded, linguistically differentiated, and behaviorally consistent. Figure 9 shows the \nstructure of the system prompt used to enforce this alignment, with a brief description of its components provided below. \nConcretely, the system prompt is organized around three profile components that constrain content, expression, and \ninteraction behavior: \n1. Medical Profile: The simulator uses a structured medical history represented by hierarchical indices (e.g., [2.3], \n[3.1]), where each code corresponds to a specific clinical fact or condition. These indices are crucial for traceability and \nannotation, allowing evaluators or downstream models to link simulated responses back to precise clinical data points. \n2. Linguistic Profile: The linguistic profile defines how medical facts are style-transferred to reflect the patient‚Äôs \nexpressive characteristics such as tone, vocabulary, and sentence complexity. This ensures that the same underlying \nmedical information can appear differently across patients (e.g., formal vs. colloquial language) while maintaining factual \nalignment. \n3. Behavioral Profile: The behavioral layer determines how the simulated patient engages with the conversation, \ncontrolling elements such as adherence, emotional engagement, topical focus, and adversarial tendencies. By enforcing \nbehavioral constraints, the simulator produces psychologically credible dialogue patterns ranging from cooperative to \navoidant or argumentative behaviors. \nQuestion-Response Logic: \nFor each intake question, the simulator follows a structured reasoning pipeline: \n1. \nIdentify Relevant Medical Facts: Locate facts from the medical profile that relate to the current query, referencing \nthem by their index (e.g., [3.2] Depression diagnosis). \n2. \nApply Style Transfer: For each fact, rephrase the medical term or phrase according to the linguistic profile while \npreserving its factual meaning. \n3. \nConstruct a Natural Response: Integrate the style-transferred facts into a contextually appropriate, natural-\nlanguage answer that aligns with both linguistic and behavioral traits. Each style-transferred phrase is wrapped \nin <\\s>...</\\s> for traceability and followed by its [X.Y] reference tag. \nResponse Format: \nAll outputs adhere to a strict JSON schema to ensure transparency, reproducibility, and structured analysis. This output \nformat is essential for the annotation process, as it allows annotators to review each conversational turn, examine the \ncorresponding medical history, and verify the accuracy and consistency of the patient simulator‚Äôs responses. The output \nJSON contains: \n"}, {"page": 32, "text": " \n \n \n‚Ä¢ \n\"relevant_medical_history\" ‚Äì the original indexed facts used in the response. \n‚Ä¢ \n\"style_transferred_medical_history\" ‚Äì the linguistically modified versions of those facts. \n‚Ä¢ \n\"response\" ‚Äì the final natural-language utterance embedding both versions for clarity and interpretability. \n \n \nFigure 9 Prompt Structure of Patient Simulator \n10.1.2 Medical Profiles \nThis section presents the medical profile generation procedure used by the analytical advice system in detail. The \nmethod follows a staged selection strategy that balances outcome relevance, statistical coherence, and controlled diversity \nto produce clinically plausible and informative profiles. \nOutcome Relevance (Top-K Filter): The algorithm first restricts the candidate space to the Top‚ÄëK predictors of the \nantidepressant response outcome e‚ÇÄ (here, K = 500). This filter improves sample efficiency and signal‚Äëto‚Äënoise by focusing \nYou are simulating a psychologically realistic patient based on three profiles: Medical, Behavioral, \nand Linguistic. \n \n1. Medical Profile: \nDemographics: \n     \n \n1.1: Age: 34 \n     \n \n1.2: Gender: Male \n      \n  \n ... ... ... \nDiagnosis History: \n \n \n2.1: Generalized Anxiety Disorder \n \n \n2.2: Hyperlipidemia variants \n \n \n... ... ... \nProcedures: \n \n \n3.1: Psychiatric Diagnostic Interview Examination \n \n \n3.2: Individual Psychotherapy \n \n \n \n... ... ... \n2. Linguistic Profile: \nStyle: Concrete, informal, sometimes vague.  \nTone: Hesitant, uncertain, conversational.  \nVocab: Everyday terms, slang, vague quantities.  \nStructure: Short, fragmented sentences; frequent fillers.  \nPatterns: Minimal elaboration unless prompted. \n3. Behavioral Profile: \n     \nConversational Adherence: Follows prompts; stays structured. \n \nEngagement: Highly engaged; adds helpful details. \n \nTopical Focus: Stays on topic; avoids tangents. \n \nAdversarial/Toxic Behavior: None; consistently polite. \n \nFor each of the questions: \n   ‚ûî Step 1: Identify relevant medical facts using their assigned index (e.g., [3.2] Individual \nPsychotherapy). \n   ‚ûî Step 2: For each identified fact, apply style transfer according to the linguistic profile. \n   ‚ûî Step 3: Construct a natural language response that embeds the style-transferred facts embedding \nthe linguistic and behavioral profile. Each style-transferred phrase must be **wrapped in `<\\s>` \n... `<\\s>`** and must also include the **[X.Y]** reference right after it. \n \nResponse format: \n\"relevant_medical_history\": [ \n \n \n\"[1.2] Gender: Male\", \n         \"[3.2] Individual Psychotherapy\"] \n\"style_transferred_medical_history\": [ \n\"[1.2] male\", \n\"[3.2] talked to someone\"], \n\"response\": \"Final response using the above style-transferred facts with inline references \nand <\\s> tags, \n \n"}, {"page": 33, "text": " \n \n \nsubsequent selection on variables with demonstrated individual association to e‚ÇÄ. As in classical filter style feature \nselection, an initial relevance screen improves downstream generalization and reduces variance in later steps [1]. In spirit, \nthis aligns with the ‚Äúmax‚Äërelevance‚Äù component of minimum‚Äëredundancy‚Äëmaximum‚Äërelevance (mRMR), which explicitly \nprioritizes features that are informative about the target before addressing redundancy [20] \nCoherence and Approximate Independence via a Symmetric Risk‚ÄëRatio Gate: New candidates are screened using a \nsymmetric acceptance band around unity based on aggregated pairwise risk ratios with respect to the already‚Äëselected set \nS. Let ùëÖùëÖ(ùë†, ùë£) denote the risk ratio between an existing event ùë† ‚àà ùëÜ and a candidate event ùë£, and let ùëéùëîùëîùëüùëíùëîùëéùë°ùëíùë†‚ààùëÜ be \na conservative aggregator (e.g., MAX) over these pairwise values. Acceptance condition: \n1\n1.5 < ùëéùëîùëîùëüùëíùëîùëéùë°ùëís‚ààS ùëÖùëÖ(ùë†, ùë£) ‚â§‚Ñéùëñùëî‚Ñé \nThis symmetric band (ùëôùëúùë§ =  1/1.5) respects the multiplicative interpretation of ùëÖùëÖ treating protective associations (<\n 1) and harmful associations (>  1) in a balanced manner while capping near deterministic couplings (>  ‚Ñéùëñùëî‚Ñé) that would \nintroduce redundancy or multicollinearity. Excluding values ‚â™ 1 also avoids strongly anticorrelated additions that can \ncreate unstable compensations in downstream predictions [20]. Using MAX as the aggregator is conservative (rejects ùë£ if \nit couples too strongly with any ùë† ‚àà ùëÜ);Controlled Diversity from the Residual Event Pool:After establishing the coherent \ncore of relevant events (Top-K features), the algorithm introduces controlled diversity by exploring the residual event pool. \nThose features not included among the top-ranked relevant set. In this phase, a residual candidate ùë¢ ‚àà ùëÖ is admitted only \nif it exhibits a meaningful positive association with at least one of the already selected relevant features ùë† ‚àà ùëÜ. This step \naims to capture latent or contextually related variables that were not strongly ranked individually but still contribute to \nplausible patient variability when correlated with the existing core. \nTo ensure statistical coherence, independence is defined as the range 1/1.5 ‚â§ ùëÖùëÖ(ùë†, ùë£) ‚â§ 1.5; any relationship \nwithin this interval is treated as neutral and thus ignored. Accordingly, only candidates showing stronger associations i.e., \nùëÖùëÖ(ùë†, ùë£) >  1.5 or ùëÖùëÖ(ùë†, ùë£) <  1/1.5 are eligible for inclusion, provided they were not part of the original relevant set. \nDiversity condition: \n‚àÉùë† ‚àà ùëÜ‚à∂ ùëÖùëÖ(ùë†, ùë£) >  1.5 \nwhere R denotes the residual pool (features outside the Top-500), and S represents the previously selected relevant \nfeatures. This mechanism ensures that the resulting simulated patient profiles include a bounded degree of heterogeneity \ndriven by correlated but previously under-ranked features, enriching diversity without compromising coherence [19, 20].  \n \nThe Risk Ratio categories and the corresponding feature inclusion logic are illustrated in Error! Reference source not \nfound.Error! Reference source not found., which depicts the transition from negatively associated to positively \nassociated features and their mapping across Step 3 (relevant) and Step 4 (coherent but irrelevant) feature sets. \n \n \n"}, {"page": 34, "text": " \n \n \n \nFigure 10: Graphical representation of Risk Ratio thresholds and feature selection workflow \nThe medical profile generation algorithm constructs a simulated clinical history by selecting events that are both \nclinically meaningful and statistically consistent with real world response patterns. The process begins with a set of \nvariables that strongly predict response to the target antidepressant, then filters these candidates through risk based \nconstraints to ensure independence and realistic variability. A second expansion stage introduces additional events that \nprovide controlled diversity without creating improbable clinical combinations. The final set of events forms a structured \nmedical profile that reflects both individual level variability and population level statistical associations. \nThe inputs listed below define the core elements required for the generation of each simulated medical profile. They \nspecify the clinical target, the size of the simulated population, the available concept codes, and the demographic \ndistributions from which each patient begins, along with the parameters that control risk ratio constraints and diversity \nexpansion. \nInputs: \n‚Ä¢ \ne0 ‚Äì Concept code of response of target antidepressant  \n‚Ä¢ \nN‚Äì Number of patients to simulate \n‚Ä¢ \nAll_Concept_Code ‚Äì List of all the concept code \n‚Ä¢ \nG ‚Äì Categorical distribution over gender (At Birth) codes \n‚Ä¢ \nA ‚Äì Categorical distribution over age-bin codes \n‚Ä¢ \nhigh ‚Äì Maximum allowed Risk Ratio for selecting a variable \n‚Ä¢ \nmax_residual_additions ‚Äì Limit on how many residual-pool events may be \nappended \n     The helper routines provide the key decision checks used throughout the selection process. They evaluate the \ncompatibility of candidate events with the partially constructed profile and ensure that all additions remain within the \nrequired risk ratio bounds. These routines allow the algorithm to enforce statistical constraints without interrupting the \nmain flow of the pseudocode. \n \nHelper Routines: \n‚Ä¢ \nùëÉùëéùë†ùë†ùëíùë†ùëÖùëÖùê∫ùëéùë°ùëí(ùë†ùëíùëôùëíùëêùë°ùëíùëë, ùëêùëéùëõùëëùëñùëëùëéùë°ùëí_ùëíùë£ùëíùëõùë°, ùëôùëúùë§, ‚Ñéùëñùëî‚Ñé) - Returns ùëáùëÖùëàùê∏ if the aggregated \npairwise risk ratio ùëÖùëÖ(ùë†, ùëêùëéùëõùëëùëñùëëùëéùë°ùëí_ùëíùë£ùëíùëõùë°) across all s in selected satisfies \n1/1.5 <  ùëéùëîùëîùëüùëíùëîùëéùë°ùëí ‚â§ ‚Ñéùëñùëî‚Ñé. Otherwise returns ùêπùê¥ùêøùëÜùê∏. \n‚Ä¢ \nùê¥ùëõùë¶ùëÖùëÖùê∏ùë•ùëêùëíùëíùëëùë†(ùë†ùëíùëôùëíùëêùë°ùëíùëë, ùëêùëéùëõùëëùëñùëëùëéùë°ùëí_ùëíùë£ùëíùëõùë°, ùë°‚Ñéùëüùëíùë†‚Ñéùëúùëôùëë) - Returns ùëáùëÖùëàùê∏ if there exists \nat least one event s in selected such that ùëÖùëÖ(ùë†, ùëêùëéùëõùëëùëñùëëùëéùë°ùëí_ùëíùë£ùëíùëõùë°) exceeds the \ngiven threshold. Otherwise returns ùêπùê¥ùêøùëÜùê∏. \n"}, {"page": 35, "text": " \n \n \n‚Ä¢ \nùëÉùëüùëíùëëùëñùëêùë°ùëÖùëíùë†ùëù(ùëÜ, ùëí‚ÇÄ): Returns the probability of response to the antidepressant \nassociated with concept ùëí‚ÇÄ, given the selected event set ùëÜ, computed using \nthe MAGI algorithm. \nFigure 11 combines the inputs and helper routines into a four-stage algorithm that builds each medical profile step by \nstep. It begins with a Top K predictor filter, initializes demographic seeds, applies an independence screen to ensure \nstatistical coherence, and finally introduces controlled diversity through residual events. Together, these stages create a \nclinically plausible and statistically grounded event set for each simulated patient. \n \nProcedure: \n \nFigure 11. Medical profile generation algorithm \nPhase ‚Äì 2: Probabilistic Patient Selection Using Binomial Distribution \nThe second phase of the medical profile generation process selects a subset of simulated patients whose response \nprobabilities collectively reproduce the population-level response distribution observed in the reference dataset. Each \nsimulated patient from Phase 1 is associated with a predicted probability of antidepressant response between 0 and 1. The \nselection aims to retain a cohort whose aggregate distribution mirrors the expected binomial pattern defined by the \npopulation mean response rate (ùëù) and total number of patients (ùëõ). \nTo operationalize this, the probability range [0, 1] is divided into seven probability bands corresponding to \napproximate œÉ-intervals of a binomial distribution ùêµ(ùëõ, ùëù). Each simulated patient is assigned to a band according to their \npredicted probability of response. The population mean (ùúá =  ùëõùëù) and standard deviation (ùúé = ‚àö(ùëõùëù(1 ‚àí ùëù)) ) define \nthe expected frequency of patients in each band, which acts as a target allocation weight. For example, for ùëõ =  100 and \n# Step‚Äë1: Selection of Top-K and Initialization \n1. V ‚Üê Top500_Predictor_of_e‚ÇÄ(e‚ÇÄ). \n \n\\\\ Top_500 predictors \n2. R ‚Üê {All_Concept_Code} \\ {V ‚à™ G ‚à™ A} \n\\\\ Residual Event \n3. Initialize output container T ‚Üê ‚àÖ. \n4. For each patient j = 1..N: \n5. \nS ‚Üê ‚àÖ   // selected set. \n6. \nA·µ• ‚Üê V;  A·µ£ ‚Üê R   // fresh available pools. \n# Step‚Äë2: Demographics Seed \n7. \nS ‚Üê S ‚à™ {weighted_random_choice(G)}   \\\\ gender \n8.  \nS ‚Üê S ‚à™ {weighted_random_choice(A)}   \\\\ age-bin \n# Step‚Äë3: Independence-Screened Selection \n9. \nWhile A·µ• ‚â† ‚àÖ: \n10. \n \nv ‚Üê random_choice(A·µ•). \n11. \n \nIf PassesRRGate(S, v, high=high, low=1/1.5): \n12. \n \n \nSet S ‚Üê S ‚à™ {v}. \n13. \n \nRemove v from A·µ•. \n14. \nDefine S_intermediate ‚Üê S.   \n# Step‚Äë4: Controlled Diversity Expansion \n15. \ni ‚Üê 1. \n16. \nWhile A·µ£ ‚â† ‚àÖ and i ‚â§ max_residual_additions: \n17, \n \n u ‚Üê random_choice(A·µ£). \n18. \n \nIf AnyRRExceeds(S_intermediate, u, threshold = 1.5): \n19. \n \n \nSet S ‚Üê S ‚à™ {u};  i ‚Üê i + 1. \n20. \n \nRemove u from A·µ£. \n21. \nCompute final pÃÇ ‚Üê PredictResp(S, e‚ÇÄ). \n22. \nAppend (j, e‚ÇÄ, |S|, S, pÃÇ) to T. \n"}, {"page": 36, "text": " \n \n \nùëù =  0.4, the binomial distribution has ùúá =  40 and ùúé ‚âà 4.9; approximately 64 % of the population lies within (ùúá ‚àí\n ùúé, ùúá +  ùúé], 15 % on each side within (ùúá ¬±  1ùúé ùë°ùëú ùúá ¬±  2ùúé], and only a few percent beyond ùúá ¬±  2ùúé. Table 13 shows the \nranges with their interpretation. \nTable 13: Generalized Sigma-Band Allocation for Binomial Distribution B(n, p) \nSigma Band Interval Range of Success Counts (k) Approximate Probability Mass (%) Interpretation \nk ‚â§ Œº ‚àí 3œÉ \n0 ‚â§ k ‚â§ ‚åäŒº ‚àí 3œÉ‚åã \n‚âà 0.1‚Äì0.3 % \nExtremely low outcome region \n(Œº ‚àí 3œÉ, Œº ‚àí 2œÉ] \n‚åäŒº ‚àí 3œÉ‚åã + 1 ‚â§ k ‚â§ ‚åäŒº ‚àí 2œÉ‚åã \n‚âà 2‚Äì3 % \nModerately below average region \n(Œº ‚àí 2œÉ, Œº ‚àí 1œÉ] \n‚åäŒº ‚àí 2œÉ‚åã + 1 ‚â§ k ‚â§ ‚åäŒº ‚àí 1œÉ‚åã \n‚âà 14‚Äì16 % \nSlightly below average region \n(Œº ‚àí 1œÉ, Œº + 1œÉ] \n‚åäŒº ‚àí 1œÉ‚åã + 1 ‚â§ k ‚â§ ‚åäŒº + 1œÉ‚åã \n‚âà 63‚Äì65 % \nCentral or typical outcome region \n(Œº + 1œÉ, Œº + 2œÉ] \n‚åäŒº + 1œÉ‚åã + 1 ‚â§ k ‚â§ ‚åäŒº + 2œÉ‚åã \n‚âà 14‚Äì16 % \nSlightly above average region \n(Œº + 2œÉ, Œº + 3œÉ] \n‚åäŒº + 2œÉ‚åã + 1 ‚â§ k ‚â§ ‚åäŒº + 3œÉ‚åã \n‚âà 2‚Äì3 % \nModerately high outcome region \nk > Œº + 3œÉ \n‚åäŒº + 3œÉ‚åã + 1 ‚â§ k ‚â§ n \n‚âà 0.1‚Äì0.3 % \nExtremely high outcome region \n \nPatients are then sampled proportionally to these weights so that the empirical distribution of predicted response \nprobabilities in the final cohort approximates the theoretical binomial distribution. This approach ensures that the selected \nsubset preserves both the central tendency and natural variability of the population while avoiding over- or under-\nrepresentation of extreme responders. The outcome is a statistically balanced and demographically diverse cohort suitable \nfor downstream simulation and evaluation.  \n10.1.3 Behavioral Profiles \nWe present the mapping of 13 commonly observed patient behaviors documented by Simpson et al. [50] into five \nhigher-level behavioral categories in Table 14. \nTable 14: Mapping of behavioral profiles to their associated patient behaviors. \nBehavioral Profile \nAssociated Patient Situation \nInquisitive & Open-Ended \nIs uncertain what they want \nReserved & Minimalist \nIs reluctant to work together \nIs anxious, worried, or upset \nWorries they will never get better \nAdversarial & Combative \nIs angry \nIs demanding \nBrings up negative feelings in the clinician \nDistracted & Unfocused \nIs difficult to direct or disorganized \nHas an unclear diagnosis \nIs an unreliable historian \nHas a difficult time changing their behavior \nDoes not take medications regularly \nHas difficulty planning ahead \n \n"}]}