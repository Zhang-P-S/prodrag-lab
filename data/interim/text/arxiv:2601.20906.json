{"doc_id": "arxiv:2601.20906", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2601.20906.pdf", "meta": {"doc_id": "arxiv:2601.20906", "source": "arxiv", "arxiv_id": "2601.20906", "title": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins", "authors": ["Nikita Makarov", "Maria Bordukova", "Lena Voith von Voithenberg", "Estrella Pivel-Villanueva", "Sabrina Mielke", "Jonathan Wickes", "Hanchen Wang", "Mingyu Derek Ma", "Keunwoo Choi", "Kyunghyun Cho", "Stephen Ra", "Raul Rodriguez-Esteban", "Fabian Schmich", "Michael Menden"], "published": "2026-01-28T15:40:54Z", "updated": "2026-02-09T22:27:07Z", "summary": "Precision oncology requires forecasting clinical events and trajectories, yet modeling sparse, multi-modal clinical time series remains a critical challenge. We introduce TwinWeaver, an open-source framework that serializes longitudinal patient histories into text, enabling unified event prediction as well as forecasting with large language models, and use it to build Genie Digital Twin (GDT) on 93,054 patients across 20 cancer types. In benchmarks, GDT significantly reduces forecasting error, achieving a median Mean Absolute Scaled Error (MASE) of 0.87 compared to 0.97 for the strongest time-series baseline (p<0.001). Furthermore, GDT improves risk stratification, achieving an average concordance index (C-index) of 0.703 across survival, progression, and therapy switching tasks, surpassing the best baseline of 0.662. GDT also generalizes to out-of-distribution clinical trials, matching trained baselines at zero-shot and surpassing them with fine-tuning, achieving a median MASE of 0.75-0.88 and outperforming the strongest baseline in event prediction with an average C-index of 0.672 versus 0.648. Finally, TwinWeaver enables an interpretable clinical reasoning extension, providing a scalable and transparent foundation for longitudinal clinical modeling.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2601.20906v2", "url_pdf": "https://arxiv.org/pdf/2601.20906.pdf", "meta_path": "data/raw/arxiv/meta/2601.20906.json", "sha256": "813f60e23863ac52bbb53b33ffe60fe3d102936ca0b7804466e26728e3e4871f", "status": "ok", "fetched_at": "2026-02-18T02:20:11.455725+00:00"}, "pages": [{"page": 1, "text": "TwinWeaver: An LLM-Based Foundation Model Framework\nfor Pan-Cancer Digital Twins\nNikita Makarov 1 2 3 Maria Bordukova 1 2 3 Lena Voith von Voithenberg 4 Estrella Pivel-Villanueva 1\nSabrina Mielke 5 Jonathan Wickes 6 Hanchen Wang 6 7 Mingyu Derek Ma 5 Keunwoo Choi 5\nKyunghyun Cho 5 8 Stephen Ra 5 Raul Rodriguez-Esteban 9 + Fabian Schmich 1 + Michael Menden 2 10 +\nAbstract\nPrecision oncology requires forecasting clinical events and trajectories, yet modeling sparse, multi-\nmodal clinical time series remains a critical challenge. We introduce TwinWeaver, an open-source\nframework that serializes longitudinal patient histories into text, enabling unified event prediction\nas well as forecasting with large language models, and use it to build Genie Digital Twin (GDT)\non 93,054 patients across 20 cancer types. In benchmarks, GDT significantly reduces forecasting\nerror, achieving a median Mean Absolute Scaled Error (MASE) of 0.87 compared to 0.97 for the\nstrongest time-series baseline (p < 0.001). Furthermore, GDT improves risk stratification, achieving\nan average concordance index (C-index) of 0.703 across survival, progression, and therapy switching\ntasks, surpassing the best baseline of 0.662. GDT also generalizes to out-of-distribution clinical trials,\nmatching trained baselines at zero-shot and surpassing them with fine-tuning, achieving a median\nMASE of 0.75–0.88 and outperforming the strongest baseline in event prediction with an average\nC-index of 0.672 versus 0.648. Finally, TwinWeaver enables an interpretable clinical reasoning\nextension, providing a scalable and transparent foundation for longitudinal clinical modeling.\n1. Introduction\nPrecision oncology aims to personalize cancer care through\ncomputational modeling of patient trajectories (Zhuang\net al., 2025). Patient Digital Twins (PDTs) serve as dig-\nital replicas of patients with a bidirectional information flow,\nlearning patient-specific representations from longitudinal,\nmulti-modal molecular and clinical data to support forecast-\ning and simulation. This necessitates scalable methods that\n+Equal supervision 1Computational Sciences Center of Excel-\nlence, Roche, Penzberg, Germany 2Computational Health Center,\nHelmholtz Munich, Munich, Germany 3Department of Biology,\nLudwig Maximilian University of Munich, Munich, Germany\n4Early Development Oncology, Roche Innovation Center Zurich,\nRoche, Schlieren, Switzerland 5Computational Sciences Center\nof Excellence, Genentech, New York City, USA 6Computational\nSciences Center of Excellence, Genentech, South San Francisco,\nUSA 7Department of Computer Science, Stanford University, Stan-\nford, CA, USA 8Center for Data Science, New York University,\nNew York City, USA 9Computational Sciences Center of Excel-\nlence, Roche, Basel, Switzerland 10Department of Biochemistry\nand Pharmacology, Bio21 Molecular Science and Biotechnology\nInstitute, The University of Melbourne, Melbourne, Australia. Cor-\nrespondence to: Fabian Schmich <fabian.schmich@roche.com>,\nMichael Menden <michael.menden@unimelb.edu.au>.\nPreprint. February 11, 2026.\ncan handle heterogeneous and sparse real-world time series\n(Kamel Boulos & Zhang, 2021; Bordukova et al., 2024). Re-\ncent advances in foundation models have further increased\nthe feasibility of large-scale clinical trajectory modeling\n(Makarov et al., 2025; Wornow et al., 2023b).\nHere, we introduce TwinWeaver, a longitudinal framework\nfor LLM-generated PDTs, and Genie Digital Twin (GDT),\na pan-cancer model instantiated using TwinWeaver to simu-\nlate patient trajectories (Figure 1). TwinWeaver serializes\npatient journeys into text, which GDT uses to forecast clini-\ncal events and trajectories across 20 cancer indications.\nLeveraging a large-scale dataset of 93,054 real-world oncol-\nogy patients from the Flatiron Health-Foundation Medicine\nClinico-Genomic Database (FH-FMI CGDB; Appendix A),\nwe present four key contributions: 1) the open-source Twin-\nWeaver framework1 for serializing clinical histories; 2) the\nGDT model, built using TwinWeaver, which demonstrates\ncompetitive performance relative to advanced time-series\nand electronic health record models; 3) demonstration of\nzero-shot generalization to clinical trials; and 4) highlight-\ning a reinforcement learning-based interpretable clinical\nreasoning extension to the base model.\n1http://github.com/MendenLab/TwinWeaver\n1\narXiv:2601.20906v2  [cs.LG]  9 Feb 2026\n"}, {"page": 2, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\n●Neutrophils: \n17 109/L\n●Hemoglobin: \n10.2 g/dL\n●Diabetes\nDiagnosis\n●Therapy: \nAtezolizumab,\nBevacizumab,\nCarboplatin,\nPaclitaxel\n●NSCLC\nDiagnosis\n●Height: \n178cm\n0 days\n12 weeks\n73 weeks\n...\nGenie Digital Twin (GDT)\nb)\nc)\nd)\ne)\nTime Series Forecast & \nEvent Prediction\nReasoning\nPatient History & Genetic Data\nWeek\n●EGFR\n14 weeks\n●ALK\n...\nGenetic mutations:\n0\n3\n6\n9\n12\nThe following is a patient \n... your task is to ...\nTask 1 is forecasting:\n2 weeks later, the ...\n<thinking>\n...\n</thinking>\n<prognosis_summary> \n...\n</prognosis_summary>\nf)\nData Conversion & LLM Prediction\nGI (20k)\nLung (19k) \nOther tumors (17k)\nGU & gynecological (16k) \nBlood (2k)\nUndetermined (19k)\nWeek \nBlood Biomarker\n20 Cancer Indications (93k total):\n8\n26\n52\n104\nDeath\nNew \nTreatment\nTwinWeaver Framework\nA general framework for constructing LLM-based patient digital twins from longitudinal, multi-modal data\na)\nFigure 1. The TwinWeaver framework serializes longitudinal patient histories into text to train the Genie Digital Twin (GDT)\npan-cancer foundation model. a) The TwinWeaver framework b) serializes multi-modal EHR data (history, genetics) into text. c) We use\nthis to develop GDT on 93,054 real-world patients across 20 cancer indications (counts shown in parentheses). GDT jointly d) forecasts\ncontinuous biomarkers and e) predicts landmark clinical events. f) The model can be further trained for interpretable predictions using\nreasoning-based outputs.\n2. Related Work\nClinical Event Prediction\nClinical event prediction esti-\nmates time-to-event outcomes from longitudinal data using\nclassical methods such as Cox Proportional Hazards mod-\nels (Cox, 1972), Random Survival Forests (Ishwaran et al.,\n2008), and deep survival models (Katzman et al., 2018).\nThese approaches often require manual data preprocessing\nto handle real-world data (RWD) and typically decouple\nevent prediction from trajectory forecasting, limiting infor-\nmation gain. These limitations call for flexible, unified mod-\nels that jointly capture longitudinal dynamics and censored\nclinical events.\nClinical & EHR Foundation Models\nRecent foundation\nmodels have shifted clinical modeling from static risk pre-\ndiction toward dynamic trajectory forecasting (Guo et al.,\n2023). LLM-based approaches such as DT-GPT (Makarov\net al., 2025) and EHR2Path (Pellegrini et al., 2025) ex-\nemplify this progress, yet they remain constrained by the\nnumber of forecastable variables or their temporal scope.\nEHR foundation models such as CLMBR-T (Wornow et al.,\n2023a) and MOTOR (Steinberg et al., 2024a) improve event\nprediction, while SCOPE (Hussain et al., 2024) further en-\nables joint longitudinal and event tasks. However, these\nmodels rely on fixed, code-based vocabularies that hinder\nadaptability (Bedi et al., 2026). These constraints under-\nscore the need for more flexible and scalable models for\nheterogeneous, long-horizon clinical trajectories.\nTime-Series Forecasting Foundation Models\nDeep\nlearning architectures such as TiDE (Das et al., 2023) and\nfoundation models such as Chronos (Ansari et al., 2024;\nHoo et al., 2024) have advanced time-series forecasting.\nWhereas LLMs can be used for forecasting by treating nu-\nmerical sequences as text (Gruver et al., 2023), their EHR\napplications remain limited to small variable sets. Moreover,\ngeneral models such as Chronos capture temporal dependen-\ncies but lack medical context and struggle with integrating\nsparse genetic data. The limitations highlight the need for\nricher multi-modal temporal representations.\nReasoning in Clinical AI\nRecent work, such as OncoRe-\nason (Hemadri et al., 2025), demonstrates the utility of\nLLMs for complex clinical reasoning and outcome predic-\ntion. These advances highlight the opportunity for models\nthat couple numerical forecasting with interpretable tex-\ntual rationales to improve transparency, trust, and clinical\nusability.\n3. TwinWeaver Framework\nWe introduce TwinWeaver, a framework that enables large\nlanguage models (LLMs) to perform clinical prediction by\njointly forecasting numeric time-series and censored clinical\nevents. TwinWeaver fine-tunes LLMs on procedurally gen-\nerated text representations of longitudinal patient journeys,\nproviding a flexible representation for multi-modal clini-\ncal data. This serialization leverages the tokenization and\ngenerative capabilities of LLMs to model irregular clinical\n2\n"}, {"page": 3, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\ntimelines and learn shared latent patient states that support\nboth continuous biomarker forecasting and discrete clinical\nevent prediction.\nWe define our core notation for the model. Let P be the\nset of patients, where each p = (sp, Hp) ∈P has static\nattributes sp and an observed history Hp = [hp1, ..., hpn]\nwhere hpi = (timestamp, event, value), for a total of n ob-\nservations. The next-token probability of the LLM is de-\nfined as qθ(xi | x1:i−1) for a given token sequence x, with\nxi being the i-th token, and parameterized by θ.\n3.1. Training\nThe training pipeline preprocesses longitudinal data, gen-\nerates input-target pairs by splitting patient trajectories at\ncritical time points, such as therapy start dates, converts the\npairs into text prompts, and fine-tunes a pretrained LLM\nwith them.\nFor the trajectory splitting for patient p, we define the input\nas the combination of static data and the history up to a split\ntime t, Xp(t) = (sp, Hp(t)), with Hp(t) = [hpi | hpi ∈\nHp, hpi,timestamp ≤t]. The target Yp(t) is defined as a set of\nfuture predictions of various tasks.\n3.1.1. FORECASTING TASK\nThe first task type is time-series forecasting, used to predict\nfrequently measured values such as blood biomarkers or\nvital signs.\nManaging LLM context size during training and inference\nrequires limiting the number of variables forecast per in-\nstance; accordingly, a subset of variables is sampled for\neach training example to ensure computational feasibility.\nWe denote the set of output variables as V , with V ′ ⊆V\nbeing a sampled subset. This sampling is weighted propor-\ntionally to each variable’s observation count and volatility\n(Appendix B.1.1).\nThe forecasting target Yforecast\np\n(tforecast, V ′) comprises\nfuture values for the sampled variables V ′ up to the forecast-\ning horizon tforecast = t + ∆tforecast with ∆tforecast ∈\nN+. We treat unmeasured values within this window and\nany values of new competing events (e.g., a new line of ther-\napy) as missing targets (Appendix B.1.2). This subsampling\nstrategy maintains flexibility across time horizons while\nensuring computational feasibility.\n3.1.2. LANDMARK EVENTS TASK\nThe second task, predicting a patient’s event status at a future\ntime point, is a critical clinical task, which we formulate\nusing the landmarking framework (Van Houwelingen, 2007)\nwith a focus on patient risk ranking.\nOur data sampling methodology enables the model to pre-\ndict event status for an arbitrarily sampled future horizon\n(Appendix B.1.3; Algorithm 1). We define E ∈E as the\nspecific clinical event from all possible events E, e.g. dis-\nease progression, and tevent = t + ∆tevent as the hori-\nzon, based on ∆tevent ∈N+. The set of event labels\nis Y = {occurred, not occurred, censored}. The model is\nthus trained to predict the patient’s status of event E at the\nlandmark time tevent as one of three classes y ∈Y .\nThis formulation explicitly models the observation process\nand competing events by treating censoring as a distinct\ntarget class. Consistent with established real-world data\nmethodologies (Latimer et al., 2014), we handle treatment\nswitching as a censoring event, as well as patients who reach\nthe end of their recorded trajectory without the occurrence\nof death, or who exceed the dataset’s global cutoff date.\n3.1.3. COMBINING, CONVERTING TO TEXT & TRAINING\nThe TwinWeaver framework transforms the structured pa-\ntient history Xp(t) and multi-task targets Yp(t) into a single,\nhuman-readable text prompt. As outlined in Appendix B.1.4\n(Algorithm 2), this serialized prompt includes static data,\nthe chronological visit history, such as blood measurements\nand biomarkers, a summary of recent critical information,\nand a numbered list of prediction tasks. To manage context\nconstraints, we truncate intermediate visits while strictly\npreserving the initial visit to retain baseline diagnostic in-\nformation. Additionally, to mitigate the ‘lost-in-the-middle’\nphenomenon, we explicitly repeat the most recent clini-\ncal observations and genetic events immediately prior to\nthe task definitions. The model is trained using a standard\ncausal language modeling loss, computed only on the target\ncompletion tokens.\n3.2. Inference\nFor evaluation, inference for forecasting and landmark event\nprediction is handled separately.\n3.2.1. FORECASTING\nFor forecasting inference, we generate { ˆ\nYp\nm}M\nm=1, M ∈\nN+ independent completions from the model’s predictive\ndistribution qθ for a given prompt for patient p (Makarov\net al., 2025). These M text-based completions are decoded\nback into numerical trajectories. We then average these\ntrajectories to produce a stable mean prediction:\nˆ\nYp\nforecast =\n1\nM\nPM\nm=1 ˆ\nYp\nm.\n3.2.2. LANDMARK EVENTS\nEvent probabilities are derived from the model’s three-\nclass outputs (occurred, not occurred, censored) using log-\nlikelihoods, which provide continuous scores required for\n3\n"}, {"page": 4, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nFollicular\nLymphoma\nNSCLC\nBreast\nPancreatic\nEndometrial\nHead & Neck\nCRC\nAdvanced Urothelial\nMetastatic Prostate\nGastric/ Esophageal\nRCC\nSCLC\nHCC\nUndetermined\nAML\nDLBCL\nCLL\nMultiple Myeloma\nMelanoma\nOvarian\nMyeloid\nLymphoid\nMel.\nCarcinomas\nUndeter.\n0.83 (0.23)\n1.03 (0.21)\n0.97 (0.15)\n0.97 (0.09)\n0.96 (0.20)\n0.99 (0.08)\n1.00 (0.00)\n1.03 (0.14)\n0.86 (0.17)\n0.97 (0.20)\n1.01 (0.22)\n0.98 (0.18)\n0.96 (0.23)\n1.00 (0.22)\n1.00 (0.00)\n1.06 (0.16)\n0.87 (0.23)\n0.93 (0.19)\n0.95 (0.15)\n0.96 (0.13)\n0.93 (0.19)\n0.97 (0.15)\n1.00 (0.00)\n1.07 (0.11)\n0.90 (0.19)\n0.98 (0.19)\n0.99 (0.15)\n0.95 (0.15)\n1.01 (0.20)\n0.99 (0.10)\n1.00 (0.00)\n1.07 (0.12)\n0.90 (0.22)\n0.97 (0.16)\n0.96 (0.14)\n0.97 (0.13)\n0.95 (0.21)\n1.03 (0.09)\n1.00 (0.00)\n1.09 (0.26)\n0.88 (0.10)\n0.94 (0.09)\n0.94 (0.10)\n0.97 (0.06)\n1.00 (0.06)\n1.01 (0.07)\n1.00 (0.00)\n1.09 (0.11)\n0.76 (0.18)\n0.93 (0.09)\n0.94 (0.08)\n0.93 (0.07)\n0.93 (0.10)\n0.97 (0.10)\n1.00 (0.00)\n1.07 (0.32)\n0.77 (0.12)\n0.92 (0.08)\n0.93 (0.09)\n0.94 (0.09)\n0.95 (0.07)\n0.98 (0.07)\n1.00 (0.00)\n1.04 (0.13)\n0.80 (0.15)\n0.94 (0.16)\n0.95 (0.16)\n0.93 (0.08)\n0.99 (0.13)\n0.99 (0.09)\n1.00 (0.00)\n1.07 (0.24)\n0.80 (0.18)\n0.93 (0.13)\n0.93 (0.10)\n0.93 (0.07)\n0.92 (0.11)\n0.94 (0.13)\n1.00 (0.00)\n1.09 (0.15)\n0.81 (0.13)\n0.94 (0.14)\n0.94 (0.08)\n0.96 (0.12)\n0.98 (0.09)\n1.00 (0.09)\n1.00 (0.00)\n1.07 (0.16)\n0.81 (0.17)\n0.92 (0.12)\n0.94 (0.10)\n0.93 (0.09)\n0.93 (0.11)\n0.94 (0.08)\n1.00 (0.00)\n1.08 (0.17)\n0.82 (0.07)\n0.94 (0.15)\n0.94 (0.10)\n0.94 (0.06)\n0.95 (0.12)\n0.97 (0.05)\n1.00 (0.00)\n1.07 (0.15)\n0.82 (0.14)\n0.96 (0.09)\n0.95 (0.10)\n0.96 (0.08)\n0.97 (0.09)\n1.00 (0.07)\n1.00 (0.00)\n1.10 (0.15)\n0.84 (0.11)\n0.93 (0.14)\n0.94 (0.16)\n0.96 (0.10)\n0.99 (0.12)\n1.03 (0.12)\n1.00 (0.00)\n1.04 (0.15)\n0.84 (0.12)\n0.95 (0.10)\n0.96 (0.09)\n0.94 (0.06)\n0.96 (0.08)\n0.99 (0.05)\n1.00 (0.00)\n1.08 (0.15)\n0.85 (0.11)\n0.97 (0.10)\n0.98 (0.12)\n0.98 (0.08)\n1.01 (0.11)\n1.01 (0.12)\n1.00 (0.00)\n1.08 (0.18)\n0.85 (0.18)\n0.95 (0.18)\n0.95 (0.14)\n0.97 (0.06)\n0.96 (0.12)\n0.98 (0.15)\n1.00 (0.00)\n1.08 (0.15)\n0.89 (0.18)\n0.98 (0.19)\n0.98 (0.17)\n1.00 (0.08)\n1.03 (0.10)\n1.01 (0.09)\n1.00 (0.00)\n1.04 (0.25)\n0.80 (0.15)\n0.94 (0.10)\n0.95 (0.10)\n0.95 (0.11)\n0.96 (0.11)\n1.00 (0.08)\n1.00 (0.00)\n1.05 (0.15)\n0.80\n0.85\n0.90\n0.95\n1.00\n1.05\n1.10\nMedian\nMASE\nGDT\nTiDE (FT-Multi)\nTiDE (FT-Uni)\nChronos (FT-Uni)\nChronos Bolt (ZS-Uni)\nChronos (ZS-Uni)\nCopy Fwd (Naive)\nLlama 3.1 (ZS)\n0.8\n1.0\n1.2\n(←) MASE\n***\na)\nb)\nFigure 2. GDT achieves reduced error in highly dynamic blood biomarker forecasting across the majority of cancer indications.\na) Heatmap of the median Mean Absolute Scaled Error (MASE - lower is better). GDT shows lower error (darker blue) compared to\nbaselines for the top 30 most time-changing variables per indication. b) Aggregated performance of the top 30 most changing variables\nshows GDT achieves a median MASE of 0.830, significantly outperforming the second-best baseline, TiDE multivariate (p < 0.001,\nWilcoxon signed-rank test). Error bars and numbers in parentheses denote the Interquartile Range (IQR) across variables. ZS denotes\nzero-shot, FT is fine tuned, Uni is univariate input, Multi is multivariate input.\nsurvival analysis evaluation rather than discrete class predic-\ntions. Specifically, we first compute the length-normalized\nlog-likelihood score Ly,p for each of the three possible tar-\nget strings y ∈Y :\nLy,p =\n1\n|x| −k + 1\n|x|\nX\ni=k\nlog(qθ(xi | x1:i−1))\nwhere k is the index of the first token of the target and x =\n[prompt; y] is the prompt concatenated with the target string\ny. We then normalize these scores using a softmax function\nto obtain a probability estimate over the three outcomes:\nˆP(y | Xp(t), E, ∆tevent) =\nexp(Ly,p)\nP\ny′∈Y exp(Ly′,p)\nThe final ranking score of the event E is taken from the\n‘occurred’ class probability:\nScore(p, E, ∆tevent) =\nˆP(y = occurred | Xp(t), E, ∆tevent)\nThe resulting risk score is used for all downstream evalua-\ntion metrics.\n4\n"}, {"page": 5, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nSurvival \nSwitching Therapy\nIPCW C-Index (→ )\na)\nb)\nc)\nd)\nMetastasis\n8\n26\n52\n104\n8\n26\n52\n104\n8\n26\n52\n104\n8\n26\n52\n104\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nPrediction Week\nGDT\nRSF\nNaive\nLlama 3.1 (ZS)\nCLMBR-T\nProgression\nFigure 3. GDT demonstrates improved risk stratification in predicting survival, progression, and switching therapy, while\nmetastasis prediction remains constrained by limited data availability. We report the mean IPCW C-Index (higher is better) and\nstandard error across 20 indications for a) survival, b) disease progression, c) switching therapy, and d) metastasis. GDT demonstrates\nrobust ranking capabilities, outperforming the strongest baselines in 12 of 16 evaluated time points. Lower performance is seen in\npredicting metastasis outcomes, likely due to low data availability (N = 3 indications).\nAlthough the formulation models the joint likelihood of\nevent occurrence and observation and lacks guarantees for\nmonotonic cumulative incidence functions, it remains ef-\nfective for ranking-based clinical tasks such as risk stratifi-\ncation and comparative treatment evaluation (Steck et al.,\n2007).\nThis approach preserves the LLM architecture and training\nprocedure, enabling direct integration with existing software\nlibraries for unified forecasting, event prediction, and rea-\nsoning. We also provide an extension with conditioning\nwithout censoring, together with monotonicity guarantees,\nby applying isotonic regression (Appendix B.2.1).\n4. Pan-Cancer LLM\nAs an instance of the TwinWeaver framework, we train\nGenie Digital Twin (GDT), a pan-cancer LLM, on a large-\nscale real-world dataset from the FH-FMI CGDB (Appendix\nA). The cohort comprises 93,054 patients with recorded\ndrug visits across 20 cancer types and is split at the patient\nlevel into 82,753 training, 4,991 validation, and 4,999 test\npatients to ensure robust evaluation.\n4.1. Data Preprocessing\nThe pipeline transforms raw multi-modal inputs, including\ndiagnoses, laboratory measurements, and genetic mutation\npanels, into a structured textual representation of longitu-\ndinal patient trajectories at weekly resolution (Appendix\nC.1.1).\n4.2. Task Configuration\nTraining focuses on clinically relevant periods by sampling\nsplit times t uniformly from visits within 90 days of a new\nline of therapy. This strategy allows us to generate multiple\ntraining samples from a single patient without overfitting on\nspecific patterns, specifically 10 for GDT, leveraging their\nfull history across different treatments.\nGDT is configured to perform two primary prediction tasks\nsimultaneously. First, we set the blood biomarker time-\nseries horizon ∆tforecast = 13 weeks, a horizon highly\nrelevant for monitoring treatment response and toxicity. Sec-\nond, we predict four key clinical events (survival, metastasis,\ndisease progression, and therapy switching) at longer hori-\nzons sampled uniformly ∆tevent ∈{1, . . . , 104}, enabling\nflexible predictions across various clinically relevant hori-\nzons. Whilst the TwinWeaver framework is model-agnostic,\nwe choose to instantiate GDT using an established open-\nsource model, Llama 3.1 8B Instruct. We train for 1 epoch\nusing the AdamW optimizer, with a learning rate of 10−5\nand a context length of 8000 tokens (Appendix C.2.1).\n4.3. Reasoning Extension\nUsing fine-tuned LLMs as a prediction platform enables\ndownstream tasks such as reasoning. We focus on neu-\ntrophil forecasting on a subsample of the NSCLC cohort\n(N = 2, 385). To address the scarcity of gold-standard clini-\ncal rationales, we employ a knowledge distillation approach,\nprompting a teacher model, Qwen3 Next 80B-A3B (Yang\n5\n"}, {"page": 6, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\na)\nb)\nc)\nd)\ne)\nf)\nLlama 3.1 (ZS)\nChronos Bolt (ZS)\nCopy Fwd (Naive)\nChronos (ZS)\nTiDE (FT-Multi)\nChronos (FT)\nGDT (ZS)\nTiDE (FT-Uni)\nGDT (SFT)\n0.6\n0.8\n1.0\n1.2\n(←) MASE\nPOPLAR Trial \n Blood Biomarker Forecasting\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n8\n26\n52\n104\nPrediction Week\nIPCW C-index (→)\nGDT (SFT)\nGDT (ZS)\nRSF\nCLMBR-T\nLlama 3.1\nNaive\n Survival\n8\n26\n52\n104\nPrediction Week\n Progression\nLlama 3.1 (ZS)\nChronos Bolt (ZS)\nCopy Fwd (Naive)\nChronos (ZS)\nChronos (FT)\nGDT (ZS)\nTiDE (FT-Multi)\nTiDE (FT-Uni)\nGDT (SFT)\n0.6\n0.8\n1.0\n1.2\n(←) MASE\nIMpower130  Trial\n Blood Biomarker Forecasting\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n8\n26\n52\n104\nPrediction Week\nIPCW C-index (→)\nGDT (SFT)\nGDT (ZS)\nRSF\nCLMBR-T\nLlama 3.1\nNaive\n Survival\n8\n26\n52\n104\nPrediction Week\n Progression\nFigure 4. GDT with supervised fine-tuning (SFT) outperforms baselines on out-of-distribution clinical trial tasks. The model is\nevaluated on the unseen trials a-c) POPLAR and d-f) IMpower130. GDT (SFT) achieves the lowest MASE (Mean Absolute Scaled Error -\nlower is better; IQR error bars across 17 variables) in blood biomarker forecasting (a, d) and highest C-Indexes (higher is better) for\nsurvival (b, e) and progression (c, f) events, demonstrating strong generalization in cold start scenarios where historical data is sparse.\nZS denotes zero-shot predictions, FT means the model is fine-tuned, whilst Uni is univariate input, Multi is multivariate input, RSF is\nRandom Survival Forest.\net al., 2025), to synthesize structured chains-of-thought con-\nditioned on patient history and ground-truth outcomes. The\nstudent GDT model first undergoes supervised fine-tuning\non this synthetic corpus, followed by alignment via Group\nRelative Policy Optimization (GRPO) (Shao et al., 2024b).\nCrucially, to ground the generated reasoning in empirical\naccuracy, we utilize a deterministic reward function defined\nby the negative Mean Absolute Error (MAE) of the numer-\nical forecast. This optimization objective ensures that the\ngenerated rationale serves as a functional intermediate rep-\nresentation aligned with accurate trajectory modeling, rather\nthan merely plausible-sounding text (Appendix C.2.2).\n4.4. Baselines\nWe compare GDT against forecasting and event-prediction\nbaselines (Appendix C.3). Forecasting baselines include\ncopy-forward, TiDE, and the foundation models Chronos\nand Chronos Bolt (Ansari et al., 2024), which were pre-\ntrained on over 700k time series. On the other hand, event\nprediction baselines include Random Survival Forest (RSF)\nand the EHR foundation model CLMBR-T, pretrained on\n2.5 million patients and adapted with a Cox proportional\nhazards head. In real-world data experiments, baselines are\ntrained on a representative 2k-patient subset; Appendix D.1\nshows that GDT retains its advantage under the same con-\nstraint. All clinical trial evaluations use identical datasets.\n5. Results\nWe benchmark GDT across 20 cancer indications on real-\nworld clinical data as well as on out-of-distribution clinical\ntrial tasks, enabling evaluation in realistic settings.\n6\n"}, {"page": 7, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\n5.1. RWD Forecasting Results\nGDT consistently outperforms forecasting baselines across\nall indications.\nAggregated across all variables, GDT\nachieves a median MASE of 0.867 (IQR 0.186), signif-\nicantly outperforming the next-best model, multivariate\nTiDE (0.966; p < 0.001, Wilcoxon signed-rank test). Other\nfoundation models and baselines, including Chronos and\nLlama 3.1, exhibit higher error rates (Appendix D.2).\nThis performance advantage is even more pronounced on\nclinically critical, highly volatile variables. Evaluated on the\ntop 30 most time-varying biomarkers per indication (Figure\n2), GDT achieves a median MASE of 0.830 (IQR 0.165),\nsignificantly outperforming multivariate TiDE (0.947; p <\n0.001). These results demonstrate GDT’s effectiveness in\nmodeling dynamic patient trajectories relative to time-series\nmodels and general-purpose LLMs.\nNotably, GDT retains this performance advantage even\nwhen trained on the same 2,000-patient subset as the base-\nlines (Appendix D.1).\n5.2. RWD Event Results\nGDT shows statistically significant improvements across\nthe majority of modeled clinical outcomes, specifically\nthose with sufficient indication coverage (Figure 3). For\nsurvival, progression, and therapy switching (each with\nN > 10 indications), GDT outperforms the strongest base-\nline, RSF, across all evaluated time points on Inverse Prob-\nability of Censoring Weighting (IPCW) C-index (0.703 vs\n0.662), and is statistically significant in 11 of 12 time points\n(padj < 0.05). This advantage does not extend to time-\nto-metastasis (IPCW C-index 0.502 vs 0.563; N = 3),\nwhere limited training diversity likely constrains perfor-\nmance, highlighting a low-data boundary for the proposed\narchitecture.\nInterestingly, we observe lower performance for the EHR\nfoundation model CLMBR-T despite its larger pretrain-\ning cohort and task-specific fine-tuning. This may be at-\ntributable to its fixed vocabulary, which covers only 11 of\nthe 283 therapies present in the dataset.\n5.3. Validation on Clinical Trials\nWe further evaluate the method on out-of-distribution clin-\nical trial tasks, using two trials for testing (POPLAR, IM-\npower130) and two additional trials for optional fine-tuning\n(OAK, IMpower131; Appendix D.3). Clinical trials can\nbe considered out-of-distribution due to differences in data\nmeasurement and format, as well as distinct patient pop-\nulations, in comparison to the RWD training set (Orcutt\net al., 2025). The task focuses on cold-start prediction from\nbaseline measurements only, reflecting a challenging and\nTiDE - fully train (0.965)\n0.85\n0.90\n0.95\n1.00\n1.05\nZero-shot 1\n2\n4\n8\n16 32 64 128\nall\n# Training Samples per Variable\n(Log Scale)\nMASE (←)\nFigure 5. Forecasting error as a function of training sample size.\nEvaluated on the test set of the POPLAR trial, using Mean Abso-\nlute Scaled Error (MASE), relative to training samples from the\nOAK trial (log X-axis; error bars denote IQR across 17 variables).\nZero-shot performance is competitive, while low-data fine-tuning\nshows an initial error increase before stabilizing and improving at\nhigher counts (all ≈880/variable).\nclinically relevant trial setting. Note, the data is identical\nacross all models in the same setup with respect to fine-\ntuning and zero-shot settings. GDT is evaluated in both\nzero-shot and fine-tuned settings, with identical data used\nacross all models within each setup (Figure 4).\n5.3.1. CLINICAL TRIAL BLOOD BIOMARKER\nFORECASTING\nIn the cold-start setting, GDT shows strong generalization\nperformance. GDT, fine-tuned on OAK and IMpower131,\nthen evaluated on POPLAR and IMpower130 attains the\nlowest error rates (median MASE 0.883 and 0.754), signifi-\ncantly outperforming the strongest baseline, univariate TiDE\n(p < 0.05), while zero-shot GDT matches task-specific fine-\ntuned models (Appendix D.3).\n5.3.2. CLINICAL TRIAL EVENT PREDICTION\nFor clinical trial event prediction, fine-tuned GDT shows\nstrong performance, achieving the highest C-index in all\nevaluation time points, with the zero-shot variant perform-\ning comparably high (IPCW C-indexes 0.672 and 0.656;\nFigure 4). RSF provides a competitive baseline (IPCW C-\nindex 0.648) without using longitudinal trajectories, while\nCLMBR-T shows variable performance across POPLAR\nand IMpower130, potentially reflecting vocabulary con-\nstraints. Statistical testing was not conducted due to limited\nsample sizes.\n5.3.3. SAMPLE EFFICIENCY ANALYSIS\nWe evaluate the sample efficiency of GDT in an out-of-\ndistribution setting by training on the OAK trial and testing\non POPLAR, which share identical treatment regimens (Fig-\nure 5). Performance is assessed by progressively subsam-\npling the training data across 17 target variables.\n7\n"}, {"page": 8, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\n0.25\n0.07\n0.14\n0.29\n0.95\n0.21\n0.00\n0.16\n0.06\n0.12\n0.27\n0.96\n0.03\n0.01\n0.19\n0.06\n0.12\n0.31\n0.65\n0.69\n0.05\n0.09\n0.03\n0.34\n0.15\n0.94\n0.05\n0.03\nTargeted\nIO\nChemo\nChemo\n+ IO\nNeutrophil\nRecruitment\nImmune\nActivation\nMarrow\nSuppression\nTP53\nEGFR\nSTK11\nHigh TMB\nRel. Importance\n0.25\n0.50\n0.75\n1.00\nFrequency\n0.25\n0.50\n0.75\na)\n<prediction>\nTask 1 is forecasting:\n...\n</prediction>\n<thinking>\n1. Patient summary: ...\n2. Key factors: ...\n3. Mechanistic \n    analysis: ...\n4. Confounding \n    factors: ...\n</thinking>\n<prognosis_summary>\n...\n</prognosis_summary>\nb)\nc)\nImmune Activation\nMarrow Suppression\n2\n4\n6\n8\n10\n12\n3\n4\n5\n6\n3\n4\n5\n6\nForecasting Week\nForecasted Neutrophils [10\n9/L]\nConcept in\nReasoning\nAbsent\nPresent\nFigure 6. GDT can be extended to provide clinically aligned reasoning. a) The model generates a structured reasoning chain, including\npatient summary, key factors, and mechanistic analysis, alongside its numerical forecast. b) Keyword analysis shows alignment with\nclinical expectations, linking marrow suppression to chemotherapy, immune activation to immunotherapy (IO), and EGFR mutations to\ntargeted therapy c) Stratifying predicted neutrophil trajectories by presence of reasoning concepts confirms validated effects: ‘Marrow\nSuppression’ is linked to lower counts, while ‘Immune Activation’ is linked to higher counts.\nWhile zero-shot performance is comparable to fully trained\nTiDE, fine-tuning GDT leads to consistently better perfor-\nmance at 64 samples per variable. Interestingly, the error\nincreases initially, potentially hinting that training on few\nsamples might overfit the model and be worse than the zero-\nshot setting.\n5.4. Reasoning Extension\nWe demonstrate the flexibility of the TwinWeaver frame-\nwork by extending GDT to generate interpretable clinical\nreasoning alongside forecasts for neutrophil trajectories in\nNSCLC (Figure 6; Appendix D.4). Keyword analysis con-\nfirms that GDT generated reasoning chains correspond to\nclinically relevant features and genetic contexts, correctly\nassociating high tumor mutational burden (TMB) more with\nimmunotherapy based medications (Shao et al., 2024a),\nwhile identifying EGFR mutations as key drivers in tar-\ngeted therapies and delineating distinct neutrophil trajecto-\nries based on patients’ immune state (Dunbar et al., 2021;\nOrr et al., 2007). The model additionally identifies STK11\nas a key genetic mutation, which has been found to be\nassociated with effects on neutrophil levels, as well as a\nprognostic marker (Zheng et al., 2024; Koyama et al., 2016).\nAlthough the reasoning extension incurs a modest increase\nin forecasting error (MASE 0.862 vs 0.828), it offers a cal-\nculated trade-off for clinical utility by providing transparent,\nbiologically grounded context for hypothesis generation.\n5.5. Training Synergy Across Cancer Indications\nWe find that the pan-cancer training improves the perfor-\nmance of individual cancer indications, thus demonstrating\nthe value of training across a diverse set of diseases, par-\nticularly for predictions in diseases that present less data\n(Appendix D.5).\n5.6. Patient History Analysis\nWe further show that incorporating richer patient histories\ncan enhance clinical trial survival predictions beyond current\ndata collection practices (Appendix D.6). We select patients\nfrom the NSCLC test set with at least 52 weeks of history,\nand systematically cut patient history whilst comparing one-\nyear survival IPCW C-index performance. We observe an\nimprovement of 9.9% of the C-index when using the full\npatient history, in comparison to using baseline information\nonly, which is often done in the context of clinical trials.\n6. Conclusion\nOverall, our findings suggest that the TwinWeaver frame-\nwork transforms pretrained LLMs using specific fine-tuning\ninto clinical prediction engines, exemplified with GDT. Our\nbenchmarks highlight that, despite standard methods re-\nmaining competitive baselines, fine-tuned LLMs overcome\ncritical limitations regarding fixed vocabularies and multi-\nmodal integration, thus improving prediction performance\nover existing methods. Specifically, the ability of GDT to\n8\n"}, {"page": 9, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\ngeneralize to new clinical trials as well as its pan-cancer ca-\npabilities offers a promising solution for low-data scenarios.\nFuture work should focus on systematic hyperparameter op-\ntimization, including sampling strategies and prompt design.\nFuture iterations should also integrate modalities such as\nhistopathology images, single-cell and spatial omics. Inte-\ngrating reasoning directly into model training may enable\nreasoning-first clinical foundation models. From a transla-\ntional perspective, rigorous clinical validation is required to\nassess real-world utility, and further refinement of time-to-\nevent modeling is needed to produce well-calibrated survival\ncurves while maintaining generative flexibility.\nIn conclusion, results with GDT demonstrate the effective-\nness of the TwinWeaver framework, indicating that LLMs\ncan be adapted successfully as a platform for patient digital\ntwins.\nSoftware and Data\nAll framework and model code can be found at\nhttp://github.com/MendenLab/TwinWeaver.\nThe FH-FMI CGDB data that support the findings of this\nstudy were originated by and are the property of Flatiron\nHealth, Inc. and Foundation Medicine, Inc. Requests for\ndata sharing by license or by permission for the specific\npurpose of replicating results in this manuscript can be sub-\nmitted to PublicationsDataAccess@flatiron.com and cgdb-\nfmi@flatiron.com.\nQualified researchers may request access to individual clini-\ncal trial patient-level data for this analysis through a data re-\nquest platform. At the time of writing, this request platform\nis https://vivli.org/ourmember/roche/. For up to date details\non Roche’s Global Policy on the Sharing of Clinical Infor-\nmation and how to request access to related clinical study\ndocuments, see here: https://go.roche.com/data_sharing.\nAnonymized records for individual patients across more\nthan one data source external to Roche cannot, and should\nnot, be linked due to a potential increase in risk of patient\nre-identification. For the clinical trial cohort, 4 clinical stud-\nies sponsored by Roche/Genentech were identified with the\nappropriate informed consent for secondary data use analy-\nsis. The analysis was conducted according to Good Clinical\nPractice and the Declaration of Helsinki.\nAcknowledgements\nWe thank the patients, families, caregivers, and site person-\nnel who participated in the data from which were included\nin this analysis.\nWe also thank Pietro Belligoli, Clara Wong-Fannjiang, Mak-\nsim Eremeev, Jesse Swanson, Claudia Iriondo and Guy\nAmster for their feedback and valuable discussions. We\nwould also like to thank Anna Bauer-Mehren, Monika Bug\nand Luise Wolf for supporting the collaborations, as well as\nEmilia Leogrande and Andrew Whitehead for enabling the\npublication.\nThis study was funded by F. Hoffmann-La Roche and the\nEuropean Union’s Horizon 2020 Research and Innovation\nProgramme (Grant agreement No. 950293–COMBAT-RES).\nN.M., M.B. and M.P.M are supported by the Helmholtz\nAssociation under the joint research school “Munich School\nfor Data Science - MUDS”.\nImpact Statement\nThis work advances precision oncology by enabling inter-\npretable Patient Digital Twins via Large Language Mod-\nels. By providing transparent reasoning alongside forecasts,\nTwinWeaver fosters clinical trust and offers a scalable solu-\ntion for data-scarce scenarios in drug development. How-\never, applying generative models to healthcare entails risks\nregarding hallucination and the propagation of biases inher-\nent in Real-World Data. We emphasize that this framework\nis currently a research tool, rigorous prospective validation\nis an essential prerequisite before clinical deployment.\nConsent for Publication\nThis manuscript is sufficiently anonymised and does not\ncontain any personal and/or medical information about an\nidentifiable patient.\nCompeting Interests\nN.M., M.B., R.R.E., L.V.V. and F.S. are all employees of\nF. Hoffmann-La Roche. S.M., J.W., D.M. are employees\nof Genentech. M.P.M. collaborates and is financially sup-\nported by GSK, F. Hoffmann-La Roche, and AstraZeneca.\nM.P.M. consults Merck Sharp & Dohme and McKinsey &\nCompany.\nAuthor Contributions\nN.M. conceived and executed the project. E.V.P., J.W., and\nD.M. contributed to methodology and the implementation\nof the software framework. M.B., L.V.V., S.M., and H.W.\nperformed data preparation, experimental analysis and vi-\nsualization. K. Choi, K. Cho, and S.R. contributed to the\nmethodology and study planning. R.R.E., F.S., and M.P.M.\nsupervised, designed and directed the project. All authors\nreviewed and contributed to the writing of the manuscript.\n9\n"}, {"page": 10, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nReferences\nAnsari, A. F., Stella, L., Turkmen, A. C., Zhang, X., Mer-\ncado, P., Shen, H., Shchur, O., Rangapuram, S. S.,\nArango, S. P., Kapoor, S., et al.\nChronos: Learning\nthe language of time series. Transactions on Machine\nLearning Research, 2024. ISSN 2835-8856.\nBecker, T., Weberpals, J., Jegg, A., So, W., Fischer, A.,\nWeisser, M., Schmich, F., Rüttinger, D., and Bauer-\nMehren, A. An enhanced prognostic score for overall\nsurvival of patients with cancer derived from a large real-\nworld cohort. Annals of Oncology, 31(11):1561–1568,\n2020.\nBedi, S., Fries, J. A., and Shah, N. H. How to interpret\n‘zero-shot’ results from generative EHR models. Nature\nMedicine, pp. 1–3, 2026. ISSN 1078-8956. doi: 10.1038/\ns41591-025-04094-8.\nBordukova, M., Makarov, N., Rodriguez-Esteban, R.,\nSchmich, F., and Menden, M. P. Generative artificial\nintelligence empowers digital twins in drug discovery\nand clinical trials. Expert opinion on drug discovery, 19\n(1):33–42, 2024.\nCox, D. R. Regression models and life-tables. Journal of\nthe Royal Statistical Society: Series B (Methodological),\n34(2):187–202, 1972.\nDas, A., Kong, W., Leach, A., Mathur, S. K., Sen, R., and Yu,\nR. Long-term forecasting with tiDE: Time-series dense\nencoder. Transactions on Machine Learning Research,\n2023. ISSN 2835-8856. URL https://openrevi\new.net/forum?id=pCbC3aQB5W.\nDunbar, A., Bolton, K. L., Devlin, S. M., Sanchez-Vega,\nF., Gao, J., Mones, J. V., Wills, J., Kelly, D., Farina, M.,\nCordner, K. B., Park, Y., Kishore, S., Juluru, K., Iyengar,\nN. M., Levine, R. L., Zehir, A., Park, W., Khorana, A. A.,\nSoff, G. A., and Mantha, S. Genomic profiling identi-\nfies somatic mutations predicting thromboembolic risk in\npatients with solid tumors. Blood, 137(15):2103–2113,\n2021. ISSN 0006-4971. doi: 10.1182/blood.2020007488.\nErickson, N., Mueller, J., Shirkov, A., Zhang, H., Larroy,\nP., Li, M., and Smola, A. Autogluon-tabular: Robust\nand accurate automl for structured data. arXiv preprint\narXiv:2003.06505, 2020.\nFlatiron Health. Database characterization guide. https:\n//flatiron.com/database-characterizat\nion, March 18 2025. Accessed December 18, 2025.\nGraf, E., Schmoor, C., Sauerbrei, W., and Schumacher, M.\nAssessment and comparison of prognostic classification\nschemes for survival data. Statistics in medicine, 18(17-\n18):2529–2545, 1999.\nGruver, N., Finzi, M., Qiu, S., and Wilson, A. G. Large\nlanguage models are zero-shot time series forecasters.\nAdvances in Neural Information Processing Systems, 36:\n19622–19635, 2023.\nGuo, L. L., Steinberg, E., Fleming, S. L., Posada, J., Lem-\nmon, J., Pfohl, S. R., Shah, N., Fries, J., and Sung, L. Ehr\nfoundation models improve robustness in the presence\nof temporal distribution shift. Scientific Reports, 13(1):\n3767, 2023.\nHemadri, R. V., Guruju, G. K., Topollai, K., and Choroman-\nska, A. E. Oncoreason: Structuring clinical reasoning\nin llms for robust and interpretable survival prediction.\narXiv preprint arXiv:2510.17532, 2025.\nHoo, S. B., Müller, S., Salinas, D., and Hutter, F. The tabular\nfoundation model tabpfn outperforms specialized time\nseries forecasting models based on simple features. In\nNeurIPS Workshop on Time Series in the Age of Large\nModels, 2024.\nHussain, Z., De Brouwer, E., Boiarsky, R., Setty, S., Gupta,\nN., Liu, G., Li, C., Srimani, J., Zhang, J., Labotka,\nR., et al. Joint ai-driven event prediction and longitu-\ndinal modeling in newly diagnosed and relapsed multiple\nmyeloma. NPJ Digital Medicine, 7(1):200, 2024.\nHyndman, R. J. and Koehler, A. B. Another look at mea-\nsures of forecast accuracy. International journal of fore-\ncasting, 22(4):679–688, 2006.\nIshwaran, H., Kogalur, U. B., Blackstone, E. H., and Lauer,\nM. S. Random survival forests. The Annals of Applied\nStatistics, 2(3):841–860, 2008.\nKamel Boulos, M. N. and Zhang, P. Digital twins: from\npersonalised medicine to precision public health. Journal\nof personalized medicine, 11(8):745, 2021.\nKatzman, J. L., Shaham, U., Cloninger, A., Bates, J., Jiang,\nT., and Kluger, Y. Deepsurv: personalized treatment rec-\nommender system using a cox proportional hazards deep\nneural network. BMC medical research methodology, 18\n(1):24, 2018.\nKoyama, S., Akbay, E. A., Li, Y. Y., Aref, A. R., Skoulidis,\nF., Herter-Sprie, G. S., Buczkowski, K. A., Liu, Y., Awad,\nM. M., Denning, W. L., Diao, L., Wang, J., Parra-Cuentas,\nE. R., Wistuba, I. I., Soucheray, M., Thai, T., Asahina,\nH., Kitajima, S., Altabef, A., Cavanaugh, J. D., Rhee, K.,\nGao, P., Zhang, H., Fecci, P. E., Shimamura, T., Hell-\nmann, M. D., Heymach, J. V., Hodi, F. S., Freeman, G. J.,\nBarbie, D. A., Dranoff, G., Hammerman, P. S., and Wong,\nK.-K. STK11/LKB1 deficiency promotes neutrophil re-\ncruitment and proinflammatory cytokine production to\n10\n"}, {"page": 11, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nsuppress t-cell activity in the lung tumor microenviron-\nment. Cancer Research, 76(5):999–1008, 2016. ISSN\n0008-5472. doi: 10.1158/0008-5472.can-15-1439.\nLatimer, N. R., Abrams, K. R., et al. Nice dsu technical\nsupport document 16: adjusting survival time estimates\nin the presence of treatment switching. 2014.\nMakarov, N., Bordukova, M., Quengdaeng, P., Garger, D.,\nRodriguez-Esteban, R., Schmich, F., and Menden, M. P.\nLarge language models forecast patient health trajectories\nenabling digital twins. npj Digital Medicine, 8(1):588,\n2025.\nOrcutt, X., Chen, K., Mamtani, R., Long, Q., and Parikh,\nR. B. Evaluating generalizability of oncology trial results\nto real-world patients using machine learning-based trial\nemulations. Nature Medicine, 31(2):457–465, 2025.\nOrr, Y., Wilson, D. P., Taylor, J. M., Bannon, P. G., Geczy,\nC., Davenport, M. P., and Kritharides, L.\nA kinetic\nmodel of bone marrow neutrophil production that char-\nacterizes late phenotypic maturation. American Journal\nof Physiology-Regulatory, Integrative and Comparative\nPhysiology, 292(4):R1707–R1716, 2007.\nPellegrini, C., Özsoy, E., Bani-Harouni, D., Keicher, M.,\nand Navab, N. From ehrs to patient pathways: Scalable\nmodeling of longitudinal health trajectories with llms.\narXiv preprint arXiv:2506.04831, 2025.\nPukelsheim, F. The three sigma rule. The American Statisti-\ncian, 48(2):88–91, 1994.\nShao, M.-m., Xu, Y.-p., Zhang, J.-j., Mao, M., and Wang,\nM.-c. Tumor mutational burden as a predictive biomarker\nfor non-small cell lung cancer treated with immune\ncheckpoint inhibitors of PD-1/PD-l1.\nClinical and\nTranslational Oncology, 26(6):1446–1458, 2024a. doi:\n10.1007/s12094-023-03370-8.\nShao, Z., Wang, P., Zhu, Q., Xu, R., Song, J., Bi, X., Zhang,\nH., Zhang, M., Li, Y., Wu, Y., et al. Deepseekmath: Push-\ning the limits of mathematical reasoning in open language\nmodels. arXiv preprint arXiv:2402.03300, 2024b.\nSingal, G., Miller, P. G., Agarwala, V., et al. Association of\npatient characteristics and tumor genomics with clinical\noutcomes among patients with non-small cell lung cancer\nusing a clinicogenomic database. JAMA, 321(14):1391–\n1399, 2019. doi: 10.1001/jama.2019.3241.\nSteck, H., Krishnapuram, B., Dehing-Oberije, C., Lambin,\nP., and Raykar, V. C. On ranking in survival analysis:\nBounds on the concordance index. Advances in neural\ninformation processing systems, 20, 2007.\nSteinberg, E., Fries, J. A., Xu, Y., and Shah, N. MOTOR:\nA time-to-event foundation model for structured medical\nrecords.\nIn The Twelfth International Conference on\nLearning Representations, 2024a.\nSteinberg, E., Wornow, M., Shah, N., et al.\nFEMR:\nFramework for Electronic Medical Records. https:\n//github.com/som-shahlab/femr, 2024b.\nUno, H., Cai, T., Pencina, M. J., D’Agostino, R. B., and Wei,\nL.-J. On the c-statistics for evaluating overall adequacy\nof risk prediction procedures with censored survival data.\nStatistics in medicine, 30(10):1105–1117, 2011.\nVan Houwelingen, H. C. Dynamic prediction by landmark-\ning in event history analysis. Scandinavian Journal of\nStatistics, 34(1):70–85, 2007.\nWornow, M., Thapa, R., Steinberg, E., Fries, J., and Shah,\nN. Ehrshot: An ehr benchmark for few-shot evaluation\nof foundation models. Advances in Neural Information\nProcessing Systems, 36:67125–67137, 2023a.\nWornow, M., Xu, Y., Thapa, R., Patel, B., Steinberg, E.,\nFleming, S., Pfeffer, M. A., Fries, J., and Shah, N. H. The\nshaky foundations of large language models and foun-\ndation models for electronic health records. npj digital\nmedicine, 6(1):135, 2023b.\nYang, A., Li, A., Yang, B., Zhang, B., Hui, B., Zheng, B.,\nYu, B., Gao, C., Huang, C., Lv, C., et al. Qwen3 technical\nreport. arXiv preprint arXiv:2505.09388, 2025.\nZheng, J., Deng, Y., Huang, B., and Chen, X. Prognostic\nimplications of STK11 with different mutation status and\nits relationship with tumor-infiltrating immune cells in\nnon-small cell lung cancer. Frontiers in Immunology, 15:\n1387896, 2024. doi: 10.3389/fimmu.2024.1387896.\nZhuang, L., Park, S. H., Skates, S. J., Prosper, A. E.,\nAberle, D. R., and Hsu, W. Advancing precision on-\ncology through modeling of longitudinal and multimodal\ndata. IEEE Reviews in Biomedical Engineering, 2025.\n11\n"}, {"page": 12, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nA. Data Source\nThis study used the US-based deidentified Flatiron Health-Foundation Medicine Breast Cancer, Colorectal Cancer, Pancreatic\nCancer, Ovarian Cancer, Metastatic Prostate Cancer, Gastric and Esophageal Cancer, Endometrial Cancer, Melanoma,\nAdvanced Urothelial Carcinoma, Renal Cell Carcinoma, Head and Neck Cancer, Small Cell Lung Cancer, Multiple Myeloma,\nHepatocellular Carcinoma, Acute Myeloid Leukemia, Chronic Lymphocytic Leukemia, Diffuse Large B-cell Lymphoma,\nand Follicular Lymphoma Clinico-Genomic Database (FH-FMI CGDB).\nClinical data from the Flatiron Health Research Database (Flatiron Health, 2025) are linked to genomic data, derived from\nFMI’s comprehensive genomic profiling (CGP) tests (FoundationOne®CDx, FoundationOne®, FoundationOne®Liquid\nCDx, FoundationOne®Liquid and/or FoundationOne®Heme), in the FH-FMI CGDB by deterministic matching, providing\na deidentified dataset (Singal et al., 2019).\n12\n"}, {"page": 13, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nB. Methodological Details\nThis section details the TwinWeaver framework, the specific GDT implementation details, and the inference post-processing\nmethods.\nB.1. TwinWeaver Framework Details\nB.1.1. FORECASTING VARIABLE SAMPLING\nThe probability p(v) of sampling a variable v ∈V for the forecasting task is set proportionally to its count and its volatility.\nWe define volatility using the root mean squared error (RMSE) of a simple “copy-forward” baseline, which predicts the\nnext value will be the same as the last observed value. We filter variables to include only those which have at least a certain\nminimum number of observations, in the case of GDT, is set to 50.\nLet S(v) = S\np∈P{(mp(v, τi), mp(v, τi+1))} be the set of all consecutive value pairs (y, y′) for v (where τi+1 is the next\nobservation time after τi for patient p) across all patients. Let Nv = |S(v)|. The copy-forward RMSE is:\nRMSEv =\nv\nu\nu\nt 1\nNv\nX\n(y,y′)∈S(v)\n(y′ −y)2\nLet σv be the standard deviation of all observed values of v. We define the normalized RMSE (NRMSE) as:\nNRMSEv = RMSEv\nσv\nLet Cv be the total number of observations for variable v in the dataset. The unnormalized sampling score sv is defined as:\nsv = log2(Cv × NRMSEv)\nThe final sampling probability p(v) is obtained by normalizing these scores over all candidate variables in V . This strategy\nbiases sampling towards variables that are frequently measured (Cv) and exhibit high, non-trivial variance over time\n(NRMSEv), which are often the most clinically relevant and challenging to predict.\nB.1.2. FORECASTING DETAILS\nThe forecasting target Yforecast is defined as the set of lists of future values for the sampled variables V ′. We only include\ntarget values up to the forecast horizon and censor the prediction window at the start of any new competing event, such as a\nnew line of therapy, which could fundamentally alter patient trajectory. Formally, the target is:\nYforecast\np\n(t, V ′) ={[mp(v, t + k) | k ∈{1, . . . , ∆tforecast},\nt + k < τcensor(p, t)] | v ∈V ′}\nwhere mp(v, τ) is the value of lab v at week τ, τcensor(p, t) is the time of the next competing event after t, and unmeasured\nvalues are treated as missing targets.\nAdditional Forecasting Task\nTo ensure the model remains relevant across a multitude of tasks, we also include a\nforecasting task for binned values. In this setup, the task is to predict which of 5 equally numbered quintiles the variable’s\nvalue lands in across the future time steps. However, due to its relevance and scope, we do not further evaluate this task in\nthis paper, and it should be explored in future work.\nB.1.3. LANDMARK EVENTS DETAILS\nThe uniform sampling of the horizon ∆t acts as a form of data augmentation, training the model to generalize to any on-\ndemand prognostic query at inference time. Although computationally feasible, this sampling approach prevents overfitting\nto canonical time points (e.g., 1-year survival) and encourages a more robust understanding of time-aware risk.\n13\n"}, {"page": 14, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nAlgorithm 1 TwinWeaver: Landmark Event Sampling Strategy\nRequire: Patient p, history Xp(t) up to split time t, event set E, horizon range h\nEnsure: Training tuple (Xp(t), E, ∆tevent, y) with y ∈Y\n1: Randomly sample an event E ∈E (e.g., disease progression).\n2: Sample a horizon ∆tevent ∼Uniform[1, h].\n3: Set tevent ←t + ∆tevent.\n4: Determine whether tevent is censored (e.g., by new therapy) and whether E occurred by tevent:\n• If a censoring event occurs in (t, tevent] before occurrence of event E, set y ←censored.\n• Else if E occurs by tevent, set y ←occurred.\n• Else set y ←not occurred.\n5: return (Xp(t), E, ∆tevent, y).\nWe also recognize that a uniform sampling strategy could be questioned, as clinical event hazards are rarely uniform. This\nmismatch could introduce a bias, potentially leading the model to be poorly calibrated at extreme horizons. Given the large\ncapacity of the LLM and the millions of training samples, we hypothesize that this bias is minimized, but we explicitly\nevaluate this by testing on stratified, predetermined landmark times.\nB.1.4. COMBINING PROMPT\nAlgorithm 2 TwinWeaver: Prompt Construction for Supervised Fine-Tuning\nRequire: Split date t, patient history Xp(t) up to split time t, forecasting variables V ′ ⊆V , targets Yforecast\np\n(t) containing\nforecasting targets Yforecast\np\n(tforecast, V ′), at least one event setup {(Ej, ∆tj, yj)}j.\nEnsure: Input string Sprompt and target completion Starget\n1: Encode a fixed starting prompt π0 into Sprompt.\n2: Encode the patient’s constant data (sp; e.g., demographics).\n3: Encode the history Hp(t) visit-by-visit in chronological order; alphabetically sort items within each visit. All missing\nvalues are skipped. If total size of prompt exceeds context length, we omit visits until the total prompt is less than the\ncontext length, while ensuring to include the first visit, which often contains important initial diagnoses.\n4: Repeat the latest critical observations (e.g. genetic observations, the latest line of therapy, and the last observed values\nof all v ∈V ′), to avoid the lost in the middle problem.\n5: Encode all tasks in text and assign each a numeric task ID j = 1, . . . , |T |.\n6: Construct Starget by encoding the corresponding task answers in the same order and required format, skipping missing\ndata.\n7: return (Sprompt, Starget).\nIn Algorithm 2, we see how the final full prompt is constructed. Note, that whilst the approach is limited by context length,\nwe anticipate that this will become less of an issue as the current large, state of the art models can process over 100k tokens.\nB.2. Inference Post-Processing\nB.2.1. CONSTRUCTING MONOTONIC CUMULATIVE INCIDENCE FUNCTION (ISOTONIC REGRESSION)\nWhereas the landmarking approach described in Section 3.2.2 provides robust risk estimates for specific horizons, treating\neach horizon ∆t as an independent query can result in temporal inconsistencies. To recover a consistent Cumulative\nIncidence Function (CIF) F(t) for individual patient analysis, we employ a two-step post-processing strategy: conditioning\nfollowed by isotonic calibration.\nStep 1: Conditioning. We first isolate the risk signal from the censoring distribution. Under the assumption of non-\ninformative censoring, the probability of the event occurring by time t, given that the observation was not censored before t,\nis a consistent estimator of the true cumulative incidence. We compute this conditional probability ˆyi for each horizon τi by\n14\n"}, {"page": 15, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nrenormalizing the model’s softmax outputs over the known outcomes:\nˆyi =\nP(occurred | τi)\nP(occurred | τi) + P(not occurred | τi)\nStep 2: Isotonic Calibration. As the independent estimates ˆyi are not guaranteed to be monotonic, we solve for the\ncalibrated sequence y∗\n1, . . . , y∗\nK for a set of K landmark times that minimizes the squared error subject to the monotonicity\nconstraint (Cumulative Incidence cannot decrease):\nmin\ny∗\nK\nX\ni=1\n(y∗\ni −ˆyi)2\nsubject to\ny∗\ni ≤y∗\ni+1\n∀i\nWe implement this using the Pool Adjacent Violators Algorithm (PAVA). This effectively projects the noisy LLM predictions\nonto the space of valid probability distribution functions, ensuring clinical interpretability without retraining the model.\n15\n"}, {"page": 16, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nC. Experimental Setup\nC.1. Dataset Statistics\nTable 1. Dataset Statistics: Patient Counts, Biomarkers, and Prediction Capabilities by Indication\nEvent Types Predicted\nIndication\nAbbr.\nPatients\nFor. Biomarkers\nSurv.\nProg.\nSwitch\nMet.\nUndetermined/multiple\nUnd.\n19,339\n90\n✓\n✓\nNon-Small Cell Lung Cancer\nNSCLC\n17,834\n74\n✓\n✓\n✓\n✓\nBreast Cancer\nBC\n13,901\n87\n✓\n✓\n✓\n✓\nColorectal Cancer\nCRC\n11,085\n80\n✓\n✓\n✓\nOvarian Cancer\nOC\n5,423\n82\n✓\n✓\n✓\nMetastatic Prostate Cancer\nmPC\n5,251\n78\n✓\n✓\nPancreatic Cancer\nPanc\n4,506\n69\n✓\n✓\nGastric / Esophageal Cancer\nGE\n3,826\n67\n✓\n✓\n✓\nEndometrial Cancer\nEC\n2,335\n78\n✓\n✓\nAdvanced Urothelial Carcinoma\naUC\n2,071\n62\n✓\n✓\n✓\nMelanoma\nMEL\n1,951\n72\n✓\n✓\n✓\n✓\nRenal Cell Carcinoma (Kidney)\nRCC\n1,385\n67\n✓\n✓\n✓\nHead and Neck Squamous Cell\nHNSCC\n934\n55\n✓\n✓\nSmall Cell Lung Cancer\nSCLC\n852\n53\n✓\n✓\n✓\nMultiple Myeloma\nMM\n564\n87\n✓\n✓\n✓\nAcute Myeloid Leukemia\nAML\n504\n67\n✓\n✓\nHepatocellular Carcinoma (Liver)\nHCC\n405\n50\n✓\n✓\n✓\nDiffuse Large B-Cell Lymphoma\nDLBCL\n350\n57\n✓\n✓\nChronic Lymphocytic Leukemia\nCLL\n337\n55\n✓\n✓\nFollicular Lymphoma\nFL\n201\n50\n✓\n✓\nNote: For. = Forecasted, Surv. = Survival, Prog. = Progression, Switch = Switching Treatments, Met. = Metastasis.\nC.1.1. DATA PREPROCESSING DETAILS\nOur preprocessing pipeline converts raw multi-modal data such as diagnoses, genetic tests, labs, etc., into a weekly\nlongitudinal format. Importantly, we encode the patient’s genetic information as text as well, noting somatic variants\nidentified from targeted sequencing, including details of the specific mutation.\nWe include tables on diagnoses, drug administrations, ECOG scores, progression, mortality, response, metastases, surgery,\nlabs, vitals, demographics, cancer-specific biomarkers, extracted genetic signatures, basic biomarkers, and paneled genetic\ndata. While the raw datasets are similar, each required specific adjustments for tables and columns. We aggregate all events\non a weekly level to align with the typical frequency of cancer therapy events and avoid over-representing acute hospital\nvisits. Numeric and categorical variables are aggregated using their mean and mode, respectively.\nTo reduce the issue of outliers in the forecasting task, we apply 3-sigma filtering to all target blood lab values during\npreprocessing (Pukelsheim, 1994). When encoding numerical values into strings, we limit the number of post-decimal digits\nto 2 to prevent single long numbers from dominating the string. Note that a small number of patients ( 311) that were present\nin multiple indication datasets were discarded from the test and validation sets.\nC.2. GDT Model & Training Details\nC.2.1. TRAINING DETAILS\nWe limit the total context length to 8000 tokens to manage GPU memory constraints, truncating the earliest visits if necessary\nwhile always preserving the first.\nFor training, we generate L number of splits per patient per line of therapy. We experimented with L ∈{1, 10} and observed\na lower validation loss with L = 10. This higher sampling rate per patient increases the total sample count to 2.49 million\nand provides the model with more diverse examples from each patient’s trajectory. In future work with more computational\nresources, higher sampling rates can also be explored. For outlier filtering, we also apply 3-sigma filtering, based on the\nper-variable statistics using the training dataset, following (Makarov et al., 2025).\nFor all smaller fine-tuning runs, we also explore using the cosine learning rate scheduler as well as a 10% warm up ratio,\ndetermined then based on the validation loss of the respective run.\nFor the fine-tuning, formally, let the full text sequence be x = (x1, . . . , xN), where xprompt = (x1, . . . , xk−1) and\n16\n"}, {"page": 17, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nTable 2. Patient demographics and visit statistics by indication. Drug visits is the number of visits where a drug was administered for a\ngiven patient.\nIndication\nBirth Year\nGender\nVisits\nDrug Visits\n(mean)\n(% Female)\n(mean)\n(mean)\nAML\n1954.1\n42.9\n132.6\n37.1\naUC\n1949.2\n28.8\n67.8\n21.2\nBC\n1958.5\n98.9\n94.7\n32.6\nCLL\n1951.9\n38.0\n116.9\n18.4\nCRC\n1957.8\n45.7\n92.8\n29.1\nDLBCL\n1955.4\n39.7\n89.0\n17.3\nEC\n1952.7\n100.0\n79.6\n20.6\nFL\n1955.4\n45.3\n98.6\n24.7\nGE\n1954.3\n26.7\n66.7\n20.1\nHCC\n1953.4\n24.9\n54.2\n9.9\nHNSCC\n1955.3\n21.0\n83.1\n24.0\nMEL\n1954.7\n34.6\n61.2\n17.5\nmPC\n1948.6\n0.0\n65.2\n12.0\nMM\n1953.3\n42.6\n145.9\n66.9\nNSCLC\n1950.8\n51.1\n62.3\n18.1\nOC\n1954.3\n100.0\n100.3\n29.1\nPanc\n1953.0\n45.5\n68.7\n18.6\nUndetermined\n1956.7\n50.1\n73.3\n19.2\nRCC\n1955.9\n28.5\n73.2\n20.1\nSCLC\n1952.5\n51.2\n68.3\n27.2\nxtarget = (xk, . . . , xN). The loss function is:\nL(θ) = −\nN\nX\ni=k\nlog qθ(xi | x1:i−1)\nwhere qθ is the LLM parameterized by θ.\nThe core training run was performed across 8 H100 GPUs, taking around 7 days, corresponding to 178 GPU hours, with full\nfine-tuning. The per-device batch size was 1, resulting in an effective batch size of 8.\nC.2.2. REASONING EXTENSION METHOD\nUsing fine-tuned LLMs as a prediction platform enables a variety of downstream tasks, including further fine-tuning to\nenable reasoning. Understanding the reasons behind a certain prediction is a critical task in biomedicine. In our example, we\nfocus on the largest single indication NSCLC. We chose to focus on forecasting the development of neutrophil counts in the\nperipheral blood owing to their high measurement frequency and variability. We demonstrate this capability by extracting\n3000 random patients from the NSCLC train dataset. We also extract 300 validation and test set patients. For all patients we\nthen generate the training data as outlined above. After dropping all patients without enough neutrophil observations, we\nobtained 2385 train, 235 validation and 244 test set patients.\nFor the reasoning, we use a setting, in which we first generate the prediction and then provide the potential reasoning. As in\nmost cases the literature to generate a truly logical step-by-step approach is limiting, we consider this step a hypothesis-\ngenerating approach. Additionally, in this setting, it is possible to provide a specific prediction and generate multiple possible\nexplanations, an important tool to provide different hypotheses for a patient’s response in clinical practice.\nWe first generated a reasoning dataset by prompting the Qwen3 Next 80B-A3B model to complete a reasoning chain given a\npatient’s history and the true targets. We then applied deterministic basic filtering (e.g. formatting).\nWe then trained GDT on this dataset for the initial predictions. Finally, to improve reasoning and prediction performance,\nwe then applied GRPO (Shao et al., 2024b) to the fine-tuned reasoning model. The GRPO reward function used only the\n17\n"}, {"page": 18, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nmean absolute error, with a lower value leading to a higher reward, and capped for errors above 20 units. β = 0, the learning\nrate was set to 10−6, using 8 generations, 0.1 warm up ratio, 1 epoch.\nC.3. Baselines & Metrics\nC.3.1. FORECASTING BASELINES\nWe compare GDT with standard time-series models on the blood biomarker forecasting task.\nTo ensure fair comparisons, we performed extensive post-processing of the data for the baseline models. For the missingness,\nwe performed linear interpolation together with forward and backward filling for the input time series, and forward filling\nfor the target variable. Since potentially other lab variables are relevant for the prediction, we include other historical time\nseries of all lab variables overlapping across all cancer types. This results in 74 lab variables for the real-world pan-cancer\ndataset and 43 variables in the clinical trials dataset. We use these variables as inputs in the multivariate capable models,\nmaking sure there is no temporal data leakage. We additionally provide a static feature vector with additional variables,\nusing their last observed value if needed, including age, gender, number of diagnoses, number of genetic events, therapy\nname, therapy number and key blood biomarkers. We apply a 30-week look-back window, and 13-week prediction window,\nensuring that the model sees over half a year of patient data. More historic blood lab value information further than 30\nweeks into the past is most likely not producing additional information relevant for blood biomarker prediction. As in GDT,\nwe also apply 3-sigma filtering to the data to remove outliers.\nEvaluating baselines on the full pan-cancer dataset was constrained by the heterogeneity of the data structure (variable\nlengths, missingness patterns) which required extensive preprocessing for non-LLM architectures. We therefore utilized\na random subsample, 2000 training patients for the baselines, resulting in 45,023 training samples with multiple lines of\ntherapies and variables per sample. Note, in the clinical trial tasks, all fine-tuned models used identical training datasets.\nTo ensure a fair comparison, we then used an identical number of training patients and set up on the clinical trial validation\ndata sets as for the GDT model, see Appendix D.1 for details. However, GDT still has improved performance.\nTiDE, Chronos and Chronos Bolt are all implemented in AutoGluon (Erickson et al., 2020). For TiDE, we explored both,\nincluding and excluding all helper columns and a hyperparameter search for the learning rate. TiDE also processes the static\nfeatures. Chronos and Chronos Bolt use only the target variable’s history as input, since the models cannot process multiple\ninput time series and we observed a lower validation loss when excluding the static features vector. We believe this is due\nto the implementation in AutoGluon, which requires an external regressor. For Chronos fine-tuning, we used the default\nlearning rate of 10−3 and performed early stopping.\nFor the clinical trial cold start task, where only baseline measurements were available, we constructed a synthetic history\nfor the time-series baselines (TiDE, Chronos) to satisfy their input window requirements. We backfilled the baseline value\nacross the 30-week look-back window. This provided the models with a valid input tensor representing a constant history.\nThis setup specifically evaluates the models’ ability to infer future trajectory dynamics based on static covariates and baseline\nmagnitude, rather than historical volatility.\nMetrics\nWe evaluate forecasting performance primarily using the Mean Absolute Scaled Error (MASE), with the copy\nforward as the naive predictor. MASE is particularly suitable for multi-modal clinical datasets where biomarker scales\ndiffer by orders of magnitude (e.g., neutrophils vs. albumin). We compute the metric by first aggregating the error across\nall patient samples for a given variable and horizon, and then taking the ratio against the aggregated copy forward (naive)\nbaseline error. A MASE < 1 indicates that the model provides superior forecasts to simply carrying forward the last known\nvalue. We formally define the aggregated MASE for a specific variable v as:\nMASEv =\nP\np∈P\nPJ\nj=1 |yp,j −ˆyp,j|\nP\np∈P\nPJ\nj=1 |yp,j −yp,last|\nwhere p indexes the patients, J is the number of forecasting horizons (up to 13 weeks in this case), yp,j is the true value, ˆyp,j\nis the predicted value, and yp,last is the last observed value before the split time t. We report the median of these MASEv\nscores across all variables and indications to ensure robustness against outliers common in real-world EHR data. We apply\n3-sigma capping to minimize the effect of outliers.\n18\n"}, {"page": 19, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nNote, we evaluate forecasting performance using a population-aggregated variant of the standard Mean Absolute Scaled\nError (MASE). Standard MASE (Hyndman & Koehler, 2006) typically scales the error of each individual time series by its\nown in-sample historical volatility. However, in the context of sparse and irregular clinical data, patient histories are often\nshort or exhibit periods of stability, leading to near-zero denominators and numerical instability when calculating per-patient\nratios.\nSince time-varying variables are the most relevant in clinical settings, we define the 30 most time varying variables, based\non the mean absolute percentage error of the copy-forward baseline.\nC.3.2. EVENTS BASELINES\nWe use the Random Survival Forest as a strong standard machine learning survival baseline focusing on the last observed\nvalues. For Random Survival Forest, we take the last observed values of critical patient parameters, representing a standard\nsurvival model. Specifically, it includes the following parameters as input: Indication, Gender, Events Until Split, Age,\nNumber of Previous Diagnoses, Number of Genetic Events, Values from ROPRO Constants (Becker et al., 2020), Therapy\nName, Therapy Line Number, Weight, Height, Oxygen Saturation, Systolic Blood Pressure, ECOG, Hemoglobin, Urea\nNitrogen, Platelets, Calcium, Glucose, Lymphocytes Percent, Alkaline Phosphatase, Total Protein, Alanine Aminotransferase,\nAlbumin, Total Bilirubin, Chloride, Monocytes Number, Eosinophils Percent, and Lactate Dehydrogenase. We use the\n‘scikit-survival‘ library, encoding all categorical variables using a one hot encoder and using default hyperparameters.\nTo compare with state of the art EHR foundation models, we employed CLMBR-T. Using CLMBR-T required extensive\npreprocessing of the data, as the vocabulary of the model is fixed. We transformed all diagnoses, medications, LOINC and\ndemographic data into the MEDS-OMOP format. We then used CLMBR-T through the femr package (Steinberg et al.,\n2024b) to generate the patient embeddings, and then trained a Cox’s proportional hazard’s model with elastic net penalty\nfrom scikit-survival. We applied a grid search with cross validation to find the optimal hyperparameters.\nFollowing the forecasting baselines, we use a 2000 patient subset for training on the pan-cancer dataset, and the full training\nset for the clinical trials.\nMetrics\nFor the landmark event tasks, we assess the model’s ability to correctly rank patients by risk using the Inverse\nProbability of Censoring Weighting (IPCW) Concordance Index (C-index)(Uno et al., 2011). The standard C-index is\nbiased in the presence of right-censored data; IPCW corrects for this by weighting patient pairs by the inverse probability\nof remaining in the study, estimated via the Kaplan-Meier estimator of the censoring distribution. Formally, for a pair of\npatients i and j, it measures the probability that the patient with the higher predicted risk score experiences the event first:\nC-index =\nP\ni,j I(Ti < Tj) · I( ˆRi > ˆRj) · Wij\nP\ni,j I(Ti < Tj) · Wij\nwhere T is the event time, ˆR is the predicted risk score (probability of event occurrence), and Wij are the censoring weights.\nA C-index of 0.5 implies random ranking, while 1.0 implies perfect discrimination. To further evaluate the reliability of the\nmodel’s confidence, we additionally compute the Brier Score, which measures the mean squared difference between the\npredicted probabilities and the actual outcomes (Graf et al., 1999). Lower Brier scores indicate better calibration. The Brier\nScore results on the adjusted monotonic versions are detailed in Appendix B.2.1.\nC.4. Evaluation Inference Details\nFor the forecasting inference on the pan-cancer test set, we set L = 3, ensuring that over 90% of variables are evaluated in\nevery indication, whilst still keeping the computational costs low.\nNote, we observed that GDT outputs consistently, achieving a 0% formatting and syntax errors across all indications in the\nreal-world dataset.\nC.4.1. EVALUATED VARIABLES (LOINC CODES)\n19\n"}, {"page": 20, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nTable 3. Evaluated forecasting variables by LOINC code across indications.\nLOINC\nAML\nBC\nCLL\nCRC\nDLBCL\nEC\nFL\nGE\nHCC\nHNSCC\nMEL\nMM\nNSCLC\nOC\nUnd.\nRCC\nSCLC\nUndet.\naUC\nmPC\n10334-1\n✓\n✓\n11051-0\n✓\n13992-3\n✓\n14804-9\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n14979-9\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n15152-2\n✓\n✓\n✓\n✓\n1742-6\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n1751-7\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n17817-8\n✓\n17842-6\n✓\n✓\n17861-6\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n18262-6\n✓\n✓\n✓\n✓\n✓\n✓\n1834-1\n✓\n19023-1\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n19123-9\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n1920-8\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n1952-1\n✓\n✓\n1963-8\n✓\n✓\n✓\n✓\n1968-7\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n1971-1\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n1975-2\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n1988-5\n✓\n✓\n✓\n✓\n✓\n1994-3\n✓\n2028-9\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n2039-6\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n20482-6\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n20570-8\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n2075-0\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n2085-9\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n2093-3\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n2141-0\n✓\n2143-6\n✓\n2160-0\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n2161-8\n✓\n✓\n✓\n✓\n2162-6\n✓\n2276-4\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n2324-2\n✓\n✓\n✓\n✓\n✓\n2345-7\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n24108-3\n✓\n✓\n✓\n✓\n✓\n✓\n2458-8\n✓\n✓\n✓\n✓\n✓\n2465-3\n✓\n✓\n✓\n✓\n2472-9\n✓\n✓\n✓\n2532-0\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n2571-8\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n26444-0\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n26449-9\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n26450-7\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n26453-1\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n26464-8\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n26474-7\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n26478-8\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n26484-6\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n26485-3\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n26499-4\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n26505-8\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n26507-4\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n26508-2\n✓\n✓\nContinued on next page\n20\n"}, {"page": 21, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nTable 3 – continued from previous page\nVariable\nAML\nBC\nCLL\nCRC\nDLBCL\nEC\nFL\nGE\nHCC\nHNSCC\nMEL\nMM\nNSCLC\nOC\nPanc\nRCC\nSCLC\nUndet.\naUC\nmPC\n26511-6\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n26515-7\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n2823-3\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n2857-1\n✓\n✓\n2862-1\n✓\n✓\n✓\n2885-2\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n2888-6\n✓\n✓\n✓\n✓\n✓\n✓\n2889-4\n✓\n2947-0\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n2951-2\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n2986-8\n✓\n3016-3\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n30180-4\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n3024-7\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n3026-2\n✓\n✓\n✓\n✓\n✓\n✓\n30376-8\n✓\n30394-1\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n30395-8\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n30451-9\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n30522-7\n✓\n✓\n3084-1\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n3094-0\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n33358-3\n✓\n33558-8\n✓\n✓\n✓\n✓\n33944-0\n✓\n✓\n35591-7\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n36916-5\n✓\n38176-4\n✓\n38483-4\n✓\n✓\n✓\n✓\n38875-1\n✓\n✓\n✓\n42483-8\n✓\n4537-7\n✓\n4544-3\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n4548-4\n✓\n✓\n48642-3\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n48643-1\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n53962-7\n✓\n5902-2\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n5905-5\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n6298-4\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n6690-2\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n6768-6\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n6875-9\n✓\n69405-9\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n704-7\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n705-4\n✓\n✓\n706-2\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n707-0\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n712-0\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n714-6\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n718-7\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n731-0\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n732-8\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n736-9\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n737-7\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n742-7\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n743-5\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n744-3\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\nContinued on next page\n21\n"}, {"page": 22, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nTable 3 – continued from previous page\nVariable\nAML\nBC\nCLL\nCRC\nDLBCL\nEC\nFL\nGE\nHCC\nHNSCC\nMEL\nMM\nNSCLC\nOC\nPanc\nRCC\nSCLC\nUndet.\naUC\nmPC\n751-8\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n753-4\n✓\n764-1\n✓\n✓\n✓\n✓\n✓\n769-0\n✓\n✓\n✓\n✓\n770-8\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n77146-9\n✓\n777-3\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n789-8\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n98979-8\n✓\n✓\n✓\n✓\n✓\n✓\n22\n"}, {"page": 23, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nD. Extended Results\nD.1. Sample Size Ablation (GDT vs Baselines on 2k Patients)\nTo ensure a fair comparison, we run GDT also trained on the identical samples as the baselines, seeing that it outperforms\nthe models, yet is worse than the model trained on the full dataset, seen in Figure 7.\n0.8\n0.9\n1.0\n1.1\n1.2\n1.3\nGDT − Full\nGDT − 2k Patients\nTiDE (FT−Multi)\nTiDE (FT−Uni)\nChronos (FT)\nChronos Bolt (ZS)\nCopy Fwd (Naive)\nChronos (ZS)\nLlama 3.1 (ZS)\nMASE\nFigure 7. GDT trained on the same 2,000-patient subset as the baselines still outperforms them, though it underperforms the full\nmodel. Comparison of MASE for forecasting blood variables. The reduced-data GDT (Light Blue) surpasses TiDE and Chronos but does\nnot match the performance of the GDT model trained on the full pan-cancer dataset (Teal), highlighting the benefits of scale. ZS denotes\nzero-shot, FT is fine tuned, Uni is univariate input, Multi is multivariate input.\n23\n"}, {"page": 24, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nD.2. Forecasting Full Results (RWD)\nWe present the forecasting results across all variables in Figure 8.\nMultiple Myeloma\nFollicular Lymphoma\nAML\nDLBCL\nCLL\nMelanoma\nOvarian\nNSCLC\nBreast\nPancreatic\nEndometrial\nHead & Neck\nCRC\nAdvanced Urothelial\nMetastatic Prostate\nGastric/ Esophageal\nRCC\nSCLC\nHCC\nUndetermined\nMyeloid\nLymphoid\nMel.\nCarcinomas\nUndeter.\n0.88 (0.22)\n1.03 (0.23)\n1.02 (0.22)\n1.00 (0.07)\n1.00 (0.19)\n1.00 (0.00)\n1.01 (0.09)\n1.11 (0.26)\n0.88 (0.22)\n0.98 (0.20)\n1.01 (0.26)\n0.98 (0.17)\n0.96 (0.19)\n1.00 (0.00)\n1.00 (0.16)\n1.08 (0.25)\n0.88 (0.31)\n0.94 (0.21)\n0.97 (0.17)\n0.97 (0.15)\n0.98 (0.16)\n1.00 (0.00)\n0.98 (0.17)\n1.09 (0.25)\n0.92 (0.22)\n1.01 (0.31)\n1.01 (0.33)\n1.00 (0.15)\n1.02 (0.21)\n1.00 (0.00)\n1.00 (0.13)\n1.10 (0.24)\n0.90 (0.22)\n0.97 (0.25)\n0.97 (0.16)\n0.97 (0.13)\n0.96 (0.22)\n1.00 (0.00)\n1.00 (0.10)\n1.09 (0.26)\n0.90 (0.13)\n0.96 (0.12)\n0.97 (0.14)\n0.99 (0.06)\n1.00 (0.09)\n1.00 (0.00)\n1.01 (0.07)\n1.10 (0.25)\n0.86 (0.16)\n0.94 (0.11)\n0.95 (0.13)\n0.96 (0.08)\n1.00 (0.10)\n1.00 (0.00)\n1.00 (0.08)\n1.14 (0.26)\n0.84 (0.17)\n0.96 (0.13)\n0.97 (0.15)\n0.98 (0.08)\n0.97 (0.13)\n1.00 (0.00)\n1.00 (0.07)\n1.10 (0.18)\n0.85 (0.16)\n0.97 (0.16)\n0.97 (0.13)\n0.97 (0.07)\n0.99 (0.10)\n1.00 (0.00)\n1.00 (0.06)\n1.08 (0.23)\n0.86 (0.14)\n0.96 (0.16)\n0.97 (0.16)\n0.96 (0.09)\n0.95 (0.17)\n1.00 (0.00)\n0.99 (0.10)\n1.14 (0.23)\n0.85 (0.18)\n0.96 (0.12)\n0.95 (0.12)\n0.97 (0.09)\n0.99 (0.10)\n1.00 (0.00)\n1.01 (0.07)\n1.11 (0.25)\n0.84 (0.16)\n0.97 (0.19)\n0.97 (0.13)\n0.96 (0.10)\n0.95 (0.19)\n1.00 (0.00)\n0.97 (0.10)\n1.13 (0.29)\n0.86 (0.15)\n0.96 (0.17)\n0.96 (0.14)\n0.97 (0.08)\n0.98 (0.11)\n1.00 (0.00)\n1.00 (0.06)\n1.13 (0.25)\n0.86 (0.16)\n0.96 (0.13)\n0.97 (0.16)\n0.98 (0.08)\n0.98 (0.10)\n1.00 (0.00)\n1.00 (0.08)\n1.09 (0.19)\n0.86 (0.12)\n0.98 (0.17)\n0.98 (0.16)\n0.98 (0.07)\n1.01 (0.09)\n1.00 (0.00)\n1.02 (0.07)\n1.10 (0.19)\n0.88 (0.18)\n0.96 (0.13)\n0.97 (0.13)\n0.96 (0.08)\n0.99 (0.07)\n1.00 (0.00)\n1.00 (0.08)\n1.09 (0.18)\n0.87 (0.20)\n0.97 (0.12)\n1.00 (0.14)\n0.99 (0.09)\n1.01 (0.10)\n1.00 (0.00)\n1.01 (0.08)\n1.11 (0.25)\n0.87 (0.23)\n0.99 (0.19)\n0.96 (0.20)\n0.98 (0.07)\n0.99 (0.12)\n1.00 (0.00)\n1.00 (0.13)\n1.10 (0.17)\n0.90 (0.20)\n0.98 (0.22)\n0.97 (0.17)\n1.00 (0.09)\n1.02 (0.15)\n1.00 (0.00)\n1.00 (0.09)\n1.06 (0.33)\n0.87 (0.18)\n0.99 (0.22)\n0.97 (0.15)\n0.97 (0.07)\n0.98 (0.08)\n1.00 (0.00)\n1.00 (0.08)\n1.10 (0.22)\n0.85\n0.90\n0.95\n1.00\n1.05\n1.10\nMedian MASE\nGDT\nTiDE (FT-Multi)\nTiDE (FT-Uni)\nChronos (FT-Uni)\nChronos Bolt (ZS-Uni)\nCopy Fwd (Naive)\nChronos (ZS-Uni)\nLlama 3.1 (ZS)\n0.8\n1.0\n1.2\n(←) MASE\n***\nFigure 8. Comprehensive blood biomarker forecasting results across all variables and indications. The heatmap displays the Median\nMASE for GDT versus baselines across all 20 cancer types. GDT consistently achieves lower error rates across both myeloid/lymphoid\nand solid tumor indications compared to standard time-series models and zero-shot LLMs. ZS denotes zero-shot, FT is fine tuned, Uni is\nunivariate input, Multi is multivariate input.\nD.3. Clinical Trial Task Setup\nTo construct the dataset, we prioritized the largest combination of clinical trials featuring overlapping treatment regimens.\nThe two largest trials were designated as the training set for the experimental settings with fine-tuning: OAK (n = 1126;\ncomparing atezolizumab vs. docetaxel) and IMpower131 (n = 949; comparing atezolizumab + carboplatin + paclitaxel vs.\natezolizumab + carboplatin + nab-paclitaxel vs. carboplatin + nab-paclitaxel). For internal validation and hyperparameter\ntuning, we employed a random 20% holdout subset of these training trials. To rigorously evaluate the model’s ability to\ngeneralize across different patient populations and protocols, we adopted a leave-trial-out testing strategy rather than a\nrandom pooled split. We utilized the two largest trials (OAK, IMpower131) for training to maximize data diversity during\n24\n"}, {"page": 25, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nlearning, while reserving two distinct, independent trials (POPLAR, IMpower130) strictly for external testing: POPLAR\n(n = 263; atezolizumab vs. docetaxel) and IMpower130 (n = 680; atezolizumab + carboplatin + nab-paclitaxel vs.\ncarboplatin + nab-paclitaxel). We used 17 blood biomarkers for forecasting, as well as survival and progression for event\nevaluation.\nD.4. Further Reasoning Results\nD.4.1. REASONING DETAILS\nTo validate the clinical semantic alignment of the generated rationales, we employed a keyword-based concept analysis\nfocusing on four distinct therapy regimens found in the NSCLC cohort: Chemotherapy, Immunotherapy (IO), Targeted\nTherapy, and Chemo-IO combinations. We manually curated a dictionary of inclusion and exclusion terms for specific clinical\nconcepts (e.g., ‘Marrow Suppression’, ‘Immune Activation’, ‘EGFR mutation’). Inclusion terms captured synonymous\nphrases and specific biological mechanisms, while exclusion terms were strictly applied to filter out negated contexts or\nunrelated mentions to ensure false positives were minimized.\nFor each concept within a therapy group, we computed two metrics:\n• Frequency: The percentage of generated reasoning chains within a specific therapy group that contained at least one\nverified instance of the concept.\n• Relative Importance: A normalized measure of concept specificity calculated row-wise. For a given concept, this is\ndefined as its frequency in the specific therapy group divided by the maximum frequency of that concept observed\nacross all four therapy groups. This scaling ensures that the therapy group with the strongest association for a given\nconcept is assigned a value of 1.0, highlighting relative specificity regardless of absolute frequency.\nD.4.2. REASONING EMBEDDINGS VISUALIZATION\nTo assess the reasoning chains, we extract them from the test set, and then embed them using Qwen3-8B. Finally, we\nperform UMAP and two-dimensional display of the embedded data.\nb)\n11.7\n12.0\n12.3\n10.4\n10.8\n11.2\nMAE\n10\n20\n30\na)\n<prediction>\nTask 1 is forecasting:\n3 weeks later, the patient visited...\n     neutrophils - 26499-4 is 6.72.\n...\n</prediction>\n<thinking>\n1. Patient summary: The patient is a \n66-year-old female with advanced ...\n2. Key factors: \n    - Durvalumab therapy: as an im-\n      mune checkpoint inhibotr, ...\n    - Recent chemotherapy washout: ...\n3. Mechanistic analysis: The \npatient’s neutrophil trajectory is ...\n4. Confounding factors:  \n    - Age related marrow reserve: At ...\n</thinking>\n<prognosis_summary>\nNeutrophil counts are expected to \ngradually decline from the current ...\n</prognosis_summary>\nc)\nUMAP 1\nUMAP 1\nUMAP 2\nUMAP 2\nFigure 9. GDT can be extended to provide reasoning, exemplified here in NSCLC neutrophil forecasting. a) Example of a generated\nprediction and reasoning chain. b) UMAP visualization of reasoning chain embeddings, colored by the top 12 most common categories,\nshows structural alignment with clinical factors such as therapy types. c) Zoomed view of the patient with the highest MAE on the test set;\nthe centroids (+) and clustering indicate that generated reasoning chains are consistent across multiple runs.\n25\n"}, {"page": 26, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nD.4.3. EXAMPLE REASONING CHAIN\n<prediction>\nTask 1 is forecasting:\n3 weeks later, the patient visited and experienced the following:\nneutrophils - 26499-4 is 3.4.\n2 weeks later, the patient visited and experienced the following:\nneutrophils - 26499-4 is 4.6.\n2 weeks later, the patient visited and experienced the following:\nneutrophils - 26499-4 is 4.8.\n2 weeks later, the patient visited and experienced the following:\nneutrophils - 26499-4 is 4.6.\n2 weeks later, the patient visited and experienced the following:\nneutrophils - 26499-4 is 3.9.\n</prediction>\n<thinking>\n1. **Patient Summary:** The patient is a 52-year-old male with metastatic NSCLC,\npreviously diagnosed with prostate cancer, currently on nivolumab (first-line\nimmune checkpoint inhibitor) as his most recent therapy. He has progressive\ndisease with bone and liver metastases, confirmed PD-L1 negativity on both\ntumor and immune cells, and a complex genomic profile including TP53, STK11,\nSMARCA4, and CDKN2A mutations, with MSI-stable status and no actionable EGFR or\nALK alterations. Recent labs show stable renal function, mild anemia, and\nfluctuating but generally preserved neutrophil counts (last value: 4.4 x\n10^9/L). ECOG has improved from 2 to 0, indicating clinical stabilization. No\nactive infection or acute inflammatory events are documented. The patient is\nnot receiving G-CSF or other myeloid growth factors.\n2. **Key Predictive Factors:**\n- **Nivolumab monotherapy:** Immune checkpoint inhibitors like nivolumab rarely\ncause severe neutropenia but can induce immune-mediated bone marrow\nsuppression or transient cytopenias via T-cell activation against\nhematopoietic precursors. Neutrophil counts typically remain stable or show\nmild fluctuations.\n- **Recent partial response (PR) to therapy:** The documented PR suggests\neffective tumor control, which reduces tumor-derived cytokines (e.g., IL-6,\nG-CSF) that can stimulate neutrophil production. This may lead to a gradual\nnormalization of neutrophil counts toward baseline.\n- **Persistent bone metastases:** Bone marrow infiltration by metastatic NSCLC\nmay impair hematopoietic reserve, particularly affecting granulopoiesis.\nHowever, the absence of severe cytopenias (e.g., hemoglobin >13, platelets\n>300) suggests compensatory hematopoiesis is still functional.\n- **Genomic profile (TP53, STK11, SMARCA4 mutations):** These mutations are\nassociated with genomic instability and may impair DNA repair in\nhematopoietic stem cells, potentially increasing susceptibility to\nsubclinical marrow stress or delayed recovery after minor insults.\n- **Trend of neutrophil stability over prior visits:** Neutrophils have\nfluctuated between 3.5-5.2 over the last 5 visits (spanning 10 weeks), with\nno consistent downward trend. This suggests a homeostatic equilibrium under\ncurrent conditions.\n3. **Mechanistic Analysis:** The neutrophil trajectory is governed by a balance\nbetween immune-mediated stress and compensatory hematopoiesis. Nivolumab does\nnot directly suppress neutrophil production but may induce low-grade immune\nactivation that occasionally triggers transient neutrophil consumption or\nredistribution. The partial response reduces tumor-derived inflammatory signals\nthat previously stimulated neutrophil release, leading to a gradual\n26\n"}, {"page": 27, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nnormalization of baseline neutrophil production. However, the presence of bone\nmetastases limits the marrow’s capacity for robust rebound, preventing\novershoot. The TP53/STK11/SMARCA4 mutations may slightly delay recovery from\nminor stressors (e.g., subclinical inflammation or transient immune\nactivation), explaining why neutrophil counts do not fully return to\npre-treatment levels. The observed fluctuations (e.g., 4.4 -> 3.4 -> 4.6 -> 4.8\n-> 4.6 -> 3.9) reflect this dynamic equilibrium: transient immune activation\n(possibly from tumor cell death or inflammatory signaling from the tumor\nmicroenvironment) causes a slight dip, followed by compensatory granulopoiesis.\nThe 2-week intervals between visits allow for partial recovery before the next\nimmune-mediated perturbation, resulting in a cyclical pattern without sustained\ndecline. The absence of G-CSF or infection means no external stimulus for rapid\nrise or crash.\n4. **Confounding Factors:** Subclinical infection (e.g., from oral soft tissue\ndisease or lymph node enlargement) could trigger neutrophilia, but no fever or\nelevated CRP/ESR is documented. Advanced age (52) is not a major risk factor\nfor neutropenia in this context, but reduced marrow reserve due to prior cancer\nand metastases may blunt recovery if stressors accumulate.\n</thinking>\n<prognosis_summary>\nNeutrophil counts are expected to remain within the low-normal to normal range with\nminor fluctuations, reflecting a dynamic equilibrium between immune-mediated\nstress and compensatory hematopoiesis, with no evidence of progressive\nmyelosuppression. The primary clinical risk is transient neutropenia without\nfebrile episodes, unlikely to require treatment interruption.\n</prognosis_summary>\nD.5. Single Indication Training vs Pan-Cancer\nTo understand the contribution of the pan-cancer training, we performed an ablation study where we trained GDT on the\nthree cancer types with the fewest patients using only cancer indication data. We focus on the fewest patient counts, as they\nare most likely to benefit from the pan-cancer capabilities and transfer learning.\nIn Figure 10, we see that the pan-cancer model consistently improves performance over the single indication models, albeit\nat a small level.\n0.934\n0.954\n0.879\n0.902\n0.897\n0.913\nCLL\nDLBCL\nFollicular Lymphoma\n0.85\n0.90\n0.95\n1.00\nMedian MASE (Lower is Better)\nComparing the median MASE across 3 key indications.\nBlue represents the Pretrained Pan−Cancer Model.\nRed represents the Single−Indication Model.\nPan−Cancer vs. Single Indication\nFigure 10. Pan-cancer training consistently improves performance over single-indication models. Comparison of Median MASE for\nthe three cancer indications with the fewest patients (< 500). The Pan-cancer GDT model (Blue) achieves lower error rates than models\ntrained solely on the specific indication data (Red), demonstrating the benefits of transfer learning in low-data regimes.\n27\n"}, {"page": 28, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nD.6. Assessing Longitudinal Input Length on Performance\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n0\n4\n26\n52\nAll\nWeeks of Patient History\nIPCW C-Index\nGDT\nRSF\nInput Length vs Performance\n(Survival @ 52 weeks)\nFigure 11. Longer historic patient trajectories improve GDT, implying that clinical trials could benefit from additional information\non patient history. Here, we compare Random Survival Forest (RSF) with GDT on NSCLC for 52-week survival prediction on IPCW\nC-index. We select patients from the test set, patients with at least 52 weeks of input history, then split only at the start of therapy, and\nsystematically cut the input history to the specific input length. 0-4 weeks can be compared to the data currently commonly gathered in\nclinical trials. We see that more input history improves model performance, implying that clinical trials could benefit from longer patient\ntimelines. We additionally see that GDT outperforms RSF consistently, which focuses on last observed values only.\nD.7. Detailed Clinical Trial Forecasting Results\nWe provide the comprehensive breakdown of forecasting performance across all models for the clinical trial validation. On\nthe trial POPLAR, the performance ranking by median MASE is as follows: GDT SFT (0.883, IQR 0.09), TiDE fine-tuned\nunivariate (0.936, IQR 0.07), GDT zero-shot (0.947, IQR 0.121), Chronos fine-tuned (0.956, IQR 0.054), TiDE fine-tuned\nmultivariate (0.993, IQR 0.131), Chronos zero-shot (0.998, IQR 0.001), Copy Forward (1.0), Chronos Bolt zero-shot (1.0),\nand Llama 3.1 (1.164, IQR 0.175).\nFor trial IMpower130, the ranking follows a similar pattern: GDT SFT (0.754, IQR 0.385), TiDE fine-tuned univariate\n(0.840, IQR 0.119), GDT zero-shot (0.874, IQR 0.163), Chronos fine-tuned (0.885, IQR 0.075), TiDE fine-tuned multivariate\n(0.853, IQR 0.208), Chronos zero-shot (0.998, IQR 0.001), Copy Forward (1.0), Chronos Bolt zero-shot (1.0), and Llama\n3.1 (1.126, IQR 0.156).\nWe observe that the TiDE univariate model generally outperforms the multivariate equivalent in this setting. We hypothesize\nthat the reason is the focus on baseline information, limiting the correlations the multivariate model can capture, thereby\nallowing the univariate model to converge more easily.\n28\n"}, {"page": 29, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nD.8. Isotonic Regression Results\nD.8.1. PAN-CANCER REAL-WORLD DATA\nIn the pan-cancer real-world data results, we see an overall slight improvement when including isotonic regression (Figure\n12). The Brier score shows an increased performance over the base model. However, further work is required for well\ncalibrated probabilities, as seen in Figure 13.\nDeath\nProgression\nLine of Therapy\nMetastasis\n8\n26\n52\n104\n8\n26\n52\n104\n8\n26\n52\n104\n8\n26\n52\n104\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nPrediction Week\nIPCW Concordance Index\nGDT (Isotonic)\nGDT (ZS)\nRSF\nCLMBR−T\nLlama 3.1 (ZS)\nMajority\nFigure 12. Isotonic regression post-processing maintains robust ranking performance on pan-cancer real-world data. The plots\nshow the IPCW C-Index for Survival and Disease Progression. The performance of the isotonic version (Teal) is highly similar to the\noriginal GDT outputs (Light Blue), indicating that enforcing monotonicity does not degrade the model’s discriminative ability.\nDeath\nProgression\nLine of Therapy\nMetastasis\n8\n26\n52\n104\n8\n26\n52\n104\n8\n26\n52\n104\n8\n26\n52\n104\n0.1\n0.2\n0.3\n0.4\n0.2\n0.3\n0.4\n0.5\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.2\n0.4\n0.6\nPrediction Week\nBrier Score\nRSF\nCLMBR−T\nGDT (Isotonic)\nLlama 3.1 (ZS)\nMajority\nGDT (ZS)\nFigure 13. Brier score analysis shows improvement over the base model with isotonic regression but indicates a need for further\ncalibration. Lower Brier scores indicate better calibration. While isotonic regression improves the score compared to the raw GDT\noutput, particularly for Line of Therapy and Death, the results suggest that further work is needed to generate well-calibrated probabilities.\n29\n"}, {"page": 30, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nD.8.2. CLINICAL TRIAL RESULTS\nGO28753\nSurvival\nGO28753\nDisease Progression\nGO29537\nSurvival\nGO29537\nDisease Progression\n8\n26\n52\n104\n8\n26\n52\n104\n8\n26\n52\n104\n8\n26\n52\n104\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nPrediction Week\nIPCW Concordance Index\nGDT (SFT) + Isotonic\nGDT (SFT)\nGDT (ZS)\nGDT (ZS) + Isotonic\nRSF\nCLMBR−T\nLlama 3.1 (ZS)\nMajority\nFigure 14. Isotonic regression has minimal impact on clinical trial C-Index as GDT predictions are largely naturally monotonic.\nResults for trials POPLAR (GO28753) and IMpower130 (GO29537) show that the isotonic regression curves overlap significantly with\nthe standard GDT curves, as only a small fraction (0.37%) of the zero-shot samples violated monotonicity.\nGO28753\nSurvival\nGO28753\nDisease Progression\nGO29537\nSurvival\nGO29537\nDisease Progression\n8\n26\n52\n104\n8\n26\n52\n104\n8\n26\n52\n104\n8\n26\n52\n104\n0.1\n0.2\n0.3\n0.4\n0.5\nPrediction Week\nBrier Score\nRSF\nCLMBR−T\nGDT (SFT) + Isotonic\nGDT (ZS) + Isotonic\nGDT (SFT)\nLlama 3.1 (ZS)\nMajority\nGDT (ZS)\nFigure 15. Brier scores for clinical trials highlight the need for improved probability calibration despite strong ranking performance.\nComparing the Brier scores across models on trials POPLAR (GO28753) and IMpower130 (GO29537) reveals that while GDT ranks\npatients effectively (high C-Index), the absolute probability estimates require refinement to minimize the Brier score.\n30\n"}, {"page": 31, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nD.9. Example Forecast Predictions\n0\n2\n4\n6\n8\n10\n12\n0\n250\n500\n750\n1000\n1250\n1500\nValue\nMultiple Myeloma\n(immunoglobulin light chains lambda free - 33944-0)\nIndividual Prediction\nObserved\nMean Pred\nLast Observed Input Value\n0\n2\n4\n6\n8\n10\n12\n0.00\n0.05\n0.10\n0.15\n0.20\nRenal Cell Carcinoma\n(basophils - 26444-0)\n0\n2\n4\n6\n8\n10\n12\n0\n5\n10\n15\n20\nBreast Cancer\n(neutrophils - 26499-4)\n0\n2\n4\n6\n8\n10\n12\n0\n250\n500\n750\n1000\n1250\n1500\nColorectal Cancer\n(carcinoembryonic ag - 2039-6)\n0\n2\n4\n6\n8\n10\n12\n0\n10\n20\n30\n40\nValue\nOvarian Cancer\n(leukocytes - 26464-8)\n0\n2\n4\n6\n8\n10\n12\n0.0\n2.5\n5.0\n7.5\n10.0\n12.5\n15.0\nEndometrial Cancer\n(leukocytes - 6690-2)\n0\n2\n4\n6\n8\n10\n12\n0\n10\n20\n30\nPan-Tumor\n(neutrophils - 751-8)\n0\n2\n4\n6\n8\n10\n12\n0\n2\n4\n6\nMetastatic Prostate\n(erythrocytes - 26453-1)\n0\n2\n4\n6\n8\n10\n12\n0\n2\n4\n6\n8\nValue\nAdv. Urothelial Carcinoma\n(eosinophils per 100 leukocytes - 26450-7)\n0\n2\n4\n6\n8\n10\n12\n0\n5\n10\n15\n20\nChronic Lymphocytic\nLeukemia\n(monocytes per 100 leukocytes - 26485-3)\n0\n2\n4\n6\n8\n10\n12\n0.0\n0.1\n0.2\n0.3\n0.4\nSmall Cell Lung Cancer\n(eosinophils - 26449-9)\n0\n2\n4\n6\n8\n10\n12\n0\n20\n40\n60\nHead & Neck Cancer\n(aspartate aminotransferase - 1920-8)\n0\n2\n4\n6\n8\n10\n12\n0\n5\n10\n15\n20\n25\nValue\nPancreatic Cancer\n(monocytes - 26484-6)\n0\n2\n4\n6\n8\n10\n12\n0\n25\n50\n75\n100\n125\n150\nDiffuse Large B-Cell\nLymphoma\n(alanine aminotransferase - 1742-6)\n0\n2\n4\n6\n8\n10\n12\n0.00\n0.25\n0.50\n0.75\n1.00\n1.25\n1.50\nHepatocellular Carcinoma\n(basophils per 100 leukocytes - 30180-4)\n0\n2\n4\n6\n8\n10\n12\n0\n20\n40\n60\n80\n100\nAcute Myeloid Leukemia\n(lymphocytes per 100 leukocytes - 26478-8)\n0\n2\n4\n6\n8\n10\n12\nWeek\n0.000\n0.025\n0.050\n0.075\n0.100\n0.125\n0.150\nValue\nMelanoma\n(basophils - 704-7)\n0\n2\n4\n6\n8\n10\n12\nWeek\n0\n2\n4\n6\n8\nNon-Small Cell Lung\nCancer\n(lymphocytes - 26474-7)\n0\n2\n4\n6\n8\n10\n12\nWeek\n0\n5\n10\n15\n20\nGastroesophageal Cancer\n(granulocytes - 30394-1)\n0\n2\n4\n6\n8\n10\n12\nWeek\n0\n10\n20\n30\n40\n50\n60\nFollicular Lymphoma\n(lymphocytes per 100 leukocytes - 736-9)\nFigure 16. Example blood biomarker forecasts by GDT. The longitudinal trajectory of different blood-based markers are shown for\na variety of tumor indications. Measured values are displayed in grey and predicted values in blue. Note that in some cases where the\naverage prediction is incorrect, individual predictions sometimes are still able to capture the shape or values, such as the first spike in\npancreatic cancer, or the dip in hepatocellular carcinoma. However, in other cases GDT is not able to capture large variability in the\nresults, such as an initial strong increase in the alanine aminotransferase values in DLBCL.\n31\n"}, {"page": 32, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nD.10. Synthetic Patient Example\nUsing a synthetic patient to ensure data privacy compliance.\nInput:\nThe following is a patient, starting with the demographic data, following visit by\nvisit everything that the patient experienced. All lab codes refer to LOINC\ncodes.\nStarting with demographic data:\nPatient gender is male,\nage of patient is 77 years,\n...\nOn the first visit, the patient experienced the following:\nadvanced cancer diagnosis is non small cell lung cancer,\ninitial cancer diagnosis is non small cell lung cancer.\nmetastasis Pleura is diagnosed.\n2 weeks later, the patient visited and experienced the following:\n<genetic>\n...\nTissue: pleura Gene: CHEK2 short variant: frameshift parameters: likely truncation,\n...\n</genetic>.\n1 weeks later, the patient visited and experienced the following:\nECOG is 2,\nalanine aminotransferase - 1742-6 is 9,\nalbumin - 1751-7 is 39,\ncalcium - 17861-6 is 8.9,\naspartate aminotransferase - 1920-8 is 20,\nbilirubin - 1975-2 is 0.3,\ncarbon dioxide - 2028-9 is 25,\nneutrophils per 100 leukocytes - 26511-6 is 72,\nplatelets - 26515-7 is 419,\n...\npotassium - 2823-3 is 4.7,\nprotein - 2885-2 is 61,\nsodium - 2951-2 is 132,\nbasophils per 100 leukocytes - 30180-4 is 0.3,\n...\n1 weeks later, the patient visited and experienced the following:\nOther fatigue is diagnosed,\nEncounter for antineoplastic immunotherapy - Z51.12 is diagnosed,\ndrug pembrolizumab is 200,\nECOG is 1,\nalanine aminotransferase - 1742-6 is 9,\nalbumin - 1751-7 is 42,\ncalcium - 17861-6 is 9.4,\naspartate aminotransferase - 1920-8 is 21,\nneutrophils - 26499-4 is 5.9,\nneutrophils per 100 leukocytes - 26511-6 is 73.2,\nplatelets - 26515-7 is 243,\n...\nthyroxine - 3026-2 is 6.7,\nurea nitrogen - 3094-0 is 10,\nthyroxine free index - 32215-6 is 2,\n32\n"}, {"page": 33, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nline number is 1,\nbody height is 180.34,\nbody weight is 63.45752,\noxygen saturation in arterial blood by pulse oximetry is 98.\n...\nHere we repeat the last observed values of each genetic event in the input data:\n0 weeks later, the patient visited and experienced the following:\n...\nTissue: pleura Gene: CHEK2 short variant: frameshift parameters: likely truncation,\n...\n</genetic>.\n...\nThe most recent line of therapy:\nPembrolizumab\nThe last values of the variables in the input data are:\nhematocrit - 20570-8 was 33.6\ncreatinine - 2160-0 was 0.6\nplatelets - 26515-7 was 257\nYou will now have multiple tasks to complete. Please answer for each task in the\nsame order as they are presented. Before every response state the task nr, e.g.\n’Task 2:’.\nTask 1 is forecasting:\nYour task is to predict the future values of the following variables for each\ncumulative week starting from the last visit:\nhematocrit - 20570-8 the future weeks 1, 4, 7, 10\ncreatinine - 2160-0 the future weeks 1, 4, 7, 10\nplatelets - 26515-7 the future weeks 1, 4, 7, 10\nTask 2 is time to event prediction:\nYour task is to predict whether the following event was censored 1 weeks from the\nlast clinical visit and whether the event occurred or not: death.\nPlease provide your prediction in the following format: ’Here is the prediction:\nthe event (<name of event>) was [not] censored and [did not occur]/[occurred].’\nOutput:\nTask 1 is forecasting:\n1 weeks later, the patient visited and experienced the following:\nhematocrit - 20570-8 is 36.1,\ncreatinine - 2160-0 is 0.65,\nplatelets - 26515-7 is 260.\n3 weeks later, the patient visited and experienced the following:\nhematocrit - 20570-8 is 39,\ncreatinine - 2160-0 is 0.6,\nplatelets - 26515-7 is 257.\n3 weeks later, the patient visited and experienced the following:\nhematocrit - 20570-8 is 36.6,\n33\n"}, {"page": 34, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\ncreatinine - 2160-0 is 0.63,\nplatelets - 26515-7 is 271.\n3 weeks later, the patient visited and experienced the following:\nhematocrit - 20570-8 is 35.7,\ncreatinine - 2160-0 is 0.61,\nplatelets - 26515-7 is 257.\nTask 2 is time to event prediction:\nHere is the prediction: the event (death) was not censored and did not occur.\nD.11. System Prompt\nAs a specialist predictive model in personalized medicine, your task is to forecast\nthe health trajectory of cancer patients by integrating genomic data, lifestyle\nfactors, treatment history and anything else provided about the patient. Use\nthe provided patient data, including genetic mutations, biomarker levels, and\nprevious treatment responses, to predict all requested tasks. Deliver precise\nand clinically relevant predictions to enhance patient care and treatment\nplanning.\nD.12. Qwen3 Next 80B-A3B Prompt\nThe following prompt was used to generate the initial reasoning chains using the Qwen3 Next 80B-A3B model. Note, that\nwe then replace the prediction with the true prediction, and also shift it to the beginning, since this showed to provide more\nstable results in early experiments.\nYou are an expert hematologist-oncologist. You will receive a complete\npatient history and a specific task to predict the patient’s neutrophil\ntrajectory.\nYour primary goal is to generate a step-by-step reasoning chain that\nleads to your prediction. This rationale is more important than the\nprediction itself.\nStructure your entire response using the following tags. Do not include\nany text outside of these tags.\n<thinking>\nInside this tag, you must follow this four-step reasoning process:\n1. **Patient Summary:** Briefly summarize the patient’s current oncological\nand hematological status. Focus on the diagnosis, active treatments,\nand the most recent relevant lab values.\n2. **Key Predictive Factors:** Identify the **top 5 most influential factors** from\nthe patient’s record that will drive the neutrophil trajectory.\nList each factor (e.g., specific drug, time since last treatment,\ncomorbidity, recent lab trend) and provide a concise justification\nfor its high importance.\n3. **Mechanistic Analysis:** This is the most critical step. Synthesize\nthe 5 factors you identified. Provide a detailed, step-by-step\nbiological explanation of how these factors will interact to\ninfluence the neutrophil count *over time*.\n* Describe the specific biological pathways involved (e.g.,\n34\n"}, {"page": 35, "text": "TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins\nmyelosuppression from a specific drug class, hematopoietic\nrecovery kinetics, effects of G-CSF on bone marrow\nprecursors, inflammatory cytokine release).\n* Explain the expected *timing* of these effects (e.g., \"The\npatient is X days post-[Chemo], so we expect the nadir\naround day Y,\" or \"The recent G-CSF administration will\nlikely cause a transient leukocytosis followed by...\").\n4. **Confounding Factors:** Briefly mention 1-2 other factors (e.g.,\npotential infection, patient age, nutritional status) that could\ncomplicate or alter your primary predicted trajectory.\n</thinking>\n<prognosis_summary>\nBased on your thinking and rationale, provide a 1-2 sentence summary of the expected\nneutrophil trend (e.g., \"Expect sharp decline into severe neutropenia,\"\nor \"Anticipate slow but steady recovery\") and the primary clinical risk\n(e.g., \"High risk of febrile neutropenia,\" or \"Risk of treatment delay\").\n</prognosis_summary>\n<prediction>\n[Place the final, formatted prediction here as specified in the task\ndescription.]\n</prediction>\n35\n"}]}