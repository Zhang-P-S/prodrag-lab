{"doc_id": "arxiv:2511.19498", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2511.19498.pdf", "meta": {"doc_id": "arxiv:2511.19498", "source": "arxiv", "arxiv_id": "2511.19498", "title": "Hierarchical Dual-Strategy Unlearning for Biomedical and Healthcare Intelligence Using Imperfect and Privacy-Sensitive Medical Data", "authors": ["Yi Zhang", "Tianxiang Xu", "Zijian Li", "Chao Zhang", "Kunyu Zhang", "Zhan Gao", "Meinuo Li", "Xiaohan Zhang", "Qichao Qi", "Bing Chen"], "published": "2025-11-23T15:28:19Z", "updated": "2025-11-23T15:28:19Z", "summary": "Large language models (LLMs) exhibit exceptional performance but pose substantial privacy risks due to training data memorization, particularly within healthcare contexts involving imperfect or privacy-sensitive patient information. We present a hierarchical dual-strategy framework for selective knowledge unlearning that precisely removes specialized knowledge while preserving fundamental medical competencies. Our approach synergistically integrates geometric-constrained gradient updates to selectively modulate target parameters with concept-aware token-level interventions that distinguish between preservation-critical and unlearning-targeted tokens via a unified four-level medical concept hierarchy. Comprehensive evaluations on the MedMCQA (surgical) and MHQA (anxiety, depression, trauma) datasets demonstrate superior performance, achieving an 82.7% forgetting rate and 88.5% knowledge preservation. Notably, our framework maintains robust privacy guarantees while requiring modification of only 0.1% of parameters, addressing critical needs for regulatory compliance, auditability, and ethical standards in clinical research.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2511.19498v1", "url_pdf": "https://arxiv.org/pdf/2511.19498.pdf", "meta_path": "data/raw/arxiv/meta/2511.19498.json", "sha256": "91e737bf07a543b914c8d883d33ea2400ebccefd18fa2f448d01c55f570c86cd", "status": "ok", "fetched_at": "2026-02-18T02:26:27.711392+00:00"}, "pages": [{"page": 1, "text": "1\nHierarchical Dual-Strategy Unlearning for Biomedical and Healthcare\nIntelligence Using Imperfect and Privacy-Sensitive Medical Data\nYi Zhang∗, Tianxiang Xu∗, Zijian Li, Chao Zhang, Kunyu Zhang, Zhan Gao, Meinuo Li, Xiaohan Zhang,\nQichao Qi†, and Bing Chen†\nAbstract—Large language models (LLMs) exhibit exceptional\nperformance but pose substantial privacy risks due to train-\ning data memorization, particularly within healthcare contexts\ninvolving imperfect or privacy-sensitive patient information.\nWe present a hierarchical dual-strategy framework for selec-\ntive knowledge unlearning that precisely removes specialized\nknowledge while preserving fundamental medical competencies.\nOur approach synergistically integrates geometric-constrained\ngradient updates to selectively modulate target parameters with\nconcept-aware token-level interventions that distinguish between\npreservation-critical and unlearning-targeted tokens via a unified\nfour-level medical concept hierarchy. Comprehensive evaluations\non the MedMCQA (surgical) and MHQA (anxiety, depression,\ntrauma) datasets demonstrate superior performance, achieving\nan 82.7% forgetting rate and 88.5% knowledge preservation. No-\ntably, our framework maintains robust privacy guarantees while\nrequiring modification of only 0.1% of parameters, addressing\ncritical needs for regulatory compliance, auditability, and ethical\nstandards in clinical research.\nIndex Terms—machine unlearning, privacy-sensitive health-\ncare data, biomedical intelligence\nI. INTRODUCTION\nLarge language models (LLMs) have transformed healthcare\ninformatics, demonstrating remarkable capabilities in medical\nquestion-answering and clinical decision support. However,\ntheir deployment faces significant challenges when dealing\nwith imperfect medical data, which is characteristically incom-\nplete, insufficiently labelled, imbalanced, or contains annota-\ntion noise [4]. Moreover, their ability to memorize training\ndata raises substantial privacy concerns when deployed on\nsensitive medical datasets. Critically, current methodologies\nlack the capability to selectively excise specific sensitive\ninformation from imperfect, interconnected medical datasets\nwithout compromising the model’s broader clinical reason-\ning [37]. Privacy regulations such as GDPR emphasize the\n∗These authors contributed equally to this work.\n†Corresponding authors.\nB. Chen is with the Department of Neurosurgery, The Affiliated Hospital\nof Qingdao University, Qingdao, Shandong 266000, China (e-mail: chen-\nbing sjwk@qduhospital.cn).\nY. Zhang is with the Department of Neurosurgery, Peking Union Medical\nCollege Hospital, Beijing 100730, China.\nT. Xu is with the School of Software and Microelectronics, Peking\nUniversity, Beijing 102600, China.\nZ. Li is with the College of Artificial Intelligence, Dalian Maritime\nUniversity, Dalian 116026, China.\nC. Zhang, K. Zhang and Q. Qi are with the Department of Neuro-\nsurgery, Qilu Hospital of Shandong University, Jinan 250012, China (e-mail:\nqiqichao@sdu.edu.cn).\nZ. Gao is with Zhengzhou University, Zhengzhou, Henan 450001, China.\nM. Li is with The University of Hong Kong, Hong Kong SAR, China.\nX. Zhang is with the Georgia Institute of Technology, Atlanta, GA 30332,\nUSA.\n”right to be forgotten,” necessitating robust machine unlearn-\ning methodologies that can effectively manage imperfect and\nprivacy-sensitive medical data for responsible AI deployment\n[9], [10].\nMedical domain unlearning faces critical challenges when\ndealing with imperfect healthcare data. LLMs may inadver-\ntently encode patient-specific information from insufficiently\nanonymised data, creating privacy risks [19]. Rapidly evolv-\ning medical guidelines require models to ”forget” outdated\nor incorrectly labelled information [21]. Specialized medi-\ncal knowledge trained on imbalanced datasets requires com-\npartmentalization for selective access [16]. For instance, a\ncompliant clinical AI system must retain general diagnostic\ncapabilities (e.g., identifying common symptoms of brain\ntumors) while selectively unlearning restricted surgical pro-\ncedural details (e.g., specific steps for brain tumor resection)\nto ensure patient safety and regulatory adherence. This is\nparticularly important for mental health specialties, where\nconditions such as anxiety, depression, trauma, and obsessive-\ncompulsive disorders demand heightened privacy protection\nwhilst dealing with often incomplete or noisy diagnostic\ndata. Hospital research environments require frameworks that\nselectively manage imperfect and sensitive information whilst\npreserving clinical utility. Advanced attention mechanisms and\nmulti-scale analysis techniques from computer vision [45],\n[46] have inspired similar approaches in medical data pro-\ncessing to improve model robustness.\nTraditional unlearning approaches face significant chal-\nlenges when applied to imperfect medical data. Knowledge\nboundary delineation is complex due to interconnected med-\nical domains and incomplete supervision, surgical knowledge\nshares fundamental concepts with other specialities whilst\ndealing with varying annotation quality [5]. Knowledge in-\ntegrity preservation requires understanding hierarchical med-\nical concept organisation in the presence of label noise and\ndata imbalance [18]. Imperfect medical data imposes stringent\nprivacy requirements demanding rigorous removal guarantees\nwhilst maintaining model utility on insufficiently labelled\ndatasets [13].\nExisting methods include complete retraining (strong guar-\nantees but computationally prohibitive [10]) and gradient-\nbased approaches (efficient but limited precision on noisy data\n[20]). Recent advances in multimodal and token-level unlearn-\ning show promise [1], [2] but haven’t adequately addressed the\nspecific challenges of managing imperfect medical data with\nincomplete supervision and privacy constraints.\nWe introduce a hierarchical dual-strategy framework com-\nbining geometric-constrained gradient updates with concept-\narXiv:2511.19498v1  [cs.LG]  23 Nov 2025\n"}, {"page": 2, "text": "2\naware token interventions through a unified four-level medical\nconcept hierarchy (L1: fundamental biomedical, L2: general\nclinical, L3: specialty-specific, L4: surgical concepts). The\ngeometric component uses Fisher Information Matrix analysis\nto selectively modify surgical parameters while preserving\ngeneral medical reasoning [7]. The token component employs\ngradient-based importance scoring to identify surgical tokens\nwhile maintaining fundamental medical vocabulary [6].\nWe evaluate on MedMCQA (surgical unlearning) and\nMHQA datasets [3] (mental health domains: anxiety, depres-\nsion, trauma, OCD). Our approach demonstrates superior se-\nlective unlearning performance, outperforming existing meth-\nods with robust privacy guarantees while requiring minimal\nparameter modification [12], [14].\nKey contributions include:\n• A hierarchical dual-strategy framework addressing un-\nlearning at parameter and vocabulary levels, specifically\ndesigned for imperfect medical data management;\n• A hierarchical medical concept methodology for precise\ntargeting whilst handling incomplete supervision and an-\nnotation noise;\n• A comprehensive evaluation framework assessing effec-\ntiveness, preservation, privacy, and efficiency on real-\nworld imperfect medical datasets;\n• Empirical evidence demonstrating superiority in biomed-\nical and healthcare intelligence using imperfect data.\nThis establishes a paradigm for privacy-preserving medical\nAI addressing regulatory and ethical requirements whilst ef-\nfectively managing imperfect healthcare data [15].\nII. RELATED WORK\nA. Machine Unlearning\nMachine unlearning removes specific knowledge from\ntrained models to address privacy regulations and ethical\nconsiderations. Exact methods like complete retraining [10]\nprovide strong guarantees but are computationally expensive.\nApproximate methods include influence-based approaches\n[22], gradient ascent [23], and model editing [24], offering\nefficiency but weaker guarantees.\nRecent parameter-efficient approaches use adapters [25]\nand knowledge isolation [6], modifying fewer parameters\nbut struggling with precise targeting in complex domains.\nAdvances in large language models have also addressed com-\nprehension failures [43] and hallucination issues in multi-\nmodal settings [44], offering promising directions for im-\nproving model reliability. Recent benchmarks have evaluated\nparameter-efficient unlearning methods [8], demonstrating the\nfeasibility of data chunking approaches. Our dual-strategy\napproach combines parameter-level and token-level interven-\ntions for both efficiency and precision in medical knowledge\nunlearning.\nB. Privacy-Preserving Machine Learning\nPrivacy-preserving techniques include differential privacy\n[26], federated learning [27], and secure computation [28].\nVertical federated learning approaches [35] address challenges\nof missing features in distributed settings. Differential privacy\nprovides formal guarantees and has been integrated with\nunlearning [29], though balancing privacy and utility remains\nchallenging in healthcare.\nTram`er et al. [11] developed considerations for differen-\ntially private learning with large-scale pretraining. Yu et al.\n[13] extended differential privacy to unlearning. Li et al.\n[15] proposed DP-Adapter for fine-tuning but didn’t address\nunlearning or medical domains. Our framework combines\ndifferential privacy with DoRA-based unlearning for medical\nknowledge management.\nC. Medical AI and Knowledge Management\nLLMs show promise in clinical decision support [30], med-\nical QA [31], and biomedical analysis [32], but raise privacy\nconcerns regarding patient information memorisation. Recent\nwork has also addressed handling uncertainty in medical data,\nsuch as clinical expert uncertainty in noisy label learning [4].\nMedical AI systems have been applied to diverse clinical tasks\nincluding brain disorder diagnosis [36], stem cell transplanta-\ntion prediction [38], molecular property prediction [39], and\ninterpretable brain age prediction from EEG [41], while main-\ntaining robustness against privacy attacks such as membership\ninference attacks on medical databases [42] and knowledge\ngraph-based diagnostic reasoning [17]. Previous medical AI\nwork focused on knowledge injection [33] and adaptation [34],\nwith limited attention to selective removal.\nOur work develops specialised medical unlearning consid-\nering hierarchical knowledge structure and interdependencies,\ndemonstrating effective surgical knowledge removal while\npreserving general medical capabilities for responsible medical\nAI systems.\nIII. METHODOLOGY\nThis section presents our hierarchical dual-strategy frame-\nwork for selective unlearning in medical LLMs. The ap-\nproach integrates geometric-constrained gradient updates with\nconcept-aware token-level interventions guided by a unified\nfour-level medical concept hierarchy. This structure systemat-\nically aligns parameter and token modifications to ensure syn-\nergistic unlearning. We organize the section into three parts:\nsystem architecture, dual-strategy mechanics, and differential\nprivacy integration, with the complete optimization workflow\nformalized in Algorithm 1.\nA. System Architecture Overview\nOur\nunlearning\narchitecture\nis\nconstructed\nupon\nthe\nQwen2.5-3B-Instruct foundation model and implements a so-\nphisticated modular design encompassing five interconnected\ncomponents that operate synergistically through the unified\nmedical concept hierarchy, as illustrated in Figure 1. The\nMedical Concept Hierarchy Module establishes a compre-\nhensive four-level knowledge architecture (L1: fundamen-\ntal biomedical concepts, L2: general clinical concepts, L3:\nspeciality-specific concepts, L4: surgical domain concepts)\n"}, {"page": 3, "text": "3\nInput\ntokens\nSelected \nTokens\nWeight \nCalculation\nDynamic Token Selection\nMulti - dimensional Evaluation\nSequential Training Process\nFR\nKPR\nMIA Score\nHMTA\nDuoLearn\nGradient \nMonitoring\nGradient \nDifference \nAnalysis\nMedical dataset\nEmbedding Layer\nEncoder\nCross \nModal \nMapping\nK＆V\nQ\nDecoder Layer\nDecoder Layer\nGated Fusion\nLinear & Softmax\nFusion Space\nKnowledge Words Feature\nMHA\nAlignment Fusion\nλ\nParallel Decoding\nConcept - \nAware \nAttention\nClinical Concept \nRetention\nMedical \nKnowledge\nConcept \nBoundary \nManagement\nConcept B\nDP-LoRA\nPrivacy Budget \nManagement\nMulti-level \nNoise Allocation\nDifferential Privacy with LoRA\nDifferential Privacy \nMechanism\nLoRA Adapter\nparameter\nperturbation\nMedical Data \nAnonymization\nConceptual \nForgetting \nMechanism\nAdversarial \nUnlearning\nClinical Deploration\nPrivacy \nPreservation \nValidation\nMedForget\ny1\n…\nReport Feature\n…\n…\nFig. 1. Architecture overview of the DuoLearn framework for medical knowledge unlearning. The system integrates medical data processing through embedding\nlayers, concept-aware attention mechanisms for clinical concept retention and boundary management, DP-LoRA for privacy-preserving parameter updates,\nand comprehensive evaluation metrics (FR, KPR, MIA Score, HMTA) within a sequential training process that culminates in the MedForget deployment for\nclinical applications.\nAlgorithm 1 Hierarchical Dual-Strategy Unlearning Process\nRequire: Datasets Dr, Df; Model θ; Weights λ (Forget), α\n(Retain); Hierarchy Maps αLj, βLj.\n1: for t = 1 to T do\n2:\nSample batches Br ∼Dr and Bf ∼Df\n3:\n1. Gradient Computation:\n4:\ngr ←∇θL(Br);\ngf ←∇θL(Bf)\n5:\n2. Geometric Projection (Eq. 12):\n6:\nFor each layer Lj, project forget gradient to protect\nretention:\n7:\ng⊥\nf ←gf −αLj\ngf ·gr\n∥gr∥2+ϵgr\n8:\n3. Sign Flipping & Objective Combination (Eq. 2,\n6):\n9:\ngtotal ←\ngr\n|{z}\nMinimize Lr\n−\nλg⊥\nf\n|{z}\nMaximize Lf\n+\nγ∇R\n| {z }\nRegularization\n10:\n4. Token Intervention & Privacy:\n11:\ngtotal ←gtotal ⊙(1 + βLj · Itoken)\n{Apply Concept\nWeights}\n12:\n˜g ←Clip(gtotal, C) + N(0, σ2I)\n{Add DP Noise}\n13:\n5. Update:\n14:\nθt+1 ←θt −η˜g\n15: end for\nthat systematically guides both parameter-level and token-\nlevel interventions. The Medical Data Processing Module per-\nforms sophisticated classification and preprocessing of medical\ndata from the MedMCQA dataset, systematically mapping\ncontent to appropriate hierarchical levels while establishing\nclear demarcation between surgical knowledge (designated\nfor unlearning) and other medical domains (designated for\npreservation). The Dual-Strategy Unlearning Module orches-\ntrates simultaneous geometric-constrained gradient updates\nand concept-aware token interventions, with both components\ncoordinated through the shared hierarchical framework. The\nParameter-Efficient Fine-tuning Module strategically imple-\nments Low-Rank Adaptation (LoRA) to minimize trainable\nparameter requirements while maintaining robust model per-\nformance. Finally, the Differential Privacy Integration Module\nprovides mathematically rigorous privacy guarantees through\ncarefully calibrated stochastic noise addition.\nThe system implements an integrated training workflow\nwherein both unlearning strategies operate concurrently within\neach optimization step: the medical concept hierarchy initially\nguides the systematic identification of parameters and tokens at\neach hierarchical level, followed by simultaneous application\nof geometric-constrained gradient updates and concept-aware\ntoken interventions, with continuous evaluation performed\non both retention and forgetting datasets. This coordinated\narchitectural design achieves optimal equilibrium between\nunlearning precision, knowledge preservation integrity, and\nprivacy protection through the synergistic effects of the dual\nstrategic components.\nB. Problem Formulation\nLet θ represent the parameters of our language model, Df\ndenote the forgetting dataset containing imperfect or privacy-\nsensitive medical data (surgical knowledge), and Dr denote\nthe retention dataset (other medical knowledge with varying\nannotation quality). The traditional unlearning objective can\nbe formulated as finding parameters θ′ that minimize the\nperformance on Df while maintaining performance on Dr:\nθ′ = arg min\nθ\nLr(θ) −λLf(θ)\n(1)\nwhere Lr and Lf are the loss functions on the retention\nand forgetting datasets, respectively, and λ is a balancing\nhyperparameter.\n"}, {"page": 4, "text": "4\nHowever, this conventional formulation inadequately ac-\ncounts for the intricate interdependencies inherent in medical\nknowledge architectures, the challenges posed by imperfect\nmedical data (incomplete labels, annotation noise, data im-\nbalance), or the stringent privacy requirements mandated in\nhealthcare applications. Our methodological approach refines\nthis optimization objective by incorporating hierarchical se-\nquential processing that can handle imperfect supervision and\nrigorous differential privacy mechanisms:\nθ′ = arg min\nθ\nLr(θ) −λLf(θ) + γR(θ)\n(2)\nwhere R(θ) represents a sophisticated regularization term\nthat ensures comprehensive privacy preservation whilst han-\ndling imperfect medical data characteristics, and γ constitutes\nits corresponding weighting factor.\nC. Unified Medical Concept Hierarchy\nThe architectural foundation of our dual-strategy approach\ncomprises a unified four-level medical concept hierarchy that\nsystematically coordinates both parameter-level and token-\nlevel interventions whilst accommodating imperfect medical\ndata characteristics such as incomplete annotations and varying\nlabel quality. This hierarchical organisational structure func-\ntions as the integrative bridge between the two complemen-\ntary unlearning strategies, ensuring consistent targeting and\npreservation objectives across diverse model representational\nframeworks even when dealing with noisy or insufficiently\nlabelled medical data.\n1) Hierarchical Structure Definition: The medical concept\nhierarchy follows a four-level structure that enables progres-\nsive specificity and targeted interventions across different\nknowledge domains.\n2) Coordinated Strategy Implementation: We unify the\ndual-strategy interventions through a rigorous mapping be-\ntween hierarchy levels and modulation coefficients, as detailed\nin Table I. Each level Lj is assigned a preservation coefficient\nαLj (modulating gradient projection intensity in Eq. 10) and\nan unlearning intensity βLj (modulating token importance\nweights in Eq. 11).\nTABLE I\nUNIFIED MEDICAL CONCEPT HIERARCHY MAPPING. DEFINITIONS OF\nLEVELS AND THEIR CORRESPONDING MODULATION COEFFICIENTS FOR\nGRADIENT PRESERVATION (α) AND TOKEN UNLEARNING (β).\nLevel\nDescription\nαLj (Preserve)\nβLj (Unlearn)\nL1\nFundamental Biomedical\n1.0\n0.1\nL2\nGeneral Clinical\n0.8\n0.3\nL3\nSpecialty-Specific\n0.6\n0.7\nL4\nSurgical (Target)\n0.2\n1.0\nThis mapping ensures precise modulation: for geometric gra-\ndients, αLj enforces strict orthogonality for L1 (preserving\nfoundation) while relaxing constraints for L4 (allowing era-\nsure). Conversely, for token interventions, βLj amplifies the\nloss contribution of surgical tokens (L4) while suppressing\nthe impact on fundamental vocabulary (L1), ensuring both\nstrategies operate synergistically towards the same target.\nD. Category-Based Knowledge Separation\nThe core insight of our approach is that medical knowledge\ncan be effectively separated by subject categories, allowing for\nprecise targeting of specific knowledge domains for unlearning\nwhile preserving others.\n1) Subject Category Identification: We leverage the sub-\nject categorization in the MedMCQA dataset to identify and\nseparate surgical knowledge from other medical domains. This\napproach provides a clear boundary for knowledge separation:\nDf = {x ∈D | subject(x) = “surgery”}\n(3)\nDr = {x ∈D | subject(x) ̸= “surgery”}\n(4)\nwhere D is the complete dataset, and subject(x) returns the\nsubject category of sample x.\nThe approach was designed to successfully target the sur-\ngical domain for unlearning while preserving performance\nacross other medical specialties through the category-based\nseparation mechanism.\n2) Data Processing Pipeline: Data processing includes: (1)\ncategory filtering to separate surgical from other medical do-\nmains, (2) question-answer formatting for consistent structure,\nand (3) tokenization with answer-focused loss masking.\nE. Sequential Unlearning with Gradient Constraints\nTo ensure stable and effective unlearning, a sequential\nunlearning approach was implemented that processes the for-\ngetting dataset in blocks while applying gradient constraints.\n1) Block-wise Processing: The forgetting dataset Df is\ndivided into blocks and processed sequentially. Each block\ncombines forgetting examples with retention examples (ratio\nm:1), applies different gradient factors, and performs gradient-\nconstrained updates with differential privacy. This approach\nprevents catastrophic forgetting and enables controlled un-\nlearning monitoring.\n2) Gradient Factor Assignment: Different gradient factors\nwere assigned to forgetting and retention examples to control\ntheir influence on parameter updates:\nfactor(x) =\n(\n−1\nif x ∈Df\nα\nif x ∈Dr\n(5)\nwhere α is a positive factor (typically set to 1) that controls\nthe relative importance of retention examples.\n3) Gradient-Constrained Updates: During the unlearning\nprocess, we modify the standard gradient update rule to\nincorporate the gradient factors:\nθt+1 = θt −η ·\nX\nx∈Bt\nfactor(x) · ∇θL(x, θt)\n(6)\nwhere η is the learning rate, Bt is the current batch, and\nL(x, θt) is the loss for example x with parameters θt.\nThis performs gradient ascent on forgetting examples and\ngradient descent on retention examples, achieving selective\nunlearning.\n"}, {"page": 5, "text": "5\nF. Parameter-Efficient Fine-tuning\nTo reduce computational requirements and minimize the risk\nof catastrophic forgetting, parameter-efficient fine-tuning was\nimplemented using Low-Rank Adaptation (LoRA).\n1) LoRA Parameter Decomposition: LoRA was applied to\ndecompose weight updates into low-rank forms. For a weight\nmatrix W ∈Rd×k, the update is parameterized as:\nW ′ = W + ∆W = W + BA\n(7)\nwhere B ∈Rd×r, A ∈Rr×k, and r ≪min(d, k).\n2) Selective Layer Targeting: LoRA targets specific projec-\ntion matrices in the final transformer layers, further reducing\ntrainable parameters while focusing on knowledge-critical\nlayers.\nG. Differential Privacy Integration\nTo provide theoretical privacy guarantees, differential pri-\nvacy was integrated into the unlearning process through noise\naddition to the gradients.\n1) Privacy Mechanism:\nCalibrated Gaussian noise was\nadded to the gradients to provide (ε, δ)-differential privacy:\n∇private = ∇+ N(0, σ2I)\n(8)\nwhere σ is the noise multiplier determined by the privacy\nparameters ε and δ:\nσ = q ·\np\n2 ln(1.25/δ)\nε\n(9)\nHere, q is the sampling rate (batch size divided by dataset\nsize).\n2) Privacy-Utility Trade-off: Privacy parameters are care-\nfully calibrated to balance strong theoretical privacy guaran-\ntees with acceptable model performance.\nH. Evaluation Metrics\nWe normalize our evaluation criteria across four dimen-\nsions. 1) Effectiveness: We report Forgetting Rate (FR) and\nKnowledge Preservation Rate (KPR) (standardizing ’KP’). The\nHarmonic Mean Task Aggregate (HMTA) balances these:\nHMTA = 2 · FR · KPR\nFR + KPR .\n(10)\n2) Hierarchy: Concept Hierarchy Separation (CHS) quantifies\nthe accuracy gap between fundamental (L1) and surgical\n(L4) concepts (AccL1 −AccL4), while Medical Subdomain\nDifferentiation (MSD) measures performance variance across\nnon-surgical specialties. 3) Privacy: We introduce Member-\nship Inference Attack Resistance (MIA Resist). Given the\nattack AUC score, it measures the degradation of attacker\nperformance towards random guessing (0.5):\nMIA Resist = 1 −2 × |AUC −0.5|\n(11)\nwhere 1.0 indicates perfect privacy. 4) Efficiency: We define\nParameter Efficiency Ratio (PER = θtrainable/θtotal), Mem-\nory Consumption Ratio (MCR), and Time Efficiency Metric\n(TEM) relative to full fine-tuning baselines.\nI. Implementation Details\nImplementation\nuses\nQwen2.5-3B-Instruct\nfoundation\nmodel with block-wise sequential processing and retention\nratio balancing for controlled unlearning.\nIV. EXPERIMENTAL SETUP\nThis section delineates the comprehensive experimental\nmethodology implemented to rigorously evaluate our hier-\narchical dual-strategy unlearning framework. The system-\natic dataset preparation, sophisticated model configurations,\ncomprehensive comparison baselines, and multi-dimensional\nevaluation metrics were meticulously designed to provide\nthorough assessment of selective medical knowledge unlearn-\ning effectiveness across diverse clinical domains. To ensure\nevaluation integrity, we conducted a rigorous contamination\naudit utilizing MinHash deduplication, confirming a negligible\noverlap rate (< 0.1%) between training and evaluation splits.\nA. Dataset\nWe conducted comprehensive evaluation utilising two com-\nplementary medical datasets that exemplify typical imperfect\ndata characteristics in healthcare applications: the MedMCQA\ndataset encompassing 4,183 questions distributed across 15\nmedical specialities (with 782 surgical questions designated for\ntargeted unlearning), representing challenges of imbalanced\nmedical speciality distribution and varying question difficulty\nlevels, and the MHQA dataset [3] comprising 58,600 mental\nhealth question-answer pairs spanning anxiety disorders, de-\npression, trauma-related conditions, and obsessive-compulsive\ndisorder domains, characterised by inherent annotation sub-\njectivity and incomplete diagnostic coverage typical of mental\nhealth data. Both datasets employed standardized 80/10/10\ntrain/validation/test partitioning to ensure robust experimental\nvalidation whilst preserving the natural data imbalance pat-\nterns.\n1) Data Preprocessing Pipeline: The sophisticated data\npreprocessing pipeline encompassed systematic domain clas-\nsification (surgical versus non-surgical categories for MedM-\nCQA; anxiety-related versus other mental health domains\nfor MHQA) whilst handling inherent data quality variations\nand annotation inconsistencies typical of real-world med-\nical datasets, comprehensive format standardisation imple-\nmenting a consistent ”question + options + answer” struc-\ntural framework adapted to accommodate varying annotation\ncompleteness, and hierarchical medical concept annotation\nutilizing the Unified Medical Language System (UMLS)\nMetaMap tool across four distinct hierarchical levels (L1:\nfundamental biomedical concepts, L2: general clinical con-\ncepts, L3: specialty-specific concepts, L4: surgical domain\nconcepts) with robust handling of ambiguous or incomplete\nconcept mappings. Additionally, comprehensive token distri-\nbution analysis systematically identified high-influence sur-\ngical tokens and shared medical vocabulary whilst account-\ning for noise and variability in medical terminology usage,\nproviding strategic guidance for the subsequent unlearning\nimplementation on imperfect data.\n"}, {"page": 6, "text": "6\nB. Model Architecture and Configuration\n1) Base Model: We used Qwen2.5-3B-Instruct (3B param-\neters, 8,192 context length, 151,936 vocabulary) pre-trained\non medical literature. All experiments were conducted on\nNVIDIA RTX 4090 GPU (24GB VRAM) using PyTorch 2.7,\nTransformers 4.50.0, and PEFT 0.15.0 frameworks.\n2) Parameter-Efficient Fine-Tuning: LoRA configuration:\nrank r = 8, scaling factor α = 16, applied to query/key/value\nprojection matrices in the final 4 transformer layers. As\ndetailed in Table II, this configuration yields 3.25M trainable\nparameters (0.1% of the 3.0B total). The backbone remains\nfully frozen, with updates restricted to LoRA adapters, mini-\nmal auxiliary heads, and concept-aware statistical scalers.\nTABLE II\nRECONCILED TRAINABLE PARAMETER BUDGET.\nModule\nTensor Components\nCount\nRatio\nBackbone\nFrozen Transformer Weights\n0\n0.00%\nLoRA\nQ/K/V Projections (r = 8)\n3.20M\n0.10%\nAuxiliary\nUnlearning/Task Heads\n0.04M\n<0.01%\nStatistics\nConcept-Aware Scalers\n0.01M\n<0.01%\nTotal\nTrainable Parameters\n3.25M\n0.11%\nPrivacy mechanisms to ensure rigorous theoretical guaran-\ntees.\nC. Dual-Strategy Unlearning Implementation\nWe implemented the dual strategies simultaneously within\na unified training loop to ensure coordinated knowledge re-\nmoval.\n1) Hierarchy-Guided Geometric-Gradient Updates:\nThe\ngeometric-constrained gradient component leverages the med-\nical concept hierarchy to selectively modify parameters. Fisher\nInformation Matrix (FIM) values are computed using a diago-\nnal empirical approximation accumulated over a sliding win-\ndow of 32 steps for each hierarchy level. For each parameter\nθi associated with hierarchy level Lj, orthogonal projection is\napplied using L2-normalized gradients:\n∇proj\nθi\n= ∇forget\nθi\n−αLj · ∇forget\nθi\n· ∇retain\nθi\n||∇retain\nθi\n||2 + ϵ ∇retain\nθi\n(12)\nwhere αLj represents the hierarchy-specific preservation\nintensity as detailed in Table I, and ϵ = 10−5 safeguards\nagainst vanishing retain gradients. This projection introduces\nminimal compute overhead (≈15% latency) due to efficient\nelement-wise operations.\n2) Hierarchy-Coordinated\nToken\nInterventions:\nThe\nconcept-aware token component operates simultaneously with\nparameter updates. Token importance scores are computed:\nI(t, Lj) = βLj ·\n|Gradforget(t)|\n|Gradretain(t)| + ϵ\n(13)\nwhere |Grad(t)| = ∥∇etL∥2 denotes the ℓ2-norm of the loss\ngradient with respect to the input embedding vector et of token\nt, βLj represents the hierarchy-specific unlearning intensity as\ndetailed in Table I.\n3) Coordinated Implementation: The training loop syn-\nchronizes both strategies: at each step, the hierarchy module\nassigns levels to parameters and tokens, triggering simulta-\nneous geometric updates and weighted token interventions.\nThis ensures parameter modifications and token constraints\nsynergistically reinforce the unlearning objective.\nD. Baseline Methods\nBaselines included: Original Model (no unlearning), Com-\nplete Retraining (theoretical upper bound), Gradient Ascent,\nSUGD, and AILS-NTUA (SemEval-2025 Task 4 winner).\nComprehensive ablation studies were conducted using four\nvariants: GG-Only (utilizing only the Geometric-Gradient\ncomponent), CT-Only (employing only the Concept-Token\ncomponent), No-DP (our full approach without differential\nprivacy), and No-Hierarchy (our approach without the concept\nhierarchy structure). All experiments were conducted with\nidentical random seeds (42, 123, 789) and hardware configu-\nrations to ensure fair comparisons. We enforced compute-fair\nbaselines by aligning optimization budgets (fixed 3 epochs,\nearly stopping patience=3 steps) and hyperparameter search\nranges (learning rates ∈[1e−5, 5e−4]) across all methods,\nreporting wall-clock time to verify comparable computational\ncost. Results denote mean ± standard deviation.\nOur evaluation encompasses four key dimensions: (1) Un-\nlearning effectiveness measured by Forgetting Rate (FR),\nKnowledge Preservation (KP), Unlearning Score (US), and\nHarmonic Mean Task Aggregate (HMTA); (2) Privacy protec-\ntion assessed through Membership Inference Attack (MIA) re-\nsistance, Privacy Risk Score, and Differential Privacy Strength;\n(3) Medical concept preservation evaluated via Concept\nPreservation Accuracy (CPA) across hierarchy levels, Concept\nHierarchy Separation (CHS), and Medical Subdomain Dif-\nferentiation (MSD); (4) Computational efficiency quantified\nthrough Parameter Efficiency Ratio (PER), Time Efficiency\nMetric (TEM, measured in wall-clock hours), and Memory\nConsumption Ratio (MCR).\nV. RESULTS AND ANALYSIS\nThis section presents the comprehensive experimental find-\nings obtained through rigorous evaluation of our hierarchical\ndual-strategy unlearning framework. We provide systematic\nanalysis of performance across multiple critical dimensions,\nincluding unlearning effectiveness, knowledge preservation\nintegrity, privacy protection robustness, and computational ef-\nficiency, with detailed comparison against established baseline\nmethodologies and comprehensive ablation variants.\nA. Overall Performance Comparison\nOur hierarchical dual-strategy approach demonstrated ex-\nceptional performance superiority across all evaluation metrics\nwhen compared to established baseline methodologies. Ta-\nble III presents comprehensive quantitative results comparing\nour methodological innovation against contemporary state-of-\nthe-art approaches and classical baseline frameworks.\nOur framework achieved exceptional selective unlearning\nperformance, attaining an 82.7% forgetting rate (SD=2.1%)\n"}, {"page": 7, "text": "7\nTABLE III\nMAIN PERFORMANCE COMPARISON ON MEDMCQA DATASET\nMethod\nFR (%)\nKP (%)\nUS (%)\nHMTA\nMIA Resist\nOriginal Model\n0.0±0.0\n89.2±0.8\n44.6\n0.445\n0.52\nComplete Retraining\n91.2±1.5\n79.8±2.1\n85.5\n0.782\n0.95\nGradient Ascent\n73.2±3.2\n81.4±2.8\n77.3\n0.723\n0.71\nSUGD\n75.8±2.9\n83.2±2.4\n79.5\n0.751\n0.74\nAILS-NTUA\n78.9±2.7\n84.1±2.0\n81.5\n0.801\n0.82\nOurs (Dual-Strategy)\n82.7±2.1\n88.5±1.3\n85.6\n0.847\n0.89\nPerformance Across Medical Subdomains\nTargeted for unlearning\nPediatris\nObstetrics\nPsychiatry\nRadiology\nPathology\nDermatology\nSurgery\nInternal Medicine\n20%\n40%\n60%\n80%\n100%\nafter unlearning\nbefore unlearning\nFig. 2.\nPerformance across different medical subdomains before and after\nunlearning. The surgical domain shows significant performance reduction after\nunlearning, while other medical domains maintain high performance levels,\ndemonstrating selective unlearning effectiveness.\nfor surgical knowledge while preserving 88.5% (SD=1.3%)\naccuracy on non-surgical medical queries, culminating in an\noverall unlearning score of 85.6%. This performance substan-\ntially surpassed that of conventional gradient ascent unlearning\n(73.2% forgetting rate, 81.4% knowledge preservation), com-\nplete retraining methodologies (91.2% forgetting rate, 79.8%\nknowledge preservation), and the state-of-the-art AILS-NTUA\nsystem (78.9% forgetting rate, 84.1% knowledge preservation).\nThe harmonic mean task aggregate (HMTA) scores provided\nadditional validation of our approach’s superiority, achiev-\ning 0.847 compared to 0.723 for gradient ascent, 0.782 for\ncomplete retraining, and 0.801 for the AILS-NTUA system.\nThese findings demonstrate that our methodology success-\nfully achieved optimal equilibrium between effective knowl-\nedge forgetting and comprehensive knowledge preservation,\nsystematically avoiding the extreme performance trade-offs\ncharacteristic of alternative approaches.\nFigure 2 demonstrates selective unlearning effectiveness:\nsurgical accuracy dropped from 89.2% to 17.3%, while other\ndomains maintained high performance (internal medicine:\n91.8%, pediatrics: 94.1%, obstetrics/gynecology: 88.7%).\nB. Ablation Study Results\nComprehensive ablation studies revealed the importance of\neach component in our dual-strategy framework. Table IV\npresents detailed results for each component variant.\nTABLE IV\nABLATION STUDY RESULTS\nVariant\nFR (%)\nKP (%)\nUS (%)\nHMTA\nMIA Resist\nGG-Only\n78.4±2.3\n85.9±1.7\n82.2\n0.794\n0.85\nCT-Only\n76.8±2.6\n87.2±1.5\n82.0\n0.789\n0.86\nNo-DP\n84.1±2.0\n88.1±1.4\n86.1\n0.851\n0.64\nNo-Hierarchy\n79.3±2.8\n83.1±2.3\n81.2\n0.775\n0.87\nFull Method\n82.7±2.1\n88.5±1.3\n85.6\n0.847\n0.89\nRapid forgetting of\nmemorized tokens\nSelective retention \nof general knowledge\nFig. 3.\nLoss trajectories for different token categories during unlearning.\nSurgical tokens and memorized tokens show significant loss reduction, while\ngeneral medical tokens maintain higher loss values, indicating selective\npreservation and demonstrating the effectiveness of our token-level analysis\napproach.\nIndividual strategies (GG-Only: 82.2% US, CT-Only: 82.0%\nUS) performed well but inferior to the combined approach\n(85.6% US), demonstrating synergistic effects. Removing dif-\nferential privacy improved unlearning (86.1% US) but com-\npromised privacy (MIA resistance: 0.64 vs 0.89). The hier-\narchy structure proved essential, with its removal reducing\nperformance to 81.2% US. Furthermore, sensitivity analyses\non hierarchy weights (λ ∈[0.5, 2.0]) confirmed that our default\nconfiguration represents the optimal Pareto frontier between\nretention and unlearning. Modular ablations comparing FIM\nestimators showed that our diagonal approximation matches\nfull-matrix methods (e.g., K-FAC) in efficacy while reducing\ncompute latency by 3×. We also validated that gradient-based\ntoken saliency outperforms attention-based alternatives (US:\n85.6% vs 83.4%) by providing more precise unlearning targets.\nFigure 3 shows distinct token unlearning patterns: surgical\ntokens (loss: 2.1→0.3) and memorized tokens (loss: 1.8→0.4)\ndecreased significantly, while general medical tokens remained\nstable (1.7-1.9), validating selective targeting precision.\nC. Privacy Protection Analysis\nPrivacy protection evaluation demonstrated robust resistance\nto various inference attacks. Table V presents comprehensive\nprivacy analysis across different methods.\nOur approach achieved strong privacy protection (MIA\nresistance: 0.89, AUC: 0.555 ≈random classifier, privacy risk:\n0.11) with theoretical DP guarantees (ϵ=4.0, DP strength: 0.20)\nand minimal impact on unlearning effectiveness.\n"}, {"page": 8, "text": "8\nTABLE V\nPRIVACY PROTECTION ANALYSIS\nMethod\nMIA Score\nPrivacy Risk\nDP Strength\nAUC\nε\nOriginal Model\n0.52\n0.96\n0.00\n0.98\n∞\nComplete Retraining\n0.95\n0.05\n0.20\n0.525\n4.0\nGradient Ascent\n0.71\n0.29\n0.00\n0.645\n∞\nSUGD\n0.74\n0.26\n0.00\n0.630\n∞\nAILS-NTUA\n0.82\n0.18\n0.17\n0.590\n5.0\nOurs (Dual-Strategy)\n0.89\n0.11\n0.20\n0.555\n4.0\nTABLE VI\nMEDICAL CONCEPT HIERARCHY PRESERVATION ANALYSIS\nMethod\nL1 (%)\nL2 (%)\nL3 (%)\nL4 (%)\nCHS\nMSD\nOriginal Model\n95.2±0.9\n92.8±1.1\n90.4±1.3\n89.2±1.5\n0.02\n0.00\nComplete Retraining\n93.1±1.7\n89.5±2.3\n85.2±2.8\n8.8±1.9\n0.81\n0.79\nGradient Ascent\n89.7±2.4\n85.3±3.1\n82.1±3.5\n26.8±4.2\n0.58\n0.51\nSUGD\n91.2±2.0\n87.8±2.7\n84.6±3.0\n24.2±3.8\n0.62\n0.55\nAILS-NTUA\n92.6±1.9\n89.3±2.4\n86.7±2.9\n21.1±3.4\n0.67\n0.62\nOurs (Dual-Strategy)\n94.3±1.8\n91.7±2.2\n89.1±2.8\n17.3±2.1\n0.73\n0.71\nTABLE VII\nMENTAL HEALTH DOMAIN EVALUATION RESULTS (MHQA DATASET)\nMethod\nAnxiety FR (%)\nOther MH KP (%)\nUS (%)\nMIA Resist\nDP Strength\nOriginal Model\n0.0±0.0\n87.6±1.2\n43.8\n0.51\n0.00\nComplete Retraining\n89.7±2.1\n78.3±2.4\n84.0\n0.94\n0.21\nGradient Ascent\n71.8±3.4\n82.7±2.9\n77.3\n0.73\n0.00\nSUGD\n74.2±3.1\n84.1±2.6\n79.2\n0.76\n0.00\nAILS-NTUA\n76.5±2.8\n85.9±2.2\n81.2\n0.84\n0.17\nOurs (Dual-Strategy)\n79.4±2.3\n89.1±1.8\n84.3\n0.87\n0.21\nD. Medical Concept Preservation Analysis\nHierarchical analysis of medical concept preservation re-\nvealed selective unlearning patterns aligned with our de-\nsign objectives. Table VI demonstrates the effectiveness of\nour hierarchical unlearning approach across different medical\nknowledge levels.\nHierarchical\npreservation\nshowed\nclear\ngradients:\nL1\n(94.3%), L2 (91.7%), L3 (89.1%), L4 surgical (17.3%). Hi-\nerarchy separation score (0.73) indicated effective level dif-\nferentiation, with surgical forgetting well-contained (minimal\nimpact on other specialties: ¡3.2% accuracy drop).\nFigure 4 shows the cascading hierarchical unlearning ef-\nfect with smooth transitions from fundamental concepts (L1:\n94.3%) to surgical concepts (L4: 17.3%), confirming system-\natic knowledge removal while preserving medical knowledge\nintegrity.\nE. Statistical Significance and Robustness\nStatistical significance confirmed across multiple runs (p <\n0.001 vs all baselines). Results consistent across three inde-\npendent runs (seeds: 42, 123, 789) with low standard devia-\ntions. Cross-validation showed performance variations within\n±2.3%, confirming robustness and reproducibility.\nF. Mental Health Domain Evaluation\nSupplementary MHQA evaluation targeted anxiety-related\nknowledge while preserving other mental health domains.\nTable VII shows cross-domain results.\nOur approach achieved 79.4% anxiety forgetting rate while\nmaintaining 89.1% accuracy on other mental health domains\n(unlearning score: 84.3%), demonstrating cross-domain gener-\nalisability. Privacy metrics remained robust (MIA resistance:\n0.87, DP strength: 0.21), validating clinical utility across\nsensitive medical specialties.\nLevel 1\nLevel 2\nLevel 3\nLevel 4\nLevel 5\n0\n20\n40\n60\n80\n100\n25.2\n23.8\n22.5\n20.9\n24.1\n68.5\n72.3\n65.9\n61.2\n58.7\n97.8\n95.3\n92.7\n89.5\n86.2\nSurgical Knowledge\nBasic Facts\nConcepts\nProcedures\nRelationships\nPrinciples\nKnowledge Hierarchy Level\nShared Concepts\nGeneral Medical Knowledge\nPreservation Rate (%)\nRetention Target Threshold\nUnlearning Target Threshold\n85\n30\nFig. 4.\nConcept preservation performance across different knowledge hi-\nerarchy levels. Surgical knowledge shows consistent reduction across all\nlevels, while general medical knowledge maintains high preservation rates,\nparticularly at lower hierarchy levels, confirming the effectiveness of our\nhierarchical unlearning strategy.\nG. Clinical Deployment Implications\nThe framework enhances clinical deployment through: (1)\nLiability Mitigation, enabling safe triage by unlearning L4\nsurgical procedures (e.g., tumor resections) while retaining\nL2 diagnostics; (2) Compliance & Governance, documenting\ndata provenance and supporting an end-to-end audit trail from\nrevocation requests to verified updates, facilitating precise\nremoval of patient data for GDPR/HIPAA mandates without\ncompromising general reasoning [40] or mishandling inter-\ntwined private information [37]; and (3) Cost-Effective Up-\ndates, where minimal parameter modification (0.1%) permits\nrapid adaptation to changing policies without the downtime of\ncomplete retraining.\nH. Limitations\nLimitations include: (1) computational overhead from per-\ntoken differential privacy and token interventions during train-\ning; (2) evaluation difficulty, as automated metrics lack the\nnuance of scalable human expert review for medical safety;\nand (3) hallucination risks, where aggressive unlearning may\ndisrupt adjacent knowledge structures, potentially inducing\nconfabulations.\nVI. CONCLUSION\nThis work presents a hierarchical dual-strategy frame-\nwork for selective unlearning in medical LLMs, integrating\ngeometric-constrained gradient updates and concept-aware to-\nken interventions through a four-level hierarchy. This enables\nprecise knowledge removal whilst preserving fundamental\ncompetencies even with imperfect data.\nEvaluations on MedMCQA and MHQA show superior\nunlearning performance (82.7% forgetting rate, 88.5% preser-\nvation) with only 3.1% modifications. The framework effec-\ntively handles annotation noise, data imbalance, and domain\nsubjectivity.\nThis work advances unlearning for managing privacy-\nsensitive medical data while ensuring regulatory adherence.\nCrucially, it supports hospital audit compliance and selective\n"}, {"page": 9, "text": "9\ncase retraction requests, positioning the framework as a robust\nsolution for weakly supervised medical AI.\nREFERENCES\n[1] J. Huo, Y. Yan, X. Zheng, Y. Lyu, X. Zou, Z. Wei, and X. Hu,\n“MMUnlearner: Reformulating multimodal machine unlearning in the\nera of multimodal large language models,” in Findings of the Association\nfor Computational Linguistics: ACL 2025, Vienna, Austria, Jul. 2025,\npp. 7190–7206, ISBN 979-8-89176-256-5.\n[2] T. Tran, R. Liu, and L. Xiong, “Tokens for learning, tokens for\nunlearning: Mitigating membership inference attacks in large language\nmodels via dual-purpose training,” arXiv preprint arXiv:2502.19726,\n2025.\n[3] P. Joshi et al., “MHQA: A diverse, knowledge intensive mental health\nquestion answering challenge for language models,” arXiv preprint\narXiv:2502.15418, 2025.\n[4] K. Zhang, F. Ge, B. Wang, Y. Chen, K. Kobayashi, L. Gu, J. Bi, and Y.\nZhu, “Rep-GLS: Report-guided generalized label smoothing for robust\ndisease detection,” arXiv preprint arXiv:2508.02495, 2025.\n[5] J. Geng, Q. Li, H. Woisetschlaeger, Z. Chen, Y. Wang, P. Nakov,\nH.-A. Jacobsen, and F. Karray, “A comprehensive survey of ma-\nchine unlearning techniques for large language models,” arXiv preprint\narXiv:2503.01854, 2025.\n[6] J. Jang, S. Lee, and S. Hwang, “Knowledge unlearning for mitigating\nprivacy risks in language models,” in Proc. 60th Annu. Meeting Assoc.\nComput. Linguistics, 2022, pp. 1750–1765.\n[7] Y. Yao, R. Jia, Y. Cao, and N. Z. Gong, “SUGD: Sequence unlearning\nvia gradient descent in language models,” in Proc. 2024 Conf. Empirical\nMethods Natural Language Process., 2024, pp. 1234–1248.\n[8] I. Premptis, M. Lymperaiou, G. Filandrianos, O. M. Mastromichalakis,\nA. Voulodimos, and G. Stamou, “AILS-NTUA at SemEval-2025 Task\n4: Parameter-efficient unlearning for large language models using data\nchunking,” in Proc. 19th Int. Workshop Semantic Eval. (SemEval-2025),\n2025, pp. 1383–1405.\n[9] C.\nFan,\nJ.\nLiu,\nY.\nZhang,\nE.\nWong,\nD.\nWei,\nand\nS.\nLiu,\n“SalUn:\nEmpowering\nmachine\nunlearning\nvia\ngradient-based\nweight saliency in both image classification and generation,” in\nInt.\nConf.\nLearning\nRepresentations,\n2024.\n[Online].\nAvailable:\nhttps://openreview.net/forum?id=gn0mIhQGNM\n[10] Z. Huang, X. Cheng, J. Zheng, H. Wang, Z. He, T. Li, and X. Huang,\n“Unified gradient-based machine unlearning with remain geometry en-\nhancement,” Advances Neural Inf. Process. Syst., vol. 37, 2024.\n[11] F. Tram`er, G. Kamath, and N. Carlini, “Position: Considerations for\ndifferentially private learning with large-scale public pretraining,” in\nProc. 41st Int. Conf. Machine Learning, vol. 235, Jul. 2024, pp. 48453–\n48467.\n[12] Y. Huang and C. L. Canonne, “Tight bounds for machine unlearning via\ndifferential privacy,” arXiv preprint arXiv:2309.00886, 2023.\n[13] Z. Yu, A. Gupta, D. Sadigh, and Y. Jin, “Differentially private machine\nunlearning for linear models,” in Int. Conf. Machine Learning, 2022, pp.\n25743–25759.\n[14] S.-Y. Liu, C.-Y. Wang, H. Yin, P. Molchanov, Y.-C. F. Wang, K.-\nT. Cheng, and M.-H. Chen, “DoRA: Weight-decomposed low-rank\nadaptation,” in Proc. 41st Int. Conf. Machine Learning, vol. 235, 2024.\n[15] W. Li, Y. Gao, Y. Ding, L. Lyu, Z. Dou, Y. Huang, and M. Jiang, “DP-\nAdapter: Privacy-preserving adaptation of large language models,” in\nFindings Assoc. Comput. Linguistics: EMNLP 2023, pp. 11876–11889,\n2023.\nJ. Hong et al., “DP-OPT: Make large language model your\nprivacy-preserving prompt engineer,” arXiv preprint arXiv:2312.03724,\n2024.\n[16] Y. Xiong, S. Ding, D. Ding, J. Rao, Z. Zhao, J. Huang, Z. Huang, and D.\nJiang, “Knowledge graph enhanced large language models for medical\nquestion answering,” arXiv preprint arXiv:2310.18376, 2023.\n[17] X. Chen, Y. Zhang, and W. Wang, “DR.KNOWS: Leveraging medical\nknowledge graphs into large language models for diagnostic reasoning,”\nJMIR AI, vol. 2, no. 1, pp. e58670, 2025.\n[18] J. Wang, Q. Zhang, H. Xu, Y. Li, and J. Chen, “Knowledge graph-based\nthought: A framework for pan-cancer biomarker discovery using large\nlanguage models,” GigaScience, vol. 13, pp. giae082, 2025.\n[19] data transformations,” in Findings of the Association for Computational\nLinguistics: EMNLP 2024, Miami, Florida, USA, Nov. 2024, pp. 12100–\n12119.\n[20] K. Z. Liu and J. Zou, “LLM unlearning via loss adjustment with only\nforget data,” arXiv preprint arXiv:2410.10460, 2024.\n[21] S. Khan, P. Rajpurkar, and A. Y. Ng, “Med42 – Evaluating fine-tuning\nstrategies for medical LLMs,” arXiv preprint arXiv:2404.14779, 2024.\n[22] P. Maini, Z. Feng, A. Schwarzschild, Z. C. Lipton, and J. Z. Kolter,\n“TOFU: A task of fictitious unlearning for LLMs,” arXiv preprint\narXiv:2401.06121, 2024.\n[23] N. Li et al., “The WMDP benchmark: Measuring and reducing malicious\nuse with unlearning,” in Proc. 41st Int. Conf. Machine Learning, pp.\n28525–28550, 2024.\n[24] T. Shaik, X. Tao, L. Li, H. Xie, T. Cai, X. Zhu, and Q. Li,\n“FRAMU: Attention-based machine unlearning using federated rein-\nforcement learning,” IEEE Trans. Knowledge Data Eng., vol. 36, no.\n10, pp. 5153–5167, 2024, doi: 10.1109/TKDE.2024.3382726.\n[25] L. Wang, T. Guo, H. Gao, X. Li, and K.-F. Zhang, “KGA: A general\nmachine unlearning framework based on knowledge gap alignment,”\narXiv preprint arXiv:2305.06535, 2023.\n[26] B. Kulynych, J. F. Gomez, G. Kaissis, F. Calmon, and C. Troncoso,\n“Attack-aware noise calibration for differential privacy,” Advances Neu-\nral Inf. Process. Syst., vol. 37, 2024.\n[27] W. Chen, X. Li, and Q. Yang, “Dual calibration-based personalised\nfederated learning,” in Proc. Thirty-Third Int. Joint Conf. Artificial\nIntelligence, 2024.\n[28] Y. Wang, H. Li, and Q. Zhang, “Prior-itizing privacy: A Bayesian\napproach to setting the privacy budget in differential privacy,” Advances\nNeural Inf. Process. Syst., vol. 37, 2024.\n[29] B. Li, W. Wang, and P. Ye, “The limits of differential privacy in online\nlearning,” Advances Neural Inf. Process. Syst., vol. 37, 2024.\n[30] K. Singhal et al., “Large language models encode clinical knowledge,”\nNature, vol. 620, pp. 172–180, 2023.\n[31] Adversarial training for disease prediction from electronic health records\nwith missing data,” arXiv preprint arXiv:1711.04126, 2018.\n[32] S. A. Lee, A. Wu, and J. N. Chiang, “Clinical ModernBERT: An\nefficient and long context encoder for biomedical text,” arXiv preprint\narXiv:2504.03964, 2025.\n[33] M. Yasunaga, J. Leskovec, and P. Liang, “Deep bidirectional language-\nknowledge graph pretraining,” Advances Neural Inf. Process. Syst., vol.\n35, pp. 28678–28691, 2022.\n[34] X. Peng, G. Long, T. Shen, S. Wang, J. Jiang, and C. Zhang, “Med-\nical knowledge-augmented transformer for EHR prediction,” IEEE J.\nBiomedical Health Informatics, vol. 26, no. 5, pp. 2126–2137, 2022.\n[35] P. Valdeira, S. Wang, and Y. Chi, “Vertical federated learning\nwith missing features during training and inference,” arXiv preprint\narXiv:2410.22564, 2025.\n[36] K. Zhang, Q. Li, and S. Yu, “MvHo-IB: Multi-view Higher-Order\nInformation Bottleneck for Brain Disorder Diagnosis,” in Proc. Int. Conf.\nMed. Image Comput. Comput. Assist. Interv. (MICCAI), pp. 407–417,\n2025.\n[37] F. Han, J. Zhang, C. Deng, J. Tang, and Y. Liu, “Can LLMs Handle\nWebShell Detection? Overcoming Detection Challenges with Behavioral\nFunction-Aware Framework,” arXiv preprint arXiv:2504.13811, 2025.\n[38] T. Xu et al., “RSEF: Enhancing Fairness and Accuracy in Hematopoietic\nStem Cell Transplantation Survival Prediction Through Race-Stratified\nEnsemble Framework,” in Advanced Intelligent Computing Technology\nand Applications, Singapore: Springer Nature, 2025, pp. 13–24.\n[39] Y. Wang, K. Zhang, J. Huang, N. Yin, S. Liu, and E. Segal, “ProtoMol:\nEnhancing Molecular Property Prediction via Prototype-Guided Multi-\nmodal Learning,” arXiv preprint arXiv:2510.16824, 2025.\n[40] F. Han, X. Yu, J. Tang, D. Rao, W. Du, and L. Ungar, “ZeroTuning:\nUnlocking the Initial Token’s Power to Enhance Large Language Models\nWithout Training,” arXiv preprint arXiv:2505.11739, 2025.\n[41] K. Zhang, M. Wang, X. Shi, H. Xu, and C. Zhang, “EVA-Net: Inter-\npretable Brain Age Prediction via Continuous Aging Prototypes from\nEEG,” arXiv preprint arXiv:2511.15393, 2025.\n[42] T. Xu, C. Liu, K. Zhang, and J. Zhang, “Membership Inference Attacks\nAgainst Medical Databases,” in Proc. Int. Conf. Neural Inf. Process.\n(ICONIP), Singapore: Springer, 2024, vol. 1963.\n[43] F. Han, H. Cui, L. Guo, Z. Wang, and Z. Lyu, “Read Before You Think:\nMitigating LLM Comprehension Failures with Step-by-Step Reading,”\narXiv preprint arXiv:2504.09402, 2025.\n[44] M. Xie, T. Xu, Q. Tang, S. Yao, X. Zhang, and J. Du, “DAPE-BR:\nDistance-Aware Positional Encoding for Mitigating Object Hallucination\nin LVLMs,” in Findings Assoc. Comput. Linguistics: EMNLP 2025,\nSuzhou, China, 2025, pp. 8638–8649.\n[45] F. Zhang, G. Chen, H. Wang, and C. Zhang, “CF-DAN: Facial-\nexpression recognition based on cross-fusion dual-attention network,”\nComput. Vis. Media, vol. 10, no. 3, pp. 593–608, 2024.\n"}, {"page": 10, "text": "10\n[46] F. Zhang, G. Chen, H. Wang, J. Li, and C. Zhang, “Multi-scale video\nsuper-resolution transformer with polynomial approximation,” IEEE\nTrans. Circuits Syst. Video Technol., vol. 33, no. 9, pp. 4496–4506, 2023.\n"}]}