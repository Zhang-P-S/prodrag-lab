{"doc_id": "arxiv:2511.04506", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2511.04506.pdf", "meta": {"doc_id": "arxiv:2511.04506", "source": "arxiv", "arxiv_id": "2511.04506", "title": "Modeling Clinical Uncertainty in Radiology Reports: from Explicit Uncertainty Markers to Implicit Reasoning Pathways", "authors": ["Paloma Rabaey", "Jong Hak Moon", "Jung-Oh Lee", "Min Gwan Kim", "Hangyul Yoon", "Thomas Demeester", "Edward Choi"], "published": "2025-11-06T16:24:53Z", "updated": "2025-11-06T16:24:53Z", "summary": "Radiology reports are invaluable for clinical decision-making and hold great potential for automated analysis when structured into machine-readable formats. These reports often contain uncertainty, which we categorize into two distinct types: (i) Explicit uncertainty reflects doubt about the presence or absence of findings, conveyed through hedging phrases. These vary in meaning depending on the context, making rule-based systems insufficient to quantify the level of uncertainty for specific findings; (ii) Implicit uncertainty arises when radiologists omit parts of their reasoning, recording only key findings or diagnoses. Here, it is often unclear whether omitted findings are truly absent or simply unmentioned for brevity. We address these challenges with a two-part framework. We quantify explicit uncertainty by creating an expert-validated, LLM-based reference ranking of common hedging phrases, and mapping each finding to a probability value based on this reference. In addition, we model implicit uncertainty through an expansion framework that systematically adds characteristic sub-findings derived from expert-defined diagnostic pathways for 14 common diagnoses. Using these methods, we release Lunguage++, an expanded, uncertainty-aware version of the Lunguage benchmark of fine-grained structured radiology reports. This enriched resource enables uncertainty-aware image classification, faithful diagnostic reasoning, and new investigations into the clinical impact of diagnostic uncertainty.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2511.04506v1", "url_pdf": "https://arxiv.org/pdf/2511.04506.pdf", "meta_path": "data/raw/arxiv/meta/2511.04506.json", "sha256": "b85a7f83036f2d2f648a95a569c0a754edafb61b98b4c49b30bccc44a948c6ef", "status": "ok", "fetched_at": "2026-02-18T02:28:22.983613+00:00"}, "pages": [{"page": 1, "text": "Modeling Clinical Uncertainty in Radiology Reports:\nfrom Explicit Uncertainty Markers to Implicit Reasoning Pathways\nPaloma Rabaey1*, Jong Hak Moon2*, Jung-Oh Lee3, Min Gwan Kim4,\nHangyul Yoon2, Thomas Demeester1, Edward Choi2\n1Ghent University – imec, 2KAIST, 3Mount Sinai Hospital, 4Seoul National University Hospital\npaloma.rabaey@ugent.be, jhak.moon@kaist.ac.kr\n*Joint first authors.\nAbstract\nRadiology reports are invaluable for clinical decision-making and hold great potential for automated analysis when\nstructured into machine-readable formats. These reports often contain uncertainty, which we categorize into two dis-\ntinct types: (i) Explicit uncertainty reflects doubt about the presence or absence of findings, conveyed through hedging\nphrases. These vary in meaning depending on the context, making rule-based systems insufficient to quantify the\nlevel of uncertainty for specific findings; (ii) Implicit uncertainty arises when radiologists omit parts of their reasoning,\nrecording only key findings or diagnoses. Here, it is often unclear whether omitted findings are truly absent or simply\nunmentioned for brevity. We address these challenges with a two-part framework. We quantify explicit uncertainty by\ncreating an expert-validated, LLM-based reference ranking of common hedging phrases, and mapping each finding to\na probability value based on this reference. In addition, we model implicit uncertainty through an expansion framework\nthat systematically adds characteristic sub-findings derived from expert-defined diagnostic pathways for 14 common\ndiagnoses. Using these methods, we release Lunguage++, an expanded, uncertainty-aware version of the Lunguage\nbenchmark of fine-grained structured radiology reports. This enriched resource enables uncertainty-aware im-\nage classification, faithful diagnostic reasoning, and new investigations into the clinical impact of diagnostic uncertainty.\nKeywords: Radiology report, Chest X-ray, Clinical uncertainty, Diagnostic reasoning, Large language model\n1.\nMotivation and Related Work\nRadiology reports play a central role in clinical\ndecision-making, serving as the primary medium\nthrough which radiologists communicate their inter-\npretations and diagnostic impressions to referring\nphysicians. These reports influence downstream\ndiagnostic reasoning, and often determine treat-\nment trajectories. As AI models have been increas-\ningly used for both automated radiology report inter-\npretation and generation, structuring frameworks\nhave been developed to convert free-text reports\ninto machine-readable formats that can be used for\ntraining and evaluation (Moon et al., 2025; Wu et al.,\n2021; Jain et al., 2021; Khanna et al., 2023). A key\nchallenge that needs to be addressed is that ra-\ndiology reports inherently contain uncertainty.\nThis uncertainty arises in two distinct forms: ex-\nplicit uncertainty, expressed directly through the\nlanguage radiologists use to qualify their findings or\ndiagnoses (Bruno et al., 2017; Hobby et al., 2000),\nand implicit uncertainty, which emerges from the\nselective and often incomplete nature of what is\nrecorded in the report (Turner et al., 2021). Figure\n1 shows how these two forms of uncertainty appear\nin chest X-ray (CXR) reports, which are especially\nprone to contain uncertainty (Callen et al., 2020;\nIrvin et al., 2019).\nExplicit uncertainty arises when radiologists\nconvey doubt about the presence or absence of\na finding or diagnosis, typically through hedging\nphrases such as “probably”, “possible”, “suggest-\nHedging phrases convey\nexplicit uncertainty\nabout presence or\nabsence of findings.\nImplicit uncertainty \narises due to the \nomission of findings \nwhich are part of \ndiagnostic reasoning.\nExpert-defined\ndiagnostic pathway\npneumonia\nopacity\nfever\nLunguage++\npossible early developing\nright middle lobe pneumonia.\nthe lungs again are\nhyperinflated suggesting\nunderlying emphysema.\nCXR Report\nStructured CXR Report\nFinding\nAttribute(s)\nCertainty\nStatus\nProbability\npneumonia\nlocation: right\nmiddle lobe\ntentative\n-\n0.45\nlungs\nmeasurement:\nhyperinflated\ndefinitive\npositive\n1.00\nemphysema\n-\ntentative\n-\n0.62\nopacity\n-\ntentative\n-\n0.45\nfever\n-\ntentative\n-\n0.45\nLunguage\nLunguage++\nFigure 1: Two types of uncertainty in radiology re-\nports that we address during structuring, expand-\ning the Lunguage dataset of structured CXR reports to\nform Lunguage++. Explicit uncertainty is conveyed by\nhedging phrases that indicate tentative findings, whose\n(un)certainty we quantify with probabilities. Implicit un-\ncertainty stems from findings that are not explicitly men-\ntioned; we mitigate this by applying expert-defined diag-\nnostic pathways to expand stated diagnoses with their\ncharacteristic sub-findings.\ning”, or “may represent”, among many others. Prior\nwork examining these expressions has highlighted\ntheir prevalence, revealing the mention of uncertain\ndiagnoses in a high proportion of CXR reports (Irvin\net al., 2019; Moon et al., 2025). The use of hedging\nin radiology reports is deliberate and meaningful:\nit enables radiologists to communicate diagnostic\narXiv:2511.04506v1  [cs.CL]  6 Nov 2025\n"}, {"page": 2, "text": "uncertainty that is crucial for appropriate clinical\ninterpretation and decision-making (Reiner, 2018;\nBruno et al., 2017). Automated systems should\nsimilarly be designed to recognize and account for\nthis uncertainty, just as human readers of radiology\nreports are trained to do.\nPrevious work has extracted uncertainty using\nrule-based systems (Irvin et al., 2019; Johnson\net al., 2019a; Zhang et al., 2023) in ternary clas-\nsification settings (positive / uncertain / negative).\nThese approaches are limited in scope, using pre-\ndefined vocabularies of hedging phrases that trig-\nger an uncertain label when detected in the re-\nport. In this work, we go beyond discrete label-\ning by quantifying uncertainty as a continuous\nprobability between 0 and 1, taking into account\nthe specific hedging phrases and their sentence-\nlevel context (see Figure 1). Earlier attempts to as-\nsign probabilistic meanings to hedging expressions\nhave typically relied on human judgments, asking\nexperts to rate phrases or position them along a\nscale of certainty (Hobby et al., 2000; Shinagare\net al., 2019). However, these approaches proved\nunreliable, as the interpretation of hedging varies\nwidely across radiologists. To address this, we in-\ntroduce an automated approach that estimates the\nprobability of a finding by leveraging large language\nmodels to perform pairwise comparisons of uncer-\ntainty expressions, constructing a relative ranking\nthat is then mapped to a continuous probability.\nBeyond overt language, reports also embody\na subtler form of implicit uncertainty that has\nreceived little systematic attention. Radiologists\nfrequently omit portions of their diagnostic rea-\nsoning, documenting only key findings or final\nimpressions to maintain conciseness and ensure\nthat the main message is easily understood by\nthe reader (Lee et al., 2013). For example, a re-\nport may state “congestive heart failure” without\nmentioning sub-findings that are commonly associ-\nated with the condition, such as “consolidation” or\n“cardiomegaly”. Consequently, it is often unclear\nwhether unmentioned findings are truly absent or\nsimply unrecorded, even though knowing this dis-\ntinction is crucial, since misinterpreting unrecorded\nevidence as true absence can systematically bias\nthe data and distort the inferred diagnostic reason-\ning (Gärtner et al., 2020; Lee et al., 2013; Gunder-\nman, 2009; Berlin, 2000).\nIn other words, implicit uncertainty does not stem\nfrom linguistic ambiguity, but from the selective and\nincomplete nature of clinical reporting (Turner et al.,\n2021) – what evidence is stated, abstracted, or\nleft unstated within the report. Disentangling these\npossibilities requires contextual understanding of\ndiagnostic logic and domain expertise, making im-\nplicit uncertainty difficult to model and largely un-\naddressed in prior research. Understanding and\nmodeling these uncertainties is not only critical for\nstructuring radiology reports but also for develop-\ning AI systems that faithfully capture the reasoning\nprocess of radiologists. By explicitly representing\nboth what is uncertain and what is implied, such\nstructured resources enable more reliable training\nand evaluation of medical AI models in uncertainty-\naware report generation and interpretation.\nTo address this gap, we aim to fill in the missing\nfindings that are not explicitly mentioned but are\nimplied by the stated diagnoses when structuring\nradiology reports, as is shown in Figure 1. We con-\nstruct expert-defined diagnostic pathways for\n14 common CXR conditions, capturing character-\nistic sub-findings typically observed with high likeli-\nhood (>80%). These pathways are then used to en-\nrich the original reports by deterministically adding\nsub-findings that support explicitly mentioned diag-\nnoses, with diagnostic certainty (derived from our\nexplicit uncertainty extraction pipeline) propagated\nto each added finding. This approach results in\nexpanded structured reports that more accurately\nreflect the radiologist’s underlying reasoning.\nIn summary, our contributions are as follows:\n• Quantifying explicit uncertainty: We intro-\nduce a comprehensive framework to estimate\nthe probability of findings in radiology reports,\ntaking into account hedging phrases and their\nsentence-level context. As part of this frame-\nwork, we publish an expert-validated reference\nranking of common hedging phrases.\n• Addressing\nimplicit\nuncertainty:\nWe\npresent the first framework to model implicit\nuncertainty in radiology reports by releasing\ndiagnostic pathways for 14 common CXR diag-\nnoses and integrating them into a rule-based\nframework.\nThis framework reconstructs\nomitted diagnostic evidence by inferring the\nsub-findings that support each diagnosis.\n• Releasing Lunguage++, which extends the\nLunguage dataset of structured radiology re-\nports (Moon et al., 2025) by incorporating our\ntechniques for capturing explicit and implicit\nuncertainty.\nCode can be found at our Github repository1,\nwhile Lunguage++ and related resources will be\nmade available via Physionet.\n2.\nLunguage Dataset\nWe demonstrate our methods on the Lunguage\ndataset (Moon et al., 2025), a benchmark dataset\ncontaining 1,473 annotated CXR reports from the\nMIMIC-CXR dataset (Johnson et al., 2019b). Each\nreport has been structured into fine-grained (finding,\nrelation, attribute) triplets, where findings represent\ncore clinical concepts (e.g. “opacity”, “pneumo-\nnia”), and relations specify their contextual links\n1github.com/prabaey/lunguage_uncertainty\n"}, {"page": 3, "text": "(e.g., “location”, “severity”) with corresponding at-\ntributes (e.g., “right lower lobe”, “moderate”). We\nuse the Lunguage dataset because of its extensive\ngranularity in the included findings, relations and\nattribute types. Furthermore, each annotated find-\ning includes a binary label (tentative and definitive)\nquantifying the confidence expressed by the radiol-\nogist – hedging phrases (e.g., “suggests”, “cannot\nexclude”) lead to a tentative label, while findings\nthat lack such phrases are labeled definitive.\nIn this work, we represent each report R as a\nstructured set of nR findings extracted from mR\nsentences:\nR = ({(fi, si, ci, ai)}nR\ni=1, {tj}mR\nj=1),\n(1)\nHere, tj denotes the textual form of each sentence,\nfi indicates the finding, si indicates the status\n(positive if the finding is present and negative if it\nis absent), ci indicates the certainty (definitive or\ntentative), and ai represents the attributes (e.g.,\nlocation, morphology) associated with each finding.\nIn Lunguage, there are 14,049 such structured find-\nings. In our study, we exclude sentences from the\nhistory section of the reports, as this section primar-\nily contains information about patient symptoms or\nprior clinical records, whereas our analysis focuses\non the findings and impression sections that convey\ndiagnostic observations and reasoning.\n3.\nExplicit uncertainty\nWe assume we have a report R, where the sen-\ntence tj expresses some uncertainty about finding\nfi, in other words ci = tentative. Across all re-\nports in Lunguage, this leaves us with a subset of\n2,066 tentative finding-sentence pairs. Our goal is\nto quantify this uncertainty by assigning a proba-\nbility pi between 0 (finding certainly absent) and 1\n(finding certainly present). In the remainder of this\nsection, we ignore the explicit status si, as the tar-\nget probability pi inherently captures the presence\nor absence of the finding. Furthermore, we disre-\ngard all findings where ci = definitive, as there is\nno uncertainty in this case. From this point onward,\na sentence refers to the complete text tj, which con-\ntains a target finding fi (e.g. “pneumonia”) and one\nor more corresponding (hedging) phrase(s) (e.g.,\n“possible”), expressing the degree of uncertainty\nassociated with fi.\nPrevious attempts to map hedging phrases to\nprobabilities relied on expert ratings of individual\nphrases, an approach shown to be unreliable due\nto inconsistency across experts (Hobby et al., 2000;\nShinagare et al., 2019). Furthermore, the context\nof the sentence beyond individual phrases should\nbe taken into account: “probably pneumonia” con-\nveys a different certainty than “probably pneumonia\ngiven patient history”, even though both use the\nphrase “probably”. To address these limitations,\nwe adopt a different strategy, which relies on large\nlanguage models (LLMs) to perform in-context pair-\nwise comparisons between sentences conveying\nuncertainty. An overview of our framework is shown\nin Figure 2. We now describe each step of the pro-\ncess in detail. Additional details can be found in\nAppendix A.\n3.1.\nExtracting a vocabulary of common\nhedging phrases\nFor each finding-sentence pair, we automatically\nextract the hedging phrases that convey uncertainty\nabout the finding fi. We do this by prompting Gem-\nini (Comanici et al., 2025). The main part of the\nprompt is shown in Listing 1, while the full prompt\ncontains a system message, ten in-context exam-\nples and additional instructions (see Appendix A.1).\nThe prompt specifies the finding fi to avoid extrac-\ntion of hedging phrases from the sentence which\nhave nothing to do with that particular finding. We\ninclude in our vocabulary all hedging phrases that\nwere extracted ten times or more, resulting in a\nvocabulary of 42 hedging phrases. Each phrase\nis associated with a list of finding-sentence pairs\nwhere it was extracted. The five most common\nextracted hedging phrases include or (373 times),\nlikely (239 times), may (215 times), suggesting (74\ntimes), and cannot be excluded (71 times); the full\nvocabulary is found in Appendix A.1.\nListing 1: Prompt for hedging phrase extraction\nYour task is to identify and extract only the words\nor phrases in the sentence that express\nuncertainty specifically about the given\nfinding.\n3.2.\nBuilding a reference ranking of\nhedging phrases\nWe construct a reference ranking of the 42 common\nhedging phrases, where the top rank corresponds\nto a probability near 1 and the bottom rank near 0.\nTrueSkill\nWe draw inspiration from ranking sys-\ntems in competitive gaming, where player skill is\ninferred from the outcomes of matches. Specifi-\ncally, we employ the TrueSkill algorithm (Herbrich\net al., 2006), a Bayesian rating system that updates\neach item’s mean skill level µ based on pairwise\ncomparisons with other items. This way, TrueSkill\nefficiently infers a global ranking that reflects the\nrelative skill level µ of each item. In our case, the\nitems are hedging phrases.\nLLM as a judge\nTo obtain a reliable and well-\ncalibrated ranking, a large number of pairwise\ncomparisons between phrases is required. We\ntherefore leverage LLMs to perform these com-\nparisons automatically, employing three general-\npurpose LLMs (Gemini (Comanici et al., 2025),\n"}, {"page": 4, "text": "3.1. Extracting a vocabulary of 42 common hedging phrases\nLunguage\n(structured\nMIMIC-CXR\nreports)\npossible early developing \nright middle lobe pneumonia\nfinding\nPrompt: \"Extract the phrases in the sentence\nthat express uncertainty about the given finding.\"\n2066 finding-sentence pairs\nwith tentative certainty\npossible\npossible\n{\"possible early developing right\nmiddle lobe pneumonia.\",..., \"patient\nhad mild pulmonary edema and possible\natelectasis.\"}\nsuggesting\n{\"lungs are hyperinflated suggesting\nthe presence of copd.\",..., \"findings\nsuggesting vascular congestion,\nseemingly improved.\"}\n...\n3.2. Building a reference ranking of hedging phrases\nvs.\nlungs are hyperinflated\nsuggesting present <finding>\nsuggesting\npossible early developing \nright middle lobe <finding>\npossible\nPrompt: \n\"Which of the\ntwo phrases\nindicates that\n<finding> is\nmore certainly\npresent?\"\nRepeat 10 times for each pair of hedging\nphrases in the vocabulary (861 pairs), with\nrandomly selected example sentences.\npossible\n...\n...\nsuggesting\n...\n...\npossible\n...\n...\nlikely\n...\n...\nappears\n...\n...\nif any\n...\n...\n...\n...\nUse the pairwise\ncomparisons to\ndetermine relative\nscores , building a\nreference ranking of\nhedging phrases.\nReference\nVocabulary\nMost likely\nAppears to be\nIf any\nLess likely\nSuggesting\n1.\n2.\n41.\n42.\n14.\n0.84\n0.17\n...\n...\nFinding\nalmost\ncertainly\npresent\nFinding\nalmost\ncertainly\nabsent\n3.4. Map to probability scale by transforming\nscore  into probability  with a sigmoid\ntransformation, anchored by radiologist knowledge.\n...<finding> may...\nappears\n...\n...\n3.3. Ranking each finding-sentence pair based on reference\n...<finding> may...\nif any\n...\n...\n...<finding> may...\nsuggesting\n...\n...\n...\n...\nFit a sentence into the\nreference ranking by\niteratively comparing\nagainst hedging phrases\nwith similar .\nthe <finding> may be hyperinflated\nFigure 2: Strategy for assigning probabilities to finding-sentence pairs with tentative certainty in the Lunguage\ndataset: We first build a vocabulary of common hedging phrases and the sentences in which these are used\n(Section 3.1). Next, we leverage LLMs to construct a reference ranking of these phrases, by performing pairwise\ncomparisons of examples sentences (Section 3.2). Each finding-sentence pair is then compared against this reference\n(Section 3.3) and is finally mapped to a probability (Section 3.4). This approach ensures that the probability assigned\nto each finding reflects not only the hedging phrase itself but also the broader context in which it appears.\nGPT-4o (Hurst et al., 2024), and Claude (An-\nthropic, 2025)) and one domain-specific medical\nLLM (MedGemma (Sellergren et al., 2025)).2 Since\nthe preferred phrase can vary depending on the\nsentence context, we conduct ten comparisons\nfor each pair of the 42 hedging phrases, where in\neach comparison, we randomly sample a sentence\nin which the phrase occurs. We ask each LLM\nto identify which phrase conveys greater certainty\nabout the presence of a finding, ensuring that such\nphrases will eventually receive a higher µ. The\nmain portion of the prompt is shown in Listing 2;\nthe complete prompt additionally includes a sys-\ntem instruction, detailed task description, and three\nin-context examples (Appendix A.2). To ensure a\nmore neutral comparison, the referenced finding fi\nwithin each sentence is masked as <finding>.\nListing 2: Prompt for hedging phrase comparison\nYou will be given two sentences from radiology\nreports. Each sentence contains a placeholder <\nfinding>, which represents a medical\nobservation. Your task is to identify which\nsentence expresses a higher degree of certainty\nthat the finding is present.\n2To deal with the sensitive nature of the reports in\nLunguage we (i) ran a HIPAA-compliant GPT-4o model\nprovided by Azure, (ii) revoked data retention rights for\nGemini and Claude, and (iii) ran MedGemma locally.\nExpert\nRef.\nGemini\nGPT-4o\nClaude\nMedGem.\nRadiologist\n0.80\n0.80\n0.82\n0.72\n0.84\nRadiologist\n0.80\n0.76\n0.82\n0.76\n0.80\nInternist\n0.86\n0.86\n0.88\n0.82\n0.90\nOncologist\n0.72\n0.68\n0.74\n0.76\n0.72\nGP\n0.66\n0.70\n0.68\n0.66\n0.62\nGP\n0.82\n0.82\n0.84\n0.78\n0.82\nAverage\n0.78\n0.77\n0.80\n0.75\n0.77\nTable 1: Expert agreement with the reference ranking\nand individual LLMs. We define agreement as the\nproportion of the 50 phrase pairs where expert and model\njudgments are concordant. GP = General Practitioner.\nThis procedure yields 4 × 8610 pairwise compar-\nisons, each treated as an independent comparison\nby the TrueSkill algorithm. We execute TrueSkill\n10 times with different random seeds that affect\nthe order of matches, and then average the re-\nsulting µ values across runs. The final averaged\nscores produce a stable reference ranking of hedg-\ning phrases, which is shown in Figure 3. Appendix\nA.2 assesses the robustness of this reference rank-\ning and explores inter-LLM agreement across the\nset of comparisons.\nExpert evaluation\nTo validate the final reference\nranking, we conducted an expert evaluation study.\nWe recruited two expert writers (radiologists) and\nfour expert readers (internist, oncologist, and two\ngeneral practitioners). Each participant was pre-\n"}, {"page": 5, "text": "Figure 3: Reference ranking of the 42 common hedg-\ning phrases in our vocabulary. The mean skill level µ\nfor each phrase is shown on the right, with the confidence\nσ represented by the error bars. Phrases at the top of the\nranking correspond to a high likelihood that the finding\nis present, while phrases at the bottom correspond to a\nhigh likelihood that the finding is absent.\nsented with 50 pairs of hedging phrases, with five\nexample sentences per phrase, all randomly sam-\npled from our vocabulary. Participants were asked\nto select the phrase that conveyed a higher degree\nof certainty that the finding was present. All partici-\npants evaluated the same set of 50 phrase pairs.\nSee Appendix A.2 for additional details.\nTable 1 presents the agreement between each\nexpert and the reference ranking. Agreement is\ndefined as the proportion of phrase pairs (out of 50)\nfor which the expert’s relative ordering of the two\nphrases matches that of the reference. In addition,\nwe assess the agreement between each expert and\neach LLM. Since each LLM evaluated every phrase\npair ten times using different example sentences,\nwe first derive a consensus decision for each pair\nthrough majority voting, resolving ties at random.\nWe see that the experts agree well with both the\nreference ranking and the individual LLMs. Further-\nmore, the inter-expert Fleiss’ κ is 0.72, indicating\nsubstantial agreement between experts. Among\nindividual LLMs, GPT-4o shows the highest agree-\nment with the experts, while Claude shows the\nlowest. Despite Claude’s lower agreement on this\nlimited subset of 50 pairs, we retain all LLMs in\nthe reference ranking, to leverage the diversity of\njudgments across models, thereby improving the ro-\nbustness of the TrueSkill-based ranking. Moreover,\nthe expert evaluation covers only a small fraction\nof the full dataset and uses a different evaluation\nprotocol than the sentence-level LLM comparisons,\nso occasional disagreements by a single LLM are\nnot sufficient reason for exclusion.\n3.3.\nRanking each finding-sentence pair\nbased on the reference ranking\nWith the reference ranking established, we fit each\nof the 2,066 tentative finding-sentence pairs from\nthe Lunguage dataset into it. Note that we cannot\nsimply use the hedging phrases extracted from the\nsentence to assign a rank directly, because (i) some\nphrases are too rare to appear in the reference vo-\ncabulary, and (ii) the context in which a phrase\noccurs can significantly alter its implied certainty.\nHere, we once again draw inspiration from compet-\nitive gaming: when a new player enters a game,\nTrueSkill quickly estimates their rank by identifying\nexisting players with similar skill levels µ. This is\ndone by selecting opponents with the highest draw\nprobability, iteratively playing those games, and up-\ndating the skill level of the new player based on the\noutcome of each game (Herbrich et al., 2006).\nTo fit a finding–sentence pair into the reference\nranking, we initialize the target sentence’s param-\neter µ to the default value of 25 and compute its\ndraw probability against all opponent phrases in\nthe reference ranking. The phrase with the highest\ndraw probability is selected, and a corresponding\nsentence is randomly sampled from the vocabu-\nlary. Using the prompt from Listing 2, the target\nand opponent sentence are compared. During the\nfirst K = 10 iterations, all four LLMs perform the\ncomparison; thereafter, one LLM is selected at ran-\ndom to reduce cost. Based on the outcome, the\nTrueSkill algorithm updates µ for the target sen-\ntence. Draw probabilities are then recomputed,\nand the next opponent is selected accordingly, with\neach opponent limited to N = 5 comparisons. The\nprocedure terminates once the target sentence’s\nrank remains stable for ten consecutive steps, or af-\nter 100 iterations, whichever occurs first. Through\nhyperparameter tuning, we set K to 10 and N to\n5. Applying our algorithm to the 2,066 tentative\nfinding-sentence pairs in Lunguage incurred a to-\ntal cost of $92.16, averaging $0.045/pair. The full\nalgorithm, including experiments to validate our op-\nponent selection strategy using draw probability,\ncan be found in Appendix A.3.\n3.4.\nMap to probability scale\nIn the final step, we map the TrueSkill score µ,\nwhich determines the position of each finding-\nsentence pair in the ranking, to a probability p ∈\n[0, 1]. This transformation is achieved using the\nsigmoid function p = 1/(1 + e−α(µ−µ0)), where α\n"}, {"page": 6, "text": "controls the steepness of the curve and µ0 is the\ninflection point corresponding to a probability of 0.5.\nWe determine α and µ0 using two anchor points:\nthe desired probability pbottom for the phrase less\nlikely (lowest-ranked, µ = 7.07), and ptop for the\nphrase most likely (highest-ranked, µ = 43.44).\nTo obtain these anchors, two radiologists inde-\npendently reviewed ten example sentences per\nphrase and assigned a probability between 0 (“cer-\ntainly absent”) and 1 (“certainly present”); see Ap-\npendix A.4 for full instructions. Averaged across\nradiologists and examples, the resulting values\nwere pbottom = 0.170 (95% CI: [0.156, 0.185]) and\nptop = 0.839 (95% CI: [0.818, 0.860]). These an-\nchors yield α = 0.089 and µ0 = 24.89.\nAfter applying this mapping, the average proba-\nbility for the 2,066 tentative finding-sentence pairs\nin Lunguage is 0.459, with a standard deviation\nof 0.185, a maximum of 0.892, and a minimum of\n0.102. Table 2 summarizes statistics for common\nCXR findings in the Lunguage dataset. For each\nfinding, we report proportions of positive and nega-\ntive cases with definitive certainty, and the mean,\nstandard deviation, minimum, and maximum prob-\nability for cases with tentative certainty.\n4.\nImplicit uncertainty\nRadiology reports often encode diagnostic reason-\ning implicitly (Gunderman, 2009; Lee et al., 2013;\nBerlin, 2000; Gärtner et al., 2020), documenting\nhigh-level diagnoses while omitting intermediate\nsupporting findings. Although such abstraction en-\nhances efficiency, it introduces ambiguity arising\nfrom unmentioned findings. To resolve this, we\npropose a Pathway Expansion Framework that\nreconstructs omitted diagnostic evidence by sys-\ntematically expanding structured findings along pre-\ndefined diagnostic pathways. This framework\nyields Lunguage++, an expanded version of Lun-\nguage, integrating explicit and implicit reasoning\ninto a unified structured representation (Figure 4).\n4.1.\nDiagnostic Pathway Construction\nWe formalize radiologists’ implicit diagnostic rea-\nsoning into explicit, machine-friendly formats that\ndescribe how each diagnosis decomposes into its\ncharacteristic radiographic findings. To preserve\ninterpretability and clinical fidelity, we established\nthree principles through expert consensus. (i) Ex-\nclusive mutual independence ensures that each\npathway differs from others by at least one defin-\ning piece of evidence. (ii) Specificity ensures that\nobservations directly contributing to diagnostic dif-\nferentiation are included, emphasizing findings that\nare concrete and fine-grained. (iii) High-certainty\nfeatures retain only clinically consistent and reli-\nable findings to minimize ambiguity and preserve\nclarity. Pathways were then constructed through a\ntwo-stage expert-in-the-loop process grounded in\nthese principles. A radiologist and an AI researcher\nfirst defined subfindings for 14 common CXR diag-\nnoses, referencing established radiological interpre-\ntation principles (Goodman, 2014; Webb and Hig-\ngins, 2011) to identify diagnostic criteria, imaging\npatterns, and hierarchical relations among findings.\nThese preliminary pathways were subsequently re-\nviewed and refined through consensus by another\nradiologist and an oncologist.\nPathways are represented as Directed Acyclic\nGraphs (DAGs) (Pearl, 2009), capturing how higher-\nlevel diagnoses require lower-level manifestations\nwithin hierarchical reasoning. An example of a\nDAG corresponding to (part of) the diagnostic\npathways for congestive heart failure (CHF), pul-\nmonary edema, pleural effusion, and cardiomegaly\nis shown in Figure 4. Each node corresponds to an\nobservable finding, and directed edges (u, v) rep-\nresent diagnostic relations ppath(v|u) established\nthrough radiologist consensus, indicating that the\nsub-finding v is typically observed when its parent u\nis present, with likelihood greater than 0.8. This top-\ndown structure models the cascading sequence of\nradiographic evidence that underlies diagnostic in-\nference. Distinct pathways are defined for each\ndiagnosis and further refined by imaging view and\npatient position, since these factors influence the\nfindings one expects to observe. Table 3 reports\nstatistical summaries of the diagnostic pathways,\nwhile the full set of pathways is provided in Ap-\npendix B.1 and on our Github repository.\n4.2.\nPathway Expansion Framework\nBuilding upon the diagnostic pathways, we design\na Pathway Expansion Framework that implements\nthe top-down reasoning process of radiological in-\nterpretation to fill in missing sub-findings. Given\nstructured findings from Lunguage (Moon et al.,\n2025), the framework reconstructs omitted interme-\ndiate findings by expanding each diagnosis along\nits predefined diagnostic pathway, following the re-\ncursive procedure detailed in Algorithm 1. It con-\nsists of four stages, each of which ensure that re-\nconstructed structures remain clinically faithful and\nlogically consistent.\n1. Finding Deduplication\nTo ensure that sub-\nsequent reasoning operates on a consistent and\nnon-redundant set of findings, overlapping or syn-\nonymous mentions referring to the same diagnostic\nconcept at the same location (e.g., “opacity in the\nbasal segment of the lung” and “lung base opacity”)\nare identified and merged within each report. Pair-\nwise cosine similarity is computed between clinical\nembeddings (BioLORD (Remy et al., 2023)) of all\nreport findings, where each finding is linearized into\na phrase combining its “entity, location, attributes”\nfollowing the LunguageScore (Moon et al., 2025)\n"}, {"page": 7, "text": "Certainty level\nDefinitive status\nTentative probability\nFinding\nDefinitive\nTentative\nPositive\nNegative\nAvg.\nStd.\nMin.\nMax.\nPleural effusion\n1165 (86.2%)\n186 (13.8%)\n497 (42.7%)\n668 (57.3%)\n0.465\n0.201\n0.102\n0.862\nPneumothorax\n897 (98.8%)\n11 (1.2%)\n43 (4.8%)\n854 (95.2%)\n0.480\n0.151\n0.269\n0.709\nAtelectasis\n419 (62.2%)\n255 (37.8%)\n408 (97.4%)\n11 (2.6%)\n0.536\n0.156\n0.145\n0.876\nPulmonary edema\n516 (83.5%)\n102 (16.5%)\n264 (51.3%)\n252 (48.7%)\n0.479\n0.186\n0.102\n0.841\nConsolidation\n406 (84.1%)\n77 (15.9%)\n90 (22.2%)\n316 (77.8%)\n0.447\n0.182\n0.113\n0.808\nPneumonia\n225 (51.3%)\n214 (48.7%)\n32 (14.2%)\n193 (85.8%)\n0.423\n0.221\n0.102\n0.872\nCardiomegaly\n313 (97.8%)\n7 (2.2%)\n308 (98.4%)\n5 (1.6%)\n0.518\n0.141\n0.365\n0.706\nCongestive heart failure\n49 (89.1%)\n6 (10.9%)\n23 (46.9%)\n26 (53.1%)\n0.591\n0.248\n0.102\n0.765\nEmphysema\n40 (80.0%)\n10 (20.0%)\n40 (100.0%)\n0 (0.0%)\n0.518\n0.134\n0.314\n0.660\nCOPD\n18 (60.0%)\n12 (40.0%)\n18 (100.0%)\n0 (0.0%)\n0.537\n0.050\n0.453\n0.594\nFracture\n12 (85.7%)\n2 (14.3%)\n12 (100.0%)\n0 (0.0%)\n0.219\n0.165\n0.102\n0.336\nLung cancer\n6 (46.2%)\n7 (53.8%)\n6 (100.0%)\n0 (0.0%)\n0.531\n0.171\n0.249\n0.662\nTuberculosis\n3 (60.0%)\n2 (40.0%)\n2 (66.7%)\n1 (33.3%)\n0.413\n0.051\n0.377\n0.449\nBronchitis\n1 (50.0%)\n1 (50%)\n1 (100.0%)\n0 (0.0%)\n0.475\n0.000\n0.475\n0.475\nTable 2: Certainty statistics for common CXR findings in the Lunguage dataset. For each finding, we collect the\ninstances in Lunguage where fi is mapped to the finding through its various lexical and contextual variants, following\nthe approach described in Section 4.2 (Finding Deduplication).\nCXR Report\nView/Position: Erect PA\nAcute exacerbation of chf. There is moderate pleural effusion along with chronic\ncardiomegaly. New right infrahilar consolidation could be regional edema.\nEnlarged\nheart size\nOpacity\nNormal lung\nvolume\nCostophrenic\nangle blunting\nCongestive heart\nfailure\nCardiomegaly\nPulmonary edema\nEnlarged\nheart size\nConsolidation\nPleural effusion\nOpacity\nNormal lung\nvolume\nCostophrenic\nangle blunting\nTop-down DAG (High-level diagnosis to sub-findings)\nDiagnostic\npathways\n(Sec. 4.1)\nExpanded data (Sec. 4.3)\nCascading Expansion Framework (Sec. 4.2)\nFinding de-\nduplication\nMerge\nsemantically\nsimilar findings\n   Pathway expansion\n   Recursive expansion: Parent       Child \n   Propagation (Attributes + Certainty)\nPathway\nmatching\nFinding\nLocation\nAttribute\nImaging\nview\n1. Original \n Inferred\n2. Remove contradiction (\n vs. \n)\n3. Retain higher probability\nConflict resolution\nConflict detection:\nResolve:\nOrig.\nExp.\nExp.\nFigure 4: Overview of the Pathway Expansion Framework. The framework expands structured findings from\nLunguage along diagnostic pathways (Section 4.1) to reconstruct omitted diagnostic evidence. It comprises four\nstages—finding deduplication, pathway matching, pathway expansion, and conflict resolution (Section 4.2)—that\njointly ensure semantic coherence and clinical validity. The resulting representation connects high-level diagnoses\nwith their underlying evidence, forming Lunguage++, which is further analyzed in Section 4.3.\nformulation. Pairs exceeding a similarity thresh-\nold of 0.9 are merged into a single finding, while\nmanually defined blacklist pairs (e.g., left vs. right)\nare excluded to prevent erroneous merges of se-\nmantically distinct findings. This precision-oriented\nthreshold and manual blacklist correction minimize\nerroneous merges while ensuring that each finding\nis represented only once before expansion. The de-\ntailed blacklist pairs are provided in Appendix B.2.1.\n2. Pathway Matching\nAfter deduplication, the\nframework aligns each finding in Lunguage with its\nmost appropriate diagnostic pathway (Section 4.1)\nthrough a sequential process based on its finding,\nlocation, attributes, and imaging view. All terms are\nfirst normalized using the Lunguage vocabulary\nto ensure consistent terminology. The process be-\ngins with finding-level matching, which identifies the\ncore diagnostic concept but may yield ambiguous\ninterpretations. For instance, “fracture” can denote\neither a medical device fracture (e.g., pacemaker\nlead) or a thoracic skeletal fracture (e.g., rib, spine).\nSuch ambiguity is resolved through location match-\ning, which determines whether the finding pertains\nto an anatomical structure within the thorax or not,\nthereby selecting the appropriate pathway (e.g., de-\nvice vs. skeletal fracture). Subsequently, attribute\nmatching refines the alignment by specifying diag-\nnostic stages such as “acute”, “chronic”, or “healed”.\nFinally, imaging view and patient orientation (e.g.,\n“PA, erect”) define the view-specific pathway variant,\nensuring that inferred findings remain anatomically\nobservable within the imaging context. For the de-\ntailed process, see Appendix B.2.2.\n3. Pathway Expansion\nBuilding on the matched\ndiagnostic pathways, the framework recursively ex-\npands structured findings in Lunguage by inferring\nomitted sub-findings through parent–child relations\ndefined in each pathway (Algorithm 1). The expan-\n"}, {"page": 8, "text": "Diagnostic Pathway Structure\nExpansion within Lunguage†\nDiagnosis\nVariants\nPathways\nDepth\nWidth\nExpandable Finding\nInferred Sub-findings\nPleural effusion\n2\n10\n1\n3\n683 (4.9%)\n+915 (6.6%)\nAtelectasis\n7\n1\n1\n2\n663 (4.7%)\n+1,215 (8.6%)\nPulmonary edema\n12\n2\n2\n4\n366 (2.6%)\n+622 (4.4%)\nConsolidation\n4\n1\n1\n2\n167 (1.2%)\n+801 (5.7%)\nPneumonia\n22\n3\n2\n3\n249 (1.8%)\n+311 (2.2%)\nCardiomegaly\n1\n1\n1\n1\n315 (2.2%)\n+340 (2.4%)\nCongestive heart failure\n5\n1\n3\n6\n29 (0.2%)\n+79 (0.6%)\nPneumothorax\n5\n2\n1\n4\n54 (0.4%)\n+160 (1.1%)\nEmphysema\n6\n2\n1\n3\n50 (0.4%)\n+98 (0.7%)\nCOPD\n3\n1\n2\n5\n30 (0.2%)\n+88 (0.6%)\nFracture\n15\n4\n1\n5\n14 (0.1%)\n+25 (0.2%)\nLung cancer\n7\n1\n1\n1\n13 (0.1%)\n+12 (0.1%)\nTuberculosis\n5\n2\n1\n3\n4 (0.0%)\n+2 (0.0%)\nBronchitis\n4\n2\n1\n3\n2 (0.0%)\n+2 (0.0%)\nTotal / Avg.\n98\n33\n1.4\n3.2\n2,639 (18.7%)\n+4,761 (33.9%)\nTable 3: Statistics of Diagnostic Pathways and Lunguage++. The left panel summarizes the hierarchical structure\nof 14 expert-defined diagnostic pathways (98 variants, 33 unique DAGs). The right panel quantifies their application\nwithin the 14,049 structured findings in Lunguage. A total of 2,636 findings (18.7%) were eligible for expansion\n(i.e., directly aligned with a pathway node) serving as anchors for hierarchical reasoning. From these anchors, the\nframework inferred 4,761 additional sub-findings (+33.9%), representing previously implicit but clinically consistent\nobservations reconstructed from the pathway hierarchy. †Percentages are relative to the 14,049 original findings in\nLunguage. “+” denotes additional findings inferred during expansion.\nAlgorithm 1 Recursive Finding Expansion\nInput: Parent node fi in pathway P with si, ci, pi, ai\nOutput: Set E of all sub-findings expanded to leaf nodes\n1: function Expand(fi, si, ci, pi, ai, P)\n2:\nE ←∅\n3:\nif si ̸= positive then\n4:\nreturn ∅// Expand only positive findings\n5:\nend if\n6:\nfor fj where (fi, fj) ∈P do // For each child fj in P\n7:\n(sj, cj, pj) ←(si, ci, pi) // Inherit fi properties to fj\n8:\nif pathway (fi →fj) defines refinements then\n9:\naj ←ai ∪attributes specified for fj\n10:\nelse\n11:\naj ←ai // Inherit as-is\n12:\nend if\n13:\n// Add expanded child fj to E\n14:\nE ←E ∪{(fj, sj, cj, pj, aj)}\n15:\nif HasChildren(fj, P) then // recurse for fj\n16:\nE ←E ∪Expand(fj, sj, cj, pj, aj, P)\n17:\nend if\n18:\nend for\n19:\nreturn E\n20: end function\nsion begins with a parent finding fi, which corre-\nsponds to one of the 14 diagnoses in the diagnostic\npathways P. Each finding is represented by its di-\nagnostic status si (positive or negative), certainty\nci (definite or tentative), probability pi (quantified\nin Section 3), and attributes ai (e.g., location, mor-\nphology). During expansion, every child node in P\ninherits all diagnostic properties from its parent—si,\nci, pi, and ai—ensuring that each descendant find-\ning reflects its parent’s context. For example, if\nfi is labeled as positive, tentative with pi = 0.6,\nall inferred sub-findings inherit the same label and\nprobability. However, findings with si = negative\nare not expanded (line 3 in Algorithm 1), since the\npathway P is not reversible; for instance, “no pneu-\nmonia” does not imply “no opacity.” This inheritance\n(lines 7–11) reflects the propagation of diagnostic\nproperties and the pathway-specific modification of\nattributes. Comprehensive expansion is achieved\nthrough recursive chaining (line 16): if a child find-\ning fj corresponds to one of the 14 diagnoses in P,\nit becomes a new parent node and triggers further\nexpansion until reaching leaf nodes. For example,\nwhen “pulmonary edema” acts as a parent node, it\nexpands to “consolidation,” which in turn recursively\nexpands to its subfinding “opacity.” This recursive\nexpansion ensures that all findings along the di-\nagnostic pathway maintain consistent uncertainty\nestimates and coherent hierarchical relations.\n4. Conflict Resolution\nAlthough pathway rela-\ntions capture generally valid diagnostic dependen-\ncies (Section 4.1), clinical exceptions and incon-\nsistent uncertain expression can lead to conflicting\nfindings during expansion. These conflicts typically\narise when multiple pathways generate overlapping\nfindings, leading to discrepancies in diagnostic sta-\ntus (positive vs. negative) or certainty (definitive\nvs. tentative). Conflicts were classified as: (i) Orig-\ninal vs. Expansion — discrepancies between the\noriginal report and expansion (e.g., a resolved “pul-\nmonary edema” reappearing from the CHF path-\nway); and (ii) Expansion vs. Expansion — contra-\ndictions among expansion (e.g., “volume loss” from\natelectasis vs. “normal volume” from consolidation).\n"}, {"page": 9, "text": "To ensure clinical plausibility, all potential conflicts\nwere reviewed with radiologist input and resolved\nthrough a rule-based consistency protocol. Resolu-\ntion followed a sequential protocol: (1) original find-\nings take precedence to preserve factual accuracy;\n(2) contradictory entries (e.g., positive vs. negative)\nare removed; and (3) among uncertain cases, the\ninstance with higher probability pi is retained. This\nprocess ensures logical coherence and clinical con-\nsistency across all expanded findings. The detailed\nprocedure is presented in Appendix B.2.3.\n4.3.\nAnalysis of Lunguage++\nWe analyze the diagnostic pathways constructed\nin Section 4.1 and the expanded dataset gener-\nated by the framework in Section 4.2. This analysis\nquantifies the extent to which the framework recon-\nstructs implicit diagnostic reasoning, propagates\nuncertainty, and maintains report-level coherence.\nTable 3 reports statistics for the full set of diagnostic\npathways.\nDiagnostic Pathway Diversity\nPathway diversity\narises from variations in imaging view, finding, loca-\ntion, and attributes, which inherently capture differ-\nences in disease stage (e.g., acute vs. chronic).\nAcross 14 diagnostic categories (e.g., pneu-\nmonia), we identified 98 disease variants (e.g.,\nhospital-acquired pneumonia) organized into 33\nunique diagnostic pathways (e.g., pneumonia\nvs. lobar pneumonia), as shown in Table 3. Each\npathway is characterized by its depth, representing\nthe maximum hierarchical expansion depth, and its\nwidth, denoting the number of leaf-level findings\nat the terminal layer. On average, pathways exhibit\na depth of 1.4 and a width of 3.2, indicating that\nmost reasoning chains consist of one to three infer-\nential layers. Among them, pleural effusion shows\nthe greatest diversity (10 pathways) due to view-\ndependent fluid distribution, whereas congestive\nheart failure exhibits the deepest hierarchy (depth\n3), cascading through cardiomegaly, pulmonary\nedema, and pleural effusion (Figure 4). In contrast,\nsimpler findings (e.g., cardiomegaly) follow single-\nlayer mappings (depth 1, width 1), directly linking\ndiagnosis to observation.\nExpansion Coverage\nAs shown in Table 3, apply-\ning the Pathway Expansion Framework to 14,049\nstructured findings in Lunguage identified 2,639\nfindings (18.7%) that aligned with predefined di-\nagnostic pathways, from which 4,761 additional\nsub-findings (+33.9%) were inferred. This shows\nthat roughly one in five findings contained implicit\ndiagnostic structure recoverable through pathways.\nExpansion was dominated by interdependent cate-\ngories such as atelectasis (+1,215), pleural effusion\n(+915), and consolidation (+801), which together\naccounted for more than half of all inferred findings.\nThese conditions frequently co-occur or appear in\nhierarchical cascades naturally producing richer ex-\npansions, e.g. effusion with edema or atelectasis.\nConflict Resolution\nTo assess the stability of the\nexpanded structures, we further examined conflicts\nthat arose during expansion. Across the entire Lun-\nguage dataset, such conflicts were rare, appearing\nin approximately 3.2% of cases overall: 0.9% arose\nbetween original and expanded findings (64.8%\nstatus, 35.2% certainty), and 2.3% between expan-\nsions (22.8% status, 77.2% certainty). After conflict\nresolution, all remaining inconsistencies were re-\nsolved, confirming that the expanded dataset main-\ntains both logical consistency and clinical validity.\nDetailed analyses are presented in Appendix B.2.3.\n5.\nConclusion\nIn this work, we present the first systematic ap-\nproach to addressing both explicit and implicit un-\ncertainty in radiology reports. We rigorously quan-\ntify the degree of explicit uncertainty of findings\nin CXR reports, through an LLM-based automated\nframework. While demonstrated on the Lunguage\ndataset, this framework can be applied to any CXR\nreport corpus, enabling the enrichment of widely\nused benchmarks such as CheXpert (Irvin et al.,\n2019) and MIMIC-CXR (Johnson et al., 2019a) (of\nwhich Lunguage++ is only a subset) with continu-\nous uncertainty measures.\nIn parallel, we expose and address implicit un-\ncertainty in radiology reports arising from omit-\nted elements of diagnostic reasoning. We intro-\nduce a rule-based expansion framework based\non expert-defined diagnostic pathways for 14 com-\nmon CXR diagnoses, which add characteristic sub-\nfindings that may have been left unstated in the\noriginal reports. The diagnostic pathways can eas-\nily be reused for other tasks, while the expansion\nframework is applicable to any dataset that has\nbeen structured using the Lunguage framework\nproposed by Moon et al. (2025).\nTogether with our reusable frameworks, we re-\nlease Lunguage++, a benchmark dataset of struc-\ntured radiology reports that includes continuous\nprobabilities for all extracted findings and pathway-\nbased expansions that expose previously omitted\nfindings. This enriched resource supports a range\nof future research directions, including training\nuncertainty-aware CXR image classifiers, guiding\nvision-language models toward uncertainty-aware\nreport interpretation and generation, and studying\nhow diagnostic uncertainty influences downstream\nclinical outcomes.\n"}, {"page": 10, "text": "Limitations\nFor the explicit uncertainty framework, a key lim-\nitation lies in our reliance on LLM-based pairwise\ncomparisons to construct the reference ranking of\nhedging phrases. While this approach offers the\nadvantage of scalability (enabling 8,610 compar-\nisons across four LLMs, far beyond what would\nbe feasible with human raters) it also introduces\ndependency on model behavior. Moreover, our\nmapping from skill level µ to probability p is based\non assessments from only two radiologists; incor-\nporating a larger expert pool would better capture\nthe variability in how uncertainty is interpreted, as\nnoted in prior studies (Hobby et al., 2000; Shina-\ngare et al., 2019). Finally, the current framework\nincurs nontrivial costs when assigning probabilities\nto new sentences, due to repeated LLM compar-\nisons with the reference ranking. Future work could\nmitigate this by training a lightweight, locally hosted\nmodel, fine-tuned on our high-quality LLM compar-\nison data.\nFor the implicit uncertainty framework, the lim-\nitations include both structural and clinical aspects.\nFirst, the diagnostic pathways are constructed as a\ntop-down Directed Acyclic Graph that maps high-\nlevel diagnoses to lower-level sub-findings. While\nthis design captures hierarchical reasoning, it re-\nmains unidirectional and cannot represent bottom-\nup or cyclic dependencies that naturally arise in\nclinical reasoning – such as when multiple findings\ninteract or reinforce one another to revise a diag-\nnosis. Future work could extend this structure into\na bidirectional or dynamically learnable graph rep-\nresentation (e.g., a Bayesian network) that allows\nreasoning to flow in both directions, thereby captur-\ning the iterative nature of diagnostic interpretation.\nSecond, when expanding findings along diagnos-\ntic pathways, we currently assign the same prob-\nability to all child nodes. For instance, if conges-\ntive heart failure (CHF) has a probability of 0.8,\nits inferred sub-findings—cardiomegaly and pul-\nmonary edema—are each assigned the same value\n(p = 0.8), even though in practice, one may be more\ncertain (e.g., p = 0.9) while the other less so (e.g.,\np = 0.6). This simplification overlooks interdepen-\ndence and uncertainty calibration among findings,\nwhich future work could address by modeling prob-\nabilistic propagation that accounts for relative diag-\nnostic confidence.\nLastly, despite being defined through high-\nprobability relations (p(v|u) > 0.8), the pathways\ninherently encompass clinical exceptions. Even\nstrongly associated findings may not hold under\natypical imaging conditions or in the presence of\ncomorbidities, occasionally causing conflicts be-\ntween pathway-inferred and explicitly reported find-\nings. These exceptions reflect the inherent vari-\nability of radiological practice rather than modeling\nerrors, but they underscore the need for incorpo-\nrating image-level verification and cross-modal rea-\nsoning to refine the framework. Future iterations\ncould leverage visual grounding to reconcile such\nexceptions, ensuring that inferred reasoning aligns\nmore closely with true clinical evidence.\nEthics Statement\nThis research made use of and expanded the Lun-\nguage dataset (Moon et al., 2025). This dataset is\nderived from MIMIC-CXR (Johnson et al., 2019b), a\npublic dataset of chest radiographs and free-text ra-\ndiology reports. As this dataset contains sensitive\npatient information, we will follow Physionet’s guide-\nlines by publishing Lunguage++ under the same\nagreement as the source data. Furthermore, to\navoid passing sensitive patient data to public LLM\nAPIs, we followed Physionet’s recommendations by\n(i) running a HIPAA-compliant GPT-4o model pro-\nvided by Azure, (ii) revoking data retention rights for\nGemini and Claude, and (iii) running MedGemma\nlocally.\nAcknowledgments\nThe authors would like to thank Géraldine De-\nberdt, Stefan Heytens and Johan Decruyenaere\nfor participating in the expert evaluation study.\nAdditionally, we are grateful to Stefan Heytens\nand Johan Decruyenaere for their input on the\nconceptual design of the expert evaluation study\nand sharing their view on uncertainty in medical\nreporting.\n"}, {"page": 11, "text": "Bibliographical References\nAnthropic. 2025.\nClaude sonnet.\nhttps:\n//www.anthropic.com/transparency/\nmodel-report.\nLeonard Berlin. 2000. Pitfalls of the vague radiol-\nogy report. American Journal of Roentgenology,\n174(6):1511–1518.\nMichael A Bruno, Jonelle Petscavage-Thomas, and\nHani H Abujudeh. 2017. Communicating uncer-\ntainty in the radiology report. American Journal\nof Roentgenology, 209(5):1006–1008.\nAndrew L Callen, Sara M Dupont, Adi Price, Ben\nLaguna, David McCoy, Bao Do, Jason Talbott,\nMarc Kohli, and Jared Narvid. 2020. Between\nalways and never: evaluating uncertainty in radi-\nology reports using natural language processing.\nJournal of Digital Imaging, 33(5):1194–1201.\nGheorghe Comanici, Eric Bieber, Mike Schaeker-\nmann, Ice Pasupat, Noveen Sachdeva, Inderjit\nDhillon, Marcel Blistein, Ori Ram, Dan Zhang,\nEvan Rosen, et al. 2025. Gemini 2.5: Pushing\nthe frontier with advanced reasoning, multimodal-\nity, long context, and next generation agentic ca-\npabilities. arXiv preprint arXiv:2507.06261.\nJulia Gärtner, Pascal O Berberat, Martina Kadmon,\nand Sigrid Harendza. 2020. Implicit expression of\nuncertainty–suggestion of an empirically derived\nframework. BMC Medical Education, 20(1):83.\nLawrence R Goodman. 2014. Felson’s principles\nof chest roentgenology, a programmed text. El-\nsevier Health Sciences.\nRichard B Gunderman. 2009. Biases in radiologic\nreasoning. American Journal of Roentgenology,\n192(3):561–564.\nRalf Herbrich, Tom Minka, and Thore Graepel.\n2006. Trueskill™: a bayesian skill rating sys-\ntem. Advances in neural information processing\nsystems, 19.\nJonathan L Hobby, BD Tom, C Todd, PW Bearcroft,\nand Adrian K Dixon. 2000. Communication of\ndoubt and certainty in radiological reports. The\nBritish Journal of Radiology, 73(873):999–1001.\nAaron Hurst, Adam Lerer, Adam P Goucher, Adam\nPerelman, Aditya Ramesh, Aidan Clark, AJ Os-\ntrow, Akila Welihinda, Alan Hayes, Alec Radford,\net al. 2024. Gpt-4o system card. arXiv preprint\narXiv:2410.21276.\nJeremy Irvin, Pranav Rajpurkar, Michael Ko, Yifan\nYu, Silviana Ciurea-Ilcus, Chris Chute, Henrik\nMarklund, Behzad Haghgoo, Robyn Ball, Katie\nShpanskaya, et al. 2019. Chexpert: A large chest\nradiograph dataset with uncertainty labels and\nexpert comparison. In Proceedings of the AAAI\nconference on artificial intelligence, volume 33,\npages 590–597.\nSaahil Jain, Ashwin Agrawal, Adriel Saporta,\nSteven QH Truong, Du Nguyen Duong, Tan Bui,\nPierre Chambon, Yuhao Zhang, Matthew P Lun-\ngren, Andrew Y Ng, et al. 2021. Radgraph: Ex-\ntracting clinical entities and relations from radiol-\nogy reports. arXiv preprint arXiv:2106.14463.\nAlistair Johnson, Matt Lungren, Yifan Peng, Zhiy-\nong Lu, Roger Mark, Seth Berkowitz, and Steven\nHorng. 2019a. Mimic-cxr-jpg-chest radiographs\nwith structured labels. PhysioNet, 101:215–220.\nAlistair EW Johnson, Tom J Pollard, Seth J\nBerkowitz, Nathaniel R Greenbaum, Matthew P\nLungren, Chih-ying Deng, Roger G Mark, and\nSteven Horng. 2019b. Mimic-cxr, a de-identified\npublicly available database of chest radiographs\nwith free-text reports. Scientific data, 6(1):317.\nSameer Khanna, Adam Dejl, Kibo Yoon, Steven QH\nTruong, Hanh Duong, Agustina Saenz, and\nPranav Rajpurkar. 2023.\nRadgraph2: Model-\ning disease progression in radiology reports via\nhierarchical information extraction. In Machine\nlearning for healthcare conference, pages 381–\n402. PMLR.\nCindy S Lee, Paul G Nagy, Sallie J Weaver, and\nDavid E Newman-Toker. 2013. Cognitive and\nsystem factors contributing to diagnostic errors\nin radiology. American Journal of Roentgenology,\n201(3):611–617.\nJong Hak Moon, Geon Choi, Paloma Rabaey,\nMin Gwan Kim, Hyuk Gi Hong, Jung-Oh Lee,\nHangyul Yoon, Eun Woo Doe, Jiyoun Kim,\nHarshita Sharma, Daniel C. Castro, Javier\nAlvarez-Valle, and Edward Choi. 2025.\nLun-\nguage: A benchmark for structured and sequen-\ntial chest x-ray interpretation.\nJudea Pearl. 2009. Causality. Cambridge university\npress.\nBruce I Reiner. 2018. Quantitative analysis of un-\ncertainty in medical reporting: creating a stan-\ndardized and objective methodology. Journal of\ndigital imaging, 31(2):145–149.\nFrançois Remy, Kris Demuynck, and Thomas De-\nmeester. 2023. Biolord-2023: Semantic textual\nrepresentations fusing llm and clinical knowledge\ngraph insights. arXiv preprint arXiv:2311.16075.\nAndrew Sellergren, Sahar Kazemzadeh, Tiam\nJaroensri, Atilla Kiraly, Madeleine Traverse,\n"}, {"page": 12, "text": "Timo Kohlberger, Shawn Xu, Fayaz Jamil,\nCían\nHughes,\nCharles\nLau,\net\nal.\n2025.\nMedgemma technical report.\narXiv preprint\narXiv:2507.05201.\nAtul B Shinagare, Ronilda Lacson, Giles W Boland,\nAijia Wang, Stuart G Silverman, William W Mayo-\nSmith, and Ramin Khorasani. 2019. Radiolo-\ngist preferences, agreement, and variability in\nphrases used to convey diagnostic certainty in\nradiology reports. Journal of the American Col-\nlege of Radiology, 16(4):458–464.\nMark Turner, Julia Ive, and Sumithra Velupillai.\n2021. Linguistic uncertainty in clinical nlp: A tax-\nonomy, dataset and approach. In International\nConference of the Cross-Language Evaluation\nForum for European Languages, pages 129–141.\nSpringer.\nW Richard Webb and Charles B Higgins. 2011.\nThoracic imaging: pulmonary and cardiovascular\nradiology. Lippincott Williams & Wilkins.\nJoy T Wu, Nkechinyere N Agu, Ismini Lourentzou,\nArjun Sharma, Joseph A Paguio, Jasper S Yao,\nEdward C Dee, William Mitchell, Satyananda\nKashyap, Andrea Giovannini, et al. 2021. Chest\nimagenome dataset for clinical reasoning. arXiv\npreprint arXiv:2108.00316.\nMengliang Zhang, Xinyue Hu, Lin Gu, Tatsuya\nHarada, Kazuma Kobayashi, Ronald Summers,\nand Yingying Zhu. 2023. Cad-chest: Comprehen-\nsive annotation of diseases based on mimic-cxr\nradiology report. PhysioNet.\n"}, {"page": 13, "text": "Appendix\nA.\nExplicit Uncertainty\nA.1.\nVocabulary of hedging phrases\nThe full prompt that was used to extract hedg-\ning phrases for each finding-sentence pair in Lun-\nguage, is shown in Listing A1.\nWe use this to\nprompt the Gemini model gemini-2.5-flash with the\nmaximum number of output tokens set to 1100,\nwhere 1000 tokens were assigned as a thinking\nbudget. Temperature and top_p parameters were\nset to their default values of 1. The total price to\nextract all hedging phrases was around $1.\nListing A1: Full prompt for hedging phrase extraction\nSYSTEM: You are a radiologist who is given pairs of\nentities and sentences. Each entity appears in\nthe corresponding sentence. Your task is to\nidentify and extract only the words or phrases\nin the sentence that express uncertainty\nspecifically about the given entity.\nTASK: You are given pairs of entities and sentences.\nEach entity appears in the corresponding\nsentence. Your task is to identify and extract\nonly the words or phrases in the sentence that\nexpress uncertainty specifically about the\ngiven entity.\nImportant notes:\n- The sentence may mention multiple entities, but\nyou should extract uncertainty clues only for\nthe specified entity. Please refer to the\nexamples below that show how you should handle\nsuch cases.\n- Look for words or phrases that suggest uncertainty\n, speculation, approximation, possibility, or\nlack of definitiveness (e.g., \"might\", \"\npossibly\", \"suggests\", \"appears to\", \"in some\ncases\").\n- Return a list of such uncertainty clues found in\nthe sentence and relevant to the query entity.\nReturn your output as a list: [\"<word or phrase 1>\",\n\"<word or phrase 2>\", ...]\nIf there are no uncertainty clues related to the\ngiven entity, return an empty list.\nBelow are 10 examples, after which you must complete\nthe task for an unseen query.\nINPUT:\n{\n\"entity\": \"pulmonary edema\",\n\"sentence\": \"overall, however, there is a more\nfocal airspace opacity in the left mid and\nlower lung, which may reflect asymmetric\npulmonary edema or an infectious process,\nless likely atelectasis.\"\n}\nOUTPUT:\n[\"may\", \"or\"]\nINPUT:\n{\n\"entity\": \"atelectasis\",\n\"sentence\": \"overall, however, there is a more\nfocal airspace opacity in the left mid and\nlower lung, which may reflect asymmetric\npulmonary edema or an infectious process,\nless likely atelectasis.\"\n}\nOUTPUT:\n[\"less likely\"]\n... <redacted for brevity>\nINPUT:\n{\n\"entity\": \"pleural effusion\",\nFigure A1: Our vocabulary of 42 common hedging\nphrases, including how many times each phrase was ex-\ntracted for tentative finding-sentence pairs in Lunguage.\n\"sentence\": \"a left pleural effusion and\natelectasis obscure the left cardiac and\nhemidiaphragmatic contours more than the\nprior day.\"\n}\nOUTPUT:\n[]\nExamine the entity and sentence pair below. If the\nsentence also talks about other entities, first\nidentify the part of the sentence that is\ntalking about the query entity, and then\nextract phrases expressing uncertainty\nspecifically related to that entity.\nReturn your output as a list: [\"<word or phrase 1>\",\n\"<word or phrase 2>\", ...]. If there are no\nuncertainty clues related to the given entity,\nreturn an empty list.\nINPUT:\n{\n\"entity\": {entity}\n\"sentence\": {sentence}\n}\nOUTPUT:\nWe manually reviewed and corrected all cases\nwhere more than one phrase was extracted (568\nfinding-sentence pairs), since these were prone to\nmistakes. Furthermore, we noticed that the LLM\noccasionally extracted phrases which did not relate\nto the uncertainty of the finding, but rather to other\nrelational attributes which were already extracted\nin Lunguage: onset, measurement and severity.\nPhrases that matched these attributes for the same\nfinding-sentence pair were filtered out. The phrase\n\"difficult to assess\" was extracted in 11 cases, but\nwas removed since it relates more to visual limita-\ntions rather than uncertainty.\nFigure A1 shows the number of times each of\nthe 42 most common hedging phrases (i.e., oc-\ncurring more than 10 times) were extracted from\nLunguage.\nA.2.\nReference ranking of hedging\nphrases\nTrueSkill details\nThe TrueSkill ranking system\nmaintains a Bayesian belief in every item’s skill\nby estimating two parameters: the average skill\n(µ) and the degree of confidence in the skill (σ),\ntogether characterizing a Gaussian distribution\nN(µ, σ). Initially, we set µ = 25 and σ =\n25\n3\n2,\nwhich is the default. TrueSkill additionally defines\n"}, {"page": 14, "text": "a parameter β2, which controls the variance of the\nitem’s performance around its average skill in a\nsingle match, set to 25/6 per default.\nWhen we use an LLM to compare two hedging\nphrases, we are essentially playing a match where\none hedging phrase is the winner. After each match,\nTrueSkill updates both µ and σ using Bayesian in-\nference: if an item performs better than expected,\nits µ increases, with the magnitude of this change\ndepending on σ, and vice versa if it performs worse\nthan expected. This mechanism is formalized in\nTrueSkill’s update equations (Herbrich et al., 2006),\nwhich ensure that σ naturally shrinks as the system\nbecomes more confident in its estimate, stabilizing\neach item’s rating. Since the winner of a match is\npicked as the phrase that is closest to “finding is\ncertainly present”, a higher µ will be obtained for\nphrases closer to that part of the likelihood spec-\ntrum. In our case, we input all pairwise compar-\nisons (across 861 pairs of hedging phrases, each\nrepeated 10 times, with 4 LLMs) one after the other,\nin a random order. Since the final ranking is order-\ndependent, we repeat this 10 times with different\nrandom orders, averaging the final µ and σ across\nruns.\nPrompting details\nThe full prompt that was used\nto perform comparisons between pairs of hedging\nphrases is shown in Listing A2. We executed this\nprompt for each pair of hedging phrases, repeating\n10 times with different example sentences (sen-\ntence_1 and sentence_2), and with each of the four\nLLMs: gemini-2.5-flash, gpt-4o, claude-sonnet-4,\nmedgemma-27b-text-it. For each LLM, we set the\nmaximum number of tokens to 100, temperature to\n1, top_p to 1. This time, we assigned zero thinking\nbudget to Gemini, to pull all the models to the same\nlevel of reasoning capabilities.\nListing A2: Full prompt for hedging phrase comparison\nSYSTEM: You are a radiologist who is ranking\nsentences expressing uncertainty.\nTASK: You will be given two sentences from radiology\nreports. Each sentence contains a placeholder\n\"<finding>\", which represents a medical\nobservation (e.g., consolidation, effusion,\nnodule). Each sentence includes a phrase that\nexpresses the degree of certainty about the\npresence or absence of the finding.\nAssume there is a certainty spectrum ranging from:\n\"<finding> is certainly absent\"\nto\n\"<finding> is certainly present\"\nYour task is to identify which sentence is **closer\nto \"<finding> is certainly present\"** on this\nscale, using the context of the sentence. In\nother words, your task is to identify which\nsentence expresses a higher degree of certainty\nthat the finding is present.\nRespond with **only** the chosen sentence (\nsentence_1 or sentence_2).\nHere are some examples.\n---\nExample 1:\nINPUT:\n{\n\"sentence_1\": \"interstitial markings are prominent\n, suggest possible mild <finding>.\",\n\"sentence_2\": \"allowing for low inspiratory\nvolumes, the <finding> is probably unchanged\n.\"\n}\nOUTPUT:\n\"sentence_2\"\n---\nExample 2:\nINPUT:\n{\n\"sentence_1\": \"given the clinical presentation, <\nfinding> must be suspected.\",\n\"sentence_2\": \"although this could represent\nsevere <finding>, the possibility of\nsupervening pneumonia or even developing ards\nmust be considered.\"\n}\nOUTPUT:\n\"sentence_1\"\n---\nExample 3:\nINPUT:\n{\n\"sentence_1\": \"this could be either pneumonia in\nthe left upper lobe or fissural <finding>.\",\n\"sentence_2\": \"the presence of a minimal left <\nfinding> cannot be excluded, given blunting\nof the left costophrenic sinus.\",\n}\nOUTPUT:\n\"sentence_1\"\n---\nINPUT:\n{\n\"sentence_1\": {sentence_1},\n\"sentence_2\": {sentence_2}\n}\nWhich of the two sentences (\"sentence_1\" or \"\nsentence_2\") indicates that <finding> is more\ncertainly present? Respond with your choice **\nonly**.\nOUTPUT:\nReference ranking\nTo assess the robustness\nof our reference ranking (shown in Figure 3), we\nconstructed an alternative ranking using only five\ncomparisons per phrase pair. Compared to the\noriginal ranking in Figure 3, this reduced version\nshowed an average absolute difference of 0.36 in\nµ and 0.76 in rank, with a Spearman correlation of\n0.996 between both rankings. These results indi-\ncate that ten comparisons per pair provide a suffi-\nciently stable and reliable ranking. We also com-\npute pairwise agreement between the four LLMs\nacross all 8610 comparisons, which is shown in Ta-\nble A1. The average agreement scores are 0.865\nfor Gemini, 0.861 for GPT-4o, 0.866 for Claude,\nand 0.866 for MedGemma. Fleiss’ Kappa between\nall four models is 0.860 and Krippendorff’s Alpha is\n0.722. These values indicate strong but imperfect\nagreement across models, highlighting the need\n"}, {"page": 15, "text": "Figure A2: Pairwise Spearman rank correlations be-\ntween TrueSkill rankings obtained for individual LLMs,\nacross 10 seeds.\nto integrate the judgments of all four LLMs when\nconstructing the final ranking, as no single model\ncan be assumed to provide the correct outcome in\nevery case.\nTable A1: Pairwise agreement between LLMs across\n8610 hedging phrase comparisons.\nModel\nGemini\nGPT-4o\nClaude\nMedGemma\nGemini\n1.000\n0.861\n0.868\n0.866\nGPT-4o\n0.861\n1.000\n0.861\n0.862\nClaude\n0.868\n0.861\n1.000\n0.870\nMedGemma\n0.866\n0.862\n0.870\n1.000\nTo further explore the variation across LLMs,\nwe apply the TrueSkill algorithm to each individ-\nual LLM’s set of comparisons (8610 each), repeat-\ning 10 times for different random orderings of the\nmatches. We then compute pairwise Spearman\nrank correlations between the obtained rankings.\nThe full correlation plot is show in Figure A2. Note\nthat correlations are high for within-LLM compar-\nisons, indicating that averaging across 10 ordering\nseeds should result in a stable ranking. Correla-\ntions are lower for across-LLM comparisons, once\nagain indicating that relying on a single LLM to build\nour reference ranking would not be sufficient. As\nstated before, our final reference ranking (shown\nin Figure 3) is obtained by applying the TrueSkill\nalgorithm to the full set of comparisons, repeating\n10 times across ordering seeds and averaging the\nfinal µ and σ across runs. Figure A3 shows the\nSpearman rank correlation between each individ-\nual LLM’s ranking across 10 seeds and the final\nreference ranking. Note that these correlations are\ngenerally higher than the pairwise correlations be-\ntween individual LLMs from Figure A2.\nFigure A3: Spearman rank correlations with the ref-\nerence ranking for TrueSkill rankings obtained for indi-\nvidual LLMs, across 10 seeds.\nExpert evaluation\nEach participant was pre-\nsented with 50 pairs of hedging phrases, with five\nexample sentences per phrase. They were asked\nto choose the phrase that expresses a higher de-\ngree of certainty that the finding is present; an ex-\nample is shown in Listing A3. The full survey, in-\ncluding detailed instructions for the evaluators, can\nbe found on our Github repository, in the file sur-\nvey_uncertainty.pdf. Table A2 shows the oc-\ncupation and experience of the six experts involved\nin our expert evaluation study. Figure A4 shows the\npairwise agreement between experts, and between\nexperts and the reference ranking. Agreement is\ndefined as the proportion of phrase pairs (out of\n50) for which the expert’s relative ordering matches\nthat of the other expert (or of the reference ranking).\nListing A3: Example question in expert evaluation study\nPhrase 1: difficult to exclude.\nExample sentences:\n- bilateral hilar vascular prominence is re-\ndemonstrated with subtle <finding> in the left\nupper lung likely representing confluence of\nvasculature though a true nodule **difficult to\nexclude**.\n- there is slight blunting of both costophrenic\nangles, felt most likely be due to overlying\nsoft tissues, but a trace <finding> be **\ndifficult to exclude**.\n- no large <finding> is seen, although trace\neffusions are **difficult to exclude**.\n- no large <finding> however, trace bilateral <\nfinding>s **difficult to exclude**.\n- mild <finding> is **difficult to exclude** in the\ncorrect clinical setting.\nPhrase 2: appear.\nExample sentences:\n- the <finding> **appear** clear.\n- the <finding> **appear** well inflated.\n- the mediastinal and <finding> **appear** unchanged\n, allowing for differences in technique.\n- mid <finding> **appear** intact.\n- <finding> **appear** grossly intact.\nA.3.\nFitting each finding-sentence pair\ninto the reference ranking\nAlgorithm\nUsing Algorithm A1, we can fit any\ntentative finding-sentence pair into the reference\nranking. Here, the draw probability between the tar-\nget sentence ttar with (µtar, σtar), and an opponent\nphrase opp with (µopp, σopp) is calculated as follows:\n"}, {"page": 16, "text": "Type\nOccupation\nExperience\nWriter\nRadiologist\n5 to 10 years\nWriter\nRadiologist\n0 to 5 years\nReader\nInternist\n30 to 40 years\nReader\nOncologist\n5 to 10 years\nReader\nGP\n30 to 40 years\nReader\nGP\n0 to 5 years\nTable A2: Expert occupation and experience\nFigure A4: Pairwise agreement between experts and\nreference ranking, across 50 hedging phrase pairs.\nDrawProb(ttar, opp) = exp( −(µtar−µopp)2\n2c2\n)\n√\nd, with\nc2 = 2β2 + σ2\ntar + σ2\nopp, d = 2 β2\nc2 , and β2 = 25/6\n(Herbrich et al., 2006).\nValidation\nTo validate our algorithm and the use\nof draw probability as an opponent selection strat-\negy, we designed the following experiment. While\nthe true rank of individual sentences in our dataset\nis unknown, we can assess performance using\nthe hedging phrases in our reference vocabulary,\nwhose ranks are known. Specifically, we simulate\na modified reference ranking in which one of the 42\nhedging phrases is temporarily excluded, then fit\nthat phrase back into the ranking using a modified\nversion of Algorithm A1. We consider two oppo-\nnent selection strategies: (i) the draw probability\nstrategy described previously, and (ii) a random\nstrategy, where an opponent is chosen uniformly\nat random at each step. We also test multiple LLM\nconfigurations: one using all LLMs for the first K\niterations (as in Algorithm A1) and then picking an\nLLM randomly, and another using a single LLM\n(Gemini, GPT-4o, Claude, or MedGemma) for all\ncomparisons. Each configuration is repeated with\n10 random seeds, which control sentence sampling,\nLLM selection, and opponent choice in the random\nsetting. At each iteration, we compute the absolute\ndistance between the current estimated rank of the\nphrase and its true rank in the reference ranking. If\nAlgorithm A1 Determine TrueSkill score µ for finding-\nsentence pair (ftar, ttar) based on reference ranking\n1: Input: Target sentence ttar, reference ranking R,\nLLMs, K, N, max_steps = 100, patience = 10\n2: Output: TrueSkill score (µtar, σtar) for ttar\n3: Initialize µtar ←25, σtar ←25\n3\n2, step ←0, s ←0\n4: Initialize opp_counts[phrase] ←0, ∀phrase ∈R\n5: while step < max_steps and s < patience do\n6:\nSelect opp ∈R with max DrawProb(ttar, opp)\n7:\nif opp_counts[opp] ≥N then skip\n8:\nopp_counts[opp] ←opp_counts[opp] + 1\n9:\nRandomly select sentence topp containing opp\n10:\nif step < K then\n11:\nmodels ←all LLMs\n12:\nelse\n13:\nmodels ←randomly pick 1 LLM\n14:\nend if\n15:\nCompare ttar vs topp using models\n16:\nUpdate TrueSkill (µtar, σtar) for ttar\n17:\nRecalculate rank rtar of µtar among R\n18:\nIf rtar unchanged then s ←s + 1 else s ←0\n19:\nstep ←step + 1\n20: end while\nFigure A5: Average distance to the true rank across\niterations of variants of Algorithm A1. We test different\nvariants of the opponent selection strategy–draw proba-\nbility vs. random–and LLMs used for comparisons–all or\nsingle-LLM (Gemini, GPT-4o, Claude, or MedGemma).\nthe algorithm converges before 100 iterations, the\nfinal rank is used for all subsequent iterations. We\nthen average the absolute rank distances across\nall 43 phrases and 10 seeds. In these experiments,\nK was set to 10 and N to 5.\nFigure A5 presents the resulting performance\nacross all configurations. Note that the strategy\nwhich uses draw probability and all LLMs performs\nbest, which is indeed the strategy implemented in\nAlgorithm A1. While the random strategy performs\nsimilarly to draw probability in the single-LLM set-\nting, it leads to less stable runs, as evidenced by the\nstandard deviation of the distance to the true rank\nat step 100, averaged across all phrases, which is\nshown in Figure A5 as well.\n"}, {"page": 17, "text": "(a) K\n(b) N\nFigure A6: Hyperparameter tuning results for K and N.\nHyperparameters\nAlgorithm A1 contains hyper-\nparameter K, which controls the number of itera-\ntions for which all four LLMs perform the phrase-\nsentence comparison, and hyperparameter N,\nwhich decides the number of times each oppo-\nnent can be selected for comparison. Following the\nsame experiment setup outlined above, with the\ndraw probability strategy and including all LLMs,\nwe perform hyperparameter optimization across\nthe hedging phrases in our vocabulary. For K,\nwe ran Algorithm A1 for K ∈[0, 1, 5, 10, 20, 50, 100]\nwith N = 5. Figure A6a shows the average dis-\ntance to the true rank in the reference ranking, av-\neraged across all phrases. Setting K = 10 forms\nthe right balance between cost-efficiency and per-\nformance. We performed the same experiment for\nN ∈[2, 3, 5, 10, 20], with K = 10, ultimately choos-\ning N = 5 (Figure A6b).\nResults and cost\nApplying Algorithm A1 to\nthe 2,066 tentative finding-sentence pairs in Lun-\nguage incurred a total cost of $92.16, averaging\n$0.045/pair. Specifically, we spent $5.59 on Gem-\nini, $39.49 on GPT-4o, and $45.12 on Claude, while\nMedGemma incurred no cost as it was run locally.\nOn average, 24.61 ranking steps were required per\nFigure A7: Histogram of probabilities in the tentative\nportion of Lunguage++.\nfinding-sentence pair, ranging from 10 to 100. The\naverage µ value is 22.62, with a minimum of 0.41\nand a maximum of 48.58, compared to a minimum\nof 7.07 and a maximum of 43.44 in the reference\nranking (see Figure 3). The average rank when fit\ninto the reference ranking is 23.87, with a minimum\nrank of 1 and a maximum rank of 43.\nA.4.\nMap to probability scale\nWe use an expert-informed sigmoid mapping (de-\nscribed in Section 3.4) to transform each µ into its\nprobability value p. A histogram of the probabilities\nin the tentative portion of Lunguage++ is shown in\nFigure A7.\nThis mapping is anchored by the expert-defined\nprobabilities for the phrases less likely and most\nlikely. Two radiologists received the following in-\nstruction:\nOn a scale of certainly absent (0) to certainly\npresent (100), where would you place the phrase\n<phrase>, as it relates to the <finding> in\neach of the following sentences? Keep in mind\nthat your answer may differ based on the\ncontext of the sentence.\nThey were asked to assign such probabilities for\n10 example sentences, for both phrases. An ex-\nample sentence for less likely includes: “Minimal\nblunting of the right costophrenic sulcus is more\nsuggestive of similar slight atelectatic change, less\nlikely persistent trace <finding>”. An example sen-\ntence for most likely includes: “Streaky predomi-\nnantly right-sided mid and lower lung opacities are\nseen, most likely due to <finding>”. The full in-\nstructions are included in the survey, which can\nbe found on our Github repository, in the file sur-\nvey_uncertainty.pdf.\n"}, {"page": 18, "text": "B.\nImplicit Uncertainty\nB.1.\nDiagnostic Pathways\nWe present the diagnostic pathways defined in\nPathway Expansion Framework. In practice, the\npathways encode context primarily along two axes:\n(i) imaging view and patient positioning, which\ndetermine which radiographic signs can be ex-\npected or meaningfully interpreted (e.g., pleural\neffusion on an erect PA view typically presents with\ncostophrenic angle blunting, whereas on a supine\nAP view it more often appears as diffuse haziness\nover the pleural space); and (ii) clinical acuity\ntogether with morphologic/anatomic subtype,\nwhich jointly modulate how a diagnosis presents\n(e.g., pneumothorax shows peripheral pleural air\nwith absent pulmonary lung markings, whereas ten-\nsion pneumothorax additionally shows mediastinal\nshift; pleural effusion may be non-loculated or loc-\nulated). These conditioning factors are encoded\nin the pathway dictionary. During expansion, the\nPathway Expansion Framework uses these path-\nways to recover omitted intermediate findings in a\nreport. Table B1 and Figures B1 to B2 present rep-\nresentative pathway variants for the 14 diagnoses.\nIn the figures, each panel depicts the diagnosis as\nthe root and its subfindings as children, with arrows\nindicating expert-defined dependencies. For exam-\nple, in congestive heart failure the pathway links\nthe root to cardiomegaly, pulmonary edema, and\ndyspnea (congestive heart failure →cardiomegaly\n+ pulmonary edema + dyspnea). A dictionary with\nall pathway variants is also released on our Github\nrepository, in the file dx_pathway.csv.\nB.2.\nCascading Expansion Framework\nB.2.1.\nBlacklist for Finding Deduplication\nWe merge near-duplicate findings into a single\ncanonical form using cosine similarity from a clini-\ncal embedding model (e.g., BioLord (Remy et al.,\n2023)) with a threshold of 0.9. Even with this high\nthreshold, purely lexical similarity can still spuri-\nously merge clinically distinct statements that differ\nalong critical axes (e.g., left lower lobe new consol-\nidation vs. right lower lobe new consolidation). To\navoid false merges of distinct concepts, we apply\nan explicit blacklist with two layers: (i) exact-pair\nexclusions and (ii) pattern-level rules. We use a\nmanually curated blacklist of mutually incompati-\nble pairs, which is invoked when two candidates\nbelong to the same study and to the same coarse\nanatomic region but differ along key discriminative\naxes such as laterality, lobar/segmental location,\ndiagnostic status, or pathophysiologic mechanism.\nA candidate pair is merged only if it passes the\nsimilarity threshold and does not match any black-\nlist entry; otherwise both findings are preserved.\nRepresentative blacklist entries and patterns are\nsummarized in Table B2.\nB.2.2.\nDetails of Pathway Matching\nAlgorithm B1 describes the pathway match-\ning procedure, which aligns each input tuple\n(finding, loc, attr, view) to at most one pathway vari-\nant from Table B1 and Figures B1 and B2. The full\ncode can be found on our Github repository.\nFor each row from Lunguage, we first apply\nNormalizeInput to obtain a normalized tuple\n(f ′, ℓ′, a′, v′), mapping raw report phrases to the\nLunguage vocabulary (e.g., “RUL” →“right upper\nlung,” “TB” →“tuberculosis”) and mapping view\nmetadata to a standardized view_information\nstring (AP, PA, LATERAL, erect, supine). In par-\nallel, we apply NormalizeDict to the pathway\ndictionary D, yielding D′ with normalized findings,\nlocations, attributes, and views for every pathway\nentry.\nGiven (f ′, ℓ′, a′, v′) and D′, the BestPathway-\nMatch routine proceeds in three compatibility steps.\nFirst, it performs a finding-level lexical match: we\nrestrict candidates to those pathways whose nor-\nmalized finding term is identical to f ′. This ensures\nthat, for example, tuples with finding “fracture” only\ncompete among fracture-related pathways, and tu-\nples with finding “pleural effusion” only among effu-\nsion pathways.\nSecond, we enforce location and attribute com-\npatibility. For example, location compatibility dis-\ntinguishes skeletal fractures from device fractures\neven when the normalized finding f’ is “fracture”.\nAttribute terms then select more specific variants:\n“loculated” triggers the loculated-effusion pathway,\n“tension” the tension-pneumothorax pathway, “com-\npression” the compression-fracture pathway, and\nacuity modifiers such as “acute,” “old,” or “healed”\nselect the corresponding fracture branch.\nFinally,\nwe check view compatibility using\nview_information, retaining only variants that\nare observable under the given view (e.g., erect\nversus supine presentations of pleural effusion, as\ndiscussed earlier). By construction, these compati-\nbility rules are defined so that at most one pathway\nvariant remains for any normalized input tuple. If a\nunique compatible variant exists, BestPathway-\nMatch returns it as c⋆; otherwise it returns none.\nB.2.3.\nStatus Conflict Resolution\nDuring pathway expansion we observed status\nconflicts for the same finding, and we also iden-\ntified inconsistencies within original reports.\nIn\nTable B3, we categorize conflicts by source and\ntype and count their occurrence in Lunguage.\nSources are original_vs_expansion (an ex-\npanded node contradicts an explicitly stated node),\n"}, {"page": 19, "text": "Diagnosis\nSpecific diagnosis\nDiagnostic pathways\nPleural Effusion\nNon-loculated pleural effusion; Loculated\npleural effusion\nNon-loculated (one of nine pathways): view:\nap, pa, lateral\n> ent:\nblunting > status:\ndp > loc:\ncostophrenic\nangle && ent:\nopacity > status:\ndp > loc:\npleural space > attr:\nhazy, diffuse\nLoculated: view:\nap, pa, lateral > ent:\nopacity >\nstatus:\ndp > loc:\npleural space > attr:\nloculated\nPneumothorax\nPneumothorax; Tension pneumothorax\nPneumothorax: view:\nap, pa, lateral > ent:\nlucency\n> status:\ndp > loc:\npleural space && ent:\nmarking > status:\ndn > loc:\npulmonary && ent:\nair > status:\ndp > loc:\nlung periphery\nTension: Pneumothorax && ent:\nshift > status:\ndp >\nloc:\nmediastinal && attr:\nlarge amount\nConsolidation\nConsolidation\nview:\nap, pa, lateral > ent:\nopacity > status:\ndp > loc:\nairspace && ent:\nvolume loss > status:\ndn\nAtelectasis\nAtelectasis\nview:\nap, pa, lateral > ent:\nopacity > status:\ndp && ent:\nvolume loss > status:\ndp\nPneumonia\nPneumonia; Aspiration pneumonia; Lobar\npneumonia\nPneumonia: view:\nap, pa, lateral > ent:\nopacity >\nstatus:\ndp && ent:\nfever > status:\ndp\nAspiration: Pneumonia > loc:\nlung > attr:\ndependent\nportion\nLobar: view:\nap, pa, lateral > ent:\nconsolidation >\nstatus:\ndp && ent:\nfever > status:\ndp\nPulmonary Edema\nInterstitial pulmonary edema; Alveolar\npulmonary edema\nInterstitial: view:\nap, pa, lateral > ent:\nopacity >\nstatus:\ndp > loc:\ninterstitial\nAlveolar: view:\nap, pa, lateral > ent:\nconsolidation\n> status:\ndp && ent:\npleural effusion > status:\ndp\nBronchitis\nBronchitis; Chronic Bronchitis\nBronchitis: view:\nap, pa, lateral > ent:\nopacity >\nstatus:\ndp > loc:\nperibronchial\nChronic: view:\nap, pa, lateral > ent:\nthickening >\nstatus:\ndp > loc:\nbronchial wall && ent:\ncough >\nstatus:\ndp\nCardiomegaly\nCardiomegaly\nview:\nap, pa > ent:\nheart size > status:\ndp >\nloc:\ncardiothoracic > attr:\nincreased\nCHF\nCHF\nview:\nap, pa, lateral > ent:\ncardiomegaly >\nstatus:\ndp && ent:\npulmonary edema > status:\ndp\n&& ent:\ndyspnea > status:\ndp\nEmphysema\nEmphysema; Severe emphysema\nEmphysema: view:\nap, pa, lateral > ent:\nlucency >\nstatus:\ndp > loc:\nlung parenchyma > attr:\ndiffuse\nSevere: Emphysema && ent:\npulmonary vascularity >\nstatus:\ndp > attr:\ndecreased && ent:\ndestruction\n> status:\ndp > loc:\nlung parenchyma\nCOPD\nCOPD\nview:\nap, pa, lateral > ent:\nhyperinflation >\nstatus:\ndp > loc:\nlungs && ent:\nemphysema >\nstatus:\ndp && ent:\ncough > status:\ndp\nFracture\nAcute fracture; Chronic/Old fracture;\nHealed fracture; Spinal/Compression\nfracture\nAcute: view:\nap, pa, lateral > ent:\ndisruption >\nstatus:\ndp > loc:\nbone\nChronic/Old: view:\nap, pa, lateral > ent:\ncallus\nformation > status:\ndp > loc:\nbone\nHealed: view:\nap, pa, lateral > ent:\ndeformity >\nstatus:\ndp > loc:\nbone\nSpinal/Compression: view:\nap, pa, lateral > ent:\nopacity > status:\ndp > loc:\nvertebral body >\nattr:\nincreased && ent:\nloss of height > status:\ndp\nTuberculosis\nActive tuberculosis; Chronic/Non-active\ntuberculosis\nActive: view:\nap, pa, lateral > ent:\nopacity >\nstatus:\ndp\nChronic/Non-active: view:\nap, pa, lateral > ent:\nnodules > status:\ndp > loc:\nbilateral upper lung\n> attr:\ncalcified && ent:\narchitectural\ndistortion > status:\ndp > loc:\nbilateral upper\nlung\nLung Cancer\nLung Cancer\nview:\nap, pa, lateral > ent:\nopacity > status:\ndp > attr:\nnodular\nTable B1: Diagnostic pathways. view denotes projection or patient orientation; ent, status, loc, and attr\nindicate the entity, status (dp is definitive positive, dn is definitive negative), anatomical location, and attributes (e.g.,\nmorphology, distribution, measurement). Pathways are ordered sequences joined by “>”, with required co-occurrence\nmarked by “&&”. We display one representative pathway out of nine defined for pleural effusion and, in total, 33\npathways spanning 14 diagnoses.\n"}, {"page": 20, "text": "Pleural Effusion\nPleural Effusion\nCostophrenic\nangle blunt-\ning (dp)\nDiffuse/hazy\nopacity +\nlayering\nfluid (dp)\nLoculated pleu-\nral opacity (dp)\nerect\nsupine\nloculated\nPneumothorax\nPneumothorax\nPleural space\nlucency (dp)\n+ pulmonary\nmarkings\n(dn) + periph-\nery air (dp)\nPleural space\nlucency (dp)\n+ pulmonary\nmarkings (dn)\n+ Mediastinal\nshift + large pe-\nriphery air (dp)\ntension\nConsolidation\nConsolidation\nAirspace\nopacity + vol-\nume loss (dn)\nAtelectasis\nAtelectasis\nParenchymal\nopacity +\nVolume\nloss (dp)\nPneumonia\nPneumonia\nParenchymal\nopacity +\nfever (dp)\nconsolidation\n+ fever (dp)\nlobar\nPulmonary Edema\nPulmonary\nEdema\ninterstitial\nopacity (dp)\nconsolidation\n+ pleural\neffusion (dp)\ninterstitial\nBronchitis\nBronchitis\nPeribronchial\nopacity (dp)\nBronchial wall\nthickening\n+ Chronic\ncough (dp)\nchronic\nCardiomegaly\nCardiomegaly\nEnlarged\ncardiac sil-\nhouette (dp)\nFigure B1: Diagnostic pathway panels (Part 1 of 2) illustrating exemplar pathways from the hand-crafted dictionary\nused by the pathway matching algorithm. Each panel is a small directed graph whose root node is a normalized\ndiagnosis (finding) and whose children are normalized sub-finding patterns over location, attributes, view, and\n(optionally) clinical context (e.g., patient symptom). Edges are annotated with the attribute or view modifiers that\nthe matcher uses when checking joint compatibility between an input tuple (finding, loc, attr, view) and a pathway\nvariant. Here, dp stands for definitive positive, while dn stands for definitive negative. Shown pathways correspond\nto: Pleural Effusion, Pneumothorax, Consolidation, Atelectasis, Pneumonia, Pulmonary Edema, Bronchitis, and\nCardiomegaly. For Pleural Effusion, the branches encode erect versus supine presentations and a loculated variant.\nFor Pneumothorax, the variants capture simple pneumothorax, tension pneumothorax, and hydropneumothorax.\nFor Pneumonia and Pulmonary Edema, the pathways encode typical parenchymal and interstitial/alveolar patterns\n(consolidation) together with key clinical or co-occurring radiographic findings (e.g., fever, pleural effusion). Bronchitis\nis represented as an airway-centered process, while Consolidation, Atelectasis, and Cardiomegaly map directly to\ntheir canonical imaging signatures. All pathway structure shown here is taken directly from the released pathway\ndictionary and is the same structure searched by BestPathwayMatch.\noriginal_vs_original (two original nodes dis-\nagree), and expansion_vs_expansion (two ex-\npanded nodes disagree). Types are polarity (dp\nvs. dn), certainty_positive (dp vs. tp), cer-\ntainty_negative (dn vs. tn), duplicate_pos\n(tn vs. tn) and duplicate_neg (tp vs. tp).\nConflict detection operates at the granularity\nof (entity,location) within each report with\nthe same study_id. Across the expanded Lun-\nguage dataset (19,216 rows), expansion-related\nconflicts were rare overall, totaling 616 cases\n(3.2%): 165 (0.9%) original_vs_expansion\nand 451 (2.3%) expansion_vs_expansion.\nWithin original_vs_expansion (n=165), con-\nflicts due to polarity of definitive findings domi-\nnated, with polarity accounting for 107 (64.8%)\nconflicts, certainty_pos for 34 (20.6%), and\ncertainty_neg for 24 (14.5%).\nWithin ex-\npansion_vs_expansion (n=451), conflicts were\ndominated by duplicates of positively tentative\nfindings: polarity accounted for 103 (22.8%)\nconflicts, certainty_pos for 133 (29.5%), cer-\ntainty_neg for 16 (3.5%), duplicate_pos\nfor 181 (40.1%), and duplicate_neg for 18\n(4.0%). In addition, some inconsistencies were\nalready present in the original reports:\norig-\n"}, {"page": 21, "text": "Congestive Heart Failure (CHF)\nCHF\nCardiomegaly (dp) +\nPulmonary edema (dp) +\nDyspnea / SOB (dp)\nEmphysema\nEmphysema\nDiffuse\nparenchymal\nlucency (dp)\nDiffuse\nparenchymal\nlucency (dp)\n+ Decreased\nparenchymal\ndestruction (dp)\nsevere\nCOPD\nCOPD\nHyperinflated lungs (dp)\n+ Emphysema (dp) +\nCough (dp)\nFracture\nFracture\nBone dis-\nruption (dp)\nBone callus\nformation (dp)\nBone de-\nformity (dp)\nIncreased\nvertebral body\nopacity +\nheight loss (dp)\nacute\nold\nhealed/old\ncompression\nTuberculosis\nTuberculosis\nopacity (dp)\nCalcified upper-\nlobe nodules +\ndistortion (dp)\nactive\nold / inactive\nLung Cancer\nLung Cancer\nNodular or\nmass-like\nopacity (dp)\nFigure B2: Diagnostic pathway panels (Part 2 of 2) illustrating exemplar pathways from the hand-crafted dictionary\nused by the pathway matching algorithm. Shown pathways correspond to CHF, Emphysema, COPD, Fracture,\nTuberculosis, and Lung Cancer. CHF is modeled as a cardiopulmonary congestion cluster, where cardiomegaly,\npulmonary edema, and dyspnea co-occur during exacerbation. Emphysema encodes a severity axis from diffuse\nparenchymal lucency to severe parenchymal destruction with decreased peripheral vascularity. COPD is represented\nas a chronic obstructive cluster combining hyperinflated lungs, emphysematous change, and chronic cough. Fracture\npathways separate acute cortical breaks, old or healed deformity, and vertebral compression patterns. Tuberculosis\nincludes an explicit disease-state axis, contrasting active parenchymal opacity with old or inactive upper-lobe scarring\nthat shows calcified nodules and architectural distortion. Lung Cancer is represented by a focal nodular or mass-like\nopacity that may reflect primary or metastatic disease.\ninal_vs_original totaled 158 cases (0.8%).\nThese conflicts were dominated by positive cer-\ntainty conflicts: polarity accounted for 10 (6.3%)\nconflicts, certainty_pos for 74 (46.8%), cer-\ntainty_neg for 2 (1.3%), duplicate_pos for\n70 (44.3%), and duplicate_neg for 2 (1.3%).\nOverall conflicts across all sources summed to 774\n(4.0% of the initial expanded Lunguage dataset).\nResolution follows a deterministic policy: (1) if a\ngroup contains both original and expansion rows,\nretain the originals and discard the expansions\n(treat the report text as the clinical source of truth);\n(2) if the remaining rows show a pure polarity clash\nwith only dp and dn, drop the group; (3) otherwise\nselect the row with the highest prob. When multi-\nple rows tie on prob, break ties by a status priority\nthat reflects clinical certainty, dp > tp > tn > dn.\nAfter resolution, 18,810 rows remained (97.9% of\n19,216), implying 406 removals (2.1%); all remain-\ning inconsistencies were eliminated, preserving log-\nical consistency and clinical validity. Algorithm B2\ndetails the procedure.\n"}, {"page": 22, "text": "Category\nNon-merge pairs (substring-level)\nLaterality and anatomical direction\n(left, right), (left-sided, right-sided), (left-sided, right), (left, right-sided),\n(upper, lower), (mid, lower), (upper, mid), (upper, middle), (middle, lower),\n(anterior, posterior), (anterior, lateral), (posterior, lateral),\n(superior, inferior), (apical, basal), (central, peripheral),\n(proximal, distal), (medial, lateral), (ventral, dorsal)\nCardiopulmonary contextual conflicts\n(cardio, pulmonary), (mediastinal, pleural), (pericardial, pleural)\nDisease mechanism divergence\n(effusion, pneumothorax), (effusion, edema), (effusion, atelectasis),\n(effusion, consolidation), (effusion, pneumonia),\n(consolidation, opacification), (consolidation, atelectasis),\n(consolidation, edema), (atelectasis, pneumonia),\n(atelectasis, aeration), (atelectasis, opacity), (pneumonia, edema)\nMass vs. airspace process\n(mass, consolidation), (mass, opacity), (mass, atelectasis)\nTable B2: Manually curated blacklist of substring pairs that prevent merges during high-precision deduplication.\nConflict\nType\nexp ↔exp\nori ↔exp\nori ↔ori\ndn ↔tn\ncertainty_neg\n16\n0\n2\ndp ↔tp\ncertainty_pos\n133\n34\n74\ntn ↔tn\nduplicate_neg\n18\n0\n2\ntp ↔tp\nduplicate_pos\n181\n24\n70\ndp ↔dn\npolarity\n103\n107\n10\n451\n165\n158\nTable B3: Pathway expansion conflicts by source and type. ori and exp denote original and expansion.\nAlgorithm B1 Pathway Matching\nInput: (f, ℓ, a, v) from Lunguage, pathway dict D // f: finding, ℓ: loca-\ntion, a: attributes, v: view\nOutput: c⋆or none\n1: function SelectVariant(f, ℓ, a, v, D)\n2:\n(f ′, ℓ′, a′, v′) ←NormalizeInput(f, ℓ, a, v) // normalize row-\nlevel finding, location, attributes, and view\n3:\nD′ ←NormalizeDict(D) // normalize findings, locations, at-\ntributes, and views in all pathways\n4:\nc⋆←BestPathwayMatch(D′, f ′, ℓ′, a′, v′)\n5:\nreturn c⋆\n6: end function\n7: function BestPathwayMatch(D′, f ′, ℓ′, a′, v′)\n8:\nC ←{ c ∈D′ : Find(c) = f ′ }// finding-level lexical match\n9:\nif C = ∅then\n10:\nreturn none\n11:\nend if\n12:\nC\n←\n{ c\n∈\nC\n:\nLocOK(c, ℓ′) ∧AttrOK(c, a′) ∧\nViewOK(c, v′) }// joint compatibility on location, attributes, and\nview\n13:\nif |C| = 1 then\n14:\nreturn the sole element of C\n15:\nelse\n16:\nreturn none// ambiguous or incompatible (should not occur\nsince pathways are independent)\n17:\nend if\n18: end function\nAlgorithm B2 Conflict Resolution\nInput: Expanded dataset D with columns:\nstudy_id, entity,\nlocation,\nstatus ∈\n{dp, tp, tn, dn},\nprob,\nsource ∈\n{original, expansion}\nOutput: resolved_df\n1: keys ←[study_id, entity, location]\n2: RES ←[ ]\n3: for all group G ⊂D by keys do\n4:\nif |G| < 2 then continue\n5:\nend if\n6:\norig ←{ r ∈G | r.source = original }\n7:\nexpd ←{ r ∈G | r.source = expansion }\n— Case 1: original vs. expansion —\n8:\nif orig ̸= ∅and expd ̸= ∅then\nRule1: keep originals only; discard expansions\n9:\nappend all rows in orig to RES\n10:\ncontinue\n11:\nend if\n— Case 2: only originals or only expansions —\n12:\nR ←orig if orig ̸= ∅else expd\n13:\nhas_dp ←(∃r ∈R : r.status = dp)\n14:\nhas_dn ←(∃r ∈R : r.status = dn)\n15:\nhas_tp ←(∃r ∈R : r.status = tp)\n16:\nhas_tn ←(∃r ∈R : r.status = tn)\nRule2: drop if pure polarity clash\n17:\nif has_dp and has_dn and not(has_tp or has_tn) then\n18:\ncontinue\n19:\nend if\nRule 3: pick highest probability; dp > tp > tn > dn\n20:\np∗←max{ r.prob : r ∈R }\n21:\nif ∃r ∈R : r.prob = p∗∧r.status = dp then\n22:\nappend any such r to RES\n23:\nelse if ∃r ∈R : r.prob = p∗∧r.status = tp then\n24:\nappend any such r to RES\n25:\nelse if ∃r ∈R : r.prob = p∗∧r.status = tn then\n26:\nappend any such r to RES\n27:\nelse\n28:\nappend any r ∈R with r.prob = p∗to RES\n29:\nend if\n30: end for\n31: resolved_df ←Concat(RES)\n32: return resolved_df\n"}]}