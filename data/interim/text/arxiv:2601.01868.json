{"doc_id": "arxiv:2601.01868", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2601.01868.pdf", "meta": {"doc_id": "arxiv:2601.01868", "source": "arxiv", "arxiv_id": "2601.01868", "title": "DermoGPT: Open Weights and Open Data for Morphology-Grounded Dermatological Reasoning MLLMs", "authors": ["Jinghan Ru", "Siyuan Yan", "Yuguo Yin", "Yuexian Zou", "Zongyuan Ge"], "published": "2026-01-05T07:55:36Z", "updated": "2026-01-05T07:55:36Z", "summary": "Multimodal Large Language Models (MLLMs) show promise for medical applications, yet progress in dermatology lags due to limited training data, narrow task coverage, and lack of clinically-grounded supervision that mirrors expert diagnostic workflows. We present a comprehensive framework to address these gaps. First, we introduce DermoInstruct, a large-scale morphology-anchored instruction corpus comprising 211,243 images and 772,675 trajectories across five task formats, capturing the complete diagnostic pipeline from morphological observation and clinical reasoning to final diagnosis. Second, we establish DermoBench, a rigorous benchmark evaluating 11 tasks across four clinical axes: Morphology, Diagnosis, Reasoning, and Fairness, including a challenging subset of 3,600 expert-verified open-ended instances and human performance baselines. Third, we develop DermoGPT, a dermatology reasoning MLLM trained via supervised fine-tuning followed by our Morphologically-Anchored Visual-Inference-Consistent (MAVIC) reinforcement learning objective, which enforces consistency between visual observations and diagnostic conclusions. At inference, we deploy Confidence-Consistency Test-time adaptation (CCT) for robust predictions. Experiments show DermoGPT significantly outperforms 16 representative baselines across all axes, achieving state-of-the-art performance while substantially narrowing the human-AI gap. DermoInstruct, DermoBench and DermoGPT will be made publicly available at https://github.com/mendicant04/DermoGPT upon acceptance.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2601.01868v1", "url_pdf": "https://arxiv.org/pdf/2601.01868.pdf", "meta_path": "data/raw/arxiv/meta/2601.01868.json", "sha256": "13f23caa72cb1bdee2e16646d09531ab129881154919bfb29fb6dd8cc079216c", "status": "ok", "fetched_at": "2026-02-18T02:23:17.342907+00:00"}, "pages": [{"page": 1, "text": "DermoGPT: Open Weights and Open Data for Morphology-Grounded\nDermatological Reasoning MLLMs\nJinghan Ru1*\nSiyuan Yan2*†\nYuguo Yin1\nYuexian Zou1‡\nZongyuan Ge2‡\n1School of Electronic and Computer Engineering, Peking University\n2Faculty of Information Technology, Monash University, Melbourne, Australia\nAbstract\nMultimodal Large Language Models (MLLMs)\nshow promise for medical applications, yet\nprogress in dermatology lags due to limited\ntraining data, narrow task coverage, and lack\nof clinically-grounded supervision that mir-\nrors expert diagnostic workflows. We present\na comprehensive framework to address these\ngaps.\nFirst, we introduce DermoInstruct,\na large-scale morphology-anchored instruc-\ntion corpus comprising 211,243 images and\n772,675 trajectories across five task formats,\ncapturing the complete diagnostic pipeline\nfrom morphological observation and clinical\nreasoning to final diagnosis.\nSecond, we\nestablish DermoBench, a rigorous bench-\nmark evaluating 11 tasks across four clini-\ncal axes: Morphology, Diagnosis, Reasoning,\nand Fairness, including a challenging subset\nof 3,600 expert-verified open-ended instances\nand human performance baselines. Third, we\ndevelop DermoGPT, a dermatology reason-\ning MLLM trained via supervised fine-tuning\nfollowed by our Morphologically-Anchored\nVisual-Inference-Consistent (MAVIC) rein-\nforcement learning objective, which enforces\nconsistency between visual observations and\ndiagnostic conclusions. At inference, we de-\nploy Confidence-Consistency Test-time adap-\ntation (CCT) for robust predictions. Experi-\nments show DermoGPT significantly outper-\nforms 16 representative baselines across all\naxes, achieving state-of-the-art performance\nwhile substantially narrowing the human-\nAI gap.\nDermoInstruct, DermoBench and\nDermoGPT will be made publicly available\nat https://github.com/mendicant04/DermoGPT\nupon acceptance.\n* Equal Contribution.\n† Project Leader.\n‡ Corresponding Authors:\nzongyuan.ge@monash.edu,\nzouyx@pku.edu.cn.\n1\nIntroduction\nSkin diseases impose a substantial global bur-\nden, yet specialist access remains limited (Hay\net al., 2014). Dermatological diagnosis requires\ndifferentiating hundreds of fine-grained condi-\ntions across modalities via systematic clinical rea-\nsoning(Mogensen et al., 2008).\nWhile Multi-\nmodal Large Language Models (MLLMs) show\npromise(Comanici et al., 2025; Bai et al., 2025),\nexisting medical MLLMs (Chen et al., 2024; Zhou\net al., 2024a; Liu et al., 2025b) struggle with der-\nmatology’s specialized requirements due to lim-\nited training data, narrow task scopes, and lack of\ninterpretable reasoning mechanisms aligned with\nclinical practice.\nAs summarized in Table 1, current resources\nexhibit three systemic limitations hindering clini-\ncal viability. First, insufficient scale and diver-\nsity: Existing resources like DermaSynth (Yilmaz\net al., 2025) and MM-Skin (Zeng et al., 2025) typ-\nically cover only 2–3 tasks with limited samples.\nThis scarcity fails to capture the long-tail visual\ncomplexity of the hundreds of conditions, severely\nlimiting generalization. Second, limited task for-\nmulations: Existing instruction data and bench-\nmarks predominantly rely on close-ended Multiple-\nChoice Question Answering (MCQAs) (Yim et al.,\n2024), inadequate for evaluating open-ended gener-\nation and multi-step reasoning required in clinical\nconsultations. Third, ungrounded clinical reason-\ning: Unlike end-to-end models (Yan et al., 2025c,b)\nthat map pixels directly to labels, expert dermatol-\nogists adhere to a “morphology-first” paradigm,\nparsing lesion morphology attributes to construct\nreasoning chains before diagnosis (Mogensen et al.,\n2008; Errichetti and Stinco, 2016). Current datasets\nlack supervision for this morphology →reason-\ning →diagnosis trajectory, yielding ungrounded\nsystems prone to hallucinations inconsistent with\nvisual evidence.\n1\narXiv:2601.01868v1  [cs.CL]  5 Jan 2026\n"}, {"page": 2, "text": "Dataset / Benchmark\nType\nScale\nFeatures\nBench.\nTrain\n#Tasks\n#Images\n#VQA Pairs\nMulti-modal\nMorph. CoT\nCoT\nFairness\nSkinCon (Ren et al., 2024)\n✗\n✓\n2\n3,886\n–\n✗\n✗\n✗\n✗\nSkinCap (Zhou et al., 2024b)\n✗\n✓\n1\n4,000\n–\n✗\n✗\n✗\n✗\nSkinCaRe (Shen et al., 2024)\n✗\n✓\n2\n7,041\n7,041\n✗\n✗\n✓\n✗\nDermaSynth (Yilmaz et al., 2025)\n✗\n✓\n2\n45,205\n92,020\n✓\n✗\n✓\n✗\nMM-Skin (Zeng et al., 2025)\n✗\n✓\n3\n11,039\n27,412\n✓\n✗\n✗\n✗\nDermaVQA (Yim et al., 2024)\n✓\n✓\n1\n3,434\n1,488\n✓\n✗\n✗\n✗\nDermBench (Shen et al., 2025b)\n✓\n✗\n1\n4,000\n4,500\n✓\n✗\n✓\n✗\nDermoInstruct (Ours)\n✗\n✓\n4\n211,243\n772,675\n✓\n✓\n✓\n✗\nDermoBench (Ours)\n✓\n✗\n11\n12,371\n33,999\n✓\n✓\n✓\n✓\nTable 1: Comparison of instruction datasets and benchmarks for dermatology MLLMs. Our datasets significantly\nexpand task diversity and introduce morphology-grounded chain-of-thought reasoning (Morph. CoT) and fairness\nevaluation, addressing key gaps in existing resources.\nTo address these gaps, we propose a holistic\nframework centered on morphology-grounded rea-\nsoning. We first introduce DermoInstruct, a large-\nscale morphology-anchored instruction corpus uni-\nfying 14 heterogeneous public datasets under a\nshared diagnostic ontology with 9 superclasses and\n325 fine-grained subclasses. The dataset contains\n211,243 images and 772,675 instruction trajecto-\nries spanning 5 task formats: free-text morpholog-\nical description, structured attribute generation,\nclinically grounded Chain-of-Thought reasoning,\nflat diagnosis, and multi-turn hierarchical diagno-\nsis. This structured diversity ensures the model\nlearns the complete diagnostic trajectory from le-\nsion observation to morphology extraction to diag-\nnostic reasoning, rather than mere label prediction.\nWe also establish DermoBench, a comprehensive\nevaluation suite with 11 tasks across 4 clinical axes:\nMorphology, Diagnosis, Reasoning, and Fairness\n(Figure 1 and Table 2). For rigorous evaluation,\nwe constructed 3,600 open-ended instances from\na 900-case core image set with line-by-line spe-\ncialist revision to guarantee morphological fidelity\nand reasoning validity, providing “Gold Standard\"\nground truth. We also benchmarked expert derma-\ntologist performance as a clinical ceiling, enabling\nprecise quantification of the Human-AI gap.\nBuilding on these resources, we develop Der-\nmoGPT, a dermatology-specialized MLLM ini-\ntialized from Qwen3-VL-8B. The training pro-\nceeds through two phases.\nFirst, Supervised\nFine-Tuning (SFT) on DermoInstruct establishes\nfoundational diagnostic capabilities. Second, a\nnovel Morphologically-Anchored Visual-Inference-\nConsistent (MAVIC) reward aligns the model\nwith clinical reasoning trajectories. MAVIC uti-\nlizes Group Relative Policy Optimization (GRPO)\n(Shao et al., 2024) to penalize logical discon-\nnects between generated visual morphology de-\nscriptions and diagnostic conclusions, enforcing\nthe “morphology-first” reasoning trajectory. At in-\nference, a Confidence-Consistency Test-time adap-\ntation (CCT) scheme aggregates predictions to im-\nprove generalization. DermoGPT significantly out-\nperforms 16 baselines across all 11 tasks, particu-\nlarly in morphology understanding and reasoning\nconsistency, narrowing the Human-AI gap.\nOur contributions are three-fold:\n(1) Der-\nmoBench Benchmark: The first unified suite\nevaluating the full clinical pipeline beyond MC-\nQAs for dermatology. Validated against an expert-\nverified core set and human baselines, it exposes\nsystemic reliability gaps in current MLLMs. (2)\nDermoInstruct Dataset: The largest ontology-\naware corpus unifying 14 sources into structured\nmulti-task trajectories, providing the essential su-\npervision for versatile, clinically-aligned reasoning.\n(3) DermoGPT: The first clinical-aligned reason-\ning MLLM in dermatology utilizing the MAVIC\nand CCT. This approach yields substantial improve-\nments, significantly narrowing the human-AI gap\nin both diagnostic accuracy and reasoning.\n2\nRelated Work\nDermatology MLLMs and Reasoning.\nThe\nlandscape of dermatology AI has evolved from\nclosed-set classification (AlSuwaidan, 2023; Yan\net al., 2025c) to open-ended multimodal reason-\ning. Early works relied on discrimitive model with\nlimited label spaces (Yan et al., 2025a; Kawahara\net al., 2018). Recently, specialized MLLMs such\nas SkinGPT-4 (Zhou et al., 2024a), SkinGPT-R1\n(Shen et al., 2025a), and Skin-R1 (Liu et al., 2025b)\nhave adapted general foundation models to derma-\ntology via instruction tuning. While these mod-\nels demonstrate improved dialogue capabilities,\nthey typically treat diagnostic reasoning as a la-\ntent, black-box process. Unlike our DermoGPT,\nwhich enforces an explicit Morphology →Reason-\ning →Diagnosis workflow via concept bottleneck,\n2\n"}, {"page": 3, "text": "Morphology Understanding\nQ: How are the dots and \nglobules characterized \nin this skin lesion? A) \nAbsent B) Regular C) \nIrregular\nAttribute MCQA\n(Dermoscopy)\nQ: Which clinical \nfeature is present in \nthe image? A) Plaque \nB) Abscess C) Friable \nD) Black\nAttribute MCQA\n(Clinical)\nDetailed Description\nA: Dermoscopy reveals a small, \nroundish-to-oval, light brown macule \nwith ... There are no streaks or signs \nof regression.\nQ: Write a detailed ... image. \nBefore any reasoning, output a \n<morph> JSON using the Derm7pt \nschema.\nDetailed Description w/ <morph>\nA:<morph>{\"morphological_features_Derm\n7pt\": {\"pigment_network\":  \"absent\"  ...}  \n</morph> Dermoscopy reveals ... regression.\nExplainability & Reasoning \nQ: What skin condition is \ndepicted in this image? \nJustify your diagnosis \nwith a clear rationale.\nCoT Reasoning\nMorph-Grounded Diagnosis\nQ: What skin condition is \ndepicted in this image? Justify \nyour diagnosis with a clear \nrationale. Then output <morph> \nblock before final diagnosis.\nA:<reasoning>Upon examining...</reasoni\nng> <morph>{\"morphological_features_\nDerm7pt\": {\"pigment_network\":\"absent\n\",...}}</morph><final_diagnosis>Nevus</fi\nnal_diagnosis>\nDiagnosis Classification \nQ: Which of the following is \nthe most likely diagnosis?\n4-option ID MCQA\nA) Hailey Hailey Disease \nB) Xeroderma Pigmentosum \nC) Epidermal Nevus \nD) Nevus Lipomatosus \nA: B) Xeroderma Pigmentosum\nQ: Which is the most \nlikely diagnosis?\nA) Bacterial Infections \nB) Nail Fungus (Onychomycosis)\n............... \nY) Acral Melanotic Macule \nA: P) Green Nail\n25-option ID MCQA\nQ: Which is the most \nlikely diagnosis?\n4-option OOD MCQA\nA) Rosacea \nB) Dyshidrosiform eczema \nC) Neutrophilic dermatoses \nD) Chronic actinic dermatitis \nA: A) Rosacea\nQ: Proceeding from 'Disorders of \nSkin Appendages', which of the \nfollowing groups does this lesion \nbelong to?  \n\"Hair Follicle & Sebaceous Gland \nDisorders\", \"Nail Disorders\".\nHierarchical Diagnosis\nA: Nail Disorders\nFairness\nQ: Write a detailed \nmorphological examination \nreport for this image.\nA: A) Plaque\nA: C) Irregular\nA:<reasoning>\nUpon examining the image, the lesion \npresents...\n </reasoning>                                \n<final_diagnosis> Nevus \n</final_diagnosis>\"}\n4-option MCQA\nFST I\nQ: Please select the most accurate \ndiagnosis from the options below.\nA) Squamous Cell Carcinoma\nB) Keratoacanthoma\nC) Basal Cell Carcinoma\nD) Baso-squamous Carcinoma\nA: A) Squamous Cell Carcinoma\n4-option MCQA\nFST V\nA: A) Squamous Cell Carcinoma\nDermoBench\nQ: Please select the most accurate \ndiagnosis from the options below.\nA) Squamous Cell Carcinoma\nB) Keratoacanthoma\nC) Basal Cell Carcinoma\nD) Baso-squamous Carcinoma\nAcc Gap \nMinimized\nFigure 1: Overall architecture of DermoBench. DermoBench contains 11 subtasks spanning four axes: Morphology\n(Task 1.1 Detailed Description; Task 1.2 Morph-grounded Description; Task 1.3 Dermoscopic Attribute MCQA;\nTask 1.4 Clinical Attribute MCQA), Diagnosis (Task 2.1 4-option ID MCQA; Task 2.2 25-option ID MCQA;\nTask 2.3 hierarchical diagnosis; Task 2.4 4-option OOD MCQA), Reasoning (Task 3.1 CoT reasoning; Task 3.2\nMorph-grounded Reasoning), and Fairness (Task 4). Note that the same set of images is used across all open-ended\ntasks (Tasks 1.1, 1.2, 3.1, and 3.2).\nexisting approaches lack fine-grained grounding,\noften leading to hallucinations where visual evi-\ndence contradicts diagnostic conclusions.\nDermatology Training Data and Benchmarks.\nThe paradigm of dermatology AI has shifted\nfrom standard classification to large-scale vision-\nlanguage alignment, exemplified by Derm1M (Yan\net al., 2025a) and subsequent instruction-tuned\nMLLMs (Zhou et al., 2024a; Liu et al., 2025b).\nHowever, current approaches rely on small-scale\ninstruction data with limited task diversity. Further-\nmore, evaluation remains underdeveloped—while\nDermBench (Shen et al., 2025b) assesses diagnos-\ntic narratives, it lacks rigorous workflow verifica-\ntion. To address these gaps, we introduce Der-\nmoInstruct, an expert-curated dataset with 772K\nmorphology-grounded instruction pairs, and Der-\nmoBench, a multi-axis testbed that evaluates the\nfull clinical workflow from morphology and diag-\nnosis to OOD robustness and fairness.\n3\nDermoInstruct\nTo address the scarcity of clinically grounded train-\ning resources, we introduce DermoInstruct. Unlike\nprior works, this corpus is constructed to opera-\ntionalize the “morphology-first” diagnostic work-\nflow, providing high-quality supervision aligned\nwith a unified ontology.\n3.1\nDermoInstruct Curation\nThe construction pipeline employs a four-step strat-\negy to ensure both data scale and clinical rigor.\n(1) Aggregation & Rigorous Cleaning: We ag-\ngregated 14 public datasets spanning clinical and\ndermoscopic modalities. To strictly prevent data\nleakage, we implemented a patient-level split. We\nfurther applied perceptual hashing (pHash, Ham-\nming distance ≤2) to remove near-duplicate im-\nages, resulting in 211,243 distinct, high-quality\nimages (see Appendix A for source details).\n(2) Ontology Induction: Addressing the label frag-\nmentation issue across heterogeneous sources, we\nemployed GPT-5 to normalize 903 raw diagnos-\ntic strings into canonical clusters. These clusters\nwere rigorously reviewed by two dermatologists\nto merge synonyms and resolve ambiguities, yield-\ning a unified ontology of 9 superclasses and 325\nfine-grained subclasses (Figure 2b; zoom in).\n(3) Morphology-grounded Reasoning Synthesis:\nTo transcend the limitations of naive CoT, we im-\nplemented a Clinically-Aligned Reasoning Syn-\nthesis pipeline that mirrors the expert diagnostic\nworkflow: Observation →Abstraction →Deduc-\ntion. We prompted Gemini-2.5-Flash (Comanici\net al., 2025) via a strict dependency-aware protocol\n(detailed prompts could be found in Appendix C):\n(i) Morphological Inspection: First, generate de-\n3\n"}, {"page": 4, "text": "Melanocytic nevus\nBenign lesion\nBCC\nMelanoma\nAtypical/Spitzoid\nEczema/Dermatitis\nSeb. keratosis\nPsoriasis\nActinic keratosis\nSCC\nFungal infection\nSJS/TEN\nAcne\nInfestations/Bites\nVitiligo\n0\n5\n10\n15\n20\nPercentage (%)\nTop 15 Diseases Distribution\n(a)\nDisorders of Skin\nAppendages\nNail Disorders\nNail Dystrophy\nNail Disorder\nSpecific Nail\nAbnormalities\nTerry's Nails\nRacquet Nail\nPincer Nail Deformity / Syndrome\nOnychoschizia\nOnycholysis\nOnychogryphosis\nMedian Nail Dystrophy\nLeukonychia\nKoilonychia\nHalf And Half Nail\nGreen Nail\nClubbing Of Fingers\nBeau's Lines\nHair Follicle &\nSebaceous Gland\nDisorders\nTrichostasis Spinulosa\nPseudorhinophyma\nKeratosis Pilaris\nIngrown Hair\nHypertrichosis\nAlopecia\nReactions to\nExternal Agents\n(Physical, Chemical,\nDrug-induced)\nPhotodermatoses\n(Light-induced\nDisorders)\nSunburn\nSolar Telangiectasia\nSolar Elastosis\nPorphyria\nPhotodermatosis\nFavre Racouchot\nCutis Rhomboidalis Nuchae\nPhysical Trauma &\nEnvironmental\nOther\nPoisoning by Nematocyst\nInjection Site Disorder\nForeign Body Reaction\nExogenous\nPressure & Friction\nKnuckle Pads\nClavus / Callus\nInjury & Repair\nWound / Abrasion\nUlcer\nTraumatic Petechiae\nTraumatic Blister\nScar\nNeurotic Excoriations\nInflicted Skin Lesions\nHemorrhage / Hematoma\nGranulation Tissue\nErosion Of Skin\nDehiscence\nCat Scratch Injury\nTemperature &\nClimate\nSuperficial Frostbite\nMiliaria\nChilblain\nBurn\nDrug Reactions\nStevens-Johnson Syndrome / Toxic Epidermal Necrolysis (SJS/TEN)\nExanthems / Drug Reaction\nDrug Reaction / Pigmentation\nDrug Reaction / Photosensitivity\nDrug Reaction / Eruption\nAcute Generalised Exanthematous Pustulosis\nNeoplasms &\nProliferations\nBenign Tumors,\nGrowths & Cysts\nOther Proliferative\nConditions\nSupernumerary Nipple\nReactive Lymphoid Hyperplasia\nMelanocytic Lesions\n(Nevi/Moles)\nNevus / Mole / Melanocytic Nevus\nCysts\nMilia\nEpidermal Cyst\nCyst\nKeratinocytic &\nEpidermal\nProliferations\nSeborrheic Keratosis\nInverted Follicular Keratosis\nDilated Pore Of Winer\nDermatosis Papulosa Nigra\nClear Cell Acanthoma\nAdnexal (Appendage)\nTumors\nSebaceous Gland\nSebaceous Gland Hyperplasia\nSebaceous Adenoma\nFordyce Spots\nHair Follicle\nWarty Dyskeratoma\nTrichofolliculoma\nTrichoblastoma\nTrichilemmoma\nPilomatricoma\nEpithelioma Adenoides Cysticum\nSweat Gland\n(Eccrine/Apocrine)\nSyringoma\nSyringocystadenoma Papilliferum\nEccrine Poroma\nChondroid Syringoma\nNeural Tumors\nNeuroma\nNeurofibroma\nCellular Neurothekeoma\nBenign Lesion\nBenign Epidermal Lesion\nMuscle Tumors\nLeiomyoma\nAngioleiomyoma\nVascular Lesions\n(Benign)\nVascular Tumors\nTufted Angioma\nPyogenic Granuloma\nPort Wine Stain\nLymphangioma\nHemangioma\nGlomangioma\nBenign Telangiectases\nAngiokeratoma\nFibrous & Adipose\nTumors\nSkin Tag\nLipoma\nKeloid\nDermatofibroma / Fibroma / Fibrous Papule\nAngiofibroma\nMalignant &\nPremalignant Lesions\nMalignant Lesion / Skin Cancer / Malignant Neoplasm\nVascular Neoplasms\nKaposi's Sarcoma\nMetastatic Disease\nMetastatic Carcinoma\nCutaneous metastasis\nLymphoid &\nHematopoietic\nNeoplasms\nMycosis Fungoides\nLeukemia Cutis\nCutaneous Lymphoma\nBlastic Plasmacytoid Dendritic Cell Neoplasm\nKeratinocytic\n(Epithelial)\nNeoplasms\nSquamous Cell Carcinoma In Situ\nSquamous Cell Carcinoma\nKeratoacanthoma\nBaso-squamous Carcinoma\nBasal Cell Carcinoma\nMelanocytic\nNeoplasms\nMelanoma\nLentigo Maligna\nAtypical Melanocytic Lesion / Spitzoid Lesion\nPremalignant Lesions\nCutaneous Horn\nArsenical Keratosis\nActinic Keratosis\nActinic Cheilitis\nAutoimmune,\nConnective Tissue &\nGenetic Diseases\nAutoimmune &\nConnective Tissue\nDiseases\nMorphea / Scleroderma\nLupus Erythematosus / Connective Tissue diseases\nLupus Erythematosus\nLichen Sclerosus\nDermatomyositis\nBehcet's Disease\nBalanitis Xerotica Obliterans\nAutoimmune Skin Disease (Category)\nGenodermatoses\n(Inherited Skin\nDisorders)\nXeroderma Pigmentosum\nTuberous Sclerosis\nPseudoxanthoma Elasticum (PXE)-Like Syndrome\nIncontinentia Pigmenti\nIchthyosis\nHailey Hailey Disease\nGenodermatoses\nEpidermolysis Bullosa\nNevi Syndromes\nNevus Sebaceous of Jadassohn\nNevus Lipomatosus Superficialis\nNevus Comedonicus\nNaevus Comedonicus\nLinear Epidermal Nevus\nEpidermal Nevus\nEhlers Danlos Syndrome\nDarier's Disease\nAplasia Cutis Congenita\nAcrokeratosis Verruciformis\nManifestations of\nSystemic Disease &\nOther Conditions\nUncategorized\nOther / Not Specified\nMucha Habermann Disease\nMiscellaneous &\nMorphological Terms\nXerosis\nToe Deformity\nStriae / Stretch Marks\nSkin Atrophy\nPearl Penile Papules\nPapillomatosis Confluentes And Reticulate\nHypersensitivity Reaction\nHyperlinear Palm\nGranular Parakeratosis\nGanglion\nFlushing\nErythroderma / Exfoliative Dermatitis\nElephantiasis Nostras\nCrowe's Sign\nAnetoderma\nCutaneous\nManifestations of\nSystemic Disease\nSystemic Disease\nLangerhans Cell Histiocytosis\nGraft Vs Host Disease\nMetabolic/Endocrine\nXanthomas\nXanthogranuloma\nVerruciform Xanthoma\nJuvenile Xanthogranuloma\nEruptive Xanthoma\nVascular/Circulatory\nVenous Stasis Ulcer\nMal Perforans\nCutis Marmorata\nCalcinosis Cutis\nGastrointestinal\nAcrodermatitis Enteropathica\nDisorders of\nKeratinization &\nMucin Deposition\nKeratosis &\nKeratodermas\nPorokeratosis\nPerforating Dermatosis\nKyrle's Disease\nKeratosis\nKeratolysis Exfoliativa\nKeratoderma\nHyperkeratosis\nFocal Acral Hyperkeratosis\nDisseminated Actinic Porokeratosis\nAmyloidosis\nLichen Amyloidosis\nCutaneous Amyloidosis\nMucinosis\nScleromyxedema / Lichenoid Myxedema\nInflammatory Mucinosis\nFollicular Mucinosis\nDiscrete Papular Lichen Myxedematosus\nAcral Persistent Papular Mucinosis\nInflammatory\nDermatoses\nNeutrophilic Dermatoses\nSneddon-Wilkinson Disease\nPyoderma Gangrenosum\nGeneral / Broad\nCategories\nSkin Infection\nLight Diseases / Disorders of Pigmentation\nInflammatory Dermatosis\nInflammatory Changes on Sun-Damaged Skin\nInflammatory / Infectious Disorder\nPapulosquamous\nDisorders\nPsoriasis / Lichen Planus\nPsoriasis\nPityriasis Rubra Pilaris\nPityriasis Rosea\nPityriasis Lichenoides\nParapsoriasis\nLichen Striatus\nLichen Spinulosus\nLichen Simplex Chronicus\nLichen Planus\nLichen Nitidus\nKoebner Phenomenon\nGrover's Disease\nGranulomatous\nDisorders\nSarcoidosis\nNecrobiosis Lipoidica\nMajocchi Granuloma\nGranulomatous Disorder\nEczematous Disorders\n(Dermatitis)\nPerioral Dermatitis\nIntertrigo\nHemosiderin Pigmentation / Stasis Dermatitis / Edema\nEczema / Dermatitis\nDesquamation\nVasculitis &\nVascular Disorders\nVasculitis\nVaricose Vein\nSolar Purpura / Actinic Purpura\nSchamberg's Disease / Pigmented Purpuric Eruption\nPurpura / Petechiae / Ecchymosis\nLivedo Reticularis\nErythema Elevatum Diutinum\nContact Purpura\nVesiculobullous\n(Blistering)\nDiseases\nAutoimmune\nBlistering Diseases\nPemphigus\nLinear Iga Disease\nHerpes Gestationis\nDermatitis Herpetiformis\nBullous Pemphigoid\nBullous Disease\nOther Blistering\nConditions\nHemorrhagic Bullae\nBullosis Diabeticorum\nBlister / Bullous Lesion / Vesicles / Bullae\nOther Inflammatory\nConditions\nUnilateral Laterothoracic Exanthem\nStomatitis\nRelapsing Polychondritis\nPustules\nPruritic Urticarial Papules and Plaques of Pregnancy\nPrurigo / Prurigo Nodularis\nJessner Lymphocytic Infiltrate\nGeographic Tongue\nFox Fordyce Disease\nFollicular Pustules\nCheilitis\nChalazion\nAtrophic Glossitis\nAngular Cheilitis\nUrticaria &\nErythemas\nUrticaria\nOther Erythemas\nErythema Ab Igne\nReactive Erythemas\nFlagellate Erythema\nErythema Nodosum\nErythema Multiforme\nErythema Marginatum\nErythema Gyratum Repens\nErythema Annulare Centrifugum\nAnnular Erythema\nAcne Urticata\nAcneiform Disorders\nRosacea\nHidradenitis Suppurativa\nAcne Keloidalis Nuchae\nAcne / Rosacea\nAcne\nDisorders of\nPigmentation\nHypopigmentation\nVitiligo\nPityriasis Alba\nNevus Anemicus\nIdiopathic Guttate Hypomelanosis\nHyperpigmentation\nUrticaria Pigmentosa\nPoikiloderma\nOchronosis\nMucosal Melanotic Macule\nMelasma\nMelanin Pigmentation Due To Exogenous Substance\nLentigo / Solar Lentigo / Actinic Pigmentation\nErythema Dyschromicum Perstans\nCafe Au Lait Macule\nAcral Melanotic Macule\nAcanthosis Nigricans\nInfections &\nInfestations\nParasitic\nInfestations & Bites\nScabies / Lyme Disease / Infestations and Bites\nArthropod\nBites/Reactions\nTick Bite\nRocky Mountain Spotted Fever\nPediculosis Lids\nMyiasis\nFlea Bite Dermatosis\nErythema Migrans\nWorm/Larva\nInfections\nTungiasis\nNematode Infection\nCutaneous Larva Migrans\nViral Infections\nWart / Verruca\nViral Dermatological Disorders\nMolluscum Contagiosum\nHerpes Virus Infection\nHerpes / HPV / STDs\nViral Exanthems\nViral Exanthem\nVaricella / Chicken Pox Exanthem\nHand Foot And Mouth Disease\nCondyloma Acuminatum\nFungal Infections\n(Mycoses)\nNail Fungus (Onychomycosis)\nLymphocutaneous Sporotrichosis\nKerion\nFungal Infection\nCoccidioidomycosis\nCandidiasis\nBacterial Infections\nWound Infection\nTuberculosis Of Skin And Subcutaneous Tissue\nSyphilis\nPitted Keratolysis\nParonychia\nImpetigo\nFolliculitis / Furuncle\nEcthyma Gangrenosum\nEcthyma\nCellulitis / Erysipelas\nAbscess\nDermoBench\nOntology\n(b)\nT1.1\nT1.2\nT3.1\nT3.2\n0\n1\n2\n3\n4\n5\nScores\n3.95\n4.20\n4.10\n4.15\n4.45\n5.00\n3.75\n4.45\nRater 1\nRater 2\n(c)\nFigure 2: Overview of DermoBench. (a) Distribution of the top 15 diseases. (b) A unified ontology organizes 325\nfine-grained diagnoses in DermoBench and DermoInstruct into 9 top-level super-classes. Zoom in for details. (c)\nHuman ratings of LLM-as-a-Judge quality. 0 stands for “strongly disagree”, and 5 represents “strongly agree”\ntailed descriptions of salient lesion structures (e.g.,\nborders, symmetry) to simulate visual examination.\n(ii) Schema-Based Anchoring: Explicitly map\nthese visual findings to standardized medical ter-\nminologies (seven-point checklist (Kawahara et al.,\n2018) for dermoscopy, general dermatology guid-\nlines (Ren et al., 2024) for clinical images). This\nacts as a “concept bottleneck,” (Koh et al., 2020),\nanchoring pixel data to verifiable medical facts.\n(iii) Evidence-Informed Diagnosis: Finally, syn-\nthesize a reasoning chain that is rigorously condi-\ntioned on these extracted attributes. This enforces\na reasoning trajectory where the model must justify\nthe diagnosis via morphological evidences (e.g.,\n“presence of atypical network implies higher risk of\nmelanoma”), ensuring the reasoning is transparent,\ninterpretable, and clinically coherent.\n(4) Diagnosis VQA Construction: Complement-\ning the open-ended reasoning, we leveraged the\nunified ontology to synthesize structured decision-\nmaking tasks that test the model’s diagnostic pre-\ncision. For Flat MCQAs, we enforced clinical\nhardness by sampling distractors exclusively from\nsibling nodes or nearest neighbors (i.e., clinical\nmimics), demanding fine-grained discrimination\nbeyond random guessing. For Hierarchical In-\nstructions, we modeled diagnosis as a sequential\nroot-to-leaf traversal with an adaptive correction\nmechanism: if the reasoning trajectory deviates,\ncorrective prompts inject expert guidance to re-\nalign the diagnostic path, simulating the interactive\npedagogy of medical training.\n3.2\nDermoInstruct Data Analysis\nThe final corpus comprises 211,243 multimodal im-\nages and 772,675 instructions (646k used for train-\ning after holding out DermoBench evaluation splits;\nsee Appendix A.2). As illustrated in Figure 2, the\ndataset features a realistic long-tail disease distri-\nbution (Fig. 2a) organized under our unified ontol-\nogy of 9 superclasses and 325 subclasses (Fig. 2b).\nThe instruction data across 4 major task dimen-\nsions spans 5 formats forming a complete diagnos-\ntic loop: (1) Free-text morphological description;\n(2) Structured attribute generation (for concept\nbottleneck training); (3) Clinically grounded CoT\nreasoning; (4) Flat diagnosis; and (5) Multi-turn\nhierarchical diagnosis. This structured diversity en-\nsures the model learns to look, reason, and deduce,\nrather than just memorize labels.\n4\nDermoBench\n4.1\nBenchmark Construction\nWe construct DermoBench, a comprehensive evalu-\nation suite comprising 33,999 VQA pairs spanning\n11 subtasks across 4 dimensions: Morphology, Di-\nagnosis, Reasoning, and Fairness (Table 2 and Ap-\npendix Figure 5). The benchmark consists of 3,600\nopen-ended instances from a 900-case core im-\nage set (enabling cross-task consistency evaluation\nacross T1.1, T1.2, T3.1, T3.2) and 30,399 closed-\nended MCQAs. Each open-ended sample under-\nwent strict line-by-line dermatologist revision to\nserve as gold-standard references. Two reasoning\ntasks (T1.2, T3.2) require structured morphological\nevidence before diagnosis to prevent ungrounded\npredictions. Independent sanity checks by two der-\nmatologists confirmed high annotation quality with\nmean scores of 3.88–4.60 in a 5-scale score across\ntasks (Appendix Figure 5b). The closed-ended\ncomponent comprises 12,533 diagnoses, 654 fair-\nness and 17,212 attribute-related MCQAs across\n7 subtasks, including Out-of-Distribution tasks\n4\n"}, {"page": 5, "text": "(image     ,\n  query     )  \nPolicy MLLM\n...\nGroup Rollouts\n...\n...\nUpdate\nMAVIC Reward\nRewards    Advantages\n(image     ,\n  query     )  \n...\nPrompt Variants\nFrozen \nMLLM\n...\nLogits Distribution\nCCT Scoring\nWeighted \nAggregation\nFinal\nPrediction\n(a) MAVIC\n(b) CCT\nFigure 3: Method overview of MAVIC and CCT. (a) MAVIC integrates diagnosis accuracy, taxonomy-level similarity,\ngated morphology agreement, and format validity into a GRPO-style group reward to enforce morphology-first\nalignment. (b) CCT is a decoding-only test-time aggregation that reweights prompt-variant distributions by\nconfidence and cross-variant consistency, requiring no parameter updates.\n(T2.4). All images are isolated from training data\nto prevent leakage. Please refer to Appendix B for\ndetails about task definitions and data sources.\n4.2\nEvaluation Metrics\nWe adopt distinct metrics (Cai et al., 2025; Hao\net al., 2025) tailored to the nature of each subtask.\nFor closed-ended questions, we use standard accu-\nracy. For open-ended tasks, we employ an LLM-\nas-a-Judge protocol (using Gemini-2.5-Pro), which\ncompares model outputs against human-curated ref-\nerences to generate mean fidelity scores. Judge con-\nsistency was validated through model substitution\nexperiments and human sanity checks. Crucially,\nto quantify the real-world utility gap, we invited\nboard-certified dermatologists to complete all tasks.\nTheir performance serves as the clinical ceiling,\nallowing us to precisely measure where MLLMs\nfall short compared to human experts. Complete\nLLM-as-a-judge protocol are in Appendix D.\n5\nDermoGPT\nWe aim to develop models that follow the dermato-\nlogical reasoning chain morphology →reasoning\n→diagnosis with explicitly verifiable intermedi-\nate steps. We propose MAVIC (Morphologically-\nAnchored Visual-Inference-Consistent) reward, an\nend-to-end computable reward function requir-\ning no external judge, achieving morphology-first\nalignment during RL training. We further introduce\nCCT (Confidence–Consistency Test-time adapta-\ntion), a plug-and-play decoding strategy that en-\nhances OOD generalization without fine-tuning.\nHyperparameters and implementation details are\ndocumented in Appendix E.\n5.1\nMAVIC: Morphologically-Anchored\nVisual-Inference-Consistent Reward\nWe begin with multi-task supervised fine-tuning\n(SFT) on DermoInstruct using Qwen3-VL-8B-\nInstruct (Bai et al., 2025).\nWe optimize cross-\nentropy loss for 1 epoch with LoRA (rank 64,\nα = 64, dropout 0.05) while freezing the LLM and\ntraining the vision tower and projector, obtaining\nDermoGPT-SFT. To enable automatic verification\nof morphological evidence, we adopt a concept bot-\ntleneck framework (Koh et al., 2020) that compels\nthe model to output structured morphological fea-\ntures following the “seven-point checklist” (Kawa-\nhara et al., 2018) and “general dermatology guide-\nline” (Ren et al., 2024) schema. This structured\noutput enables direct computation of morphology-\nlevel rewards without external judges—a key de-\nparture from prior approaches that rely on costly\nLLM-as-a-judge pipelines.\nHowever, RL training for open-ended morphol-\nogy descriptions faces a critical challenge: lack of\ndirectly verifiable reward signals. Diagnosis-only\nrewards are sparse and encourage shortcut learning\nthat bypasses morphological evidence. To address\nthis, we design MAVIC reward with the following\ncomponents. Given an image and instruction, we\nsample G completions from the current policy fol-\nlowing GRPO (Shao et al., 2024) and compute the\nfollowing reward components for each rollout:\n(1) Racc: Standard 0-1 reward for tasks with unique\n5\n"}, {"page": 6, "text": "Axis\nTask\nType\n#Pairs\nMorphology\nT1.1 Detailed Description\nOpen-ended\n900\nT1.2 Morph-grounded Description\nOpen-ended\n900\nT1.3 Dermoscopic attribute MCQA\nMCQA\n5,530\nT1.4 Clinical attribute MCQA\nMCQA\n11,682\nDiagnosis\nT2.1 ID 4-way MCQA\nMCQA\n2,000\nT2.2 ID 25-way MCQA\nMCQA\n2,000\nT2.3 Hierarchical diagnosis\nMCQA (multi-step)\n2,000\nT2.4 OOD 4-way MCQA\nMCQA\n6,533\nReasoning\nT3.1 CoT reasoning\nOpen-ended\n900\nT3.2 Morph-grounded reasoning\nOpen-ended\n900\nFairness\nT4 Skin-type fairness MCQA\nMCQA\n654\nTable 2: DermoBench tasks, sizes, and data sources.\nground-truth (e.g., MCQAs).\n(2) Shier ∈[0, 1]: Hierarchical similarity over\nthe diagnostic ontology using Wu-Palmer func-\ntion (Wattiheluw and Sarno, 2018). This differen-\ntiates completely incorrect diagnoses from predic-\ntions correct at superclass level, mitigating sparse\nrewards while encouraging coarse-to-fine diagnos-\ntic alignment.\n(3) Smorph ∈[0, 1]: Morphology similarity com-\nputed via PMI-weighted Tversky matching on\nstructured outputs (Derm7pt/SkinCon attributes).\n(4) Gating g(·) and Rfmt: To prevent models\nfrom exploiting template-style morphology outputs\nwhen diagnoses diverge from ground truth, we pro-\ngressively unlock morphology rewards only when\ndiagnostic alignment is reasonable:\ng(Shier) = σ\n\u0000k · (Shier −µ)\n\u0001\n,\n(1)\nwhere µ is the median Shier within each batch\n(adaptive difficulty threshold). Rfmt verifies JSON\nschema validity and critical tags to ensure auditable\noutputs. The total MAVIC reward is:\nR = Racc + λhierShier + λmorph g(Shier) Smorph + Rfmt,\n(2)\nwith λhier = λmorph = 1 by default. We opti-\nmize the standard GRPO objective using MAVIC\nrewards to obtain DermoGPT-RL. Complete imple-\nmentation detail is in Appendix E.2.\n5.2\nConfidence–Consistency Test-time\nAdaptation\nTo further improve generalization under distribu-\ntion shifts, we note that trivial deterministic de-\ncoding often yields unstable predictions on out-of-\ndistribution (OOD) samples, yet full test-time fine-\ntuning is infeasible in clinical workflows. Thus,\nwe propose CCT, a purely decoding-level strategy\nthat enhances OOD robustness through weighted\naggregation of multiple stochastic rollouts, without\nupdating model parameters. The key insight is that\nreliable predictions should be both confident and\nconsistent across sampling variations, aligning with\ndermatological practice where diagnostic certainty\nrequires stable evidence.\n5.2.1\nConfidence–Consistency Ensemble\nAt each decoding step t for input (x, query), we\nsample K rollouts yielding token distributions\np(1)\nt , . . . , p(K)\nt\n∈∆V −1. For each rollout r, we\ncompute:\nConfidence Cr (margin-based): Let p(r)\nt,(1) and\np(r)\nt,(2) denote the highest and second-highest prob-\nabilities in p(r)\nt . We define Cr = p(r)\nt,(1) −p(r)\nt,(2) ∈\n[0, 1]. A larger margin indicates a more confident\nprediction. For discrete answer tasks, we compute\nthis over option tokens; for free-form generation,\nover the full vocabulary.\nConsistency Dr (deviation from barycenter):\nWe compute the empirical barycenter ¯pt\n=\n1\nK\nPK\nj=1 p(j)\nt\nand set Dr = 1\n2 ∥p(r)\nt\n−¯pt∥2\n2. Roll-\nouts that deviate significantly from ¯pt (large Dr)\nare downweighted exponentially.\nWe construct the aggregated distribution via\nweighted combination:\nqt =\nK\nX\nr=1\nwrp(r)\nt ,\nwr =\nexp(λCr −βDr)\nPK\nj=1 exp(λCj −βDj)\n,\n(3)\nwhere λ and β control the relative importance of\nconfidence and consistency. The weighting ex-\nponentially suppresses outlier rollouts (high Dr)\nwhile favoring confident predictions (high Cr), en-\nsuring predictions are both stable and confident,\ncritical for clinical reliability. The next token is\nsampled from qt, and this process repeats for each\nstep. In practice, we set K = 8 and λ = β = 1.0.\n5.2.2\nTheoretical Guarantee\nTo formalize the robustness of this weighting\nscheme, we establish the following guarantee un-\nder distribution contamination; full proofs appear\nin Appendix G.\nTheorem 1 (Robustness of CCT, informal). Let\n{p(r)\nt }K\nr=1 be sampled from a mixture where frac-\ntion (1 −ε) comes from a “good” component\nconcentrated near p⋆\nt , and fraction ε comes from\nan arbitrary “bad” component (ε < 1\n2). Under\nbounded variance assumptions, there exist con-\nstants εeff, CU, γeff > 0 such that:\n\r\rqt −p⋆\nt\n\r\r\n2 ≤εeff + CU + const · exp\n\u0000−βγeff + λ\n\u0001\n. (4)\nThe bound shows that corrupted rollouts’ in-\nfluence decays exponentially with β, keeping qt\n6\n"}, {"page": 7, "text": "Model\nParams\nTask 1: Morphology\nTask 2: Diagnosis\nTask 3: Reasoning\nTask 4\nT1.1\nT1.2\nT1.3\nT1.4\nAvg.\nIn-Distribution (ID)\nOut-of-Distribution (OOD)\nT3.1\nT3.2\nAvg.\nFair.\n(Desc)\n(Struct)\n(D7pt)\n(SkinCon)\n(T1)\n4-cls\n25-cls\nHier.\nAvg.\nDerm1M\nDDI\nD7pt\nSNU\nAvg.\n(CoT)\n(M-CoT)\n(T3)\n(Score)\nGeneral Purpose MLLMs\nGPT-4o-mini\n/\n34.55\n51.80\n41.19\n61.09\n47.16\n59.50\n34.75\n65.90\n53.38\n52.12\n58.54\n56.48\n59.17\n56.57\n42.83\n51.65\n47.24\n94.06\nClaude-Sonnet-4.5-Thinking\n/\n36.75\n55.90\n29.73\n59.20\n45.40\n55.35\n34.15\n63.40\n50.97\n53.64\n52.90\n50.40\n68.75\n56.42\n43.54\n54.37\n48.95\n91.40\nGemini-2.5-Flash\n/\n40.08\n53.48\n39.28\n66.59\n49.86\n72.60\n47.20\n70.31\n63.37\n66.33\n59.15\n53.96\n65.42\n61.21\n48.92\n58.49\n53.70\n79.89\nGLM-4.5V\n106B\n36.85\n42.75\n45.50\n52.03\n44.28\n63.65\n28.85\n52.39\n48.30\n45.51\n48.17\n43.08\n57.08\n48.46\n44.19\n53.28\n48.73\n93.59\nQwen2.5-VL-72B\n72B\n27.97\n49.35\n52.91\n60.51\n47.69\n61.50\n35.95\n53.93\n50.46\n54.63\n54.88\n58.36\n66.67\n58.63\n40.39\n49.71\n45.05\n97.32\nQVQ-72B-Preview\n72B\n22.38\n41.02\n49.77\n59.20\n43.09\n64.65\n47.30\n57.25\n56.40\n60.53\n53.66\n56.92\n62.92\n58.51\n51.56\n54.14\n52.85\n86.26\nLlama-3.2-90B\n90B\n28.20\n44.43\n35.84\n49.19\n39.41\n47.85\n51.65\n51.20\n50.23\n44.76\n49.09\n37.14\n49.58\n45.14\n44.61\n56.14\n50.38\n91.31\nLlama-3.2-11B\n11B\n12.33\n38.48\n39.13\n29.93\n29.97\n29.25\n16.50\n35.98\n27.58\n25.50\n21.80\n26.90\n42.92\n29.28\n36.16\n38.29\n37.22\n53.85\nNemotron-Nano\n12B\n18.93\n29.09\n38.72\n59.20\n36.49\n47.25\n25.60\n40.17\n37.67\n44.12\n39.48\n36.84\n52.08\n43.14\n31.90\n37.40\n34.65\n92.40\nQwen3-VL-32B\n32B\n50.30\n57.43\n46.15\n60.67\n53.64\n64.25\n38.05\n64.08\n55.46\n48.13\n57.93\n63.11\n69.58\n59.69\n55.04\n53.85\n54.45\n81.78\nQwen3-VL-8B (Base)\n8B\n33.18\n46.05\n40.43\n62.06\n45.43\n67.20\n45.35\n44.77\n52.44\n52.67\n51.07\n59.10\n55.42\n54.31\n47.53\n53.43\n50.48\n89.37\nMedical/Dermatology Specialized\nHuatuoGPT-Vis-7B\n7B\n18.15\n34.50\n33.82\n38.15\n31.15\n51.60\n26.05\n46.10\n41.25\n31.40\n36.13\n41.64\n47.92\n39.27\n39.41\n43.98\n41.69\n76.80\nLLaVA-Med-v1.5\n7B\n23.07\n29.73\n40.15\n56.42\n37.34\n49.65\n32.40\n43.29\n41.78\n41.38\n36.74\n33.63\n37.08\n37.21\n38.33\n46.19\n42.26\n60.48\nSkinVL-PubMM\n7B\n27.82\n42.63\n43.62\n61.31\n43.84\n57.15\n38.75\n52.19\n49.36\n51.12\n48.93\n58.95\n54.58\n53.40\n42.92\n54.62\n48.77\n83.04\nLingshu-32B\n32B\n14.94\n44.85\n43.47\n52.39\n38.91\n53.45\n38.40\n49.11\n46.99\n30.29\n34.91\n32.24\n45.83\n35.82\n44.41\n49.55\n46.98\n75.44\nLingshu-7B\n7B\n16.44\n40.74\n43.92\n46.08\n36.80\n49.55\n31.90\n43.43\n41.64\n25.95\n32.16\n33.88\n40.00\n33.00\n47.16\n49.30\n48.23\n61.58\nDermoGPT-SFT\n8B\n41.74\n49.11\n53.69\n75.56\n55.02\n89.55\n64.30\n77.91\n77.25\n68.91\n62.80\n65.88\n59.17\n64.19\n62.57\n63.34\n62.95\n91.12\nDermoGPT-SFT + CCT\n8B\n43.49\n50.96\n54.10\n75.92\n56.12\n89.75\n64.45\n78.06\n77.42\n70.65\n64.33\n65.58\n61.25\n65.45\n63.73\n65.31\n64.52\n92.41\nDermoGPT-RL\n8B\n43.93\n59.29\n56.53\n76.67\n59.10\n90.30\n64.60\n79.12\n78.01\n69.68\n62.80\n68.59\n60.00\n65.27\n66.04\n65.48\n65.76\n93.49\nDermoGPT-RL + CCT\n8B\n44.76\n60.33\n56.94\n77.22\n59.81\n89.60\n65.40\n79.12\n78.04\n71.56\n62.96\n70.13\n61.25\n66.48\n67.74\n66.64\n67.19\n93.88\nHuman Performance\n-\n73.36\n79.27\n83.00\n92.00\n81.90\n85.00\n77.00\n87.54\n83.18\n94.00\n86.00\n89.00\n93.00\n90.50\n82.15\n78.41\n80.28\n94.00\nTable 3: Main Results on DermoBench. We evaluate models across four dimensions, and report each model’s\nparameter count when publicly available (Params; “/” denotes unknown). Blue columns indicate open-ended gen-\neration tasks (description and structured output), while orange columns indicate close-ended classification/scoring\ntasks. White columns represent aggregate metrics. CCT denotes our confidence–consistency test-time adaptation\nmodule. Bold indicates the best result in each column.\nnear p⋆\nt when β is sufficiently large relative to λ.\nThis theoretical guarantee explains why CCT re-\nmains robust even when a substantial fraction (up to\nε < 50%) of rollouts are corrupted by distribution\nshifts—the aggregation automatically suppresses\noutliers without requiring knowledge of the corrup-\ntion distribution.\n6\nExperiments\nPerformance on Closed-Ended Tasks. We eval-\nuate model accuracy across Dermoscopic/Clinical\nAttribute Recognition (T1.3–1.4), Diagnosis (in-\ncluding In-Distribution 4-cls/25-cls/Hierarchical\nMCQA and OOD MCQA; T2), and Fairness (T4).\nResults demonstrate that our DermoGPT-SFT base-\nline alone establishes a new state-of-the-art, validat-\ning the high quality of our instruction data. On In-\nDistribution (ID) diagnosis (T2 Avg), SFT achieves\n77.25%, surpassing its base model (Qwen3-VL-\n8B; 52.44%) and the strongest commercial base-\nline Gemini-2.5-Flash (63.37%) by substantial mar-\ngins; notably, it excels in Hierarchical Diagnosis\n(77.91% vs. Gemini 70.31%) and Clinical Attribute\nRecognition (T1.4: 75.56% vs. Gemini 66.59%).\nBuilding on this foundation, our subsequent mod-\nules steadily improve robustness: the RL stage\nenhances OOD performance from 64.19% (SFT)\nto 65.27%, and the CCT module further elevates\nit to 66.48% by mitigating domain shifts. Conse-\nquently, our final DermoGPT-RL+CCT establishes\na comprehensive new state-of-the-art, significantly\noutperforming Gemini-2.5-Flash across all axes:\nit improves ID and OOD diagnostic accuracy by\n+14.67% and +5.27%, respectively; crucially, it\nsimultaneously achieves an exceptional Fairness\nscore of 93.88 (Task 4), surpassing Gemini (79.89)\nby nearly 14%, effectively minimizing diagnostic\ndisparities across diverse skin tones.\nOpen-Ended Morphology & Reasoning.\nIn\nOpen-Ended Morphology and Reasoning tasks\n(T1.1, T1.2, T3), DermoGPT-RL+CCT demon-\nstrates superior generation quality over both\ngeneral-purpose MLLMs and existing medical-\nspecialized models. Notably, previous medical spe-\ncialized models (e.g., HuatuoGPT-Vis-7B) score\nonly 41.69% on the Reasoning axis, lower than\nmost general MLLMs, suggesting that naive fine-\ntuning without morphological constraints produces\n\"black-box\" classifiers rather than genuine reason-\ning agents. In contrast, our model scores 67.19%\non the Reasoning axis on average (T3), outperform-\ning Gemini-2.5-Flash (53.70%) by over 13.49%;\nthis verifies that our Concept Bottleneck design\neffectively reduces hallucination by grounding rea-\nsoning in explicit morphological evidence. Human\nsanity checks confirmed high reliability of LLM-\nJudge scoring (> 4.0/5.0, Figure 2c). Despite\nthese algorithmic advances, a significant Human-\nAI gap persists, particularly in Detailed Description\n(T1.1; 73.36 vs 44.76), highlighting that capturing\nfine-grained visual nuances remains a critical chal-\n7\n"}, {"page": 8, "text": "Task 1.1       Detailed Description\nQ:Summarize all important morphological \nfeatures visible in this image.\nGT: Dermoscopy reveals a flat, light to medium \nbrown macule characterized predominantly by \nthe presence of multiple small brown dots and \nglobules. These dots and globules vary slightly in \nsize and are distributed in a somewhat irregular \nand haphazard fashion, becoming sparser \ntowards the periphery of the lesion. The overall \noutline of the lesion appears mildly irregular. \nThere is no evidence of a pigment network, blue-\nwhitish veil, or distinct vascular structures. No \nstreaks or regression structures are observed.\nscore = 15.4\nDermoGPT-RL (condensed):\nDermoscopy reveals a flat macule with heterogeneous light–medium brown pigmentation \nand numerous small dark brown dots with some slightly larger globules,\n irregularly distributed and varying in size. A distinct pigment network is not discernible, \nand there is no evidence of a blue-whitish veil, specific vascular structures, streaks, or \nregression structures.\nscore = 80.0\nTask 3.2       Morph-Grounded Reasoning\nQ:Analyze the clinical presentation in this image. What is your \ndifferential diagnosis, and what is the final conclusion? Explain \nyour reasoning.\\n\\nThen output EXACTLY three blocks in this \norder and nothing else\nGT: (condensed)\n<reasoning>Symmetric, homogeneous dark-brown macule; \nwell-defined regular border; no atypical structures.  \n</reasoning><morph>{\"pigment_network\":\"absent\",\"pigment\nation\":\"diffuse regular\", \"blue_whitish_veil\":\"absent\", \n\"vascular_structures\":\"absent\",\"streaks\":\"absent\",\"dots_and_g\nlobules\":\"absent\",\"regression_structures\":\"absent\"}</morph>\n<final_diagnosis>Melanocytic nevus</final_diagnosis>\nGemini 2.5 Flash (condensed):\n<reasoning>Reports atypical network + irregular globules + irregular pigmentation; no \nveil/vessels/streaks/regression.</reasoning> <morph>{\"pigment_network\":\"atypical\",\n\"pigmentation\":\"diffuse irregular\", \"blue_whitish_veil\":\"absent\", \"vascular_structures\":\n\"absent\", \"streaks\":\"absent\", \"dots_and_globules\":\"irregular\", \"regression_structures\":\"absent\"} \n</morph> <final_diagnosis>Melanocytic nevus</final_diagnosis>\nscore = 52.3\nDermoGPT-RL (condensed):\n<reasoning>Small symmetric macule; uniform light–medium brown;  sharp \nregular border; no veil/regression.</reasoning>   \n<morph> {\"pigment_network\":\"absent\",\"pigmentation\":\"diffuse regular\", \"blue_whitish_veil\": \n\"absent\",\" vascular_structures\":\"absent\", \"streaks\":\"absent\", \"dots_and_globules\":\"absent\", \n\"regression_structures\": \"absent\"}</morph> <final_diagnosis>Melanocytic \nnevus</final_diagnosis>\nscore = 90.1\nGemini 2.5 Flash (condensed):\nThe lesion shows a multicomponent, relatively symmetrical reticular–globular \npattern. Centrally, there is a cluster of numerous, well-defined brown dots and small \nglobules,  creating a negative pigment network appearance; peripherally, a faint, \ndelicate, regular light-brown pigment network is described with indistinct, gradually \nfading borders. Color is mainly light brown at the periphery with darker brown \ncentrally, without black/blue/grey or marked red tones.\nFigure 4: Qualitative comparison on DermoBench. Left: Task 1.1 (Detailed Description). Right: Task 3.2\n(Morph-Grounded Reasoning with ultra-short structured outputs). Compared to Gemini-2.5 Flash, DermoGPT-RL\nbetter matches the reference morphology and achieves higher scores.\nSetting\nT1.1\nT1.2\nT3.1\nT3.2\nSFT only\n41.74\n49.11\n62.57\n63.34\nGRPO (acc+fmt)\n35.13\n41.20\n61.34\n59.88\nw/o Smorph\n39.65\n48.09\n65.40\n65.27\nw/o Shier\n42.59\n50.11\n63.96\n65.02\nw/o gate (g=1)\n43.26\n56.03\n66.71\n63.89\nPMI→uniform\n42.56\n56.98\n57.32\n56.64\nFull MAVIC\n43.93\n59.29\n66.04\n65.48\nTable 4: MAVIC ablations under GRPO setup (K=8).\nHigher is better for all metrics.\nMethod\nID MCQA OOD MCQA\nHier.\nFair.\nSingle (K=1)\n77.80\n65.27\n79.63 93.49\nVote (K=4)\n78.10\n65.83\n79.15 93.50\nMeanProb (K=4)\n77.95\n65.69\n79.51 93.32\nConfOnly (K=4)\n78.40\n66.47\n79.49 93.09\nConsOnly (K=4)\n78.35\n66.59\n79.82 93.58\nCC (Ours, K=4)\n78.80\n66.27\n80.31 93.76\nTable 5: Ablation of confidence–consistency compo-\nnents on 900-case core set. Higher is better for all\nmetrics.\nlenge.\nAblation Study. We further dissect component\ncontributions on the core set and OOD benchmarks.\nPlease refer to Appendix F for more results.\n(1) MAVIC Reward Analysis. We first investigate\nthe necessity of morphology-guided rewards (Ta-\nble 4). Naively applying standard RL with only\naccuracy and format rewards (GRPO(acc+fmt))\nproves detrimental, degrading performance below\nSFT baseline across all reasoning tasks. This in-\ndicates that unconstrained RL encourages metric\ngaming rather than genuine clinical reasoning. In-\ncorporating morphological similarity (Smorph) and\nhierarchical diagnosis rewards (Shier) steadily im-\nproves performance. Crucially, the full MAVIC\nsetup with gating mechanism (g) achieves peak per-\nformance (65.48 on T3.2). Ablating the gate drops\nperformance to 63.89, confirming that difficulty-\naware gating prevents the model from bypassing\nmorphological evidence to make uninformed diag-\nnostic guesses.\n(2) CCT Test-Time Adaptation Analysis. We\nevaluate test-time inference with K prompt vari-\nants and find that Confidence–Consistency (CC)\naggregation consistently outperforms standard en-\nsemble baselines (Majority Vote, MeanProb). As\nshown in Table 5, on Task 2.1, neither signal alone\nis sufficient: ConfOnly (78.40%) and ConsOnly\n(78.35%) both underperform CC (78.80%), indi-\ncating complementary robustness cues. We also\nobserve test-time scaling: as K increases from 2 to\n8, OOD performance rises from 65.82% to 66.48%,\nsupporting TTS for improved reliability.\nQualitative Analysis.\nFig. 4 validates Der-\nmoGPT’s reasoning superiority over Gemini-2.5-\nFlash, which exhibits hallucinated morphology\nconcepts (Task 1.1) and inconsistent reasoning\nbetween observations and diagnoses (Task 3.2).\nMAVIC-guided training enables DermoGPT to\nmaintain strict alignment, achieving significantly\nhigher accuracy in feature description and diagnos-\ntic consistency.\n7\nConclusion\nWe present a comprehensive framework for derma-\ntology MLLMs grounded in morphology-first clini-\ncal reasoning. Our unified data–benchmark–model\n8\n"}, {"page": 9, "text": "suite—comprising DermoInstruct, DermoBench,\nand DermoGPT—enables systematic training and\nevaluation across diverse dermatological tasks, sig-\nnificantly advancing the state-of-the-art while nar-\nrowing the human–AI performance gap. This work\nestablishes a foundation for developing clinically-\nviable dermatology AI systems that mirror expert\ndiagnostic workflows.\nLimitations\nDespite substantial progress, several limitations\nwarrant discussion. First, while DermoGPT signif-\nicantly narrows the human–AI gap, performance\ndisparities persist across all tasks, highlighting the\ninherent difficulty of clinical-grade diagnostic rea-\nsoning. Second, although our benchmark is com-\nprehensive, it may not fully capture the complexity\nof real-world clinical scenarios, such as patient-\nlevel holistic analysis (Yan et al., 2025c) or cases\nrequiring longitudinal patient histories. Third, de-\nspite integrating expert knowledge during data cu-\nration, the morphology-grounded reasoning chains\nremain susceptible to noise, particularly in ambigu-\nous cases where visual features alone are insuffi-\ncient for definitive diagnosis. Finally, computa-\ntional constraints limited our exploration of larger\nmodel architectures and full parameter fine-tuning,\nboth of which may further improve performance.\nReferences\nLulwah AlSuwaidan. 2023.\nDeep learning based\nclassification of dermatological disorders. Biomed-\nical\nengineering\nand\ncomputational\nbiology,\n14:11795972221138470.\nShuai Bai, Yuxuan Cai, Ruizhe Chen, Keqin Chen,\nXionghui Chen, Zesen Cheng, Lianghao Deng, Wei\nDing, Chang Gao, Chunjiang Ge, and 1 others.\n2025. Qwen3-vl technical report. arXiv preprint\narXiv:2511.21631.\nZhenyang Cai, Jiaming Zhang, Junjie Zhao, Ziyi Zeng,\nYanchao Li, Jingyi Liang, Junying Chen, Yunjin\nYang, Jiajun You, Shuzhi Deng, and 1 others. 2025.\nDentalgpt: Incentivizing multimodal complex reason-\ning in dentistry. arXiv preprint arXiv:2512.11558.\nBill Cassidy, Connah Kendrick, Andrzej Brodzicki,\nJoanna Jaworek-Korjakowska, and Moi Hoon Yap.\n2022. Analysis of the isic image datasets: Usage,\nbenchmarks and recommendations. Medical image\nanalysis, 75:102305.\nJunying Chen, Ruyi Ouyang, Anningzhe Gao, Shunian\nChen, Guiming Hardy Chen, Xidong Wang, Ruifei\nZhang, Zhenyang Cai, Ke Ji, Guangjun Yu, Xiang\nWan, and Benyou Wang. 2024. Huatuogpt-vision,\ntowards injecting medical visual knowledge into mul-\ntimodal llms at scale. Preprint, arXiv:2406.19280.\nAlbert S Chiou, Jesutofunmi A Omiye, Haiwen Gui,\nSusan M Swetter, Justin M Ko, Brian Gastman,\nJoshua Arbesman, Zhuo Ran Cai, Olivier Gevaert,\nChristoph Sadée, and 1 others. 2025. Multimodal\nimage dataset for ai-based skin cancer (midas) bench-\nmarking. NEJM AI, 2(6):AIdbp2400732.\nGheorghe Comanici, Eric Bieber, Mike Schaekermann,\nIce Pasupat, Noveen Sachdeva, Inderjit Dhillon, Mar-\ncel Blistein, Ori Ram, Dan Zhang, Evan Rosen, and\n1 others. 2025. Gemini 2.5: Pushing the frontier with\nadvanced reasoning, multimodality, long context, and\nnext generation agentic capabilities. arXiv preprint\narXiv:2507.06261.\nMarc Combalia, Noel CF Codella, Veronica Rotem-\nberg, Brian Helba, Veronica Vilaplana, Ofer Re-\niter, Cristina Carrera, Alicia Barreiro, Allan C\nHalpern, Susana Puig, and 1 others. 2019. Bcn20000:\nDermoscopic lesions in the wild.\narXiv preprint\narXiv:1908.02288.\nRoxana Daneshjou, Kailas Vodrahalli, Roberto A\nNovoa, Melissa Jenkins, Weixin Liang, Veronica\nRotemberg, Justin Ko, Susan M Swetter, Elizabeth E\nBailey, Olivier Gevaert, and 1 others. 2022. Dis-\nparities in dermatology ai performance on a di-\nverse, curated clinical image set. Science advances,\n8(31):eabq6147.\nDermNet. 2023. Dermnet. Accessed: 2023.\nEnzo Errichetti and Giuseppe Stinco. 2016.\nDer-\nmoscopy in general dermatology:\na practical\noverview. Dermatology and therapy, 6(4):471–507.\nMatteo Farina, Gianni Franchi, Giovanni Iacca, Massim-\niliano Mancini, and Elisa Ricci. 2024. Frustratingly\neasy test-time adaptation of vision-language models.\nAdvances in Neural Information Processing Systems,\n37:129062–129093.\nPhilippe Gottfrois, Fabian Gröger, Faly Herizo Andri-\nambololoniaina, Ludovic Amruthalingam, Alvaro\nGonzalez-Jimenez, Christophe Hsu, Agnes Kessy,\nSimone Lionetti, Daudi Mavura, Wingston Ng’ambi,\nand 1 others. 2024. Passion for dermatology: Bridg-\ning the diversity gap with pigmented skin images\nfrom sub-saharan africa. In International Confer-\nence on Medical Image Computing and Computer-\nAssisted Intervention, pages 703–712. Springer.\nMatthew Groh, Caleb Harris, Luis Soenksen, Felix Lau,\nRachel Han, Aerin Kim, Arash Koochek, and Omar\nBadri. 2021. Evaluating deep neural networks trained\non clinical images in dermatology with the fitzpatrick\n17k dataset. In Proceedings of the IEEE/CVF con-\nference on computer vision and pattern recognition,\npages 1820–1828.\nZhihui Guo, Xin Man, Hui Xu, and Jie Shao. 2025. Lisa:\nA layer-wise integration and suppression approach\n9\n"}, {"page": 10, "text": "for hallucination mitigation in multimodal large lan-\nguage models. arXiv preprint arXiv:2507.19110.\nJing Hao, Yuci Liang, Lizhuo Lin, Yuxuan Fan, Wenkai\nZhou, Kaixin Guo, Zanting Ye, Yanpeng Sun, Xinyu\nZhang, Yanqi Yang, and 1 others. 2025. Oralgpt-\nomni: A versatile dental multimodal large language\nmodel. arXiv preprint arXiv:2511.22055.\nRoderick J Hay, Nicole E Johns, Hywel C Williams,\nIan W Bolliger, Robert P Dellavalle, David J Margo-\nlis, Robin Marks, Luigi Naldi, Martin A Weinstock,\nSarah K Wulf, and 1 others. 2014. The global burden\nof skin disease in 2010: an analysis of the prevalence\nand impact of skin conditions. Journal of investiga-\ntive dermatology, 134(6):1527–1534.\nEdward J Hu, Yelong Shen, Phillip Wallis, Zeyuan\nAllen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,\nWeizhu Chen, and 1 others. 2022. Lora: Low-rank\nadaptation of large language models. ICLR, 1(2):3.\nJeremy Kawahara, Sara Daneshvar, Giuseppe Argen-\nziano, and Ghassan Hamarneh. 2018. Seven-point\nchecklist and skin lesion classification using multi-\ntask multimodal neural nets. IEEE journal of biomed-\nical and health informatics, 23(2):538–546.\nKhushbu and Sharun Akter. 2024. Skin disease classifi-\ncation dataset.\nNewton M Kinyanjui, Timothy Odonga, Celia Cintas,\nNoel CF Codella, Rameswar Panda, Prasanna Sat-\ntigeri, and Kush R Varshney. 2020. Fairness of clas-\nsifiers across skin tones in dermatology. In Inter-\nnational conference on medical image computing\nand computer-assisted intervention, pages 320–329.\nSpringer.\nPang Wei Koh, Thao Nguyen, Yew Siang Tang, Stephen\nMussmann, Emma Pierson, Been Kim, and Percy\nLiang. 2020. Concept bottleneck models. In In-\nternational conference on machine learning, pages\n5338–5348. PMLR.\nPravin\nR\nKshirsagar,\nHariprasath\nManoharan,\nS Shitharth, Abdulrhman M Alshareef, Nabeel\nAlbishry, and Praveen Kumar Balachandran. 2022.\nDeep learning approaches for prognosis of automated\nskin disease. Life, 12(3):426.\nZihan Li, Diping Song, Zefeng Yang, Deming Wang,\nFei Li, Xiulan Zhang, Paul E Kinahan, and Yu Qiao.\n2025. Visionunite: A vision-language foundation\nmodel for ophthalmology enhanced with clinical\nknowledge. IEEE Transactions on Pattern Analy-\nsis and Machine Intelligence.\nBo Liu, Ke Zou, Li-Ming Zhan, Zexin Lu, Xiaoyu\nDong, Yidi Chen, Chengqiang Xie, Jiannong Cao,\nXiao-Ming Wu, and Huazhu Fu. 2025a. Gemex: A\nlarge-scale, groundable, and explainable medical vqa\nbenchmark for chest x-ray diagnosis. In Proceed-\nings of the IEEE/CVF International Conference on\nComputer Vision, pages 21310–21320.\nShengyuan Liu, Boyun Zheng, Wenting Chen, Zhihao\nPeng, Zhenfei Yin, Jing Shao, Jiancong Hu, and\nYixuan Yuan. 2023. Endobench: A comprehensive\nevaluation of multi-modal large language models for\nendoscopy analysis. In The Thirty-ninth Annual Con-\nference on Neural Information Processing Systems\nDatasets and Benchmarks Track.\nZehao Liu, Wejieying Ren, Jipeng Zhang, Tianxiang\nZhao, Jingxi Zhu, Xiaoting Li, and Vasant G Honavar.\n2025b. Skin-r1: Toward trustworthy clinical rea-\nsoning for dermatological diagnosis. arXiv preprint\narXiv:2511.14900.\nMette Mogensen, Hanan A Morsy, Lars Thrane, and\nGregor BE Jemec. 2008. Morphology and epidermal\nthickness of normal skin imaged by optical coherence\ntomography. Dermatology, 217(1):14–20.\nNiklas Muennighoff, Zitong Yang, Weijia Shi, Xi-\nang Lisa Li, Li Fei-Fei, Hannaneh Hajishirzi, Luke\nZettlemoyer, Percy Liang, Emmanuel Candès, and\nTatsunori B Hashimoto. 2025. s1: Simple test-time\nscaling. In Proceedings of the 2025 Conference on\nEmpirical Methods in Natural Language Processing,\npages 20286–20332.\nStephanie S Noronha, Mayuri A Mehta, Dweepna Garg,\nKetan Kotecha, and Ajith Abraham. 2023. Deep\nlearning-based dermatological condition detection:\nA systematic review with recent methods, datasets,\nchallenges, and future directions.\nIEEE Access,\n11:140348–140381.\nAndre GC Pacheco, Gustavo R Lima, Amanda S Salo-\nmao, Breno Krohling, Igor P Biral, Gabriel G De An-\ngelo, Fábio CR Alves Jr, José GM Esgario, Alana C\nSimora, Pedro BC Castro, and 1 others. 2020. Pad-\nufes-20: A skin lesion dataset composed of patient\ndata and clinical images collected from smartphones.\nData in brief, 32:106221.\nTschandl Philipp, Akay Nisa Bengü, Rosendahl Cliff,\nRotemberg Veronica, Todorovska Verche, Weber\nJochen, Wolber Anna Katharina, Müller Christoph,\nKurtansky Nicholas, Halpern Allan, and 1 others.\n2025. Milk10k: A hierarchical multimodal imaging\nlearning toolkit for diagnosing pigmented and non-\npigmented skin cancer and its simulators. Journal of\nInvestigative Dermatology.\nZhihang Ren, Yunqi Li, Xinyu Li, Xinrong Xie, Erik P\nDuhaime, Kathy Fang, Tapabrata Chakraborti, Yun-\nhui Guo, Stella X Yu, and David Whitney. 2024.\nSkincon: Towards consensus for the uncertainty\nof skin cancer sub-typing through distribution reg-\nularized adaptive predictive sets (draps). In Inter-\nnational Conference on Medical Image Computing\nand Computer-Assisted Intervention, pages 405–415.\nSpringer.\nJinghan Ru, Jun Tian, Chengwei Xiao, Jingjing Li, and\nHeng Tao Shen. 2023. Imbalanced open set domain\nadaptation via moving-threshold estimation and grad-\nual alignment. IEEE Transactions on Multimedia,\n26:2504–2514.\n10\n"}, {"page": 11, "text": "Jinghan Ru, Yuxin Xie, Xianwei Zhuang, Yuguo Yin,\nZhihui Guo, Zhiming Liu, Qianli Ren, and Yuex-\nian Zou. 2025. Do we really have to filter out ran-\ndom noise in pre-training data for language models?\narXiv preprint arXiv:2502.06604.\nZhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu,\nJunxiao Song, Xiao Bi, Haowei Zhang, Mingchuan\nZhang, YK Li, Yang Wu, and 1 others. 2024.\nDeepseekmath: Pushing the limits of mathematical\nreasoning in open language models. arXiv preprint\narXiv:2402.03300.\nYuhao Shen, Jiahe Qian, Zhangtianyi Chen, Yuanhao\nHe, and Juexiao Zhou. 2025a. Skingpt-r1: Adapter-\nonly dual distillation for efficient dermatology rea-\nsoning. arXiv preprint arXiv:2511.15242.\nYuhao Shen, Jiahe Qian, Shuping Zhang, Zhangtianyi\nChen, Tao Lu, and Juexiao Zhou. 2025b. Towards\ntrustworthy dermatology mllms: A benchmark and\nmultimodal evaluator for diagnostic narratives. arXiv\npreprint arXiv:2511.09195.\nYuhao Shen, Liyuan Sun, Yan Xu, Wenbin Liu, Shuping\nZhang, Shawn Afvari, Zhongyi Han, Jiaoyan Song,\nYongzhi Ji, Tao Lu, and 1 others. 2024. Skincare: A\nmultimodal dermatology dataset annotated with med-\nical caption and chain-of-thought reasoning. arXiv\ne-prints, pages arXiv–2405.\nYuxuan Sun, Yunlong Zhang, Yixuan Si, Chenglu\nZhu, Kai Zhang, Zhongyi Shui, Jingxiong Li, Xuan\nGong, XINHENG LYU, Tao Lin, and Lin Yang.\n2025. Pathgen-1.6m: 1.6 million pathology image-\ntext pairs generation through multi-agent collabora-\ntion. In The Thirteenth International Conference on\nLearning Representations.\nLexiang Tang, Xianwei Zhuang, Bang Yang, Zhiyuan\nHu, Hongxiang Li, Lu Ma, Jinghan Ru, and Yuexian\nZou. 2025. Not all tokens and heads are equally im-\nportant: Dual-level attention intervention for halluci-\nnation mitigation. arXiv preprint arXiv:2506.12609.\nPhilipp Tschandl, Cliff Rosendahl, and Harald Kittler.\n2018. The ham10000 dataset, a large collection of\nmulti-source dermatoscopic images of common pig-\nmented skin lesions. Scientific data, 5(1):1–9.\nDequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno\nOlshausen, and Trevor Darrell. 2020. Tent: Fully\ntest-time adaptation by entropy minimization. arXiv\npreprint arXiv:2006.10726.\nJuncheng Wang, Yilan Zhang, Fengying Xie, and Jie\nLiu. 2025a. Enhancing diagnosis of psoriasis and\ninflammatory skin diseases: A spatially aligned mul-\ntimodal model integrating clinical and dermoscopic\nimages. Journal of Investigative Dermatology.\nZixin Wang, Yadan Luo, Liang Zheng, Zhuoxiao Chen,\nSen Wang, and Zi Huang. 2025b. In search of lost\nonline test-time adaptation: A survey. International\nJournal of Computer Vision, 133(3):1106–1139.\nAbbi Ward, Jimmy Li, Julie Wang, Sriram Lak-\nshminarasimhan, Ashley Carrick, Bilson Cam-\npana, Jay Hartford, Pradeep K Sreenivasaiah, Tiya\nTiyasirisokchai, Sunny Virmani, and 1 others. 2024.\nCreating an empirical dermatology dataset through\ncrowdsourcing with web search advertisements.\nJAMA Network Open, 7(11):e2446615–e2446615.\nFadli Husein Wattiheluw and Riyanarto Sarno. 2018.\nDeveloping word sense disambiguation corpuses us-\ning word2vec and wu palmer for disambiguation. In\n2018 International Seminar on Application for Tech-\nnology of Information and Communication, pages\n244–248. IEEE.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,\nand 1 others. 2022. Chain-of-thought prompting elic-\nits reasoning in large language models. Advances\nin neural information processing systems, 35:24824–\n24837.\nSiyuan Yan, Ming Hu, Yiwen Jiang, Xieji Li, Hao Fei,\nPhilipp Tschandl, Harald Kittler, and Zongyuan Ge.\n2025a. Derm1m: A million-scale vision-language\ndataset aligned with clinical ontology knowledge for\ndermatology. arXiv preprint arXiv:2503.14911.\nSiyuan Yan, Xieji Li, Ming Hu, Yiwen Jiang, Zhen\nYu, and Zongyuan Ge. 2025b. Make: Multi-aspect\nknowledge-enhanced vision-language pretraining for\nzero-shot dermatological assessment.\nIn Interna-\ntional Conference on Medical Image Computing\nand Computer-Assisted Intervention, pages 369–379.\nSpringer.\nSiyuan Yan, Zhen Yu, Clare Primiero, Cristina Vico-\nAlonso, Zhonghua Wang, Litao Yang, Philipp\nTschandl, Ming Hu, Lie Ju, Gin Tan, and 1 others.\n2025c. A multimodal vision foundation model for\nclinical dermatology. Nature Medicine, pages 1–12.\nAbdurrahim\nYilmaz,\nSirin\nPekcan\nYasar,\nGul-\nsum Gencoglan, and Burak Temelkuran. 2024.\nDerm12345: A large, multisource dermatoscopic\nskin lesion dataset with 40 subclasses.\nScientific\nData, 11(1):1302.\nAbdurrahim Yilmaz, Furkan Yuceyalcin, Ece Gokyayla,\nDonghee Choi, Ozan Erdem, Ali Anil Demircali,\nRahmetullah Varol, Ufuk Gorkem Kirabali, Gulsum\nGencoglan, Joram M Posma, and 1 others. 2025.\nDermasynth: Rich synthetic image-text pairs using\nopen access dermatology datasets. arXiv preprint\narXiv:2502.00196.\nWen-wai Yim, Yujuan Fu, Zhaoyi Sun, Asma Ben\nAbacha, Meliha Yetisgen, and Fei Xia. 2024. Der-\nmavqa: A multilingual visual question answering\ndataset for dermatology. In International Confer-\nence on Medical Image Computing and Computer-\nAssisted Intervention, pages 209–219. Springer.\nYuguo Yin, Yuxin Xie, Wenyuan Yang, Dongchao Yang,\nJinghan Ru, Xianwei Zhuang, Liming Liang, and\nYuexian Zou. 2025. ATRI: Mitigating multilingual\n11\n"}, {"page": 12, "text": "audio text retrieval inconsistencies by reducing data\ndistribution errors. In Proceedings of the 63rd An-\nnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 5491–\n5504, Vienna, Austria. Association for Computa-\ntional Linguistics.\nP Zaballos, LJ Del Pozo, G Argenziano, C Medina,\nF Lacarrubba, B Ferrer, JM Martin, A Llambrich,\nI Zalaudek, and J Bañuls. 2019. Dermoscopy of\ncutaneous smooth muscle neoplasms: a morpho-\nlogical study of 136 cases.\nJournal of the Euro-\npean Academy of Dermatology and Venereology,\n33(4):693–699.\nWenqi Zeng, Yuqi Sun, Chenxi Ma, Weimin Tan, and\nBo Yan. 2025. Mm-skin: Enhancing dermatology\nvision-language model with an image-text dataset\nderived from textbooks. In Proceedings of the 33rd\nACM International Conference on Multimedia, pages\n3769–3778.\nJuexiao Zhou, Xiaonan He, Liyuan Sun, Jiannan Xu, Xi-\nuying Chen, Yuetan Chu, Longxi Zhou, Xingyu Liao,\nBin Zhang, Shawn Afvari, and 1 others. 2024a. Pre-\ntrained multimodal large language model enhances\ndermatological diagnosis using skingpt-4. Nature\nCommunications, 15(1):5649.\nJuexiao Zhou, Liyuan Sun, Yan Xu, Wenbin Liu, Shawn\nAfvari, Zhongyi Han, Jiaoyan Song, Yongzhi Ji, Xi-\naonan He, and Xin Gao. 2024b. Skincap: A multi-\nmodal dermatology dataset annotated with rich medi-\ncal captions. arXiv preprint arXiv:2405.18004.\nXianwei Zhuang, Yuxin Xie, Yufan Deng, Liming\nLiang, Jinghan Ru, Yuguo Yin, and Yuexian Zou.\n2025. Vargpt: Unified understanding and generation\nin a visual autoregressive multimodal large language\nmodel. arXiv preprint arXiv:2501.12327.\n12\n"}, {"page": 13, "text": "Appendix\nContents\nA Source Datasets and Extended Related Work\n15\nA.1\nSource Dermatology Datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\nA.2\nLeakage prevention and de-duplication.\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n15\nA.3\nDermatology Benchmarks and Vision-Language Models\n. . . . . . . . . . . . . . . . .\n15\nA.4\nConcept Bottleneck Models and Morphology-Grounded Reasoning . . . . . . . . . . . .\n15\nA.5\nReinforcement Learning, GRPO, and Instruction-Tuned MLLMs . . . . . . . . . . . . .\n16\nA.6 Test-Time Adaptation and Test-Time Scaling\n. . . . . . . . . . . . . . . . . . . . . . .\n17\nB\nDermoBench Task Definitions and Data Sources\n17\nB.1\nTask Overview and Sample Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\nB.2\nTraining Isolation and Leakage Control (Clean Separation) . . . . . . . . . . . . . . . .\n17\nB.3\nMorphology Understanding (Task 1.x) . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\nB.3.1\nT1.1–T1.2: Open-Ended Morphology Evaluation on 900-Case Core Set . . . . .\n18\nB.3.2\nT1.3: Dermoscopic Attribute MCQA\n. . . . . . . . . . . . . . . . . . . . . . .\n18\nB.3.3\nT1.4: SkinCon Attribute Multiple-Choice Questions (Clinical Attribute MCQA)\n18\nB.4\nDiagnosis classification (Task 2.x) . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\nB.4.1\nIn-distribution (ID) diagnosis (T2.1–T2.3) . . . . . . . . . . . . . . . . . . . . .\n19\nB.4.2\nOut-of-distribution (OOD) diagnosis (T2.4) . . . . . . . . . . . . . . . . . . . .\n19\nB.5\nReasoning (Task 3.x) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\nB.5.1\nT3.1: CoT reasoning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\nB.5.2\nT3.2: Morph-grounded reasoning\n. . . . . . . . . . . . . . . . . . . . . . . . .\n19\nB.6\nFairness (Task 4.x)\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\nB.7\nGold standard annotation protocol for the 900-case core set . . . . . . . . . . . . . . . .\n19\nB.8\nConcept bottleneck tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\nC Prompt Templates and Example Outputs for DermoInstruct\n20\nC.1\nMorphology and Reasoning Supervision . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\nC.2\nMorphology JSON Prompts\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\nC.2.1\nClinical Images (SkinCon) . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\nC.2.2\nDermoscopic Images (Derm7pt) . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\nC.3\nChain-of-Thought Reasoning Prompt . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\nC.4\nDiagnosis VQA prompt templates\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\nD LLM-as-a-Judge Prompts\n24\nD.1 Task 1.1 (Morph Description) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n25\nD.2 Task 1.2 (Morph Content + Narrative) . . . . . . . . . . . . . . . . . . . . . . . . . . .\n25\nD.3 Task 3.1 (Reasoning + Final Diagnosis)\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n26\nD.4 Task 3.2 (Morph-grounded Reasoning) . . . . . . . . . . . . . . . . . . . . . . . . . . .\n27\nD.5\nJudge Reliability and Human Sanity Check\n. . . . . . . . . . . . . . . . . . . . . . . .\n27\nD.5.1\nJudge sensitivity on the 900-case core set . . . . . . . . . . . . . . . . . . . . .\n27\nD.5.2\nAggregate-level inter-judge agreement metrics\n. . . . . . . . . . . . . . . . . .\n27\nD.6\nHuman sanity check (20 cases) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n27\nE\nTraining Details\n28\nE.1\nHyperparameters\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n28\nE.2\nMAVIC Implementation Details\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n28\n13\n"}, {"page": 14, "text": "F\nAblation Study\n29\nF.1\nImpact of MAVIC Reward Components . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\nF.2\nAblation of Confidence–Consistency Components . . . . . . . . . . . . . . . . . . . . .\n29\nG Theoretical Analysis\n29\nG.1\nHuber Contamination on the Simplex\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n30\nG.2\nHigh-Probability Geometric Separation\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n30\nG.3\nRobust Aggregation via Squared ℓ2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\nG.4\nEffect of the Margin Term as a Bounded Perturbation . . . . . . . . . . . . . . . . . . .\n34\nH Human Annotation and Ethical Considerations\n35\nH.1\nInstructions Given to Participants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n35\nH.1.1\nQuality Assessment of Model-Generated Drafts . . . . . . . . . . . . . . . . . .\n35\nH.1.2\nGold Standard Manual Revision for the Core Set . . . . . . . . . . . . . . . . .\n35\nH.1.3\nHuman Sanity Check for LLM-as-a-Judge . . . . . . . . . . . . . . . . . . . . .\n36\nH.1.4\nHuman Performance Baseline . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\nH.2\nRecruitment, Compensation, and Consent . . . . . . . . . . . . . . . . . . . . . . . . .\n36\nH.3\nData Consent, Release Policy, and Ethics Review . . . . . . . . . . . . . . . . . . . . .\n36\nI\nVisualization\n36\n14\n"}, {"page": 15, "text": "A\nSource Datasets and Extended Related\nWork\nA.1\nSource Dermatology Datasets\nTo construct DermoInstruct and DermoBench,\nwe aggregate fourteen public or institutionally\ncurated dermatology datasets covering clinical\nphotographs, dermoscopic images, and smart-\nphone or teledermatology photos from diverse\nhealthcare systems: Daffodil (Khushbu and Ak-\nter, 2024), DermNet (DermNet, 2023), Fitz-\npatrick17k (Groh et al., 2021), ISIC Archive (Cas-\nsidy et al., 2022), MIDAS (Chiou et al., 2025),\nPAD-UFES-20 (Pacheco et al., 2020), PAS-\nSION (Gottfrois et al., 2024), PUMCH (Wang\net al., 2025a), SCIN (Ward et al., 2024), SD-\n198 (Kinyanjui et al., 2020), BCN20000 (Com-\nbalia et al., 2019), HAM10000 (Tschandl et al.,\n2018), Derm12345 (Yilmaz et al., 2024), and\nMILK10k (Philipp et al., 2025). Note that im-\nages hosted on the ISIC platform that are not part\nof these named subsets are grouped into “ISIC\nArchive” collection.\nThese datasets span pig-\nmented and non-pigmented lesions, benign and ma-\nlignant conditions, a wide range of anatomic sites\nand skin tones, and both controlled and real-world\nacquisition conditions. We briefly summarize their\nscope in Table 6; the main paper focuses on the\nunified ontology and task construction built on top\nof these sources.\nAcross these datasets, we harmonize heteroge-\nneous diagnosis labels into a unified hierarchy of\nsuperclasses and subclasses, and map existing at-\ntribute schemas (e.g., dermoscopic structures, pig-\nmentation patterns) into a common morphology\nontology used consistently throughout DermoIn-\nstruct and DermoBench.\nA.2\nLeakage prevention and de-duplication.\nWe split data at the patient level (all images from\nthe same patient_id are confined to a single split),\nallowing multiple cases per patient in the test set\nbut ensuring no patient overlap with training. We\nexclude images from DDI, SCIN, PAD, SkinCon,\nand Derm7pt from training and reserve them for\nevaluation-only settings. Finally, we apply near-\nduplicate filtering with perceptual hashing (pHash;\nHamming distance ≤2) to remove visually redun-\ndant images. In total, we retain 646,018 pairs for\ntraining after leakage controls and de-duplication.\nA.3\nDermatology Benchmarks and\nVision-Language Models\nTraditional deep-learning systems for dermatol-\nogy have focused on single-image diagnosis of a\nlimited set of conditions, often trained and evalu-\nated on individual datasets such as HAM10000 or\nISIC, and commonly framed as closed-set classifi-\ncation tasks (Kshirsagar et al., 2022; AlSuwaidan,\n2023; Noronha et al., 2023; Daneshjou et al., 2022).\nRecent work has begun to emphasize both fair-\nness and robustness, highlighting disparities across\nskin tones and acquisition conditions and calling\nfor more diverse benchmarks (Groh et al., 2021;\nKinyanjui et al., 2020; Ward et al., 2024; Daneshjou\net al., 2022).\nIn parallel, several multimodal and vision-\nlanguage dermatology datasets and models have\nemerged. MAKE (Yan et al., 2025b) pre-trains a\ndermatology VLM with multi-aspect knowledge,\nand PanDerm (Yan et al., 2025c) proposes a der-\nmatology vision foundation model trained on large-\nscale multimodal data. SkinGPT-4 (Zhou et al.,\n2024a), Skin-R1 (Liu et al., 2025b), and SkinGPT-\nR1 (Shen et al., 2025a) explore instruction-\ntuning and reasoning-style training for dermatol-\nogy LLMs. DermBench (Shen et al., 2025b) and\nDermaVQA (Yim et al., 2024) provide evaluation\ndatasets for diagnostic narratives and question an-\nswering, while SkinCap (Zhou et al., 2024b) and\nSkinCaRe (Shen et al., 2024) enrich image-text\npairs with medical captions and chain-of-thought\nreasoning. More recently, Derm1M (Yan et al.,\n2025a) and DermaSynth (Yilmaz et al., 2025) scale\ndermatology vision-language data to the million-\nsample regime.\nBeyond dermatology, there is a growing ecosys-\ntem of multimodal medical benchmarks and foun-\ndation models, such as GEMEX for chest X-ray\nVQA (Liu et al., 2025a), PathGen for pathology\nimage-text pairs (Sun et al., 2025), EndoBench\nfor endoscopy (Liu et al., 2023), and VisionUnite\nfor ophthalmology (Li et al., 2025). Compared to\nthese efforts, DermoBench is specifically designed\nto evaluate dermatology MLLMs along a morphol-\nogy →reasoning →diagnosis axis, with fairness\nand robustness explicitly foregrounded.\nA.4\nConcept Bottleneck Models and\nMorphology-Grounded Reasoning\nConcept bottleneck models (CBMs) explicitly in-\nsert an interpretable concept layer between raw\n15\n"}, {"page": 16, "text": "Dataset\nModality\nPopulation / setting\nScale\nNotes\nDaffodil (Khushbu\nand Akter, 2024)\nDermoscopic\nBangladesh hospital\nS\nBiopsy-proven dermoscopy dataset.\nDermNet (DermNet,\n2023)\nClinical\nGlobal web atlas\nL\nExpert-curated clinical photos.\nFitzpatrick17k (Groh\net al., 2021)\nClinical\nUS outpatient clinics\nM\nIncludes Fitzpatrick skin-type labels.\nISIC Archive (Cas-\nsidy et al., 2022)\nDermoscopic\nMulti-center dermoscopy\nL\nStandard benchmark for dermoscopic le-\nsions.\nMIDAS (Chiou et al.,\n2025)\nClinical & der-\nmoscopic\nMulti-institution NEJM AI\ndataset\nM\nPaired clinical/dermoscopy with biopsy\nlabels.\nPAD-UFES-\n20 (Pacheco et al.,\n2020)\nClinical\nBrazilian teledermatology\nS-M\nSmartphone photos with rich metadata.\nPASSION (Gottfrois\net al., 2024)\nClinical\nSub-Saharan Africa\nM\nSmartphone images emphasizing pig-\nmented skin.\nPUMCH\n(Wang\net al., 2025a)\nClinical\nChinese tertiary hospital\nM\nBroad inflammatory and neoplastic dis-\neases.\nSCIN (Ward et al.,\n2024)\nClinical\nUS crowdsourced users\nM\nDiverse smartphone photos with demo-\ngraphics.\nSD-198 (Kinyanjui\net al., 2020)\nClinical\nChina dermatology clinic\nS-M\n198-category long-tail dataset.\nBCN20000\n(Com-\nbalia et al., 2019)\nDermoscopic\nBarcelona tertiary center\nM-L\nLarge European dermoscopy cohort.\nHAM10000 (Tschandl\net al., 2018)\nDermoscopic\nAustria & Australia\nM\nClassic dermoscopy benchmark.\nDerm12345 (Yilmaz\net al., 2024)\nDermoscopic\nTurkish hospital\nM\n40-class dermoscopic dataset.\nMILK10k (Philipp\net al., 2025)\nClinical & der-\nmoscopic\nISIC multimodal cohort\nM\nPaired clinical/dermoscopy with meta-\ndata.\nTable 6: Summary of the fourteen source dermatology datasets used to construct DermoInstruct and DermoBench.\n“Scale” is qualitative (S: <5k images, M: 5k-20k, L: >20k).\nfeatures and task predictions: the model first pre-\ndicts a vector of human-understandable concepts\nand then predicts the final label from those con-\ncepts (Koh et al., 2020). Such models allow users\nto inspect and intervene on the intermediate con-\ncept predictions, improving transparency and en-\nabling richer human-model interaction. Subsequent\nwork has studied robustness, intervention strategies,\nand automatic discovery of concepts, but the core\nidea remains to align model internals with domain-\nrelevant abstractions.\nDermatology is naturally aligned with the CBM\nparadigm, because clinical practice is organized\naround lesion morphology. Dermatologists rely\non structured morphology descriptors in both clin-\nical and dermoscopic settings (Mogensen et al.,\n2008; Errichetti and Stinco, 2016; Zaballos et al.,\n2019), and recent datasets such as the SkinCon\nschema and the dermoscopic seven-point checklist\nprovide explicit morphology annotations for skin\nlesions (Ren et al., 2024; Kawahara et al., 2018).\nOur benchmark instantiates a soft concept bottle-\nneck for dermatology: Task 1 evaluates morphol-\nogy descriptions and attributes, Task 3 assesses\nchain-of-thought reasoning grounded in these con-\ncepts, and Task 2 measures whether diagnoses are\nconsistent with both. Rather than inserting a fixed-\ndimensional concept layer into a single network,\nwe expose morphology, reasoning, and diagnosis\nas separate but tightly coupled tasks, and exploit\ncross-task consistency as both a training signal (via\nDermoInstruct) and an evaluation criterion (via\nDermoBench).\nA.5\nReinforcement Learning, GRPO, and\nInstruction-Tuned MLLMs\nReinforcement learning has become a central tool\nfor enhancing the reasoning capabilities of large\n16\n"}, {"page": 17, "text": "language models beyond standard supervised fine-\ntuning. DeepSeekMath (Shao et al., 2024), for\nexample, combines continued pre-training on math-\nheavy corpora with RL and introduces Group Rela-\ntive Policy Optimization (GRPO), a variant of PPO\nthat replaces a learned value-function critic with a\ngroup-based baseline over multiple sampled trajec-\ntories. GRPO-style objectives have quickly been\nadopted in reasoning-focused LLMs because they\nare sample-efficient, remove the need for a sepa-\nrate critic network, and work well with verifiable\nor heuristic reward signals.\nOur MAVIC framework is inspired by this line\nof work but tailors the reward design to dermatol-\nogy. Instead of rewarding only final correctness,\nwe combine multiple terms capturing hierarchical\ndiagnosis correctness, proximity in the ontology,\nmorphology-grounded agreement with Task 1 out-\nputs, and format constraints. This connects GRPO-\nstyle RL with clinical desiderata such as lesion\nunderstanding and cross-skin-type robustness, and\nis complementary to standard instruction-tuning\nwith LoRA adaptation (Hu et al., 2022) and chain-\nof-thought prompting (Wei et al., 2022) used in\ngeneral-purpose MLLMs such as Qwen3-VL and\nGemini (Bai et al., 2025; Comanici et al., 2025;\nTang et al., 2025) and in domain-specific mod-\nels such as SkinGPT-4 and Skin-R1 (Zhou et al.,\n2024a; Liu et al., 2025b; Shen et al., 2025a; Zhuang\net al., 2025; Guo et al., 2025).\nA.6\nTest-Time Adaptation and Test-Time\nScaling\nTest-time\nadaptation.\nTest-time\nadaptation\n(TTA) adapts a pre-trained model to unlabeled\ntest data at deployment time, typically to mitigate\ncovariate shifts without full re-training. Classical\ndomain adaptation methods (Ru et al., 2023; Wang\net al., 2020) update batch-normalization statistics\nor minimize prediction entropy, while more recent\nwork explores online adaptation, pseudo-labeling,\nand robustness under dynamic streams (Wang\net al., 2025b; Ru et al., 2025; Yin et al., 2025).\nFor vision-language models, recent methods study\nboth optimization based and optimization-free\nstrategies. ZERO (Farina et al., 2024) shows that\na surprisingly strong VLM TTA baseline can be\nobtained by aggressive test-time augmentation,\ntemperature-0 prediction, and confidence-based\nmarginalization, requiring only a single batched\nforward pass and no backpropagation.\nThese\nresults demonstrate that much of the benefit of\nprompt-tuning style TTA can be captured by\ncarefully designed test-time inference procedures.\nOur CCT framework is complementary to these\nmethods. Instead of updating model parameters,\nwe adapt how the model is queried and how mul-\ntiple stochastic predictions are aggregated: we\nsample multiple responses under morphology- and\ndiagnosis-focused prompting, then aggregate them\nusing confidence- and consistency-based weight-\ning across tasks, images, and augmentations. This\ncan be seen as a lightweight, domain-specific TTA\nscheme that relies on cross-task dermatology priors\nrather than parameter updates.\nTest-time scaling.\nTest-time scaling (TTS) refers\nto improving model performance by allocating\nmore compute at inference time without changing\nmodel parameters (Guo et al., 2025; Muennighoff\net al., 2025). In the LLM literature, canonical exam-\nples include chain-of-thought prompting with self-\nconsistency, where multiple reasoning paths are\nsampled and the majority answer is selected, and\nbest-of-n sampling guided by task-specific scor-\ners (Wei et al., 2022). Such techniques can substan-\ntially improve reasoning quality but incur linear\ncost in the number of samples.\nOur CCT procedure can be interpreted as a spe-\ncialized TTS scheme for dermatology MLLMs. By\ncombining multi-sample decoding with confidence-\nand consistency-based aggregation across morphol-\nogy, reasoning, and diagnosis tasks, CCT leverages\nthe structure of DermoBench to stabilize predic-\ntions under distribution shifts (e.g., across devices\nor skin-tone groups) while keeping computation\nmodest relative to naive best-of-n sampling.\nB\nDermoBench Task Definitions and Data\nSources\nB.1\nTask Overview and Sample Statistics\nTable 2 summarizes all DermoBench subtasks, data\nsources, and sample sizes. The complete bench-\nmark contains 33,999 VQA-style samples, dis-\ntributed as follows: Task 1 has 19,012 samples;\nTask 2 has 12,533; Task 3 has 1,800; and Task 4\nhas 654.\nB.2\nTraining Isolation and Leakage Control\n(Clean Separation)\nTo ensure credible evaluation results, DermoBench\nimplements the following isolation strategies:\n17\n"}, {"page": 18, "text": "Task 1\n19012\nTask 2\n12533\nTask 3\n1800\nTask 4\n654\nT1.3\n5530\nT1.4\n11682\nOOD\n6533\nID 4\n2000\nID 25\n2000\nID hier\n2000\nT1.1 (900)\nT4 (654)\nT3.2 (900)\nT3.1 (900)\nT1.2 (900)\n(a)\n0\n1\n2\n3\n4\n5\nScore\n0\n5\n10\n15\n20\n25\n30\n35\n40\nPercentage of cases (%)\n6%\n14%\n11%\n38%\n26%\n5%\n4%\n15%\n12%\n27%\n28%\n14%\nMorphology faithfulness\nRater 1\nRater 2\n0\n1\n2\n3\n4\n5\nScore\n3%\n12%\n21%\n31%\n22%\n10%\n3%\n9%\n26%\n16%\n31%\n16%\nReasoning plausibility\nRater 1\nRater 2\n(b)\nMorph Description\nMorph-Attribute MCQ\nID Diagnosis\nMCQ\nOOD Diagnosis MCQ\nHierarchical Diagnosis\nCoT Reasoning\nMorph-Grounded\nDiagnosis\nFairness\n29.9\n51.6\n42.5\n66.6\n45.9\n77.4\n35.8\n65.3\n44.8\n79.1\n44.4\n66.0\n49.6\n65.5\n75.4\n93.5\nLLaMA-3.2-90B-Vision\nLingshu-32b\nGemini-2.5-Flash\nQwen3-VL-8B (Baseline)\nDermoGPT-8B-SFT\nDermoGPT-8B-RL\n(c)\nFigure 5: Benchmark statistics and key evaluation dimensions of DermoBench and DermoInstruct. (a) Task-wise\nand sub-task-wise distribution of VQA pairs. (b) Human ratings of synthesized morphological features and CoT of\nDermoInstruct. (c) Performance of representative MLLMs.\n(1) Image-level Isolation.\nUnless explicitly\nstated, DermoBench images are sourced from\ndatasets unused in DermoInstruct or from strictly\nheld-out splits of the same source datasets. Critical\nmorphology evaluation datasets such as Derm7pt\nand SkinCon are designated as evaluation-exclusive\nsources, with no images or labels utilized for train-\ning.\n(2)\nText-level\nIsolation.\nRefer-\nence\ntexts\nfor\nall\nopen-ended\ntasks\n(T1.1/T1.2/T3.1/T3.2)—including\nmorpho-\nlogical reports, attribute JSONs, reasoning chains,\nand diagnostic statements—are excluded from\ntraining corpora to prevent artificially inflated\nperformance through answer memorization.\n(3) Question/Template-level Isolation.\nBoth\nmultiple-choice and open-ended tasks employ min-\nimal sets of semantically equivalent templates. We\nperform rigorous deduplication checks between\ntraining and evaluation template sets, and provide\ncomplete template inventories with cryptographic\nhashes for reproducibility upon release (see Ap-\npendix C).\nB.3\nMorphology Understanding (Task 1.x)\nB.3.1\nT1.1–T1.2: Open-Ended Morphology\nEvaluation on 900-Case Core Set\nInput.\nA single clinical or dermoscopic image +\ninstruction.\nOutput and Format Constraints.\n• T1.1 (Morph report): Generate a structured\nmorphological examination report covering\nkey aspects including lesion type, color, bor-\nder, surface/scales, and distribution.\n• T1.2 (Morph JSON + report): In addition to\nthe report, output a JSON object wrapped in\n<morph>...</morph> tags. Dermoscopic im-\nages follow Derm7pt checklist fields; clinical\nimages follow SkinCon fields.\nGold Standard Construction (Core Process).\nWe first use a strong VLM to generate for each\ncore set image: (i) morphological report, (ii) at-\ntribute JSON, and (iii) diagnostic reasoning with\nfinal diagnosis (for Task 3.x). Dermatologists then\nconduct line-by-line review and revision to ensure\n(a) textual descriptions align with visible evidence\nin images, (b) JSON field values conform to clinical\nterminology and definitions, and (c) consistency be-\ntween descriptions and diagnoses. Detailed review\nguidelines, conflict resolution examples, and final\nconsistency checks are provided in Appendix B.7.\nB.3.2\nT1.3: Dermoscopic Attribute MCQA\nData Source.\nThe dermoscopic test split of\nDerm7pt is used for evaluation. Although Derm7pt\nprovides training splits, we exclude all its images\nand labels from training.\nQuestion Construction.\nEach question queries\none attribute from the Derm7pt checklist (e.g., pig-\nment network, streaks, etc.), with options corre-\nsponding to valid states for that attribute. Question\ntemplates and option generation rules are specified\nin Appendix C.\nB.3.3\nT1.4: SkinCon Attribute\nMultiple-Choice Questions (Clinical\nAttribute MCQA)\nData Source.\nSkinCon does not provide an offi-\ncial test split; we treat all its annotated samples as\nevaluation-only, generating MCQAs from its mor-\n18\n"}, {"page": 19, "text": "phological annotations. Question and option con-\nstruction follow the same principles as above, with\nfields and value spaces determined by the SkinCon\nschema.\nB.4\nDiagnosis classification (Task 2.x)\nB.4.1\nIn-distribution (ID) diagnosis\n(T2.1–T2.3)\nData sources and partitioning.\nThe ID diagno-\nsis evaluation set was constructed by extracting\nstrictly held-out images from the same 14 source\ndatasets as DermoInstruct (completely isolated\nfrom training instruction pairs, see Appendix B.2).\nT2.1: 4-way MCQA (leaf-level).\nThe correct op-\ntion is a fine-grained leaf-node diagnosis; distrac-\ntors are preferentially sampled from neighboring\nnodes/siblings under the same parent node in the\nunified ontology to enhance \"clinical confusabil-\nity.\"\nT2.2: 25-way MCQA (coarse-grained triage).\nThe 325 leaf-node diagnoses are collapsed into 25\ncoarse-grained categories with stronger clinical sig-\nnificance, creating a fixed option menu to simulate\nreal-world triage scenarios.\nT2.3: Hierarchical diagnosis.\nA single diagno-\nsis is decomposed into sequential decisions along\nthe ontology path (root→leaf). Each question cor-\nresponds to one step along the path, with both per-\nlevel accuracy and path-level metrics measured.\nB.4.2\nOut-of-distribution (OOD) diagnosis\n(T2.4)\nData sources.\nEvaluation partitions from multi-\nple external dermoscopy/clinical datasets are used,\nincluding Derm1M educational split, Derm7pt,\nDDI, and SNU134.\nKey setting: Non-aligned label spaces.\nUnlike\nID tasks, OOD tasks construct MCQAs within each\ndataset’s original label space: We do not map\nground-truth labels or options to a unified ontol-\nogy. Consequently, models must simultaneously\nhandle visual distribution shifts and label space\nmismatches, preventing inflated scores from \"inter-\npolating\" on a unified taxonomy.\nMCQA construction.\nFor each sample, the orig-\ninal dataset label serves as the correct option; dis-\ntractors are sampled from the same dataset’s label\nset (potentially weighted by class frequency or con-\nfusability).\nB.5\nReasoning (Task 3.x)\nB.5.1\nT3.1: CoT reasoning\nData\nand\nobjective.\nWe\nuse\nthe\nsame\n900-case core set as in T1.1/T1.2.\nMod-\nels must output reasoning text enclosed in\n<reasoning>...</reasoning>\ntags,\nconnect-\ning\nvisible\nevidence\nwith\ncandidate\ndiag-\nnoses, and provide the final diagnosis within\n<final_diagnosis> tags.\nB.5.2\nT3.2: Morph-grounded reasoning\nBuilding upon T3.1, models are additionally re-\nquired to output <morph> JSON (with the same\nschema as in T1.2). This setup explicitly tests:\nwhether the morphological evidence documented\nby the model sufficiently supports its reasoning\nchain and final diagnosis.\nConsistency check (analysis dimension).\nBe-\nyond open-ended scoring, we additionally perform\nautomated \"morphology↔diagnosis consistency\"\nchecks on the core set: For example, contradictions\nare counted when the model declares critical nega-\ntive features in the JSON (e.g., no pigment network)\nbut cites contradictory evidence in its reasoning.\nB.6\nFairness (Task 4.x)\nData and grouping.\nWe reuse the DDI-based 4-\nway MCQAs and group images according to Fitz-\npatrick skin type (FST I–V).\nFairness metric.\nLet Acck denote the model ac-\ncuracy for each group. Fairness is defined as:\nFairness = mink Acck\nmaxk Acck\n.\nThis metric achieves higher values when overall\nperformance is high and performance gaps across\nskin tone groups are small. In addition to this pri-\nmary metric, we also report per-group accuracies\nto avoid misinterpretations where \"ratios mask ab-\nsolute performance differences\".\nB.7\nGold standard annotation protocol for the\n900-case core set\nStep 1: Draft generation.\nThree types of drafts\nare generated for each image: (i) morphologi-\ncal report, (ii) attribute JSON (Derm7pt/SkinCon\nschema), and (iii) reasoning chain + final diagnosis.\n19\n"}, {"page": 20, "text": "     Data & Metadata Extraction\n14 Public Datasets\nClinical \nImages\nDermoscopic\nImages\nMetadata\nISIC,\nDermNet,\netc.\nRaw Images\nMetadata\nDiagnoses\nGemini-2.5-Flash\nSchemas\n(SkinCon/Derm7pt)\nPre-defined\nPrompts\nMorphology\nReasoning\n<morph> JSON\nDetailed Description\n<reasoning> XML\n<final_diagnosis> XML\nMetadata\nDiagnoses\nGPT-5 & Expert\nStandardization\nUnified Ontology\n9 Superclasses\n325 Subclasses\nGemini Synthsis & Ontology Construction\nFigure 6: Construction pipeline for DermoInstruct. We aggregate 14 source datasets, apply leakage controls and\nde-duplication, then generate morphology- and reasoning-grounded instruction pairs using a SOTA multimodal LLM\n(Gemini-2.5-Flash). The final training subset of DermoInstruct dataset contains 646k high-quality image-instruction\npairs.\nStep 2: Clinical line-by-line revision.\nTwo der-\nmatologists conduct line-by-line review and revi-\nsion of the drafts, with focus on correcting: (a) in-\nvisible or exaggerated morphological descriptions;\n(b) JSON field values inconsistent with definitions;\n(c) reasoning inconsistent with morphological evi-\ndence; (d) diagnoses unsupported by the evidence\nchain.\nStep 3:\nConsistency and format valida-\ntion.\nWe perform format validation (tag/J-\nSON\nparseability)\nand\nconsistency\nchecks\n(morphology↔reasoning↔diagnosis)\nfor\nall\nsamples. If conflicts are detected, we return to Step\n2 and iterate until all checks pass.\nStep 4: Quality spot-checking and documenta-\ntion.\nA random subset undergoes dual review by\ntwo annotators, with common error patterns docu-\nmented and revision guidelines updated to ensure\nannotation consistency and scalability.\nB.8\nConcept bottleneck tasks\nTask motivation.\nT1.2 and T3.2 enforce the out-\nput of standardized morphological concepts (the\n<morph> JSON), using “interpretable morpholog-\nical evidence” as a diagnostic intermediate bot-\ntleneck.\nThis extends evaluation from merely\n“whether the answer is correct” to “whether the\nevidence chain is auditable and self-consistent.”\nOutput format and ordering constraints.\nBoth\ntasks require outputting parseable JSON enclosed\nwithin <morph>...</morph> tags: (i) T1.2: the\n<morph> tag is placed before the morphological\nreport; (ii) T3.2: output the <morph> JSON right\nafter the <reasoning> paragraph, and finally the\n<final_diagnosis>.\nC\nPrompt Templates and Example\nOutputs for DermoInstruct\nC.1\nMorphology and Reasoning Supervision\nWe obtain morphology-centric supervision by\nquerying a SOTA multimodal LLM, Gemini-2.5-\nFlash (Comanici et al., 2025), with a small set\nof templates for every image. For each case, the\nmodel is asked to (i) describe the lesion in free text,\n(ii) output a structured set of morphology attributes,\nand (iii) perform step-by-step diagnostic reasoning\nthat ends in a final diagnosis chosen from a can-\ndidate list. This provides a unified image-to-text\npipeline whose outputs are reused across DermoIn-\nstruct and DermoBench.\nWe distinguish clinical and dermoscopic images\nonly through the morphology schema. For clini-\ncal photographs, prompts align Gemini’s outputs\nwith the 48 SkinCon concepts (Ren et al., 2024),\nreturning a short report plus a JSON object indi-\ncating which attributes are present. For dermo-\nscopic photographs, we instead condition on the\nseven-point checklist (Kawahara et al., 2018) to\nobtain an analogous JSON over dermoscopic struc-\ntures and a brief dermoscopy report. In both cases,\nthe model must first commit to morphology be-\nfore predicting any disease label. We then aug-\nment each case with chain-of-thought (CoT) su-\npervision (Wei et al., 2022): given the image, the\nmorphology JSON, and a small candidate set of\ndiagnoses derived from metadata and our ontology\n(Sec. 2.1.3), Gemini produces a reasoning para-\ngraph and a <final_diagnosis> tag selecting one\nfine-grained diagnosis.\n20\n"}, {"page": 21, "text": "C.2\nMorphology JSON Prompts\nC.2.1\nClinical Images (SkinCon)\nSkinCon clinical prompt (system + user)\nPROMPT_DICT = {\n\"system_prompt\": \"You are an expert in\ndermatology. Your task is to perform a\ndetailed visual analysis of a provided\nskin lesion image (clinical or\ndermoscopic). You will be given an\nimage of a skin lesion and a predefined\nlist of 48 standardized clinical\nconcepts from the SkinCon dataset. Your\ntask is to analyze the image, describe\nit clinically, and then map the\nobserved features to the provided\nSkinCon concepts. Any features you\nobserve that are not on the list must\nbe categorized separately. Your output\nmust be a single, clean JSON object and\nnothing else.\",\n\"user_prompt\": \"Analyze the provided skin\nlesion image using the established\nSkinCon vocabulary. First, perform a\ndetailed, step-by-step visual\nassessment. Second, generate a single,\nvalid JSON object as your final and\nONLY output. Do not include any text,\nexplanations, or markdown formatting\noutside of the JSON object.\\n\\n###\nSkinCon Morphological Concepts List\\\nnHere are the 48 standardized concepts\nyou MUST use for classification:\\n1.\nAbscess\\n2. Acuminate\\n3. Atrophy\\n4.\nBlack\\n5. Blue\\n6. Brown(\nHyperpigmentation)\\n7. Bulla\\n8. Burrow\n\\n9. Comedo\\n10. Crust\\n11. Cyst\\n12.\nDome-shaped\\n13. Erosion\\n14. Erythema\\\nn15. Excoriation\\n16. Exophytic/\nFungating\\n17. Exudate\\n18. Fissure\\n19\n. Flat topped\\n20. Friable\\n21. Gray\\\nn22. Induration\\n23. Lichenification\\\nn24. Macule\\n25. Nodule\\n26. Papule\\n27\n. Patch\\n28. Pedunculated\\n29.\nPigmented\\n30. Plaque\\n31. Poikiloderma\n\\n32. Purple\\n33. Purpura/Petechiae\\n34\n. Pustule\\n35. Salmon\\n36. Scale\\n37.\nScar\\n38. Sclerosis\\n39. Telangiectasia\n\\n40. Translucent\\n41. Ulcer\\n42.\nUmbilicated\\n43. Vesicle\\n44. Warty/\nPapillomatous\\n45. Wheal\\n46. White(\nHypopigmentation)\\n47. Xerosis\\n48.\nYellow\\n\\n### Required JSON Output\nStructure\\nThe JSON object MUST contain\nexactly three keys:\\n1.\ndetailed_description: (String) A\ncomprehensive clinical narrative of the\nlesion's morphology, including primary\nlesion type, color, shape, border,\nsurface, and texture.\\n2.\nmorphological_features_skincon: (Array\nof Strings) A list of all observed\nfeatures that EXACTLY MATCH one or more\nterms from the 48 SkinCon concepts\nprovided above.\\n3.\nmorphological_features_others: (Array\nof Strings) A list of important\nobserved features that are NOT found in\nthe SkinCon list. If all features are\ncovered by the SkinCon list, this array\nshould be empty [].\\n\\n ### Examples\nfor Guidance\\n\\n**INPUT:** [Image of a\nPsoriasis Plaque] \\n**REQUIRED JSON\nOUTPUT:**\\n{\\n \\\"detailed_description\n\\\": \\\"The image shows a sharply\ndemarcated, erythematous plaque with a\nraised, indurated surface. The lesion\nis ovoid and its borders are well-\ndefined. The surface is covered by a\nthick layer of silvery-white, lamellar\nscales. The perilesional skin appears\nunremarkable.\\\",\\n \\\"\nmorphological_features_skincon\\\": [\\n\n\\\"Plaque\\\",\\n \\\"Erythema\\\",\\n \\\"Scale\n\\\"\\n ],\\n \\\"\nmorphological_features_others\\\": [\\n \\\"\nwell-demarcated\\\",\\n \\\"silvery-white\\\"\\\nn ]\\n}\\n\\n---\\n### YOUR TASK\\nNow, for\nthe image I have provided, please\nperform the same analysis and generate\nthe JSON output. Remember, the JSON\nobject is the only thing you should\nreturn.\\n\"\n}\nSkinCon example JSON\n{\"\"detailed_description\"\": \"\"The image shows\nmultiple digits (toes) affected by\nsevere onychodystrophy and prominent\nperiungual inflammation. The nail plates\nare markedly thickened, opaque, and\ndisplay significant discoloration,\npredominantly yellow and brownish hues.\nMany nails exhibit onycholysis,\nappearing separated from the nail bed,\noften with underlying subungual\nhyperkeratosis. The surrounding\nperiungual skin and distal phalanges are\ndiffusely erythematous, swollen, and\nindurated, indicative of chronic\ninflammation. Localized areas of scaling\nand subtle crusting are also observed\non the inflamed periungual tissue.\"\", \"\"\nmorphological_features_skincon\"\": [ \"\"\nYellow\"\", \"\"Brown(Hyperpigmentation)\"\",\n\"\"Erythema\"\", \"\"Scale\"\", \"\"Induration\"\",\n\"\"Crust\"\" ], \"\"\nmorphological_features_others\"\": [ \"\"\nOnychodystrophy\"\", \"\"Onycholysis\"\", \"\"\nSubungual hyperkeratosis\"\", \"\"Nail\nthickening\"\", \"\"Opaque nails\"\", \"\"\nSwelling\"\", \"\"Periungual inflammation\"\"\n] }\n21\n"}, {"page": 22, "text": "C.2.2\nDermoscopic Images (Derm7pt)\nDerm7pt dermoscopic prompt (system +\nuser)\nPROMPT_DICT = {\n\"system_prompt\": \"You are an expert in\ndermatology. Your task is to perform a\ndetailed visual analysis of a provided\ndermoscopic image. You will analyze the\nimage and classify its features\naccording to the 7-point checklist,\nassigning the single most fitting\nmorphological label to each of the\nseven criteria. Your output must be a\nsingle, clean JSON object and nothing\nelse.\",\n\"user_prompt\": \"Analyze the provided skin\nlesion image using the established\nDerm7pt vocabulary. First, perform a\ndetailed, step-by-step visual\nassessment. Second, for each of the 7\ncriteria, select the single most\nappropriate label from the lists\nprovided below. Finally, generate a\nsingle, valid JSON object as your final\nand ONLY output. Do not include any\ntext, explanations, or markdown\nformatting outside of the JSON object.\\\nn\\n### Derm7pt Morphological Concepts\nand Labels\\nYou MUST classify the\nlesion by selecting exactly one label\nfor each of the 7 criteria:\\n\\n1. **\npigment_network**: [\\\"absent\\\", \\\"\ntypical\\\", \\\"atypical\\\"]\\n2. **\nblue_whitish_veil**: [\\\"absent\\\", \\\"\npresent\\\"]\\n3. **vascular_structures**:\n[\\\"absent\\\", \\\"arborizing\\\", \\\"comma\n\\\", \\\"hairpin\\\", \\\"within regression\\\",\n\\\"wreath\\\", \\\"dotted\\\", \\\"linear\nirregular\\\"]\\n4. **pigmentation**: [\\\"\nabsent\\\", \\\"diffuse regular\\\", \\\"\nlocalized regular\\\", \\\"diffuse\nirregular\\\", \\\"localized irregular\\\"]\\\nn5. **streaks**: [\\\"absent\\\", \\\"regular\n\\\", \\\"irregular\\\"]\\n6. **\ndots_and_globules**: [\\\"absent\\\", \\\"\nregular\\\", \\\"irregular\\\"]\\n7. **\nregression_structures**: [\\\"absent\\\",\n\\\"blue areas\\\", \\\"white areas\\\", \\\"\ncombinations\\\"]\\n\\n### Required JSON\nOutput Structure\\nThe JSON object MUST\ncontain exactly three keys:\\n1.\ndetailed_description: (String) A\ncomprehensive clinical narrative of the\nlesion's morphology, including primary\nlesion type, color, shape, border,\nsurface, and texture, justifying your\nlabel choices.\\n2.\nmorphological_features_Derm7pt: (Object\n) An object where each key is one of\nthe 7 Derm7pt criteria and its value is\na single (String) label selected from\nthe lists above.\\n3.\nmorphological_features_others: (Array\nof Strings) A list of important\nobserved features that are NOT part of\nthe 7-point checklist classification (e\n.g., symmetry, specific colors). If\nnone, this array should be empty [].\\n\\\nn### Examples for Guidance\\n\\n**INPUT\n:** [Dermoscopic image of a melanoma]\\n\n**REQUIRED JSON OUTPUT:**\\n{\\n \\\"\ndetailed_description\\\": \\\"Dermoscopy\nreveals a chaotic and asymmetrical\nlesion. The pigment network is\nthickened and irregular, with variable\nhole sizes and abrupt cut-offs at the\nperiphery, classifying it as 'atypical\n'. Irregular streaks are visible\nradiating from the main body. There are\nmultiple blotches of dark brown and\nblack pigment concentrated in one\nquadrant, consistent with 'localized\nirregular' pigmentation. Additionally,\na peppering of various-sized gray-black\ndots and globules is present,\nindicating an 'irregular' pattern. The\nlesion also features both scar-like\nwhite areas and peppercorn-like blue\nareas, which points to 'combinations'\nof regression structures. Abnormal\nlinear irregular vessels are noted. A\nblue-whitish veil is absent.\\\",\\n \\\"\nmorphological_features_Derm7pt\\\": {\\n\n\\\"pigment_network\\\": \\\"atypical\\\",\\n \\\"\nblue_whitish_veil\\\": \\\"absent\\\",\\n \\\"\nvascular_structures\\\": \\\"linear\nirregular\\\",\\n \\\"pigmentation\\\": \\\"\nlocalized irregular\\\",\\n \\\"streaks\\\":\n\\\"irregular\\\",\\n \\\"dots_and_globules\\\":\n\\\"irregular\\\",\\n \\\"\nregression_structures\\\": \\\"combinations\n\\\"\\n },\\n \\\"\nmorphological_features_others\\\": [\\n \\\"\nasymmetry\\\",\\n \\\"chaotic appearance\\\",\\\nn \\\"color variegation (dark brown,\nblack, gray-black, white, blue)\\\"\\n ]\\n\n}\\n\\n---\\n### YOUR TASK\\nNow, for the\nimage I have provided, please perform\nthe same analysis and generate the JSON\noutput. Remember, the JSON object is\nthe only thing you should return.\\n\"\n}\nC.3\nChain-of-Thought Reasoning Prompt\nCoT reasoning prompt (system + user)\nPROMPT_DICT = {\n\"system_prompt\": \"You are an expert\ndermatologist AI, acting as a clinical\nconsultant. Your primary task is to\nanalyze a skin lesion image and\ngenerate a concise clinical reasoning\nnarrative. You will be provided with\npotential clinical concepts (which may\nnot be entirely accurate) and a\nconfirmed diagnosis. You must\ncritically evaluate the visual evidence\nin the image to explain how it\nsupports the diagnosis, adhering to a\nstrict XML format for your output.\",\n\"user_prompt_template\": \"Analyze the\nprovided image and its context. Your\n22\n"}, {"page": 23, "text": "entire output must be a structured\nresponse containing a reasoning block\n(<reasoning>) and a final diagnosis\nblock (<final_diagnosis>).\\n\\n### Input\nContext\\n* **Image:**\\n\\n* **Potential\nClinical Concepts:** {\nclinical_concepts}\\n* **Confirmed\nDiagnoses:** {diagnoses}\\n\\n### Your\nTask\\nYour response MUST follow these\nthree rules precisely:\\n1. **First,**\nprovide a step-by-step clinical\nrationale explaining how the visual\nevidence in the image leads to the\nconfirmed diagnosis. Your explanation\nshould be from the perspective of an\nexpert explaining the case to a\ncolleague. Ground your reasoning in the\nvisual features of the lesion (e.g.,\nshape, color, border, texture, specific\nstructures). Use the 'Potential\nClinical Concepts' as a guide, but your\nprimary justification must come from\nthe image itself. Enclose this entire\nprocess within <reasoning> and </\nreasoning> tags.\\n2. **Second,**\nprovide the most specific diagnosis\nfrom the 'Confirmed Diagnoses' list\ninside <final_diagnosis> and </\nfinal_diagnosis> tags.\\n3. **Third,**\nensure there is absolutely NO extra\ntext, explanation, or markdown\nformatting outside of these two\nrequired XML tags.\\n\\n### Example for\nGuidance\\n\\n**INPUT CONTEXT:**\\n* **\nImage:** [Dermoscopic image of a\nmelanoma]\\n* **Potential Clinical\nConcepts:** [\\\"Asymmetry\\\", \\\"Irregular\nBorder\\\", \\\"Color Variegation (Brown,\nBlack, Blue-Gray)\\\", \\\"Atypical Pigment\nNetwork\\\"]\\n* **Confirmed Diagnoses:**\n[\\\"Malignant\\\", \\\"Malignant Melanoma\n\\\"]\\n\\n**REQUIRED OUTPUT:**\\n<reasoning\n>Upon examining the image, the lesion\nexhibits several hallmark features\nconcerning for malignancy. There is\nclear asymmetry in its overall shape\nand the border is poorly defined and\nirregular, with notches and blurred\nedges in several areas. I observe\nsignificant color variegation, with\nmultiple shades of brown and black, as\nwell as a focal blue-gray area, which\nis a strong indicator of pigment\nregression or deep melanin. These\nobservations align with the classic\nclinical signs for melanoma. The\ncombination of these visual findings\nprovides a strong basis for diagnosing\nthis lesion as a malignant melanoma,\ndifferentiating it from a benign nevus\n.</reasoning><final_diagnosis>Malignant\nMelanoma</final_diagnosis>\\n\\n---\\n###\nYOUR TASK\\nNow, for the image,\nconcepts, and diagnoses I have provided\n, generate the response in the required\nformat.\"\n}\nCoT example XML\n<reasoning>Upon visual inspection, the image\ndisplays an erythematous, ill-defined\nplaque with an irregular shape on the\nskin. Centrally, there are multiple\nconfluent erosions and ulcerations,\nappearing moist and suggestive of serous\nexudate. A yellowish-brown crust is\nalso visible within this central eroded\narea, indicating dried serous fluid or\npossibly a secondary bacterial component\n. The presence of acute erythema,\nclustered erosions, exudate, and\ncrusting is highly characteristic of an\nacute viral infection, such as Herpes\nSimplex Virus. This morphology strongly\nsupports the diagnosis as fitting within\nthe category of \"other Viral Infections\n,\" as distinct from typical warts or\nmolluscum contagiosum which present\ndifferently.</reasoning><final_diagnosis\n>Warts Molluscum and other Viral\nInfections</final_diagnosis>\nC.4\nDiagnosis VQA prompt templates\nUsing the ontology described above, we synthesize\ndiagnosis VQA items in two forms. First, for flat\nfour-way MCQA questions, we sample one ground-\ntruth diagnosis and three ontology-consistent dis-\ntractors (typically siblings or closely related con-\nditions), and render them as options A–D. The\nquestion stem is drawn at random from a small\npool of interchangeable prompts that ask the model\nto choose the most likely diagnosis. This yields\ndiverse yet semantically equivalent formulations\nwhile keeping the underlying label space fixed.\nSecond, for hierarchical diagnosis VQA, we tra-\nverse the ontology level by level. At each step, we\npresent the image and a set of candidate categories,\nand instantiate one of several templated prompts\nfor (i) selecting a top-level superclass, (ii) refining\nthe choice within its subcategories, and (iii) choos-\ning a final leaf diagnosis. Additional declarative\nprompts are used to convert the completed path into\na natural-language statement of the final diagno-\nsis, and a small set of “human correction” prompts\nsupports expert editing when the automatically pro-\nposed path is incorrect.\nTogether, these instruction types give dense su-\npervision over both what diagnosis to output and\nhow to traverse and correct a hierarchical diagnos-\ntic reasoning process.\n23\n"}, {"page": 24, "text": "PROMPTS for 4-way diagnosis MCQA\nPROMPTS = [\n\"Observe this skin image. Which of the\nfollowing diagnoses is the most\nlikely?\",\n\"Based on the skin lesion shown in this\nimage, please select the most\naccurate diagnosis from the options\nbelow.\",\n\"Which of the following diagnoses best\nmatches the skin condition shown in\nthis image?\",\n\"Considering the clinical presentation\nof the skin lesion in the image,\nwhich of the following is the most\nlikely diagnosis?\"\n]\nTOP_LEVEL_PROMPTS_GEN\nTOP_LEVEL_PROMPTS_GEN = [\n\"Based on the clinical image, identify\nthe most fitting major\ndermatological category from the\nfollowing list: {options_list}.\",\n\"Observe the skin lesion. Which of these\nhigh-level classifications best\ndescribes it? Here are the\npossibilities: {options_list}.\",\n\"Please provide a broad categorization\nfor the skin condition shown. Your\nanswer should be one of the\nfollowing: {options_list}.\"\n]\nSUB_LEVEL_PROMPTS_GEN\nSUB_LEVEL_PROMPTS_GEN = [\n\"Correct, the condition is a form of '{\nparent_category}'. Now, specify the\nsub-category from this list: {\noptions_list}.\",\n\"Proceeding from '{parent_category}',\nwhich of the following groups does\nthis lesion belong to? {options_list\n}.\",\n\"Understood. Let's refine the diagnosis\nwithin '{parent_category}'. Please\nchoose the most accurate description\nfrom the following: {options_list\n}.\"\n]\nFINAL_LEVEL_PROMPTS_GEN\nFINAL_LEVEL_PROMPTS_GEN = [\n\"We've classified this under '{\nparent_category}'. Now, provide the\ndefinitive diagnosis from the\nchoices available: {options_list}.\",\n\"Excellent. To finalize, please state\nthe specific diagnosis for '{\nparent_category}', which should be\none of the following: {options_list\n}.\",\n\"Perfect. Based on our hierarchical\nclassification ending with '{\nparent_category}', please identify\nthe definitive diagnosis from this\nlist: {options_list}.\"\n]\nDECLARATIVE_PROMPTS\nDECLARATIVE_PROMPTS = [\n\"Following the diagnostic path to '{\nparent_category}', the evidence\npoints to a single definitive\ndiagnosis, which is {final_diagnosis\n}.\",\n\"Correct. The reasoning has led us to '{\nparent_category}', which contains\nonly one specific condition.\nTherefore, the diagnosis must be {\nfinal_diagnosis}.\",\n\"Excellent. Since '{parent_category}' is\nthe most specific category and it\ncorresponds to a single diagnosis,\nwe can conclude the condition is {\nfinal_diagnosis}.\"\n]\nHUMAN_CORRECTION_PROMPTS\nHUMAN_CORRECTION_PROMPTS = [\n\"That's not quite right. While '{\nwrong_choice}' is a possibility, the\nvisual evidence points more\nstrongly to '{correct_choice}'. Let'\ns proceed with the correct category\n.\",\n\"Actually, that's incorrect. A closer\nlook reveals features more\nconsistent with '{correct_choice}'.\nPlease correct the path.\",\n\"Incorrect. The diagnosis should be '{\ncorrect_choice}', not '{wrong_choice\n}'. Let's continue from the right\ncategory.\",\n\"I disagree. '{correct_choice}' is the\nmore accurate classification here.\nLet's use that one instead.\"\n]\nD\nLLM-as-a-Judge Prompts\nWe use a text-only LLM-as-a-Judge protocol: the\njudge does not see the image and evaluates by com-\nparing the REFERENCE text versus the CANDI-\nDATE text under a strict dermatology morphology\nrubric. All tasks output a scalar final_overall\nin [0, 100] and we report mean_final_overall in\nthe main paper.\n24\n"}, {"page": 25, "text": "D.1\nTask 1.1 (Morph Description)\nTask 1.1 – SYSTEM PROMPT\nYou are a strict, no-nonsense clinical\ndermatology evaluator.\nYou DO NOT see the image; evaluate ONLY by\ncomparing the REFERENCE vs the CANDIDATE\ntext.\nUse dermatology morphology standards. Avoid\nrewarding verbosity; penalize\ncontradictions and invented findings.\nFocus on: anatomical site, number/\narrangement, primary lesion types, color\n, shape, borders, surface features, size\n/extent,\ndistribution/pattern, and special/contextual\nfeatures (e.g., pen markings,\ndermoscopic 7-point structures if\napplicable).\nReturn STRICT JSON only.\nTask 1.1 – USER PROMPT TEMPLATE\n[Task Prompt]\n\\{task\\_prompt\\}\n[REFERENCE]\n\\{reference\\}\n[CANDIDATE]\n\\{candidate\\}\nEvaluate as follows:\n1) Decompose REFERENCE into <=25 atomic\nCLAIMS.\n2) For each CLAIM, label wrt CANDIDATE:\nSupported, PartiallySupported,\nContradicted, Missing, or Vague.\n3) Identify any EXTRA INCORRECT statements\nin CANDIDATE.\n4) Score:\nrecall_like = (Supported + 0.5*\nPartiallySupported) / max(1,\ntotal_ref_claims)\nprecision_penalty = min(1.0, (\nContradicted + ExtraIncorrect) / max\n(1, total_ref_claims))\noverall [0-100] = round(100 * max(0,\nrecall_like - 0.5*precision_penalty),\n1)\nProvide rubric sub-scores (accuracy,\ncompleteness, consistency) in [0,1].\nJSON ONLY. Schema:\n\\{\n\"claims\": [\\{\"text\":\"...\",\"label\":\"\nSupported|PartiallySupported|\nContradicted|Missing|Vague\"\\}],\n\"counts\": \\{\"supported\":0,\"partial\":0,\"\ncontradicted\":0,\"missing\":0,\"vague\n\":0,\"extra\\_incorrect\":0,\"total\\_ref\\\n_claims\":0\\},\n\"rubric\": \\{\"accuracy\":0.0,\"completeness\n\":0.0,\"consistency\":0.0\\},\n\"overall\": 0.0,\n\"short\\_feedback\": \"<=40 words concise\njustification\"\n\\}\nD.2\nTask 1.2 (Morph Content + Narrative)\nTask 1.2 – SYSTEM PROMPT\nYou are a strict dermatology evaluator for\nTask 1.2 (morph content + narrative).\nYou DO NOT see the image. Focus on CONTENT,\nnot formatting.\nBoth REFERENCE and CANDIDATE may or may not\nwrap the morph JSON in <morph> tags.\nDo NOT penalize missing tags, extra\nwhitespace, or minor ordering/format\ndifferences.\nIf a JSON block is present anywhere, treat\nthe FIRST JSON object as the morph\ncontent.\nIf no JSON is present, infer the morph\nfeature set from the surrounding text.\nSchemas you may encounter:\n- SkinCon: \\{\"morphological\\_features\\\n_skincon\": [<feature strings>]\\}\n- Derm7pt: \\{\"morphological\\_features\\\n_Derm7pt\": \\{pigment\\_network, blue\\\n_whitish\\_veil, vascular\\_structures,\npigmentation, streaks, dots\\_and\\\n_globules, regression\\_structures\\}\\}\nFor the narrative comparison, use\ndermatology morphology standards (site,\nnumber/arrangement, primary lesion types\n, color, shape, borders, surface\nfeatures, size/extent, distribution/\npattern, special/context).\nAlso check CROSS-CONSISTENCY between the\nCANDIDATE morph content and CANDIDATE\nnarrative.\nReturn STRICT JSON only.\nTask 1.2 – USER PROMPT TEMPLATE\nYou will be given REFERENCE and CANDIDATE\ntexts.\nEach may contain a morph JSON (SkinCon or\nDerm7pt) with or without <morph> tags,\npossibly followed by a narrative paragraph.\nDo NOT penalize formatting.\nRules:\n- If a JSON object appears anywhere, treat\nthe FIRST JSON object as the morph\ncontent.\n- If no JSON is found, infer the morph\nfeature set from the surrounding text (\nbest-effort).\n- Use synonyms tolerance for semantic\nmatching.\n[Task Prompt]\n\\{task\\_prompt\\}\n[REFERENCE]\n\\{reference\\}\n25\n"}, {"page": 26, "text": "[CANDIDATE]\n\\{candidate\\}\nYour tasks:\n1) MORPH SEMANTICS (content-first): Compare\nCANDIDATE-morph vs REFERENCE-morph\nsemantically (synonyms allowed).\nCount supported/missing/contradicted/\nextra and give a semantic score in\n[0,1].\nIf CANDIDATE has no explicit JSON, infer\nits morph set from the candidate text.\n2) TEXT (NARRATIVE): Compare REFERENCE-\nnarrative vs CANDIDATE-narrative using\nmorphology standards.\nExtract <=25 atomic claims from the\nREFERENCE-narrative; for each, label\nCANDIDATE as Supported/\nPartiallySupported/Contradicted/\nMissing/Vague.\nProvide rubric sub-scores (accuracy,\ncompleteness, consistency) in [0,1]\nand overall [0,100] using:\nrecall_like = (Supported + 0.5*\nPartiallySupported) / max(1,\ntotal_ref_claims)\nprecision_penalty = min(1.0, (\nContradicted + ExtraIncorrect) / max\n(1, total_ref_claims))\noverall = round(100 * max(0, recall_like -\n0.5*precision_penalty), 1)\n3) CROSS-CONSISTENCY: Judge if the CANDIDATE\nnarrative contradicts the CANDIDATE\nmorph content.\nOutput a penalty in [0,1] (0=no issue, 1=\nsevere) and short notes.\nOutput STRICT JSON:\n\\{\n\"morph\\_semantic\": \\{\n\"schema\": \"SkinCon\" | \"Derm7pt\" | \"\nUnknown\",\n\"supported\": 0, \"missing\": 0, \"\ncontradicted\": 0, \"extra\": 0,\n\"score\\_semantic\": 0.0,\n\"notes\": \"<=60 words\"\n\\},\n\"text\\_judge\": \\{\n\"claims\": [\\{\"text\":\"...\",\"label\":\"\nSupported|PartiallySupported|\nContradicted|Missing|Vague\"\\}],\n\"counts\": \\{\"supported\":0,\"partial\":0,\"\ncontradicted\":0,\"missing\":0,\"vague\n\":0,\"extra\\_incorrect\":0,\"total\\_ref\n\\_claims\":0\\},\n\"rubric\": \\{\"accuracy\":0.0,\"completeness\n\":0.0,\"consistency\":0.0\\},\n\"overall\": 0.0,\n\"short\\_feedback\": \"<=40 words\"\n\\},\n\"cross\\_consistency\": \\{\"penalty\": 0.0, \"\nnotes\": \"<=40 words\"\\}\n\\}\nD.3\nTask 3.1 (Reasoning + Final Diagnosis)\nTask 3.1 – SYSTEM PROMPT\nYou are a strict dermatology evaluator for\nTask 3 (reasoning + final diagnosis).\nYou DO NOT see the image; evaluate ONLY the\ntextual content. Ignore formatting and\ntags.\nGoal: robustly extract (A) the candidate's\nreasoning and (B) the candidate's final\ndiagnosis,\nthen score (1) REASONING ALIGNMENT vs the GT\nreasoning and (2) DIAGNOSIS SIMILARITY\nvs the GT final diagnosis.\nPenalize contradictions and hallucinated\nfindings. Do not reward verbosity.\nReturn STRICT JSON only.\nTask 3.1 – USER PROMPT TEMPLATE\n[Task Prompt]\n\\{task\\_prompt\\}\n[GROUND\\_TRUTH\\_RAW]\n\\{reference\\}\n[CANDIDATE\\_RAW]\n\\{candidate\\}\nEvaluate with these steps (format-agnostic;\nfocus on content):\nA) Extraction (be robust even if the\ncandidate is unstructured):\n- From GROUND_TRUTH_RAW, extract:\ngt_reasoning: inside <reasoning>...</\nreasoning> if present; else best-\neffort summary.\ngt_final_dx: inside <final_diagnosis\n>...</final_diagnosis> if present;\nelse best-effort label.\n- From CANDIDATE_RAW, extract:\ncand_reasoning: the explanation/\nrationale (anywhere).\ncand_final_dx: the single most likely\nfinal diagnosis term/phrase.\nB) Reasoning Alignment:\n- Decompose gt_reasoning into <=25 atomic\nclaims.\n- For each claim, label wrt\ncand_reasoning: Supported |\nPartiallySupported | Contradicted |\nMissing | Vague.\n- Compute reasoning_score [0-100] using\nthe same recall/penalty formula.\nC) Diagnosis Similarity (graded, not binary)\n:\n- Decide relation: Exact | Synonym |\nParent | Child | Sibling/\nCloseDifferential | SameSuperfamily |\nUnrelatedPlausible | WrongSystem |\nNonsense/NoAnswer.\n- Map to similarity in [0,1] and compute\ndiagnosis_score [0-100].\n26\n"}, {"page": 27, "text": "D) Overall:\n- overall [0-100] = round(0.5 *\nreasoning_score + 0.5 *\ndiagnosis_score, 1)\nSTRICT JSON ONLY (use the specified schema\nin the paper).\nD.4\nTask 3.2 (Morph-grounded Reasoning)\nTask 3.2 – SYSTEM PROMPT\nYou are a strict dermatology evaluator for\nTask 3.2 (reasoning + morph JSON + final\ndiagnosis).\nYou DO NOT see the image. Focus on CONTENT,\nnot formatting.\nBoth REFERENCE and CANDIDATE may or may not\nwrap the morph JSON in <morph> tags.\nDo NOT penalize missing tags, extra\nwhitespace, or ordering differences.\nIf a JSON object appears anywhere, treat the\nFIRST JSON object as the morph content.\nIf no JSON is present, infer the morph\nfeature set from the surrounding text.\nSCHEMA SELECTION RULE: Detect the schema\nused by REFERENCE. Compare and output\nusing the SAME schema.\nTask 3.2 – USER PROMPT TEMPLATE\nYou will be given REFERENCE and CANDIDATE\ntexts containing three conceptual parts:\n<reasoning>, <morph> JSON, and <\nfinal_diagnosis>.\nBe format-agnostic; extract content even\nwhen tags are missing or order differs.\nAllowed schemas:\n- Derm7pt (object with EXACT keys):\npigment_network, blue_whitish_veil,\nvascular_structures, pigmentation,\nstreaks, dots_and_globules,\nregression_structures\n- SkinCon (array of strings only): \\{\"\nmorphological\\_features\\_skincon\": [ ...\n]\\} from a CLOSED set.\nSCHEMA SELECTION:\n- Detect the schema used by REFERENCE (\nDerm7pt vs SkinCon). Use that schema for\nextraction/normalization and comparison\n. Do NOT switch schemas.\n[Task Prompt]\n\\{task\\_prompt\\}\n[REFERENCE]\n\\{reference\\}\n[CANDIDATE]\n\\{candidate\\}\nTasks:\nA) EXTRACTION: reasoning, morph (normalized\nto REFERENCE schema), final_dx for both\nsides.\nB) REASONING ALIGNMENT: compute\nreasoning_score [0-100].\nC) MORPH SEMANTICS: score_semantic in [0,1].\nD) DIAGNOSIS SIMILARITY: diagnosis_score\n[0-100].\nE) CROSS-CONSISTENCY: penalty in [0,1] if\ncandidate reasoning contradicts\ncandidate morph JSON.\nSTRICT JSON ONLY (use the specified schema\nin the paper).\nD.5\nJudge Reliability and Human Sanity\nCheck\nD.5.1\nJudge sensitivity on the 900-case core\nset\nTable 7 reports mean_final_overall on the 900-\ncase core set when swapping the judge between\nGemini-2.5-Pro (main paper default) and GPT-5.\nThis comparison is intended as a robustness check\nfor evaluator choice rather than a replacement of\nthe main evaluation protocol.\nCandidate model\nJudge\nT1.1\nT1.2\nT3.1\nT3.2\nQwen3-VL-8B\nGemini-2.5-Pro\n33.18\n46.05\n47.53\n53.43\nQwen3-VL-8B\nGPT-5\n37.73\n43.92\n51.08\n59.81\nGPT-4o-mini\nGemini-2.5-Pro\n34.55\n51.80\n42.83\n51.65\nGPT-4o-mini\nGPT-5\n31.32\n47.82\n45.28\n49.17\nTable 7: Judge sensitivity on the 900-case core set (re-\nported as mean_final_overall in [0, 100]).\nD.5.2\nAggregate-level inter-judge agreement\nmetrics\nUsing the 8 paired items in Table 7 (2 candi-\ndate models × 4 tasks), we compute rank/absolute\nagreement metrics between GPT-5 and Gemini-2.5-\nPro judge scores. Results indicate strong agreement\nat the level of model-task means.\nMetric\nValue\nPearson r\n0.883\nSpearman ρ\n0.857\nMean difference (GPT-5 −Gemini)\n+0.65\nMean absolute difference (MAE)\n3.60\nTable 8: Inter-judge agreement between GPT-5 and\nGemini-2.5-Pro computed over the 8 paired model-task\nmeans in Table 7.\nD.6\nHuman sanity check (20 cases)\nWe further sample 20 cases from Qwen3-VL-8B +\nGemini-2.5-Pro and ask clinicians to rate whether\n27\n"}, {"page": 28, "text": "the judge scoring and feedback are reasonable on\na 0–5 scale (higher is more reasonable). Figure 2c\nsummarizes the reasonableness ratings.\nE\nTraining Details\nE.1\nHyperparameters\nBackbone and precision.\nWe initialize from\nQwen3-VL-8B-Instruct, train with Deepspeed\nZeRO-2, and use BF16 with TF32 enabled.\nFlashAttention-2 is used unless stated otherwise.\nGradient checkpointing is enabled in both stages.\nStage 1: Supervised fine-tuning (SFT).\nWe\nperform one epoch of multi-task SFT on the\nmerged instruction data.\nWe enable LoRA\nadapters\nwith\nrank\nr=64,\nα=64,\ndropout\n0.05, and exclude lm_head and embed_tokens\nfrom LoRA injection.\nWe freeze the lan-\nguage\nmodel\nbackbone\n(freeze_llm=True),\nwhile keeping the vision tower and merger\ntrainable\n(freeze_vision_tower=False,\nfreeze_merger=False).\nWe set per-device\nbatch size to 8 on 8 GPUs with gradient accu-\nmulation steps 2 (global batch size 128).\nWe\ntrain with learning rate 1e−4, and optionally\nuse module-specific learning rates for the vision\ntower (2e−6) and the merger (1e−5).\nWeight\ndecay is 0.1, warmup ratio is 0.03, and we use\na cosine scheduler. Images are resized by pixel\nconstraints with image_min_pixels = 256 · 322\nand image_max_pixels = 1280 · 322. Unless oth-\nerwise specified, we use the training framework’s\ndefault AdamW-type optimizer settings.\nStage 2: GRPO with MAVIC reward.\nWe fur-\nther optimize the SFT checkpoint with GRPO us-\ning group size K=num_generations = 8. We\ntrain for one epoch with per-device batch size\n32 and gradient accumulation steps 3. We sam-\nple completions with temperature 1.0, top-p 1.0,\nand top-k 50, using maximum prompt length\n4096 and maximum completion length 640. We\nset learning rate to 1e−6, weight decay to 0.1,\nwarmup ratio to 0.03, and cosine scheduler. We\nuse beta=0.1 for GRPO’s KL regularization. In\nthis stage, we freeze the vision tower, language\nmodel, and merger, and train only LoRA adapters\n(LoRA rank 16, α = 32, dropout 0.05, exclud-\ning lm_head and embed_tokens). Images are con-\nstrained by image_min_pixels = 256 · 282 and\nimage_max_pixels = 1280 · 282.\nHyperparameter\nSFT\nGRPO\nGPUs\n8\n8\nEpochs\n1\n1\nPer-device batch\n8\n32\nGrad. accumulation\n2\n3\nGlobal batch\n128\n768\nLoRA rank / α\n64 / 64\n16 / 32\nLoRA dropout\n0.05\n0.05\nBackbone frozen?\nLLM frozen\nLLM/Vision/Merger frozen\nLR\n1e−4\n1e−6\nVision LR / Merger LR\n2e−6 / 1e−5\n–\nWeight decay\n0.1\n0.1\nWarmup / Scheduler\n0.03 / cosine\n0.03 / cosine\nGroup size K\n–\n8\nSampling\n–\nT=1.0, top-p=1.0, top-k=50\nMax prompt / completion\n–\n4096 / 640\nKL coef. (beta)\n–\n0.1\nTable 9: Key hyperparameters for SFT and RL training.\nE.2\nMAVIC Implementation Details\nMorphology representation (tokens).\nEach\ncompletion must contain a structured morphol-\nogy field encoded as JSON under a <morph> tag.\nFor dermoscopic images, we use Derm7pt-style\nattributes (Kawahara et al., 2018); for clinical im-\nages, we use SkinCon-style attributes (Ren et al.,\n2024).\nWe binarize morphology into a vector\nm ∈{0, 1}F , where each dimension f corre-\nsponds to an attribute indicator. For Derm7pt, we\nexpand categorical states into attribute-state indi-\ncators (e.g., streaks_irregular); for SkinCon,\neach label is an indicator.\nPMI-based weights (precomputed lookup).\nBe-\ncause each training sample has a known leaf di-\nagnosis y, we precompute diagnosis-conditioned\nweights wf(y) once before RL training. We esti-\nmate PMI with log and ϵ = 10−5 smoothing and\nkeep negative values:\nPMI(mf; y) = log ˆp(mf=1, y) + ϵ\nˆp(mf=1)ˆp(y) + ϵ.\n(5)\nWe then normalize per diagnosis with a softmax\nover features:\nwf(y) =\nexp(PMI(mf; y))\nP\nf′ exp(PMI(mf′; y)).\n(6)\nDuring RL, wf(y) is obtained by table lookup.\nMorphology similarity Smorph.\nLet P and G be\nthe predicted and ground-truth sets of active mor-\nphology indicators. We compute a PMI-weighted\n28\n"}, {"page": 29, "text": "Tversky score with α = 0.7, β = 0.3:\nTP =\nX\nf\nwf1[ ˆmf = 1 ∧mf = 1],\nFP =\nX\nf\nwf1[ ˆmf = 1 ∧mf = 0],\nFN =\nX\nf\nwf1[ ˆmf = 0 ∧mf = 1].\n(7)\nSmorph( ˆm, m) =\nTP\nTP + αFP + βFN.\n(8)\nHierarchy similarity Shier.\nWe map a diagnosis\nto its taxonomy path (ancestors) and append the\nleaf label to the end of the path. We compute Wu–\nPalmer similarity:\nShier = 2 · depth(LCA(pathpred, pathgt))\n|pathpred| + |pathgt|\n.\n(9)\nWhen parsing model outputs, we canonicalize\nstrings and use alias/fuzzy matching (threshold 0.8)\nto map predictions to taxonomy leaves.\nSoft gate.\nWithin each GRPO sampling group\n(size K), we set µ as the median Shier and apply\nthe sigmoid gate with k = 10.\nFormat term Rfmt.\nRfmt ∈{0, 1} indicates\nwhether the completion satisfies required tag struc-\nture and JSON validity: (i) presence of required\ntags (e.g., <morph> and, for reasoning tasks,\n<final_diagnosis>); (ii) parseable JSON under\n<morph>; (iii) exactly one valid schema (Derm7pt\nor SkinCon); (iv) schema matches image modality;\nand (v) tag ordering constraints when applicable.\nInvalid outputs receive Rfmt = 0.\nHyperparameters.\nWe use λhier = λmorph = 1,\nα = 0.7, β = 0.3, ϵ = 10−5, fuzzy threshold 0.8,\nand gate slope k = 10.\nF\nAblation Study\nF.1\nImpact of MAVIC Reward Components\nAs shown in Table 4, using standard reinforcement\nlearning rewards alone (acc+fmt) actually degrades\nperformance on T3.2 (59.88). Incorporating mor-\nphological similarity reward Smorph and hierarchi-\ncal diagnosis reward Shier steadily improves scores\nto 65.48. Crucially, the combination of Smorph with\nthe logical gating mechanism g(Shier) effectively\nprevents models from bypassing pathological fea-\ntures to make uninformed diagnostic guesses.\nK\nTask2.4 (OOD) ↑\nTask4 (Fair.) ↑\n2\n65.82\n93.81\n4\n66.27\n93.76\n8\n66.48\n93.88\nTable 10: Sensitivity to the number of prompt variants\nK.\nF.2\nAblation of Confidence–Consistency\nComponents\nSetup.\nWe evaluate test-time adaptation (TTA)\nunder the same deterministic decoding setting as\nthe main paper (temperature = 0). The only source\nof diversity is prompt paraphrasing: we use K\nprompt variants per example (including the original\nprompt), and aggregate MCQA option probabilities\nderived from the first-step logits.\nBaselines.\nWe compare against standard, simpler\nensemble decoding variants: (i) Single (K=1),\nno TTA; (ii) Vote, majority vote over predicted\noption letters across prompts; (iii) MeanProb,\nunweighted averaging of option probability vec-\ntors pr; (iv) ConfOnly, weights based on confi-\ndence margin only (β=0); (v) ConsOnly, weights\nbased on consistency only (drop ˜Cr term); (vi) CC\n(Ours), full confidence–consistency weighting.\nSensitivity to K and hyperparameters.\nWe fur-\nther vary the number of prompt variants K and the\nconfidence exponent α / consistency weight β.\nTakeaway.\nAcross datasets, the gains of CC ag-\ngregation cannot be explained solely by using more\nprompts (K), and persist after controlling for sim-\npler voting/averaging baselines, supporting the\nclaim that confidence and consistency provide com-\nplementary signals for robust MCQA aggregation.\nG\nTheoretical Analysis\nWe provide a probabilistic model explaining why\nour CCT can suppress outlier rollouts and remain\nclose to an underlying “ideal” token distribution.\nSetup.\nFix a decoding step t. For notational sim-\nplicity, we omit the superscript and write pr ∈\n∆V −1 for the token distribution of the r-th rollout\nat this step, where ∆V −1 is the probability simplex\nin RV . For any p ∈∆V −1 we have\n∥p∥2 ≤1,\n(10)\nand hence for any p, p∗∈∆V −1,\n∥p −p∗∥2\n2 ≤2.\n(11)\n29\n"}, {"page": 30, "text": "At this time step, our method forms a weighted\nensemble\nq =\nK\nX\nr=1\nwrpr,\nwr =\nexp(λCr −βDr)\nPK\nj=1 exp(λCj −βDj)\n.\n(12)\nwhere\n• Cr ∈[0, 1] is a margin-based confidence\nscore, derived from the top-1 vs. top-2 proba-\nbility gap of pr;\n• Dr = 1\n2 ∥pr −¯p∥2\n2 is the squared ℓ2-distance\nto the empirical barycenter ¯p := 1\nK\nPK\nj=1 pj;\n• λ ≥0 controls the strength of the confidence\nterm, and β > 0 controls how aggressively\nwe downweight outliers.\nIntuitively, Dr penalizes rollouts that deviate from\nthe main cluster, while Cr slightly favors locally\nconfident rollouts among those that are consistent.\nWe now formalize this intuition via a contamina-\ntion model.\nG.1\nHuber Contamination on the Simplex\nWe assume that the rollouts at a fixed decoding step\nare i.i.d. samples from a mixture of a “clean” (good)\ncomponent and a contaminated (bad) component.\nAssumption 1 (Huber contamination on the sim-\nplex). There exists an unknown target distribution\np∗∈∆V −1 such that each rollout distribution pr\nis drawn i.i.d. from\npr ∼(1 −ε) DG + ε DB,\n(13)\nwhere r = 1, . . . , K, 0 ≤ε < 1\n2, DG and DB\ndenote the clean and contaminated components,\nrespectively.\nWe assume the following moment and separation\nconditions:\nEp∼DG\n\u0002\n∥p −p∗∥2\n2\n\u0003\n≤σ2,\n(14)\nEp∼DB\n\u0002\n∥p −p∗∥2\n2\n\u0003\n≥σ2 + ∆2,\n(15)\nfor some σ2 > 0 and ∆2 > 0. Let µG := EDG[p]\nand µB := EDB[p] be the means of the clean and\ncontaminated components, respectively. We further\nassume a signal-to-noise condition:\nε ∥µB −µG∥2 ≤c0 ∆\nfor some c0 < 1\n2 (16)\nFinally, we assume that the clean noise level σ\nis sufficiently small relative to the separation ∆\n(and the contamination rate ε) so that there exists\na parameter α ∈(0, 1) satisfying simultaneously:\nRG(α) :=\nσ\n√α < RB :=\nr\nσ2 + ∆2\n2 ,\n(17)\n(1 −ε)(1 −α) > 1\n2,\n(18)\nσ + c0∆≤η(RB −RG)\n(19)\nfor some η ∈(0, 1\n2). This mild requirement is\nautomatically satisfied whenever the clean cluster\nis sufficiently concentrated (small σ) compared to\nthe separation ∆and the contamination rate ε is\nmoderate.\nAssumption 1 is a Huber contamination model\nadapted to the probability simplex. Conditions\n(14)–(15) ensure that the clean component concen-\ntrates around p∗, while the contaminated compo-\nnent is, on average, farther away. The signal-to-\nnoise condition (16) ensures that the mixture mean\nis not dominated by the contaminated component.\nConditions (17)–(18) guarantee that we can choose\na single parameter α that yields both geometric\nseparation and a strict majority of “good” rollouts.\nBecause pr ∈∆V −1, all random variables are\nuniformly bounded by (10), and standard concen-\ntration inequalities (Hoeffding, Chernoff, and their\nvector-valued variants) apply directly.\nG.2\nHigh-Probability Geometric Separation\nWe now show that, under Assumption 1, the em-\npirical sample {pr}K\nr=1 exhibits a geometric “good-\ncluster / bad-cluster” separation with high proba-\nbility. This is precisely the structure used in deter-\nministic analyses of outlier suppression.\nLemma 1 (High-probability geometric separa-\ntion). Suppose Assumption 1 holds and the rollouts\np1, . . . , pK are drawn i.i.d. from the mixture (13).\nFix any δ ∈(0, 1) and let α ∈(0, 1) be chosen so\nthat (17) and (18) hold. Define\nεeff := RG(α) =\nσ\n√α,\n∆eff := RB =\nr\nσ2 + ∆2\n2 .\n(20)\nThen there exist constants ρeff ∈(1\n2, 1), η ∈\n(0, 1\n2) and a sample size threshold K0\n=\nK0(σ, ∆, ε, α, δ) such that the following holds.\nIf K ≥K0, then with probability at least 1 −δ\nover the draw of {pr}K\nr=1, there exist index sets\nGeff, Beff ⊆{1, . . . , K} with Geff ∩Beff = ∅and\nGeff ∪Beff ̸= ∅such that:\n30\n"}, {"page": 31, "text": "1. (Effective good cluster)\n∥pg −p∗∥2 ≤εeff, ∀g ∈Geff,\n|Geff| ≥ρeff K.\n(21)\nwhere ρeff > 1\n2.\n2. (Effective bad cluster is farther)\n∥pb −p∗∥2 ≥∆eff, ∀b ∈Beff,\n∆eff > εeff.\n(22)\n3. (Barycenter remains in the attraction basin)\nLet ¯p\n:=\n1\nK\nPK\nr=1 pr be the empirical\nbarycenter. Then\n∥¯p −p∗∥2 ≤η\n\u0000∆eff −εeff\n\u0001\n.\n(23)\nProof. We proceed in three steps.\nStep 1: Effective good cluster. Consider the ran-\ndom variable\nXG(p) := ∥p −p∗∥2\n2,\nfor p ∼DG. By (14), EDG[XG] ≤σ2, and by (11),\n0 ≤XG(p) ≤2 a.s.\nBy Markov’s inequality, for the fixed α ∈(0, 1)\n(chosen in the assumption),\nPr\np∼DG\n\u0000XG(p) > σ2\nα\n\u0001\n≤α.\n(24)\nEquivalently,\nPr\np∼DG\n\u0010\n∥p −p∗∥2 ≤\nσ\n√α\n\u0011\n=\nPr\np∼DG\n\u0010\nXG(p) ≤σ2\nα\n\u0011\n,\n≥1 −α.\n(25)\nRecall that we define\nRG(α) :=\nσ\n√α, εeff := RG(α).\nNow consider the mixture D in (13).\nThe\nprobability that p is drawn from DG and satisfies\n∥p −p∗∥2 ≤RG(α) is at least\nPr\np∼D\n\u0010\np ∼DG, ∥p −p∗∥2 ≤RG(α)\n\u0011\n≥(1 −ε)(1 −α).\n(26)\nwhere we used independence between the mixture\ncomponent choice and the conditional distribution.\nFor each r ∈{1, . . . , K}, define the indicator\nIr := 1{pr ∼DG and ∥pr −p∗∥2 ≤RG(α)}.\nThen (Ir)K\nr=1 are i.i.d. Bernoulli random variables\nwith\nE[Ir] = Pr\npr∼D(Ir = 1) ≥(1 −ε)(1 −α). (27)\nBy Hoeffding’s inequality, for any τ > 0,\nPr\n\u0010 1\nK\nK\nX\nr=1\nIr ≤(1 −ε)(1 −α) −τ\n\u0011\n≤exp\n\u0000−2Kτ 2\u0001\n.\n(28)\nSince by Assumption (18), (1−ε)(1−α) > 1\n2, we\ncan choose τ > 0 such that\n(1 −ε)(1 −α) −τ > 1\n2.\nFix such a τ, and define the event\nEG :=\nn 1\nK\nK\nX\nr=1\nIr > (1 −ε)(1 −α) −τ\no\n.\nGiven a target failure probability δ ∈(0, 1), choose\nK large enough such that\nexp\n\u0000−2Kτ 2\u0001\n≤δ\n3.\nThen Pr(EG) ≥1 −δ/3, and on EG,\nK\nX\nr=1\nIr >\n\u0000(1 −ε)(1 −α) −τ\n\u0001\nK := ρeffK\nfor some ρeff > 1/2.\nDefine Geff to be any subset of indices with\nIg = 1 for all g ∈Geff and |Geff| = PK\nr=1 Ir.\nBy construction, on EG we have\n∥pg −p∗∥2 ≤RG(α) = εeff,\ng ∈Geff,\n(29)\n|Geff| ≥ρeff K.\nso (29) holds.\nStep 2: Effective bad cluster. Consider\nXB(p) := ∥p −p∗∥2\n2\nfor p ∼DB. By (15),\nEDB[XB] ≥σ2 + ∆2,\n(30)\nand by (11), we have 0 ≤XB(p) ≤2 almost\nsurely.\nFix the threshold\na := σ2 + ∆2\n2 .\n(31)\n31\n"}, {"page": 32, "text": "From (11) and EDB[XB] ≤2, it follows that σ2 +\n∆2 ≤2, hence a ≤σ2 + ∆2 ≤2 and in particular\na ≤2. Decompose\nEDB[XB] = EDB[XB1{XB < a}]\n+ EDB[XB1{XB ≥a}]\n≤a · Pr(XB < a) + 2 · Pr(XB ≥a)\n= a + (2 −a) Pr(XB ≥a)\n(32)\nsince XB ≤2 almost surely. Combining this with\nEDB[XB] ≥σ2 + ∆2 yields\nσ2 + ∆2 ≤a + (2 −a) Pr(XB ≥a)\n= σ2 + ∆2\n2 + (2 −a) Pr(XB ≥a),\n(33)\nand hence\nPr(XB ≥a) ≥\n∆2\n2\n2 −a ≥∆2\n4 .\n(34)\nEquivalently,\nPr\np∼DB\n\u0010\n∥p −p∗∥2 ≥√a\n\u0011\n≥∆2\n4 .\n(35)\nDefine\nRB := √a =\nr\nσ2 + ∆2\n2 ,\n∆eff := RB.\n(36)\nBy Assumption (17), we have ∆eff = RB >\nRG(α) = εeff.\nNow consider the mixture D. The probability\nthat p ∼D is drawn from DB and satisfies ∥p −\np∗∥2 ≥RB is at least\nPr\np∼D\n\u0000p from DB, ∥p −p∗∥2 ≥RB\n\u0001\n≥ε · ∆2\n4 .\n(37)\nFor each r, define the indicator\nJr := 1{pr is drawn from DB and ∥pr−p∗∥2 ≥RB}.\nThen (Jr)K\nr=1 are i.i.d. Bernoulli random variables\nwith\nE[Jr] = Pr\npr∼D(Jr = 1) ≥ε · ∆2\n4 .\n(38)\nApplying Hoeffding’s inequality again, for any\nτ ′ > 0,\nPr\n\u0010 1\nK\nK\nX\nr=1\nJr ≤ε∆2\n4 −τ ′\u0011\n≤exp\n\u0000−2Kτ ′2\u0001\n.\n(39)\nGiven δ, we may choose τ ′ > 0 and K large\nenough so that ε ∆2\n4 −τ ′ > 0 and exp(−2Kτ ′2) ≤\nδ/3.\nDefine the event\nEB :=\nn 1\nK\nK\nX\nr=1\nJr > ε∆2\n4 −τ ′o\n.\nThen Pr(EB) ≥1 −δ/3, and on EB there are at\nleast\n\u0010\nε∆2\n4 −τ ′\u0011\nK\nindices r such that Jr = 1. Define Beff to be any\nsubset of indices with Jb = 1 for all b ∈Beff\nand |Beff| = PK\nr=1 Jr. By construction, for all\nb ∈Beff we have ∥pb −p∗∥2 ≥RB = ∆eff, so\n(22) holds on EB.\nStep 3: Control of the barycenter. Let µ := E[pr]\nbe the mean of the mixture D. From (13) we have\nµ = (1 −ε)µG + εµB.\n(40)\nUsing Jensen’s inequality and (14),\n∥µG −p∗∥2\n2 ≤EDG\n\u0002\n∥p −p∗∥2\n2\n\u0003\n≤σ2,\n(41)\nso ∥µG −p∗∥2 ≤σ. Hence\n∥µ −p∗∥2 =\n\r\r(1 −ε)(µG −p∗) + ε(µB −p∗)\n\r\r\n2\n≤(1 −ε)∥µG −p∗∥2 + ε∥µB −p∗∥2\n≤∥µG −p∗∥2 + ε∥µB −µG∥2\n≤σ + ε∥µB −µG∥2\n≤σ + c0∆,\n(42)\nwhere we used (16) in the last inequality.\nNow consider the empirical barycenter ¯p =\n1\nK\nPK\nr=1 pr. Since each pr ∈∆V −1 with ∥pr∥2 ≤\n1, the vector-valued Hoeffding inequality implies\nthat, for any t > 0,\nPr\n\u0000∥¯p −µ∥2 ≥t\n\u0001\n≤2 exp\n\u0000−cKt2\u0001\n,\n(43)\nfor some universal constant c > 0.\nGiven δ,\nchoose t > 0 and K large enough such that\n2 exp(−cKt2) ≤δ/3. Define\nEM :=\n\b\n∥¯p −µ∥2 ≤t\n\t\n.\nThen Pr(EM) ≥1 −δ/3, and on EM,\n∥¯p−p∗∥2 ≤∥¯p−µ∥2+∥µ−p∗∥2 ≤t+σ+c0∆.\n(44)\nWe now ensure that this is bounded by a fraction\nof the gap ∆eff −εeff = RB −RG(α) > 0. By\n32\n"}, {"page": 33, "text": "Assumption (17), RG(α) < RB, so ∆eff−εeff > 0.\nFix any η ∈(0, 1\n2). By increasing K, we can make\nt arbitrarily small, and therefore we can choose K\nso large that\nt+σ+c0∆≤η\n\u0000RB−RG(α)\n\u0001\n= η\n\u0000∆eff −εeff\n\u0001\n.\n(45)\nOn EM we then have\n∥¯p −p∗∥2 ≤η\n\u0000∆eff −εeff\n\u0001\n,\nwhich is (23).\nStep 4: Union bound. Define\nE := EG ∩EB ∩EM.\nBy construction and our choices of K, we have\nPr(E) ≥1 −\n\u0000 δ\n3 + δ\n3 + δ\n3\n\u0001\n= 1 −δ,\nand on E all three properties hold. This proves the\nlemma.\nLemma 1 states that, for sufficiently many roll-\nouts, with high probability the empirical set be-\nhaves as if there were a deterministic “good cluster”\nand “bad cluster” around p∗, with the barycenter\n¯p staying within the attraction region of the good\ncluster. We next exploit this for robust aggregation.\nG.3\nRobust Aggregation via Squared ℓ2\nWe now show that, on the high-probability event\nof Lemma 1, exponential weighting based on the\nsquared ℓ2 distance Dr suppresses contaminated\nrollouts exponentially.\nFor the moment, we ignore the confidence term\n(λ = 0) and consider pure distance-based weights\nwr ∝exp(−βDr), Dr = 1\n2 ∥pr −¯p∥2\n2,\n(46)\nTheorem 2 (Robust aggregation under geometric\nseparation). Suppose the high-probability event of\nLemma 1 holds, with parameters εeff, ∆eff, ρeff, η\nsatisfying ∆eff > εeff and η <\n1\n2. Then there\nexists a constant γeff > 0, depending only on these\nparameters, such that:\n1. For all g ∈Geff and b ∈Beff,\nDb ≥Dg + γeff.\n(47)\n2. For any β > 0, the aggregate distribution q =\nPK\nr=1 wrpr with wr ∝exp(−βDr) satisfies\n∥q −p∗∥2 ≤εeff + CU+\n(∆max −εeff)1 −ρeff\nρeff\ne−βγeff\n(48)\nwhere CU is a constant. In particular, if Geff ∪\nBeff = [K], the aggregated distribution q con-\nverges in ℓ2 to the effective good cluster up to ra-\ndius εeff, and the influence of contaminated rollouts\nis exponentially suppressed.\nProof. Step 1: Gap in Dr. By Lemma 1, for all\ng ∈Geff we have ∥pg −p∗∥2 ≤εeff and for all\nb ∈Beff we have ∥pb −p∗∥2 ≥∆eff, and the\nbarycenter satisfies ∥¯p −p∗∥2 ≤η(∆eff −εeff).\nFor any g ∈Geff,\n∥pg −¯p∥2 ≤∥pg −p∗∥2 + ∥p∗−¯p∥2\n≤εeff + η\n\u0000∆eff −εeff\n\u0001\n,\n(49)\nso\nDg = 1\n2∥pg −¯p∥2\n2 ≤1\n2\n\u0000εeff + η(∆eff −εeff)\n\u00012\n=: Dmax\ng\n.\n(50)\nSimilarly, for any b ∈Beff,\n∥pb −¯p∥2 ≥\n\f\f∥pb −p∗∥2 −∥p∗−¯p∥2\n\f\f\n≥∆eff −η\n\u0000∆eff −εeff\n\u0001\n,\n(51)\nand thus\nDb = 1\n2∥pb −¯p∥2\n2 ≥1\n2\n\u0000∆eff −η(∆eff −εeff)\n\u00012\n=: Dmin\nb\n.\n(52)\nDefine\nf(η) := Dmin\nb\n−Dmax\ng\nAt η = 0 we have\nf(0) = 1\n2\n\u0000∆2\neff −ε2\neff\n\u0001\n> 0\nsince ∆eff > εeff. The map η 7→f(η) is continu-\nous on [0, 1\n2), so there exists η0 ∈(0, 1\n2) such that\nf(η) > 0 for all η ∈[0, η0]. Lemma 1 guarantees\nthat η can be chosen in (0, 1\n2); by further shrinking\nη if necessary we may assume η ≤η0. Define\nγeff := f(η) > 0.\n(53)\nIt follows that, for all g ∈Geff and b ∈Beff,\nDb ≥Dmin\nb\n= Dmax\ng\n+ γeff ≥Dg + γeff,\nwhich proves (47).\nStep 2:\nExponential suppression and error\nbound. Define the remaining index set\nUeff := [K] \\\n\u0000Geff ∪Beff\n\u0001\n,\n33\n"}, {"page": 34, "text": "and the corresponding total weights\nWB :=\nX\nb∈Beff\nwb, WG :=\nX\ng∈Geff\nwg,\nWU :=\nX\nu∈Ueff\nwu,\n(54)\nso that WB + WG + WU = 1.\nLet\nA :=\nX\ng∈Geff\ne−βDg, B :=\nX\nb∈Beff\ne−βDb,\nC :=\nX\nu∈Ueff\ne−βDu, Z := A + B + C.\n(55)\nThen for every r ∈[K],\nwr = e−βDr\nZ\n,\nand\nWB = B\nZ .\nUsing (47), for any b ∈Beff and any g ∈Geff,\ne−βDb ≤e−β(Dg+γeff) = e−βγeff e−βDg.\nTaking min over g and summing over b gives\nB ≤|Beff| e−βγeff min\ng∈Geff e−βDg\n(56)\n≤|Beff| e−βγeff\n1\n|Geff|\nX\ng∈Geff\ne−βDg\n(57)\n= |Beff|\n|Geff|e−βγeff A,\n(58)\nand thus\nR := B\nA ≤|Beff|\n|Geff|e−βγeff.\nSince |Geff| ≥ρeffK and |Beff| ≤K −|Geff| ≤\n(1 −ρeff)K, we obtain\nR ≤1 −ρeff\nρeff\ne−βγeff.\nMoreover, because Z ≥A + B,\nWB = B\nZ ≤\nB\nA + B =\nR\n1 + R ≤R,\nso\nWB ≤1 −ρeff\nρeff\ne−βγeff.\nFinally,\n∥q −p∗∥2 =\n\r\r\r\nK\nX\nr=1\nwr(pr −p∗)\n\r\r\r\n2\n≤\nK\nX\nr=1\nwr∥pr −p∗∥2\n≤εeff\nX\ng∈Geff\nwg + ∆max\nX\nr/∈Geff\nwr\n= εeffWG + ∆max(WB + WU), (59)\nwhere ∆max := max1≤r≤K ∥pr −p∗∥2 ≤\n√\n2 for\ndistributions on the simplex.\nUsing WG = 1 −WB −WU, (59) implies\n∥q −p∗∥2 ≤εeff(1 −WB −WU)+\n∆max(WB + WU)\n= εeff + (∆max −εeff)(WB + WU)\n≤εeff + (∆max −εeff)WU+\n(∆max −εeff)1 −ρeff\nρeff\ne−βγeff.\n(60)\nDefining the residual term\nCU := (∆max −εeff)WU\n(≤∆max −εeff),\nwe can rewrite (60) in the same final form as\n∥q−p∗∥2 ≤εeff+CU+(∆max−εeff)1 −ρeff\nρeff\ne−βγeff.\nG.4\nEffect of the Margin Term as a Bounded\nPerturbation\nWe now return to the full weighting scheme, which\nincludes a margin-based confidence term Cr ∈\n[0, 1]:\nsr = λCr −βDr,\nwr ∝exp(sr).\n(61)\nSince Cr ∈[0, 1], the margin term perturbs each\nlog-weight by at most λ:\n−βDr ≤sr ≤−βDr + λ ⇒\ne−βDr ≤esr ≤eλe−βDr.\n(62)\nCorollary 1 (Robustness with margin-based con-\nfidence). Under the high-probability event of\nLemma 1, consider the full weighting scheme\nwr ∝exp\n\u0000λCr −βDr\n\u0001\n,\nCr ∈[0, 1],\nDr = 1\n2∥pr −¯p∥2\n2.\n(63)\nLet Ueff := [K] \\ (Geff ∪Beff) and\nWU :=\nX\nu∈Ueff\nwu.\nLet ∆max := max1≤r≤K ∥pr −p∗∥2 (for distribu-\ntions on the simplex, ∆max ≤\n√\n2). Then, for any\nβ > 0,\n∥q−p∗∥2 ≤εeff + (∆max −εeff)WU+\n(∆max −εeff)1 −ρeff\nρeff\nexp\n\u0000−βγeff + λ\n\u0001\n.\n(64)\nIn particular, as long as βγeff > λ, the influence\nof Beff is exponentially suppressed (up to constant\nfactors).\n34\n"}, {"page": 35, "text": "Proof. Let wr be the full weights with sr = λCr −\nβDr. Define the (unnormalized) sums\nAs :=\nX\ng∈Geff\nesg,\nBs :=\nX\nb∈Beff\nesb,\nCs :=\nX\nu∈Ueff\nesu,\nZs := As + Bs + Cs. (65)\nThen wr = esr/Zs and WB := P\nb∈Beff wb =\nBs/Zs. For any b ∈Beff and g ∈Geff, using\nCb ≤1, Cg ≥0 and (47),\nsb −sg = λ(Cb −Cg)−β(Db −Dg) ≤λ−βγeff,\nhence\nesb ≤exp\n\u0000−βγeff + λ\n\u0001\nesg.\nTaking min over g and summing over b yields\nBs ≤|Beff| exp\n\u0000−βγeff + λ\n\u0001\nmin\ng∈Geff esg\n≤|Beff|\n|Geff| exp\n\u0000−βγeff + λ\n\u0001 X\ng∈Geff\nesg\n= |Beff|\n|Geff| exp\n\u0000−βγeff + λ\n\u0001\nAs.\n(66)\nTherefore, with Rs := Bs/As,\nRs ≤|Beff|\n|Geff| exp\n\u0000−βγeff + λ\n\u0001\n≤1 −ρeff\nρeff\nexp\n\u0000−βγeff + λ\n\u0001\n,\n(67)\nwhere we used |Geff| ≥ρeffK and |Beff| ≤K −\n|Geff| ≤(1 −ρeff)K. Moreover, since Zs ≥As +\nBs,\nWB = Bs\nZs\n≤\nBs\nAs + Bs\n=\nRs\n1 + Rs\n≤Rs\n≤1 −ρeff\nρeff\nexp\n\u0000−βγeff + λ\n\u0001\n.\n(68)\nFinally, define\nWG :=\nX\ng∈Geff\nwg,\nWU :=\nX\nu∈Ueff\nwu,\nso WG + WB + WU = 1. By the same triangle-\ninequality argument as in the robust-aggregation\nproof,\n∥q −p∗∥2 ≤εeffWG + ∆max(WB + WU)\n= εeff + (∆max −εeff)(WB + WU).\n(69)\nPlugging in the bound on WB gives (64).\nH\nHuman Annotation and Ethical\nConsiderations\nThis appendix reports the human-in-the-loop proce-\ndures used in our study. All human involvement in\nthis work concerns expert evaluation and revision\nof model-generated drafts, and does not involve\nany new patient data collection.\nH.1\nInstructions Given to Participants\nH.1.1\nQuality Assessment of\nModel-Generated Drafts\nWe ask dermatology experts to review a 900-case\ncore set and rate the quality of Gemini-generated\ninitial drafts.\nInstruction. Please review the provided derma-\ntology image and the corresponding AI-generated\nreport. Using a 0–5 Likert scale, rate the following\ntwo dimensions:\n• Morphological Fidelity: Are the described\nclinical features (e.g., color, border, lesion\ntype) fully consistent with the visual evidence\nin the image?\n• Reasoning Validity: Is the chain-of-thought\nreasoning logically sound and properly\ngrounded in visual evidence from the image?\nScore definition. 5 indicates fully accurate and\nlogically rigorous; 0 indicates severe errors such as\nmajor misdiagnosis or hallucinated features.\nH.1.2\nGold Standard Manual Revision for the\nCore Set\nExperts revise model-generated drafts using a dedi-\ncated web interface.\nInstruction. The text box contains an AI-generated\ndraft. Please perform the following:\n1. Line-by-line revision: Compare against the\noriginal image and manually correct terminol-\nogy errors, missing key features, or reasoning\ngaps.\n2. Bottleneck verification:\nEnsure the re-\nvised <morph> JSON strictly follows the\nDerm7pt/SkinCon schema.\n3. Final approval: The revised content should\nrepresent the clinical gold-standard answer\nfor this case.\n35\n"}, {"page": 36, "text": "Figure 7: An example of web interface used to get .\nH.1.3\nHuman Sanity Check for\nLLM-as-a-Judge\nFor 20 randomly sampled cases, experts evaluate\nwhether the Judge (Gemini-2.5-Pro) provides rea-\nsonable scores and feedback.\nInstruction. Please review the model output, ref-\nerence answer, and the AI Judge’s score and feed-\nback.\n• Task: Rate (0–5) whether the AI Judge’s eval-\nuation is reasonable.\n• Reasonableness criteria: The score should\nbe objective, and the feedback should point\nout key medical differences.\n• Acceptance threshold: Scores ≥3 are con-\nsidered acceptable.\nH.1.4\nHuman Performance Baseline\nTo obtain the “Human Performance” results, we\nrandomly sample 100 cases per task and ask ex-\nperts to complete the benchmark without any AI\nassistance.\nInstruction. Please independently complete Der-\nmoBench evaluation tasks as in clinical practice,\nwithout referencing any AI hints:\n1. MCQA tasks: Select the most likely diagno-\nsis from 4-choice or 25-choice options.\n2. Hierarchical diagnosis: Perform step-wise\nselection along the diagnosis tree path (Super-\nclass →Subclass).\n3. Open-ended description: Write a detailed\nmorphological examination report without\nviewing any reference answer.\nH.2\nRecruitment, Compensation, and\nConsent\nRecruitment and qualifications. We invited and\nengaged two dermatology clinicians via targeted\nonline outreach. Both participants have relevant\nclinical experience in dermatology.\nCompensation. Participants were compensated\nat approximately 100 RMB per hour, following\nlocal norms for medical professional consulting,\nwhich we consider adequate to reflect the value of\nexpert labor.\nAnnotator consent. All participating clinicians\nsigned an agreement acknowledging that their revi-\nsion, annotation, and rating outputs would be used\nfor open research purposes in developing and eval-\nuating our dermatology MLLMs and benchmark.\nH.3\nData Consent, Release Policy, and Ethics\nReview\nOpen datasets and intended use.\nThis work\nuses only publicly released, de-identified derma-\ntology datasets. We follow the licenses and in-\ntended research use specified by the original dataset\nproviders. Experts may view the original images\nduring evaluation and revision; however, we do not\nredistribute or release the original images. We\nrelease only derived artifacts (e.g., prompts, anno-\ntations, benchmark splits, and evaluation outputs),\nand users should obtain images from the original\nsources.\nEthics review. We do not collect any new pa-\ntient data and only use de-identified, publicly avail-\nable datasets; the expert annotation activities are\nminimal-risk. Therefore, ethics board approval was\nnot required under our institutional policy.\nI\nVisualization\nThe following pictures provide additional visual-\nizations and qualitative case studies to better under-\nstand the data characteristics of DermoBench.\n36\n"}, {"page": 37, "text": "Task 1.1       Detailed Description\nGT: The dermoscopic image displays a centrally located, reddish-brown lesion with a relatively \nuniform, diffuse pigmentation spread throughout its body. The lesion exhibits an overall oval shape \nwith borders that are somewhat ill-defined yet appear regular. A distinct pigment network is absent. \nNo definite vascular structures are identified; the reddish hue appears as structureless \npigmentation. No blue-whitish veil is present. There are no radiating streaks or distinct dots and \nglobules of pigment. Furthermore, no regression structures, such as blue or white areas, are \nidentified.\nQ:Summarize all important \nmorphological features visible in \nthis image.\nGemini 2.5 Flash:\nBased on the provided dermoscopic images, here is a summary of the important morphological \nfeatures of the skin lesion:\\n\\n*   **Overall Structure and Symmetry:** The lesion is relatively \nsymmetrical in its round-to-oval shape but shows asymmetry in its internal structures and color \ndistribution.\\n*   **Borders:** The borders are ill-defined and fuzzy, gradually fading into the \nsurrounding skin rather than having a sharp, distinct edge.\\n*   **Color:** The lesion is multicolored \n(polychromatic), exhibiting shades of light brown, dark brown, and a prominent reddish-pink hue \nthroughout.\\n*   **Central Features:**\\n    *   **Blotch:** There is a central, darker, structureless blotch \nthat is dark brown to reddish.\\n    *   **Regression Structures:** Shiny white lines (also known as \nchrysalis structures or crystalline structures) are visible in the central area, which are signs of fibrosis \nor regression.\\n*   **Pigment Network:** A faint, atypical, and disorganized pigment network can be \nobserved, particularly towards the periphery.\\n*   **Vascular Pattern:** A diffuse reddish \\\"blush\\\" or \nerythema is present across the lesion, indicating a significant vascular component, though specific \nvessel patterns are not clearly defined.\\n\\nIn summary, the key features are the multicomponent \npattern with structural and color asymmetry, ill-defined borders, multiple colors including a \nprominent red hue, a central blotch, and signs of regression (shiny white lines).\nLLM-as-a-Judge:\n{\"score\":{\"final_overall\":8.8,\"rubric\":{\"accuracy\":0.42,\"completeness\":0.29,\"consistency\":0.42},\"counts\n\":{\"supported\":5,\"partial\":0,\"contradicted\":7,\"missing\":5,\"vague\":0,\"extra_incorrect\":0,\"total_ref_claim\ns\":17},\"short_feedback\":\"The candidate description directly contradicts the reference on multiple key \ndermoscopic features, including color, symmetry, pigment network, and regression structures. It \nalso invents findings (e.g., shiny white lines) not present in the reference text.\"}}\nLingshu-32B:\nThe image shows a close-up view of a skin lesion. The lesion appears to be a small, reddish area on \nthe skin, surrounded by fine hairs. The lesion has a slightly raised, irregular shape and appears to be \ninflamed or irritated. The surrounding skin appears to be relatively normal, with no other visible \nabnormalities.\nLLM-as-a-Judge:\n{\"score\":{\"final_overall\":0.0,\"rubric\":{\"accuracy\":0.2,\"completeness\":0.1,\"consistency\":0.3},\"counts\":{\"\nsupported\":0,\"partial\":1,\"contradicted\":2,\"missing\":14,\"vague\":1,\"extra_incorrect\":2,\"total_ref_claims\":\n18},\"short_feedback\":\"The candidate description is extremely superficial, missing all specific \ndermoscopic features. It contradicts the reference on shape and border regularity and invents \nfindings like elevation and inflammation, resulting in a score of zero.\"}\n \nFigure 8: Case study.\n37\n"}, {"page": 38, "text": "Task 1.1       Detailed Description\nGT: The dermoscopic image displays a centrally located, reddish-brown lesion with a relatively \nuniform, diffuse pigmentation spread throughout its body. The lesion exhibits an overall oval shape \nwith borders that are somewhat ill-defined yet appear regular. A distinct pigment network is absent. \nNo definite vascular structures are identified; the reddish hue appears as structureless \npigmentation. No blue-whitish veil is present. There are no radiating streaks or distinct dots and \nglobules of pigment. Furthermore, no regression structures, such as blue or white areas, are \nidentified.\nQ:Summarize all important \nmorphological features visible in \nthis image.\nDermoGPT-RL:\nDermoscopy reveals a relatively symmetrical, round to oval lesion with a predominantly reddish-\nbrown coloration. The pigmentation is diffuse and appears largely regular throughout the lesion, \nwithout significant areas of darker blotches or lighter patches. A distinct pigment network is not \nobserved. There is no evidence of a blue-whitish veil. While the lesion has a reddish hue, no specific \nvascular structures such as arborizing, comma, hairpin, wreath, dotted, or linear irregular vessels are \nclearly identifiable. The lesion lacks any radiating streaks or pseudopods at its periphery. \nFurthermore, no discrete dots or globules are present within the lesion. There are no signs of \nregression, such as blue areas or white scar-like areas.\nLLM-as-a-Judge:\n{\"score\":{\"final_overall\":88.2,\"rubric\":{\"accuracy\":1.0,\"completeness\":0.941,\"consistency\":1.0},\"counts\":\n{\"supported\":14,\"partial\":2,\"contradicted\":0,\"missing\":1,\"vague\":0,\"extra_incorrect\":0,\"total_ref_claims\n\":17},\"short_feedback\":\"Excellent accuracy and consistency. The candidate is slightly verbose but \ncaptures nearly all key features. The only missing detail is the 'ill-defined' nature of the borders, a \nminor omission in an otherwise comprehensive description.\"}}\nFigure 9: Case study.\n38\n"}, {"page": 39, "text": "Task 1.2      Morph-grounded Description\nGT: <morph>\\n{\\n  \\\"morphological_features_Derm7pt\\\": {\\n    \\\"pigment_network\\\": \\\"absent\\\",\\n    \n\\\"blue_whitish_veil\\\": \\\"absent\\\",\\n    \\\"vascular_structures\\\": \\\"linear irregular\\\",\\n    \\\"pigmentation\\\": \n\\\"diffuse irregular\\\",\\n    \\\"streaks\\\": \\\"absent\\\",\\n    \\\"dots_and_globules\\\": \\\"absent\\\",\\n    \n\\\"regression_structures\\\": \\\"absent\\\"\\n  }\\n}\\n</morph>\\n\\nDermoscopy of this skin area reveals a \nbroad, ill-defined lesion with diffuse and irregular pigmentation, primarily consisting of light brown \nand yellowish-brown patches that blend into the surrounding skin without clear demarcation. A \npigment network is not distinctly discernible within this variegated background. Numerous fine, \nlinear irregular vascular structures are observed, distributed somewhat haphazardly across the \nlesion, contributing to a subtle background erythema. There is no evidence of blue-whitish veil, \nstreaks, or distinct dots and globules that would classify as regular or irregular. Furthermore, no \nregression structures, such as blue areas or white areas, are present.\nQ:Describe the lesion based on the 7-point checklist \n(pigment network, blue-whitish veil, vascular \nstructures, pigmentation, streaks, dots/globules, and \nregression structures).\\n\\nBefore any reasoning, first \noutput a <morph> JSON using the Derm7pt schema, \nthen provide exactly ONE detailed paragraph.\",\n      \nGemini 2.5 Flash:\n<morph>\\n{\\n  \\\"morphological_features_Derm7pt\\\": {\\n    \\\"pigment_network\\\": \\\"atypical\\\",\\n    \n\\\"blue_whitish_veil\\\": \\\"absent\\\",\\n    \\\"vascular_structures\\\": \\\"linear irregular\\\",\\n    \\\"pigmentation\\\": \n\\\"diffuse irregular\\\",\\n    \\\"streaks\\\": \\\"absent\\\",\\n    \\\"dots_and_globules\\\": \\\"irregular\\\",\\n    \n\\\"regression_structures\\\": \\\"white areas\\\"\\n  }\\n}\\n\\nThis lesion is characterized by diffuse irregular \npigmentation, with blotchy areas of tan and light brown coloration distributed unevenly over a \npinkish background. A faint and focally present atypical pigment network is visible, appearing as \nbroad and interrupted lines. The vascular pattern consists of multiple fine, short, linear irregular \nvessels scattered throughout the lesion. No blue-whitish veil or peripheral streaks are observed.\nLLM-as-a-Judge:\n{\"score\":{\"final_overall\":39.85,\"rubric\":{\"accuracy\":0.7,\"completeness\":0.47,\"consistency\":1.0},\"counts\":\n{\"supported\":7,\"partial\":0,\"contradicted\":3,\"missing\":5,\"vague\":0,\"extra_incorrect\":0,\"total_ref_claims\":\n15},\"short_feedback\":\"The candidate narrative correctly identifies several features but contradicts \nthe reference on key findings like pigment network, dots/globules, and regression. It also misses \ndescribing the lesion's broad, ill-defined nature.\"}\nLingshu-32B:\n<morph>\\n{\\n  \\\"morphological_features_Derm7pt\\\": {\\n    \\\"pigment_network\\\": \\\"absent\\\",\\n    \n\\\"blue_whitish_veil\\\": \\\"absent\\\",\\n    \\\"vascular_structures\\\": \\\"absent\\\",\\n    \\\"pigmentation\\\": \n\\\"absent\\\",\\n    \\\"streaks\\\": \\\"absent\\\",\\n    \\\"dots_and_globules\\\": \\\"absent\\\",\\n    \n\\\"regression_structures\\\": \\\"absent\\\"\\n  }\\n}\\n</morph>\\n\\nThe dermoscopic image shows a lesion \nwith no discernible pigment network, indicating an absence of the typical interconnecting lines of \npigment. There is no visible blue-whitish veil, which would have appeared as a whitish or bluish haze \nover the lesion. The vascular structures are not present, meaning there are no visible blood vessels \nor vascular patterns.  The dots and globules are absent, indicating no small, round structures of \npigment. Lastly, there are no regression structures, such as blue or white areas, which would \nindicate areas of regression within the lesion. \nLLM-as-a-Judge:\n{\"score\":{\"final_overall\":42.15,\"rubric\":{\"accuracy\":0.45,\"completeness\":0.33,\"consistency\":1.0},\"count\ns\":{\"supported\":5,\"partial\":0,\"contradicted\":6,\"missing\":4,\"vague\":0,\"extra_incorrect\":0,\"total_ref_clai\nms\":15},\"short_feedback\":\"The candidate correctly identifies the absence of several features but \nseverely mischaracterizes the lesion by stating pigmentation and vascular structures are absent.\"}\nFigure 10: Case study.\n39\n"}, {"page": 40, "text": "Task 1.2       Morph-grounded Description\nGT: <morph>\\n{\\n  \\\"morphological_features_Derm7pt\\\": {\\n    \\\"pigment_network\\\": \\\"absent\\\",\\n    \n\\\"blue_whitish_veil\\\": \\\"absent\\\",\\n    \\\"vascular_structures\\\": \\\"linear irregular\\\",\\n    \\\"pigmentation\\\": \n\\\"diffuse irregular\\\",\\n    \\\"streaks\\\": \\\"absent\\\",\\n    \\\"dots_and_globules\\\": \\\"absent\\\",\\n    \n\\\"regression_structures\\\": \\\"absent\\\"\\n  }\\n}\\n</morph>\\n\\nDermoscopy of this skin area reveals a \nbroad, ill-defined lesion with diffuse and irregular pigmentation, primarily consisting of light brown \nand yellowish-brown patches that blend into the surrounding skin without clear demarcation. A \npigment network is not distinctly discernible within this variegated background. Numerous fine, \nlinear irregular vascular structures are observed, distributed somewhat haphazardly across the \nlesion, contributing to a subtle background erythema. There is no evidence of blue-whitish veil, \nstreaks, or distinct dots and globules that would classify as regular or irregular. Furthermore, no \nregression structures, such as blue areas or white areas, are present.\nQ:Describe the lesion based on the 7-point checklist \n(pigment network, blue-whitish veil, vascular \nstructures, pigmentation, streaks, dots/globules, and \nregression structures).\\n\\nBefore any reasoning, first \noutput a <morph> JSON using the Derm7pt schema, \nthen provide exactly ONE detailed paragraph.\",\n      \nDermoGPT-RL:\n<morph>\\n{\\n  \\\"morphological_features_Derm7pt\\\": {\\n    \\\"Pigment Network\\\": \\\"absent\\\",\\n    \\\"Blue \nWhitish Veil\\\": \\\"absent\\\",\\n    \\\"Vascular Structures\\\": \\\"linear irregular\\\",\\n    \\\"Pigmentation\\\": \\\"diffuse \nirregular\\\",\\n    \\\"Streaks\\\": \\\"absent\\\",\\n    \\\"Dots and Globules\\\": \\\"absent\\\",\\n    \\\"Regression Structures\\\": \n\\\"absent\\\"\\n  }\\n}\\n</morph>\\n\\nDermoscopy reveals a large, ill-defined lesion characterized by a \nvariegated appearance with areas of light brown, yellowish-brown, and pinkish-red discoloration. The \npigmentation is diffuse and irregular, lacking a clear, organized pattern. A distinct pigment network is \nabsent. There is no evidence of a blue-whitish veil. Fine, somewhat tortuous, and irregularly \ndistributed linear vessels are visible, particularly within the pinkish-red areas, classifying them as \n'linear irregular' vascular structures. No streaks or pseudopods are observed. Discrete dots or \nglobules are not a prominent feature, and no regression structures such as blue or white areas are \npresent. The lesion exhibits asymmetry in its color distribution and overall morphology.\nLLM-as-a-Judge:\n{\"score\":{\"final_overall\":98.1,\"rubric\":{\"accuracy\":1.0,\"completeness\":0.96,\"consistency\":1.0},\"counts\":{\"\nsupported\":12,\"partial\":1,\"contradicted\":0,\"missing\":0,\"vague\":0,\"extra_incorrect\":0,\"total_ref_claims\":\n13},\"short_feedback\":\"Excellent narrative that accurately supports almost all reference claims. It \ncorrectly identifies all key dermoscopic features and their absence. The description of background \nerythema is slightly less direct but implied.\"}\nFigure 11: Case study.\n40\n"}, {"page": 41, "text": "Task 3.1      CoT Reasoning\nGT: <reasoning>Upon examination, the lesion presents with a largely homogeneous reddish-brown \ncoloration, which is a reassuring feature, as significant color variegation is absent. While the \nborders appear somewhat ill-defined and diffuse, gradually fading into the perilesional skin, they \nlack the sharp irregularities, notching, or sharp demarcations that would be concerning for \nmalignancy. There is no atypical pigment network, streaks, or blue-white veil visible. The overall \nuniform pigment distribution, despite the somewhat irregular contour, supports a benign \ndiagnosis.</reasoning><final_diagnosis>Benign Lesion</final_diagnosis> \nQ:Based on the provided image, what is the most \nlikely diagnosis? Please provide a detailed reasoning \nprocess before giving the final answer.      \nGemini 2.5 Flash:\n<reasoning>\\n1. The dermoscopic image displays a solitary, flat (macular) pigmented lesion on hair-\nbearing skin.\\n2. The lesion is markedly asymmetric in both shape and color. The borders are ill-\ndefined and fade into the surrounding skin, particularly on the left side.\\n3. The color is \nheterogeneous, with shades ranging from light tan to dark brown. There is a darker, more \ndisorganized area in the center-right portion of the lesion.\\n4. A subtle, disorganized, and atypical \npigment network is present. More importantly, there are signs of asymmetric pigmentation around \nthe hair follicle openings (asymmetric follicular openings), a key feature of this diagnosis.\\n5. The \ncombination of asymmetry, ill-defined borders, color variegation, and specific dermoscopic patterns \nlike asymmetric follicular openings, especially on what appears to be sun-exposed skin, is highly \nindicative of a melanoma in situ on sun-damaged skin.</reasoning>\\n<final_diagnosis>\\nLentigo \nmaligna\\n</final_diagnosis>\nLLM-as-a-Judge:\n{\"score\":{\"final_overall\":5.0,\"rubric\":{\"reasoning_alignment\":0.0,\"diagnosis_similarity\":10.0,\"internal_c\nonsistency\":100.0},\"counts\":{\"supported\":1,\"partial\":0,\"contradicted\":5,\"missing\":3,\"vague\":0,\"extra_in\ncorrect\":2,\"total_ref_claims\":9},\"short_feedback\":\"The reasoning directly contradicts the ground \ntruth on multiple key features, such as color and pigment network, leading to an incorrect diagnosis \nof malignancy instead of a benign lesion. The candidate's findings are internally consistent. \"}\nLingshu-32B:\n<reasoning>The image shows a close-up view of a skin lesion with a brownish color and irregular \nshape. The lesion appears to have a slightly raised surface and is surrounded by hair follicles. The \nirregular pigmentation and asymmetry are notable features. These characteristics are commonly \nassociated with melanocytic lesions, such as melanoma. The irregular shape and uneven color \ndistribution are key indicators that differentiate melanoma from benign lesions like nevi. \nConsidering the visual cues, the lesion's asymmetry, irregular borders, and uneven coloration \nstrongly suggest a diagnosis of melanoma. Other differential diagnoses, such as seborrheic \nkeratosis or lentigo, are less likely due to the lack of typical features such as a waxy appearance or \nuniform pigmentation.</reasoning>\\n<final_diagnosis>Melanoma</final_diagnosis>\nLLM-as-a-Judge:\n{\"score\":{\"final_overall\":35.0,\"rubric\":{\"reasoning_alignment\":0.0,\"diagnosis_similarity\":70.0,\"internal\n_consistency\":1.0},\"counts\":{\"supported\":0,\"partial\":1,\"contradicted\":5,\"missing\":3,\"vague\":0,\"extra_in\ncorrect\":2,\"total_ref_claims\":9},\"short_feedback\":\"The candidate's reasoning directly contradicts the \nground truth's description of a benign lesion, incorrectly identifying features of malignancy \n(irregular color/borders).\"}\nFigure 12: Case study.\n41\n"}, {"page": 42, "text": "Task 3.1      CoT Reasoning\nGT: <reasoning>Upon examination, the lesion presents with a largely homogeneous reddish-brown \ncoloration, which is a reassuring feature, as significant color variegation is absent. While the \nborders appear somewhat ill-defined and diffuse, gradually fading into the perilesional skin, they \nlack the sharp irregularities, notching, or sharp demarcations that would be concerning for \nmalignancy. There is no atypical pigment network, streaks, or blue-white veil visible. The overall \nuniform pigment distribution, despite the somewhat irregular contour, supports a benign \ndiagnosis.</reasoning><final_diagnosis>Benign Lesion</final_diagnosis> \nQ:Based on the provided image, what is the most \nlikely diagnosis? Please provide a detailed reasoning \nprocess before giving the final answer.      \nDermoGPT-RL:\n<morph>\\n{\\n  \\\"morphological_features_Derm7pt\\\": {\\n    \\\"Pigment Network\\\": \\\"absent\\\",\\n    \\\"Blue \nWhitish Veil\\\": \\\"absent\\\",\\n    \\\"Vascular Structures\\\": \\\"linear irregular\\\",\\n    \\\"Pigmentation\\\": \\\"diffuse \nirregular\\\",\\n    \\\"Streaks\\\": \\\"absent\\\",\\n    \\\"Dots and Globules\\\": \\\"absent\\\",\\n    \\\"Regression Structures\\\": \n\\\"absent\\\"\\n  }\\n}\\n</morph>\\n\\nDermoscopy reveals a large, ill-defined lesion characterized by a \nvariegated appearance with areas of light brown, yellowish-brown, and pinkish-red discoloration. The \npigmentation is diffuse and irregular, lacking a clear, organized pattern. A distinct pigment network is \nabsent. There is no evidence of a blue-whitish veil. Fine, somewhat tortuous, and irregularly \ndistributed linear vessels are visible, particularly within the pinkish-red areas, classifying them as \n'linear irregular' vascular structures. No streaks or pseudopods are observed. Discrete dots or \nglobules are not a prominent feature, and no regression structures such as blue or white areas are \npresent. The lesion exhibits asymmetry in its color distribution and overall morphology.\nLLM-as-a-Judge:\n{\"score\":{\"final_overall\":98.1,\"rubric\":{\"accuracy\":1.0,\"completeness\":0.96,\"consistency\":1.0},\"counts\":{\"\nsupported\":12,\"partial\":1,\"contradicted\":0,\"missing\":0,\"vague\":0,\"extra_incorrect\":0,\"total_ref_claims\":\n13},\"short_feedback\":\"Excellent narrative that accurately supports almost all reference claims. It \ncorrectly identifies all key dermoscopic features and their absence. The description of background \nerythema is slightly less direct but implied.\"}\nFigure 13: Case study.\n42\n"}, {"page": 43, "text": "Task 3.2      Morph-Grounded Reasoning\nGT: <reasoning>Upon visual assessment, the lesion presents as a very subtle, flat macule. Its \nprimary characteristic is the faint, homogeneous yellowish-brown coloration which is barely \ndiscernible from the surrounding skin. Crucially, the borders of this pigmented area are \nexceedingly ill-defined, blending imperceptibly into the normal skin without any sharp demarcation, \nnotching, or irregular extensions. There is no evidence of asymmetry in shape or color distribution, \nnor any suspicious structures or textures suggesting an atypical melanocytic proliferation or other \nmalignancy. The absence of variegated colors, atypical pigment network, dots, globules, streaks, or \nulceration, combined with the flat, faint, and ill-defined appearance, strongly supports a benign \ndiagnosis.</reasoning>\\n<morph>\\n{\\n  \\\"morphological_features_Derm7pt\\\": {\\n    \n\\\"pigment_network\\\": \\\"typical\\\",\\n    \\\"blue_whitish_veil\\\": \\\"absent\\\",\\n    \\\"vascular_structures\\\": \n\\\"absent\\\",\\n    \\\"pigmentation\\\": \\\"localized regular\\\",\\n    \\\"streaks\\\": \\\"absent\\\",\\n    \n\\\"dots_and_globules\\\": \\\"absent\\\",\\n    \\\"regression_structures\\\": \n\\\"absent\\\"\\n  }\\n}\\n</morph>\\n<final_diagnosis>Benign Lesion</final_diagnosis>\"\nQ:Analyze the clinical presentation in this image. What is your differential \ndiagnosis, and what is the final conclusion? Explain your reasoning.\\n\\nThen \noutput EXACTLY three blocks in this order and nothing \nelse:\\n<reasoning>your step-by-step, image-grounded \nreasoning</reasoning>\\n<morph>{STRICT JSON using the Derm7pt schema; \nexactly one value per field; valid JSON}</morph>\\n<final_diagnosis>ONE \nlabel from our taxonomy</final_diagnosis>\",\n            \nGemini 2.5 Flash:\n<reasoning>\\nThe dermoscopic image reveals a flat, poorly demarcated macule with a focal area of \nlight brown pigmentation.\\n1.  **Pigment Network**: A subtle, delicate pigment network is visible in \nthe central pigmented area. This network is considered atypical because it is disorganized, with lines \nof varying thickness and irregularly sized and shaped holes. It is not the uniform, honeycomb pattern \nof a typical network.\\n2.  **Pigmentation**: The pigmentation is localized to one part of the lesion and \nis irregular in its distribution and shade, varying from tan to light brown.\\n3.  **Other Structures**: \nThere is a lack of other significant dermoscopic features. Specifically, there is no blue-whitish veil, no \nrecognizable vascular structures (like arborizing or dotted vessels), no streaks at the periphery, no \nprominent dots or globules, and no signs of regression (like white scar-like areas or blue-gray \ngranules).\\n4.  **Conclusion**: The key finding is the atypical pigment network within an irregularly \npigmented flat lesion. This combination is a major criterion for malignancy and is highly suspicious for \nmelanoma, particularly the lentigo maligna subtype, which often presents as a subtle, flat macule on \nsun-damaged skin.\\n</reasoning>\\n<morph>\\n{\\n  \\\"morphological_features_Derm7pt\\\": {\\n    \n\\\"pigment_network\\\": \\\"atypical\\\",\\n    \\\"blue_whitish_veil\\\": \\\"absent\\\",\\n    \\\"vascular_structures\\\": \n\\\"absent\\\",\\n    \\\"pigmentation\\\": \\\"localized irregular\\\",\\n    \\\"streaks\\\": \\\"absent\\\",\\n    \n\\\"dots_and_globules\\\": \\\"absent\\\",\\n    \\\"regression_structures\\\": \n\\\"absent\\\"\\n  }\\n}\\n</morph>\\n<final_diagnosis>melanoma</final_diagnosis>\nLLM-as-a-Judge:\n{\"score\":{\"final_overall\":43.05,\"rubric\":{\"reasoning_alignment\":7.3,\"diagnosis_similarity\":50.0,\"internal\n_consistency\":100.0},\"counts\":{\"supported\":5,\"partial\":0,\"contradicted\":6,\"missing\":0,\"vague\":0,\"extra\n_incorrect\":0,\"total_ref_claims\":11},\"short_feedback\":\"The candidate's reasoning and morph features \nare internally consistent but directly contradict the reference's benign assessment. The core \ndisagreement on the pigment network and pigmentation leads to a completely different and \nincorrect final diagnosis of melanoma instead of a benign lesion.\"}\nFigure 14: Case study.\n43\n"}, {"page": 44, "text": "Task 3.2      Morph-Grounded Reasoning\nGT: <reasoning>Upon visual assessment, the lesion presents as a very subtle, flat macule. Its \nprimary characteristic is the faint, homogeneous yellowish-brown coloration which is barely \ndiscernible from the surrounding skin. Crucially, the borders of this pigmented area are \nexceedingly ill-defined, blending imperceptibly into the normal skin without any sharp demarcation, \nnotching, or irregular extensions. There is no evidence of asymmetry in shape or color distribution, \nnor any suspicious structures or textures suggesting an atypical melanocytic proliferation or other \nmalignancy. The absence of variegated colors, atypical pigment network, dots, globules, streaks, or \nulceration, combined with the flat, faint, and ill-defined appearance, strongly supports a benign \ndiagnosis.</reasoning>\\n<morph>\\n{\\n  \\\"morphological_features_Derm7pt\\\": {\\n    \n\\\"pigment_network\\\": \\\"typical\\\",\\n    \\\"blue_whitish_veil\\\": \\\"absent\\\",\\n    \\\"vascular_structures\\\": \n\\\"absent\\\",\\n    \\\"pigmentation\\\": \\\"localized regular\\\",\\n    \\\"streaks\\\": \\\"absent\\\",\\n    \n\\\"dots_and_globules\\\": \\\"absent\\\",\\n    \\\"regression_structures\\\": \n\\\"absent\\\"\\n  }\\n}\\n</morph>\\n<final_diagnosis>Benign Lesion</final_diagnosis>\"\nQ:Analyze the clinical presentation in this image. What is your differential \ndiagnosis, and what is the final conclusion? Explain your reasoning.\\n\\nThen \noutput EXACTLY three blocks in this order and nothing \nelse:\\n<reasoning>your step-by-step, image-grounded \nreasoning</reasoning>\\n<morph>{STRICT JSON using the Derm7pt schema; \nexactly one value per field; valid JSON}</morph>\\n<final_diagnosis>ONE \nlabel from our taxonomy</final_diagnosis>\",\n            \nLingshu-32B:\n<reasoning>The image shows a light-colored lesion with a faint, slightly irregular pattern. There are \nno distinct vascular structures, pigment networks, or blue-whitish veils visible. The lesion appears to \nhave a diffuse, irregular pigmentation pattern, which is not typical of benign lesions. The absence of \nother significant features such as streaks, dots, or globules further supports the irregularity of the \nlesion. Given these observations, the differential diagnosis includes conditions such as melanoma, \nwhich often presents with irregular pigmentation and lacks distinct vascular structures. The final \nconclusion is that the lesion is indicative of melanoma due to its irregular pigmentation and lack of \nother benign features.</reasoning>\\n<morph>\\n{\\n  \\\"morphological_features_Derm7pt\\\": {\\n    \n\\\"pigment_network\\\": \\\"absent\\\",\\n    \\\"blue_whitish_veil\\\": \\\"absent\\\",\\n    \\\"vascular_structures\\\": \n\\\"absent\\\",\\n    \\\"pigmentation\\\": \\\"diffuse irregular\\\",\\n    \\\"streaks\\\": \\\"absent\\\",\\n    \n\\\"dots_and_globules\\\": \\\"absent\\\",\\n    \\\"regression_structures\\\": \n\\\"absent\\\"\\n  }\\n}\\n</morph>\\n<final_diagnosis>melanoma</final_diagnosis>\nLLM-as-a-Judge:\n{\"score\":{\"final_overall\":40.64,\"rubric\":{\"reasoning_alignment\":0.0,\"diagnosis_similarity\":50.0,\"internal\n_consistency\":100.0},\"counts\":{\"supported\":3,\"partial\":0,\"contradicted\":6,\"missing\":0,\"vague\":1,\"extra_\nincorrect\":0,\"total_ref_claims\":10},\"short_feedback\":\"The candidate correctly identified the absence \nof most dermoscopic structures but incorrectly interpreted the overall pattern as irregular and \nsuspicious. This led to a direct contradiction of the reference's benign assessment, resulting in an \nincorrect final diagnosis of melanoma.\"}\nFigure 15: Case study.\n44\n"}, {"page": 45, "text": "Task 3.2      Morph-Grounded Reasoning\nGT: <reasoning>Upon visual assessment, the lesion presents as a very subtle, flat macule. Its \nprimary characteristic is the faint, homogeneous yellowish-brown coloration which is barely \ndiscernible from the surrounding skin. Crucially, the borders of this pigmented area are \nexceedingly ill-defined, blending imperceptibly into the normal skin without any sharp demarcation, \nnotching, or irregular extensions. There is no evidence of asymmetry in shape or color distribution, \nnor any suspicious structures or textures suggesting an atypical melanocytic proliferation or other \nmalignancy. The absence of variegated colors, atypical pigment network, dots, globules, streaks, or \nulceration, combined with the flat, faint, and ill-defined appearance, strongly supports a benign \ndiagnosis.</reasoning>\\n<morph>\\n{\\n  \\\"morphological_features_Derm7pt\\\": {\\n    \n\\\"pigment_network\\\": \\\"typical\\\",\\n    \\\"blue_whitish_veil\\\": \\\"absent\\\",\\n    \\\"vascular_structures\\\": \n\\\"absent\\\",\\n    \\\"pigmentation\\\": \\\"localized regular\\\",\\n    \\\"streaks\\\": \\\"absent\\\",\\n    \n\\\"dots_and_globules\\\": \\\"absent\\\",\\n    \\\"regression_structures\\\": \n\\\"absent\\\"\\n  }\\n}\\n</morph>\\n<final_diagnosis>Benign Lesion</final_diagnosis>\"\nQ:Analyze the clinical presentation in this image. What is your differential \ndiagnosis, and what is the final conclusion? Explain your reasoning.\\n\\nThen \noutput EXACTLY three blocks in this order and nothing \nelse:\\n<reasoning>your step-by-step, image-grounded \nreasoning</reasoning>\\n<morph>{STRICT JSON using the Derm7pt schema; \nexactly one value per field; valid JSON}</morph>\\n<final_diagnosis>ONE \nlabel from our taxonomy</final_diagnosis>\",\n            \nDermoGPT-RL:\n<reasoning>Upon dermoscopic examination, the lesion presents as a macule with a predominantly \nyellowish-brown coloration. The pigmentation is largely homogeneous, lacking significant color \nvariegation or atypical pigment patterns. The borders are ill-defined and gradually fade into the \nsurrounding skin, which is a feature often associated with benign lesions such as solar lentigines or \nflat seborrheic keratoses. There is no evidence of asymmetry, atypical pigment network, streaks, \nblue-white veil, or other dermoscopic criteria suggestive of malignancy. The overall bland and \nuniform appearance, coupled with the ill-defined borders and yellowish-brown hue, strongly \nsupports a benign diagnosis.</reasoning>\\n<morph>\\n{\\n  \\\"morphological_features_Derm7pt\\\": {\\n    \n\\\"Pigment Network\\\": \\\"absent\\\",\\n    \\\"Blue Whitish Veil\\\": \\\"absent\\\",\\n    \\\"Vascular Structures\\\": \n\\\"absent\\\",\\n    \\\"Pigmentation\\\": \\\"localized irregular\\\",\\n    \\\"Streaks\\\": \\\"absent\\\",\\n    \\\"Dots and \nGlobules\\\": \\\"absent\\\",\\n    \\\"Regression Structures\\\": \n\\\"absent\\\"\\n  }\\n}\\n</morph>\\n<final_diagnosis>Benign Lesion</final_diagnosis>\nLLM-as-a-Judge:\n{\"score\":{\"final_overall\":82.45,\"rubric\":{\"reasoning_alignment\":76.7,\"diagnosis_similarity\":100.0,\"intern\nal_consistency\":100.0},\"counts\":{\"supported\":10,\"partial\":0,\"contradicted\":0,\"missing\":2,\"vague\":0,\"ext\nra_incorrect\":0,\"total_ref_claims\":12},\"short_feedback\":\"Excellent reasoning and correct final \ndiagnosis. The main area for improvement is the morph JSON, which contradicts the reference on \ntwo features (pigment network and pigmentation type), leading to a lower score in that section.\"}\nFigure 16: Case study.\n45\n"}]}