{"doc_id": "arxiv:2601.10951", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2601.10951.pdf", "meta": {"doc_id": "arxiv:2601.10951", "source": "arxiv", "arxiv_id": "2601.10951", "title": "Multi-Stage Patient Role-Playing Framework for Realistic Clinical Interactions", "authors": ["Shijie Jiang", "Zefan Zhang", "Kehua Zhu", "Tian Bai", "Ruihong Zhao"], "published": "2026-01-16T02:34:22Z", "updated": "2026-01-16T02:34:22Z", "summary": "The simulation of realistic clinical interactions plays a pivotal role in advancing clinical Large Language Models (LLMs) and supporting medical diagnostic education. Existing approaches and benchmarks rely on generic or LLM-generated dialogue data, which limits the authenticity and diversity of doctor-patient interactions. In this work, we propose the first Chinese patient simulation dataset (Ch-PatientSim), constructed from realistic clinical interaction scenarios to comprehensively evaluate the performance of models in emulating patient behavior. Patients are simulated based on a five-dimensional persona structure. To address issues of the persona class imbalance, a portion of the dataset is augmented using few-shot generation, followed by manual verification. We evaluate various state-of-the-art LLMs and find that most produce overly formal responses that lack individual personality. To address this limitation, we propose a training-free Multi-Stage Patient Role-Playing (MSPRP) framework, which decomposes interactions into three stages to ensure both personalization and realism in model responses. Experimental results demonstrate that our approach significantly improves model performance across multiple dimensions of patient simulation.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2601.10951v1", "url_pdf": "https://arxiv.org/pdf/2601.10951.pdf", "meta_path": "data/raw/arxiv/meta/2601.10951.json", "sha256": "fe2261a0d10c5e307b3c77c4fd7cad760b477e36bbb686a6b9ed691db08ef7e5", "status": "ok", "fetched_at": "2026-02-18T02:21:29.042892+00:00"}, "pages": [{"page": 1, "text": "Multi-Stage Patient Role-Playing Framework for\nRealistic Clinical Interactions\nShijie Jianga, Zefan Zhanga, Kehua Zhub, Tian Baia,∗, Ruihong Zhaoc,∗∗\naCollege of Computer Science and Technology, Key Laboratory of Symbolic Computation\nand Knowledge Engineering, Ministry of Education, Jilin University, Changchun 130012,\nChina\nbCollege of Software, Jilin University, Changchun 130012, China\ncGastrointestinal Endoscopy Center, The First Hospital of Jilin University, Changchun\n130012, China\nAbstract\nThe simulation of realistic clinical interactions plays a pivotal role in\nadvancing clinical Large Language Models (LLMs) and supporting medical\ndiagnostic education. Existing approaches and benchmarks rely on generic\nor LLM-generated dialogue data, which limits the authenticity and diversity\nof doctor-patient interactions. In this work, we propose the first Chinese\npatient simulation dataset (Ch-PatientSim), constructed from realistic clin-\nical interaction scenarios to comprehensively evaluate the performance of\nmodels in emulating patient behavior. Patients are simulated based on a\nfive-dimensional persona structure. To address issues of the persona class\nimbalance, a portion of the dataset is augmented using few-shot generation,\nfollowed by manual verification. We evaluate various state-of-the-art LLMs\nand find that most produce overly formal responses that lack individual per-\nsonality. To address this limitation, we propose a training-free Multi-Stage\nPatient Role-Playing (MSPRP) framework, which decomposes interactions\ninto three stages to ensure both personalization and realism in model re-\nsponses. Experimental results demonstrate that our approach significantly\nimproves model performance across multiple dimensions of patient simula-\ntion. Our dataset is available at https://github.com/SerajJon/MSPRP.\nKeywords:\nPatient Role-Playing, Large Language Models, Clinical\n∗Corresponding author: baitian@jlu.edu.cn (Tian Bai)\n∗∗Corresponding author: ruihongzhao8@jlu.edu.cn (Ruihong Zhao)\narXiv:2601.10951v1  [cs.CL]  16 Jan 2026\n"}, {"page": 2, "text": "Simulation\n1. Introduction\nThe rapid advancement of Large Language Models (LLMs) (Grattafiori\net al. (2024); Hurst et al. (2024); Team et al. (2024); Yang et al. (2025))\nhas attracted widespread attention due to their remarkable capabilities in\ncontextual understanding and semantic reasoning. Among their emerging\napplications, text-based Role-Playing Language Agents (RPLAs) stand out,\nenabling intelligent agents to emulate diverse personas and driving a wide\nrange of applications, from digital clones and AI chatbots to role-playing\ngames and social science research (Wang et al. (2024); Zhao et al. (2025)),\nhighlighting the growing integration of intelligent agents into daily life.\nIn the medical domain, role-playing in realistic clinical interactions is of\nparticular importance. Expert systems that simulate doctors can provide\nusers with extensive medical knowledge and diagnostic guidance, aiming to\nimprove accuracy in tasks such as disease diagnosis, triage recommendation,\nand treatment plan generation. Simulating patient roles is equally critical.\nPatient simulations not only enable the evaluation of LLMs’ diagnostic rea-\nsoning when acting as doctors but also support medical students in learning\nand assessing diagnostic skills within authentic clinical scenarios.\nRecent advances in Large Language Models enable realistic simulation\nof clinical workflows. AI Hospital (Fan et al. (2025)) evaluates LLM doc-\ntors on diagnostic accuracy, symptom collection, and test recommendations\nthrough multi-agent interactions with patients and examiners. EvoPatient\n(Du et al. (2025)) and the AIE/SAPS framework (Liao et al. (2024)) generate\nhigh-quality, multi-turn doctor–patient dialogues using standardized or real\nhospital cases, while PATIENTSIM (Kyung et al. (2025)) supports diverse\npatient types based on personality, language, and cognitive traits. These\nsystems collectively demonstrate the potential of multi-agent frameworks for\ntraining and evaluating LLMs in realistic clinical scenarios. Despite recent\nefforts to create patient simulation datasets, most existing resources rely on\nLLM-generated data. These datasets are limited in their ability to capture\nauthentic patient response styles, emotional expressions, and cognitive states,\nwhich restricts their applicability for advancing AI-assisted diagnostic tools\nand training, as the comparison shown in Figure 1.\nTo tackle the challenges outlined above, this study presents the first pa-\ntient simulation dataset built for authentic clinical dialogue scenarios. Fo-\n2\n"}, {"page": 3, "text": "Doctor\nOurs\nPatient\nPatientSim\n你哪里不舒服？\nWhat seems to be the trouble?\n就是最近老是拉肚子，大概有两周了吧，记不太清楚了。有\n时候还会觉得肚子有点胀气。这到底是怎么回事啊？\nIt's been constantly having diarrhea recently, probably for \nabout two weeks, though I'm not quite sure. Sometimes I \nalso feel a bit bloated. What's going on with this?\nPatient\nDoctor\n就是最近这一个多月，我一到饿的时候就感觉胸口烧烧的，有\n时候吃完饭也还是会有点烧心的感觉。这个毛病真是挺烦人的，\n之前都没注意这些，现在弄得我吃饭都不太敢随便吃了。\nIt's been about a month recently, and whenever I feel hungry, \nI've been experiencing a burning sensation in my chest. \nSometimes even after eating, I still have a slightly burning \nsensation. This problem is really quite annoying. I didn't notice \nthese things before,  now it's making me hesitant to eat freely.\n怎么不舒服呢？\nCould you tell me more about how you’re feeling?\nAI Hospital\nExample 2\nExample 1\nDoctor\nPatient\nMy mom had skin problems, I think. And my dad had \nsomething with his heart. I don't remember exactly.\nPatient\nDoctor\nIn the past six months, I've started to feel unsteady \nwhile walking.\nMay I ask where you are feeling unwell?\nHas anyone in your family had similar stomach or liver \nproblems, or any significant health conditions?\nPersonality:Suspicious\nEmotion:Anxious\nMedical History Recall: Low\nPersonality:Verbose\nEmotion:Irritable\nFigure 1: Comparison of different patient simulation datasets (AI Hospital (Fan et al.\n(2025)), PatientSim (Kyung et al. (2025)) and ours).\ncusing on gastroenterology, we collect outpatient records from 150 real pa-\ntients, including medical histories, case reports, imaging findings, laboratory\nresults, verbatim doctor–patient conversations, and others. To diversify pa-\ntient profiles and balance category distribution, we further used LLMs with a\nfew-shot strategy to generate additional cases, followed by thorough human\nverification. The final dataset contains 591 cases, each with roughly 10.5\ndialogue turns on average. For evaluation, we prompt LLMs acting as simu-\nlated patients with real doctors’ questions, and use actual patient responses\nas ground truth. Model performance is assessed across five dimensions: ba-\nsic content alignment, persona consistency, factual consistency, naturalness,\nand contextual relevance. These metrics ensure that simulated behaviors re-\nmain faithful to real clinical contexts. Across a range of LLMs, we observe\na consistent pattern: most LLMs, regardless of scale, tend to produce overly\nuniform, formal, and emotionally flat responses during patient simulation.\nTo mitigate this issue, we propose a multi-stage regulation framework that\ncoordinates a base generation stage with control stages to stabilize and re-\nfine the simulated patient’s behavior. Experiments show that this framework\nyields substantial improvements across diverse LLM architectures.\nOur contributions are summarized as follows:\n• We introduce Ch-PatientSim, the first benchmark built from real clin-\nical doctor–patient interactions, designed to provide a reliable evalua-\n3\n"}, {"page": 4, "text": "tion framework for LLM-based patient simulation.\n• To address LLMs’ tendency to produce overly uniform, formal, and\nemotionally flat responses when simulating patients, we propose a multi-\nstage regulation framework that stabilizes and refines simulated patient\nresponses.\n• Our approach delivers significant improvements in both the realism and\naccuracy of patient simulation across multiple LLMs.\n2. Related work\n2.1. Simulation of LLMs in Medical Scenarios\nWith the advancement of Large Language Models (LLMs) in natural lan-\nguage understanding and generation, their applications in medical scenarios\nhave gradually expanded from simple question-answering to complex agent\nsimulation. Early research (Zhou et al. (2025b); Oniani et al. (2024); Gaber\net al. (2025); Masanneck et al. (2024); Zhao et al. (2025)) on agents mainly\nfocused on automating clinical processes, such as disease diagnosis, triage\nrecommendation, or treatment plan generation, aiming primarily to improve\ntask accuracy, with less attention paid to interaction realism.\nSubsequently, some studies (Li et al. (2024); Fan et al. (2025); Almansoori\net al. (2025)) attempted to simulate multi-role collaboration within hospitals\nthrough multi-agent systems, including doctors, nurses, and patients. These\nworks demonstrated the potential of LLMs in information integration, rea-\nsoning, and collaborative decision-making, but patient agents are usually\nsimplified as generic question-answering objects, lacking modeling of indi-\nvidual differences and language styles, which limit the realism of simulated\ninteractions.\nIn recent years, some studies have shifted focus to doctor-patient di-\nalogues and educational scenarios, evaluating the performance of doctor\nmodels in communication skills, empathy, and patient-centered interactions\n(Chow and Li (2024); Zohny et al. (2025)), or exploring their potential as\nmedical education aids (Zhui et al. (2024); Lucas et al. (2024)). These find-\nings indicate that LLMs can perform multi-role tasks in medical scenarios,\nbut making simulated patient roles semantically authentic and reflective of\nindividual differences remains a central challenge.\n4\n"}, {"page": 5, "text": "2.2. Role-Playing and Persona Modeling\nTo enhance the naturalness and role consistency of LLMs in interactions,\nrole-playing and persona modeling have become important directions. Chen\net al. (2024) pointed out in From Persona to Personalization that role-playing\nlanguage agents, through explicit persona profiles or multi-attribute prompts,\ncan improve consistency in identity maintenance, language style, and be-\nhavior logic. Shao et al. (2023) formalized role-playing as a trainable task,\ncombining persona profiles with scene prompts to enhance role consistency\nand tone stability in language generation. Peng and Shang (2024) proposed a\n“Global Faithfulness” metric to quantify the alignment between generated be-\nhaviors and role definitions, and optimized strategies to improve the stability\nof persona-driven generation.\nIn terms of evaluation, Tu et al. (2024) constructed a systematic Chinese\nrole-playing benchmark, assessing model performance in conversational abil-\nity, character consistency, and role-playing attractiveness. Zhou et al. (2025a)\nfurther proposed a more comprehensive evaluation framework, covering be-\nlievability, morality, memory, persona, knowledge, and emotion, providing\nstandardized tests for persona-driven generation.\nThese studies suggest that LLMs can generate stable characters under\npersonality control. However, in medical scenarios, due to strict semantic\nconstraints and high ethical requirements, generation control methods that\nensure medical accuracy while reflecting individualized traits are still needed.\n2.3. Personalized Patient Modeling in Medical Scenarios\nDriven by advances in general role-playing technologies, research on med-\nical dialogue simulation is shifting from early process-level modeling toward\nmore fine-grained persona modeling, integrating richer patient personality\ncharacteristics to improve interaction authenticity and diversity.\nAI Hospital (Fan et al. (2025)) constructs a dynamic multi-agent system\nof doctors, patients, and examiners, evaluating LLM doctors on symptom\ncollection, test recommendation, and diagnosis using high-quality clinical\nrecords, though its primary focus remains on diagnostic workflows. EvoPa-\ntient (Du et al. (2025)) introduces a collaborative multi-agent evolutionary\nframework that enables LLMs to autonomously simulate standardized pa-\ntients and generate high-quality diagnostic dialogues through a dual doc-\ntor–patient agent setup. The AIE and SAPS simulators (Liao et al. (2024))\nfurther enhance realism by grounding multi-turn interactions in 50 real clini-\ncal cases, with GPT-4 acting as both doctor and patient to produce approxi-\n5\n"}, {"page": 6, "text": "mately 10-round consultations. In addition, Bodonhelyi et al. (2025) examine\nhow LLMs adapt communication strategies for different patient types (e.g.,\naccusatory, dependent), highlighting the influence of emotion and communi-\ncation style on interaction quality. Kyung et al. (2025) extend this line of\nwork with a persona-driven simulation framework based on multidimensional\npersona profiles, enabling more emotionally varied and personality-consistent\ndialogues and improving the realism of personalized patient interactions.\nHowever, these studies mostly relied on qualitative personality type la-\nbels, lacking fine-grained, operationalized, structured dimensions to guide\nLLM generation precisely. This resulted in thin patient characterizations and\ninconsistent behaviors. Additionally, the doctor-patient dialogues in these\nstudies are largely generated by LLMs, with limited real-world dialogue data\nto support them, restricting the medical authenticity of the patient language\ngenerated by the models.\n3. Dataset\nIn this section, we focus on explaining the construction process of the\nChinese patient simulation dataset (Ch-PatientSim), which is illustrated in\nFigure 2.\n3.1. Data Collection\nThe patient simulation dataset developed in this study is derived from real\ngastroenterology outpatient encounters in a hospital setting, encompassing\nmulti-turn doctor–patient dialogues as well as complete medical record infor-\nmation. For each patient, the dataset includes basic demographic attributes,\npersona annotations, integrated patient clinical information, and outpatient\nconversation transcripts.\nTogether, these components form a structured,\nmulti-source corpus that supports the application of multi-dimensional con-\ntrol mechanisms during patient-simulation generation.\n3.2. Data Cleaning\nDuring data cleaning, medical professionals first review each consultation\nrecord sentence by sentence, distinguishing doctor and patient utterances and\nstandardizing their formatting. Structured fields are then extracted from the\nelectronic medical record system, with naming conventions unified and all\nidentifiable information removed.\n6\n"}, {"page": 7, "text": "Figure 2:\nThe construction process of the Chinese patient simulation dataset (Ch-\nPatientSim).\nPersona attributes are annotated across multiple dimensions, including\npersonality traits, emotional tendencies, recall ability regarding medical his-\ntory, level of medical understanding, and expressive capability. After nor-\nmalization and template-based cleaning, dialogue texts are integrated with\nthe fused patient state information and persona labels to form standardized\nsamples.\nAll data undergo two rounds of manual verification to ensure medical\naccuracy, linguistic naturalness, and consistency in persona expression. A\nthird expert reviews cases showing annotation disagreement between the two\nannotators to determine the final outcome. Among the 591 samples, 43 cases\nrequire adjudication due to annotation inconsistencies.\n3.3. Data Augmentation\nBecause the collected data exhibit category imbalance in persona and\npatient-state attributes, we apply LLM-based augmentation to rebalance the\ndistribution. This process involves regenerating patient cases through per-\nsona reshaping of existing samples. A few-shot prompting strategy is used\nto guide LLM in producing additional dialogue records aligned with specific\npersonas and state categories, thereby expanding the dataset while main-\ntaining category balance. All augmented samples subsequently undergo both\nautomated rule-based filtering and expert review to ensure medical correct-\nness, persona consistency, and contextual coherence. Only dialogues that\n7\n"}, {"page": 8, "text": "pass these checks are retained, guaranteeing that the expanded data remain\nreliable and clinically valid.\n3.4. Evaluation\nTo quantitatively assess the semantic accuracy of model-generated pa-\ntient responses, we employ a set of widely adopted automatic evaluation\nmetrics, including BLEU, ROUGE, METEOR, and BERTScore. These met-\nrics collectively examine different dimensions of semantic similarity between\nthe generated response and the reference answer. Specifically, BLEU and\nROUGE capture n-gram level correspondence, measuring lexical overlap and\nphrase-level fidelity; METEOR incorporates synonym matching and stem-\nming to evaluate semantic alignment more flexibly; and BERTScore lever-\nages contextualized embeddings to estimate deeper semantic similarity that\ngoes beyond surface-level token matching. Together, these metrics provide\na comprehensive examination of the model’s ability to produce semantically\naligned and content-faithful outputs.\nIn addition, we adopt a model-based assessment framework using a strong\nLLM evaluator to judge higher-level pragmatic and contextual qualities of the\ngenerated responses. Following a discrete scoring scale from 1 to 5 (poor to\nexcellent), we design carefully curated evaluation prompts and the collected\npatient responses to elicit consistent and interpretable judgments across four\nkey dimensions:\nPersona Consistency, which assesses whether the generated response ad-\nheres to the target patient persona, including personality, emotion, medical\nhistory recall, medical comprehension, and language fluency;\nFactual Consistency, which measures the correctness of medical informa-\ntion and the presence of hallucinations or contradictory statements;\nNaturalness, which evaluates the expressive fluidity, coherence, and human-\nlikeness of the response in clinical communication;\nContextual Relevance, which examines whether the model appropriately\nresponds to the doctor’s questions, maintaining situational awareness and\nprogression within the conversation.\nThe combination of all these evaluation metrics enables a multi-angle and\nfine-grained assessment of both semantic fidelity and pragmatic communica-\ntion quality, ensuring a robust understanding of the model’s performance in\nmedical dialogue settings.\n8\n"}, {"page": 9, "text": "Figure 3: Analysis of the persona attributes in the Ch-PatientSim dataset.\n3.5. Dataset Analysis\nStatistical analysis shows that the dataset comprises 591 patients and\n5,935 dialogue samples, covering a broad range of common clinical scenar-\nios and diverse combinations of five-dimensional persona attributes. Each\npatient contributes an average of 10.5 dialogue turns, and the distribution\nacross all five persona dimensions is well balanced, as illustrated in Fig-\nure 3, ensuring both diversity and representativeness of the training data.\nGrounded in authentic clinical content and medically sound annotations,\nthe dataset provides robust support for patient-simulation research based on\nmulti-dimensional coordinated control mechanisms. It offers a reliable data\nfoundation for advancing the application of large language models in medical\nconsultation dialogue generation.\n4. Method\n4.1. Overall Framework\nTo address LLMs’ tendency to produce overly uniform, formal, and emo-\ntionally flat responses when simulating patients, we propose a multi-stage\nregulation framework that stabilizes and refines simulated patient responses.\n9\n"}, {"page": 10, "text": "Stage 1 ：Basic Information Generation\nStage 3 ：Expression Consistency Regulation\nStage 2 ：Communication Style Injection\nPersona\nInformation Integrity Control\nDialogue Consistency Control\nHistorical Dialogue\nEvaluation\nDoctor\nPatient\nPatient\nMedical Context\nPersona\nReal Response\nHistorical Dialogue\nMethod\nLLM Critic\nMSPRP\nPatient Info\nFact \nConsistency\nNaturalness\nContextual \nConsistency\nLLM response\nDoctor Qusetion\n•\nContextual Coherence & Recall Regulation\n•\nSymptom Information Completeness\n•\nTemporal Logic Consistency\n•\nMedical Data Accuracy \n•\nPersona-aligned Interaction Modeling\n•\nSynergistic Regulation of \n     Communication Style\nMedical History Recall\nMedical Comprehension\nLanguage Fluency\n•\nProjection of Expressive Capacity \nonto Linguistic Forms\n•\nRefinement Based on \nHistorical Dialogues\n•\nFine-grained Adjustment of \nLanguage Expression Form\nPersonality\nEmotion\n•\nScenario Identification\n•\nScenario Rule-Guided Behavior \nvia Interaction Matrix\nPersona\nMedical Context\nMedical Record\nDiagnosis\nInitial Clinical Consultation\nDiscussion of Medical Tests\nTreatment Risks\nDivergent  Medical Opinions\nInteraction Matrix \nBehavior Boundary\nPatient Info\nDotor Question\nLLM Response\nPersona \nConsistency\nFigure 4: Multi-Stage Patient Role-Playing (MSPRP) framework.\nThe method targets patient simulation within clinical interactions and cen-\nters on a persona modeling architecture consisting of five complementary\ndimensions organized into two functional categories, combined with a three-\nstage collaborative regulation mechanism. The overall framework is illus-\ntrated in Figure 4.\nThe objective of this task is to generate an answer A based on several\ntypes of input information. These inputs include the patient’s persona vec-\ntor profile P, the Medical Context C (i.e., the patient information, medical\nrecord, and diagnosis), the dialogue history H, and the current doctor’s ques-\ntion Q.\n4.2. Five-dimensional Persona\nThe persona vector profile P is defined as P =\n\u0002\npPersonality, pEmotion,\npMedical History Recall, pMedical Comprehension, pLanguage Fluency\u0003\n, which could be di-\nvided into two functional categories:\n• Communication Style. The dimensions of personality and emotion\n10\n"}, {"page": 11, "text": "characterize the patient’s stable interpersonal tendencies and affective\ntone during medical encounters. They determine the patient’s commu-\nnication attitude, response patterns, and overall interaction manner.\n• Expressive Capacity. The medical history recall, medical compre-\nhension, and language fluency dimensions describe the patient’s abil-\nity to produce medically relevant information, understand clinical con-\ncepts, and articulate symptoms with appropriate detail.\nThese two categories play a crucial role by providing structured behavioral\nsignals to the three-stage regulation mechanism, which allows the model to\ngenerate dialogue responses that are consistent, tailored to the individual,\nand medically appropriate.\n4.3. Three-stage Collaborative Regulation Mechanism\nTo integrate patient personas into the dialogue generation process, we\ndevelop a three-stage collaborative regulation mechanism. The framework\nprogressively ensures medical accuracy, persona alignment, and expression-\nlevel consistency.\n4.3.1. Stage 1: Basic Information Generation\nThis stage focuses on establishing a medically reliable and logically co-\nherent foundation for generation. It regulates the integrity and consistency\nof clinical information through:\n• Symptom information completeness: ensuring that the core symptom\nelements are fully preserved;\n• Temporal logic consistency: preventing contradictions across the clini-\ncal timeline;\n• Medical detail accuracy: covering medications, examinations, and di-\nagnostic information;\n• Contextual coherence and recall regulation: maintaining multi-turn fac-\ntual consistency and modulating the extent of remembered information\naccording to the medical history recall.\nTogether, these controls ensure that subsequent persona-related adjust-\nments are grounded on structurally sound medical content.\n11\n"}, {"page": 12, "text": "4.3.2. Stage 2: Communication Style Injection\nAfter factual correctness is secured, this stage introduces the patient’s\ncommunication style by aligning the generation with persona definitions and\ninteraction patterns. It includes:\n• Persona-aligned interaction modeling: ensuring that the generated re-\nsponses reflect the patient’s multi-dimensional persona;\n• Synergistic regulation of communication style: capturing the joint in-\nfluence of patients’ personality and emotion on conversational behavior;\n• Scenario identification: determining the clinical situation of the current\nturn;\n• Scenario rule-guided behavior via an Interaction Matrix: categorizing\ncommon medical scenarios and prescribing personality–emotion behav-\nioral rules for each situation.\nThrough these mechanisms, Stage 2 shapes how the patient speaks and\nreacts in a clinically coherent and persona-consistent manner.\n4.3.3. Stage 3: Expression Consistency Regulation\nThis stage refines how persona traits are realized in linguistic form, mainly\nguided by the last three persona dimensions: medical history recall ability,\nmedical comprehension ability, and language fluency.\n• Projection of expressive capacity onto linguistic forms: ensuring that\nexpressive behavior aligns with the patient’s cognitive and communica-\ntive capacities;\n• Refinement based on historical dialogues: adjusting expressions to main-\ntain multi-turn stylistic coherence;\n• Fine-grained adjustment of expressive form: controlling detail level,\nfluency, and clarity based on the patient’s expressive capacity.\nStage 3 ensures that the patient not only behaves according to their per-\nsona but also communicates in a way that matches their cognitive and lin-\nguistic profile.\nAutomatic evaluation metrics for different LLMs. Missing entries indicate\nunavailable results.\n12\n"}, {"page": 13, "text": "Table 1: Basic evaluation of different LLMs on Ch-PatientSim.\nModel\nBLEU-1\nBLEU-2\nBLEU-3\nBLEU-4\nROUGE-L\nMETEOR\nBERTScore\nQwen2.5-7B\n0.1828\n0.0856\n0.0504\n0.0329\n0.2051\n0.2004\n0.6437\nGLM-4-9B\n0.1824\n0.0874\n0.0521\n0.0346\n0.2099\n0.1949\n0.6478\nLlama-3.1-8B\n0.1656\n0.0724\n0.0422\n0.0278\n0.1839\n0.1663\n0.6293\nInternlm3-8B\n0.1552\n0.0749\n0.0454\n0.0308\n0.1844\n0.1812\n0.6299\nQwen2.5-72B\n0.2006\n0.1019\n0.0634\n0.0431\n0.2257\n0.2256\n0.6551\nGPT-4omini\n0.1606\n0.0738\n0.0434\n0.0285\n0.1873\n0.1940\n0.6383\nDeepSeek-V3\n0.1348\n0.0596\n0.0335\n0.0214\n0.1606\n0.1948\n0.6266\nQwen2.5-7B+MSPRP\n0.2031\n0.0956\n0.0569\n0.0375\n0.2196\n0.2041\n0.6491\nQwen2.5-72B+MSPRP\n0.2054\n0.1057\n0.0659\n0.0450\n0.2291\n0.2313\n0.6575\nTable 2: Persona evaluation of different LLMs on Ch-PatientSim.\nModel\nPersona Consistency\nFactual Consistency\nNaturalness\nContextual Relevance\nQwen2.5-7B\n3.748\n3.795\n3.824\n3.780\nGLM-4-9B\n3.770\n3.790\n3.857\n3.796\nLlama-3.1-8B\n3.416\n3.515\n3.523\n3.384\nInternlm3-8B\n3.589\n3.642\n3.602\n3.572\nQwen2.5-72B\n3.870\n3.896\n3.914\n3.910\nGPT-4omini\n3.858\n3.855\n3.906\n3.871\nDeepSeek-V3\n3.936\n3.883\n3.962\n3.916\nQwen2.5-7B+MSPRP\n3.905\n3.918\n3.942\n3.937\nQwen2.5-72B+MSPRP\n3.939\n3.956\n3.970\n3.969\n5. Experiments\nIn this section, we conduct comprehensive experiments on the Ch-PatientSim\ndataset. Our overarching goal is to answer the following research questions:\n• RQ1: How well do current LLMs perform in patient simulation tasks?\n• RQ2: How effective is the MSPRP method proposed in this paper?\n• RQ3: Are LLMs’ patient-simulation behaviors natural and clinically\nplausible in realistic doctor–patient communication scenarios?\n5.1. Implementation Details\nWe evaluate the role-playing capabilities of several LLMs, including Qwen2.5\n(Yang et al. (2025)), GLM-4 (GLM et al. (2024)), DeepSeek-V3 (Liu et al.\n(2024)), Llama-3.1 (Grattafiori et al. (2024)), Internlm3 (Cai et al. (2024)),\nand GPT-4o-mini (Hurst et al. (2024)). The persona evaluation metrics are\ntested using Qwen2.5-14B. The data augmentation method employs Qwen2.5-\n72B. All experiments are conducted on NVIDIA A40 GPUs.\n13\n"}, {"page": 14, "text": "5.2. RQ1: How well do current LLMs perform in patient simulation tasks?\nTo answer RQ1, we evaluate a range of representative LLMs on the Ch-\nPatientSim dataset using both automatic similarity metrics and model-based\nhuman-aligned evaluations. The results in Table 1 and Table 2 reveal clear\nand consistent trends across models.\nFirst, as shown in Table 1, Although the Qwen 2.5-72B performed best,across\nall models, BLEU, ROUGE, METEOR, and BERTScore remain relatively\nlow, indicating that patient responses generated by current LLMs still di-\nverge considerably from real patient utterances at the lexical and semantic\nlevels. This highlights the inherent difficulty of matching the fragmented,\ncolloquial, and personally varied speech patterns commonly observed in real\nclinical encounters.\nSecond, as presented in Table 2, top-performing models — including\nQwen2.5-72B, GPT-4omini, and DeepSeek-V3 — achieve relatively high scores\nin persona and pragmatic evaluation, with DeepSeek-V3 distinguishing itself\nparticularly in Persona Consistency and Naturalness. In contrast, smaller-\nscale models such as Llama-3.1-8B and Internlm3-8B exhibit notably lower\nperformance across these dimensions.\nImportantly, no model surpasses a\nscore of 4.0 in any evaluation category—a finding that underscores a critical\nlimitation: even large-scale models struggle to consistently embody individ-\nualized patient traits, often failing to maintain a stable personality, coherent\nemotional tone, and consistent expression style in dialogues.\nThird, a common issue across models is over-formalization: generated pa-\ntient responses tend to be polite, structured, and medically coherent, but lack\nthe diverse personalities, emotional fluctuation, and idiosyncratic expression\npatterns that characterize real patient interactions. This aligns with earlier\nobservations that LLMs default to normative and institutionally “safe” tones\nwhen simulating patients.\nOverall, these findings demonstrate that existing LLMs exhibit reason-\nable medical correctness and contextual logic, but fall short in simulating\nnaturally varied and persona-driven patient behavior, which is the main gap\nthat our proposed MSPRP framework aims to address.\n5.3. RQ2: How effective is the MSPRP method proposed in this paper?\nComparative Study: To evaluate the effectiveness of MSPRP, we com-\npare baseline models with their MSPRP-enhanced models. The results show\nclear and consistent improvements across all assessed dimensions.\n14\n"}, {"page": 15, "text": "In terms of basic metrics, MSPRP increases BLEU-n, ROUGE-L, ME-\nTEOR, and BERTScore for both small and large models (e.g., Qwen2.5-7B\nand Qwen2.5-72B). These gains suggest that MSPRP helps models generate\nanswers that more closely match real patient responses, reflecting improve-\nments in content alignment and semantic fidelity.\nThe improvements are more striking in semantic evaluations. MSPRP\nbrings substantial enhancements in persona consistency, factual consistency,\nnaturalness, and contextual relevance.\nNotably, persona consistency im-\nproves the most, confirming that the multi-stage regulation mechanism ef-\nfectively stabilizes the projection of the target persona across dialogue turns.\nMoreover, improvements in naturalness indicate that the communication-\nstyle and expression-regulation stages lead to linguistic behaviors that better\nresemble real patients.\nAblation Study: To further validate the contribution of the compo-\nnents of the MSPRP framework, we conducted ablation experiments aimed\nat answering two core questions: (1) the effectiveness of each stage, and (2)\nthe impact of the execution sequence. Tables 3 and 4 show the results of au-\ntomated and manual evaluations, respectively. The single-stage application\noutperformed the baseline on all metrics, confirming the independent value\nof each module. Among them, Stage 1 (basic information generation) signifi-\ncantly improved performance at the basic evaluation, and Stage 2 (communi-\ncation style injection) achieved the most obvious optimization in the persona\nevaluation. In the multi-stage combination experiment, the results of Stage\n2+3+1 confirm that the factual accuracy guaranteed by Stage 1 is the basic\nprerequisite for the effective operation of the entire framework. The perfor-\nmance of Stage 1+3+2 confirms the patient’s expression logic, showing that\na gradual progression from internal style shaping to external language output\naligns better with real-world communication needs. Stage 1+2+3 performs\nthe best, outperforming other combinations in both basic evaluation metrics\nand persona evaluation metrics.\nIn summary, the effectiveness of the MSPRP framework stems from three\ncore factors: the inherent value of each independent stage, the complemen-\ntary gains generated from the combination of multiple stages, and the pro-\ngressive adjustment process of “factual basis→style shaping→expression\nrefinement”, which provides key support for optimizing the quality of lan-\nguage generation and the fidelity of persona.\nThese results validate that MSPRP is an effective, training-free solution\nfor enhancing patient-simulation quality. By decomposing generation into\n15\n"}, {"page": 16, "text": "Table 3: Ablation results of each stage and stage ordering in MSPRP on basic evaluation.\nBaseline: Qwen2.5-7B. Stage 1: Basic Information Generation, Stage 2: Communication\nStyle Injection, and Stage 3: Expression Consistency Regulation.\nModel\nBLEU-1\nBLEU-2\nBLEU-3\nBLEU-4\nROUGE-L\nMETEOR\nBERTScore\nBaseline\n0.1828\n0.0856\n0.0504\n0.0329\n0.2051\n0.2004\n0.6437\nStage 1\n0.1999\n0.0937\n0.0552\n0.0360\n0.2177\n0.2004\n0.6483\nStage 2\n0.1904\n0.0884\n0.0518\n0.0339\n0.2110\n0.2002\n0.6457\nStage 3\n0.1929\n0.0900\n0.0530\n0.0348\n0.2126\n0.1997\n0.6457\nStage2+3+1\n0.1936\n0.0900\n0.0526\n0.0342\n0.2115\n0.2019\n0.6459\nStage1+3+2\n0.1934\n0.0897\n0.0522\n0.0338\n0.2129\n0.2050\n0.6467\nStage1+2+3\n0.2031\n0.0956\n0.0569\n0.0375\n0.2196\n0.2041\n0.6491\nTable 4: Ablation results of each stage and stage ordering in MSPRP on persona evalua-\ntion.\nModel\nPersona Consistency\nFactual Consistency\nNaturalness\nContextual Relevance\nBaseline\n3.748\n3.795\n3.824\n3.780\nStage 1\n3.777\n3.818\n3.846\n3.835\nStage 2\n3.821\n3.835\n3.882\n3.849\nStage 3\n3.786\n3.828\n3.859\n3.842\nStage2+3+1\n3.816\n3.846\n3.876\n3.860\nStage1+3+2\n3.836\n3.843\n3.886\n3.862\nStage1+2+3\n3.905\n3.918\n3.942\n3.937\nstructured stages and applying persona regulation, the framework compen-\nsates for LLMs’ inherent tendency toward generic and uniform responses.\n5.4. RQ3: Are LLMs’ patient-simulation behaviors natural and clinically\nplausible in realistic doctor–patient communication scenarios?\nTo address RQ3, we analyze the naturalness and clinical plausibility\nof LLM patient simulations through quantitative metrics and qualitative\ncases, with results varying significantly between models with and without\nthe MSPRP framework.\nQuantitatively, MSPRP-enhanced models show notable improvements in\nkey dimensions. As seen in Table 2, Qwen2.5-72B+MSPRP scores 3.970 in\nNaturalness and 3.969 in Contextual Relevance, up from the baseline’s 3.914\nand 3.910, while its Factual Consistency reaches 3.956, ensuring responses\nare clinically accurate and contextually coherent.\nQualitative observations further validate the effectiveness of the MSPRP\nframework. As shown in Figure 5, when faced with doctors’ diagnostic ques-\ntions, the base model can provide factually correct answers but tends to be\n16\n"}, {"page": 17, "text": "Patient\n患者信息\nPatient Info\n人格\nPersona\n性格：偏执\nPersonality: Paranoid\n情绪：焦虑\nEmotion: Anxious\n病史回忆能力：高\nMedical History Recall: High\n医学理解力：高\nMedical Comprehension: \nHigh\n语言表达能力：中\n临床信息\nClinical Info\n主诉：间断呕吐3天\nChief Complaint: Intermittent vomiting for 3 \ndays\n现病史：伴低热，近期应用药物后症状减轻。\nPresent Medical History: Low-grade \nfever,symptoms alleviated after recent \nmedication use\n既往史：胃结石2年（内镜下碎石）；HP+，根\n除失败；剖宫产术后41年；血糖偏高\nPast History: Gastrolithiasis for 2 years (treated \nwith endoscopic lithotripsy); Helicobacter pylori \npositive with failed eradication; 41 years post \ncesarean section; Slightly elevated blood \nglucose\n药物过敏史：无\nHistory of Drug Allergy: None\n体格检查：无专科阳性特征\n Physical Examination: \nNo specialist positive signs\n主诊断：慢性胃炎\nPrimary Diagnosis: Chronic gastritis\nDoctor\nLabel\nQwen2.5-72B\nQwen2.5-72B\n+MSPRP\nPID:xxx\n性别：男\nGender:Male\n年龄：45\nAge:45\nDoctor\n你得缓一缓，因为反复刺激可能又会加重你的这些不舒服的感觉。\nYou need to slow down, because repeated stimulation may likely worsen these \nuncomfortable feelings again.\n但是这个吐不会是胃有什么问题吧？我一直担心是不是胃有问题，以前也听说过胃病会\n导致这种情况。\nBut could this be a problem with my stomach? I've been worried that there might be an \nissue with my stomach, and I've heard before that stomach problems can cause this.\n好的，我理解了。那我就先按照你说的做，暂时不做胃镜，专心复查，看看情况再说。\n谢谢医生！\nAlright, I understand. Then I will do as you said, temporarily not have an endoscopy, \nfocus on follow-up checks, and see how things go from there. Thank you, doctor!\n好的，我明白。那我今天先查指标，看看情况再说。谢谢您,不过我还是有点担心，希\n望这次检查能查清楚到底是什么原因。\nAlright, I understand. So, I'll check the indicators first and see how it goes. Thank \nyou, but I'm still a bit worried. I hope this check can figure out what the actual \nproblem is.\n如果是胃本身疾病导致的吐，比如说肿长东西了啥的，那不可能打消炎药能打好，\n你明白吗？\nIf the vomiting is caused by a disease of the stomach itself, such as a growth or \nsomething like that, then it's impossible for anti-inflammatory medication to help, \ndo you understand?\n嗯，我明白，但我还是有点担心。毕竟之前我也看过，那时候也是吃了药好了一点，但\n后来又反复了。\nWell, I understand, but I'm still a bit worried. After all, I've seen it before too. Back then, \nit improved a bit after taking medicine, but then it came back again.\n明白了，医生，那我先按照你说的复查，如果还不见好转，我会再找你咨询的。谢谢\n医生！\nUnderstood, doctor. I will follow your advice to have a follow-up first. If it still hasn't \nimproved, I will consult you again.\n我懂，但还是有点担心。毕竟我以前有胃结石，还做过内镜碎石，胃部一直不太舒服。\n这次吐会不会是旧病复发了？\nI understand, but I'm still a bit worried. After all, I used to have gallstones in my \nstomach and had an endoscopic lithotripsy, so my stomach has never really felt \ncomfortable. Could this time of vomiting be a relapse of the old condition?\nLanguage Fluency: Moderate\nLabel\nQwen2.5-72B\nQwen2.5-72B\n+MSPRP\nFigure 5: Case Study. Comparison of Original Responses, Basic Responses, and Responses\nApplying the MSPRP Framework to Physician Questions.\noverly formal, lacks emotional expression, and fails to demonstrate the re-\ntrieval and response to relevant medical information related to the patient.\nIn contrast, the output of the model enhanced by MSPRP is more aligned\nwith the linguistic characteristics of patients in real clinical settings. For\nexample, when a doctor suggests postponing a gastroscopy to alleviate the\npatient’s physical discomfort, the simulated anxious-type patient under the\nMSPRP framework will proactively express concerns about “postponing the\nexamination may not clarify the cause”. Even after the doctor provides a\nsecondary explanation, the patient will still reiterate their concerns based on\ntheir paranoid personality traits. The response also combines the patient’s\nmedical history to substantiate the validity of his concerns, which aligns with\nthe “high medical history recall ability” dimension and confirms the value of\nthe MSPRP framework in Stage 1.\nOverall, both quantitative and qualitative results indicate that MSPRP\nsubstantially enhances the naturalness and clinical plausibility of simulated\n17\n"}, {"page": 18, "text": "patient interactions, bringing model behavior closer to real-world doctor–patient\ncommunication patterns.\n6. Conclusion\nIn this paper, we investigate the simulation of realistic patient behavior\nas a crucial component for advancing clinical LLMs and enhancing medical\ndiagnostic education. We present Ch-PatientSim, the first Chinese patient\nsimulation dataset constructed from authentic clinical interaction scenarios,\nenabling a comprehensive evaluation of LLMs’ ability to emulate patient\ntraits. By modeling patients based on a five-dimension persona structure\nand augmenting the dataset via few-shot generation with LLMs followed\nby manual verification, we ensure diversity and realism. Our evaluation of\nstate-of-the-art LLMs reveals that many models generate responses that are\noverly formal and lack individualized personality. To overcome this limita-\ntion, we introduce a training-free Multi-Stage Patient Role-Playing (MSPRP)\nframework, which decomposes patient-LM interactions into three stages to\nmaintain both personalization and contextual realism. Experimental results\nshow that MSPRP substantially enhances model performance across multiple\ndimensions of patient simulation, including persona consistency, factual ac-\ncuracy, naturalness, and contextual relevance. These findings underscore the\nimportance of structured role-playing frameworks in improving LLM-based\npatient simulations.\n7. Acknowledgements\nThis work is supported by the National Natural Science Foundation of\nChina [62576149] and the Fundamental Research Funds for the Central Uni-\nversity, JLU.\nReferences\nAlmansoori, M., Kumar, K., Cholakkal, H., 2025.\nMedagentsim:\nSelf-\nevolving multi-agent simulations for realistic clinical interactions, in: Inter-\nnational Conference on Medical Image Computing and Computer-Assisted\nIntervention, Springer. pp. 362–372.\nBodonhelyi, A., Stegemann-Philipps, C., Sonanini, A., Herschbach, L., Szep,\nM., Herrmann-Werner, A., Festl-Wietek, T., Kasneci, E., Holderried, F.,\n18\n"}, {"page": 19, "text": "2025. Modeling challenging patient interactions: Llms for medical com-\nmunication training. arXiv preprint arXiv:2503.22250 .\nCai, Z., Cao, M., Chen, H., Chen, K., Chen, K., Chen, X., Chen, X., Chen,\nZ., Chen, Z., Chu, P., et al., 2024.\nInternlm2 technical report.\narXiv\npreprint arXiv:2403.17297 .\nChen, J., Wang, X., Xu, R., Yuan, S., Zhang, Y., Shi, W., Xie, J., Li, S.,\nYang, R., Zhu, T., et al., 2024. From persona to personalization: A survey\non role-playing language agents. arXiv preprint arXiv:2404.18231 .\nChow, J.C., Li, K., 2024. Ethical considerations in human-centered ai: ad-\nvancing oncology chatbots through large language models. JMIR Bioin-\nformatics and Biotechnology 5, e64406.\nDu, Z., LujieZheng, L., Hu, R., Xu, Y., Li, X., Sun, Y., Chen, W., Wu, J.,\nCai, H., Ying, H., 2025. Llms can simulate standardized patients via agent\ncoevolution, in: Proceedings of the 63rd Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Papers), pp. 17278–17306.\nFan, Z., Wei, L., Tang, J., Chen, W., Siyuan, W., Wei, Z., Huang, F., 2025.\nAi hospital: Benchmarking large language models in a multi-agent medical\ninteraction simulator, in: Proceedings of the 31st International Conference\non Computational Linguistics, pp. 10183–10213.\nGaber, F., Shaik, M., Allega, F., Bilecz, A.J., Busch, F., Goon, K., Franke,\nV., Akalin, A., 2025. Evaluating large language model workflows in clinical\ndecision support for triage and referral and diagnosis. npj Digital Medicine\n8, 263.\nGLM, T., Zeng, A., Xu, B., Wang, B., Zhang, C., Yin, D., Zhang, D., Rojas,\nD., Feng, G., Zhao, H., et al., 2024. Chatglm: A family of large language\nmodels from glm-130b to glm-4 all tools. arXiv preprint arXiv:2406.12793\n.\nGrattafiori, A., Dubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle,\nA., Letman, A., Mathur, A., Schelten, A., Vaughan, A., et al., 2024. The\nllama 3 herd of models. arXiv preprint arXiv:2407.21783 .\n19\n"}, {"page": 20, "text": "Hurst, A., Lerer, A., Goucher, A.P., Perelman, A., Ramesh, A., Clark, A.,\nOstrow, A., Welihinda, A., Hayes, A., Radford, A., et al., 2024. Gpt-4o\nsystem card. arXiv preprint arXiv:2410.21276 .\nKyung, D., Chung, H., Bae, S., Kim, J., Sohn, J.H., Kim, T., Kim, S.K.,\nChoi, E., 2025. Patientsim: A persona-driven simulator for realistic doctor-\npatient interactions. arXiv preprint arXiv:2505.17818 .\nLi, J., Lai, Y., Li, W., Ren, J., Zhang, M., Kang, X., Wang, S., Li, P., Zhang,\nY.Q., Ma, W., et al., 2024. Agent hospital: A simulacrum of hospital with\nevolvable medical agents. arXiv preprint arXiv:2405.02957 .\nLiao, Y., Meng, Y., Wang, Y., Liu, H., Wang, Y., Wang, Y., 2024. Automatic\ninteractive evaluation for large language models with state aware patient\nsimulator. arXiv preprint arXiv:2403.08495 .\nLiu, A., Feng, B., Xue, B., Wang, B., Wu, B., Lu, C., Zhao, C., Deng, C.,\nZhang, C., Ruan, C., et al., 2024. Deepseek-v3 technical report. arXiv\npreprint arXiv:2412.19437 .\nLucas, H.C., Upperman, J.S., Robinson, J.R., 2024. A systematic review of\nlarge language models and their implications in medical education. Medical\neducation 58, 1276–1285.\nMasanneck, L., Schmidt, L., Seifert, A., Kölsche, T., Huntemann, N., Jansen,\nR., Mehsin, M., Bernhard, M., Meuth, S.G., Böhm, L., et al., 2024. Triage\nperformance across large language models, chatgpt, and untrained doctors\nin emergency medicine: comparative study. Journal of medical Internet\nresearch 26, e53297.\nOniani, D., Wu, X., Visweswaran, S., Kapoor, S., Kooragayalu, S., Polanska,\nK., Wang, Y., 2024. Enhancing large language models for clinical deci-\nsion support by incorporating clinical practice guidelines, in: 2024 IEEE\n12th International Conference on Healthcare Informatics (ICHI), IEEE.\npp. 694–702.\nPeng, L., Shang, J., 2024. Quantifying and optimizing global faithfulness in\npersona-driven role-playing. Advances in Neural Information Processing\nSystems 37, 27556–27583.\n20\n"}, {"page": 21, "text": "Shao, Y., Li, L., Dai, J., Qiu, X., 2023. Character-llm: A trainable agent for\nrole-playing. arXiv preprint arXiv:2310.10158 .\nTeam, G., Georgiev, P., Lei, V.I., Burnell, R., Bai, L., Gulati, A., Tanzer, G.,\nVincent, D., Pan, Z., Wang, S., et al., 2024. Gemini 1.5: Unlocking multi-\nmodal understanding across millions of tokens of context. arXiv preprint\narXiv:2403.05530 .\nTu, Q., Fan, S., Tian, Z., Shen, T., Shang, S., Gao, X., Yan, R., 2024.\nCharactereval: A chinese benchmark for role-playing conversational agent\nevaluation, in: Proceedings of the 62nd Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Papers), pp. 11836–11850.\nWang, N., Peng, Z., Que, H., Liu, J., Zhou, W., Wu, Y., Guo, H., Gan, R.,\nNi, Z., Yang, J., et al., 2024. Rolellm: Benchmarking, eliciting, and en-\nhancing role-playing abilities of large language models, in: Findings of the\nAssociation for Computational Linguistics: ACL 2024, pp. 14743–14777.\nYang, A., Li, A., Yang, B., Zhang, B., Hui, B., Zheng, B., Yu, B., Gao, C.,\nHuang, C., Lv, C., et al., 2025. Qwen3 technical report. arXiv preprint\narXiv:2505.09388 .\nZhao, X., Liu, S., Yang, S.Y., Miao, C., 2025. Medrag: Enhancing retrieval-\naugmented generation with knowledge graph-elicited reasoning for health-\ncare copilot, in: Proceedings of the ACM on Web Conference 2025, pp.\n4442–4457.\nZhou, J., Huang, Y., Wen, B., Bi, G., Chen, Y., Ke, P., Chen, Z., Xiao,\nX., Peng, L., Tang, K., et al., 2025a.\nCharacterbench: Benchmarking\ncharacter customization of large language models, in: Proceedings of the\nAAAI Conference on Artificial Intelligence, pp. 26101–26110.\nZhou, S., Xu, Z., Zhang, M., Xu, C., Guo, Y., Zhan, Z., Fang, Y., Ding,\nS., Wang, J., Xu, K., et al., 2025b. Large language models for disease\ndiagnosis: A scoping review. npj Artificial Intelligence 1, 9.\nZhui, L., Fenghe, L., Xuehu, W., Qining, F., Wei, R., 2024. Ethical consid-\nerations and fundamental principles of large language models in medical\neducation. Journal of Medical Internet Research 26, e60083.\n21\n"}, {"page": 22, "text": "Zohny, H., Allen, J.W., Wilkinson, D., Savulescu, J., 2025. Which ai doctor\nwould you like to see? emulating healthcare provider–patient communica-\ntion models with gpt-4: proof-of-concept and ethical exploration. Journal\nof Medical Ethics .\n22\n"}]}