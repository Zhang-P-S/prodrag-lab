{"doc_id": "arxiv:2601.03627", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2601.03627.pdf", "meta": {"doc_id": "arxiv:2601.03627", "source": "arxiv", "arxiv_id": "2601.03627", "title": "Evaluating the Pre-Consultation Ability of LLMs using Diagnostic Guidelines", "authors": ["Jean Seo", "Gibaeg Kim", "Kihun Shin", "Seungseop Lim", "Hyunkyung Lee", "Wooseok Han", "Jongwon Lee", "Eunho Yang"], "published": "2026-01-07T06:15:21Z", "updated": "2026-01-08T01:47:05Z", "summary": "We introduce EPAG, a benchmark dataset and framework designed for Evaluating the Pre-consultation Ability of LLMs using diagnostic Guidelines. LLMs are evaluated directly through HPI-diagnostic guideline comparison and indirectly through disease diagnosis. In our experiments, we observe that small open-source models fine-tuned with a well-curated, task-specific dataset can outperform frontier LLMs in pre-consultation. Additionally, we find that increased amount of HPI (History of Present Illness) does not necessarily lead to improved diagnostic performance. Further experiments reveal that the language of pre-consultation influences the characteristics of the dialogue. By open-sourcing our dataset and evaluation pipeline on https://github.com/seemdog/EPAG, we aim to contribute to the evaluation and further development of LLM applications in real-world clinical settings.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2601.03627v2", "url_pdf": "https://arxiv.org/pdf/2601.03627.pdf", "meta_path": "data/raw/arxiv/meta/2601.03627.json", "sha256": "c0ad26c4991f5da150b9f60ca49fb0b6fc7a76369cd4d3fe519f87153e42ad58", "status": "ok", "fetched_at": "2026-02-18T02:22:31.090214+00:00"}, "pages": [{"page": 1, "text": "Evaluating the Pre-Consultation Ability of LLMs\nusing Diagnostic Guideliness\nJean Seo1, Gibaeg Kim1, Kihun Shin3, Seungseop Lim1,\nHyunkyung Lee1, Wooseok Han1, Jongwon Lee4, Eunho Yang1,2\n1AITRICS\n2KAIST\n3Severance Hospital, Yonsei University\n4College of Medicine, The Catholic University of Korea\n{jeanseo}@aitrics.com\nAbstract\nWe introduce EPAG, a benchmark dataset and\nframework designed for Evaluating the Pre-\nconsultation Ability of LLMs using diagnos-\ntic Guidelines. LLMs are evaluated directly\nthrough HPI-diagnostic guideline comparison\nand indirectly through disease diagnosis. In\nour experiments, we observe that small open-\nsource models fine-tuned with a well-curated,\ntask-specific dataset can outperform frontier\nLLMs in pre-consultation. Additionally, we\nfind that increased amount of HPI (History\nof Present Illness) does not necessarily lead\nto improved diagnostic performance. Further\nexperiments reveal that the language of pre-\nconsultation influences the characteristics of\nthe dialogue. By open-sourcing our dataset and\nevaluation pipeline on https://github.com/\nseemdog/EPAG, we aim to contribute to the\nevaluation and further development of LLM\napplications in real-world clinical settings.\n1\nIntroduction\nLarge Language Models (LLMs) are increasingly\nintegrated into clinical applications, transform-\ning healthcare industry by automating various\ntasks (Yang et al., 2023a; Zhou et al., 2024;\nThirunavukarasu et al., 2023; Wang et al., 2025).\nOne example is pre-consultation, where LLMs as-\nsist history-taking (Wang et al., 2024; Yang et al.,\n2023b) and decision-making (SAMIEE; Li et al.,\n2024). However, it is crucial to acknowledge the\nsignificant risks involved. Erroneous outputs can\nresult in severe adverse consequences such as mis-\ntreatment or incorrect drug prescription, highlight-\ning the necessity of rigorous evaluations (Kim et al.,\n2025; Ullah et al., 2024).\nWe\npropose\nEPAG\n(Evaluating\nthe\nPre-\nconsultation Ability of LLMs using diagnostic\nGuidelines), a benchmark dataset and evaluation\npipeline specifically designed for pre-consultation.\nGiven basic patient information, such as age, sex,\nand chief complaints, pre-consultation models ask\nquestions to elicit symptoms related to potential\ndiagnoses. EPAG benchmark dataset comprises\n520 patient profiles, spanning 26 diseases, 10 ICD-\n11 chapters, 10 primary specialties, and 22 sec-\nondary specialties, along with pre-defined diag-\nnostic guidelines. In EPAG, the pre-consultation\ndialogue is evaluated through two tasks: (1) HPI-\nDiagnostic Guideline Comparison, and (2) Disease\nDiagnosis. In our experiments, eleven LLMs are\nevaluated across various numbers of dialogue turns.\nThe main contributions of our work are:\n• Developing a systematic framework and con-\nstructing a high-quality dataset for evaluating\nthe clinical pre-consultation ability of LLMs.\n• Open-sourcing the dataset and pipeline.\n• Implementing targeted experiments and shar-\ning the results with in-depth analysis.\n2\nRelated Work\n2.1\nMedical LLMs in Clinical Applications\nExisting clinical chatbot applications include Hu-\natuoGPT (Zhang et al., 2023), ChatDoctor (Li et al.,\n2023), MedChatZH (Tan et al., 2024), MedAide\n(Basit et al., 2024), and MILD Bot (Kim et al.,\n2024). Other medical LLM applications not limited\nto chatbots are Kumichev et al. (2024); Zhang et al.\n(2024); Wiest et al. (2024); Ghosh et al. (2024);\nWaisberg et al. (2024). LLMs have demonstrated\ndiagnostic accuracy comparable to that of physi-\ncians in certain contexts (Qian et al., 2021), with\nexisting works primarily focusing on final diag-\nnostic outcomes (McDuff et al., 2023; Singhal\net al., 2023; Tu et al., 2024). However, research\non patient information collection during LLM pre-\nconsultation remains limited. To address this, we\npropose a fine-grained framework that evaluates\nLLM pre-consultation capabilities.\narXiv:2601.03627v2  [cs.CL]  8 Jan 2026\n"}, {"page": 2, "text": "Guideline 1\n...\nGuideline j\nTop-k Accuracy\nTop-1 Accuracy\nBasic Information\nChief Complaint\nQuestion, Options\nPatient\nDoctor\nAnswer\nPatient\nTurn 1\n...\n(1) Dialogue Generation\nUnit 1\nUnit 2\n...\nAnswer\nPatient\nQuestion, Options\nDoctor\nTurn n\nUnit m\nOrganizer\n(3) Disease Diagnosis\n(2) HPI-Diagnostic Guideline Comparison\nComparer\nDiagnostician\nGuideline i\nDisease 1\n...\nDisease k\nDialogue\nEvaluator\niterate for m\nor\nNone of Above\nFigure 1: EPAG pipeline. (1) Dialogue Generation: The patient-agent acts as a patient given a specific profile,\nwhile the doctor-agent conducts a pre-consultation using only the basic information and chief complaint. After\nn turns, the doctor-agent is assessed through two tasks: (2) HPI-Diagnostic Guideline Comparison, where the\norganizer model extracts HPI units and the comparer model determines which of the diagnostic guidelines is most\nrelevant, and (3) Disease Diagnosis, where the dialogue is given to a separate diagnostician-agent for diagnosis.\n2.2\nEvaluation of Medical LLMs\nMultiple-choice QA is widely used for medical\nevaluation, as demonstrated by Med-HALT (Pal\net al., 2023), MedMCQA (Pal et al., 2022), Pub-\nMedQA (Jin et al., 2019), and KoreMedMCQA\n(Kweon et al., 2024). However, it is insufficient\nfor assessing real-world clinical conversational\nabilities (Bedi et al., 2024; Chen et al., 2024).\nMore sophisticated evaluation frameworks in the\nclinical domain have been proposed, including\nMEDIC (Kanithi et al., 2024), LLM-Mini-CEX\n(Shi et al., 2023), CRAFT-MD (Johri et al., 2025).\nOther evaluation benchmarks regarding disease di-\nagnosis include works by Hou et al. (2024), Zhu\net al. (2025), Bhasuran et al. (2025), Delaunay and\nCusido (2024), Sarvari and Al-Fagih (2025), Reese\net al. (2025), Gaber et al. (2025). While Winston\net al. and Fast et al. propose evaluation pipelines for\npre-consultation, their dataset coverage is limited\nand peripheral.\n3\nEPAG Benchmark\nWe assess pre-consultation models designed to\ncollect as much relevant information as possible\nfrom the patient, including symptoms, family his-\ntory, and other factors, referred to as the History\nof Present Illness (HPI). This section covers the\ntasks, dataset construction process, and evaluation\npipeline of EPAG.\n3.1\nEvaluation Tasks\nAs Figure 1 demonstrates, we propose a two-tiered\nevaluation framework based on the collected HPI.\n3.1.1\nHPI-Diagnostic Guideline Comparison\nFor direct evaluation, we focus on how effectively\nthe models capture information necessary for accu-\nrate disease identification. The evaluation process\ninvolves pre-consultation simulation with a patient-\nagent exhibiting symptoms of a specific disease and\na doctor-agent, which is the subject of evaluation.\nDuring this interaction, the doctor-agent asks ques-\ntions and provides multiple options for the patient-\nagent to choose from. The HPI collected is then\ncompared against a set of diagnostic guidelines\nfor the specific disease. The diagnostic guidelines\nrepresent a collection of essential information for\ndiagnosing a particular disease, curated by human\nclinicians from trusted sources with further details\nin Section 3.2.1.\n3.1.2\nDisease Diagnosis\nFor indirect evaluation, we assess how well the\ncollected HPI supports accurate diagnoses when\nprovided to a separate diagnostic model. While\nthis is not a direct evaluation of the HPI extracted\nby LLMs, it is a crucial assessment as one of the\neventual goals of LLM pre-consultation is to assist\nin correct diagnosis and treatment.\n3.2\nDataset\nFigure 2 shows the dataset construction process.\n3.2.1\nDiagnostic Guideline\nTo evaluate whether each dialogue turn elicits\nmeaningful patient information for diagnosis, we\nconstruct a gold-label diagnostic guideline dataset.\n"}, {"page": 3, "text": "Figure 2: EPAG benchmark dataset construction process. Expert clinicians collect all possible diagnostic guidelines\nof diseases from credible clinical sources. They then filter diseases based on whether they can be reasonably\ndiagnosed through consultation alone and sufficiently common to ensure unbiased evaluation. Next, clinicians verify\nthat the disease list is comprehensive enough to serve as a generalizable evaluation set. Using the finalized list,\nsynthetic patient profiles are generated and finalized through qualitative analysis by clinicians.\nThe following steps are implemented by profes-\nsional clinicians based on credible clinical associa-\ntions and organizations in Appendix A: (1) collect\ndiagnostic guidelines with explicit references; (2-1)\nfilter diseases that are diagnosable through consul-\ntation alone, without reliance on physical exams,\nX-ray or MRI; (2-2) exclude diseases that are too\nrare. As exemplified in Appendix B, each diag-\nnostic guideline specifies key symptoms, ancillary\nsymptoms, family history, and other relevant risk\nfactors. Each feature is assigned a weight of either\nhigh or medium.\n3.2.2\nDisease\nAs our primary goal is to evaluate language mod-\nels rather than multi-modal models, we focus on\ndiseases that can be differentiated without reliance\non other examination results. Through extensive\ndiscussions with clinicians, we identify 26 such\ndiseases spanning 10 primary specialties and 22\nsecondary specialties. To ensure that the selection\nof 26 diseases provides sufficient clinical general-\nizability, clinicians classify them according to the\nInternational Classification of Diseases, 11th Revi-\nsion (ICD-11) 1. This categorization confirms that\nthe included diseases span a broad range of condi-\ntions across 10 ICD-11 chapters, as shown in Table\n3, indicating that the dataset covers a clinically di-\n1https://icd.who.int/en\nverse and representative scope of diseases that can\nbe reasonably differentiated through history-taking.\nEach disease is systematically assigned to both\nprimary and secondary specialties following estab-\nlished clinical criteria in Appendix C, reflecting the\nmultidisciplinary nature of real-world patient care.\n3.2.3\nPatient Profile\nWe generate diverse patient profiles using OpenAI\no3-mini 2. Expert clinicians then conduct a qualita-\ntive review to ensure (i) sufficient diversity across\nprofiles and (ii) adequate clinical detail to support\nrealistic patient–doctor interactions. To minimize\nbias in the synthetic dataset, we retain 20 profiles\nper disease, yielding a total of 520 profiles. Each\nprofile contains demographic and clinical informa-\ntion such as age, sex, height, weight, and relevant\nmedical history, representing realistic patient cases.\nEach patient profile is used to assign a role to the\npatient-agent, which then interacts with the doctor-\nagent, simulating realistic scenarios. A sample pro-\nfile and diversity of patient group can be found in\nTable 4 and Figure 6 respectively.\n3.3\nEvaluation Framework\nSupposing pre-consultation models that ask ques-\ntions and provide options to choose from, [Ques-\ntion, Options, Answer] triplets are utilized through-\n2https://openai.com/\n"}, {"page": 4, "text": "Model\nHPI-Diagnostic Guideline\nComparison Score\nDisease Diagnosis\nAccuracy\nNot Weighted\nWeighted\nTop-1\nTop-k\nHuman Expert\n4.35\n7.29\n68.24\n80.65\nLLMs\nGPT-4.1\n4.82\n8.12\n74.56\n83.81\nGPT-4.1-mini\n4.46\n7.64\n69.15\n81.36\nGPT-4o\n4.39\n7.59\n69.23\n81.35\nGPT-4o-mini\n4.46\n7.75\n64.62\n79.62\nClaude-3.7-Sonnet\n4.59\n8.12\n69.23\n82.31\nClaude-3.5-Sonnet\n4.62\n8.05\n72.69\n81.35\nClaude-3.5-Haiku\n4.58\n7.84\n65.38\n80.77\nPhi-3.5-mini\n3.91\n6.88\n61.82\n78.84\nLlama-3.2-3B\n3.87\n6.8\n58.14\n72.09\nQwen2.5-7B\n3.74\n6.51\n58.46\n76.54\nMedgemma-4B \u001a\n4.19\n7.22\n65.93\n82.31\nTable 1: HPI–diagnostic guideline comparison scores\nand disease diagnosis accuracies for eleven models,\nalongside a human expert baseline, over five-turn di-\nalogues. Results exceeding the human baseline are\nshaded in blue, and those below in red. Stethoscope\n(\u001a) denotes the medically fine-tuned model.\nout evaluation.\n3.3.1\nHPI-Diagnostic Guideline Comparison\nScore\n(1) Response Generation\nThe doctor-agent is provided with the chief com-\nplaint and basic information, including age, sex,\nheight, weight, then generates questions and op-\ntions. The patient-agent is provided with the full\npatient profile, and asked to select the appropriate\noption with the prompt in Table 5. This process is\niterated for n times.\n(2) Organization\nAfter n turns of pre-consultation, the [Question, Op-\ntions, Answer] triplets are organized into individual\nunits, each representing a single piece of clinical in-\nformation, by an organizer model, using the prompt\nin Table 6. This step is crucial because, in the next\nphase, we compare each unit against pre-defined\ndiagnostic guidelines to assess whether it matches\nany. Since a single [Question, Options, Answer]\ntriplet may contain multiple pieces of information,\nseparating them into individual units ensures more\naccurate comparison. For example:\nQuestion: Are there any other symptoms\nthat occur with chest tightness?\nOptions: Shortness of breath or difficulty\nbreathing, A feeling of a racing heart, Cold\nsweats, Dizziness, Vomiting or nausea\nAnswer: Shortness of breath or difficulty\nbreathing\nThe number of organized units should be five,\nnot one: (1) Patient has shortness of breath or diffi-\nculty breathing, (2) Patient does not have a racing\nheart, (3) nor cold sweats, (4) nor dizziness, (5)\nnor vomiting or nausea. In differential diagnosis,\nthe absence of symptoms is as significant as their\npresence, so the unselected options are treated as\nseparate units. Additionally, to avoid duplicating\nscores for redundant questions, we deduplicate the\ninformation extracted during the organization step.\nAn example is provided in Appendix D.\n(3) Comparison\nNext, we use a comparer model with the prompt in\nTable 7 to match each unit with the most relevant\ndiagnostic guideline. If a unit does not match any\nof the guidelines, the comparer model is instructed\nto respond with \"None of Above.\" As illustrated\nin Figure 1, for each of the m units, the comparer\nperforms the comparison process.\n(4) Score Calculation\nThe final score for the pre-consultation dialogue\nis calculated by awarding 1 point if the unit cor-\nresponds to a guideline and 0 point for \"None of\nAbove.\" Since some diagnostic guidelines may be\nmore influential in diagnosing or ruling out certain\ndiseases than others, we also compute a weighted\nscore. Human expert clinicians assign each guide-\nline a significance level of medium or high, as\nshown in Appendix B. A unit corresponding to a\nmedium-significance guideline earns 1 point, while\na high-significance guideline earns 2 points. Both\nversions of the score are calculated for each patient\nand averaged across 520 datasets to determine the\nfinal score for each doctor-agent.\nTo verify the reliability of our evaluation\npipeline, we conduct a human comparison. For\neach disease, one is randomly sampled for each\ndisease and evaluated by a human clinician using\nthe same pipeline. After performing an F-test (p >\n0.05) to ensure equal variances, a T-test confirms\nthat the two sets of scores are statistically similar\n(p > 0.05).\n3.3.2\nDisease Diagnosis Accuracy\nFor indirect evaluation of the pre-consultation dia-\nlogue, we use an independent diagnostician-agent\nwith the prompt in Table 8. To account for multiple\nnames for the same disease, we consider the pre-\ndiction correct if the model identifies a parent or\nchild concept of the gold label disease. We employ\nan evaluator model using the prompt in Table 9 to\ndetermine if the predicted disease matches the gold\nlabel.\n"}, {"page": 5, "text": "Figure 3: Performance of Qwen-2.5 models (7B, 32B,\n72B) before (grey) and after (blue) SFT. Red horizon-\ntal line marks human clinician performance, and blue\nmarks GPT-4.1 performance—the strongest model.\n4\nExperiments\nWe evaluate eleven models as the doctor-agent, in-\ncluding four from OpenAI 3, three from Anthropic\n4, and four open-source LLMs, one of which is med-\nically fine-tuned, and compare their performance to\na human baseline. For the human baseline, human\nclinicians go through the same pre-consultation\nprocess as the doctor-agents, while the rest of the\npipeline remains unchanged. Figure 8 shows the\nuser interface used by human clinicians. The result-\ning pre-consultation dialogues are then evaluated\nusing our proposed pipeline. In this experiment, all\nother components in the pipeline use GPT-4o-mini,\nwith distinct prompts assigned to each role (patient,\norganizer, comparer, diagnostician, evaluator). To\nensure reproducibility, we fix the random seed and\nset the temperature of each agent to 0. The only\nvariable is the doctor-agent model.\n5\nResult and Analysis\nAs shown in Table 1, in five turn dialogues, GPT-4.1\nattains the highest performance across all metrics,\ntying with Claude-3.7-Sonnet on the weighted HPI-\ndiagnostic guideline comparison score. Qwen2.5-\n7B and Llama-3.2-3B perform worst overall. The\nhuman baseline places above all open-source mod-\nels, but below every proprietary LLM. Contrary\nto our intuition that medical fine-tuning would\nelicit decent performance, Medgemma-4B under-\nperforms the human baseline. A plausible explana-\n3https://openai.com/\n4https://www.anthropic.com/\ntion is that Medgemma-4B is fine-tuned primarily\non existing medical tasks, which may have weak-\nened its instruction-following ability on unseen\ntasks like pre-consultation. We conduct a series\nof additional experiments, providing several impor-\ntant takeaways.\nModel size does not guarantee performance.\nLarger or more expensive models are expected\nto outperform their smaller counterparts across\nmost tasks. This holds true in the GPT-4.1 family,\nwhere GPT-4.1 exceeds GPT-4.1-mini on all four\nmetrics. However, GPT-4o-mini outperforms GPT-\n4o on HPI-diagnostic guideline comparison score.\nMoreover, Claude-3.5-Sonnet outperforms Claude-\n3.7-Sonnet, the most expensive model, on the un-\nweighted score and Top-1 accuracy. Although tech-\nnical reports often emphasize gains from increased\nscale, our findings suggest that this relationship\nweakens for clinical pre-consultation.\nTask-specific Fine-tuning matters.\nIf model size does not guarantee pre-consultation\nability, what does? We hypothesize that once a\nmodel’s medical knowledge surpasses a certain\nthreshold, its performance depends primarily on\nhow effectively it can leverage that knowledge\nto generate appropriate questions. This interpre-\ntation is supported by the underperformance of\nMedgemma-4B, despite its presumed advantage\nin medical knowledge. To test this, we construct\na 3k pre-consultation dialogue dataset indepen-\ndent from EPAG—generated by LLMs and rigor-\nously reviewed by clinical experts—and fine-tune\nQwen-2.5 models (7B, 32B, 72B) using LoRA (Hu\net al., 2021). Figure 3 compares each model’s per-\nformance before and after supervised fine-tuning.\nConsistent with our earlier analysis, the baseline\nmodels do not exhibit strict monotonic gains with\nsize: while Top-1 accuracy improves as model size\nincreases, the other three metrics rank as 32B <\n7B < 72B. After SFT, all models show marked\nimprovements across most metrics, with 32B bene-\nfiting the most. Although the base models fall be-\nlow both the human expert and GPT-4.1, fine-tuned\nmodels often exceed the human expert—and no-\ntably, 7B and 32B match or even surpass GPT-4.1.\nQwen2.5-72B’s slight decline in Top-k accuracy af-\nter fine-tuning possibly suggests underfitting, likely\nbecause our 3k-dialogue dataset is insufficient to\nfully optimize the largest model but more than ad-\nequate for the smallest model, making 32B the\noptimal size for this dataset. Overall, the peaking\n"}, {"page": 6, "text": "Figure 4: EPAG results across eleven models with number of dialogue turns ranging from five to nine.\nperformance of fine-tuned Qwen2.5-32B demon-\nstrates that relatively small open-source models,\nwhen trained on high-quality, task-specific data,\ncan outperform larger, more expensive models in\nspecialized applications.\nNot all HPI directly lead to correct diagnosis.\nAs shown in Figure 4, the amount of HPI increases\nwith the number of dialogue turns, while diagnostic\naccuracy does not. Appendix E exemplifies why\nmore HPI does not directly correlate with accurate\ndifferential diagnosis. If a model fixates on certain\nkeywords that are loosely connected to the correct\ndiagnosis, it may ask numerous guideline-related\nbut clinically less significant questions and even\nincrease the likelihood of misdiagnosis.\nLanguage affects dialogue patterns.\nWith the prior experiments done in Korean, we ex-\nplore whether the used language makes any differ-\nence by comparing English and Korean dialogues\nwith Qwen 2.5 models (7B, 32B, 72B). We hypoth-\nesize that English pre-consultations would yield\nstronger performance as the English training cor-\npus is understood to be much larger than Korean.\nSurprisingly, Figure 5 shows that Korean dialogues\nproduce higher HPI-diagnostic guideline compar-\nison scores, while English dialogues achieve su-\nperior disease diagnosis accuracy. A qualitative\nreview explains this enigma: in English, the model\nfrequently pursues deep, repetitive follow-ups on a\nsingle symptom—enhancing diagnostic confidence\nbut generating fewer unique atomic units. By con-\ntrast, in Korean sessions it casts a wider net, query-\ning a broader array of symptoms, which boosts HPI\nscores but dilutes focus and can introduce multiple\ndiagnostic possibilities. This behavior aligns with\nour earlier finding that not all HPI directly lead to\ncorrect diagnosis.\nFigure 5: Performance of Qwen-2.5 models (7B, 32B,\n72B) on Korean (grey) versus English (green) dialogues.\n6\nConclusion\nWe present EPAG, a benchmark dataset and auto-\nmated pipeline for Evaluating the Pre-consultation\nAbility of LLMs using diagnostic Guidelines. Ex-\nperiments show that model size does not guaran-\ntee performance, and not all extracted HPI con-\ntribute directly to diagnosis, highlighting the need\nfor future research to quantify the impact of each\nHPI component on specific diagnosis and refine\npre-consultation models. Additional studies demon-\nstrate that smaller open-source LLMs can surpass\nlarger proprietary models when fine-tuned with\nhigh-quality data, and that the language used during\npre-consultation shapes dialogue characteristics.\nLimitation and Future Work\nThe EPAG benchmark dataset includes 26 diseases\nacross 10 ICD-11 chapters but focuses solely on\ntext-based pre-consultation models, excluding dis-\neases that require physical test results, such as X-\n"}, {"page": 7, "text": "rays, or MRIs, which are more common in real-\nworld settings. Therefore, future work should incor-\nporate multi-modal evaluation of pre-consultation\nmodels to process inputs beyond text, including\nmedical images.\nEthics Statement\nWhile our proposed evaluation pipeline for assess-\ning the pre-consultation abilities of LLMs demon-\nstrates a high correlation with human evaluation, it\nhas limitations and does not cover all disease cate-\ngories. As such, the experimental results presented\nin this paper should not be considered definitive.\nThe selection of a model for any specific clinical\napplication should involve thorough assessment be-\nfore being deployed in practice.\nReferences\nAbdul Basit, Khizar Hussain, Muhammad Abdullah\nHanif, and Muhammad Shafique. 2024. Medaide:\nLeveraging large language models for on-premise\nmedical assistance on edge devices.\nSuhana Bedi, Yutong Liu, Lucy Orr-Ewing, Dev Dash,\nSanmi Koyejo, Alison Callahan, Jason A Fries,\nMichael Wornow, Akshay Swaminathan, Lisa So-\nleymani Lehmann, et al. 2024. A systematic review\nof testing and evaluation of healthcare applications\nof large language models (llms). medRxiv, pages\n2024–04.\nBalu Bhasuran, Qiao Jin, Yuzhang Xie, Carl Yang,\nKarim Hanna, Jennifer Costa, Cindy Shavor, Wen-\nshan Han, Zhiyong Lu, and Zhe He. 2025. Prelim-\ninary analysis of the impact of lab results on large\nlanguage model generated differential diagnoses. npj\nDigital Medicine, 8(1):166.\nXiaolan Chen, Jiayang Xiang, Shanfu Lu, Yexin Liu,\nMingguang He, and Danli Shi. 2024. Evaluating\nlarge language models in medical applications: a sur-\nvey. arXiv preprint arXiv:2405.07468.\nJulien Delaunay and Jordi Cusido. 2024. Evaluating the\nperformance of large language models in predicting\ndiagnostics for spanish clinical cases in cardiology.\nApplied Sciences, 15(1):61.\nDennis Fast, Lisa C. Adams, Felix Busch, Conor Fallon,\nMarc Huppertz, Robert Siepmann, Philipp Prucker,\nNadine Bayerl, Daniel Truhn, Marcus Makowski,\nAlexander Löser, and Keno K. Bressem.\nAu-\ntonomous medical evaluation for guideline adherence\nof large language models. npj Digital Medicine, 7.\nFarieda Gaber, Maqsood Shaik, Fabio Allega, Agnes Ju-\nlia Bilecz, Felix Busch, Kelsey Goon, Vedran Franke,\nand Altuna Akalin. 2025.\nEvaluating large lan-\nguage model workflows in clinical decision support\nfor triage and referral and diagnosis. npj Digital\nMedicine, 8(1):263.\nAkash Ghosh, Arkadeep Acharya, Raghav Jain, Sri-\nparna Saha, Aman Chadha, and Setu Sinha. 2024.\nClipsyntel: clip and llm synergy for multimodal ques-\ntion summarization in healthcare. In Proceedings of\nthe AAAI Conference on Artificial Intelligence, vol-\nume 38, pages 22031–22039.\nRuihui Hou, Shencheng Chen, Yongqi Fan, Guangya\nYu, Lifeng Zhu, Jing Sun, Jingping Liu, and Tong\nRuan. 2024. Msdiagnosis: A benchmark for eval-\nuating large language models in multi-step clinical\ndiagnosis.\nEdward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan\nAllen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and\nWeizhu Chen. 2021. Lora: Low-rank adaptation of\nlarge language models.\nQiao Jin, Bhuwan Dhingra, Zhengping Liu, William Co-\nhen, and Xinghua Lu. 2019. PubMedQA: A dataset\nfor biomedical research question answering. In Pro-\nceedings of the 2019 Conference on Empirical Meth-\nods in Natural Language Processing and the 9th In-\nternational Joint Conference on Natural Language\nProcessing (EMNLP-IJCNLP), pages 2567–2577,\nHong Kong, China. Association for Computational\nLinguistics.\nShreya Johri, Jaehwan Jeong, Benjamin A. Tran,\nDaniel I. Schlessinger, Shannon Wongvibulsin, Lean-\ndra A. Barnes, Hong-Yu Zhou, Zhou Ran Cai, et al.\n2025. An evaluation framework for conversational\nreasoning in clinical llms during patient interactions.\nNature Medicine.\nPraveen K Kanithi, Clément Christophe, Marco AF Pi-\nmentel, Tathagata Raha, Nada Saadi, Hamza Javed,\nSvetlana Maslenkova, Nasir Hayat, Ronnie Rajan,\nand Shadab Khan. 2024. Medic: Towards a com-\nprehensive framework for evaluating llms in clinical\napplications.\nMirae Kim, Kyubum Hwang, Hayoung Oh, Min Ah\nKim, Chaerim Park, Yehwi Park, and Chungyeon\nLee. 2024. MILD bot: Multidisciplinary childhood\ncancer survivor question-answering bot. In Proceed-\nings of the 2024 Conference on Empirical Methods in\nNatural Language Processing: Industry Track, pages\n665–676, Miami, Florida, US. Association for Com-\nputational Linguistics.\nYubin Kim, Hyewon Jeong, Shan Chen, Shuyue Stella\nLi, Mingyu Lu, Kumail Alhamoud, Jimin Mun,\nCristina Grau, Minseok Jung, Rodrigo Gameiro,\nLizhou Fan, Eugene Park, Tristan Lin, Joonsik Yoon,\nWonjin Yoon, Maarten Sap, Yulia Tsvetkov, Paul\nLiang, Xuhai Xu, Xin Liu, Daniel McDuff, Hyeon-\nhoon Lee, Hae Won Park, Samir Tulebaev, and Cyn-\nthia Breazeal. 2025. Medical hallucinations in foun-\ndation models and their impact on healthcare.\n"}, {"page": 8, "text": "Gleb Kumichev, Pavel Blinov, Yulia Kuzkina, Vasily\nGoncharov, Galina Zubkova, Nikolai Zenovkin,\nAleksei Goncharov, and Andrey Savchenko. 2024.\nMedsyn: Llm-based synthetic medical text gener-\nation framework.\nIn Joint European Conference\non Machine Learning and Knowledge Discovery in\nDatabases, pages 215–230. Springer.\nSunjun Kweon, Byungjin Choi, Gyouk Chu, Junyeong\nSong, Daeun Hyeon, Sujin Gan, Jueon Kim, Minkyu\nKim, Rae Woong Park, and Edward Choi. 2024. Ko-\nrmedmcqa: Multi-choice question answering bench-\nmark for korean healthcare professional licensing\nexaminations.\nBrenna Li, Ofek Gross, Noah Crampton, Mamta Kapoor,\nSaba Tauseef, Mohit Jain, Khai N Truong, and Alex\nMariakakis. 2024. Beyond the waiting room: Pa-\ntient’s perspectives on the conversational nuances\nof pre-consultation chatbots. In Proceedings of the\n2024 CHI Conference on Human Factors in Comput-\ning Systems, pages 1–24.\nYunxiang Li, Zihan Li, Kai Zhang, Ruilong Dan, Steve\nJiang, and You Zhang. 2023. Chatdoctor: A medical\nchat model fine-tuned on a large language model\nmeta-ai (llama) using medical domain knowledge.\nDaniel McDuff, Mike Schaekermann, Tao Tu, Anil\nPalepu, Amy Wang, Jake Garrison, Karan Singhal,\nYash Sharma, Shekoofeh Azizi, Kavita Kulkarni,\nLe Hou, Yong Cheng, Yun Liu, S Sara Mahdavi,\nSushant Prakash, Anupam Pathak, Christopher Sem-\nturs, Shwetak Patel, Dale R Webster, Ewa Domi-\nnowska, Juraj Gottweis, Joelle Barral, Katherine\nChou, Greg S Corrado, Yossi Matias, Jake Sunshine,\nAlan Karthikesalingam, and Vivek Natarajan. 2023.\nTowards accurate differential diagnosis with large\nlanguage models.\nAnkit Pal, Logesh Kumar Umapathi, and Malaikannan\nSankarasubbu. 2022. Medmcqa : A large-scale multi-\nsubject multi-choice dataset for medical domain ques-\ntion answering.\nAnkit Pal, Logesh Kumar Umapathi, and Malaikannan\nSankarasubbu. 2023. Med-halt: Medical domain hal-\nlucination test for large language models.\nHan Qian, Bin Dong, Jia-jun Yuan, Fan Yin, Zhao Wang,\nHai-ning Wang, Han-song Wang, Dan Tian, Wei-hua\nLi, Bin Zhang, et al. 2021. Pre-consultation system\nbased on the artificial intelligence has a better diag-\nnostic performance than the physicians in the outpa-\ntient department of pediatrics. Frontiers in Medicine,\n8:695185.\nJustin T Reese, Leonardo Chimirri, Yasemin Bridges,\nDaniel Danis, J Harry Caufield, Michael A Gargano,\nCarlo Kroll, Andrew Schmeder, Fengchen Liu, Kyran\nWissink, et al. 2025.\nSystematic benchmarking\ndemonstrates large language models have not reached\nthe diagnostic accuracy of traditional rare-disease de-\ncision support tools. medRxiv, pages 2024–07.\nMANA SAMIEE. General practitioners’ perspectives\non llm chatbots for shared decision-making.\nPeter Sarvari and Zaid Al-Fagih. 2025. Rapidly bench-\nmarking large language models for diagnosing co-\nmorbid patients: comparative study leveraging the\nllm-as-a-judge method. JMIRx Med, 6:e67661.\nXiaoming Shi, Jie Xu, Jinru Ding, Jiali Pang, Sichen\nLiu, Shuqing Luo, Xingwei Peng, Lu Lu, Haihong\nYang, Mingtao Hu, Tong Ruan, and Shaoting Zhang.\n2023. Llm-mini-cex: Automatic evaluation of large\nlanguage model for diagnostic conversation.\nKaran Singhal, Tao Tu, Juraj Gottweis, Rory Sayres,\nEllery Wulczyn, Le Hou, Kevin Clark, Stephen Pfohl,\nHeather Cole-Lewis, Darlene Neal, Mike Schaeker-\nmann, Amy Wang, Mohamed Amin, Sami Lachgar,\nPhilip Mansfield, Sushant Prakash, Bradley Green,\nEwa Dominowska, Blaise Aguera y Arcas, Nenad\nTomasev, Yun Liu, Renee Wong, Christopher Sem-\nturs, S. Sara Mahdavi, Joelle Barral, Dale Webster,\nGreg S. Corrado, Yossi Matias, Shekoofeh Azizi,\nAlan Karthikesalingam, and Vivek Natarajan. 2023.\nTowards expert-level medical question answering\nwith large language models.\nYang Tan, Zhixing Zhang, Mingchen Li, Fei Pan, Hao\nDuan, Zijie Huang, Hua Deng, Zhuohang Yu, Chen\nYang, Guoyang Shen, et al. 2024. Medchatzh: A tun-\ning llm for traditional chinese medicine consultations.\nComputers in biology and medicine, 172:108290.\nArun James Thirunavukarasu, Darren Shu Jeng Ting,\nKabilan Elangovan, Laura Gutierrez, Ting Fang Tan,\nand Daniel Shu Wei Ting. 2023. Large language\nmodels in medicine. Nature medicine, 29(8):1930–\n1940.\nTao Tu, Anil Palepu, Mike Schaekermann, Khaled Saab,\nJan Freyberg, Ryutaro Tanno, Amy Wang, Brenna Li,\nMohamed Amin, Nenad Tomasev, Shekoofeh Azizi,\nKaran Singhal, Yong Cheng, Le Hou, Albert Web-\nson, Kavita Kulkarni, S Sara Mahdavi, Christopher\nSemturs, Juraj Gottweis, Joelle Barral, Katherine\nChou, Greg S Corrado, Yossi Matias, Alan Karthike-\nsalingam, and Vivek Natarajan. 2024. Towards con-\nversational diagnostic ai.\nEhsan Ullah, Anil Parwani, Mirza Mansoor Baig, and\nRajendra Singh. 2024. Challenges and barriers of\nusing large language models (llm) such as chat-\ngpt for diagnostic medicine with a focus on digi-\ntal pathology–a recent scoping review. Diagnostic\npathology, 19(1):43.\nEthan Waisberg, Joshua Ong, Mouayad Masalkhi, and\nAndrew G Lee. 2024. Large language model (llm)-\ndriven chatbots for neuro-ophthalmic medical educa-\ntion. Eye, 38(4):639–641.\nCai Wang, Qian Chen, Weizi Shao, and Xiaofeng\nHe. 2024.\nKemedgpt: Intelligent medical pre-\nconsultation with knowledge-enhanced large lan-\nguage model.\nIn 2024 IEEE International Con-\nference on Medical Artificial Intelligence (MedAI),\npages 386–391.\n"}, {"page": 9, "text": "Wenxuan Wang, Zizhan Ma, Zheng Wang, Chenghan\nWu, Wenting Chen, Xiang Li, and Yixuan Yuan. 2025.\nA survey of llm-based agents in medicine: How far\nare we from baymax?\nIsabella C Wiest, Marie-Elisabeth Leßmann, Fabian\nWolf, Dyke Ferber, Marko Van Treeck, Jiefu Zhu,\nMatthias P Ebert, Christoph Benedikt Westphalen,\nMartin Wermke, and Jakob Nikolas Kather. 2024.\nAnonymizing medical documents with local, pri-\nvacy preserving large language models: The llm-\nanonymizer. medRxiv, pages 2024–06.\nCaleb Winston, Cleah Winston, Claris Winston, and\nChloe Winston. Medical question-generation for pre-\nconsultation with llm in-context learning. In GenAI\nfor Health: Potential, Trust and Policy Compliance.\nHe Yang, Fei Wang, Matthew Greenblatt, Sharon Huang,\nand Yi Zhang. 2023a. Ai chatbots in clinical labo-\nratory medicine: Foundations and trends. Clinical\nchemistry, 69.\nRui Yang, Ting Tan, Wei Lu, Arun Thirunavukarasu,\nDaniel Ting, and Nan Liu. 2023b. Large language\nmodels in health care: Development, applications,\nand challenges. Health Care Science, 2.\nHongbo Zhang, Junying Chen, Feng Jiang, Fei Yu,\nZhihong Chen, Guiming Chen, Jianquan Li, Xi-\nangbo Wu, Zhang Zhiyi, Qingying Xiao, Xiang Wan,\nBenyou Wang, and Haizhou Li. 2023. HuatuoGPT,\ntowards taming language model to be a doctor. In\nFindings of the Association for Computational Lin-\nguistics: EMNLP 2023, pages 10859–10885, Singa-\npore. Association for Computational Linguistics.\nKai Zhang, Yangyang Kang, Fubang Zhao, and Xi-\naozhong Liu. 2024. Llm-based medical assistant\npersonalization with short- and long-term memory\ncoordination.\nHongjian Zhou, Fenglin Liu, Boyang Gu, Xinyu Zou,\nJinfa Huang, Jinge Wu, Yiru Li, Sam S. Chen, Peilin\nZhou, Junling Liu, Yining Hua, Chengfeng Mao,\nChenyu You, Xian Wu, Yefeng Zheng, Lei Clifton,\nZheng Li, Jiebo Luo, and David A. Clifton. 2024. A\nsurvey of large language models in medicine: Princi-\nples, applications, and challenges.\nYakun Zhu, Zhongzhen Huang, Linjie Mu, Yutong\nHuang, Wei Nie, Jiaji Liu, Shaoting Zhang, Pengfei\nLiu, and Xiaofan Zhang. 2025.\nDiagnosisarena:\nBenchmarking diagnostic reasoning for large lan-\nguage models.\nA\nSource of Diagnostic Guidelines\n• Cardiology: American College of Cardiology\n5, American Heart Association 6\n• Oncology: National Comprehensive Cancer\nNetwork 7\n• Stroke: American Heart Association, Ameri-\ncan Stroke Association 8\n• Allergy & Immunology: Joint Task Force for\nPractice Parameters 9, American Academy of\nAllergy Asthma & Immunology 10, American\nCollege of Allergy Asthma and Immunology\n11\n• Gastroenterology: American Gastroenterolog-\nical Association Homepage 12\n• HIV/AIDS: U.S. Preventive Services Task\nForce 13\n• Pulmonology: Global Initiative for Chronic\nObstructive Lung Disease 14, Global Initiative\nfor Asthma 15\n• Nephrology: Improving Global Outcomes 16\n• Diabetes: American Diabetes Association 17\n• General Surgery: American College of Sur-\ngeons 18\n• Rheumatology: European League Against\nRheumatism 19\n• Endocrinology: American Association of\nClinical Endocrinologists 20\n5https://www.acc.org/\n6https://www.heart.org/\n7https://www.nccn.org/\n8https://www.stroke.org/en/\n9https://www.aaaai.org/allergist-resources/statements-\npractice-parameters/practice-parameters-guidelines\n10https://www.aaaai.org/\n11https://acaai.org/\n12https://gastro.org/\n13https://www.uspreventiveservicestaskforce.org/uspstf/\n14https://goldcopd.org/\n15https://ginasthma.org/\n16https://kdigo.org/\n17https://diabetes.org/\n18https://www.facs.org/\n19https://www.eular.org/\n20https://www.aace.com/\n"}, {"page": 10, "text": "B\nDiagnostic Guideline Example\nWeight\nFeature\nhigh\nPalpable Breast Lump\nhigh\nNipple Discharge, Bloody or Spontaneous\nhigh\nSkin Changes: Peau d’orange, Ulceration, Erythema, Thickening\nhigh\nNew-Onset Nipple Inversion/Retraction\nhigh\nAxillary Masses/Lymphadenopathy\nmedium\nAsymmetry in Breast Size/Shape, New Onset\nmedium\nNipple/Areolar Eczema or Itching\nmedium\nLocalized Thickening or Induration\nmedium\nSystemic Symptoms: Weight Loss, Fatigue, Night Sweats, Fever\nmedium\nPregnancy/Lactation-Related Abnormalities\nmedium\nPost-Surgical or Post-Radiation Breast Changes\nhigh\nFamily History of Breast Cancer, BRCA Mutation\nhigh\nGenetic Predisposition: BRCA1/BRCA2, TP53, PALB2 etc.\nhigh\nPrior Biopsy with Atypia or LCIS/ADH\nmedium\nHormonal Factors: Early Menarche, Late Menopause, HRT Use\nhigh\nPrior Chest Radiation Therapy, esp. 10∼30 y/o\nTable 2: Diagnostic guidelines for breast cancer.\nC\nDisease Categorization\nTo enhance the generalization and reliability of our\nbenchmarking system, we adopt the International\nClassification of Diseases, 11th Revision (ICD-11)\nas the main categorization of diseases. This ap-\nproach ensures comprehensive coverage across di-\nverse disease groups. For better alignment with\nreal-world clinical decision-making we assign each\ndisease to a Primary Specialty and, where applica-\nble, one or more Secondary Specialties.\nC.1\nPrimary Specialty Selection Criteria\nEach disease is assigned to a Primary Specialty,\nthe leading specialty responsible for the disease’s\nmanagement, based on the following:\n1. ICD-11 Disease Classification:\n• Each disease is mapped to its correspond-\ning ICD-11 chapter, which indicates the\nmajor body system or disease category it\nbelongs to.\n• The specialty most commonly responsi-\nble for managing diseases in each chapter\nis assigned as the Primary Specialty.\n2. International Clinical Guidelines: The Pri-\nmary Specialty is further validated using well\nestablished medical guidelines from globally\nrecognized organizations listed in Appendix\nA.\n3. Standard Medical Practice: The most com-\nmonly designated department responsible for\nmanaging the disease in hospitals and health-\ncare settings is selected.\nC.2\nSecondary Specialty Selection Criteria\nMany diseases require collaboration across multi-\nple specialties. A Secondary Specialty, additional\nspecialties that frequently contribute to diagno-\nsis, treatment, or complication management, is as-\nsigned in cases where:\n1. Multidisciplinary care is essential.\n• Conditions which require involvement\nfrom multiple specialties for optimal\nmanagement.\n• Example: Stroke (8B20)\n– Primary: Neurology (acute treatment\nand long-term management)\n– Secondary: Cardiology (stroke pre-\nvention in atrial fibrillation), Rehabil-\nitation Medicine (post-stroke recov-\nery)\n2. Complication management is required.\n• Specialties involved in managing compli-\ncations related to the primary disease.\n• Example: Diabetes (5A14)\n– Primary: Endocrinology (blood sugar\ncontrol, metabolic regulation)\n– Secondary: Nephrology (diabetic\nnephropathy), Cardiology (cardiovas-\ncular risk)\n3. Surgical vs. Non-Surgical considerations.\n• Conditions where both medical and sur-\ngical specialties play a role.\n• Example: Colorectal Cancer (2B91)\n– Primary: Oncology (chemotherapy\nand cancer management)\n– Secondary: Gastroenterology (diag-\nnosis via colonoscopy), General\nSurgery (surgical treatment)\nBy structuring disease classification based on\nthese criteria, we ensure that our benchmark\nsystem accurately represents real-world clini-\ncal workflows and enhances the applicability\nof AI-driven medical decision support tools.\nD\nOrganized Unit Example\nMain Symptom:\nI keep coughing and have difficulty breathing.\n"}, {"page": 11, "text": "D.1\n[Question, Options, Answer] Triplet\nQuestion: When you cough, do you produce any\nsputum?\nOptions: Dry cough with no sputum, White or\nclear sputum, Yellow or green sputum, Red or\nbrown sputum\nAnswer: White or clear sputum\nQuestion: When is your difficulty breathing\nworse?\nOptions: I have difficulty breathing even when\nI am at rest, I have difficulty breathing when\nwalking on flat ground, I have difficulty breathing\nwhen climbing stairs or going uphill, I only have\ndifficulty breathing when I move quickly or\nexercise\nAnswer: I have difficulty breathing when walking\non flat ground\nQuestion: How long have you had the coughing\nand difficulty breathing symptoms?\nOptions: Less than 2 weeks, 2 weeks to 3 months,\n3 months to 6 months, More than 6 months\nAnswer: More than 6 months\nQuestion: Do you smoke?\nOptions: I currently smoke, I used to smoke but\nquit, I have never smoked, I am often exposed to\nsecondhand smoke\nAnswer: I currently smoke\nQuestion: Do you have any symptoms while\nsleeping?\nOptions: I wake up because I can’t breathe, I can’t\nsleep due to severe coughing, I need more than one\npillow to breathe properly, I snore a lot, I sleep\nwithout any special symptoms\nAnswer: I wake up because I can’t breathe\nD.2\nOrganized Units\n• White or clear sputum is produced when\ncoughing.\n• The difficulty in breathing worsens when\nwalking on flat ground.\n• The coughing and difficulty in breathing\nsymptoms have lasted more than 6 months.\n• I currently smoke.\n• I wake up during sleep because I can’t breathe.\nE\nAnalysis\nThe following case involves a patient expected to be\ndiagnosed with Acute Kidney Injury. MedGemma-\n4B is used as the doctor agent model.\nChief Complaint: Decreased urine output and flank pain.\nHPI from 5-turn dialogue\nThere is pain in the right flank.\nThe amount of urine has decreased.\nRecently had symptoms of a cold.\nTakes antihypertensive medication regularly.\nNo history of urinary stones.\nDiagnosis: Acute Kidney Injury (correct)\nHPI from 6-turn dialogue\nThere is pain in the right flank.\nThe amount of urine has decreased.\nRecently had symptoms of a cold.\nTakes antihypertensive medication regularly.\nNo history of urinary stones.\nThe flank pain is severe, rated 7 out of 10 in intensity. (Added)\nDiagnosis: Renal Colic due to Urinary Stone (incorrect)\nAlthough both Acute Kidney Injury and Renal Colic\ncan present with flank pain, the additional 6th turn\nprovides patient information about the intensity\nof pain, which may have shifted the model’s di-\nagnostic focus away from other relevant symp-\ntomatic information. Renal Colic typically results\nfrom urinary stone, leading to severe pain. In this\ncase, highlighting the severity of flank pain may\nhave caused the model to prioritize pain-centric\nreasoning, which misled the differential diagnosis\ntoward Renal Colic. While the additional informa-\ntion (pain intensity) is clinically relevant and could\naid a physician’s understanding, it may have inad-\nvertently diverted the model’s diagnostic focus.\n"}, {"page": 12, "text": "ICD-11 Chapter\nDisease\nICD-11 Code\nPrimary Specialty\nSecondary Specialty\nNeoplasms\nBreast Cancer\n2E65\nOncology\nGeneral Surgery\nProstate Cancer\n2C82\nOncology\nUrology\nColorectal Cancer\n2B91\nOncology\nGastroenterology,\nGeneral Surgery\nLung Cancer\n2C25\nOncology\nPulmonology,\nThoracic Surgery\nGastric Cancer\n2B72\nOncology\nGastroenterology,\nGeneral Surgery\nDiseases of the\nCirculatory System\nHypertrophic Cardiomyopathy\nBC43.1\nCardiology\nMedical Genetics\nPeripheral Artery Disease\nBD4Z\nCardiology\nVascular Surgery\nAtrial Fibrillation\nBC81.3\nCardiology\nNeurology\n(Stroke Risk),\nInternal Medicine\nHeart Failure\nBD1Z\nCardiology\nEndocrinology\n(Diabetes-related)\nDiseases of the\nNervous System\nStroke\n8B20\nNeurology\nCardiology,\nRehabilitation Medicine\nAneurysmal Subarachnoid\nHaemorrhage\n8B01.0\nNeurology\nNeurosurgery,\nEmergency Medicine\nDiseases of the\nImmune System\nAnaphylaxis\n4A84\nAllergy & Immunology\nEmergency Medicine\nSystemic Sclerosis\n4A42\nRheumatology\nPulmonology\n(Lung fibrosis),\nCardiology\n(Cardiac involvement)\nSystemic Lupus\nErythematosus\n4A40.0\nRheumatology\nNephrology\n(Lupus Nephritis),\nCardiology\n(Vascular Complications)\nDiseases of the\nSkin\nAtopic Dermatitis\nEA80\nAllergy & Immunology\nDermatology\nDiseases of the\nDigestive System\nUlcerative Colitis\nDD71\nGastroenterology\nRheumatology\n(Autoimmune-related)\nNonalcoholic Fatty\nLiver Disease\nDB92.Z\nGastroenterology\nEndocrinology\n(Metabolic Syndrome)\nIrritable Bowel Syndrome\nwith Constipation (IBS-C)\nDD91.00\nGastroenterology\nPsychiatry\n(Stress-related IBS)\nAcute Pancreatitis\nDC31\nGastroenterology\nGeneral Surgery\nCertain Infectious\nor\nParasitic Diseases\nHuman Immunodeficiency\nVirus (HIV) Infection\n1C62\nInfectious Diseases\nImmunology\nDiseases of the\nRespiratory System\nChronic Obstructive\nPulmonary Disease\nCA22\nPulmonology\nInternal Medicine\nAsthma\nCA23\nPulmonology\nAllergy & Immunology\nAllergic Rhinitis\nCA08.0\nAllergy & Immunology\nOtorhinolaryngology,\nPulmonology\nDiseases of the\nGenitourinary System\nAcute Kidney Injury\nGB60\nNephrology\nCritical Care Medicine\nEndocrine, Nutritional\nor\nMetabolic Diseases\nDiabetes Mellitus\n5A14\nEndocrinology\nNephrology\n(Diabetes-related\nKidney Disease)\nHypothyroidism\n5A00\nEndocrinology\nCardiology\n(Atrial Fibrillation Risk),\nPsychiatry\n(Depression Link)\nTable 3: List of 26 diseases consisting EPAG benchmark. Detailed classification of diseases including ICD-11\nChapter, ICD-11 Code, Primary Specialty, and Secondary Specialty are provided.\n"}, {"page": 13, "text": "Patient Profile\nDisease Name\nBreast Cancer\nTypicality\nNormal\nBasic Information\nAge\n51\nSex\nFemale\nHeight\n162cm\nWeight\n62kg\nHistory of Present Illness\nLocation\nLeft breast and adjacent axillary region\nQuality\nFirm, irregular mass\nSeverity\n4/10 (Mild pain but significant anxiety)\nDuration\nApproximately 3 months\nTiming\nSlight variations with menstrual cycle, discovered accidentally during routine examination\nContext\nDetected by the patient herself during a routine breast examination\nModifying Factors\nSlight reduction in swelling post-menstruation, no specific alleviating factors\nAssociated Signs and Symptoms\nMild nipple discharge, slight fatigue, minimal pain\nAdditional Information\nFamily History\nNo family history of breast cancer or similar cancers\nPrevious Surgery or Illness\nNo previous history of breast-related surgery or conditions\nLifestyle Changes\nNo recent changes in lifestyle; the patient aims for early detection through screening\nHealth Check-ups\nRegularly undergoes women’s health check-ups\nPain Area\nLeft chest (pectoral region)\nLeft anterior acromio-clavicular region\nPast Medical History\nNo history of breast diseases\nNo other chronic illnesses\nSocial History\nOffice worker, full-time\nNon-smoker, drinks alcohol 1-2 times per week\nRegular health check-ups and breast self-examination\nChief Complaint\nA firm lump in the left chest, causing anxiety\nTable 4: Sample patient profile with breast cancer.\nFigure 6: Distribution of age group, BMI category, smoking status, exercise level of patients for each disease.\n"}, {"page": 14, "text": "Original\n당신은아래와같은프로필을가진환자입니다.\n{patient_information}\n적절한진단을위해의사의문진에충실히대답해야합니다. 의사가제시한질문지중한가지를골라대답하세요.\n출력형식:\nAnswer:\nTranslated\nYou are a patient with the following profile:\n{patient_information}\nYou should faithfully answer the doctor’s inquiries for an appropriate diagnosis. Choose one of the questions provided by the doctor and respond.\nOutput format:\nAnswer:\nTable 5: Patient Agent Prompt\nOriginal\n**Prompt:**\nBelow is a set of consultation dialogues between a doctor and a patient with disease. The dialogue consists of the patient’s chief complaint, a few turns of questions, options, and answer triplets.\nThe questions and options are given by the doctor, and the answers are provided by the patient.\nYour task is to organize the dialogue in a clear, information-based manner using bullet points. Each bullet point should contain only one piece of information.\nThis structured information is essential for diagnosing the patient’s condition, so make sure to extract as much relevant information as possible.\n**Guidelines for Organizing:**\n- Do not include the main symptom in the bullet points.\nThe main symptom is just for reference and should not be summarized in bullet points.\n- Focus only on the information that can be inferred from the Question-Options-Answer triplets.\n- Each bullet point must present only one piece of information.\n- Avoid sentences with multiple clauses.\nFor example, instead of “The patient has cough and sputum,” break it down into two points:\n“The patient has a cough” and “The patient has sputum.”\n- Avoid using demonstrative pronouns (e.g., “this symptom”) and pronouns (e.g., “he/she”). Focus on the specific symptoms.\n- Organize the information from the patient’s perspective, avoiding the doctor as the subject.\n- Keep the language neutral and concise, stating only the facts shared by the patient.\n- If the question asks about additional symptoms beyond the main symptom and the answer is that no other symptoms are present,\nlist each symptom option provided in the question and state that the patient does not have each of those symptoms.\nFor example, instead of \"There are no other symptoms,\" specify each of the symptom option provided:\n\"There is no family history,\" \"There is no weight loss,\" \"There is no fever.\"\n- Be precise and specific in organizing the information.\nFor example, if a question asks about \"whether the patient has ever had any tests related to lumps or breasts,\"\nand the answer is \"No,\" do not simply write \"The patient has not had any tests.\"\nInstead, write, \"The patient has not had any tests related to lumps or breasts.\"\n**Example**:\n{examples}\n**Input**\n{input}\n**Organized Information:**\n-\nTable 6: Organizer Prompt\n"}, {"page": 15, "text": "Original\nYou are a medical/health expert. Below is a conversation between a disease patient and a doctor.\nIn this case, evaluate whether [the interview conversation (A)] effectively leads to the [key diagnostic elements (B)], which are pre-defined for specific diseases.\nHere, (B) includes not only symptoms but also important elements such as past medical history, family history, and other disease diagnoses.\nFirst, identify if (A) is relevant enough to disease and helpful in drawing out new information to diagnose disease given (H).\nIf not, output \"Irrelevant/Redundant.\"\nIf (A) is relevant to disease and helpful in drawing out new information to diagnose disease given (H),\ndetermine whether each item in (B) can be identified through the interview conversation (A).\nIf two or more (B) items can be identified from (A), output the most relevant (B) item. If no (B) items can be identified through (A), output \"None of above.\"\n<Explanation of the provided information>\n- **Dialogue History (H)**\nThis is a prior conversation between the patient and the doctor.\nIt includes the main symptom the patient reported, the questions the doctor asked to make a diagnosis, the options presented, and the patient’s answer.\nSometimes only the main symptom the patient complained about may be provided.\n- **Interview Conversation (A)**\nThis consists of the questions and options the doctor asks the patient for diagnostic purposes.\nThe patient chooses one option from the given choices to respond.\n- **Pre-defined Key Diagnostic Elements List (B)**\nExample: Persistent Cough, Hemoptysis (Coughing up Blood), Dyspnea (Shortness of Breath), Chest Pain, Unexplained Weight Loss, Family History of Lung Cancer, Smoking History, etc.\n<Important Notes>\n1. **Evaluation Criteria**\n- Check if the interview conversation (A) is designed to identify (B),\nor if it directly helps to determine specific aspects of (B) such as the onset, duration, more exact location and frequency of symptoms.\n- If (A) is related to an item in (B) but deviates from the patient disease which is disease, then output \"None of above.\"\n- Assess if the questions and options in (A) can effectively elicit relevant information related to (B) from the patient.\n2. **Output Criteria** - Provide a brief Reason for\nwhether (A) can effectively elicit (B)-related information. Do not repeat the questions and options.\n- The Reason should be up to two sentences.\n- The Final Response should be either [(B) item] or \"None of above.\" or \"Irrelevant/Redundant.\"\n- If multiple (B) items can be identified from (A), output only the one most directly related to (A).\nIf the relevance is judged to be the same, separate the related (B) items using \"[OR]\" and output them all.\n- (H) is for reference only, so the evaluation should focus on whether (A) is related to (B).\n**Example**:\n{example}\n(H):\n{h}\n(A):\n{a}\n(B):\n{b}\nReason:\nTable 7: Comparer Prompt\nOriginal\nYou are a medical expert. Given ’patient_info’ and ’medical_history’, output the suspected disease names in order of highest probability. Output your prediction in English in YAML format.\nInstructions:\n- Use only specific disease names related to the patient’s symptoms.\n- Prioritize based on main symptoms, severity, duration, and answers given in the medical history.\n- Exclude diseases that don’t match the responses or are too generic.\n- List the diseases in order of highest probability first.\n- Do not provide any extra explanation.\nOutput format:\nDiseases:\n- (probable diseases)\nTable 8: Diagnostician Agent Prompt\nOriginal\nYou are a medical expert. Given ’model_predictions’ and ’golden_standard’, decide if the predictions are correct. Output your reasoning in English in YAML format.\nInstructions:\n- Accept if the predicted disease is very similar to the actual one.\n- Accept synonyms or other expressions for the same disease.\n- Accept if the disease names include hierarchical (superior/inferior) relationships.\n- Accept medical abbreviations as equivalent to official names.\n- Allow regional/cultural expression differences.\n- If at least one prediction is correct, consider it acceptable.\nOutput format:\nReasoning: |\n(your reasoning in English)\nResult: True/False\nTable 9: Evaluator Prompt\n"}, {"page": 16, "text": "Age: 51\nSex: Male\nC.C: I keep coughing and have difficulty breathing.\nQuestion: \nWhen you cough, do you produce any sputum?\nOptions:\n  - Dry cough with no sputum\n  - White or clear sputum\n  - Yellow or green sputum\n  - Red or brown sputum\nAnswer:\nWhite or clear sputum\nDiagnostic Guideline for Asthma\nWeight\nSymptom\n...\nShortness of Breath, Dyspnea\nCough\nChest Tightness\nAbnormal Breath Sounds\nAllergy-Associated Symptoms\nQuestion:\nWhen is your difficulty breathing worse?\nOptions:\n  - Even when I am at rest\n  - When walking on flat ground\n  - When climbing stairs or going uphill\n  - Only when I move quickly or exercise\nAnswer:\nWhen walking on flat ground\nPatient\nPatient Profile\nDoctor\nDoctor\n- White or clear sputum is produced\nwhen coughing.\nhigh\nhigh\nhigh\nmedium\nmedium\nPatient\nTurn 1\nTurn 2\n- The difficulty in breathing worsens\nwhen walking on flat ground.\nOrganized Units\n...\n...\nscore: - \nweighted score: -\nscore: +1\nweighted score: +2\n \nHPI-Diagnostic Guideline\nComparison Score:\nscore: 5\nweighted score: 8\n \n...\nThe difficulty in breathing worsens\nwhen walking on flat ground.\nFigure 7: Sample pre-consultation dialogue and HPI-diagnostic guideline comparison process. Given basic patient\ninformation, including the chief complaint, the doctor asks questions and the patient selects answers from provided\noptions. The dialogues are organized into atomic units, each of which is compared against a pre-defined diagnostic\nguideline. Units matching the guideline receive a score; those that do not are not scored.\n"}, {"page": 17, "text": "Figure 8: User interface used by human clinicians to simulate pre-consultation dialogues with patient agents. Given\nthe patient profile displayed on the left, clinicians generate questions and response options for the patient agent to\nselect. After each submission, the selected option is shown to the clinician, who then formulates the next question\nand options. After a series of dialogue turns, clinicians provide a diagnosis of the possible diseases.\n"}]}