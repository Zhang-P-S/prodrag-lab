{"doc_id": "arxiv:2511.06230", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2511.06230.pdf", "meta": {"doc_id": "arxiv:2511.06230", "source": "arxiv", "arxiv_id": "2511.06230", "title": "Overview of CHIP 2025 Shared Task 2: Discharge Medication Recommendation for Metabolic Diseases Based on Chinese Electronic Health Records", "authors": ["Juntao Li", "Haobin Yuan", "Ling Luo", "Tengxiao Lv", "Yan Jiang", "Fan Wang", "Ping Zhang", "Huiyi Lv", "Jian Wang", "Yuanyuan Sun", "Hongfei Lin"], "published": "2025-11-09T05:11:27Z", "updated": "2025-11-09T05:11:27Z", "summary": "Discharge medication recommendation plays a critical role in ensuring treatment continuity, preventing readmission, and improving long-term management for patients with chronic metabolic diseases. This paper present an overview of the CHIP 2025 Shared Task 2 competition, which aimed to develop state-of-the-art approaches for automatically recommending appro-priate discharge medications using real-world Chinese EHR data. For this task, we constructed CDrugRed, a high-quality dataset consisting of 5,894 de-identified hospitalization records from 3,190 patients in China. This task is challenging due to multi-label nature of medication recommendation, het-erogeneous clinical text, and patient-specific variability in treatment plans. A total of 526 teams registered, with 167 and 95 teams submitting valid results to the Phase A and Phase B leaderboards, respectively. The top-performing team achieved the highest overall performance on the final test set, with a Jaccard score of 0.5102, F1 score of 0.6267, demonstrating the potential of advanced large language model (LLM)-based ensemble systems. These re-sults highlight both the promise and remaining challenges of applying LLMs to medication recommendation in Chinese EHRs. The post-evaluation phase remains open at https://tianchi.aliyun.com/competition/entrance/532411/.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2511.06230v1", "url_pdf": "https://arxiv.org/pdf/2511.06230.pdf", "meta_path": "data/raw/arxiv/meta/2511.06230.json", "sha256": "c7b23107427919dd3e2fa5d846855a3a1ad3536c09b4f5a3ee506ec16692cf08", "status": "ok", "fetched_at": "2026-02-18T02:28:05.184360+00:00"}, "pages": [{"page": 1, "text": "Overview of CHIP 2025 Shared Task 2: Discharge \nMedication Recommendation for Metabolic Diseases \nBased on Chinese Electronic Health Records \n \nJuntao Li1, Haobin Yuan1, Ling Luo1,(ï€ª), Tengxiao Lv1, Yan Jiang2, Fan Wang2, Ping \nZhang2, Huiyi Lv2, Jian Wang1, Yuanyuan Sun1 and Hongfei Lin1 \n1 Dalian University of Technology, Dalian 116024,  Liaoning, China \n2 The Second Affiliated Hospital of Dalian Medical University, Dalian 116023, Liaoning, \nChina \nlingluo@dlut.edu.cn \nAbstract. Discharge medication recommendation plays a critical role in ensuring \ntreatment continuity, preventing readmission, and improving long-term manage-\nment for patients with chronic metabolic diseases. This paper present an over-\nview of the CHIP 2025 Shared Task 2 competition, which aimed to develop state-\nof-the-art approaches for automatically recommending appropriate discharge \nmedications using real-world Chinese EHR data. For this task, we constructed \nCDrugRed, a high-quality dataset consisting of 5,894 de-identified hospitaliza-\ntion records from 3,190 patients in China. This task is challenging due to multi-\nlabel nature of medication recommendation, heterogeneous clinical text, and pa-\ntient-specific variability in treatment plans. A total of 526 teams registered, with \n167 and 95 teams submitting valid results to the Phase A and Phase B leader-\nboards, respectively. The top-performing team achieved the highest overall per-\nformance on the final test set, with a Jaccard score of 0.5102, F1 score of 0.6267, \ndemonstrating the potential of advanced large language model (LLM)-based en-\nsemble systems. These results highlight both the promise and remaining chal-\nlenges of applying LLMs to medication recommendation in Chinese EHRs. The \npost-evaluation phase remains open at https://tianchi.aliyun.com/competition/en-\ntrance/532411/.  \nKeywords: Medication Recommendation, Electronic Health Records, Large \nLanguage Models, Metabolic Diseases. \n1 \nIntroduction \nWith the global incidence of chronic metabolic diseasesâ€”such as diabetes, hyperten-\nsion, and fatty liver diseaseâ€”continuing to rise, their treatment and management have \nbecome increasingly complex. Patients with metabolic disorders often suffer from mul-\ntiple comorbidities, require long-term pharmacological treatment, and exhibit signifi-\ncant individual variability. The selection of medications appropriate medications after \nhospital discharge plays a critical role in ensuring long-term disease control, preventing \n"}, {"page": 2, "text": "2  \nJ. Li et al. \nreadmission, and improving treatment safety. During hospitalization, rich diagnostic, \nlaboratory, and treatment information is continuously recorded in electronic health rec-\nords (EHRs). These records provide valuable real-world data for developing precise \nand intelligent discharge medication recommendation systems that can assist clinicians \nin optimizing personalized treatment strategies [1-3].  \nIn recent years, drug recommendation has received increasing research attention, \nwith most studies primarily focusing on English-language datasets such as MIMIC-III \n[4] and MIMIC-IV [5]. Despite the growing research interest, there remains a lack of \nstandardized shared tasks for drug recommendation based on real-world EHR data. In \nparticular, research and evaluation efforts based on Chinese clinical data are still in their \nearly stages. Publicly available benchmark datasets and standardized evaluation criteria \nare essential to ensure fair comparisons across different approaches. Therefore, we or-\nganized the discharge medication recommendation task for metabolic diseases based \non Chinese EHRs at the China Health Information Processing Conference (CHIP), aim-\ning to promote research on intelligent medication recommendation in real-world Chi-\nnese healthcare settings [6]. As shown in Fig. 1, the task involves inputting de-identi-\nfied inpatient Chinese EHR texts into the models to automatically recommend drugs \nselected from a predefined candidate list. \n \n \nFig. 1. Overview of the Discharge Medication Recommendation Task  \n \nThe taskâ€™s evaluation competition was hosted on the Tianchi platform1 and consisted \nof two phases: Phase A (development set) for model training and Phase B (test set) for \nfinal evaluation. The competition attracted active participation from universities, enter-\nprises, and research institutions. A total of 526 teams registered, among which 167 \nteams submitted results for the Phase A leaderboard, and 95 teams participated in the \nPhase B evaluation. The results revealed numerous promising approaches for Chinese \nEHR-based drug recommendation. The top-ranked team achieved the best \n \n1  https://tianchi.aliyun.com/competition/entrance/532411/information \n"}, {"page": 3, "text": " \nOverview of CHIP 2025 Shared Task 2 \n3 \nperformance, with a Jaccard score of 0.5102 and an F1 score of 0.6267, demonstrating \nthe feasibility and potential of applying advanced machine learning and natural lan-\nguage processing methods to discharge medication recommendation tasks. \nTo further advance research in the field, a post-evaluation phase was launched after \nthe competition to encourage continued exploration using the dataset. In this paper, the \nfollowing sections first review related work, then provide a detailed description of the \ndataset construction, task definition and evaluation metric. Subsequently, we analyze \nthe key methods adopted by the top-performing teams and their results, and finally pre-\nsent a summary and outlook for this evaluation. \n2 \nRelated Work \nTo promote the development of artificial intelligence technologies in the biomedical \ndomain, a growing number of challenge evaluations have been organized, such as Bi-\noCreative2, China Conference on Knowledge Graph and Semantic Computing (CCKS) \n[7], China National Conference on Computational Linguistics (CCL), and CHIP. Alt-\nhough many of these evaluations are held annually and cover a wide range of biomed-\nical topics, tasks specifically targeting medication recommendation remain relatively \nscarce. Recently, Task 9 of CCL25-Eval3 has focused on the core challenges of syn-\ndrome differentiation and herbal prescription generation in Traditional Chinese Medi-\ncine. Given clinical symptom descriptions as input, participants are required to generate \npersonalized herbal prescriptions. In contrast, our task centers on modern medicine, \ntargeting discharge medication recommendation for metabolic diseases based on real \nelectronic medical records. Moreover, our evaluation is supported by a larger, high-\nquality dataset, enabling more comprehensive benchmarking and facilitating the devel-\nopment of robust, data-driven medication recommendation models. \nWith the continuous development of large language models (LLMs) [8-12], their \napplications in the healthcare have expanded rapidly, leading to the emergence of nu-\nmerous medical LLMs [13-15]. These models are typically trained on medical corpora \nand have achieved strong performance across various benchmark tasks [16-18]. For \nexample, Med-PaLM 2 [19] integrates large-scale, high-quality medical data with \nmulti-stage instruction fine-tuning to enhance capabilities in medical question answer-\ning, clinical reasoning, medical knowledge retrieval, and professional text generation. \nIn the Chinese medical context, LLMs such as HuatuoGPT-o1 [20] have been devel-\noped for complex medical reasoning tasks. HuatuoGPT-o1 is trained on a dataset of \n40,000 verifiable medical questions and employing a medical verifier to evaluate output \nquality, thereby enabling quantifiable optimization of reasoning pathways. \nIn recent years, a growing number of open-source medical datasets have also been \nreleased [21-24], most of which serve as benchmarks for evaluating the performance of \nmedical LLMs. Research on discharge medication recommendation heavily relies on \nopen EHR and clinical text data for model training and validation [25-27]. Among these \ndatasets [4,5,28], the MIMIC series [4,5] from Beth Israel Hospital is one of the most \n \n2 https://www.ncbi.nlm.nih.gov/research/bionlp/biocreative \n3 https://tianchi.aliyun.com/competition/entrance/532301 \n"}, {"page": 4, "text": "4  \nJ. Li et al. \nwidely used, playing a crucial role in studies on diagnosis prediction, prognosis mod-\neling, and medication recommendation. However, most existing datasets for drug rec-\nommendation are based on English-language data, and Chinese datasets remain scarce. \nThe DAILMED dataset [29], which adopts a dialogue-based paradigm for medication \nrecommendation, is among of the few available Chinese datasets in this field. There-\nfore, we introduce CDrugRed [30], the Chinese discharge medication recommendation \ndataset focusing on metabolic diseases. This dataset provides a valuable foundation for \ndeveloping and evaluating intelligent medication recommendation systems tailored to \nChinese clinical practice. \n3 \nMaterial and Methods \n3.1 \nTask Definition \nIn this shared task, the systems of participating teams are required to predict a set of \ndischarge medications for patients with metabolic diseases  based on de-identified Chi-\nnese EHR texts. The recommended medications must be selected from a predefined \ncandidate drug list. The input to the model consists of the patientâ€™s inpatient records, \nand the output is a patient-specific list of medications that would be appropriately pre-\nscribed at discharge. Participants were encouraged to explore diverse technical solu-\ntions, including traditional machine learning, deep learning, pretrained language mod-\nels, or retrieval-augmented generation methods. To ensure fairness and reproducibility, \nthe task imposed certain constraints: 1) The total model size was limited to 10 billion \nparameters; 2) The use of external resources or knowledge bases was permitted only if \ntheir sources were explicitly declared. These standardized requirements aimed to pro-\nmote methodological innovation while maintaining the integrity and comparability of \nsystem performance across participating teams. \n \n3.2 \nDataset Description \nThe evaluation was conducted using the CDrugRed dataset [30], a new Chinese dis-\ncharge medication recommendation dataset focused on metabolic diseases. This dataset \nwas developed to facilitate research on intelligent and interpretable clinical medication \nrecommendation. CDrugRed is constructed from real electronic medical records col-\nlected at a top-tier tertiary hospital in China, covering 5,894 de-identified hospitaliza-\ntion records from 3,190 patients spanning the years 2013 and 2023. The dataset includes \n651 candidate drugs and provides rich clinical information, including basic demo-\ngraphic data, admission conditions, inpatient clinical course, laboratory and examina-\ntion results, past medical history, discharge diagnoses, and actual discharge medica-\ntions prescribed by physicians. An example is shown in Table 1. To protect patient \nprivacy and ensure data quality, the dataset underwent a multi-stage processing pipeline \ninvolving large-model-assisted de-identification, standardized drug-name normaliza-\ntion, and manual review to ensure data security and consistency with clinical terminol-\nogy. \n \n"}, {"page": 5, "text": " \nOverview of CHIP 2025 Shared Task 2 \n5 \nTable 1.  Example data format \nItems \nExample \nPatient ID \n2 \nVisit ID \n\"2-1\" \nSex \n\"Female\" \nDate of Birth \n\"1940-12\" \nEthnicity \n\"Han Chinese\" \nBMI \n27.3 \nDate of Visit \n\"2015-03\" \nClinical Course \n\"Outpatient urine test: ketone bodies: +, leukocytes: \n250/Âµl; microscopic examination: 7â€“9/HP. Upon admis-\nsion: urinalysis: leukocytes +++, urine leukocytes \n62.25/HP (â†‘). After oral rehydration, repeat urinalysis \nshowed leukocytes and ketones (-). Steamed bun meal test \nresults reported: glycated hemoglobin......\" \nCondition on Admission \n\"The patient was admitted with the chief complaint of \npolydipsia, polyuria, and polyphagia for 5 years, dysuria \nwith poor glycemic control for 2 months. Key physical ex-\namination findings: T 36.6 Â°C, P 76 bpm, R 22 \nbreaths/min, BP 160/80 mmHg......\" \nHistory of Present Illness \n\"Five years prior, the patient developed polydipsia, \npolyuria, and polyphagia without obvious precipitating \nfactors, and presented to ** Hospital. Fasting blood glu-\ncose was 16.7 mmol/L. The patient was treated with met-\nformin, repaglinide, and acarbose for glycemic con-\ntrol......\" \nPast Medical History \n\"No history of coronary heart disease. Denies history \nof infectious diseases including hepatitis, tuberculosis, \nand malaria. No history of food or drug allergy. No history \nof trauma, surgery, or blood transfusion. Immunization \nhistory is unknown.\" \nChief Complaint \n\"Polydipsia, polyuria, and polyphagia for 5 years; dys-\nuria with poor glycemic control for 2 months.\" \nDischarge Diagnoses \n[â€œType 2 Diabetes Mellitusâ€, â€œDiabetic Ketosisâ€, â€œUri-\nnary Tract Infectionâ€, â€œDiabetic Macrovascular Compli-\ncationsâ€, ...] \nDischarge Medications \n[\"Acarbose\", \n\"Repaglinide\", \n\"Rosuvastatin\", \n\"Telmisartan\", \"Amlodipine\", \"Calcium Carbonate Tab-\nlets\"] \n \nFor model training and evaluation, the dataset was divided into training, validation, and \ntest sets at a ratio of 6:1:3 based on unique patient identifiers. This ensured that multiple \nvisits from the same patient were confined to a single subset, thereby preserving data \nindependence and avoiding information leakage. Detailed statistics are presented in Ta-\nble 2. \nCDrugRed captures realistic disease progression patterns and comorbidity profiles \nof Chinese patients with metabolic diseases, offering a valuable benchmark for advanc-\ning data-driven clinical decision support and intelligent medication recommendation \nresearch in Chinese healthcare settings.  \n"}, {"page": 6, "text": "6  \nJ. Li et al. \nTable 2. Statistical summary of the CDrugRed dataset \nDataset \nNumber of Patients \nNumber of Visits \nTrain \n1910 \n3602 \nValidation \n320 \n570 \nTest \n960 \n1722 \n \n3.3 \nBaseline System \nTo provide a reference for comparison with the participantsâ€™ systems, we established \nan LLM-based baseline model. Specifically, we conducted supervised fine-tuning \n(SFT) based on the GLM4-9B-Chat model using the LoRA method. The fine-tuning \nhyperparameters are summarized in Table 3, and the corresponding instruction tem-\nplate is illustrated in Fig. 2. . For the instruction training data construction, all patient \ninformation fields excluding discharge medications were concatenated to form the in-\nstruction input, while the corresponding discharge medication list was used as the out-\nput. This instruction-response formulation enables the model to learn the mapping be-\ntween clinical context and medication recommendation, thereby establishing a large \nlanguage modelâ€“based baseline for this task.  \nTable 3. LoRA fine-tuning hyperparameters for GLM4-9B-Chat \nHyperparameter \nValue \nBatch size \n1 \nGradient accumulation \n4 \nLearning rate \n1e-4 \nLoRA rank \n8 \nLoRA alpha \n16 \nEpoch \n10 \n \n \nFig. 2. Instruction template used for baseline model training. (Note that the English prompt is \nnot part of the input, it is the translation of the Chinese.) \n"}, {"page": 7, "text": " \nOverview of CHIP 2025 Shared Task 2 \n7 \n3.4 \nEvaluation Metric \nSince the discharge medications are restricted to a predefined set of 651 candidate \ndrugs, this task can be treated as a multi-label classification problem. Accordingly, two \ncommonly used metrics, i.e., Jaccard score and F1 score, are adopted to comprehen-\nsively evaluate system performance. \nğ½ğ‘ğ‘ğ‘ğ‘ğ‘Ÿğ‘‘= 1\nğ‘âˆ‘\n|ğ‘¦ğ‘–âˆ©ğ‘¦Ì‚ğ‘–|\n|ğ‘¦ğ‘–âˆªğ‘¦Ì‚ğ‘–|\nğ‘\nğ‘–=1\n(1) \nğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘›(ğ‘¦ğ‘–, ğ‘¦Ì‚ğ‘–) =\n|ğ‘¦ğ‘–âˆ©ğ‘¦Ì‚ğ‘–|\n|ğ‘¦Ì‚ğ‘–|\n(2) \nğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™(ğ‘¦ğ‘–, ğ‘¦Ì‚ğ‘–) =\n|ğ‘¦ğ‘–âˆ©ğ‘¦Ì‚ğ‘–|\n|ğ‘¦ğ‘–|\n(3) \nğ‘“1(ğ‘¦ğ‘–, ğ‘¦Ì‚ğ‘–) = 2 â‹…ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘›(ğ‘¦ğ‘–, ğ‘¦Ì‚ğ‘–) â‹…ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™(ğ‘¦ğ‘–, ğ‘¦Ì‚ğ‘–)\nğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘›(ğ‘¦ğ‘–, ğ‘¦Ì‚ğ‘–) + ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™(ğ‘¦ğ‘–, ğ‘¦Ì‚ğ‘–)\n(4) \nIn the metrics, ğ‘¦ denotes the set of ground-truth drugs, ğ‘¦Ì‚ denotes the set of drugs pre-\ndicted by the model, and |ğ‘‹| denotes the number of elements in set ğ‘‹. \nTo obtain overall system performance, macro-averaged precision, recall, and F1 \nscores are computed across all ğ‘ patient records: \nAVG_P = 1\nğ‘âˆ‘ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘›(ğ‘¦ğ‘–, ğ‘¦Ì‚ğ‘–)\nğ‘\nğ‘–=1\n(5) \nAVG_R = 1\nğ‘âˆ‘ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™(ğ‘¦ğ‘–, ğ‘¦Ì‚ğ‘–)\nğ‘\nğ‘–=1\n(6) \nF1 = 1\nğ‘âˆ‘ğ‘“1(ğ‘¦ğ‘–, ğ‘¦Ì‚ğ‘–)\nğ‘\nğ‘–=1\n(7) \nFinally, the overall ranking score used for leaderboard evaluation is defined as the av-\nerage of the Jaccard and F1 scores, which balances the modelâ€™s performance in terms \nof both label overlap and predictive accuracy: \nScore = 1\n2 â‹…(ğ½ğ‘ğ‘ğ‘ğ‘ğ‘Ÿğ‘‘+ ğ¹1)\n(8) \nThis composite metric ensures a fair and comprehensive assessment of system perfor-\nmance across all participating teams. \n4 \nResults \nA total of 526 teams registered for this shared task. Among them, 167 teams submitted \nvalid results to the Phase A leaderboard, and 95 teams submitted results to the Phase B \nleaderboard. These teams are from a diverse range of organizations, including univer-\nsities, enterprises, and research institutions. Each team was allowed to submit up to \n"}, {"page": 8, "text": "8  \nJ. Li et al. \nthree runs per day, and the highest historical score was recorded as the teamâ€™s final \nleaderboard result. \n \n4.1 \nEvaluation Results \nDuring Phase A, participants were evaluated on the validation set, while Phase B used \nthe test set for the final leaderboard ranking. The best results achieved by the partici-\npants, along with the baseline performances in both phases, are summarized in Table \n4. \nTable 4. Best results and baseline performances on both leaderboards \nPhase \nType \nJaccard \nAVG_P \nAVG_R \nF1 \nScore \nLeaderboard A \nBest result \n0.5025 \n0.6764 \n0.6077 \n0.6164 \n0.5594 \nBaseline \n0.4444 \n0.5751 \n0.5958 \n0.5621 \n0.5032 \nLeaderboard B \nBest result \n0.5102 \n0.6905 \n0.6121 \n0.6267 \n0.5685 \nBaseline \n0.4477 \n0.5864 \n0.5872 \n0.5648 \n0.5062 \n  \nAs shown in Table 4, the top-performing systems achieved notable improvements \nover the baseline, particularly in the Jaccard and F1 scores. The best-performing model \nin Phase A and B achieved final scores of 0.5594 and an F1 score of 0.5685, outper-\nforming the baseline by 5.62% and 6.23%, respectively. \nTable 5 further presents the results of the top ten teams on Leaderboard B. The first-\nranked team, DeepDrug, achieved the highest overall score of 0.5685, establishing a \nclear lead over other teams. In contrast, the performance gap among the second to tenth \nteams is relatively small, with overall scores ranging from 0.5226 to 0.5453, suggesting \na high degree of competitiveness in this range. \nTable 5. The performance results of top 10 ranking teams.  \nTeam \nRank \nJaccard \nAVG_P \nAVG_R \nF1 \nScore \nDeepDrug \n1 \n0.5102 \n0.6905 \n0.6121 \n0.6267 \n0.5685 \nZZUNLP \n2 \n0.4876 \n0.6897 \n0.5735 \n0.6031 \n0.5453 \nsuxiao818 \n3 \n0.4870 \n0.6740 \n0.5810 \n0.6014 \n0.5442 \næ™šå®‰ä¸œè \n4 \n0.4790 \n0.6333 \n0.6070 \n0.5965 \n0.5378 \nH-3-C \n5 \n0.4732 \n0.6430 \n0.5857 \n0.5899 \n0.5316 \nå¯¹å¯¹é˜Ÿ \n6 \n0.4721 \n0.6194 \n0.6019 \n0.5883 \n0.5302 \nMed-LLM \n7 \n0.4697 \n0.6317 \n0.5812 \n0.5851 \n0.5274 \nIIGROUP \n8 \n0.4669 \n0.6345 \n0.5858 \n0.5850 \n0.5260 \nSeeking Your Roots \n9 \n0.4644 \n0.6068 \n0.6036 \n0.5826 \n0.5235 \nç†¬å¤œç¾å°‘å¥³æˆ˜å£« \n10 \n0.4628 \n0.6276 \n0.5771 \n0.5824 \n0.5226 \nBaseline \n28 \n0.4477 \n0.5864 \n0.5872 \n0.5648 \n0.5062 \n \nOverall, 27 teams outperformed the baseline on Leaderboard B. These results show that \nmany participating teams effectively leveraged model fine-tuning, data augmentation, \nand ensemble strategies to substantially enhance predictive performance compared to \nthe baseline. The consistent improvement across multiple teams underscores the \n"}, {"page": 9, "text": " \nOverview of CHIP 2025 Shared Task 2 \n9 \npotential of LLMs for clinical decision support tasks, particularly when combined with \ndomain-specific data augmentation and prompt design strategies. \n \n4.2 \nDescriptions of Top Five Teams  \nTeam DeepDrug (Tencent Jarvis Lab) \nThe DeepDrug team proposed a generative recommendation framework integrating  \nmulti-dimensional feature enhancement and multi-scale model fusion. At the data rep-\nresentation level, they introduced drug category annotations, explicit patient meta-fea-\ntures, and diseaseâ€“drug co-occurrence knowledge to enhance clinical semantic under-\nstanding. They also applied order perturbations to diagnostic and medication lists to \nimprove model robustness and generalization. At the model level, they performed full \nsupervised fine-tuning based on the Qwen-series LLMs and adopted differentiated \ntraining strategies for models of different parameter sizes to obtain complementary en-\nsembles. During inference, a hierarchical weighted-voting fusion mechanism was in-\ntroduced, assigning adaptive weights based on validation performance to balance bias \nand variance across model predictions. \nTeam ZZUNLP (Zhengzhou University) \nThe ZZUNLP team developed a systematic solution across the dimensions of data, \nmodel training, and inference. To address the domain specificity of medical text and \nthe scarcity of labeled data, they designed prompt templates tailored for clinical medi-\ncation reasoning and introduced a pseudo-labeling data-augmentation strategy. They \nused the cross-entropy loss of label sequences as a confidence indicator to filter high-\nquality pseudo-labeled samples. Multiple open-source LLMs were fine-tuned using \nLoRA and optimized with the liger-kernel cross-entropy loss for efficient memory uti-\nlization. For inference, they employed a two-stage hierarchical ensemble: in stage one, \nweighted voting was applied separately within model groups trained on original data \nand augmented data to obtain high-confidence predictions; in stage two, an adaptive \nfusion strategy based on differences in predicted list length and Jaccard similarity fur-\nther improved final recommendation performance. \nTeam suxiao818 (MISUMI (China) Precision Machinery Trading Co., Ltd.) \nThe suxiao818 team implemented a fine-tuning and ensemble-based framework built \nupon multiple LLMs. They split the dataset (9:1) into training and validation subsets \nand selected the top-performing four models with LoRA fine-tuning for ensemble. To \nmitigate randomness in generative decoding, each model produced multiple predictions \nunder different decoding temperatures, which were fused using majority voting. Can-\ndidate drugs appearing in more than half of the predictions were retained and ranked \nby frequency, with list length truncated to the average. \nTeam æ™šå®‰ä¸œè (South China Normal University) \nThis team fine-tuned Qwen2.5-7B-Instruct for discharge medication generation. In \ndata preprocessing, they designed prompt strategies for electronic medical records, con-\ncatenating all fields of a case as model input to generate structured or natural-language-\nstyle drug lists. They then performed supervised fine-tuning via LoRA. At inference, \nthey ran multiple temperature settings for models outputting the different styles, and \nselected the three best-performing configurations for ensemble. They further \n"}, {"page": 10, "text": "10  \nJ. Li et al. \nnormalized drug names to improve consistency. The final ensemble used a voting rule: \ndrugs appearing in at least two lists were retained; if there was no overlap, the union of \nall predictions was used to increase recall. \nTeam H-3-C (H3C Technologies Co., Limited) \nThe H-3-C team designed a data-centric approach emphasizing rare-drug over-\nsampling and ensemble enhancement. Low-relevance fields (such as patient index, gen-\nder, BMI) were removed, and samples containing rare drugs were duplicated or tripli-\ncated based on frequency thresholds. To increase data diversity, they introduced order-\nshuffled samples and combined them with the oversampled set, resulting in 6,740 aug-\nmented samples. Five open-source LLMs were fine-tuned using LoRA on these da-\ntasets. During inference, fuzzy string matching normalized predicted drugs to the can-\ndidate list, supplemented by a manually curated alias mapping table. Final predictions \nwere generated via majority voting (appearing in â‰¥3 models), with sequential back-\nfilling from GLM4-9B-Chat and CareBot_Medical_multi-llama3-8b-instruct models \nfor empty outputs. \n \n4.3 \nAnalysis of Top Team Solutions \nTable 6 presents the performance of the top five teams on the Leaderboard B. Since all \nthese teams adopted model ensemble strategies, we report both their best single-model \n(Single) results and their best ensembled results. The ensemble approaches generally \nled to consistent performance gains across all teams, highlighting the importance of \nmodel diversity and fusion in this multi-label clinical prediction task. \nTable 6. Single and ensemble results of the top five ranking teams on the test set. Single refers \nto Best Single Model \nTeam \nRank \nMethod \nJaccard \nAVG_P \nAVG_R \nF1 \nScore \nDeepDrug \n1 \nSingle \n- \n- \n- \n- \n- \nEnsemble \n0.5102 \n0.6905 \n0.6121 \n0.6267 \n0.5685 \nZZUNLP \n2 \nSingle \n0.4480 \n0.5837 \n0.5902 \n0.5648 \n0.5064 \nEnsemble \n0.4876 \n0.6897 \n0.5735 \n0.6031 \n0.5453 \nsuxiao818 \n3 \nSingle \n0.4700 \n0.6498 \n0.5750 \n0.5865 \n0.5283 \nEnsemble \n0.4870 \n0.6740 \n0.5810 \n0.6014 \n0.5442 \næ™šå®‰ä¸œè \n4 \nSingle \n0.4644 \n0.6044 \n0.6082 \n0.5821 \n0.5232 \nEnsemble \n0.4790 \n0.6333 \n0.6070 \n0.5965 \n0.5378 \nH-3-C \n5 \nSingle \n0.4538 \n0.5965 \n0.5946 \n0.5715 \n0.5127 \nEnsemble \n0.4732 \n0.6430 \n0.5857 \n0.5899 \n0.5316 \n \nNotably, the second-place team (ZZUNLP) achieved the largest performance gain after \nensemble fusion, with its score increasing from 0.5064 to 0.5453, underscoring the ef-\nfectiveness and sophistication of its two-stage ensemble strategy. This approach com-\nbines intra-group weighted voting with inter-group adaptive fusion. It demonstrates that \ncarefully designed hierarchical ensemble mechanisms can capture complementary \nmodel strengths more effectively than simple averaging or majority voting. Overall, \nthese findings highlight that, while large language models provide strong baselines, \n"}, {"page": 11, "text": " \nOverview of CHIP 2025 Shared Task 2 \n11 \nensemble-based optimization remains a crucial technique for improving the stability \nand accuracy of clinical drug recommendation systems. \n5 \nConclusion \nIn this paper, we established the first benchmark for discharge medication recommen-\ndation in metabolic diseases using Chinese EHR data through the CHIP 2025 Shared \nTask 2. The high level of participation and diverse system designs reflect strong com-\nmunity engagement and the growing interest in data-driven clinical decision support. \nThe top-performing teams demonstrated that ensemble frameworks combining domain-\nspecific fine-tuned LLMs can effectively leverage EHR information to improve dis-\ncharge medication prediction. This shared task provides valuable insights into the prac-\ntical application of NLP and machine learning for personalized medication manage-\nment, contributing to the advancement of precision medicine in chronic metabolic care.  \nDespite these advances, challenges remain in addressing label imbalance, rare med-\nication usage, and generalizing across institutions. For future work, we plan to expand \nthe dataset with additional clinical contexts from multiple institutions, incorporating \nmulti-modal data such as laboratory and medical imaging, and moving beyond drug \nname recommendation to generating complete medication regimens, including dosage \nand instructions. These efforts aim to promote explainable and trustworthy AI systems \nfor clinical medication applications.  \n \nAcknowledgments. This research was supported by the Natural Science Foundation of China \n(No. 62302076, 62276043), the Fundamental Research Funds for the Central Universities (No. \nDUT25YG108), and the Research Project on High Quality Development of Hospital Pharmacy, \nNational Institute of Hospital Administration, NHC, China (No. NIHAYSZX2525). \nReferences \n1. Zhang Y, Chen R, Tang J, et al. LEAP: learning to prescribe effective and safe treatment \ncombinations for multimor-bidi-ty[C]//proceedings of the 23rd ACM SIGKDD interna-\ntional conference on knowledge Discovery and data Mining. 2017: 1315-1324. \n2. Shang J, Xiao C, Ma T, et al. Gamenet: Graph augmented memory networks for recom-\nmending medication com-bina-tion[C]//proceedings of the AAAI Conference on Artifi-cial \nIntelligence. 2019, 33(01): 1126-1133. \n3. Yang C, Xiao C, Ma F, et al. SafeDrug: Dual Molecular Graph Encoders for Recommending \nEffective and Safe Drug Combinations[C]//30th International Joint Conference on Artificial \nIntelligence, IJCAI 2021. International Joint Conferences on Artificial Intelligence, 2021: \n3735-3741. \n4. Johnson A E W, Pollard T J, Shen L, et al. MIMIC-III, a freely accessible critical care data-\nbase[J]. Scientific data, 2016, 3(1): 1-9. \n5. Johnson A E W, Bulgarelli L, Shen L, et al. MIMIC-IV, a freely accessible electronic health \nrecord dataset[J]. Scientific data, 2023, 10(1): 1. \n"}, {"page": 12, "text": "12  \nJ. Li et al. \n6. Etemadi M, Abkenar S B, Ahmadzadeh A, et al. A systematic review of healthcare recom-\nmender systems: Open issues, challenges, and techniques[J]. Expert Systems with Applica-\ntions, 2023, 213: 118823. \n7. Li J, Luo L, Lv T, et al. Instruction fine-tuning of large language models for traditional \nChinese medicine[C]//China Conference on Knowledge Graph and Semantic Computing. \nSingapore: Springer Nature Singapore, 2024: 419-430. \n8. Achiam J, Adler S, Agarwal S, et al. Gpt-4 technical report[J]. arXiv preprint \narXiv:2303.08774, 2023. \n9. Yang A, Li A, Yang B, et al. Qwen3 technical report[J]. arXiv preprint arXiv:2505.09388, \n2025. \n10. GLM T, Zeng A, Xu B, et al. Chatglm: A family of large language models from glm-130b \nto glm-4 all tools[J]. arXiv preprint arXiv:2406.12793, 2024. \n11. Meta A I. The llama 4 herd: The beginning of a new era of natively multimodal ai innova-\ntion[J]. https://ai. meta. com/blog/llama-4-multimodal-intelligence/, checked on, 2025, 4(7): \n2025. \n12. Guo D, Yang D, Zhang H, et al. Deepseek-r1: Incentivizing reasoning capability in llms via \nreinforcement learning[J]. arXiv preprint arXiv:2501.12948, 2025. \n13. Luo L, Ning J, Zhao Y, et al. Taiyi: a bilingual fine-tuned large language model for diverse \nbiomedical tasks[J]. Journal of the American Medical Informatics Association, 2024, 31(9): \n1865-1874. \n14. Chen J, Wang X, Ji K, et al. Huatuogpt-ii, one-stage training for medical adaption of llms[J]. \narXiv preprint arXiv:2311.09774, 2023. \n15. Xiong H, Wang S, Zhu Y, et al. Doctorglm: Fine-tuning your chinese doctor is not a hercu-\nlean task[J]. arXiv preprint arXiv:2304.01097, 2023. \n16. Zhou H, Liu F, Wu J, et al. A collaborative large language model for drug analysis[J]. Nature \nBiomedical Engineering, 2025: 1-12. \n17. Dou C, Liu C, Yang F, et al. Baichuan-m2: Scaling medical capability with large verifier \nsystem[J]. arXiv preprint arXiv:2509.02208, 2025. \n18. Wang G, Gao M, Yang S, et al. Citrus: Leveraging expert cognitive pathways in a medical \nlanguage model for advanced medical decision support[J]. arXiv preprint arXiv:2502.18274, \n2025. \n19. Singhal K, Tu T, Gottweis J, et al. Toward expert-level medical question answering with \nlarge language models[J]. Nature Medicine, 2025, 31(3): 943-950. \n20. Chen J, Cai Z, Ji K, et al. Huatuogpt-o1, towards medical complex reasoning with llms[J]. \narXiv preprint arXiv:2412.18925, 2024. \n21. Jin D, Pan E, Oufattole N, et al. What disease does this patient have? a large-scale open \ndomain question answering dataset from medical exams[J]. Applied Sciences, 2021, 11(14): \n6421. \n22. Jin Q, Dhingra B, Liu Z, et al. PubMedQA: A Dataset for Biomedical Research Question \nAnswering[C]//Proceedings of the 2019 Conference on Empirical Methods in Natural Lan-\nguage Processing and the 9th International Joint Conference on Natural Language Pro-\ncessing (EMNLP-IJCNLP). 2019: 2567-2577. \n23. Liu J, Zhou P, Hua Y, et al. Benchmarking large language models on cmexam-a compre-\nhensive chinese medical exam dataset[J]. Advances in Neural Information Processing Sys-\ntems, 2023, 36: 52430-52452. \n24. Yue W, Wang X, Zhu W, et al. Tcmbench: A comprehensive benchmark for evaluating large \nlanguage models in traditional chinese medicine[J]. arXiv preprint arXiv:2406.01126, 2024. \n25. Wu R, Qiu Z, Jiang J, et al. Conditional generation net for medication recommenda-\ntion[C]//Proceedings of the ACM web conference 2022. 2022: 935-945. \n"}, {"page": 13, "text": " \nOverview of CHIP 2025 Shared Task 2 \n13 \n26. Zhao Z, Jing Y, Feng F, et al. Leave no patient behind: Enhancing medication recommen-\ndation for rare disease patients[C]//Proceedings of the 47th International ACM SIGIR Con-\nference on Research and Development in Information Retrieval. 2024: 533-542. \n27. Zhao Z, Fan C, Gao C, et al. Addressing overprescribing challenges: Fine-tuning large lan-\nguage models for medication recommendation tasks[J]. arXiv preprint arXiv:2503.03687, \n2025. \n28. Pollard T J, Johnson A E W, Raffa J D, et al. The eICU Collaborative Research Database, a \nfreely available multi-center database for critical care research[J]. Scientific data, 2018, 5(1): \n1-13. \n29. He Z, Han Y, Ouyang Z, et al. DialMed: A Dataset for Dialogue-based Medication Recom-\nmendation[C]//Proceedings of the 29th International Conference on Computational Linguis-\ntics. 2022: 721-733. \n30. Li J, Yuan H, Luo L, et al. CDrugRed: A Chinese Drug Recommendation Dataset for Dis-\ncharge Medications in Metabolic Diseases[J]. arXiv preprint arXiv:2510.21084, 2025. \n"}]}