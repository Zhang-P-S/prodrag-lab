{"doc_id": "arxiv:2512.02816", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2512.02816.pdf", "meta": {"doc_id": "arxiv:2512.02816", "source": "arxiv", "arxiv_id": "2512.02816", "title": "A benchmark dataset for evaluating Syndrome Differentiation and Treatment in large language models", "authors": ["Kunning Li", "Jianbin Guo", "Zhaoyang Shang", "Yiqing Liu", "Hongmin Du", "Lingling Liu", "Yuping Zhao", "Lifeng Dong"], "published": "2025-12-02T14:26:44Z", "updated": "2025-12-02T14:26:44Z", "summary": "The emergence of Large Language Models (LLMs) within the Traditional Chinese Medicine (TCM) domain presents an urgent need to assess their clinical application capabilities. However, such evaluations are challenged by the individualized, holistic, and diverse nature of TCM's \"Syndrome Differentiation and Treatment\" (SDT). Existing benchmarks are confined to knowledge-based question-answering or the accuracy of syndrome differentiation, often neglecting assessment of treatment decision-making. Here, we propose a comprehensive, clinical case-based benchmark spearheaded by TCM experts, and a specialized reward model employed to quantify prescription-syndrome congruence. Data annotation follows a rigorous pipeline. This benchmark, designated TCM-BEST4SDT, encompasses four tasks, including TCM Basic Knowledge, Medical Ethics, LLM Content Safety, and SDT. The evaluation framework integrates three mechanisms, namely selected-response evaluation, judge model evaluation, and reward model evaluation. The effectiveness of TCM-BEST4SDT was corroborated through experiments on 15 mainstream LLMs, spanning both general and TCM domains. To foster the development of intelligent TCM research, TCM-BEST4SDT is now publicly available.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2512.02816v1", "url_pdf": "https://arxiv.org/pdf/2512.02816.pdf", "meta_path": "data/raw/arxiv/meta/2512.02816.json", "sha256": "4e468fe26ab518eb5a39daa9d5e2d9dc20d4f2f0da572f8f4fe46e29a077eb8a", "status": "ok", "fetched_at": "2026-02-18T02:25:39.702480+00:00"}, "pages": [{"page": 1, "text": "1\nA benchmark dataset for evaluating Syndrome Differentiation and\nTreatment in large language models\nAuthors\nKunning Li1, Jianbin Guo3,4, Zhaoyang Shang3,5, Yiqing Liu1, Hongmin Du3, Lingling Liu1, Yuping\nZhao2, Lifeng Dong3,4\nAffiliations\n1. Research Center for Intelligent Science and Engineering Technology of Traditional C\nhinese Medicine, China Academy of Chinese Medical Sciences, Beijing, 100700, China\n2. Institute of Basic Theory for Chinese Medicine, China Academy of Chinese Medical\nSciences, Beijing, 100700, China\n3. Beijing Wenge Technology Co.,Ltd, Beijing, 100190, China\n4. Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China\n5. College of Intelligence and Computing, Tianjin University, 300350, China\nThese authors contributed equally: Kunning Li, Jianbin Guo.\ncorresponding authors: Yuping Zhao (zhaoyp@ibtcm.ac.cn), Lifeng Dong (lifeng.dong@i\na.ac.cn)\nAbstract\nThe emergence of Large Language Models (LLMs) within the Traditional Chinese Medicine\n(TCM) domain presents an urgent need to assess their clinical application capabilities.\nHowever, such evaluations are challenged by the individualized, holistic, and diverse nature\nof TCM’s \"Syndrome Differentiation and Treatment\" (SDT). Existing benchmarks are confined\nto knowledge-based question-answering or the accuracy of syndrome differentiation, often\nneglecting assessment of treatment decision-making. Here, we propose a comprehensive,\nclinical case-based benchmark spearheaded by TCM experts, and a specialized reward model\nemployed to quantify prescription-syndrome congruence. Data annotation follows a rigorous\npipeline. This benchmark, designated TCM-BEST4SDT, encompasses four tasks, including\nTCM Basic Knowledge, Medical Ethics, LLM Content Safety, and SDT. The evaluation\nframework integrates three mechanisms, namely selected-response evaluation, judge model\nevaluation, and reward model evaluation. The effectiveness of TCM-BEST4SDT was\ncorroborated through experiments on 15 mainstream LLMs, spanning both general and TCM\n"}, {"page": 2, "text": "2\ndomains. To foster the development of intelligent TCM research, TCM-BEST4SDT is now\npublicly available.\nBackground & Summary\nIn recent years, Large Language Models (LLMs) technology has advanced rapidly and has\nbeen widely applied in multiple domains, such as intelligent interaction and scientific\nresearch support 1. Particularly in the medical field, LLMs have shown significant potential in\nassisting disease diagnosis2 and optimizing diagnostic and treatment workflows.\nIn Traditional Chinese Medicine (TCM), the core clinical principle is \"Syndrome\nDifferentiation\nand\nTreatment\"\n(SDT)3.\nThis\nprocess\nrequires\nthe\nsynthesis\nof\nmultidimensional information for syndrome differentiation, which then informs the\nformulation of individualized treatment plans based on principles such as \"different\ntreatments for same disease.\" Although TCM domain LLMs, such as Zhongjing4 and\nHuatuoGPT5, have emerged, their clinical application still faces significant challenges due to\nthe complexity and individualized nature of this diagnostic and treatment model. Critically,\nthere is currently a lack of both evaluation benchmarks that cover the complete clinical\ndecision-making chain and specialized metrics for assessing the models' reasoning processes.\nTherefore, academia and industry urgently need a benchmark dataset that can objectively\nand comprehensively evaluate the clinical application capabilities of these models. Such a\nbenchmark will provide support for the performance evaluation, iterative optimization, and\neventual clinical application of TCM domain LLMs.\nHowever, the individualized, holistic, and diverse characteristics of SDT in TCM pose\nsubstantial challenges to the construction of such a benchmark dataset. Individualization\nimplies that patients with the same disease may present disparate syndromes owing to\nvariations in constitution, disease progression, and lifestyle habits, which significantly\nincreases the difficulty of benchmark construction6. TCM diagnosis is a holistic reasoning\nprocess. It relies on multiple diagnostic methods to integrate multidimensional information\nand, through analysis of aspects such as the cause of disease and pathogenesis, ultimately\ncompletes syndrome differentiation and treatment formulation. This comprehensive\ndiagnostic logic demands a benchmark dataset of greater evaluative breadth7. Furthermore,\nthe frequent concurrence of multiple syndromes in a single patient, coupled with the\ndiversity of diagnostic methods, also introduces significant subjectivity to the evaluation\nresults6. In summary, these characteristics render the construction of a comprehensive\nbenchmark for evaluating the clinical application capabilities of TCM domain LLMs\nexceptionally difficult.\n"}, {"page": 3, "text": "3\nExisting evaluation benchmarks for TCM domain LLMs exhibit marked limitations. First,\nbenchmarks such as CMExam8, MLEC-QA9, MedBench10 and CMB11 are largely based on\nstandardized examination questions, for instance, those from the National Qualification\nExamination For Medical Practitioners. While these benchmarks can gauge a model's grasp\nof fundamental TCM theory, they fail to assess its capacity for SDT. Second, although\nbenchmarks such as TCMEval-SDT7 and TCM-SD6 only evaluate syndrome differentiation\ncapabilities, they neglect the assessment of treatment decision-making. Concurrently, they\nfail to consider unique features of TCM, such as the possibility of multiple syndromes in one\npatient and the diversity of diagnostic methods. Furthermore, the rapid development of\nreasoning models, such as OpenAI-o112 and DeepSeek-R113, is catalyzing the emergence of\nreasoning models within the TCM domain. However, the majority of existing benchmarks\nremain focused on outcome accuracy, lacking evaluation of the model's reasoning process.\nThis outcome-oriented evaluation paradigm fails to comprehensively reflect the model's\napplication value in real-world clinical scenarios.\nTo address the above problems, this study, led by a team of TCM experts, constructed a\ncomprehensive evaluation benchmark derived from clinical cases and authoritative\nexamination questions. Data annotation follows a three-stage pipeline consisting of\nannotation by experts, mutual cross-validation, and independent third-party review. This\nbenchmark, designated TCM-BEST4SDT, encompasses four tasks, including TCM Basic\nKnowledge, Medical Ethics, LLM Content Safety, and SDT. This study aims to evaluate the\napplication capabilities of models in real-world TCM clinical scenarios (i.e., SDT), provide\nguidance for the iterative optimization of TCM domain LLMs, and consequently promote the\nindustrialization of intelligent TCM research. The core objectives of this study are as follows:\n1.\nTo propose an evaluation framework centered on the capability for SDT, which can\nquantify the reasoning outcomes and also evaluate the reasoning process.\n2.\nTo design three evaluation mechanisms, including selected-response evaluation, judge\nmodel evaluation and reward model evaluation, to ensure objectivity and professional\nrigor throughout the benchmarking process.\n3.\nTo address the challenge of mismatching between prescriptions and syndromes by\ntraining a dedicated reward model that quantifies prescription-syndrome congruence,\nthereby enabling objective assessment of prescription suitability.\n"}, {"page": 4, "text": "4\nMethods\nFig. 1 The overview of TCM-BEST4SDT. (a) The construction process of the dataset; (b) The\nevaluation methods of TCM-BEST4SDT.\nAs illustrated in Fig. 1, this section details the dataset construction process and evaluation\nmethodologies. For dataset construction, the study was led by a team of TCM experts who\ncollected samples from clinical cases, classical case records, and authoritative examination\nquestions. All samples were subsequently deduplicated, cleaned, and anonymized. Data\nannotation follows a three-stage pipeline consisting of annotation by experts, mutual\ncross-validation, and independent third-party review. The resulting benchmark, designated\nTCM-BEST4SDT, comprises 600 questions covering four tasks, including TCM Basic\nKnowledge, Medical Ethics, LLM Content Safety, and SDT, as illustrated in Fig. 2. Regarding\nevaluation methodologies, this study designed three mechanisms to quantify model\napplication capabilities in real-world TCM clinical scenarios. The first is selected-response\nevaluation. This method involves multiple rounds of independent evaluation for each\nquestion, randomizes the option order, and calculates scores using different scoring\nstrategies based on the question type. The second is judge model evaluation. This\nmechanism utilizes an LLM, combined with expert-designed prompts, to score the responses\nof the model under evaluation. The third is reward model evaluation. This study developed a\nspecialized reward model to objectively quantify prescription-syndrome congruence.\n"}, {"page": 5, "text": "5\nFig. 2 TCM-BEST4SDT comprises four task categories: TCM Basic Knowledge, Medical Ethics,\nLLM Content Safety, and Syndrome Differentiation and Treatment, covering a total of 27\nevaluation dimensions. Notably, Syndrome Differentiation and Treatment encompasses 14\noutcome-oriented dimensions and 2 process-oriented dimensions.\nCreation of TCM-BEST4SDT\nData Collection and Preprocessing\nTCM-BEST4SDT comprises two categories of tasks, namely the SDT task and general\nevaluation tasks. Data for the former are sourced from clinical cases and classical case\nrecords, whereas the latter cover TCM Basic Knowledge, Medical Ethics, and LLM Content\nSafety. The TCM Basic Knowledge component is selected from public examination questions,\nincluding the National Qualification Examination for Medical Practitioners, the National\nPostgraduate Entrance Examination: Comprehensive Clinical Medicine (TCM Integrated), and\nthe Chinese Herbal Medicine Title Examination. The Medical Ethics component, in addition\nto being sourced from authoritative databanks, was also manually annotated by experts\nbased on specific scenarios. The LLM Content Safety component was independently\ndesigned and constructed by experts in relevant fields based on practical requirements.\nDuring the data preprocessing stage, all cases and examination questions were first\ndeduplicated to ensure sample independence, followed by systematic data cleaning.\nSamples lacking question stems or options, or those containing non-textual content such as\nfigures and tables, were excluded. Concurrently, character errors resulting from OCR\nrecognition were manually proofread to ensure textual accuracy and consistency. For clinical\ncase and medical record data, anonymization was performed in strict adherence to medical\nethics and privacy protection principles. This involved deleting or replacing patient names\nand other identifiable information to ensure data compliance and privacy safety. The clinical\ncases used in this study were approved by the Ethics Committee of the Xiyuan Hospital of\nCACMS (approval number: 2025XLA135-2).\n"}, {"page": 6, "text": "6\nData Annotation\nSDT is the core principle of TCM diagnosis and therapy, encompassing the two links of\n\"syndrome differentiation\" and \"treatment formulation\". To evaluate model capabilities in\nthis process, this study proposes a comprehensive 14-dimension evaluation framework,\nincluding syndrome, causative factors, and pathogenesis, as detailed in Table 1. All standard\nanswers and options were first annotated by TCM experts, then mutually cross-validated,\nand finally underwent an independent third-party review to ensure annotation consistency\nand\nreliability.\nNotably,\nthe\nselected-response\nquestions\nwere\nconstructed\nwith\nsophisticated distractors to enhance the discriminative power of the assessment.\nBeyond evaluating the final reasoning outcomes of SDT, this study also introduces two\nprocess-oriented metrics, namely Chain-of-Thought (CoT) Content Completeness, which\nmeasures the coverage of key patient information within the model's CoT, and CoT Accuracy,\nwhich assesses the consistency of elements cited in the CoT with the original clinical case to\nidentify potential hallucinations or reasoning deviations.\nThe general evaluation tasks aim to reveal model differences in foundational cognition\nand normative responses, thereby achieving a more comprehensive and interpretable\noverall\nevaluation.\nAll\nquestions\nare\nselected-response\nquestions,\nincluding\nboth\nsingle-selection and multiple-selection types. The TCM Basic Knowledge component covers\nfour core dimensions: (i) comprehension of TCM classics; (ii) grasp of basic theories; (iii)\nknowledge of Chinese materia medica and formulas; and (iv) syndrome differentiation ability\nbased on tongue, pulse, facial complexion, and acupoints. Questions for this component\nwere selected from preprocessed authoritative examination questions. The Medical Ethics\ncomponent assesses the model's understanding and judgment of clinical ethics, with content\ncovering conflicts between traditional concepts and modern medicine, discrimination of\nunscientific behaviors, respect for patient cultural beliefs, and informed consent. This\ncomponent is sourced from authoritative examination questions and supplemented by\nexpert-designed questions based on the aforementioned scenarios. The Content Safety\ncomponent aims to evaluate the performance of the TCM domain LLM in terms of\nprofessional boundaries and safety compliance. The model should only answer TCM-related\nquestions and refuse to respond to non-medical domain inquiries involving user privacy,\nsafety risks, or human values. Relevant questions were independently designed and\nreviewed by experts in content safety and ethics according to these principles, ensuring the\nevaluation meets the professionalism and safety requirements for TCM domain LLMs.\n"}, {"page": 7, "text": "7\nDimension\nDescription\nQuestion Type\nEvaluation\nMethods\nSyndrome\nA pathological summarization on the\ndisease location, etiological factors,\nnature, severity and prognosis in a\ncertain stage.\nMultiple-Selection\nQuestions\n(each containing ten\noptions)\nSelected-Response\nEvaluation\nNature of Disease\nA summary of the pathological nature\nof the disease.\nLocation of Disease\nThe location of the disease or the area\nof pathological changes.\nTherapeutic\nPrinciples and\nMethods\nThe former establishes the direction of\ntreatment, while the latter provides\nspecific methods.\nSingle-Selection\nQuestions\n(each containing four\noptions)\nHerbal Composition\nand Dosage\nIncludes the name of the medicinal\nmaterial and its dosage.\nQuestion Answering\nReward Model\nEvaluation\nCausative Factors\nAll causes of diseases.\nJudge Model\nEvaluation\nPathogenesis\nThe mechanism of the occurrence,\nprogress, and change of the disease.\nPrinciples of Herb\nCombination in\nFormulae\nThe principle of combining two or more\nChinese herbs based on their medicinal\nproperties and therapeutic needs.\nIncompatibility of\nDrugs in Prescription\nCertain combinations of medicines\nshould be avoided because they may\nreduce curative effects, produce or\nenhance toxic or side effects, and/or\ncompromise medication safety.\nContraindications\nDuring Pregnancy\nRefers to medicinal substances that are\nprohibited or used with extreme\ncaution during pregnancy, as they may\ncause miscarriage or harm to the fetus.\nSafety of Medicinal\nMaterials\nRefers to the assessment and\nmanagement of risks associated with\nmedicinal materials, including toxicity,\nadulteration, pesticides, heavy metals,\nand correct species identification.\nPreparation and\nAdministration\nThe specific procedure for decocting\nChinese medicinal herbs in water and\nthen taking the resulting liquid.\nModification\nAccording to\nSymptoms\nTreatment methods that flexibly adjust\nmedication according to the specific\nchanges in the patient's symptoms.\nPrecautions\nWarnings and guidance for patients\nregarding diet contraindications,\npotential side effects, activities to\navoid, and special warnings for specific\npopulations during treatment.\nTable 1 Names, descriptions, question types and evaluation methods of the 14 evaluation\ndimensions included in the Syndrome Differentiation and Treatment task.\nDataset Features\nTCM-BEST4SDT\nsurpasses\nexisting\nevaluation\nbenchmarks\nin\nmultiple\naspects:\n(1)\nChallenging: In contrast to previous datasets largely focused on basic TCM knowledge,\nTCM-BEST4SDT is centered on SDT and features highly discriminative evaluation scenarios.\n(2) Comprehensiveness: It enables the assessment of treatment decision-making and\nprovides broad coverage of 257 syndromes and 20 ICD-11 disease groups, as illustrated in\nFig. 3a,b. (3) Domain Adaptability: The syndrome evaluation concurrently considers both\n"}, {"page": 8, "text": "8\nprimary syndromes and secondary syndromes. This simulates the authentic clinical\ndifferentiation process, reflecting the holistic perspective of TCM and the principle of SDT.\n(4) Novelty: It achieves, for the first time, the quantitative evaluation of the SDT reasoning\nprocess, extending the assessment from being outcome-oriented to process-oriented. (5)\nHigh Quality: All questions have been annotated by TCM experts, mutually cross-validated,\nand verified by an independent third-party review, ensuring professionalism and annotation\nconsistency.\nFig. 3 (a) The Syndrome Differentiation and Treatment task encompasses 257 syndromes,\ncategorized according to 'Pattern differentiation by the eight principles'; (b) The Syndrome\nDifferentiation and Treatment task encompasses 20 major disease groups, categorized\naccording to the ICD-11 for Mortality and Morbidity Statistics.\nEvaluation methods\nSelected-Response Evaluation\nThe selected-response questions in TCM-BEST4SDT include\nsingle-selection and multiple-selection types. Both question types utilize a unified evaluation\nprocess: each question undergoes three rounds of independent evaluation, and the option\norder is randomized in each round to mitigate the impact of chance and cuing bias on the\nresults.\n(1) Single-selection questions: A question is judged as correct only if the model's output\nis completely consistent across all three rounds and indicates the correct answer. This strict\ncriterion ensures the stability and reliability of the results.\n(2 )Multiple-selection questions:\nS =\n|A ∩B|\n|A| + |Ā ∩B|\n,\n(1)\nhere, S represents the task score, A is the set of standard answers, and B is the set of\nmodel-selected options.∣A∩B∣represents the count of correctly selected options, while\n| Ā ∩B∣represents the count of incorrectly selected options. The final score for each\n"}, {"page": 9, "text": "9\nquestion is the average of the three evaluation rounds, serving to smooth incidental errors\nand enhance the scientific rigor and robustness of the scoring.\nJudge Model Evaluation\nThe judge model evaluation employs a high-performance LLM as\nan evaluator, wherein the response from the model under evaluation is input together with\nthe standard answer for the corresponding dimension. This is supplemented with scoring\nprompts designed by TCM experts to guide the judgment, ensuring professionalism and\nconsistency in the evaluation. Process-oriented metrics are likewise quantitatively assessed\nusing specialized scoring prompts, thereby objectively measuring the completeness and\naccuracy of the model's CoT.\nReward Model Evaluation\nTo address the challenge of mismatching between prescriptions\nand\nsyndromes,\nthis\nstudy\ndeveloped\na\ndedicated\nreward\nmodel\nto\nquantify\nprescription-syndrome congruence, thereby enabling objective assessment of prescription\nsuitability. Its training data, derived from clinical cases and classical TCM formulas, consists\nof 10k samples. Each sample contains one syndrome and six candidate prescriptions. A team\nof TCM experts rated the six candidate prescriptions for their degree of matching to the\ngiven syndrome, based on established principles of TCM formula composition. After expert\nrating, each sample contains k high-matching-degree positive prescriptions and 6-k\nlow-matching-degree negative prescriptions, accompanied by scoring rationales based on\nprinciples of herb combination in formulae. Each candidate prescription was also annotated\nfor\nincompatibility\nof\ndrugs\nin\nprescription,\nsafety\nof\nmedicinal\nmaterials,\nand\ncontraindications during pregnancy. Finally, based on this expert-annotated data, we\nsupervised fine-tuning on Qwen3-14B14 to construct the prescription-syndrome matching\nreward model.\nData Records\nThe TCM-BEST4SDT benchmark dataset is available for access and download on Figshare\n(https://doi.org/10.6084/m9.figshare.30615956)15, provided under the CC-BY 4.0 license.\nThe dataset comprises five JSON files, namely (1) TCM_SDT.json, containing 300 clinical\ncases; (2) Basic_Knowledge.json, containing 100 selected-response questions on TCM basic\nknowledge; (3) Medical_Ethics.json, containing 100 selected-response questions on medical\nethics; (4) LLM_Content_Safety.json, containing 100 selected-response questions on LLMs\ncontent safety; and (5) TCM-BEST4SDT.json, the complete dataset. Python scripts for\ntechnical validation are also available on Figshare15. More detailed information and usage\ninstructions are provided in the 'README.md' file.\n"}, {"page": 10, "text": "10\nTechnical Validation\nTo validate the effectiveness of TCM-BEST4SDT, this study selected 15 publicly accessible\nLLMs as evaluation subjects, comprising 8 general domain LLMs and 7 TCM domain LLMs.\nBased on these models, a zero-shot prompting strategy was designed to systematically\ncompare their overall performance on TCM tasks without fine-tuning, thereby quantifying\nSDT capabilities of different models.\nModel Selection. This study evaluated two categories of models. (1) General domain\nLLMs: These cover state-of-the-art general domain models including GPT-5 16, Gemini\n2.5 Pro17 , DeepSeek-R1, Doubao-seed-1.618, Kimi-K2 19, the Qwen3 series (4B, 8B, 14\nB, 32B, 80B, 235B)14, GLM-4.520, and Llama-4-Scout-17B-16E-Instruct21. These models a\nre trained on large-scale general corpora and possess broad language understanding\nand generation capabilities. (2) TCM domain LLMs: These include various representati\nve models specifically designed and optimized for TCM semantics, such as HuatuoGPT\n-o1-7B22, BianCang-Qwen2.5-7B23, Baichuan-M2-32B24, Sunsimiao-Qwen2-7B25, ShizhenGP\nT-32B-LLM26, Zhongjing-GPT-13B27, and Taiyi 228.\nExperimental Setup.\nFor smaller, open-source models, we implemented local deployment\nusing\nthe\nSWIFT29\nframework,\nwith\nunified\ninvocation\nand\nevaluation\nvia\nan\nOpenAI-compatible interface. For larger-scale open-source models that are difficult to\ndeploy locally, as well as all closed-source models, including GPT-5, Gemini 2.5 Pro,\nDeepSeek-R1, Doubao-seed-1.6, Kimi-K2, and GLM-4.5, remote invocation and evaluation\nwere conducted via their official APIs. Only Taiyi 2 was loaded and evaluated locally using the\nTransformers30 library. In all evaluations, the temperature parameter was uniformly set to 0\nto ensure the stability and reproducibility of the results. Given that some LLMs lack\nreasoning capabilities, such as Kimi-K2 and Llama 4 Scout, this study used the --skip_think\nparameter to control whether to enable CoT quantitative evaluation.\nResults Analysis. Based on the evaluation framework constructed in this study, all the\naforementioned general and TCM domain LLMs were evaluated. The overall results are\nillustrated in Fig. 4.\n"}, {"page": 11, "text": "11\nFig. 4 Performance of 15 LLMs on the TCM-BEST4SDT benchmark dataset.\nFirst, several TCM domain LLMs demonstrated performance significantly superior to\nthat of the general domain models, such as ShizhenGPT-32B-LLM. This indicates that\nhigh-quality TCM corpora and supervised fine-tuning can effectively enhance their clinical\ninference capabilities.\nSecond, the majority of TCM domain LLMs lagged behind several general domain\nmodels, including Sunsimiao-Qwen2-7B, Zhongjing-GPT-13B, and Taiyi 2. This gap may stem\nfrom two factors. The first is that TCM domain LLMs generally have smaller parameter scales,\nrepresenting a significant disparity compared to generalist models. The second is that the\ntraining of these TCM domain LLMs may have relied excessively on medical or TCM corpora,\nwhereas real-world clinical scenario corpora are limited, leading to insufficient generalization\nability. TCM-BEST4SDT is centered on SDT capabilities. It places higher demands on the\ndecision-making abilities of LLMs in clinical contexts; consequently, the performance of these\nTCM models on this benchmark was relatively poor.\nThird, among the general domain LLMs, GPT-5 scored markedly lower than Gemini 2.5\nPro. This discrepancy likely reflects differences in the coverage of TCM-related data within\ntheir respective training corpora. Gemini 2.5 Pro may have incorporated more extensive\nmedical and TCM knowledge during its pre-training phase, thus equipping it with stronger\n"}, {"page": 12, "text": "12\nsemantic understanding and transfer capabilities when addressing TCM knowledge-intensive\ntasks.\nFourth, as illustrated in Fig. 5, the results for the Qwen3 series models exhibited a\nsteady upward trend in performance corresponding to the increase in model scale. This\nvalidates the effectiveness of scaling laws and simultaneously highlights the sensitivity and\nefficacy of TCM-BEST4SDT in discriminating between model capabilities.\nOverall, the evaluation results demonstrate that TCM-BEST4SDT can objectively reflect\nthe performance differences among various types of LLMs on TCM tasks and effectively\ndemonstrate their potential application value in real-world clinical scenarios. By constructing\na quantitative and reproducible evaluation system, this study provides a scientific basis for\nthe clinical application of TCM domain LLMs and further promotes the standardization and\nindustrialization of intelligent TCM research.\nFig. 5 Performance of Qwen3 models of different scales on the TCM-BEST4SDT benchmark\ndataset.\nData Availability\nTCM-BEST4SDT is publicly accessible and downloadable on Figshare (https://doi.org/10.\n6084/m9.figshare.30615956)15.\nCode Availability\nThe Python scripts used in the technical validation are available on Figshare (https://\ndoi.org/10.6084/m9.figshare.30615956)15 and GitHub (https://github.com/DYJG-research/\nTCM-BEST4SDT).\n"}, {"page": 13, "text": "13\nReferences\n1.\nZhang, Y. et al. Large language models to accelerate organic chemistry synthesis.\nNat Mach Intell 7, 1010–1022 (2025).\n2.\nLiu, X. et al. A generalist medical language model for disease diagnosis assistanc\ne. Nat Med 31, 932–942 (2025).\n3.\nGong, L., Jiang, J., Chen, S. & Qi, M. A syndrome differentiation model of TCM\nbased on multi-label deep forest using biomedical text mining. Front Genet 14, 1\n272016 (2023).\n4.\nYang, S. et al. Zhongjing: Enhancing the Chinese Medical Capabilities of Large Lan\nguage Model through Expert Feedback and Real-World Multi-Turn Dialogue. Proce\nedings of the AAAI Conference on Artificial Intelligence 38, 19368–19376 (2024).\n5.\nZhang, H. et al. HuatuoGPT, Towards Taming Language Model to Be a Doctor. in\nFindings of the Association for Computational Linguistics: EMNLP 2023 10859–10\n885, https://doi.org/10.18653/v1/2023.findings-emnlp.725 (2023).\n6.\nRen, M. et al. TCM-SD: A Benchmark for Probing Syndrome Differentiation via N\natural Language Processing. in Chinese Computational Linguistics 247–263, https://\ndoi.org/10.1007/978-3-031-18315-7_16 (2022).\n7.\nWang, Z. et al. TCMEval-SDT: a benchmark dataset for syndrome differentiation t\nhought of traditional Chinese medicine. Sci Data 12, 437 (2025).\n8.\nLiu, J. et al. Benchmarking Large Language Models on CMExam - A comprehensiv\ne Chinese Medical Exam Dataset. Advances in Neural Information Processing Syste\nms 36, 52430–52452 (2023).\n9.\nLi, J., Zhong, S. & Chen, K. MLEC-QA: A Chinese Multi-Choice Biomedical Questio\nn Answering Dataset. in Proceedings of the 2021 Conference on Empirical Method\ns in Natural Language Processing 8862–8874, https://doi.org/10.18653/v1/2021.em\nnlp-main.698 (2021).\n10. Cai, Y. et al. MedBench: A Large-Scale Chinese Benchmark for Evaluating Medical\nLarge Language Models. Proceedings of the AAAI Conference on Artificial Intellig\nence 38, 17709–17717 (2024).\n11. Wang, X. et al. CMB: A Comprehensive Medical Benchmark in Chinese. in Procee\ndings of the 2024 Conference of the North American Chapter of the Association f\nor Computational Linguistics: Human Language Technologies (Volume 1: Long Pap\ners) 6184–6205, https://doi.org/10.18653/v1/2024.naacl-long.343 (2024).\n12. OpenAI et al. OpenAI o1 System Card. Preprint at https://doi.org/10.48550/arXiv.2\n412.16720 (2024).\n"}, {"page": 14, "text": "14\n13. Guo, D. et al. DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement\nlearning. Nature 645, 633–638 (2025).\n14. Yang, A. et al. Qwen3 Technical Report. Preprint at https://doi.org/10.48550/arXi\nv.2505.09388 (2025).\n15. Guo J. TCM-BEST4SDT. figshare https://doi.org/10.6084/m9.figshare.30615956.v1 (2\n025).\n16. OpenAI. Introducing GPT-5, https://openai.com/index/introducing-gpt-5 (2025).\n17. Comanici, G. et al. Gemini 2.5: Pushing the Frontier with Advanced Reasoning, M\nultimodality, Long Context, and Next Generation Agentic Capabilities. Preprint at\nhttps://doi.org/10.48550/arXiv.2507.06261 (2025).\n18. ByteDance. Seed1.6 Tech Introduction, https://seed.bytedance.com/en/seed1_6 (20\n25).\n19. Team, K. et al. Kimi K2: Open Agentic Intelligence. Preprint at https://doi.org/10.\n48550/arXiv.2507.20534 (2025).\n20. Team, G.-4 5 et al. GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation M\nodels. Preprint at https://doi.org/10.48550/arXiv.2508.06471 (2025).\n21. Meta AI. The Llama 4 herd: The beginning of a new era of natively multimodal\nAI innovation, https://ai.meta.com/blog/llama-4-multimodal-intelligence (2025).\n22. Chen, J. et al. HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs. Pr\neprint at https://doi.org/10.48550/arXiv.2412.18925 (2024).\n23. Wei, S. et al. BianCang: A Traditional Chinese Medicine Large Language Model. IE\nEE Journal of Biomedical and Health Informatics 1–12, https://doi.org/10.1109/JBH\nI.2025.3612415 (2024).\n24. Team, B.-M. et al. Baichuan-M2: Scaling Medical Capability with Large Verifier Sys\ntem. Preprint at https://doi.org/10.48550/arXiv.2509.02208 (2025).\n25. Yan, X. et al. Sunsimiao: Chinese Medicine LLM. https://github.com/X-D-Lab/Sunsi\nmiao (2023).\n26. Chen, J. et al. ShizhenGPT: Towards Multimodal LLMs for Traditional Chinese Me\ndicine. Preprint at https://doi.org/10.48550/arXiv.2508.14706 (2025).\n27. Kang, Y. et al. CMLM-ZhongJing: Large Language Model is Good Story Listener. ht\ntps://github.com/pariskang/CMLM-ZhongJing (2023).\n28. Luo, L. et al. Taiyi: a bilingual fine-tuned large language model for diverse biome\ndical tasks. J Am Med Inform Assoc 31, 1865–1874 (2024).\n29. Zhao, Y. et al. SWIFT: A Scalable Lightweight Infrastructure for Fine-Tuning. Proce\nedings of the AAAI Conference on Artificial Intelligence 39, 29733–29735 (2025).\n"}, {"page": 15, "text": "15\n30. Wolf, T. et al. Transformers: State-of-the-Art Natural Language Processing. in Proc\needings of the 2020 Conference on Empirical Methods in Natural Language Proce\nssing: System Demonstrations 38–45, https://doi.org/10.18653/v1/2020.emnlp-demo\ns.6 (2020).\nAcknowledgements\nAll authors gratefully acknowledge financial support from Scientific and technological\ninnovation project of China Academy of Chinese Medical Sciences.\nAuthor contributions\nJ.G. conceived the study. K.L., Y.L. and L.L. were responsible for dataset collection. Z.S., H.D.,\nK.L., Y.L. and L.L. handled dataset annotation. J.G., Z.S. and H.D. wrote the code and\nperformed the experiments. K.L., J.G., Z.S., Y.Z. and L.D. co-drafted the initial manuscript and\noversaw its revision. All authors have read and approved the final manuscript.\nCompeting interests\nThe authors declare no competing interests.\nFunding\nThis study was supported by Scientific and technological innovation project of China\nAcademy of Chinese Medical Sciences (ZN2023A02).\n"}]}