{"doc_id": "arxiv:2512.20074", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2512.20074.pdf", "meta": {"doc_id": "arxiv:2512.20074", "source": "arxiv", "arxiv_id": "2512.20074", "title": "Reason2Decide: Rationale-Driven Multi-Task Learning", "authors": ["H M Quamran Hasan", "Housam Khalifa Bashier", "Jiayi Dai", "Mi-Young Kim", "Randy Goebel"], "published": "2025-12-23T05:58:47Z", "updated": "2025-12-23T05:58:47Z", "summary": "Despite the wide adoption of Large Language Models (LLM)s, clinical decision support systems face a critical challenge: achieving high predictive accuracy while generating explanations aligned with the predictions. Current approaches suffer from exposure bias leading to misaligned explanations. We propose Reason2Decide, a two-stage training framework that addresses key challenges in self-rationalization, including exposure bias and task separation. In Stage-1, our model is trained on rationale generation, while in Stage-2, we jointly train on label prediction and rationale generation, applying scheduled sampling to gradually transition from conditioning on gold labels to model predictions. We evaluate Reason2Decide on three medical datasets, including a proprietary triage dataset and public biomedical QA datasets. Across model sizes, Reason2Decide outperforms other fine-tuning baselines and some zero-shot LLMs in prediction (F1) and rationale fidelity (BERTScore, BLEU, LLM-as-a-Judge). In triage, Reason2Decide is rationale source-robust across LLM-generated, nurse-authored, and nurse-post-processed rationales. In our experiments, while using only LLM-generated rationales in Stage-1, Reason2Decide outperforms other fine-tuning variants. This indicates that LLM-generated rationales are suitable for pretraining models, reducing reliance on human annotations. Remarkably, Reason2Decide achieves these gains with models 40x smaller than contemporary foundation models, making clinical reasoning more accessible for resource-constrained deployments while still providing explainable decision support.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2512.20074v1", "url_pdf": "https://arxiv.org/pdf/2512.20074.pdf", "meta_path": "data/raw/arxiv/meta/2512.20074.json", "sha256": "ecdee261d4642efafa8b4670c3f41aa091a876b2049c470e1a11017515225bba", "status": "ok", "fetched_at": "2026-02-18T02:23:56.995367+00:00"}, "pages": [{"page": 1, "text": "Reason2Decide: Rationale-Driven Multi-Task Learning\nH M Quamran Hasan, Housam Khalifa Bashier, Jiayi Dai,\nMi-Young Kim†, Randy Goebel\nUniversity of Alberta\nEdmonton, Alberta, Canada\n† Camrose, Alberta, Canada\n{hmquamra, khalifab, dai1, miyoung2, rgoebel}@ualberta.ca\nAbstract\nDespite the wide adoption of Large Language Models (LLM)s, clinical decision support systems face a critical\nchallenge: achieving high predictive accuracy while generating explanations aligned with the predictions. Current\napproaches suffer from exposure bias leading to misaligned explanations. We propose Reason2Decide, a two-stage\ntraining framework that addresses key challenges in self-rationalization, including exposure bias and task separation.\nIn Stage-1, our model is trained on rationale generation, while in Stage-2, we jointly train on label prediction and\nrationale generation, applying scheduled sampling to gradually transition from conditioning on gold labels to model\npredictions. We evaluate Reason2Decide on three medical datasets, including a proprietary triage dataset and\npublic biomedical QA datasets. Across model sizes, Reason2Decide outperforms other fine-tuning baselines and\nsome zero-shot LLMs in prediction (F1) and rationale fidelity (BERTScore, BLEU, LLM-as-a-Judge). In triage,\nReason2Decide is rationale source-robust across LLM-generated, nurse-authored, and nurse-post-processed\nrationales. In our experiments, while using only LLM-generated rationales in Stage-1, Reason2Decide outperforms\nother fine-tuning variants. This indicates that LLM-generated rationales are suitable for pretraining models, reducing\nreliance on human annotations. Remarkably, Reason2Decide achieves these gains with models 40× smaller than\ncontemporary foundation models, making clinical reasoning more accessible for resource-constrained deployments\nwhile still providing explainable decision support.\nKeywords: Explainable AI, Explainability, Interpretability, Self-Explainable Models\n1.\nIntroduction\nThe integration of reasoning capabilities with pre-\ndiction tasks has been a critical research prob-\nlem in natural language processing (NLP). Existing\nstate-of-the-art language models struggle to bal-\nance high predictive accuracy while also generating\nhuman-interpretable explanations (Niu et al., 2025).\nAlthough LLMs have demonstrated strong perfor-\nmance on various question-answering benchmarks\n(Hendrycks et al., 2021; Srivastava et al., 2023),\ntheir ability to provide rationales that align with their\npredictions remains limited. This limitation is sub-\nstantially amplified in healthcare where explana-\ntions are essential for trust and adoption.\nCurrent approaches for rationale generation face\ntwo fundamental challenges. First, the exposure\nbias problem (Schmidt, 2019), which arises when\nmodels are trained to generate rationales condi-\ntioned only on ground-truth labels, but need to ex-\nplain their own potentially incorrect predictions dur-\ning inference. Second, the task separation prob-\nlem, which occurs when prediction and rationale\ngeneration are treated independently rather than\nas mutually supporting tasks (Narang et al., 2020).\nWhile multi-task learning has shown promising per-\nformance, existing methods have failed to address\nthe train-test discrepancy: models exclusively learn\nto explain gold-standard labels during training, leav-\ning them unprepared for rationalizing their own pre-\ndiction during inference.\nRecent work has acknowledged these chal-\nlenges and explored various approaches to improve\nmodel interpretability.\nFor example, “Chain-of-\nThought” (CoT) prompting (Wei et al., 2022) demon-\nstrates that step-by-step reasoning can improve\ncomplex reasoning; similarly, self-consistency tech-\nniques (Wang et al., 2023) show the value of\naggregating multiple reasoning paths. However,\nthese methods primarily focus on inference time\nstrategies rather than addressing the fundamen-\ntal training dynamics that help establish more ro-\nbust reasoning capabilities.\nKnowledge distilla-\ntion approaches (Hsieh et al., 2023) and rationale-\naugmented training (Lampinen et al., 2022) have\nalso shown benefits, but do not train models to\ngenerate explanations conditioned on their own\npredictions during training.\nHere we propose Reason2Decide (Figure 1), a\nframework which trains a single model to jointly\npredict and generate rationales. Our approach con-\nsists of a two-stage training regime, based on in-\nsights from curriculum learning (Bengio et al., 2009)\nand scheduled sampling (Bengio et al., 2015). The\nidea is to first learn to model explanation funda-\nmentals and then jointly produce predictions and\nrationales, where we gradually shift from gold-label\nconditioning to self-conditioning. Through this pro-\narXiv:2512.20074v1  [cs.AI]  23 Dec 2025\n"}, {"page": 2, "text": "cess, the model learns to explain its own predic-\ntions. This addresses the exposure bias problem\nwhile promoting alignment between predictions and\nrationales. The main contributions of this paper are:\n• We propose Reason2Decide, a two-stage\ntraining framework for LLMs that first learns\nthe fundamentals of explanation generation\nfrom rationales and then jointly optimizes pre-\ndictions and rationales in a multi-task setup.\n• We introduce a scheduled sampling mecha-\nnism that gradually transitions from gold labels\nto predicted label conditioning, mitigating ex-\nposure bias in self-rationalization.\n2.\nRelated Work\nOur work builds upon research in rationale gener-\nation, multi-task learning, and existing methods to\nmitigate exposure bias.\n2.1.\nRationale Generation and\nExplainable AI\nA primary goal of Explainable AI (XAI) is making\nmodel decisions transparent and interpretable. The\ndevelopment of early XAI methods focused on post-\nhoc explanation generation by analyzing model in-\nternals or feature importance (Ribeiro et al., 2016;\nLundberg and Lee, 2017). But recently, the field\nhas shifted towards self-explaining models that can\nlearn to generate rationales simultaneously with\ntheir predictions (Camburu et al., 2018). Our work\naligns with the latter. For instance, (Narang et al.,\n2020) fine-tuned T5 (Raffel et al., 2023) models to\ngenerate explanations by treating them as a sepa-\nrate task. Similarly, (Lampinen et al., 2022) demon-\nstrate that incorporating natural language explana-\ntions during training can improve reasoning and\ngeneralization. However, these approaches often\ntreat the explanation as a secondary output, which\ncreates a separation between the prediction and\nits explanation. In contrast, our Reason2Decide\nframework is designed to align the predictive task\nwith the explanatory one, to help ensure that the\nexplanation is an integral part of the reasoning pro-\ncess.\n2.2.\nMulti-Task Learning and Knowledge\nDistillation\nMulti-Task Learning aims to improve generalization\nby leveraging shared representations across re-\nlated tasks (Ruder, 2017; Caruana, 1997). In NLP,\nmodels like T5 are considered multi-task learners\nby combining diverse problems into a unified text-\nto-text format. We similarly use this foundation but\nspecifically focus on the alignment between predic-\ntion and rationales. Closely related work includes\nknowledge distillation approaches that use ratio-\nnales. Hsieh et al. (2023) distills the capabilities\nof a larger teacher model that generates step-by-\nstep rationales into a smaller student model. While\nthis approach can be effective in improving predic-\ntive accuracy, it does not explicitly enforce predic-\ntion–explanation coordination. The student model\nbenefits from teacher rationales but is not trained\nto ensure that its own predictions and explanations\nare self-consistent. Our method addresses this by\nexplicitly training the coordination between predic-\ntion and rationale generation.\n2.3.\nMitigating Exposure Bias and\nScheduled Sampling\nExposure bias in self-rationalization occurs when\nmodels are trained to generate explanations con-\nditioned on gold labels but at inference time must\njustify their own predictions. Scheduled sampling\n(Bengio et al., 2015) addresses the issue by gradual\nreplacement of teacher-forced tokens with model-\ngenerated ones. Here, we adapt this principle to\nthe task level, thus treating the model’s predicted\nlabel as the conditioning context for rationale gen-\neration. Our mechanism systematically transitions\nfrom using gold labels to the model’s own predic-\ntions, directly mitigating this bias and preparing\nmodels for real-world deployment.\n3.\nMethodology\nOur method addresses the problem of combined\nprediction and rationale generation, where given\nan input x (clinical note or biomedical question),\na model must predict a discrete label y ∈Y and\ngenerate a free-text rationale r which justifies the\nprediction.\nTo do so, we employ a single encoder-decoder\narchitecture fθ (T5 variants) that handles both tasks.\nFor example, the model first predicts the label as\npredict:x 7→ˆy, then employs the label to con-\ndition the rationale as: given label:y∗or ˆy,\nexplain:x 7→ˆr, where y∗is the gold label, ˆy is\nthe model’s predicted label, and ˆr is the generated\nrationale.\n3.1.\nStage-1: Rationale Foundation\nTraining\nPrevious work has shown that domain-specific pre-\ntraining significantly improves model performance\nin specialized tasks (Lewis et al., 2020; Lee et al.,\n2019). With this motivating background, our first\nstage teaches explanation fundamentals by training\nthe model to generate rationales. Let θ denote the\n"}, {"page": 3, "text": "Gold label, y*\nScheduled \nSampler\nStage-1\nStage-2\nTriage Note\nNo Vomiting.\ntemp: 37\nmild pain: 6/10 \nbreathing: yes\n.............\nTriage Note\nNo Vomiting.\ntemp: 37\nmild pain: 6/10 \nbreathing: yes\n.............\nGenerated \nExplanation\nGenerated \nExplanation\nPredicted \nLabel, ŷ\nPrompt \nconditioned on \ny* or ŷ\nTriage Note\nNo Vomiting.\ntemp: 37\nmild pain: 6/10 \nbreathing: yes\n.............\nprediction\nPrompt conditioned on \nprediction\nPrediction\n+\nExplanation\nReview by Healthcare \nProfessional\nFinal advice \nto patient\nStage 1 \ncheckpoint\nFinal Model\nInference\nFigure 1: Overview of Reason2Decide. Stage-1 trains rationale generation. Stage-2 jointly predicts labels\nand generates label-conditioned explanations with task-level scheduled sampling. A single T5 model is\nused throughout; inference conditions explanations on the model’s own prediction.\nparameters of the T5 model. Given a gold rationale\nr∗, we optimize:\nLstage1 = −log Pθ(r∗| explain:x)\nwhere Pθ(r∗| ·) denotes the autoregressive proba-\nbility of the full rationale token sequence. The best\nmodel checkpoint is used to initialize Stage-2.\nThis two-stage structure follows a curriculum-\ninspired design, where the model first learns ex-\nplanation fundamentals before being required to\njustify its own predictions.\n3.2.\nStage-2: Joint optimization of\nPrediction and Explanation with\nTask-Level Scheduled Sampling\nThe second stage jointly optimizes prediction and\nexplanation, starting with gold labels and gradually\nshifting to predicted labels for conditioning.\nPrediction Task:\nThe model treats label predic-\ntion as a text generation task, optimized via cross-\nentropy loss:\nLpred = −log Pθ\n\u0000y∗\f\f predict:x\n\u0001\nwhere Pθ(y∗| ·) denotes the autoregressive proba-\nbility of the full gold label sequence.\nExplanation\nwith\nTask-Level\nScheduled\nSampling:\nTo mitigate exposure bias in self-\nrationalization, we introduce a scheduled sampling\nmechanism. Unlike prior token-level scheduled\nsampling (Bengio et al., 2015), which replaces\ntarget tokens within sequences, we apply it at the\ntask level by switching the conditioning context\nfrom gold labels to model-predicted labels. For\ninstance, instead of gradually replacing reference\ntokens in a generated sequence, our method\ngradually replaces reference labels used for\nconditioning the rationale generation.\nFor each example we condition on either the gold\nlabel y∗or the model prediction ˆy (greedily decoded\nduring training):\n˜y =\n(\ny∗\nwith probability 1 −πt\nˆy\nwith probability πt\nwhere πt follows a linear schedule. With total\ntraining steps T, warm-up phase w = 0.05T, tran-\nsition phase m = 0.60T, for step t:\nπt =\n\n\n\n\n\n\n\n\n\n\n\n0,\n0 ≤t < w,\nmin\n\u0012\n0.9, t −w\nm\n\u0013\n,\nw ≤t < w + m,\n0.9,\nt ≥w + m.\nThe ceiling 0.9 was a design choice to prevent\nthe model from fully relying on self-generated labels\nduring training to help avoid error amplification from\nincorrect predictions. The hyperparameters (0.05\nand 0.6) were determined through hyperparameter\noptimization using a few sets of predefined tuples,\nand are motivated by two key considerations:\nWarm-up Phase:\nDuring 0 < t < w, we linearly\nincrease αt from 0 to 0.7. This is to prioritize ex-\nplanation loss Lexpl over prediction loss Lpred, to\nprovide a smoother transition from single-task to\n"}, {"page": 4, "text": "multi-task optimization. After this phase αt is held\nconstant at 0.7 for the rest of the training. We heuris-\ntically selected 0.7 to balance both tasks, with a\nslight bias towards predictions, as Stage-1 already\nteaches rationale generation.\nTransition Phase:\nDuring w ≤t < w + m, we\ngradually increase the fraction of predicted labels\nused for conditioning from 0 to 0.9. This transi-\ntion period is to systematically address exposure\nbias by training the model to learn coherent ratio-\nnale generation conditioned on its own (potentially\nimperfect) predictions, bridging the gap between\ntraining and inference conditions.\nThe explanation loss is:\nLexpl = −log Pθ(r∗| prompt)\nwhere prompt = given label:˜y, explain:x.\nPθ(r∗| ·) denotes the autoregressive probability of\nthe full rationale token sequence.\nThe total loss combines both objectives with\nadaptive weighting:\nLtotal = αtLpred + (1 −αt)Lexpl\n3.3.\nInference\nDuring inference, we first predict the label via\ngreedy decoding:\nˆy = arg max\ny\nPθ(y | predict:x)\nand then generate the rationale, via greedy decod-\ning, conditioned on that prediction:\nˆr = arg max\nr\nPθ(r | prompt),\nwhere prompt = given label:ˆy, explain:x.\n4.\nExperiments\nIn this section we introduce the datasets, provide\nimplementation details, followed by the experimen-\ntal results.\n4.1.\nTasks and Datasets\nWe evaluate Reason2Decide on one proprietary\nclinical decision-making task (triage notes), and two\npublic biomedical QA benchmarks (PubMedQA,\nBioASQ). As models we use T5-Small/Base/Large\nand zero-shot LLMs as non-fine-tuned references.\n4.1.1.\nClinical Triage Dataset\nThe Clinical Triage Dataset is derived from a Cana-\ndian provincial health service. The dataset con-\ntains triage notes authored by nurses based on tele-\nphone triage dialogue with calling patients, along\nwith the recommended care disposition and a ra-\ntionale for that disposition choice. Specific data\nsource details are omitted to preserve anonymity.\nTask: Given a nurse triage note, predict a dis-\nposition (care pathway) and generate a rationale\nfor the decision. The label space consists of 12\nclasses ranging from low (Home Care) to high ur-\ngency (Go to Emergency Department (ED) now).1\nRationale sources: We use three versions of\nrationales to assess source robustness:\n• Nurse-authored rationales (original)\n• Nurse post-processed rationales (lightly edited\nby an LLM)\n• LLM-generated rationales (full generation us-\ning an LLM)\nTable 1 shows sample rationales of each type. The\npost-processed version is there because the orig-\ninal version consists of atomic facts and are not\nalways grammatically correct. We use 2 a Qwen-3\n8B (Team, 2025) model to convert them into gram-\nmatically correct full sentences without adding new\ninformation. For LLM-generated notes, we provide\nthe model the triage note and disposition and ask\nit to explain why the disposition was chosen. For\nexperiments on the whole dataset, we used the\nLLM-generated rationales.\nData split: The train, validation and test sets\nconsist of 170,695, 21,312 and 9,704 samples re-\nspectively.\n4.1.2.\nPubMedQA\nTask:\nBiomedical\nquestion\nanswering\nwith\nYes/No/Maybe labels (Jin et al., 2019). We con-\ncatenate the question and context as the model\ninput as triage note replacement.\nRationales:\nWe\nuse\nthe\ndataset’s\nlong_answer field as the gold-standard ra-\ntionale.\nData split: We draw 100k stratified random\nsamples (by labels) using a fixed seed from\npqa_artificial (the dataset artificially generated),\nand create a 70k/20k/10k train/validation/test split.\nWe then augment the test set with the 1k samples\nin pqa_labeled, as they are human annotated data,\nresulting in final splits of 70k (train), 20k(validation),\nand 11k (test: 10k pqa_artificial + 1k pqa_labeled).\n4.1.3.\nBioASQ (Task B, Yes/No)\nTask: Biomedical question answering dataset from\nthe BioASQ 13 challenge (Nentidis et al., 2025).\n1A complete list of the 12 disposition classes is pro-\nvided in the Appendix, Subsection 9.2\n2All prompts used are provided in the Appendix, Sub-\nsection 9.1.\n"}, {"page": 5, "text": "Nurse-\nauthored\nPost-\nprocessed\nLLM-generated\n[1] Earache\nAND [2]\nMODERATE\npain OR\nSEVERE pain\ninadequately\ntreated per\nguideline advice\n- yes\nThe patient has\nan earache with\nmoderate or\nsevere pain\ninadequately\ntreated\naccording to\nguideline\nadvice.\nPersistent\nsevere ear pain\nwithout fever or\ninfection signs\nrequires timely\nmedical\nevaluation to\nprevent\ncomplications\nand ensure\nappropriate\ntreatment.\n[1] MILD-\nMODERATE\npain AND [2]\nconstant AND\n[3] present > 2\nhours\nThe patient has\nmild to\nmoderate pain\nthat is constant\nand has been\npresent for more\nthan two hours.\nUrgent\nevaluation\nneeded due to\npersistent\nabdominal pain,\nbowel changes,\nand recent\nconfusion, to\nrule out serious\nconditions and\nensure\nappropriate\ntreatment.\nTable 1: Sample rationale variants.\nFor our experiments, we focus on yesno questions\n(binary classification).\nRationales: We extract and concatenate the\nsnippets to serve as rationales for each question.\nBecause the concatenated snippets can be long,\nwe first summarize them with a Qwen-3-8B model\nand use the summary as the gold rationale.\nData split: The official training dataset consists\nof 1,459 yesno questions. We randomly select 250\nquestions for our validation set, and 1,209 ques-\ntions for the train set. For the test set, we use\nthe concatenation of the four official test batches,\nyielding 82 questions.\n4.2.\nImplementation Details\nWe implement Reason2Decide using T5 Small\n(77M), Base (250M), Large (800M) architectures\nusing A100 X 4 GPUs.3 Training uses AdamW op-\ntimizer (Loshchilov and Hutter, 2019) with learning\nrate 5 × 10−5, max input length = 1024, and effec-\ntive batch size = 64. Model-specific configuration\nis provided in Table 2.\nFor Stage-1, we monitor validation loss and early\nstop with patience of 3 validation evaluations. For\nStage-2, We use delayed early stopping, with a pa-\n3Source code available at: https://github.com/\nquamranhasan/Reason2Decide\ntience of 5, that activates only after the scheduled\nsampling phase completes. This is to ensure the\nmodel fully benefits from our warm-up and sched-\nuled sampling recipe.\nDuring validation, we evaluate only the predic-\ntion task using F1-score, treating rationales as an\nauxiliary training signal. The best model check-\npoint (highest F1-score) is loaded at the end of\ntraining. The models are trained using publicly\navailable packages from https://github.com/\nhuggingface/transformers.\nModel\nPer-GPU Batch\nGrad Accum\nT5-Small\n16\n1\nT5-Base\n4\n4\nT5-Large\n2\n8\nTable 2: Training configuration by model size. Ef-\nfective batch size is Per-GPU Batch × #GPUs ×\nGrad Accum.\n4.3.\nBaselines\nWe compare Reason2Decide against the following:\n• Standard fine-tuning (SFT): Single-task la-\nbel prediction without rationales (Howard and\nRuder, 2018); model selection by validation\nMacro-F1.\n• Distilling Step-by-Step (DSS): Multi-task\ntraining following (Hsieh et al., 2023). We run\ntwo selection criteria:\n– DSS-Loss: Model selection by validation\nloss (as in Hsieh et al. (2023)).\n– DSS-F1: Model selection by validation\nMacro-F1 (to align with our selection pro-\ntocol).\nImplementation follows the authors’ release.\n• Zero-shot LLMs: Zero-shot baselines without\ntask-specific fine-tuning, using open-source\nmodels including Qwen-3-8B and Qwen-3-\n32B (Team, 2025), as well as Llama-3.1-Aloe-\nBeta-8B (Garcia-Gasulla et al., 2025).\nProtocol:\nFor all fine-tuned baselines, we use the\nsame optimizer, learning rate, effective batch size\nas our method; per-device batch sizes are set fol-\nlowing Table 2. Early stopping is used with patience\nof 5 validation evaluations. Model selection is by\nvalidation Macro-F1 unless otherwise stated (DSS-\nLoss). We report means over three seeds/runs.\nWe use greedy decoding to ensure run-to-run de-\nterminism.\n"}, {"page": 6, "text": "4.4.\nEvaluation\nWe provide a comprehensive evaluation across\npredictive performance and rationale quality:\nPredictive Performance:\nWe report Accuracy\nand Macro-F1 on the discrete label space (dispo-\nsitions for triage; Yes/No/Maybe for PubMedQA;\nYes/No for BioASQ). Scores are computed on held-\nout test sets. Due to the high class imbalance in\nthe Triage Dataset (major and minor classes have\n33, 633 and 239 samples respectively in the training\nset), we primarily rely on Macro-F1.\nRationale Fidelity:\nWe assess explanation qual-\nity with:\n• BERTScore (Zhang et al., 2020) (F1 variant):\nSemantic similarity between generated and\ngold rationales.\n• BLEU (Papineni et al., 2002): N-gram overlap\nfor surface-level quality.\n• LLM-as-a-Judge:\nFollowing recent work\ndemonstrating strong alignment between LLM\nand human evaluation (Zheng et al., 2023; Niu\net al., 2025), we employ Qwen-3-8B for expert-\nstyle assessment on random 2k samples for\nthe Triage Dataset and PubMedQA, and the\nwhole test set for BioASQ (82 samples). We\nevaluate three defined metrics:\nCorrectness: 5-point scale for clinical align-\nment between the rationales and predictions.\nThe motivation is “If the predicted disposition\nis Go to L&D now, does the generated ra-\ntionale justify the decision - not homecare?\"\nTo ensure consistent evaluation, we gener-\nated standardized disposition definitions using\nprompt-based refinement with a Qwen-3-32B\nmodel.\nCoverage: 5-point scale that evaluates infor-\nmation retention. Scores measure how much\nrelevant clinical information from the generated\nrationale is in the original triage note.\nOverlap: 5-point scale for semantic content\npreservation between the gold and generated\nrationale.\nFor the triage dataset, we report all three LLM-as-\na-Judge metrics. For PubMedQA and BioASQ, we\nonly report overlap, as the others do not strictly\nalign with QA datasets, due to missing triage notes\nand simple (yes/no/maybe)labels, respectively.\n4.5.\nResults\n4.5.1.\nRationale Source Robustness\nWe evaluate Reason2Decide’s robustness to ra-\ntionale source variations by training Stage-1 ex-\nclusively on LLM-generated rationales, and in\nStage-2, using the matching rationale variant (LLM-\ngenerated, nurse-authored, post-processed). As\nshown in Table 3, Reason2Decide maintains con-\nsistent performance across rationale variants while\noutperforming all baselines on both prediction and\nrationale metrics, with +0.37 to +6.09 F1 over DSS\nvariants. Although this experiment was conducted\non only 12% of the dataset, our method produces\nobservable gains in data-scarce clinical situations.\nDespite training on LLM-generated rationales\nonly during Stage-1, Reason2Decide shows 51%\nlower F1 variation than DSS-F1 (1.08-point spread\nvs 2.21) and better rationale metrics.\nThe F1\ngains demonstrate that rationale pretraining pro-\nvides transferable reasoning benefits that improve\nprediction, and not only explanation generation.\nThis pattern suggests that LLM rationales may sub-\nstitute for human-authored rationales during pre-\ntraining, thereby reducing reliance on costly human\nrationales. Our method demonstrates strong ra-\ntionale source robustness, successfully adapting\nto different rationale styles during Stage-2 training,\nachieving best performance on post-processed ra-\ntionales (51.14 F1) with consistent gains across\nrationale sources in BERTScore, BLEU, and LLM-\nas-a-Judge Overlap.\n4.5.2.\nConsistent Performance Across Model\nSizes and Tasks\nFrom Table 4, across all three datasets, Rea-\nson2Decide shows improvement over other fine-\ntuned variants. For Clinical Triage, Reason2Decide\noutperforms every other baselines, across model\nsizes.\nSimilar results are observed with PubMedQA,\nwith Reason2Decide outperforming other variants\nwith the Small and Large models. Despite slightly\nlagging behind DSS F1 with the Base model, Rea-\nson2Decide outperforms DSS F1 on BLEU and\nBERTScore.\nBioASQ proved to be a challenging dataset for\nall fine-tuned variants, possibly due to its limited\ndata size. Although Reason2Decide outperforms\nthe baselines on the Small and Base models, SFT\ntakes the win with the Large model.\nReason2Decide outperformed both Qwen mod-\nels on all datasets.\nHowever, Aloe-8B scores\nthe highest on BioASQ. This can be attributed\nto its pretraining on biomedical literature, which\nclosely matches the domain and format of BioASQ,\nbut differs from the conversational and reasoning-\noriented style of the triage and PubMedQA\ndatasets.\nWhile T5-Large (800M) is 40× smaller than the\n32B Qwen model and is not a foundation model pre-\ntrained on medical corpora, it outperformed Qwen-\n3-32B on all three datasets and Aloe-8B on 2/3\n"}, {"page": 7, "text": "Rationale Source\nMethod\nMacro F1\nBERTSc.\nBLEU\nOverlap\nSFT\n48.78 ± 0.44\n-\n-\n-\nLLM-generated\nDSS-F1\n49.69 ± 0.58\n90.68 ± 0.12\n15.00 ± 0.44\n2.43\nDSS-Loss\n47.27 ± 0.40\n90.38 ± 0.05\n13.72 ± 0.17\n2.37\nReason2Decide\n50.06 ± 0.14\n91.02 ± 0.02\n16.46 ± 0.06\n2.50\nNurse-authored\nDSS-F1\n48.01 ± 0.39\n87.67 ± 0.06\n24.88 ± 0.40\n2.51\nDSS-Loss\n46.76 ± 1.02\n87.51 ± 0.07\n23.87 ± 0.39\n2.47\nReason2Decide\n50.76 ± 1.01\n88.06 ± 0.23\n26.62 ± 1.44\n2.62\nPost-processed\nDSS-F1\n47.48 ± 2.11\n90.15 ± 0.13\n22.47 ± 0.85\n2.54\nDSS-Loss\n45.05 ± 3.07\n89.89 ± 0.03\n20.68 ± 0.23\n2.48\nReason2Decide\n51.14 ± 0.44\n90.46 ± 0.07\n24.03 ± 0.55\n2.64\nTable 3: Rationale Source Robustness on Clinical Triage (T5-Small on 12% of Clinical Triage Dataset)\nDataset\nModel\nMethod\nMacro F1\nAccuracy\nBERTSc.\nBLEU\nClinical Triage\nT5-Small\nSFT\n52.69 ± 0.86\n-\n-\n-\nDSS-Loss\n52.73 ± 0.99\n-\n91.14 ± 0.09\n17.37 ± 0.45\nDSS-F1\n52.09 ± 0.50\n-\n90.99 ± 0.06\n16.72 ± 0.33\nReason2Decide\n55.88 ± 0.01\n-\n91.52 ± 0.06\n19.33 ± 0.29\nT5-Base\nSFT\n57.10 ± 1.15\n-\n-\n-\nDSS-Loss\n53.26 ± 0.89\n-\n91.78 ± 0.04\n20.86 ± 0.27\nDSS-F1\n54.53 ± 2.63\n-\n91.56 ± 0.32\n19.50 ± 1.70\nReason2Decide\n59.92 ± 0.42\n-\n92.09 ± 0.02\n22.74 ± 0.06\nT5-Large\nSFT\n56.85 ± 7.21\n-\n-\n-\nDSS-Loss\n58.09 ± 0.77\n-\n92.08 ± 0.05\n22.73 ± 0.17\nDSS-F1\n59.43 ± 1.07\n-\n92.20 ± 0.03\n23.56 ± 0.09\nReason2Decide\n60.58 ± 0.46\n-\n92.30 ± 0.03\n24.13 ± 0.19\nAloe-8B\nZero-Shot\n24.73 ± 0.00\n-\n-\n-\nQwen-3-8B\n23.28 ± 0.00\n-\n-\n-\nQwen-3-32B\n28.03 ± 0.00\n-\n-\n-\nPubMedQA\nT5-Small\nSFT\n52.18 ± 0.07\n91.87 ± 0.34\n-\n-\nDSS-F1\n53.63 ± 0.57\n93.12 ± 0.16\n89.14 ± 0.01\n6.36 ± 0.06\nDSS-Loss\n53.63 ± 0.07\n93.14 ± 0.08\n89.11 ± 0.05\n6.27 ± 0.07\nReason2Decide\n55.02 ± 0.16\n93.51 ± 0.14\n89.30 ± 0.03\n6.76 ± 0.15\nT5-Base\nSFT\n57.31 ± 0.16\n94.58 ± 0.11\n-\n-\nDSS-F1\n58.16 ± 0.11\n95.00 ± 0.03\n89.40 ± 0.04\n6.93 ± 0.13\nDSS-Loss\n57.69 ± 0.25\n94.79 ± 0.14\n89.40 ± 0.01\n6.82 ± 0.10\nReason2Decide\n58.10 ± 0.22\n95.04 ± 0.09\n89.51 ± 0.03\n7.17 ± 0.04\nT5-Large\nSFT\n59.60 ± 0.26\n95.72 ± 0.17\n-\n-\nDSS-F1\n59.92 ± 0.21\n95.90 ± 0.06\n89.62 ± 0.04\n7.41 ± 0.12\nDSS-Loss\n59.74 ± 0.26\n95.70 ± 0.28\n89.61 ± 0.03\n7.08 ± 0.09\nReason2Decide\n60.28 ± 0.05\n96.05 ± 0.01\n89.60 ± 0.05\n7.64 ± 0.15\nAloe-8B\nZero-Shot\n45.33 ± 0.00\n95.25 ± 0.00\n-\n-\nQwen-3-8B\n52.85 ± 0.00\n87.89 ± 0.00\n-\n-\nQwen-3-32B\n58.33 ± 0.00\n90.83 ± 0.00\n-\n-\nBioASQ\nT5-Small\nSFT\n64.81 ± 2.09\n72.76 ± 1.86\n-\n-\nDSS-F1\n66.02 ± 1.19\n71.14 ± 0.70\n84.16 ± 0.43\n2.68 ± 0.14\nDSS-Loss\n40.47 ± 2.14\n65.04 ± 1.41\n82.80 ± 0.39\n1.86 ± 0.15\nReason2Decide\n67.57 ± 2.26\n73.58 ± 0.70\n85.14 ± 0.18\n3.27 ± 0.09\nT5-Base\nSFT\n53.70 ± 12.29\n67.88 ± 2.54\n-\n-\nDSS-F1\n66.28 ± 0.54\n71.54 ± 1.86\n85.78 ± 0.14\n3.85 ± 0.02\nDSS-Loss\n59.99 ± 13.58\n71.14 ± 6.72\nX\nX\nReason2Decide\n68.02 ± 2.19\n73.98 ± 1.41\n85.64 ± 0.30\n3.55 ± 0.10\nT5-Large\nSFT\n66.80 ± 2.64\n73.98 ± 1.41\n-\n-\nDSS-F1\n65.73 ± 2.15\n70.73 ± 2.44\n85.79 ± 0.25\n3.43 ± 0.29\nDSS-Loss\n44.55 ± 4.19\n67.48 ± 1.41\nX\nX\nReason2Decide\n66.58 ± 4.57\n73.17 ± 2.44\n85.80 ± 0.11\n3.39 ± 0.26\nAloe-8B\nZero-Shot\n79.09 ± 0.00\n81.71 ± 0.00\n-\n-\nQwen-3-8B\n50.32 ± 0.00\n75.61 ± 0.00\n-\n-\nQwen-3-32B\n50.69 ± 0.00\n76.83 ± 0.00\n-\n-\nTable 4: Performance comparison across datasets. Best F1 score per dataset is bold+underlined. Best\nfine-tuning strategy per model size is bold. Standard deviations are shown as ± values. Instances where\nrationale generation is non-applicable are shown as -. Instances where the model failed to generate a\nrationale are shown as X.\ndatasets, narrowing the performance gap between\nLLMs and smaller language models.\n"}, {"page": 8, "text": "4.5.3.\nRationale Analysis\nBLEU and BERTScore: As shown in Table 4,\non Clinical Triage, for all three model sizes, Rea-\nson2Decide outperforms DSS variants in both met-\nrics. On PubMedQA and BioASQ, we observe\nsimilar trends with Reason2Decide scoring com-\npetitively with DSS variants.\nLLM-as-a-Judge Evaluation: To assess the\nquality of generated rationales, we evaluate three\nmetrics as defined earlier. These were scored on a\n(1 −5) Likert scale. From Table 5, Reason2Decide\nscores the highest in all metrics with the Small and\nBase model variants. With the Large model, the\noverlap and coverage scores are very close,\nwith our proposed method scoring comparatively\nhigher in correctness.\nA sample prediction and rationale is provided in\nTable 6.\nModel Size\nMethod\nCoverage\nCorrectness\nOverlap\nT5-Small\nDSS-Loss\n4.52\n4.02\n2.50\nDSS-F1\n4.50\n3.96\n2.48\nReason2Decide\n4.62\n4.26\n2.58\nT5-Base\nDSS-Loss\n4.74\n4.09\n2.57\nDSS-F1\n4.71\n4.05\n2.55\nReason2Decide\n4.76\n4.37\n2.61\nT5-Large\nDSS-Loss\n4.78\n4.13\n2.60\nDSS-F1\n4.81\n4.19\n2.61\nReason2Decide\n4.80\n4.43\n2.63\nTable 5: LLM-as-a-Judge evaluation metrics.\nMethod\nRationale and Prediction\nGold Standard\nRationale: Infant has repeated episodes of gasping for air, indicat-\ning possible serious breathing difficulty requiring immediate medical\nevaluation.\nPrediction: Go to ED Now\nReason2Decide Rationale: Infant has repeated episodes of gasping for air, indicat-\ning possible serious breathing difficulty requiring immediate medical\nevaluation.\nPrediction: Go to ED Now\nDSS-F1\nRationale: Infant’s frequent gasping episodes with fever require im-\nmediate evaluation to rule out serious respiratory issues despite\nnormal appearance and no worsening symptoms.\nPrediction: See Physician or PCP within 24 Hours\nDSS-Loss\nRationale: Infant’s frequent gasping episodes with normal breathing\nand no fever require prompt medical evaluation to rule out serious\nrespiratory issues.\nPrediction: Go to ED Now\nTable 6: Sample rationale and prediction. Rea-\nson2Decide produced gold-aligned rationale and\nprediction; DSS-F1 gave contradicting rationale\nand prediction; DSS-Loss made correct prediction\nbut with inaccurate rationale.\n4.6.\nAblation Study\nWe performed ablations to assess the contribution\nof each component in our Reason2Decide frame-\nwork. Table 7 shows that removing Stage-1 consis-\ntently hurt performance across datasets, confirm-\ning that explanation-focused pretraining improves\ndownstream decision-making. Stage-2 is essential\nfor predictions, because the Stage-1 model only\nlearns to generate explanations.\nThe primary purpose of scheduled sampling is ra-\ntionale alignment via exposure-bias mitigation. This\nis reflected with its equal or higher BERT and BLEU\nscores across both datasets. Additionally, it im-\nproves prediction on complex, multi-class datasets\nlike Clinical Triage (59.92 vs. 57.28 F1), suggesting\nthat training with realistic inference conditions could\nprovide a greater benefit for challenging prediction\ntasks.\nIncluding warm-up steps slightly improved perfor-\nmance on Clinical Triage across all metrics. Remov-\ning warm-up steps on BioASQ caused a substantial\nF1 drop despite small BERT/BLEU gains, indicat-\ning the importance of gradual adaptation from the\nsingle-task to the multi-task objective in Stage-2.\nMethod\nAccuracy\nF1\nBERT\nBLEU\nClinical Triage\nw/o Stage-1\n—\n58.25\n91.65\n19.95\nw/o Stage-2\n—\n0.00\n91.78\n20.72\nw/o Scheduled sampling\n—\n57.28\n92.09\n22.59\nw/o Warm-up steps\n—\n59.51\n92.07\n22.64\nReason2Decide\n—\n59.92\n92.09\n22.74\nBioASQ\nw/o Stage-1\n71.95\n65.99\n85.55\n3.32\nw/o Stage-2\n0.00\n0.00\n84.17\n2.95\nw/o Scheduled sampling\n72.76\n68.06\n84.15\n3.07\nw/o Warm-up steps\n69.10\n61.27\n85.68\n3.71\nReason2Decide\n73.98\n68.02\n85.64\n3.55\nTable 7: Ablation results on Clinical Triage and\nBioASQ (Base model).\n5.\nConclusion and Future Work\nWe have introduced Reason2Decide, a two-stage\ntraining framework for LLMs designed to enhance\ndecision quality and interpretability in clinical NLP\ntasks. Through this framework, the model learns\nto generate rationales that align with its predictions.\nExperiments on nurse triage and biomedical QA\ndatasets show that Reason2Decide outperforms\nother fine-tuning variants in both prediction and\nexplanation metrics. With our low cross-source F1\nvariation, we show that synthetic rationales can\nsubstitute for costly human rationales.\nIn future work, our aim is to extend this approach\nto broader clinical and biomedical subdomains, to\nassess its generalizability. We also want to investi-\ngate the effect of integrating rule-based or CoT-style\nrationales. In addition, our goal is to add human\nevaluation for better assessing the rationales.\n6.\nLimitations\nWhile Reason2Decide demonstrates strong per-\nformance over other fine-tuning variants, certain\nlimitations remain. Firstly, the datasets used in this\nwork fall under nurse triage and biomedical QA.\nTo effectively assess Reason2Decide, it should be\n"}, {"page": 9, "text": "extended to other subdomains in clinical NLP. Sec-\nondly, the LLM-generated rationales were not rule-\nbased. It would be valuable to see the impact of\nusing CoT-style rationales during Stage-1 on predic-\ntions. Moreover, our two-stage training framework\nrequires increased computational resources during\ntraining. However, this overhead is not necessary\nduring inference as one can choose to only gen-\nerate predictions. The approach involved several\nhyperparameters that were chosen heuristically. A\nmore granular hyperparameter optimization strat-\negy may lead to Reason2Decide’s further improved\nperformance. Finally, our rationale evaluation lacks\nhuman oversight. Although LLM-as-a-Judge meth-\nods are becoming increasingly adopted, they may\nbe imperfect. For high-stakes domains like clinical\nNLP, human verification remains essential.\n7.\nEthics Statement\nDuring this research, we ensured to follow ethical\nguidelines for clinical NLP. The proprietary dataset\nused was de-identified. No personally identifiable\ninformation was accessible to the models or re-\nsearchers during training/evaluation. Only open-\nsource models were used, and were run on local\nmachines. All clinical predictions and rationales\ngenerated by Reason2Decide should be treated as\na decision support tool requiring human verification\nand not a replacement for human decisions.\n8.\nBibliographical References\nSamy Bengio, Oriol Vinyals, Navdeep Jaitly, and\nNoam Shazeer. 2015. Scheduled sampling for\nsequence prediction with recurrent neural net-\nworks. In Proceedings of the 29th International\nConference on Neural Information Processing\nSystems - Volume 1, NIPS’15, page 1171–1179,\nCambridge, MA, USA. MIT Press.\nYoshua Bengio, Jérôme Louradour, Ronan Col-\nlobert, and Jason Weston. 2009. Curriculum\nlearning. In Proceedings of the 26th Annual Inter-\nnational Conference on Machine Learning, ICML\n’09, page 41–48, New York, NY, USA. Associa-\ntion for Computing Machinery.\nOana-Maria Camburu, Tim Rocktäschel, Thomas\nLukasiewicz, and Phil Blunsom. 2018. e-snli:\nNatural language inference with natural language\nexplanations.\nRich Caruana. 1997. Multitask learning. Mach.\nLearn., 28(1):41–75.\nDario Garcia-Gasulla, Jordi Bayarri-Planas, Ash-\nwin Kumar Gururajan, Enrique Lopez-Cuena,\nAdrian Tormos, Daniel Hinjos, Pablo Bernabeu-\nPerez, Anna Arias-Duart, Pablo Agustin Martin-\nTorres, Marta Gonzalez-Mallo, et al. 2025. The\naloe family recipe for open and specialized\nhealthcare llms.\nDan Hendrycks, Collin Burns, Steven Basart, Andy\nZou, Mantas Mazeika, Dawn Song, and Jacob\nSteinhardt. 2021. Measuring massive multitask\nlanguage understanding.\nJeremy Howard and Sebastian Ruder. 2018. Uni-\nversal language model fine-tuning for text classi-\nfication. In Proceedings of the 56th Annual Meet-\ning of the Association for Computational Linguis-\ntics (Volume 1: Long Papers), pages 328–339,\nMelbourne, Australia. Association for Computa-\ntional Linguistics.\nCheng-Yu Hsieh, Chun-Liang Li, Chih-kuan Yeh,\nHootan Nakhost, Yasuhisa Fujii, Alex Ratner,\nRanjay Krishna, Chen-Yu Lee, and Tomas Pfis-\nter. 2023. Distilling step-by-step! outperforming\nlarger language models with less training data\nand smaller model sizes. In Findings of the Asso-\nciation for Computational Linguistics: ACL 2023,\npages 8003–8017, Toronto, Canada. Association\nfor Computational Linguistics.\nQiao Jin, Bhuwan Dhingra, Zhengping Liu, William\nCohen, and Xinghua Lu. 2019. PubMedQA: A\ndataset for biomedical research question answer-\ning. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Process-\ning and the 9th International Joint Conference on\nNatural Language Processing (EMNLP-IJCNLP),\npages 2567–2577, Hong Kong, China. Associa-\ntion for Computational Linguistics.\nAndrew K. Lampinen, Nicholas A. Roy, Ishita Das-\ngupta, Stephanie C. Y. Chan, Allison C. Tam,\nJames L. McClelland, Chen Yan, Adam Santoro,\nNeil C. Rabinowitz, Jane X. Wang, and Felix Hill.\n2022. Tell me why! explanations support learning\nrelational and causal structure.\nJinhyuk Lee,\nWonjin Yoon,\nSungdong Kim,\nDonghyeon Kim, Sunkyu Kim, Chan Ho So,\nand Jaewoo Kang. 2019.\nBiobert:\na pre-\ntrained biomedical language representation\nmodel for biomedical text mining. Bioinformatics,\n36(4):1234–1240.\nPatrick Lewis, Myle Ott, Jingfei Du, and Veselin\nStoyanov. 2020. Pretrained language models for\nbiomedical and clinical tasks: Understanding and\nextending the state-of-the-art. In Proceedings\nof the 3rd Clinical Natural Language Processing\nWorkshop, pages 146–157, Online. Association\nfor Computational Linguistics.\n"}, {"page": 10, "text": "Ilya Loshchilov and Frank Hutter. 2019. Decoupled\nweight decay regularization.\nScott Lundberg and Su-In Lee. 2017. A unified\napproach to interpreting model predictions.\nSharan Narang, Colin Raffel, Katherine Lee, Adam\nRoberts, Noah Fiedel, and Karishma Malkan.\n2020. Wt5?! training text-to-text models to ex-\nplain their predictions.\nAnastasios\nNentidis,\nGeorgios\nKatsimpras,\nAnastasia Krithara, Martin Krallinger, Miguel\nRodríguez-Ortega, Eduard Rodriguez-López,\nNatalia Loukachevitch,\nAndrey Sakhovskiy,\nElena Tutubalina, Dimitris Dimitriadis, Grigorios\nTsoumakas, George Giannakoulas, Alexandra\nBekiaridou,\nAthanasios\nSamaras,\nGiorgio\nMaria Di Nunzio, Nicola Ferro, Stefano March-\nesin, Marco Martinelli, Gianmaria Silvello, and\nGeorgios Paliouras. 2025. Overview of bioasq\n2025:\nThe thirteenth bioasq challenge on\nlarge-scale biomedical semantic indexing and\nquestion answering.\nShuai Niu, Jing Ma, Hongzhan Lin, Liang Bai, Zhi-\nhua Wang, Richard Yi Da Xu, Yunya Song, and\nXian Yang. 2025. Knowledge-augmented mul-\ntimodal clinical rationale generation for disease\ndiagnosis with small language models. In Pro-\nceedings of the 63rd Annual Meeting of the As-\nsociation for Computational Linguistics (Volume\n1: Long Papers), pages 11011–11024, Vienna,\nAustria. Association for Computational Linguis-\ntics.\nKishore Papineni, Salim Roukos, Todd Ward, and\nWei-Jing Zhu. 2002. Bleu: a method for auto-\nmatic evaluation of machine translation. In Pro-\nceedings of the 40th Annual Meeting of the As-\nsociation for Computational Linguistics, pages\n311–318, Philadelphia, Pennsylvania, USA. As-\nsociation for Computational Linguistics.\nColin Raffel, Noam Shazeer, Adam Roberts,\nKatherine Lee, Sharan Narang, Michael Matena,\nYanqi Zhou, Wei Li, and Peter J. Liu. 2023. Ex-\nploring the limits of transfer learning with a unified\ntext-to-text transformer.\nMarco Tulio Ribeiro, Sameer Singh, and Carlos\nGuestrin. 2016. \"why should i trust you?\": Ex-\nplaining the predictions of any classifier.\nSebastian Ruder. 2017. An overview of multi-task\nlearning in deep neural networks.\nFlorian Schmidt. 2019. Generalization in genera-\ntion: A closer look at exposure bias. In Proceed-\nings of the 3rd Workshop on Neural Generation\nand Translation, pages 157–167, Hong Kong.\nAssociation for Computational Linguistics.\nAarohi Srivastava et al. 2023. Beyond the imitation\ngame: Quantifying and extrapolating the capa-\nbilities of language models.\nQwen Team. 2025. Qwen3 technical report.\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc\nLe, Ed Chi, Sharan Narang, Aakanksha Chowd-\nhery, and Denny Zhou. 2023. Self-consistency\nimproves chain of thought reasoning in language\nmodels.\nJason Wei, Xuezhi Wang, Dale Schuurmans,\nMaarten Bosma, brian ichter, Fei Xia, Ed Chi,\nQuoc V Le, and Denny Zhou. 2022. Chain-of-\nthought prompting elicits reasoning in large lan-\nguage models. In Advances in Neural Information\nProcessing Systems, volume 35, pages 24824–\n24837. Curran Associates, Inc.\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.\nWeinberger, and Yoav Artzi. 2020. Bertscore:\nEvaluating text generation with bert.\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng,\nSiyuan\nZhuang,\nZhanghao\nWu,\nYonghao\nZhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P.\nXing, Hao Zhang, Joseph E. Gonzalez, and Ion\nStoica. 2023. Judging llm-as-a-judge with mt-\nbench and chatbot arena.\n9.\nAppendix\n9.1.\nPrompts Used\nPrompt for Post-Processing Nurse-Authored\nRationales:\nYou are a helpful assistant who expands brief\nmedical notes into full, grammatically correct\nsentences using fewer than 20 words. Do not\nadd new information.\nConvert this to a sentence without adding new\ninformation: [RATIONALE]\nThis created the nurse post-processed rationale\nvariant by replacing [RATIONALE] with each origi-\nnal nurse note.\nPrompt for Generating Standardized Disposi-\ntion Definitions:\n"}, {"page": 11, "text": "You are building a clinical definition for the\ndisposition: [DISPOSITION_NAME].\nCurrent\nworking\ndefinition:\n[CUR-\nRENT_DEFINITION]\nYou are given new examples of triage notes\nand rationales for this disposition. Use them\nto refine, expand, or correct the working defini-\ntion. Keep the definition concise but clinically\naccurate.\nTriage Notes and Rationales: [EXAMPLES]\nUpdate the definition:\n- Incorporate any new key symptoms, criteria,\nor thresholds.\n- Remove incorrect parts.\n- Keep it as clear and specific as possible.\nOutput only the revised definition text, nothing\nelse.\nWhere\n[DISPOSITION_NAME],\n[CUR-\nRENT_DEFINITION], and [EXAMPLES] were\nreplaced with actual data. This process generated\nthe standardized definitions used for consistent\nLLM-as-a-Judge scoring.\nPrompt for Zero-Shot Disposition Classifica-\ntion:\nIssue: [ISSUE_ASSESSMENT]\nDispositions: [CLASSES_TEXT]\nClassify the healthcare issue into one of the\ndispositions above. Return your answer in the\nfollowing **strict** format:\nClass: [chosen digit]\nDo not ask for more information, and do not\nprovide any general statements.\nOnly re-\nspond with the digit.\nWhere [ISSUE_ASSESSMENT] contained the\ntriage note text and [CLASSES_TEXT] listed the 12\ndisposition options with their numerical identifiers.\nThis prompt was used for zero-shot LLM evaluation.\nPrompt for Summarizing BioASQ Snippets:\nPlease summarize the following medical ratio-\nnale in 100 words or less. Focus on the key\npoints and main conclusions. Keep it concise\nand informative.\nRationale to summarize: [RATIONALE]\nSummary:\nWhere [RATIONALE] was replaced with the con-\ncatenated text snippets from BioASQ. This created\nconcise gold-standard rationales for BioASQ exper-\niments.\nPrompt for LLM-as-a-Judge Correctness\nScoring:\nYou are an expert clinical trainer for telephone\ntriage nursing.\n[DEFINITIONS]\nTask: Given the following rationale and dispo-\nsition, score the alignment on a scale of 1 to\n5, where:\n5 - Excellent Alignment\n4 - Good Alignment\n3 - Moderate Alignment\n2 - Poor Alignment\n1 - Very Poor Alignment\nRationale: [RATIONALE]\nDisposition: [DISPOSITION]\nOutput exactly one number (1, 2, 3, 4, or 5)\nwith no other text.\nWhere [DEFINITIONS] was replaced with the\nstandardized disposition definitions following Sub-\nsection 9.2, [RATIONALE] with the generated ratio-\nnale, and [DISPOSITION] with the predicted dispo-\nsition.\nPrompt for LLM-as-a-Judge Coverage Scor-\ning:\nYou are a medical text comparison assistant.\nTask: Compare the triage note with the text\nprovided. Determine how much of the infor-\nmation in the text is also present in the triage\nnote.\nOutput only one number based on this scale:\n5 = The note contains everything mentioned\nin the text.\n4 = The note contains most things mentioned\nin the text.\n3 = The note contains some but not most\nthings mentioned in the text.\n2 = The note contains almost nothing men-\ntioned in the text.\n1 = The note contains nothing mentioned in\nthe text.\nTriage Note: [NOTE]\nText: [TEXT]\nOutput only the number:\nWhere [NOTE] was replaced with the original\ntriage note and [TEXT] with the generated rationale.\nPrompt for LLM-as-a-Judge Overlap Scoring:\n"}, {"page": 12, "text": "You are a clinical text comparison assistant.\nTask: Compare the nurse’s original rationale\nwith the model’s predicted rationale and rate\nhow much of the nurse’s rationale is present\nin the predicted rationale. Judge semantic con-\ntent, not wording. Paraphrases/synonyms count\nas overlap. Ignore pleasantries and generic in-\nstructions. Contradictions reduce overlap.\nOutput exactly one number per line for each pair,\nwith no other text:\n1 = No overlap\n2 = Almost no overlap\n3 = Some but not most overlap\n4 = Most overlap\n5 = Complete overlap\nNurse Rationale: [NURSE_RATIONALE]\nPredicted Rationale:\n[PREDICTED_RATIONALE]\nOutput only the number:\nWhere\n[NURSE_RATIONALE]\nwas\nthe\ngold-standard\nnurse\nrationale\nand\n[PRE-\nDICTED_RATIONALE] was the model-generated\nrationale.\n9.2.\nClinical Disposition Definitions\nHome Care:\nPatients suitable for Home Care\ndisposition have mild to moderate, stable, and non-\nprogressive symptoms without signs of immediate\nor severe complications requiring emergency in-\ntervention. They exhibit no respiratory distress,\nhemodynamic instability, severe pain unresponsive\nto treatment, significant bleeding, high fever with\nsystemic symptoms, spreading infection, altered\nmental status, neurological deficits, or other urgent\nclinical concerns. Their condition allows for safe\nmanagement, symptom relief, and observation at\nhome with appropriate follow-up. This includes sta-\nble minor injuries, controlled localized infections,\nmild chronic condition issues, and non-urgent ques-\ntions or concerns. Patients and caregivers should\nbe advised to seek urgent care if symptoms worsen\nor new concerning signs develop.\nSee Physician or PCP within 3 days: Patients\nwith mild to moderate, stable but persistent or wors-\nening symptoms that do not pose an immediate\nthreat to life or function, and who require timely\nmedical evaluation to prevent complications. This\nincludes conditions without severe pain, respira-\ntory distress, hemodynamic instability, significant\nneurological deficits, acute infection, or other ur-\ngent signs. The disposition excludes any patients\nexhibiting signs of severe or rapidly progressing\nillness, acute psychiatric emergencies, or other ur-\ngent conditions necessitating immediate or emer-\ngency care.\nCall Pharmacist within 24 Hours: This dispo-\nsition is used when a caller has non-emergency\nmedication-related questions or concerns that re-\nquire timely pharmacist expertise within 24 hours to\nensure safe, effective, and appropriate medication\nuse. It applies when immediate urgent care is not\nneeded but professional assessment is necessary\nto clarify dosing, manage side effects, verify medi-\ncation information, address potential interactions,\nsupport adherence, assist with medication access,\nor provide guidance on special populations and\ncircumstances. This ensures optimized therapy,\nprevention of harm, and informed patient decisions\nwithout delay.\nSee Physician or PCP within 4 Hours (or PCP\ntriage): Patients with new or worsening moderate\nto severe symptoms, signs of infection, or condi-\ntions at risk of rapid deterioration that require timely\nclinical evaluation within hours to prevent compli-\ncations. This includes significant pain unrelieved\nby initial treatment, progressive neurological symp-\ntoms, signs of systemic infection, post-procedural\ncomplications, unstable vital signs, moderate to\nsevere respiratory, abdominal, or urinary symp-\ntoms, pregnancy-related concerns, dehydration,\nmetabolic instability, mental health deterioration,\nand other clinical presentations indicating potential\nfor rapid decline. The disposition ensures prompt\nphysician assessment to guide urgent management\nand prevent adverse outcomes.\nCall EMS 911 Now: Initiate immediate emer-\ngency medical services activation for any patient\npresenting with signs or symptoms of a potentially\nlife-threatening condition. This includes acute neu-\nrological deficits, severe chest pain or cardiac symp-\ntoms, significant respiratory distress, signs of ana-\nphylaxis, major trauma or uncontrolled bleeding,\nsevere abdominal or back pain with systemic symp-\ntoms, acute deterioration in patients with serious\nunderlying conditions, active suicidal intent with risk\nof harm, critical illness in infants or young children,\nshock or imminent collapse, severe infection or\nsepsis, altered mental status or unresponsiveness,\nand any situation posing an immediate threat to life,\nsafety, or vital functions. Prompt EMS activation\nis essential whenever there is concern for compro-\nmised airway, breathing, circulation, neurological\nstatus, or urgent mental health crisis requiring rapid\nintervention.\nGo to ED Now: Immediate emergency depart-\nment evaluation is required for patients presenting\nwith sudden, severe, or rapidly worsening symp-\ntoms that pose an immediate risk to life, limb, or\nfunction. This includes active uncontrolled bleed-\ning, significant head or neck injuries, severe respi-\nratory distress or airway compromise, acute neuro-\nlogical deficits, severe or persistent pain suggestive\nof surgical or obstetric emergencies, signs of shock\n"}, {"page": 13, "text": "or altered consciousness, severe allergic reactions,\nprolonged seizures, suspected serious infections,\nsevere metabolic disturbances, and any other crit-\nical conditions requiring urgent assessment and\nintervention.\nSee Physician or PCP within 2 Weeks: Pa-\ntients with new, persistent, worsening, or recurrent\nsymptoms that are stable and do not require emer-\ngency care but need timely medical evaluation to\ndiagnose, monitor, or adjust treatment. This in-\ncludes conditions without signs of acute distress,\nhemodynamic instability, severe pain, neurological\ndeficits, respiratory compromise, systemic infection,\nor other urgent symptoms. The disposition applies\nto a broad range of non-emergent but concerning\nclinical presentations where prompt follow-up is\nnecessary to prevent progression or complications.\nGo to L&D Now: Immediate evaluation in La-\nbor and Delivery is required for pregnant individuals\npresenting with signs of active labor at or near term,\nsuspected or confirmed rupture of membranes, sig-\nnificant vaginal bleeding, decreased or absent fetal\nmovement, new or worsening moderate to severe\nabdominal or pelvic pain, signs of preterm labor,\npregnancy complications or risk factors combined\nwith concerning symptoms, abdominal or pelvic\ntrauma, maternal conditions suggestive of serious\ncomplications (e.g., preeclampsia, infection, hemo-\ndynamic instability), or any other acute symptoms\nindicating potential maternal or fetal compromise.\nPrompt assessment is essential to ensure maternal\nand fetal safety.\nCall Poison Center Now: Immediate expert tox-\nicology consultation is required for any suspected\nor confirmed exposure to potentially harmful sub-\nstances or situations with risk of significant toxicity,\noverdose, or complications. This includes expo-\nsures involving high-risk medications, chemicals,\ntoxins, unknown or unlabeled agents, vulnerable\npopulations (such as children or pregnant women),\nor any new or worsening symptoms suggestive of\nsystemic toxicity. Prompt specialist guidance is es-\nsential to ensure safe management and appropriate\ntreatment.\nSee More Appropriate Guideline: Use this\ndisposition when the caller’s concerns do not re-\nquire emergency or urgent care but need assess-\nment, advice, or management under a more spe-\ncific, condition-focused guideline. It applies to sta-\nble, non-urgent symptoms or questions without red\nflags, including chronic conditions, mild new symp-\ntoms, or informational and care coordination needs.\nAvoid this disposition for any signs of acute de-\nterioration, emergencies, or conditions requiring\nimmediate intervention. Direct callers to the guide-\nline that best matches their specific symptom or\nconcern to ensure appropriate care.\nSee Physician or PCP within 24 Hours: Pa-\ntients with new, worsening, or persistent moderate\nsymptoms that impact daily activities but do not\nrequire emergency care. This includes localized\nsigns of infection or inflammation without systemic\ninvolvement, moderate injuries without severe com-\nplications, mild to moderate neurological, respira-\ntory, gastrointestinal, or mental health symptoms\nwithout acute distress, and other conditions need-\ning timely medical evaluation to prevent deteriora-\ntion, ensure appropriate management, and monitor\nprogression.\nCall Dentist when Office is Open: This dispo-\nsition applies to patients with non-emergent dental\nissues that do not exhibit signs of serious infec-\ntion, airway compromise, uncontrolled bleeding, or\nsystemic illness. It includes mild to moderate pain\nor discomfort manageable with analgesics, stable\npost-procedure symptoms, minor dental trauma\nwithout active bleeding or severe pain, and dental\nappliance-related discomfort without urgent com-\nplications. Patients should seek dental care during\nregular office hours and be advised to obtain imme-\ndiate emergency care if symptoms worsen or signs\nof a dental or medical emergency develop.\n"}]}