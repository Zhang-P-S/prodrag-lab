{"doc_id": "arxiv:2601.11344", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2601.11344.pdf", "meta": {"doc_id": "arxiv:2601.11344", "source": "arxiv", "arxiv_id": "2601.11344", "title": "How Much Would a Clinician Edit This Draft? Evaluating LLM Alignment for Patient Message Response Drafting", "authors": ["Parker Seegmiller", "Joseph Gatto", "Sarah E. Greer", "Ganza Belise Isingizwe", "Rohan Ray", "Timothy E. Burdick", "Sarah Masud Preum"], "published": "2026-01-16T14:48:00Z", "updated": "2026-01-16T14:48:00Z", "summary": "Large language models (LLMs) show promise in drafting responses to patient portal messages, yet their integration into clinical workflows raises various concerns, including whether they would actually save clinicians time and effort in their portal workload. We investigate LLM alignment with individual clinicians through a comprehensive evaluation of the patient message response drafting task. We develop a novel taxonomy of thematic elements in clinician responses and propose a novel evaluation framework for assessing clinician editing load of LLM-drafted responses at both content and theme levels. We release an expert-annotated dataset and conduct large-scale evaluations of local and commercial LLMs using various adaptation techniques including thematic prompting, retrieval-augmented generation, supervised fine-tuning, and direct preference optimization. Our results reveal substantial epistemic uncertainty in aligning LLM drafts with clinician responses. While LLMs demonstrate capability in drafting certain thematic elements, they struggle with clinician-aligned generation in other themes, particularly question asking to elicit further information from patients. Theme-driven adaptation strategies yield improvements across most themes. Our findings underscore the necessity of adapting LLMs to individual clinician preferences to enable reliable and responsible use in patient-clinician communication workflows.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2601.11344v1", "url_pdf": "https://arxiv.org/pdf/2601.11344.pdf", "meta_path": "data/raw/arxiv/meta/2601.11344.json", "sha256": "33ae13a3e642be13c0c9e40fd7f77d660498caad619a87922f42d0a475c23506", "status": "ok", "fetched_at": "2026-02-18T02:21:23.886909+00:00"}, "pages": [{"page": 1, "text": "How Much Would a Clinician Edit This Draft?\nEvaluating LLM Alignment for Patient Message Response Drafting\nParker Seegmiller1, Joseph Gatto1, Sarah E. Greer1,\nGanza Belise Isingizwe1, Rohan Ray1, Timothy Burdick2,3, Sarah M. Preum1\n1 Department of Computer Science, Dartmouth College\n2 Department of Community and Family Medicine, Dartmouth Health\n3 The Dartmouth Institute, Dartmouth College\n{pkseeg.gr, sarah.masud.preum}@dartmouth.edu\nAbstract\nLarge language models (LLMs) show promise\nin drafting responses to patient portal messages,\nyet their integration into clinical workflows\nraises various concerns, including whether they\nwould actually save clinicians time and effort\nin their portal workload. We investigate LLM\nalignment with individual clinicians through a\ncomprehensive evaluation of the patient mes-\nsage response drafting task.\nWe develop a\nnovel taxonomy of thematic elements in clin-\nician responses and propose a novel evalua-\ntion framework for assessing clinician editing\nload of LLM-drafted responses at both con-\ntent and theme levels. We release an expert-\nannotated dataset and conduct large-scale eval-\nuations of local and commercial LLMs using\nvarious adaptation techniques including the-\nmatic prompting, retrieval-augmented gener-\nation, supervised fine-tuning, and direct pref-\nerence optimization. Our results reveal sub-\nstantial epistemic uncertainty in aligning LLM\ndrafts with clinician responses. While LLMs\ndemonstrate capability in drafting certain the-\nmatic elements, they struggle with clinician-\naligned generation in other themes, particularly\nquestion asking to elicit further information\nfrom patients. Theme-driven adaptation strate-\ngies yield improvements across most themes.\nOur findings underscore the necessity of adapt-\ning LLMs to individual clinician preferences to\nenable reliable and responsible use in patient-\nclinician communication workflows.\n1\nIntroduction\nThe use of large language models (LLMs) for draft-\ning responses to asynchronous patient messages\nhas garnered significant interest in the medical com-\nmunity (Hu et al., 2025). This would involve the\nintegration of LLMs in the patient-clinician com-\nmunication loop by drafting an initial clinician re-\nsponse to an incoming patient message, which the\nclinician would then edit and send to the patient.\nFigure 1: Patient message response drafting. LLMs\ndraft responses to patient messages, then clinicians edit\nthe draft by deleting and adding content as needed. We\nevaluate content-level and theme-level alignment be-\ntween clinicians and LLMs.\nFigure 1 shows an example of this task: generat-\ning a response draft to a patient-initiated message,\ngiven the message and a summary of the patient’s\nrelevant electronic health record (EHR) data. Re-\nsponding to patient portal messages places a heavy\nburden on clinicians due to increasing use of the\npatient portal and significant clinical workforce\nconstraints (Budd, 2023; Underdahl et al., 2024;\nMartinez et al., 2023; Yan et al., 2021). As such,\nthere is growing interest in developing AI-mediated\nsupport for improving efficiency and engagement\nin patient portal messaging (Gatto et al., 2025; Biro\net al., 2025). Thus, patient portal messaging is a\nhigh-stakes, real-world setting for evaluating LLMs\non the task of drafting responses.\nPrior work has gathered clinician feedback on\nLLM response drafts to patient portal messages\nwith mixed results. Some studies report that these\nresponses can be useful (Hu et al., 2025; Garcia\net al., 2024; Bootsma-Robroeks et al., 2025; En-\nglish et al., 2024b). However, there is evidence\nthat LLM responses often diverge from clinician\nresponses in style and content, and lack accuracy\n(Hu et al., 2025; Biro et al., 2025; Sharma et al.).\nDivergence between LLM response drafts and\n1\narXiv:2601.11344v1  [cs.CL]  16 Jan 2026\n"}, {"page": 2, "text": "Theme\nExample Frame\nExample Response Element\nEmpathy\nEncouragement of patient treatment effort\nYou’ve been doing a great job with your tapering.\nSymptom Questions\nAsking about location of symptoms\nHas your pain only been in your lower back?\nMedication Questions\nAsking about intake of medications\nHave you been taking your Amoxicillan regularly?\nMedical Assessment\nExplanation of test result\nYour iron levels look normal.\nMedical Planning\nConfirmation of required testing\nLet’s get you in for a bloodwork test.\nLogistics\nConfirmation of clinic policy\nWe can only offer telehealth in the state.\nCare Coordination\nPromise of future patient contact\nWe’ll reach out after we receive the results.\nContingency Planning\nSymptom-related backup plan\nIf you’re feeling dizzy, please call triage\nTable 1: Themes derived from clinician responses to patient portal messages, alongside representative frames and\nexample response elements/utterances. For example, “explanation of test result” is a frame within the medical\nassessment theme, and “your iron levels look normal” is a clinician response component that falls under this frame.\nIn total, we derive 8 clinician response themes comprised of 67 unique frames (examples in supplemental materials).\nclinician responses may lead to either unreliability,\nif LLM response drafts must be significantly edited,\ncontributing to clinicians’ workload in responding\nto patient messages, or irresponsibility, if unedited\nlow-quality LLM response draft elements are sent\nto the patient. Reliability is important, as clini-\ncians spending significant time editing/improving\nthe drafted response defeats the purpose of using\nLLMs to improve efficiency (Tai-Seale et al., 2024;\nBootsma-Robroeks et al., 2025). Clinician respon-\nsibility is critical, as LLM-generated drafts may\ncontain clinically-significant errors and adversely\nimpact the standards of care (Biro et al., 2025;\nSharma et al.; Chen et al., 2025).\nWe investigate the use of LLM drafts in sup-\nporting clinician responses to patient messages, by\nevaluating alignment of LLMs to responses gener-\nated by real clinicians. Specifically, we aim to ex-\nplore the content-level and theme-level alignment\nbetween clinician-written and LLM-generated re-\nsponses, to inform responsible use of NLP in pa-\ntient message response drafting. We answer three\nrelevant research questions. RQ1: What consti-\ntutes a high-quality clinician response to a patient\nmessage? RQ2: How might we automate evalua-\ntion of LLM response draft quality, with respect\nto clinician editing workload? RQ3: How can\nwe adapt LLMs to support clinicians in generating\nquality responses to patient messages?\nIn answering these research questions, we make\nfour key contributions. First, we use a clinicians-\nin-the-loop, hybrid approach to develop a clinically-\nrelevant set of “themes” and frames to systemat-\nically characterize clinician responses to patient\nmessages.\nSecond, we develop and validate a\nnovel two-level evaluation framework for assess-\ning clinician editing load given LLM-drafted re-\nsponses to patient messages. Third, we annotate\nand release an expert-clinician-annotated dataset\nfor evaluating performance on the patient message\nresponse drafting task1. Finally, we conduct a\nrigorous evaluation of three local and three com-\nmercial LLMs on this task, using five LLM adap-\ntation techniques varying in degree of supervision,\nfinding that theme-driven adaptation of LLMs im-\nproves response drafting performance by 33% over\n0-shot models.\n2\nOverview of Data\nThe patient-clinician conversations used in our ex-\nperiments are collected from a large academic hos-\npital in the United States. These conversations are\nsourced from the hospital’s electronic health record\n(EHR) portal messaging platform. Patient portal\nmessaging is an asynchronous healthcare communi-\ncation service in which patients and their clinicians\ndiscuss a wide variety of patient health issues, in-\ncluding symptoms, medication efficacy, treatment\nplanning, scheduling logistics, and more (North\net al., 2019).\nWe begin with 610k total messages taken from\nthe secure patient portal between 1/2020 - 9/2024.\nOur dataset includes messages from primary care,\nand thus includes a wide range of medical topics.\nWe gather all patient-initiated messages which re-\nceived a written clinician response to create 146k\nconversations, i.e. original patient message and\nresponse from a clinician. Our final data pool con-\ntains 10,105 unique patients, of which 64% are\nfemale and 36% are male, with ages ranging be-\ntween 18-80. Each sample in our data pool consists\nof a patient message, a clinician response, and a\nsummary of the patient’s chart or electronic health\nrecord (EHR) data2. We utilize 144k conversa-\ntions from the data pool as training data, and gather\nevaluation datasets from the remaining 2k conver-\nsations.\n1https://hf.co/collections/PortalPal-AI/\nevaluating-alignment-for-patient-message-response-drafting\n2See appendix A for full dataset details\n2\n"}, {"page": 3, "text": "Dataset\nSource\nResponse\nClinician ct.\nSize\nMessage\nResponse\nIPPM\nPatient Portal Message + EHR\nTheme-Guided\n4\n300\n83±54\n53±32\nSyPPM\nSynthetic Message + EHR\nTheme-Guided\n3\n100\n110±51\n70±26\nSoCPPM\nPatient Portal Message + EHR\nReal-Time\n196\n300\n69±45\n55±78\nTable 2: Summary of the three datasets. Patient messages in IPPM and SoCPPM, and EHR summaries for all\ndatasets are sourced from a real EHR portal. SyPPM messages are semi-synthetic, generated using de-identified real\npatient messages for public release. Details on how clinician responses are collected and annotated are in Appendix\nG. We include mean ±standard deviation of the word count of patient messages and clinician responses.\n2.1\nThematic Analysis of Responses\nWe address RQ1 by carefully deriving elements\nof high-quality clinician responses to patient mes-\nsages. Based on manual thematic analysis of our\nreal patient-clinician conversations, and research\nworkshops with a team of 13 expert primary care\nphysicians, nurses, and triage nurses, we derive\na set of clinically-relevant “themes” which can\nbe used to characterize the quality of clinician re-\nsponses to patient messages (Braun and Clarke,\n2006; Sun et al., 2013). These themes can be found\nin Table 1. Appendix B gives full details of our\nmixed-methods approach to identify these themes.\n2.2\nSummary of Evaluation Datasets\nTable 2 summarizes our three evaluation datasets.\nHere we briefly describe the three datasets derived\nfrom these 2k conversations and share additional\ndataset details in Appendix A.2. Each sample in\neach dataset is a tuple of strings {m, c, r} consist-\ning of a patient message m, a summary c of the\npatient’s EHR chart and a single clinician response\nr. The Ideal Patient Portal Messaging (IPPM)\ndataset is created to evaluate LLMs in a setting\nwhere clinicians do not face the same resource\nconstraints as in the real-world, thus responses\nare written by a team of paid expert clinicians\nwho are guided by the themes derived in Section\n2.1. The publicly-available Synthetic Patient Portal\nMessage (SyPPM) contain semi-synthetic patient\nportal messages, paired with real de-identified pa-\ntient EHR summaries, with responses collected via\nthe same method as IPPM. The Standards of Care\nPatient Portal Messaging (SoCPPM) dataset is cre-\nated to evaluate LLMs in a practical setting, where\nresponse drafts are compared with a clinician re-\nsponse which was sent via the portal in real time,\nthus responses are collected via the patient portal.\n3\nScalable Evaluation of LLMs\nWe want to evaluate the reliability of LLM re-\nsponses on the response drafting task (RQ2). Our\nevaluation seeks to identify: in order to achieve\nthe same quality of response, 1) how much content\nwould the clinician need to add to the LLM draft?\nand 2) how much content would the clinician need\nto remove from the LLM draft? Hence, we use a\nreference-based approach which directly compares\nan LLM draft with a response written by an expert\nclinician (Li et al., 2024). Comparing what needs\nto be removed from and added to an LLM-drafted\nresponse to achieve an expert-written response, is\nanalogous to measuring 1) recall, i.e. how much\nof the expert-written response is covered by the\nLLM-drafted response, and 2) precision, i.e. how\nmuch of the LLM-drafted response is matched in\nthe expert’s response. As our goal is to identify the\nediting load of a clinician using a LLM-as-judge\nframework, we call this the EditJudge Evalua-\ntion Framework (Figure 2). This framework is a\nhuman-AI collaborative, task-specific, reference-\nbased, LLM-as-judge evaluation framework (Li\net al., 2025; Bavaresco et al., 2025).\nWe use two measures of editing load to capture\ncomplementary aspects of alignment between gen-\nerated and reference responses. The content-level\nedit-F1 score assesses whether a response drafting\nLLM reproduces specific clinical facts, instructions,\nor action items present in the reference, which is\ncritical for safety and correctness. However, clini-\ncally appropriate drafts may vary substantially in\nwording or level of detail while addressing the\nsame underlying intent. The theme-level edit-F1\nscore captures higher-level alignment by measur-\ning whether the response addresses thematically\nsimilar clinical goals, concerns, and communica-\ntive functions (e.g., reassurance, triage guidance,\nor follow-up planning), even when the granular\ncontent differs. Using both metrics distinguishes\nincomplete response drafts from those that are se-\nmantically (content-level) and thematically aligned\nbut phrased differently, providing a more reliable\nevaluation of response draft quality.\n3.1\nContent-Level edit-F1 Score\nGiven an expert-written clinician response re and\nan LLM response draft rd, the content-level edit-F1\n3\n"}, {"page": 4, "text": "Figure 2: The EditJudge Evaluation Framework for evaluating LLM response drafts. The content-level edit-F1\nscore identifies matching content in the response draft (EM, i.e. true positives), along with expected deletions\n(ED, false positives) and expected additions (EA, false negatives) needed in order to align the LLM response draft\nwith the clinician’s desired response. The theme-level edit score identifies matching themes, serving as a relaxed\nevaluation of the theme-level alignment.\nscore aims to identify how many expected additions\n(EA) and expected deletions (ED) are needed\nfrom the clinician, in order to unify rd with re.\nMatching content in the response draft rd is re-\nferred to as an expected match (EM), meaning we\nwould not expect the clinician to have to rewrite\nthat content in order to achieve their desired re-\nsponse re, saving the clinician time and achieving\nreliability via LLM response drafting.\nWe give our algorithm for counting EA, ED,\nand EM in Algorithm 1 in Appendix C. This al-\ngorithm splits an expert-written response re into\natomic elements (sentences), then for each element\nuses a fine-tuned judge LLM (content-level edit-\nJudge) to either identify expected matches EM in\nthe response draft rd, or expected additions EA\nto the response draft to achieve that element. The\ncontent-level editJudge takes as input a sentence\nfrom the expert-written response se and the LLM-\ndrafted response rd, and outputs either the match-\ning content from the LLM-drafted response sd, or\n“NO MATCH” if there is no matching content. Fi-\nnally, this algorithm identifies expected deletions\nED in the response draft by quantifying the re-\nmaining amount of unmatched content. By treat-\ning expected matches, expected additions, and ex-\npected deletions as true positives, false negatives,\nand false positives respectively, we calculate recall,\ni.e. the percentage of the expert-written response\nre which does not need to be added to rd, and pre-\ncision, i.e. the percentage of the LLM response\ndraft rd which does not need to be removed. We\ncalculate the harmonic mean of the content-level\nrecall and precision scores (i.e. F1) and call this the\ncontent-level edit-F1 score. Assuming additions\nand deletions are evenly-weighted, content-level\nedit-F1 gives the expected reduction in editing load\nfor the clinician by using the LLM response draft.\nWe evaluate 10 variations of content-level ed-\nitJudge models, and select a fine-tuned LLama-\n3-8B-Instruct model for use in our experiments\nin Section 5. This editJudge model achieves 96%\nagreement with expert human annotators, including\n92% overlap with expert-annotated matching con-\ntent decisions. We discuss data annotation, training,\nand evaluation of editJudge models in Appendix C.\n3.2\nTheme-Level edit-F1 Score\nGiven a clinician response re and an LLM response\ndraft rd, the theme-level edit-F1 score aims to\nidentify the higher-level themes in the clinician\nresponse re which are correctly matched by the\nthemes in the LLM response draft rd. To identify\nthemes in each response, we develop and evaluate\na theme-level editJudge model. Given a sentence\nfrom either the clinician response se ∈re or the\nLLM drafted response sd ∈rd, the theme-level\neditJudge model assigns a theme label ls. Predict-\ning clinician response themes is an 9-class multi-\nlabel classification task, as there are 8 high-level\nthemes (see Table 1) and an “Other” class to cap-\nture miscellaneous themes not captured in the main\n8 classes. Using the theme labels lsd assigned to\nsentences sd from the LLM drafted response rd\nas predictions for the theme labels lse assigned to\nsentences se from the clinician response re, the\ntheme-level edit-F1 score is the micro average F1\nof theme predictions. We develop and evaluate a\nfine-tuned theme-level editJudge theme classifica-\ntion model which achieves an F1 score of 0.82 on\nexpert-annotated dataset (details in Appendix C).\n4\n"}, {"page": 5, "text": "4\nExperimental Setup\nWe are interested in how LLMs might be more\nclosely aligned with expert clinicians, to increase\nthe reliability and responsibility of LLMs in re-\nsponse drafting (RQ3). We describe the models\nused in our evaluation, a measure of inter-annotator\npredictability (IAP) to contextualize our results,\nand a measurement of theme frequency in clinician\nand LLM response drafts.\n4.1\nModels and Adaptation Methods\n4.1.1\nLocal and Frontier LLMs\nLocally-hosted LLMs are often preferable in clini-\ncal settings due to the sensitive nature of protected\nhealth information (PHI) and the frequency with\nwhich PHI occurs in patient portal messages (Sal-\nlam et al., 2023; Zhou et al., 2023). Token through-\nput and hosting memory constraints are also im-\nportant considerations (Lorencin et al., 2025). As\nsuch, we are interested in evaluating 7-8b param-\neter LLMs on the response drafting task. We use\nthree models: (i) the instruction-tuned Llama3-8B\nmodel (AI@Meta, 2024), (ii) a healthcare-specific\nversion of the same model Aloe-8B (Gururajan\net al., 2024), and (iii) Qwen3-8B (Team, 2025)\nfrom a different model family. We also test three\ncommercial models on the SyPPM dataset, our\npublic dataset: (i) Claude 4.5 Sonnet (Anthropic,\n2025), (ii) Gemini 2.5 Pro (Comanici et al., 2025),\nand (iii) GPT-OSS (Agarwal et al., 2025).\n4.1.2\nAdaptation Techniques\nWe are interested in exploring several avenues for\naligning LLMs with expert clinicians to improve\nreliability and responsibility. We briefly describe\neach adaptation strategy here, providing full details\nin Appendix D, and prompts in Appendix H.\n0-Shot. Minimally-guided responses from each\nmodel are evaluated to identify how closely-aligned\nthe LLM is with expert clinicians.\nThematic. Some prior work has shown that\nprompting techniques can improve LLM perfor-\nmance on patient messaging tasks (Genovese et al.,\n2025). We are interested in whether the themes de-\nrived in Section 2.1 can align LLMs more closely\nwith expert clinicians. The thematic prompt in-\ncludes a brief explanation of each of the 8 themes,\nto guide the LLM with context.\nRAG. Retrieval augmented generation has been\nused in other patient messaging tasks to improve\nstyle and content of LLM responses (Chen et al.,\n2025). We perform 5-shot RAG prompting.\nSFT. Supervised fine-tuning on prior patient-\nclinician conversations has proven to be an effec-\ntive way to adapt LLM for patient message re-\nsponse drafting (Liu et al., 2024). We perform\nSFT using all 144k training messages.\nTADPOLE. We develop a novel Thematic Agen-\ntic Direct Preference Optimization for Learning En-\nhancement strategy for creating theme-driven pref-\nerence training data for DPO (Rafailov et al., 2023).\nTADPOLE uses response enhancement agents de-\nsigned for each theme derived in Section 2.1. We\ntest several preference pair creation strategies (de-\ntails in Appendix D.3), and report the results of\nmodels trained using the best-performing strategy.\n4.2\nInter-Annotator Predictability\nA key consideration when evaluating the LLM-\nclinician alignment is how closely-aligned clini-\ncians are with each other. Clinician alignment may\nvary based on experience factors (e.g. role, years\nof experience, specialty), personality factors (e.g.\nwriting style), and interpersonal factors (e.g. re-\nlationship with the patient). We gather 3 expert\nresponses to 40 samples from the SyPPM dataset\nto quantify inter-annotator predictability (IAP). We\ncalculate IAP using the editJudge framework to\ncompare inter-human alignment on patient mes-\nsage response drafting. IAP gives us a measure of\nhow useful a different clinician’s response might\nbe when used as a response draft. We also report\ninter-annotator agreement of ground truth in Tables\n10-11 in Appendix E.1.\n4.3\nEstimated Theme Frequency\nAs manually annotating sentence themes in all\nresponses would be inefficient, we use our\nempirically-validated sentence-level theme classi-\nfier (theme-level editJudge LLM, achieves 0.82 F1\non test set in Appendix C) to classify themes in all\nclinician responses (i.e., ground truth) and all LLM\nresponse drafts to estimate thematic tendencies (see\nTable 5).\n5\nResults\nWe evaluate six LLMs and five adaptation tech-\nniques on the IPPM and SyPPM response draft-\ning evaluation datasets and discuss our findings.\nDue to space constraints, we discuss results on the\nSoCPPM dataset in Appendix F.\nTable 3 contains both content-level and theme-\nlevel edit-F1 scores, averaged across the three lo-\n5\n"}, {"page": 6, "text": "Content-Level\nTheme-Level\nDataset\nModel\nPrecision\nRecall\nEdit-F1\nPrecision\nRecall\nEdit-F1\nIPPM\n0-Shot\n0.07±0.02\n0.26±0.04\n0.10±0.02\n0.49±0.03\n0.74±0.03\n0.58±0.02\nTheme\n0.06±0.01\n0.30±0.05\n0.09±0.01\n0.47±0.01\n0.80±0.02\n0.58±0.01\nRAG\n0.11±0.03\n0.30±0.17\n0.13±0.01\n0.48±0.20\n0.66±0.09\n0.56±0.02\nSFT\n0.15±0.01\n0.16±0.00\n0.14±0.01\n0.64±0.01\n0.57±0.01\n0.60±0.01\nTADPOLE\n0.13±0.01\n0.18±0.01\n0.14±0.01\n0.54±0.00\n0.65±0.02\n0.59±0.01\nSyPPM\n0-Shot\n0.12±0.04\n0.31±0.03\n0.16±0.04\n0.47±0.02\n0.46±0.03\n0.47±0.02\nTheme\n0.11±0.00\n0.33±0.10\n0.15±0.02\n0.50±0.01\n0.58±0.01\n0.54±0.00\nRAG\n0.17±0.08\n0.28±0.07\n0.18±0.05\n0.47±0.03\n0.43±0.02\n0.45±0.02\nSFT\n0.22±0.01\n0.17±0.01\n0.18±0.0\n0.64±0.01\n0.41±0.01\n0.50±0.01\nTADPOLE\n0.21±0.01\n0.20±0.02\n0.20±0.01\n0.62±0.01\n0.54±0.02\n0.58±0.01\nGemini\n0.20\n0.43\n0.26\n0.58\n0.69\n0.64\nIAP\n0.26\n0.25\n0.24\n0.61\n0.63\n0.62\nTable 3: Edit-F1 scores for LLM adaptations on the IPPM and SyPPM patient message response drafting datasets.\nEach model adaptation is performed on three underlying LLMs, we report scores as average±standard deviation. We\nreport content-level precision, recall, and edit-F1 (Section 3.1), as well as theme-level precision, recall, and edit-F1\n(Section 3.2). We include the best commercial model (Gemini + theme prompting) scores on the publicly-available\nSyPPM dataset. Finally, we report content-level inter-annotator predictability (IAP), comparing LLM performance\nand expert human alignment.\ncal LLMs described in Section 4.1.1, alongside\nstandard deviation. Table 4 contains content- and\ntheme-level edit-F1 scores for Claude 4.5 Sonnet,\nGemini 2.5 Pro, and GPT-OSS reasoning models,\nusing both 0-shot and thematic prompting adapta-\ntion. In Tables 3 and 4 we report micro average\nprecision, recall, and edit-F1 at the content and\ntheme levels. Table 5 contains theme frequencies\nfor clinician responses and adapted LLM drafts,\naveraged across all evaluation datasets.\n5.1\nContent-Level Results\nUsefulness of Thematic Context: We find that\nfine-tuned models achieve highest precision, theme-\nprompted models achieve highest recall, and the\nTADPOLE adaptation strategy offers the best blend\nof precision and recall with the highest average\ncontent-level edit-F1 scores. We find that added\ncontext improves LLM alignment with individual\nclinicians, and that edit-F1 performance generally\nscales with the amount of added context.\nEx-\namining theme-specific content-level recall (Table\n14 in Appendix F.2), TADPOLE-adapted models\nblend precision with empathetic communication\ncontent (0.30 average recall vs 0.28 average among\nother adaptations) and contingency planning con-\ntent (0.27 vs 0.21)—two themes which tend to\nappear more in “ideal” response drafts. Among\ncommercial models, thematic prompting adapta-\ntion improves performance of all three LLMs. We\nfind that the best frontier-level model in our eval-\nuation is Gemini 2.5 Pro adapted with thematic\nprompting, achieving 0.26 content-level and 0.64\ntheme-level edit-F1. Our single best-performing\nTADPOLE model (Qwen3-8B trained on the “cor-\nrupted” preference pairs3) achieves comparable per-\nformance (0.25 content-level edit-F1 score) to the\nbest-performing frontier model (Gemini 2.5 Pro +\ntheme prompt, 0.26). Our evaluation suggests that\nusing one of these models in patient message re-\nsponse drafting would lead to a 25-26% reduction\nin clinician edits.\nEpistemic Uncertainty: Individual variation\nstemming from epistemic uncertainty is often ob-\nserved in medicine (Han et al., 2021), including pa-\ntient message response drafting (Chen et al., 2024b;\nGarcia et al., 2024; Laukka et al., 2020; Baxter\net al., 2024; English et al., 2024a). Our results\nsupport this finding (see Tables 10-12 in Appendix\nE.1). When one clinician’s responses are used as\ndrafts for another clinician, we find an average\ncontent-level edit-F1 score of 0.24—meaning that\nusing another clinicians response as a draft only\nreduces clinician edits by 24%. This indicates sub-\nstantial epistemic uncertainty at the content level\nof clinician responses, i.e., LLMs specialized at\nthe task level are subject to performance loss due\nto inter-clinician variation in judgment and pref-\nerences. This highlights the need for LLMs to be\nspecialized at the expert level in order to further\nimprove clinician efficiency with response drafts.\n5.2\nTheme-Level Results\nLLMs Generate Quality Empathetic Content:\nEvaluating at the theme level shows that LLMs\nare capable of generating some themes accurately,\nwhile other themes are more challenging.\nFor\nexample, LLMs tend to generate the empathetic\n3See TADPOLE results in Table 9 in Appendix D.3\n6\n"}, {"page": 7, "text": "Content-Level\nTheme-Level\nPrompt\nModel\nPr\nRe\nEdit-F1\nPr\nRe\nEdit-F1\n0-Shot\nGPT\n0.03\n0.21\n0.05\n0.45\n0.64\n0.53\nGemini\n0.17\n0.40\n0.23\n0.52\n0.56\n0.54\nClaude\n0.20\n0.38\n0.25\n0.52\n0.54\n0.53\nAvg\n0.13\n0.33\n0.18\n0.50\n0.58\n0.53\nTheme\nGPT\n0.06\n0.30\n0.09\n0.49\n0.77\n0.60\nGemini\n0.20\n0.43\n0.26\n0.56\n0.69\n0.64\nClaude\n0.16\n0.37\n0.22\n0.58\n0.69\n0.63\nAvg\n0.14\n0.37\n0.19\n0.54\n0.72\n0.62\nIAP\n0.26\n0.25\n0.24\n0.61\n0.63\n0.62\nTable 4: Edit-F1 results for Claude 4.5 Sonnet, Gemini 2.5 Pro, and GPT-OSS reasoning models on the publicly-\navailable SyPPM evaluation dataset. We evaluate each model using 0-shot and thematic prompts, and average\nscores for each prompt. We report precision, recall, and edit-F1 at both the content and theme levels. We report\ncontent-level IAP, comparing LLM performance and expert human alignment at the content level.\ncommunication theme frequently (Table 5), and\nthey perform well overall at generating this theme—\ne.g. TADPOLE-adapted models achieve an aver-\nage theme-level edit-F1 score of 0.99 on the em-\npathetic communication theme in SyPPM (see Ta-\nble 15 in Appendix F.2). This finding supports\nEnglish et al. (2024b), which finds that nurses re-\nport that LLM response drafts improve empathy\nand tone. On the contrast, Table 5 shows that un-\naligned LLMs will rarely ask follow-up questions.\nUnaligned LLMs tend to be misaligned with clini-\ncians on question asking themes—e.g. 0-shot mod-\nels achieve only 0.17 and 0.08 average theme-level\nedit-F1 scores on SyPPM symptom and medica-\ntion question-asking themes (Table 15). Contextual\nadaptation greatly improves LLM performance at\nquestion asking, with TADPOLE-adapted LLMs\nimproving to 0.79 and 0.49 average theme-level\nedit-F1 scores on SyPPM symptom and medication\nquestion-asking themes.\nIndividuality of Expert Clinicians: In general,\nIAP is much higher at the theme level than at the\ncontent level, indicating that theme-level alignment\nis a more achievable goal when drafting clinician\nresponses. However, some individual themes have\nvery low IAP, e.g. treatment planning (0.07 IAP\ntheme-level edit-F1 score in Table 15) and contin-\ngency planning (0.06). Discussions with various\nclinicians, including our annotators, highlight that\ndifferent clinicians tend to think differently about\nhow content will be perceived by patients – e.g.\nsome clinicians indicate that the benefits of provid-\ning contingency plans do not outweigh the burden\nit places on patients. This again underscores the\nneed for LLMs to be able to be adapted at an in-\ndividual level, in order to draft useful responses\nfor individual clinicians with different roles (triage\nnurse, medical assistant, residents), specialties (in-\nternal medicine vs family medicine), years of ex-\nperiences, and preferences. Individual alignment\nis vital for reliable and responsible use of LLM-\nmediated tools in high-stakes professional work-\nflows like healthcare.\n5.3\nImplications of Results\nReliable LLM Adaptation: We find that un-\nadapted LLMs tend to generate medical assess-\nment themes more successfully than contextually-\nadapted LLMs. This is supported by our estimate\nof theme proportions (Table 5), which finds that\nunadapted LLMs generate far more medical assess-\nment and treatment planning themes than clinicians\nand contextually-adapted LLMs. These themes\ncover utterances related to medical decision mak-\ning and communication, i.e., explaining test results,\nsymptoms, and potential diagnoses; and recom-\nmending various forms of treatment. Intuitively,\nunadapted LLMs generate these themes more fre-\nquently as they relate to general LLM alignment\nprinciples, e.g., safety and helpfulness (Ji et al.,\n2023). However, such behavior can lead to over-\ndiagnosis and over-treatment (Kale and Korenstein,\n2018), an emerging concern about using AI in\nmedicine (Scott et al., 2024). Responses drafted\nby unadapted models also tend to be longer (Gar-\ncia et al., 2024; Hu et al., 2025; Tai-Seale et al.,\n2024), which may introduce more cognitive bur-\nden for clinicians, defeating the purpose of saving\nclinicians’ time spent in responding to messages.\nImportance of Evaluation: Our evaluation mea-\nsures how many edits a clinician would make to\nthe LLM-generated draft before sending the re-\nsponse. This is different from the goal of measur-\ning response quality along pre-defined axes, and\ninfluences our decision to define a ground truth as\na single clinician response, rather than a strategy\n7\n"}, {"page": 8, "text": "Response\nEmp\nSym Q\nMed Q\nAssess\nPlan\nLogis\nCoord\nCont\nOth\nClinicians\n0.85\n0.36\n0.30\n0.34\n0.19\n0.56\n0.45\n0.22\n0.02\n0-Shot\n0.94\n0.02\n0.05\n0.89\n0.82\n0.59\n0.78\n0.18\n0.14\nTheme\n0.95\n0.26\n0.13\n0.94\n0.79\n0.64\n0.82\n0.18\n0.20\nRAG\n0.77\n0.01\n0.05\n0.79\n0.65\n0.56\n0.69\n0.11\n0.19\nSFT\n0.97\n0.02\n0.02\n0.23\n0.26\n0.38\n0.69\n0.02\n0.02\nTADPOLE\n0.99\n0.29\n0.20\n0.28\n0.31\n0.36\n0.83\n0.25\n0.01\nTable 5: Proportion of responses containing different thematic content, found in responses written by clinicians and\nvarious model adaptations. Clinician theme proportion is averaged across the IPPM, SyPPM, and SoCPPM datasets.\nLLM adaptation theme proportion is averaged over the three underlying LLMs as well as the three datasets. Bold\nproportions highlight the adaptation that was closest to clinician proportions.\nsuch as rubric-based evaluation (Arora et al., 2025)\nor surveying expert feedback (Liu et al., 2024) on a\ngenerated response. Results from our targeted eval-\nuation highlight the challenge of aligning models\nwith individual clinicians’ judgment, tone, and pref-\nerences when responding to patients. It also yields\ninsights for future work to explore alternatives to\nresponse drafting to improve clinician efficiency,\ne.g., suggesting clinicians theme-based “nudges” —\nrather than content— for themes with higher epis-\ntemic uncertainty.\n6\nRelated Works\nPatient Message Response Drafting.\nSeveral\nworks have studied the usefulness of LLMs in draft-\ning clinician responses to patient messages. Most\nevaluate drafts via only clinician feedback, lim-\niting the scale of evaluation, and employ only 0-\nshot frontier-level LLMs (most commonly OpenAI\nGPT-4) (Biro et al., 2025; Sharma et al.; English\net al., 2024b; Small et al., 2024; Tai-Seale et al.,\n2024; Hu et al., 2025; Bootsma-Robroeks et al.,\n2025). Our work extends prior work in two ways:\n(1) large scale evaluation of adapted LLMs and\n(2) inclusion of EHR data with message to situ-\nate generated responses. Results from prior stud-\nies are mixed, with some showing the potential\nof LLM drafts in promoting empathy and giving\nhealth advice (English et al., 2024b; Eschler et al.,\n2015), while others show that there is room for im-\nprovement in LLM draft completeness, tone, and\nsimplicity (Garcia et al., 2024; Small et al., 2024;\nChen et al., 2024b). Among studies that go be-\nyond 0-shot evaluation, Hu et al. (2025) and Kim\net al. (2024) explore prompting strategies to im-\nprove LLM response drafts. Our thematic prompt-\ning strategy builds on prior work by incorporating a\nmore granular-level understanding of LLM behav-\nior in response generation across the constituent\nthemes of a clinician’s response. Liu et al. (2024)\nis perhaps most similar to our work in that they\nperform SFT of a Llama model and evaluate on a\nsmall test set (n=10) using clinician feedback and\nBERTScore. Our work in developing a thorough\nautomated evaluation framework aims to build on\nthis by enabling larger-scale automated evaluation.\nOur focus on large-scale evaluation enables deeper\ninsight into the risks and benefits of LLM use in\npatient message response drafting.\nEvaluation based on LLM-As-Judge.\nThe use\nof LLMs as judges of LLM-generated content has\ngrown significantly in recent years (Li et al., 2024;\nLin and Chen, 2023; Li et al., 2025; Bavaresco\net al., 2025), including in healthcare text generation\ncontexts (Croxford et al., 2025; Bedi et al., 2025;\nZhao et al., 2025; Krolik et al., 2024). Perhaps most\nsimilar to our work, Croxford et al. (2025) intro-\nduce an LLM-as-Judge framework for evaluating\ngenerated EHR summaries and use a rubric-based\nevaluation. In contrast, our novel edit-F1 frame-\nwork is designed to estimate edit load, i.e., expected\ndeletions/additions to LLM-generated draft.\n7\nConclusion\nWe have evaluated LLMs on the patient message\nresponse drafting task. We have developed a set\nof clinician response themes and used these to de-\nvelop a novel evaluation framework for assessing\nclinician editing load given LLM response drafts.\nWe have performed a large-scale evaluation of\ncontextually-adapted LLMs and frontier LLMs,\nfinding that contextual adaptation improves LLM\nperformance. We highlight that individual clinician\npreferences vary significantly, and that adaptation\nof LLMs to individual clinicians is required to fur-\nther increase the reliability and responsibility of\nLLM use for patient message response drafting.\n8\n"}, {"page": 9, "text": "8\nLimitations\nDataset Our data is drawn from a single hospi-\ntal system and patient portal platform, which may\nlimit generalizability to other healthcare settings\nwith different workflows, patient populations, and\ncommunication norms. This is a rural hospital sys-\ntem. Future work may explore safety, bias and\nrobustness of adapted LLMs in such settings. The\njudge LLM and thematic classification models we\ndeveloped in Section 3 are tuned specifically for our\nevaluation datasets and would require additional\nvalidation before application in other contexts (Wu\nand Aji, 2025; Chen et al., 2024a).\nAutomated Evaluation Some prior evaluations\nof minimally-adapted LLM use in the patient portal\nsuggest that reduction in clinician time via LLM\nresponse drafting is minimal (Hu et al., 2025; Tai-\nSeale et al., 2024; Bootsma-Robroeks et al., 2025).\nOur evaluation seeks to fill a critical research gap\nby automating the evaluation of how much a clin-\nician would edit these responses, which we hope\nwill enable progress towards better LLM alignment\nwith individual clinicians and meaningful reduction\nin clinician workload. Our evaluation suggests that\nbest-performing response drafting LLMs would re-\nduce clinician edits by 25-26%. This is a modest\nreduction, potentially due to the complexity of our\ndata which covers real messages from general pri-\nmary care and a wide range of medical topics and\npatient intents. Our focus on this automated evalua-\ntion limits us from performing in-depth qualitative\nanalysis by clinicians and patients. While our hos-\npital network is not an early adopter of LLM use\nin clinic which prohibits the use of our models for\nlive patient messages, we hope to perform further\nstudies with clinicians and patients in future work.\nEthical Considerations Real patient data used\nin our evaluations is highly sensitive, and extreme\ncaution should be taken when using LLMs on real\npatient data to ensure patient privacy. We carefully\ndesign our evaluations to promote the responsible\nuse of this data in our evaluation. Our data clean-\ning process ensures sensitive patients, e.g. patients\nunder the age of 18, were not included in our final\ndataset. We host all real data on a secure server\nand perform all IPPM and SoCPPM experiments\non this server. We only use proprietary LLMs on\nsemi-synthetic data (SyPPM) which was created\nvia completely de-identified patient charts and mes-\nsages.\nReferences\nSandhini Agarwal, Lama Ahmad, Jason Ai, Sam Alt-\nman, Andy Applebaum, Edwin Arbus, Rahul K\nArora, Yu Bai, Bowen Baker, Haiming Bao, and 1\nothers. 2025. gpt-oss-120b & gpt-oss-20b model\ncard. arXiv preprint arXiv:2508.10925.\nAI@Meta. 2024. Llama 3 model card.\nAnthropic. 2025. Claude 4.5 sonnet.\nRahul K Arora, Jason Wei, Rebecca Soskin Hicks, Pre-\nston Bowman, Joaquin Quiñonero-Candela, Foivos\nTsimpourlas, Michael Sharman, Meghan Shah, An-\ndrea Vallone, Alex Beutel, and 1 others. 2025.\nHealthbench:\nEvaluating large language models\ntowards improved human health.\narXiv preprint\narXiv:2505.08775.\nElizabeth Baltaro, Wendy Henderson, and Karen M\nGoldstein. 2022. Patient electronic messaging: 12\ntips to save time.\nFamily Practice Management,\n29(6):5–9.\nAnna Bavaresco, Raffaella Bernardi, Leonardo Berto-\nlazzi, Desmond Elliott, Raquel Fernández, Albert\nGatt, Esam Ghaleb, Mario Giulianelli, Michael\nHanna, Alexander Koller, Andre Martins, Philipp\nMondorf, Vera Neplenbroek, Sandro Pezzelle, Bar-\nbara Plank, David Schlangen, Alessandro Suglia,\nAditya K Surikuchi, Ece Takmaz, and Alberto\nTestoni. 2025. LLMs instead of human judges? a\nlarge scale empirical study across 20 NLP evalua-\ntion tasks. In Proceedings of the 63rd Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 2: Short Papers), pages 238–255, Vienna,\nAustria. Association for Computational Linguistics.\nSally L Baxter, Christopher A Longhurst, Marlene\nMillen, Amy M Sitapati, and Ming Tai-Seale. 2024.\nGenerative artificial intelligence responses to pa-\ntient messages in the electronic health record: early\nlessons learned. JAMIA open, 7(2):ooae028.\nSuhana Bedi, Hejie Cui, Miguel Fuentes, Alyssa Unell,\nMichael Wornow, Juan M. Banda, Nikesh Kotecha,\nTimothy Keyes, Yifan Mai, Mert Oez, Hao Qiu,\nShrey Jain, Leonardo Schettini, Mehr Kashyap, Ja-\nson Alan Fries, Akshay Swaminathan, Philip Chung,\nFateme Nateghi, Asad Aali, and 62 others. 2025.\nMedhelm: Holistic evaluation of large language mod-\nels for medical tasks. ArXiv, abs/2505.23802.\nJoshua M. Biro, Jessica L. Handley, J. Malcolm Mc-\nCurry, Adam Visconti, Jeffrey M Weinfeld, J. Gre-\ngory Trafton, and Raj M. Ratwani. 2025. Opportuni-\nties and risks of artificial intelligence in patient portal\nmessaging in primary care. NPJ Digital Medicine, 8.\nCharlotte\nMHHT\nBootsma-Robroeks,\nJessica\nD\nWorkum, Stephanie CE Schuit, Anne Hoekman,\nTarannom Mehri, Job N Doornberg, Tom P van der\nLaan, and Rosanne C Schoonbeek. 2025.\nAi-\ngenerated draft replies to patient messages: explor-\ning effects of implementation. Frontiers in Digital\nHealth, 7:1588143.\n9\n"}, {"page": 10, "text": "Virginia Braun and Victoria Clarke. 2006. Using the-\nmatic analysis in psychology. Qualitative research\nin psychology, 3(2):77–101.\nJeffrey Budd. 2023. Burnout related to electronic health\nrecord use in primary care. Journal of Primary Care\n& Community Health, 14.\nGuiming Hardy Chen, Shunian Chen, Ziche Liu, Feng\nJiang, and Benyou Wang. 2024a. Humans or llms\nas the judge? a study on judgement biases. arXiv\npreprint arXiv:2402.10669.\nShan Chen, Marco Guevara, Shalini Moningi, Frank\nHoebers, Hesham Elhalawani, Benjamin H Kann, Fal-\nlon E Chipidza, Jonathan Leeman, Hugo JWL Aerts,\nTimothy Miller, and 1 others. 2024b. The effect of\nusing a large language model to respond to patient\nmessages. The Lancet Digital Health, 6(6):e379–\ne381.\nWenyuan Chen, Fateme Nateghi Haredasht, Kameron C\nBlack,\nFrancois\nGrolleau,\nEmily\nAlsentzer,\nJonathan H Chen,\nand Stephen P Ma. 2025.\nRetrieval-augmented\nguardrails\nfor\nai-drafted\npatient-portal messages: Error taxonomy construc-\ntion and large-scale evaluation.\narXiv preprint\narXiv:2509.22565.\nGheorghe Comanici, Eric Bieber, Mike Schaekermann,\nIce Pasupat, Noveen Sachdeva, Inderjit Dhillon, Mar-\ncel Blistein, Ori Ram, Dan Zhang, Evan Rosen, Luke\nMarris, Sam Petulla, Colin Gaffney, Asaf Aharoni,\nNathan Lintz, Tiago Cardal Pais, Henrik Jacobs-\nson, Idan Szpektor, Nan-Jiang Jiang, and 3416 oth-\ners. 2025. Gemini 2.5: Pushing the frontier with\nadvanced reasoning, multimodality, long context,\nand next generation agentic capabilities. Preprint,\narXiv:2507.06261.\nEmma Croxford, Yanjun Gao, Elliot First, Nicholas\nPellegrino, Miranda Schnier, John Caskey, Madeline\nOguss, Graham Wills, Guanhua Chen, Dmitriy Dli-\ngach, and 1 others. 2025. Automating evaluation of\nai text generation in healthcare with a large language\nmodel (llm)-as-a-judge. medRxiv, pages 2025–04.\nCathal Doyle, Laura Lennox, and Derek Bell. 2013. A\nsystematic review of evidence on the links between\npatient experience and clinical safety and effective-\nness. BMJ open, 3(1):e001570.\nEden English, Janelle Laughlin, Jeffrey Sippel, Matthew\nDeCamp, and Chen-Tan Lin. 2024a. Utility of arti-\nficial intelligence–generative draft replies to patient\nmessages. JAMA Network Open, 7(10):e2438573–\ne2438573.\nEden F. English, Janelle Laughlin, Jeffrey Sippel,\nMatthew DeCamp, and Chen-Tan Lin. 2024b. Utility\nof artificial intelligence–generative draft replies to\npatient messages. JAMA Network Open, 7.\nJordan Eschler, Leslie S Liu, Lisa M Vizer, Jennifer B\nMcClure, Paula Lozano, Wanda Pratt, and James D\nRalston. 2015. Designing asynchronous communica-\ntion tools for optimization of patient-clinician coor-\ndination. In AMIA Annual Symposium Proceedings,\nvolume 2015, page 543.\nPatricia Garcia, Stephen P. Ma, Shreya J. Shah, Mar-\ngaret Smith, Yejin Jeong, Anna Devon-Sand, Ming\nTai-Seale, Kevin Takazawa, Danyelle Clutter, Kyle\nVogt, Carlene Lugtu, Matthew Rojo, Steven Lin, Tait\nShanafelt, Michael A. Pfeffer, and Christopher Sharp.\n2024. Artificial intelligence–generated draft replies\nto patient inbox messages. JAMA Network Open, 7.\nJoseph Gatto, Parker Seegmiller, Timothy E. Burdick,\nInas S. Khayal, Sarah DeLozier, and Sarah M. Preum.\n2025. Follow-up question generation for enhanced\npatient-provider conversations. In Proceedings of the\n63rd Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers), pages\n25222–25240, Vienna, Austria. Association for Com-\nputational Linguistics.\nJoseph Gatto, Parker Seegmiller, Timothy E. Burdick,\nand Sarah M. Preum. 2024. In-context learning for\npreserving patient privacy: A framework for synthe-\nsizing realistic patient portal messages. In Machine\nLearning for Health (ML4H) Findings.\nAriana Genovese, Sahar Borna, Cesar Abraham Gomez-\nCabello, Syed Ali Haider, Srinivasagam Prabha,\nMaissa Trabilsy, Cui Tao, Keith T Aziz, Peter M.\nMurray, and AJ Forte. 2025. Artificial intelligence\nfor patient support: Assessing retrieval-augmented\ngeneration for answering postoperative rhinoplasty\nquestions. Aesthetic surgery journal.\nAshwin Kumar Gururajan, Enrique Lopez-Cuena, Jordi\nBayarri-Planas, Adrian Tormos, Daniel Hinjos, Pablo\nBernabeu-Perez, Anna Arias-Duart, Pablo Agustin\nMartin-Torres,\nLucia Urcelay-Ganzabal,\nMarta\nGonzalez-Mallo, Sergio Alvarez-Napagao, Eduard\nAyguadé-Parra, and Ulises Cortés Dario Garcia-\nGasulla. 2024. Aloe: A family of fine-tuned open\nhealthcare llms. Preprint, arXiv:2405.01886.\nPaul KJ Han, Tania D Strout, Caitlin Gutheil, Carl\nGermann, Brian King, Eirik Ofstad, Pål Gulbrand-\nsen, and Robert Trowbridge. 2021. How physicians\nmanage medical uncertainty: a qualitative study and\nconceptual taxonomy.\nMedical decision making,\n41(3):275–291.\nPaul A Harris, Robert Taylor, Robert Thielke, Jonathon\nPayne, Nathaniel Gonzalez, and Jose G Conde.\n2009. Research electronic data capture (redcap)—a\nmetadata-driven methodology and workflow process\nfor providing translational research informatics sup-\nport. Journal of Biomedical Informatics, 42(2):377–\n381.\nDi Hu, Yawen Guo, Yiliang Zhou, Lidia Flores, and Kai\nZheng. 2025. A systematic review of early evidence\non generative ai for drafting responses to patient mes-\nsages. npj Health Systems, 2(1):27.\n10\n"}, {"page": 11, "text": "Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan\nAllen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,\nWeizhu Chen, and 1 others. 2022. Lora: Low-rank\nadaptation of large language models. ICLR, 1(2):3.\nJiaming Ji, Mickel Liu, Josef Dai, Xuehai Pan, Chi\nZhang, Ce Bian, Boyuan Chen, Ruiyang Sun, Yizhou\nWang, and Yaodong Yang. 2023. Beavertails: To-\nwards improved safety alignment of llm via a human-\npreference dataset. Advances in Neural Information\nProcessing Systems, 36:24678–24704.\nThinking Machines John Schulman. 2025. Lora without\nregret.\nMinal S Kale and Deborah Korenstein. 2018. Over-\ndiagnosis in primary care: framing the problem and\nfinding solutions. Bmj, 362.\nJiyeong Kim, Michael L Chen, Shawheen J Rezaei,\nApril S Liang, Susan M Seav, Sonia Onyeka, Julie J\nLee, Shivam C Vedak, David Mui, Rayhan A Lal, and\n1 others. 2024. Perspectives on artificial intelligence–\ngenerated responses to patient messages. JAMA Net-\nwork Open, 7(10):e2438535–e2438535.\nJack Krolik, Herprit Mahal, Feroz Ahmad, Gaurav\nTrivedi, and Bahador Saket. 2024. Towards lever-\naging large language models for automated medical\nq&a evaluation. arXiv preprint arXiv:2409.01941.\nElina Laukka, Moona Huhtakangas, Tarja Heponiemi,\nSari Kujala, Anu-Marja Kaihlanen, Kia Gluschkoff,\nand Outi Kanste. 2020. Health care professionals’\nexperiences of patient-professional communication\nover patient portals: systematic review of qualita-\ntive studies. Journal of Medical Internet Research,\n22(12):e21623.\nDawei Li, Bohan Jiang, Liangjie Huang, Alimohammad\nBeigi, Chengshuai Zhao, Zhen Tan, Amrita Bhat-\ntacharjee, Yuxuan Jiang, Canyu Chen, Tianhao Wu,\nand 1 others. 2025. From generation to judgment:\nOpportunities and challenges of llm-as-a-judge. In\nProceedings of the 2025 Conference on Empirical\nMethods in Natural Language Processing, pages\n2757–2791.\nHaitao Li, Qian Dong, Junjie Chen, Huixue Su, Yu-\njia Zhou, Qingyao Ai, Ziyi Ye, and Yiqun Liu.\n2024.\nLlms-as-judges: a comprehensive survey\non llm-based evaluation methods. arXiv preprint\narXiv:2412.05579.\nShuyue Stella Li, Jimin Mun, Faeze Brahman, Pedram\nHosseini, Bryceton G Thomas, Jessica M Sin, Bing\nRen, Jonathan S Ilgen, Yulia Tsvetkov, and Maarten\nSap. Alfa: Aligning llms to ask good questions a case\nstudy in clinical reasoning. In Second Conference on\nLanguage Modeling.\nYen-Ting Lin and Yun-Nung Chen. 2023. Llm-eval:\nUnified multi-dimensional automatic evaluation for\nopen-domain conversations with large language mod-\nels. In Proceedings of the 5th Workshop on NLP\nfor Conversational AI (NLP4ConvAI 2023), pages\n47–58.\nSiru Liu, Allison B McCoy, Aileen P Wright, Babatunde\nCarew, Julian Z Genkins, Sean S Huang, Josh F Peter-\nson, Bryan Steitz, and Adam Wright. 2024. Leverag-\ning large language models for generating responses\nto patient messages—a subjective analysis. Journal\nof the American Medical Informatics Association,\n31(6):1367–1379.\nIvan Lorencin, Nikola Tankovic, and Darko Etinger.\n2025. Optimizing healthcare efficiency with local\nlarge language models. Intelligent Human Systems\nIntegration (IHSI 2025): Integrating People and In-\ntelligent Systems, 160(160).\nKathryn A. Martinez, Rebecca Schulte, Michael B.\nRothberg, Maria C Tang, and Elizabeth R. Pfoh. 2023.\nPatient portal message volume and time spent on the\nehr: an observational study of primary care clinicians.\nJournal of General Internal Medicine, 39:566 – 572.\nFrederick North, Kristine E Luhman, Eric A Mall-\nmann, Toby J Mallmann, Sidna M. Tulledge-Scheitel,\nEmily J North, and Jennifer L. Pecina. 2019. A retro-\nspective analysis of provider-to-patient secure mes-\nsages: How much are they increasing, who is doing\nthe work, and is the work happening after hours?\nJMIR Medical Informatics, 8.\nRafael Rafailov, Archit Sharma, Eric Mitchell, Christo-\npher D Manning, Stefano Ermon, and Chelsea Finn.\n2023. Direct preference optimization: Your language\nmodel is secretly a reward model. Advances in neural\ninformation processing systems, 36:53728–53741.\nNils Reimers and Iryna Gurevych. 2019. Sentence-bert:\nSentence embeddings using siamese bert-networks.\nIn Proceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the 9th\nInternational Joint Conference on Natural Language\nProcessing (EMNLP-IJCNLP), pages 3982–3992.\nMatthew Sakumoto and Aditi U. Joshi. 2023. Digital\nempathy 2.0: Connecting with patients using the\nwritten word. Telehealth and Medicine Today, 8(5).\nMalik Sallam, Nesreen A Salim, Muna Barakat, and\nAla’a B Al-Tammemi. 2023. Chatgpt applications in\nmedical, dental, pharmacy, and public health educa-\ntion: A descriptive study highlighting the advantages\nand limitations. Narra j, 3(1):e103.\nIan A Scott, Anton Van Der Vegt, Paul Lane, Steven\nMcPhail, and Farah Magrabi. 2024.\nAchieving\nlarge-scale clinician adoption of ai-enabled deci-\nsion support.\nBMJ Health & Care Informatics,\n31(1):e100971.\nRahul Sharma, Pragnya Ramjee, Kaushik Murali, and\nMohit Jain. Editing with ai: How doctors refine llm-\ngenerated answers to patient queries. In The Second\nWorkshop on GenAI for Health: Potential, Trust, and\nPolicy Compliance.\nWilliam R Small, Batia Wiesenfeld, Beatrix Brandfield-\nHarvey, Zoe Jonassen, Soumik Mandal, Elizabeth R\n11\n"}, {"page": 12, "text": "Stevens, Vincent J Major, Erin Lostraglio, Adam Sz-\nerencsy, Simon Jones, and 1 others. 2024. Large lan-\nguage model–based responses to patients’ in-basket\nmessages.\nJAMA network open, 7(7):e2422399–\ne2422399.\nMoira Stewart. 1995. Effective physician-patient com-\nmunication and health outcomes: a review. CMAJ :\nCanadian Medical Association journal = journal de\nl’Association medicale canadienne, 152 9:1423–33.\nSi Sun, Xiaomu Zhou, Joshua C Denny, Trent S Rosen-\nbloom, and Hua Xu. 2013. Messaging to your doc-\ntors: understanding patient-provider communications\nvia a portal system. In Proceedings of the SIGCHI\nConference on Human Factors in Computing Systems,\npages 1739–1748.\nMing Tai-Seale, Sally L Baxter, Florin Vaida, Amanda\nWalker, Amy Sitapati, Chad Osborne, Joseph Diaz,\nNimit Desai, Sophie Webb, Gregory Polston, Teresa\nHelsten, Erin Gross, Jessica Thackaberry, Ammar\nMandvi, Dustin Lillie, Steve Li, Geneen T Gin,\nSuraj A Achar, Heather Hofflich, and 3 others.\n2024.\nAi-generated draft replies integrated into\nhealth records and physicians’ electronic commu-\nnication. JAMA Network Open, 7.\nQwen Team. 2024. Qwen2.5: A party of foundation\nmodels.\nQwen Team. 2025. Qwen3 technical report. Preprint,\narXiv:2505.09388.\nLouise Underdahl, Mary Ditri, and Lunthita M Duthely.\n2024. Physician burnout: Evidence-based roadmaps\nto prioritizing and supporting personal wellbeing.\nJournal of Healthcare Leadership, 16:15 – 27.\nMinghao Wu and Alham Fikri Aji. 2025. Style over sub-\nstance: Evaluation biases for large language models.\nIn Proceedings of the 31st International Conference\non Computational Linguistics.\nQi Yan, Zheng Jiang, Zachary Harbin, Preston H Tolbert,\nand Mark G Davies. 2021. Exploring the relation-\nship between electronic health records and provider\nburnout: a systematic review. Journal of the Amer-\nican Medical Informatics Association, 28(5):1009–\n1021.\nJustin Zhao, Timothy Wang, Wael Abid, Geoffrey An-\ngus, Arnav Garg, Jeffery Kinnison, Alex Sherstin-\nsky, Piero Molino, Travis Addair, and Devvret Rishi.\n2024. Lora land: 310 fine-tuned llms that rival gpt-4,\na technical report. arXiv preprint arXiv:2405.00732.\nM. Zhao, I. Y. Oh, A. Gupta, S. Cohen-Cutler, K. M.\nHarmoney, A. M. Lai, and B. A. Sisk. 2025. Au-\ntomating evaluation of llm-generated responses to\npatient questions about rare diseases. In medRxiv.\nJuexiao Zhou, Xiaonan He, Liyuan Sun, Jiannan Xu,\nXiuying Chen, Yuetan Chu, Longxi Zhou, Xingyu\nLiao, Bin Zhang, and Xin Gao. 2023.\nSkingpt-\n4: an interactive dermatology diagnostic system\nwith visual large language model. arXiv preprint\narXiv:2304.10691.\n12\n"}, {"page": 13, "text": "A\nDataset Details\nA.1\nData Collection and Formatting\nAs described in Section 2, the patient-clinician\nconversations used in our experiments are col-\nlected from a large academic hospital in the East-\nern United States. These conversations are sourced\nfrom the hospital’s electronic health record (EHR)\nportal messaging platform. 610k total messages\nare taken from the secure patient portal between\n1/2020 - 9/2024. Our dataset includes messages\nfrom primary care, and thus includes a wide range\nof medical topics. We gather all patient-initiated\nmessages which received a written clinician re-\nsponse to create 146k conversations, i.e. original\npatient message and response from a clinician. Our\nfinal data pool contains 10,105 unique patients, of\nwhich 64% are female and 36% are male, with ages\nranging between 18-80. Each sample in our data\npool consists of a patient message, a clinician re-\nsponse, and a summary of the patient’s chart before\nthe sending of the patient message. We designate\n144k conversations from the data pool as training\ndata, and we gather evaluation datasets from the\nremaining 2k conversations.\nDetails from throughout the EHR are summa-\nrized into four categories. First, the patient’s age\nrange and gender are given as Demographics.\nNext, the patient’s active problems are listed under\nFull Active Problem List. The patient’s recent en-\ncounters (with a maximum of 10 entries), including\ndiagnoses, surgeries, visits, etc. are listed under\nRecent Encounters. Finally, a patient’s outpatient\nmedications are summarized in Medications. An\nexample de-identified chart from SyPPM is pro-\nvided in Figure 3.\nA.2\nEvaluation Dataset Details\nDesignating 144k training conversations, we gather\nevaluation datasets from the remaining 2k conver-\nsations. We create three evaluation sets, designed\nto evaluate LLM alignment with experts according\nto different standards of care. Each sample in each\ndataset is a tuple of strings {m, c, r} consisting of\na patient message m, a summary c of the patient’s\nEHR chart and a single clinician response r.\nIPPM The Ideal Patient Portal Messaging\n(IPPM) dataset is created to evaluate LLMs in a set-\nting where clinicians do not face the same resource\nconstraints as in the real-world. In this evaluation\ndataset, ground-truth responses are written by a\npaid team of 4 expert primary care nurses who\nwork daily in the patient portal, collected via RED-\nCap surveys (Harris et al., 2009). In addition to\ngiving ample time to write a full response to each\nmessage/EHR summary, experts were asked “if\nyou had unlimited time, what would be included in\nyour response to this patient?” To provoke quality\nresponses, clinicians were given a separate text en-\ntry box for each of the themes derived in Section\n2.1. For example, the Treatment Contingency Plan-\nning text box included the prompt “please outline a\nbackup/red flag plan for the patient, if applicable.”\nAn example REDCap survey is given in Appendix\nG for reproducibility. The IPPM dataset is com-\nprised of 300 patient messages and corresponding\nEHR charts, with one expert clinician response per\nsample.\nSyPPM As the other datasets use real patient\ndata containing protected health information (PHI),\nthey are not suitable for public release. We create\nthe Synthetic Patient Portal Messaging (SyPPM)\nas a public benchmark to promote open-source re-\nsearch in clinician response drafting. We begin\nby taking 100 semi-synthetic patient portal mes-\nsages which are created using a small number of de-\nidentified patient portal messages in an in-context\nsynthesis prompt (Gatto et al., 2025, 2024) and\npair them with real de-identified patient EHR sum-\nmaries. Ground-truth responses to each patient\nmessage are then provided by a primary care clini-\ncian, using the same theme-guided REDCap survey\nused for IPPM.\nSoCPPM The Standards of Care Patient Portal\nMessaging (SoCPPM) dataset is created to evalu-\nate LLMs in a practical setting, in which response\ndrafts are compared with the clinician response\nwhich was sent via the secure portal in real time.\nThis dataset is comprised of 300 patient messages\nand corresponding EHR summaries, where ground-\ntruth responses are sourced from the patient portal.\nWe evaluate LLM response drafts with respect to\nthese real responses from the patient portal to study\nhow LLM responses might perform in real-world\nsettings, against the current standards of care in the\npatient portal.\nB\nThematic Analysis Details\nWe carefully derive elements of high-quality clini-\ncian responses to patient messages. Based on prior\nwork, manual thematic analysis of real patient-\nclinician conversations, and consultation with ex-\npert primary care physicians, nurses, and triage\n13\n"}, {"page": 14, "text": "###Demographics###\nAge: Between 35 - 40\nGender: Female\n###Full Active Problem List###:\nDVT prophylaxis - Pelvic floor dysfunction - Chronic left-sided low back pain with left-sided\nsciatica - Hypothyroidism due to Hashimoto’s thyroiditis - IUD (intrauterine device) in place - H/O\nabnormal cervical Papanicolaou smear - Paresthesia of left leg - Hypothyroid - Vitamin D deficiency -\nUncontrolled pain - Healthcare maintenance - CREATED BY INTERFACE - Disorder of muscle,\nligament, and fascia - Postoperative pain - Altered bowel habits\n###Recent Encounters (Max 10)###\nDiagnoses (Past Year): Cough, persistent - Acne vulgaris - Abnormal uterine bleeding - Encounter for\ncosmetic procedure - Changing skin lesion - Acne scarring - Fatigue, unspecified type - COVID-19\nruled out\nDiagnoses (Older):\n###Medications (Outpatient)###\nActive (Start Date Before Message, Not Yet Ended):\n-TRETINOIN 0.025 % TOPICAL CREAM\n-LEVOTHYROXINE 75 MCG TABLET\n-CLINDAMYCIN 1 % LOTION\n-SPIRONOLACTONE 100 MG TABLET\n-SPIRONOLACTONE 50 MG TABLET\n-LORAZEPAM 1 MG TABLET\nFigure 3: Example de-identified EHR chart summary from our SyPPM patient message response drafting evaluation\ndataset\nnurses, we derive a set of “themes” which can\nbe used to characterize the quality of clinician re-\nsponses to patient messages (Braun and Clarke,\n2006; Sun et al., 2013). Below, we present our hy-\nbrid (top-down and bottom-up) approach to identify\nthese themes.\nAs the quality of patient-clinician communica-\ntion has a significant impact on patient health out-\ncomes, characterizing quality response elements is\nimportant preliminary work for evaluating LLMs\non the patient message response drafting task\n(Stewart, 1995; Doyle et al., 2013).\nOur goal\nis to derive themes that should occur in clini-\ncian responses to patient messages. We are inter-\nested in both empirically-derived themes, sourced\nfrom real patient-clinician conversations, as well as\ntheoretically-derived themes, sourced from expert\nconsultation and clinician communication theory\n(Stewart, 1995; Sakumoto and Joshi, 2023). Empir-\nical themes are indicative of the current standards\nof care in patient portal communication, whereas\ntheoretical themes may not be found in real-world\nclinician communication due to time, system, and\nresource constraints often experienced in asyn-\nchronous patient-clinician communication in the\npatient portal (North et al., 2019; Martinez et al.,\n2023). We therefore employ a hybrid top-down\n(theoretical), bottom-up (empirical) approach to\nidentifying themes of quality clinician communica-\ntion within the patient portal.\nB.1\nTheoretical Response Themes\nWe collaborate with a team of 11 clinicians to iden-\ntify “ideal” clinician response themes to various\npatient messages. This iterative process involved\n1-1 interviews with 2 primary care physicians and\n9 primary care nurses, all of whom regularly in-\nteract with patients on the EHR portal from which\nour data pool (Appendix A) is sourced. These\ninterviews consisted of discussions based on open-\nended questions, e.g. “what are your primary goals\nwhen writing responses to patient messages in the\npatient portal?” as well as discussions guided by\nexamples of patient messages, e.g. “what would\nyou want to say to this patient?” or \"how would\nyour response vary based on a <specific change>\nin the patient-initiated message?\" Through these\ninterviews, we derive an initial set of theoretical\n14\n"}, {"page": 15, "text": "clinician response themes based on suggested best\npractices.\nB.2\nEmpirical Response Themes\nUsing notes from these conversations as a back-\ndrop, a team of three authors 4, including a primary\ncare physician, performed a comprehensive, iter-\native thematic analysis (Braun and Clarke, 2006)\nusing a random sample of 100 patient messages,\nalongside a summary of the patient’s electronic\nhealth record and the clinician’s response. This pro-\ncess involved hand-labeling each sentence-length\nelement of 25 clinician responses with a “frame,”\nthen grouping those frames into “themes,” and re-\npeating this process with new samples. In total we\nrepeated this process four times.\nAfter performing the bottom-up thematic analy-\nsis, additional input from two primary care physi-\ncians guided the final, comprehensive list of eight\nclinician response themes comprised of 67 frames.\nDescriptions and examples of each response theme\ncan be found in Table 1.\nC\nEditJudge Framework Details\nIn Figure 2 we see an example of how the content-\nlevel and theme-level edit-F1 scores are calculated\ngiven a clinician response and an LLM response\ndraft. In Algorithm 1 we give the algorithm for\ncounting expected matches EM, expected addi-\ntions EA, and expected deletions ED in an LLM-\ndrafted response, in order to calculate content-level\nedit-F1 scores.\nC.1\nContent-Matching Judge Model\nHere we describe the process used to fine-tune the\ncontent-level editJudge model used in Algorithm\n1 to calculate content-level edit-F1. First, three\nauthors hand-label 450 training samples and 50\nevaluation samples. Each sample input is a re-\nsponse draft written by the Aloe-8B (Gururajan\net al., 2024) 0-shot model, along with a sentence\ndrawn from an expert-written response to a sam-\nple from the publicly-available SyPPM evaluation\ndataset. The annotators either wrote “NO MATCH”\nif there was no matching content from the response\ndraft, or copy/pasted the matching content from the\nresponse draft if applicable. The prompt to identify\nmatches was “if the expert clinician would not have\nto rewrite this content in order to achieve the same\n4Each team member is well-versed in health informatics\nand qualitative thematic analysis\nAlgorithm 1 Counting expected matches EM, ex-\npected additions EA, and expected deletions ED\nin an LLM-drafted response\nRequire: re (expert-written response), rd (LLM-\ndrafted response)\nEnsure: EM, ED, EA\n1: Split re into atomic elements (sentences)\n2: Initialize EM ←0, EA ←0\n3: for all sentence se in re do\n4:\nif MATCH se with content in rd then\n5:\nEM ←EM + 1\n6:\nelse\n7:\nEA ←EA + 1\n8:\nend if\n9: end for\n10: r−\nd ←Remove matching content from rd\n11: Split r−\nd into sentences\n12: ED ←number of sentences in r−\nd\n13: return EM, ED, EA\nmeaning as their given sentence, this is matching\ncontent.” Author annotators were asked to flag all\nsamples about which they were unsure or which re-\nquired clinical expertise, and two expert clinicians\nwere consulted on these samples to make a final\ndecision.\nThis matching decision is not always straight-\nforward. For example, in Figure 2 we see that\nthe clinician-written sentence “I’m sorry to hear\nabout your new symptoms” matches with the LLM-\ndrafted sentence “I’m sorry you’ve been feeling\nnauseous.” While expert clinicians in our evalua-\ntion agreed that they would not need to rewrite this\nLLM-drafted sentence, in order to achieve the same\nmeaning as the clinician-written sentence, this is\nnot always trivial and may vary from clinician to\nclinician. Examples of clinician-verified matches\nand non-matches from our training samples can be\nfound in Table 6.\nGiven a sentence se from an expert-written re-\nsponse re and an LLM-drafted response rd the\ncontent-level editJudge model was tasked with out-\nputting either the matching content from the LLM\ndraft sd, or the string “NO MATCH”. Since the\nmatching content sd is later removed from rd to\nidentify expected deletions ED, the output of the\njudge model ˆsd must match verbatim to the match-\ning content in the draft sd in order to remove sd in\nAlgorithm 1. We therefore evaluate the editJudge\nmodel by identifying whether it outputs exactly-\nmatching content sd identified by the annotators.\n15\n"}, {"page": 16, "text": "Clinician Sentence\nLLM Draft (Excerpt)\nMatch Decision\nClinician Reasoning\nThank you for\ntouching base -\nI’m sorry you\nhave been\nexperiencing these\ntroubling symptoms.\nHi Sarah, Thank you for\nreaching out and bringing\nthis to my attention.\nPostmenopausal bleeding can\nindeed be a sign of something\nmore serious, so it’s important\nthat we investigate further.\nThank you for reaching out\nand bringing this to\nmy attention.\nBoth sentences thank the\npatient for being proactive\nand express sympathy about\ntheir symptoms. The clinician\nwould not have to rewrite\nthis component in order to\nachieve the same meaning.\nPlease let us know\nif you have\nany issues with\ngetting the\nmedication.\nThanks for reaching out to me\nabout your decision to switch.\nI would recommend a\ndifferent medication.\nPlease let me know if you have\nquestions or concerns.\nWe can discuss this further\nin your upcoming appointment.\nNO MATCH\nWhile issues with getting\nthe medication may be\nclassified as a concern,\nthe draft is not specific\nenough and the clinician\nwould have to rewrite.\nHave you eaten\nanything out of\nthe ordinary\nfor you?\nHave you experienced any\nother symptoms, such as\nstomach pain, bloating,\nor changes in bowel movements?\nAre you taking any new\nmedications or supplements\nthat could be causing the nausea?\nHave you recently changed\nyour diet or experienced\nany significant stress?\nHave you recently changed\nyour diet or experienced\nany significant stress?\nBoth symptom-related follow-up\nquestions ask the patient\nabout recent diet changes,\nand the clinician would not\nhave to rewrite the drafted\nsentence in order to achieve\nthe same meaning.\nTable 6: Selected examples from the content-level editJudge evaluation dataset. The editJudge model is given the\nLLM draft (an excerpt from each is shown in this table to preserve space) and a sentenec from a clinician-written\nresponse, and is tasked with outputting either the matching content from the LLM draft, or the string “NO MATCH”.\nWe show two matching decisions, one from the empathetic communication theme and another from the symptom-\nrelated follow-up question theme, as well as a close non-match from the contingency planning theme.\nModel\nType\nAvg Agr\nAvg Non-Match\nAvg Match\n% Match\nQwen2.5-7B-Instruct\n0-Shot\n0.74\n1.00\n0.07\n0.07\nLlama-3-8B-Instruct\n0-Shot\n0.17\n0.11\n0.32\n0.50\nQwen2.5-7B-Instruct\n5-Shot\n0.71\n0.93\n0.14\n0.14\nLlama-3-8B-Instruct\n5-Shot\n0.63\n0.88\n0.00\n0.00\nQwen2.5-3B\nSFT\n0.76\n0.97\n0.21\n0.21\nQwen2.5-3B-Instruct\nSFT\n0.80\n0.94\n0.43\n0.50\nLlama-3.2-3B-Instruct\nSFT\n0.85\n1.00\n0.46\n0.57\nQwen2.5-7B\nSFT\n0.87\n0.97\n0.61\n0.71\nQwen2.5-7B-Instruct\nSFT\n0.89\n0.97\n0.68\n0.71\nLlama-3-8B-Instruct\nSFT\n0.96\n1.00\n0.84\n0.92\nTable 7: EditJudge model performance across different configurations. We find that SFT is superior to either\n0-shot or 5-shot editJudge models. We find that the best model, the fine-tuned instruction-tuned Llama3-8B model,\nachieves 96% agreement with clinician-guided author annotations. 84% of the matching author annotations were\nexactly matched by this judge model, and 92% of match decisions contained at least some overlap.\n16\n"}, {"page": 17, "text": "We first identify whether the editJudge model cor-\nrectly makes the matching decision (either by out-\nputting “NO MATCH” or some substring ˆsd from\nthe LLM draft rd), and call this agreement, i.e.\nthe proportion of evaluation samples on which the\njudge model makes the correct matching decision.\nWe further score the editJudge model by identify-\ning non-match agreement, i.e. the proportion of\nnon-matches correct identified by the judge model,\nand match agreement, the proportion of annotated\nwhich are exactly matched by the editJudge model\noutputs. To get a granular estimate of judge model\noutputs, we also score match overlap, i.e. the pro-\nportion of evaluation responses in which editJudge\nmodel output ˆsd and annotated matching content\nsd overlap. We evaluated 6 judge models, testing 0-\nshot, 5-shot, and supervised fine-tuning adaptation\nstrategies for this content-level matching task.\nWe see content-level judge results in Table 7.\nIn general, SFT is far superior to either 0-shot\nor 5-shot judge models.\nWe find that the best\nmodel, the instruction-tuned Llama3-8B model\n(AI@Meta, 2024) fine-tuned on the 450 training\nsamples, achieves 96% agreement with clinician-\nguided author annotations. 84% of the matching\nauthor annotations were exactly matched by this\njudge model, meaning the exact correct content\nwould be removed from the LLM draft rd to iden-\ntify exact expected deletions ED, and 92% of\nmatch decisions contained at least some overlap.\nC.2\nSentence Theme Classification Model\nWe now similarly describe the fine-tuning the\nsentence-level theme classification model, used to\ncalculate the theme-level edit-F1 score described\nin Section 2.1. First, one author hand-labeled 175\ntraining samples and 50 evaluation samples. Each\nsample was a sentence-length string taken from re-\nsponses to SyPPM samples generated by the Aloe-\n8B (Gururajan et al., 2024) 0-shot. Consulting with\ntwo expert clinicians, each sample was assigned a\nsingle theme label, including the 8 themes and an\n“Other” label, to set up a 9-class classification task.\nExample sentences from each theme can be found\nin Table 1.\nFollowing the results of the content-level edit-\nJudge training, we choose to fine-tune a Llama3-8B\nmodel (AI@Meta, 2024) to perform the sentence\nclassification, where the task is to output the class\nlabel (e.g. “Symptom-Related Follow-Up Ques-\ntion”) given the response sentence. Class-wise per-\nformance and micro average F1 of this sentence\nTheme\nF1\nEmpathetic Communication\n0.94\nSymptom-Related\nFollow-Up Questions\n1.00\nMedication-Related\nFollow-Up Questions\n0.67\nMedical Assessment Explanation\n0.67\nMedical Planning Instruction\n0.71\nLogistics: Scheduling,\nBilling, Operations\n0.82\nCare Coordination\n0.80\nContingency Planning\n0.67\nOther\n1.00\nMicro Avg\n0.82\nTable 8: Sentence classification model results. Using\na fine-tuned Llama3-8B model (AI@Meta, 2024), we\nreport class-wise performance and micro average F1.\nWe see that the sentence classification model performs\nwell overall, with a micro average F1 of 0.82, and that it\npredicts all individual classes competently (> 0.67 F1).\nclassification model are reported in Table 8. We\nsee that the sentence classification model performs\nwell overall, with a micro average F1 of 0.82, and\nthat it predicts all individual classes competently\n(> 0.67 F1). We note that this task is subjective on\nsome level, given that theme classes are not neces-\nsarily disjoint. For example, there are valid reasons\nto argue that a question such as “have you noticed\nany diarrhea while on your amoxicillin?” could be\nboth a symptom- and medication-related follow-up\nquestion. However, we enforce a single-class label\nfor simplicity in our evaluations.\nD\nLLM Adaptation Details\nAs described in Section 4.1.2, here we provide\ndetails for the supervised fine-tuning (SFT) and\nthematic agentic direct preference optimization for\nlearning enhancement (TADPOLE) LLM adapta-\ntion strategies which we use in our evaluation in\nSection 5. Prompts for the 0-shot and thematic\nadaptations can be found in Appendix H. Further\ndetails for the RAG, SFT, and TADPOLE adapta-\ntions can be found below.\nD.1\nRAG Details\nUsing the training dataset (144k) as a RAG\ndatabase,\nwe encode patient messages and\nEHR summaries using S-BERT5 (Reimers and\n5all-MiniLM-L6-v2\n17\n"}, {"page": 18, "text": "Gurevych, 2019), and include the 5 most similar\nmessage + EHR strings, along with their real clin-\nician responses in the prompt to guide the LLM,\nalongside the instruction from the 0-shot prompt.\nD.2\nSFT Details\nWe perform supervised fine-tuning using all 144k\ntraining messages. The LLM is trained to output\nthe clinician response r, given the patient message\nm and a summary of the patient’s EHR c contextu-\nalized with the 0-shot prompt (see Appendix H for\nthis prompt).\nEach time a model is fine-tuned, both for the SFT\nmodels in Section 4.1.2 and for the fine-tuned judge\nmodels in Section 3, we train for 1 epoch using a\nbatch size of 4 on a single Nvidia A40 GPU (48GB\nRAM). We train using low-rank adaptation (LoRA)\n(Hu et al., 2022) for efficiency, which has shown to\nbe a performant fine-tuning strategy (John Schul-\nman, 2025; Zhao et al., 2024). We use LoRA with\nrank 8 and an alpha scaling factor of 16. We use\nthe AdamW optimizer with weight decay of 0.01,\nlinear learning rate scheduler with warmup over\n10% of the training steps, and gradient clipping at a\nnorm of 1.0. We apply mixed precision training us-\ning float16 to optimize memory usage and training\nspeed.\nD.3\nTADPOLE Details\nFor each theme, TADPOLE takes a a base response\nr and creates both an “enhanced” response r+ and\n“corrupted” response r−by either adding or re-\nmoving thematic content from the response. First,\nwe take 8k training samples and generate base re-\nsponses using the fine-tuned (SFT) model. For\nenhancing a response r with content from a given\ntheme t, we use a response enhancing agent to\nget an enhanced response r+\nt . Each thematic en-\nhancement agent is a simple 3-shot prompt. For\ncorrupting a response r with content from a given\ntheme t, we use a standard corruption agent con-\ntextualized with the theme t to obtain a corrupted\nresponse r−\nt . Enhancement prompts and the cor-\nruption prompts are developed for and passed to\nthe Qwen2.5-32B-Instruct6 (Team, 2024) model.\nWe obtain 1k enhanced responses for each theme\nand 1k corrupted responses for each theme for a\ntotal of 8k enhanced, base, and corrupted response\n{r+, r, r−} tuples.\nFollowing Li et al., we test several preference\n6Qwen/Qwen2.5-32B-Instruct\npair creation strategies using these tuples. En-\nhanced pairs {r+, r} use enhanced responses and\nbase responses as chosen and rejected responses,\nrespectively.\nCorrupted pairs {r, r−} choose\nbase responses over corrupted responses. Hard-\nCorrupted pairs {r+, r−} choose enhanced re-\nsponses over corrupted responses. We also investi-\ngate a Blend which contains an even amount of all\nthree pairs. We perform DPO (Rafailov et al., 2023)\non the fine-tuned model using 8k TADPOLE pref-\nerence pairs. We perform DPO on the SFT model\nusing a beta of 0.01. Similarly with SFT, we per-\nform DPO by training for 1 epoch using a batch size\nof 1 on a single Nvidia A40 GPU (48GB RAM).\nWe apply mixed precision training using float16 to\noptimize memory usage and training speed.\nWe report average content-level and theme-\nlevel edit-F1 scores on IPPM for each TADPOLE\nstrategy in Table 9. The hard-corrupted strategy\nachieves best performance at the content-level, as\nwell as overall when weighting evenly between\ncontent- and theme-level edit-F1 scores. Hence we\nreport the results of the models trained on hard-\ncorrupted pairs in Section 5.\nE\nMeasures of Inter-Clinician Variation\nE.1\nInter-Annotator Agreement\nClinician responses to patient messages may vary\nbased on experience factors (e.g. role, years of ex-\nperience, specialty), personality factors (e.g. writ-\ning style), and interpersonal factors (e.g. relation-\nship with the patient). Table 12 gives examples\nof different clinician responses to the same patient\nmessage within the SyPPM dataset.\nAs noted in Section 4.2, we gather 3 expert re-\nsponses to 40 samples from the SyPPM dataset. Of\nthe 3 experts, 1 is a primary care physician with 15+\nyears of experience and 2 are primary care nurses,\neach with 5+ years of experience. In Section 4.2\nwe describe how we might use multiple responses\nto understand inter-annotator predictability (IAP).\nHere we describe three measures of inter-annotator\nagreement (IAA), using these same samples.\nWe are interested in measuring how similarly\nclinicians would respond to the same patient mes-\nsage in the same conditions. We start by identi-\nfying, for each theme, the proportion of patient\nmessages to which all three annotator responses\neither included that theme (strict inclusion), or did\nnot include that theme (strict exclusion). Taken\ntogether (strict agreement), we can estimate the\n18\n"}, {"page": 19, "text": "Content-Level\nTheme-Level\nPairs\nPr\nRe\nEdit-F1\nPr\nRe\nEdit-F1\nBlend\n0.13\n0.19\n0.14\n0.53\n0.65\n0.58\nEnhanced\n0.09\n0.14\n0.10\n0.45\n0.62\n0.52\nCorrupted\n0.13\n0.16\n0.12\n0.60\n0.62\n0.61\nHard-Corrupted\n0.13\n0.18\n0.14\n0.54\n0.65\n0.59\nIAP\n0.26\n0.25\n0.24\n0.61\n0.63\n0.62\nTable 9: Content-level and theme-level edit-F1 scores for varying TADPOLE preference pair creation strategies on\nthe IPPM dataset. The hard-corrupted strategy achieves best performance at the content-level, as well as overall\nwhen weighting evenly between content- and theme-level edit-F1 scores.\nIAA Measure\nEmp\nSym Q\nMed Q\nAsse\nPlan\nLog\nCoord\nCont\nStrict Inclusion\n0.53\n0.53\n0.20\n0.03\n0.00\n0.57\n0.00\n0.00\nStrict Exclusion\n0.00\n0.00\n0.00\n0.33\n0.93\n0.00\n0.33\n0.47\nStrict Agreement\n0.53\n0.53\n0.20\n0.36\n0.93\n0.57\n0.33\n0.47\nTable 10: Inter-annotator agreement (IAA) measured at the theme-level by identifying cases when all three annotators\neither included (strict inclusion) or excluded (strict exclusion) each theme in their response. We find that some\nthemes are unanimously found in all clinician responses to most (> 50%) patient messages. Interestingly, we also\nfind that the medical treatment theme is almost never found in any clinician response to most patient messages (<\n7%). This speaks to the reluctance of these clinicians to treat patients via the portal, instead favoring information\nseeking (e.g. follow-up questions) responses.\nClinician\nA\nB\nC\nA\n1.00\n0.51\n0.59\nB\n0.51\n1.00\n0.45\nC\n0.59\n0.45\n1.00\nTable 11: Inter-annotator agreement measured at the\ncontent-level between clinician pairs using cosine simi-\nlarity. We find that agreement between clinician pairs\nvaries substantially, with some (clinicians A and C)\nmore aligned than others (clinicians B and C).\nextent to which each response theme is clinician-\nindependent.\nThese theme-level IAA measurements can be\nfound in Table 10. We find that themes such as em-\npathetic communication, symptom-related follow-\nup questions, and logistical information are unan-\nimously found in all clinician responses to most\n(> 50%) patient messages in SyPPM. Interestingly,\nwe also find that the medical treatment theme is al-\nmost never found in any clinician response to most\npatient messages (< 7%). This speaks to the re-\nluctance of these clinicians to treat patients via the\nportal, instead favoring information seeking (e.g.\nfollow-up questions) responses.\nFor a simpler measure of IAA, we also mea-\nsure the average pairwise cosine similarity of each\nclinician’s responses, comparing each pair of clini-\ncians in Table 11. We find that agreement between\nclinician pairs varies substantially, with some (clin-\nicians A and C, 0.59) more aligned than others\n(clinicians B and C, 0.45).\nE.2\nInter-Annotator Predictability\nWe calculate IAP using both content-level and\ntheme-level edit-F1 scores to enable direct compar-\nison to our model results in Section 5. To estimate\nthe amount of agreement between two expert clini-\ncians in our evaluation framework, we assign the\nfirst clinician the role of expert and the second the\nrole of drafting responses. Treating the first clini-\ncian’s response as the expert response re and the\nsecond’s response as the response draft rd, we cal-\nculate content-level and theme-level edit-F1 scores\nusing the editJudge described in Section 3. Assign-\ning each ordered pair (N = 6) of expert responses\nas ground-truth responses and response drafts, we\ncompare 6 × 40 = 240 total responses, and take\nthe average results. Tables 3, 14, and 15 give IAP\nestimates for content-level and theme-level edit-F1\nscores, class average content-level recall scores,\nand class average theme-level edit-F1 scores, re-\nspectively.\n19\n"}, {"page": 20, "text": "Patient Message\nClinician A Response\nClinician B Response\nI’m not feeling quite\nmyself lately. I’ve been\nexperiencing some weakness\nthat’s making everyday\nactivities a bit more\nchallenging. I was wondering\nif we could touch base\nabout what might be\ncausing this?\nI’m sorry you have been\nexperiencing these troubling\nsymptoms. Could you describe\nwhere you experience the\nweakness? How does it impede\nyour daily activities? Does it\ncome and go? How long has\nthis been going on? Do you\nhave any other symptoms such\nas dizziness or lightheadedness?\nHave you checked your blood\npressure at home? Have you had\nany changes to your medications\nrecently? Please call the office\nto schedule an appointment for\nurgent evaluation. If your symptoms\nworsen acutely, including any\ndizziness or lightheadedness, or\nsyncopal episodes (fainting), you\nshould call 911 and be seen\nemergently in the ER.\nSorry to hear you aren’t feeling\nwell. Are you having any other\nsymptoms? How long have these\nsymptoms been going on? Have\nyou ever had symptoms like this\nbefore? Are you having any nausea,\nvomiting, diarrhea, or constipation?\nAre you having any fevers? Are you\nlosing weight without trying? Are\nyou having any blood in bowel\nmovements? Are you having\nabdominal pain? Have you noticed\nany particular foods that trigger\nthe symptoms? Have you started\nany new medications or supplements?\nHave you recently changed dosing\nor timing of medications you take?\nHave you tried any medications\nthat have helped? Please give us\na call to schedule an appointment.\nYou should be seen in the ED if\nyou have worsening or sudden\nabdominal pain, severe vomiting,\ndizziness, chest pain, or shortness\nof breath.\nI’m having a pretty rough\ntime with my seasonal\nallergies right now. My eyes\nare itchy, I’m congested, and\nI just can’t seem to stop\nsneezing. I’ve been using\nsome over-the-counter meds,\nbut they’re not really giving\nme the relief I need. I was\nwondering if you could\nrecommend something a bit\nstronger or if I should come\nin for an appointment.\nI’m sorry you have been\nexperiencing these troubling\nsymptoms. Which medications\nhave you tried, and what has\nhelped you in the past?\nAre you having any other\nsymptoms? Are you having\nany fevers? Are you having\nany shortness of breath?\nHave you started any new\nmedications or supplements?\nHave you recently changed\ndosing or timing of medications\nyou take? Have you tried any\nmedications that have helped?\nPlease give us a call to\nschedule an appointment. Give\nour triage nurses a call if\nyour symptoms are worsening.\nI’ve been dealing with itchy\neyes for weeks now, and I’m\nguessing it’s just my allergies\nacting up again. I was wondering\nif I could get your thoughts\non it - should I just stick with\nmy usual meds or is there\nsomething else I can try?\nI’m sorry that you have been\nexperiencing these troubling\nsymptoms. Have you been having\nany other symptoms? Have you\nhad any recent changes in your\nmedications? Have you tried\nanything that may have helped\nalleviate your symptoms? If your\nsymptoms are persisting on your\nusual allergy medications, or\nsymptoms are worsening, please\ncall the office to schedule an\nappointment.\nThanks for checking in. Are you\nhaving any other symptoms? How\nlong have these symptoms been\ngoing on? Have you ever had\nsymptoms like this before? Have\nyou started any new medications\nor supplements? Have you recently\nchanged dosing or timing of\nmedications you take? Have you\ntried any medications that have\nhelped? Please call to schedule\nan appointment. You should be\nseen in the ED if you have\nworsening or sudden shortness\nof breath, vision changes, or\nchest pain.\nTable 12: Examples of different clinician responses to the same patient message within the SyPPM dataset. We\ncollect responses from three separate annotators to 40 messages within the SyPPM dataset, and show selected\nexamples from two annotators here.\n20\n"}, {"page": 21, "text": "Content-Level\nTheme-Level\nDataset\nModel\nPrecision\nRecall\nEdit-F1\nPrecision\nRecall\nEdit-F1\nSoCPPM\n0-Shot\n0.06±0.01\n0.29±0.08\n0.10±0.01\n0.48±0.01\n0.83±0.08\n0.61±0.01\nTheme\n0.06±0.00\n0.32±0.11\n0.09±0.01\n0.44±0.00\n0.85±0.11\n0.58±0.01\nRAG\n0.11±0.03\n0.33±0.18\n0.14±0.01\n0.49±0.03\n0.75±0.18\n0.59±0.01\nSFT\n0.15±0.01\n0.18±0.00\n0.15±0.01\n0.63±0.01\n0.62±0.00\n0.62±0.01\nTADPOLE\n0.12±0.01\n0.19±0.01\n0.14±0.01\n0.51±0.01\n0.69±0.01\n0.59±0.01\nIAP\n0.26\n0.25\n0.24\n0.61\n0.63\n0.62\nTable 13: Edit-F1 scores for LLM adaptations on the SoCPPM patient message response drafting dataset. Each\nmodel adaptation is performed on three underlying LLMs, we report scores as average±standard deviation. We\nreport content-level precision, recall, and edit-F1 (Section 3.1), as well as theme-level precision, recall, and edit-F1\n(Section 3.2). We report content-level inter-annotator predictability (IAP), comparing LLM performance and expert\nhuman alignment.\nF\nAdditional Results\nF.1\nSocPPM Results\nThe SoCPPM dataset is created to evaluate LLMs\nin a practical setting, in which response drafts are\ncompared with the clinician response which was\nsent via the secure portal in real time. In some ways\nthis is a less-ideal form of the patient message re-\nsponse drafting task, because real-time clinician\nresponses tend to contain a high degree of variation\nwhich is challenging to filter automatically. For ex-\nample, real-time clinician responses frequently con-\ntain standardized responses (“dot phrases”) which\noffer commonly-repeated instructions, e.g. “please\ncall the COVID-19 hotline if you are experiencing\nany of the following symptoms...” (Baltaro et al.,\n2022). Additionally, real-time responses are writ-\nten under more duress due to workforce constraints\nand growing use of the patient portal (Budd, 2023;\nUnderdahl et al., 2024; Martinez et al., 2023; Yan\net al., 2021).\nIn Table 13 we report the content-level and\ntheme-level precision, recall and edit-F1 scores\nfor adapted LLMs on the SoCPPM dataset. We\nfind that LLMs in general perform more poorly\non this dataset than the ideal IPPM and SyPPM\ndatasets. The best-performing model adaptation\non SyPPM (TADPOLE) achieves 0.20 content-\nlevel edit-F1 scores on SyPPM (see Table 3). The\nbest-performing model adaptation on SoCPPM\n(SFT) achieves only 0.15 content-level edit-F1 on\nSoCPPM (Table 13). We hypothesize that this is\nbecause the SoCPPM dataset represents a version\nof the patient message response drafting task that\nis both more challenging, due to the existence of\nsituated knowledge scattered throughout the EHR\nsystem that is unknowable for the response drafting\nLLM, and less ideal, given that frequently clinician\nresponses in practical settings can be messy and\noften sent under time pressure (Budd, 2023; Under-\ndahl et al., 2024; Martinez et al., 2023; Yan et al.,\n2021).\nWe also note that SFT outperforms TADPOLE\non the SoCPPM dataset, with SFT achieving 0.15\nand 0.62 content- and theme-level edit-F1 scores,\nrespectively, and TADPOLE achieving only 0.14\nand 0.59 (Table 13). As TADPOLE adaptation uses\nthematic preference pairs to further fine-tune SFT\nmodels, we hypothesize that the themes used to\ngenerate these preference pairs are less suitable for\nthe lower-quality, higher-variation responses found\nin real-time clinician responses.\nF.2\nClass-Average Edit-F1 Scores\nIn Tables 3 and 13 we report content-level edit-\nF1 scores across the IPPM-SyPPM, and SoCPPM\ndatasets, respectively.\nTo investigate theme-\nspecific performance of LLM response drafts, we\nalso report theme class-specific scores at the con-\ntent and theme levels. At the content level, in Table\n14 we report the average recall of theme-labeled\ncontent within the expert responses of a given eval-\nuation dataset. At the theme level, in Table 15 we\nreport the class-average edit-F1 scores when pre-\ndicting expert response themes with LLM response\ndraft themes. We discuss these results in Section 5.\nIn Table 4 in Section 5 we give content-level and\ntheme-level edit-F1 scores for the Claude 4.5 Son-\nnet (Anthropic, 2025), Gemini 2.5 Pro (Comanici\net al., 2025) and GPT-OSS (Agarwal et al., 2025)\nreasoning models. In Tables 16 and 17 we similarly\nreport the content-level average recall of theme-\nlabeled content and the theme-level class-average\nedit-F1 scores.\n21\n"}, {"page": 22, "text": "Dataset\nModel\nEmp\nSymQ\nMedQ\nAssess\nPlan\nLogis\nCoord\nCont\nSoCPPM\nProportion\n0.81\n0.05\n0.02\n0.38\n0.27\n0.42\n0.58\n0.03\n0-Shot\n0.29±0.02\n0.07±0.00\n0.07±0.00\n0.16±0.01\n0.23±0.01\n0.21±0.02\n0.24±0.01\n0.21±0.02\nTheme\n0.30±0.02\n0.07±0.01\n0.07±0.00\n0.16±0.00\n0.23±0.00\n0.23±0.03\n0.25±0.00\n0.24±0.04\nRAG\n0.30±0.02\n0.07±0.00\n0.07±0.00\n0.16±0.01\n0.25±0.03\n0.22±0.03\n0.25±0.01\n0.23±0.04\nSFT\n0.30±0.01\n0.08±0.00\n0.07±0.00\n0.15±0.00\n0.21±0.01\n0.24±0.00\n0.24±0.00\n0.27±0.00\nTADPOLE\n0.30±0.02\n0.08±0.00\n0.07±0.00\n0.15±0.01\n0.23±0.03\n0.23±0.02\n0.24±0.00\n0.25±0.04\nIPPM\nProportion\n0.76\n0.23\n0.09\n0.31\n0.24\n0.51\n0.67\n0.07\n0-Shot\n0.28±0.02\n0.07±0.00\n0.07±0.00\n0.15±0.01\n0.23±0.02\n0.21±0.03\n0.24±0.00\n0.22±0.04\nTheme\n0.29±0.02\n0.07±0.02\n0.06±0.01\n0.15±0.00\n0.28±0.09\n0.23±0.02\n0.25±0.01\n0.22±0.07\nRAG\n0.24±0.06\n0.04±0.03\n0.04±0.03\n0.15±0.00\n0.33±0.09\n0.19±0.06\n0.26±0.01\n0.20±0.06\nSFT\n0.30±0.00\n0.08±0.00\n0.07±0.00\n0.15±0.00\n0.21±0.00\n0.24±0.00\n0.24±0.00\n0.27±0.00\nTADPOLE\n0.30±0.00\n0.08±0.00\n0.07±0.00\n0.15±0.01\n0.21±0.02\n0.24±0.01\n0.24±0.01\n0.26±0.02\nSyPPM\nProportion\n0.99\n0.79\n0.79\n0.33\n0.05\n0.75\n0.11\n0.56\n0-Shot\n0.28±0.03\n0.06±0.02\n0.07±0.01\n0.15±0.00\n0.27±0.05\n0.22±0.01\n0.24±0.00\n0.22±0.02\nTheme\n0.30±0.02\n0.08±0.00\n0.08±0.00\n0.16±0.01\n0.24±0.01\n0.24±0.03\n0.25±0.01\n0.25±0.05\nRAG\n0.31±0.01\n0.08±0.00\n0.07±0.00\n0.16±0.01\n0.23±0.02\n0.25±0.01\n0.24±0.01\n0.26±0.01\nSFT\n0.29±0.03\n0.06±0.02\n0.06±0.02\n0.15±0.01\n0.27±0.06\n0.24±0.01\n0.25±0.01\n0.22±0.05\nTADPOLE\n0.30±0.00\n0.08±0.00\n0.07±0.00\n0.15±0.01\n0.21±0.01\n0.24±0.01\n0.24±0.01\n0.27±0.00\nGemini\n0.30\n0.07\n0.07\n0.16\n0.23\n0.24\n0.24\n0.24\nIAP\n0.30\n0.07\n0.07\n0.16\n0.23\n0.24\n0.24\n0.24\nTable 14: Class average content-level recall scores for adapted LLMs. Each model adaptation is performed on three\nunderlying LLMs, we report average results ±standard deviation. We report micro average recall scores for each\ntheme class. We also report the proportion of responses which contain each theme in each dataset. We include\nSyPPM results of the best commercial model (Gemini with theme prompting) for comparison. Finally, we report\ntheme-level IAP, comparing LLM performance and expert human alignment at the theme level.\nG\nExample REDCap Survey\nIn the IPPM evaluation dataset, ground-truth re-\nsponses are written by a paid team of 4 expert\nprimary care nurses who work daily in the patient\nportal, collected via REDCap surveys (Harris et al.,\n2009). In the SyPPM evaluation dataset, ground-\ntruth responses are written by a paid primary care\ndoctor with 15+ years of experience. Each clinician\nwas paid $50 for every 10 responses (estimated to\ntake 1 hour), in order to give ample time to write\na full response to each message/EHR summary.\nWhile writing responses, experts were prompted\n“if you had unlimited time, what would be included\nin your response to this patient?” To provoke qual-\nity responses, clinicians were given a separate text\nentry box for each of the themes derived in Section\n2.1. For example, the Treatment Contingency Plan-\nning text box included the prompt “please outline\na backup/red flag plan for the patient, if applica-\nble.” Screenshots of an example REDCap survey\nquestion can be found in Figure 4 and Figure 5.\nH\nPrompts\nIn Section 3 we describe several methods for adapt-\ning LLMs for the patient message response drafting\ntask. We give the 0-shot and thematic prompts in\nFigure 6 and Figure 7, respectively. The thematic\nprompt guides the model to use our derived themes\nwhen drafting responses to patient messages. In\nSection 5 we see that thematic prompting, and other\nforms of contextual adaptation such as RAG, SFT,\nand our novel TADPOLE DPO-based strategy, im-\nprove LLM performance on the response drafting\ntask.\n22\n"}, {"page": 23, "text": "Figure 4: Screenshot of the beginning of a REDCap survey question used to collect clinician responses to patient\nmessages in the SyPPM dataset. The patient’s EHR chart and message are first given, then the clinician is prompted\nwith a series of text entry boxes for each response theme described in Section 2.1.\n23\n"}, {"page": 24, "text": "Figure 5: Screenshot of the end of a REDCap survey response used to collect clinician responses to patient messages\nin the SyPPM dataset. After seeing the patient’s EHR chart and message, the clinician is prompted with a series\nof text entry boxes for each response theme described in Section 2.1. The clinician is also prompted to give any\nadditional thoughts or assumptions they made while drafting their response.\n24\n"}, {"page": 25, "text": "Dataset\nModel\nEmp\nSymQ\nMedQ\nAssess\nPlan\nLogis\nCoord\nCont\nSoCPPM\nProportion\n0.81\n0.05\n0.02\n0.38\n0.27\n0.42\n0.58\n0.03\n0-Shot\n0.88±0.02\n0.12±0.06\n0.08±0.07\n0.57±0.02\n0.46±0.02\n0.58±0.03\n0.68±0.02\n0.12±0.07\nTheme\n0.88±0.02\n0.13±0.05\n0.12±0.05\n0.55±0.00\n0.44±0.02\n0.58±0.03\n0.69±0.02\n0.09±0.01\nRAG\n0.82±0.05\n0.12±0.05\n0.07±0.06\n0.55±0.01\n0.47±0.01\n0.57±0.03\n0.70±0.03\n0.11±0.09\nSFT\n0.88±0.01\n0.10±0.16\n0.00±0.00\n0.42±0.02\n0.36±0.07\n0.51±0.04\n0.64±0.02\n0.09±0.08\nTADPOLE\n0.89±0.00\n0.18±0.04\n0.10±0.04\n0.45±0.02\n0.35±0.07\n0.53±0.05\n0.68±0.01\n0.09±0.03\nIPPM\nProportion\n0.76\n0.23\n0.09\n0.31\n0.24\n0.51\n0.67\n0.07\n0-Shot\n0.85±0.02\n0.05±0.05\n0.09±0.06\n0.51±0.02\n0.42±0.02\n0.59±0.02\n0.76±0.03\n0.12±0.05\nTheme\n0.85±0.02\n0.45±0.05\n0.20±0.06\n0.49±0.01\n0.41±0.00\n0.59±0.02\n0.77±0.00\n0.15±0.04\nRAG\n0.77±0.05\n0.05±0.02\n0.08±0.10\n0.47±0.00\n0.46±0.05\n0.58±0.03\n0.75±0.02\n0.11±0.03\nSFT\n0.86±0.00\n0.08±0.02\n0.08±0.08\n0.32±0.03\n0.38±0.05\n0.49±0.03\n0.73±0.01\n0.07±0.07\nTADPOLE\n0.87±0.00\n0.45±0.02\n0.21±0.07\n0.30±0.05\n0.36±0.05\n0.46±0.05\n0.77±0.01\n0.15±0.02\nSyPPM\nProportion\n0.99\n0.79\n0.79\n0.33\n0.05\n0.75\n0.11\n0.56\n0-Shot\n0.98±0.02\n0.17±0.10\n0.08±0.07\n0.50±0.00\n0.10±0.01\n0.54±0.23\n0.19±0.08\n0.42±0.06\nTheme\n0.99±0.00\n0.72±0.01\n0.32±0.01\n0.50±0.01\n0.06±0.04\n0.52±0.05\n0.17±0.01\n0.33±0.15\nRAG\n0.93±0.03\n0.19±0.10\n0.05±0.00\n0.49±0.01\n0.12±0.04\n0.57±0.17\n0.20±0.02\n0.32±0.21\nSFT\n0.98±0.01\n0.38±0.04\n0.09±0.04\n0.33±0.08\n0.24±0.13\n0.58±0.09\n0.22±0.02\n0.13±0.03\nTADPOLE\n0.99±0.00\n0.79±0.03\n0.49±0.01\n0.16±0.04\n0.17±0.09\n0.19±0.02\n0.22±0.03\n0.46±0.16\nGemini\n0.99\n0.71\n0.28\n0.50\n0.14\n0.76\n0.33\n0.71\nIAP\n0.80\n0.80\n0.53\n0.38\n0.07\n0.73\n0.15\n0.06\nTable 15: Class average theme-level edit-F1 scores for LLM adaptations. Each model adaptation is performed on\nthree underlying LLMs, we report average results ±standard deviation. We report micro average edit-F1 scores for\neach theme class. We also report the proportion of responses which contain each theme in each dataset. We include\nSyPPM results of the best commercial model (Gemini with theme prompting) for comparison. Finally, we report\ntheme-level IAP, comparing LLM performance and expert human alignment at the theme level.\nPrompt\nModel\nEmp\nSymQ\nMedQ\nAssess\nPlan\nLogis\nCoord\nCont\n0-Shot\nGPT\n0.31\n0.07\n0.07\n0.15\n0.21\n0.24\n0.24\n0.27\nGemini\n0.30\n0.08\n0.07\n0.15\n0.21\n0.25\n0.24\n0.28\nClaude\n0.31\n0.07\n0.07\n0.15\n0.23\n0.24\n0.24\n0.27\nAvg\n0.31\n0.07\n0.07\n0.15\n0.22\n0.24\n0.24\n0.27\nTheme\nGPT\n0.28\n0.07\n0.08\n0.14\n0.34\n0.21\n0.24\n0.19\nGemini\n0.30\n0.07\n0.07\n0.16\n0.23\n0.24\n0.24\n0.24\nClaude\n0.31\n0.08\n0.07\n0.14\n0.20\n0.24\n0.24\n0.27\nAvg\n0.30\n0.07\n0.07\n0.15\n0.26\n0.23\n0.24\n0.23\nIAP\n0.30\n0.21\n0.21\n0.13\n0.27\n0.37\n0.15\n0.64\nTable 16: Class average content-level recall scores for Claude 4.5 Sonnet, Gemini 2.5 Pro and GPT-OSS reasoning\nmodels models on the publicly-available SyPPM evaluation dataset. We evaluate each model using 0-shot and\nthematic prompts. Classifying elements in clinician responses into themes, we report response draft recall scores\naveraged across each theme. We also report content-level IAP, comparing LLM performance and expert human\nalignment at the content level.\nPrompt\nModel\nEmp\nSymQ\nMedQ\nAssess\nPlan\nLogis\nCoord\nCont\n0-Shot\nGPT\n0.99\n0.42\n0.22\n0.50\n0.10\n0.81\n0.27\n0.64\nGemini\n0.99\n0.16\n0.03\n0.50\n0.12\n0.79\n0.29\n0.66\nClaude\n0.99\n0.49\n0.22\n0.50\n0.09\n0.53\n0.34\n0.52\nAvg\n0.99\n0.36\n0.16\n0.50\n0.10\n0.71\n0.30\n0.61\nTheme Prompting\nGPT\n0.99\n0.80\n0.43\n0.50\n0.10\n0.82\n0.27\n0.60\nGemini\n0.99\n0.71\n0.28\n0.50\n0.14\n0.76\n0.33\n0.71\nClaude\n0.99\n0.87\n0.39\n0.50\n0.12\n0.63\n0.15\n0.56\nAvg\n0.99\n0.79\n0.37\n0.50\n0.12\n0.74\n0.25\n0.62\nTheme Proportion\n0.99\n0.79\n0.79\n0.33\n0.05\n0.75\n0.11\n0.56\nIAP\n0.80\n0.80\n0.53\n0.38\n0.07\n0.73\n0.15\n0.06\nTable 17: Class average theme-level edit-F1 scores for Claude 4.5 Sonnet, Gemini 2.5 Pro and GPT-OSS reasoning\nmodels models on the publicly-available SyPPM evaluation dataset. We evaluate each model using 0-shot and\nthematic prompts. We report edit-F1 scores for each theme class. Additionally, we report the proportion of responses\nwhich contain each theme (theme proportion) in the SyPPM dataset. Finally, we also report theme-level IAP,\ncomparing LLM performance and expert human alignment at the theme level.\n25\n"}, {"page": 26, "text": "You will be given a patient portal message and the patient’s EHR chart. Respond to the message as\nthough you were their doctor.\nPatient Chart: {chart}\nPatient Message: {message}\nDoctor Response:\nFigure 6: 0-shot prompt for patient message response drafting\nYou will be given a patient portal message and the patient’s EHR chart. Respond to the message as\nthough you were their doctor.\nGood doctor responses are typically concise, and may contain some of the following themes:\n- Empathetic communication, e.g. showing understanding and care for the patient’s situation\n- Symptom-related follow-up questions, e.g. asking about the patient’s symptoms or history\n- Medication-related follow-up questions, e.g. asking about the patient’s medication history or plans\n- Medical assessment, e.g. explaining symptom causes or why you are prescribing a medication\n- Medical instruction, e.g. outlining medical plans for the patient or providing instructions to the\npatient\n- Logistical information, e.g. giving details about scheduling, billing, operations\n- Care coordination, e.g. outlining communication plans for/with the patient, and/or inter- or intra-\nclinic communication plans\n- Contingency planning, e.g. outlining a backup/red flag plan for the patient\nPatient Chart: {chart}\nPatient Message: {message}\nDoctor Response:\nFigure 7: Thematic prompt for patient message response drafting\n26\n"}]}