{"doc_id": "arxiv:2602.13571", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2602.13571.pdf", "meta": {"doc_id": "arxiv:2602.13571", "source": "arxiv", "arxiv_id": "2602.13571", "title": "LLM-Confidence Reranker: A Training-Free Approach for Enhancing Retrieval-Augmented Generation Systems", "authors": ["Zhipeng Song", "Xiangyu Kong", "Xinrui Bao", "Yizhi Zhou", "Jiulong Jiao", "Sitong Liu", "Yuhang Zhou", "Heng Qi"], "published": "2026-02-14T03:12:05Z", "updated": "2026-02-14T03:12:05Z", "summary": "Large language models (LLMs) have revolutionized natural language processing, yet hallucinations in knowledge-intensive tasks remain a critical challenge. Retrieval-augmented generation (RAG) addresses this by integrating external knowledge, but its efficacy depends on accurate document retrieval and ranking. Although existing rerankers demonstrate effectiveness, they frequently necessitate specialized training, impose substantial computational expenses, and fail to fully exploit the semantic capabilities of LLMs, particularly their inherent confidence signals. We propose the LLM-Confidence Reranker (LCR), a training-free, plug-and-play algorithm that enhances reranking in RAG systems by leveraging black-box LLM confidence derived from Maximum Semantic Cluster Proportion (MSCP). LCR employs a two-stage process: confidence assessment via multinomial sampling and clustering, followed by binning and multi-level sorting based on query and document confidence thresholds. This approach prioritizes relevant documents while preserving original rankings for high-confidence queries, ensuring robustness. Evaluated on BEIR and TREC benchmarks with BM25 and Contriever retrievers, LCR--using only 7--9B-parameter pre-trained LLMs--consistently improves NDCG@5 by up to 20.6% across pre-trained LLM and fine-tuned Transformer rerankers, without degradation. Ablation studies validate the hypothesis that LLM confidence positively correlates with document relevance, elucidating LCR's mechanism. LCR offers computational efficiency, parallelism for scalability, and broad compatibility, mitigating hallucinations in applications like medical diagnosis.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2602.13571v1", "url_pdf": "https://arxiv.org/pdf/2602.13571.pdf", "meta_path": "data/raw/arxiv/meta/2602.13571.json", "sha256": "1485c60033984f9e86695fcef555587ca6fac69b031f5d64826bf49a2cfcbd76", "status": "ok", "fetched_at": "2026-02-18T02:19:19.078308+00:00"}, "pages": [{"page": 1, "text": "LLM-Confidence Reranker: A Training-Free Approach for\nEnhancing Retrieval-Augmented Generation Systems\nLLM-Confidence Reranker: A Training-Free Approach for\nEnhancing Retrieval-Augmented Generation Systems\nZhipeng Songa,âˆ—, Xiangyu Kongb,âˆ—, Xinrui Baoe, Yizhi Zhouc, Jiulong Jiaoa,d, Sitong Liuf,\nYuhang Zhoug and Heng Qia,âˆ—âˆ—\naSchool of Computer Science and Technology, Dalian University of Technology, No.2 Linggong Road, Ganjingzi District, Dalian, 116024, China\nbSchool of Information Engineering, Liaodong University, No.116 Linjiang Back Street, Zhenan District, Dandong, 118001, China\ncSchool of Information Engineering, Dalian Ocean University, No. 2-52, Heishijiao Street, Shahekou District, Dalian, 116023, China\ndInformation Technology Center, Qinghai University, 251 Ningda Road, Chengbei District, Xining, 810016, China\neSchool of Electronic and Information Engineering, Liaoning Technical University, 188 Longwan South Street, Sijiatun\nDistrict, Huludao, 125105, China\nfSchool of Artificial Intelligence, Tianjin Normal University, 393 Binshui West Road, Xiqing District, Tianjin, 300387, China\ngTencent (Dalian Northern Interactive Entertainment Technology Co., Ltd.), 21/F, Tencent Building, No. 26 Jingxian St, Ganjingzi\nDistrict, Dalian, 116085, China\nA R T I C L E I N F O\nKeywords:\nlarge language models\nretrieval-augmented generation\nreranking\nmodel uncertainty\nA B S T R A C T\nLarge language models (LLMs) have revolutionized natural language processing, yet hallucina-\ntions in knowledge-intensive tasks remain a critical challenge. Retrieval-augmented generation\n(RAG) addresses this by integrating external knowledge, but its efficacy depends on accurate\ndocument retrieval and ranking. Although existing rerankers demonstrate effectiveness, they\nfrequently necessitate specialized training, impose substantial computational expenses, and fail\nto fully exploit the semantic capabilities of LLMs, particularly their inherent confidence signals.\nWe propose the LLM-Confidence Reranker (LCR), a training-free, plug-and-play algorithm\nthat enhances reranking in RAG systems by leveraging black-box LLM confidence derived\nfrom Maximum Semantic Cluster Proportion (MSCP). LCR employs a two-stage process:\nconfidence assessment via multinomial sampling and clustering, followed by binning and multi-\nlevel sorting based on query and document confidence thresholds. This approach prioritizes\nrelevant documents while preserving original rankings for high-confidence queries, ensuring\nrobustness. Evaluated on BEIR and TREC benchmarks with BM25 and Contriever retrievers,\nLCRâ€”using only 7â€“9B-parameter pre-trained LLMsâ€”consistently improves NDCG@5 by up\nto 20.6% across pre-trained LLM and fine-tuned Transformer rerankers, without degradation.\nAblation studies validate the hypothesis that LLM confidence positively correlates with docu-\nment relevance, elucidating LCRâ€™s mechanism. LCR offers computational efficiency, parallelism\nfor scalability, and broad compatibility, mitigating hallucinations in applications like medical\ndiagnosis.\n1. Introduction\nIn recent years, large language models (LLMs) have achieved remarkable progress in natural language processing\n(NLP). They excel in tasks such as text generation and question answering. Leveraging their advanced capabilities in\nlanguage understanding and generation, LLMs have significantly enhanced task efficiency and user experience across a\nwide range of applications (DeepSeek-AI et al., 2025). However, a persistent challenge remains: â€œhallucinationâ€â€”the\nâˆ—The two authors contribute equally to this work and should be regarded as co-first authors.\nâˆ—âˆ—Corresponding author.\nsongzhipeng@mail.dlut.edu.cn ( Zhipeng Song); xiangyukong@liaodongu.edu.cn ( Xiangyu Kong);\n4724200573@stu.lntu.edu.cn ( Xinrui Bao); zhouyizhi@dlou.edu.cn ( Yizhi Zhou); jiaojiulong@mail.dlut.edu.cn ( Jiulong Jiao);\nliusitong@stu.tjnu.edu.cn ( Sitong Liu); ginozhou@tencent.com ( Yuhang Zhou); hengqi@dlut.edu.cn ( Heng Qi)\nORCID(s): 0009-0009-6249-1988 ( Zhipeng Song); 0000-0003-1940-8674 ( Xiangyu Kong); 0009-0000-7916-2122 ( Xinrui Bao);\n0000-0002-6761-5953 ( Yizhi Zhou); 0009-0001-9852-7999 ( Jiulong Jiao); 0009-0000-4728-7078 ( Sitong Liu);\n0009-0007-3489-0549 ( Yuhang Zhou); 0000-0002-8770-3934 ( Heng Qi)\nSong et al.: Preprint submitted to Elsevier\nPage 1 of 21\narXiv:2602.13571v1  [cs.CL]  14 Feb 2026\n"}, {"page": 2, "text": "LLM-Confidence Reranker\ngeneration of plausible yet factually inaccurate or entirely fabricated content. This issue poses a significant barrier\nin knowledge-intensive applications, such as medical diagnosis, where factual accuracy is paramount (Ji et al., 2023;\nHuang et al., 2025; Luo et al., 2026; PÅ‚onka et al., 2025; Chi et al., 2026; L. Li et al., 2025).\nTo mitigate hallucination, retrieval-augmented generation (RAG) has emerged as a promising approach. By\nintegrating external knowledge retrieval with the generation process, RAG provides LLMs with a factual foundation.\nThis improves the accuracy of generated outputs (Lewis et al., 2020; W. Yu, 2022; Yao et al., 2026; T. Ren et al., 2025).\nHallucinations often stem from low confidence in internal knowledge, which can be addressed by external documents\nthat boost model confidence. Nevertheless, the success of RAG hinges on the relevance of retrieved documents. Poorly\nranked documents undermine the quality of subsequent generation. This limits the frameworkâ€™s effectiveness (Liu et\nal., 2024).\nReranking has gained prominence as a vital step in enhancing retrieval outcomes within RAG systems. By\nreordering initially retrieved documents, reranking techniques improve document relevance and provide higher-\nquality inputs for generation (Y. Yu et al., 2024; Salemi & Zamani, 2024; S. Xu et al., 2024; R. Ren, Ma, &\nZheng, 2025). Although existing reranking methods have advanced retrieval performance, they encounter notable\nlimitations. Many depend on proprietary models trained on specific datasets, leading to poor generalization across\ndomains and high computational costs (Ma et al., 2023; Sun et al., 2023; X. Wang et al., 2023; Dong et al., 2024)â€”\nconstraints that severely restrict their practical applicability. In contrast, pre-trained LLM-based rerankers provide\nstrong generalization and no additional training costs compared to trained models; however, existing LLM-based\nrerankers primarily assess query-document relevance but underutilize LLMsâ€™ strengths in semantic understanding,\nparticularly by overlooking confidence signals from generation processes. Furthermore, even state-of-the-art rerankers\ndemonstrate suboptimal performance, with their Normalized Discounted Cumulative Gain (NDCG) scores often falling\nbelow 0.8 on benchmarks like BEIR (Ehsan et al., 2024). This underscores the necessity for continued innovation in\nreranking methodologies.\nLLM\n0.9\n0.6\n0.5\n0.4\n0.1\n0.9 â†‘\n0.5  -\n0.6  -\n0.4  -\n0.1 â†“\nConfidence\nMeasurement\nPreserve the original order\nRetriever\nSimilarity\nReranker\nRelevance\nLCR\nHelpfulness\nQuery\nTop K\nTop N\nLLM\nFigure 1: Illustration of LLM-Confidence Reranker (LCR) algorithm. LCR leverages LLM confidence signals derived from\ndocument helpfulness to enhance ranking, distinct from traditional relevance or similarity measures.\nThe main contributions of this study are as follows:\n1. We propose a novel zero-shot reranking method LLM-Confidence Reranker (LCR) based on black-box LLM\nconfidence signals, which quantifies confidence through the Maximum Semantic Cluster Proportion (MSCP).\nSong et al.: Preprint submitted to Elsevier\nPage 2 of 21\n"}, {"page": 3, "text": "LLM-Confidence Reranker\nThis approach fully leverages the LLMâ€™s semantic understanding and question-answering capabilities to enhance\ndocument ranking accuracy in RAG systems.\n2. LCR exhibits high adaptability and generalization, functioning as a standalone reranker or seamlessly integrating\nafter existing rerankers to further refine ranking results. The approach relies solely on lightweight pre-trained\nLLMs with 7-9B parameters, requiring no training or internal parameter access, ensuring high computational\nefficiency and low cost, and achieving consistent performance improvements across diverse retrievers and\nrerankers on the BEIR and TREC benchmarks, achieving NDCG@5 gains of up to 20.6%.\n3. This method employs a pointwise independent scoring mechanism, supporting parallel processing and scalability\nto large-scale documents.\n4. Through experiments, we validate the hypothesis that LLM confidence in generated responses positively\ncorrelates with document relevance, elucidating the effective mechanism of LCR and providing a theoretical\nfoundation for mitigating hallucinations in knowledge-intensive tasks.\nThe remainder of the paper is organized as follows: Section 2 reviews the related literature. Section 3 elucidates\nthe confidence modeling techniques and delineates the LCR algorithm. Section 4 details the experimental evaluations,\nincluding the setup, results, and analyses of the impacts of retrievers, models, hyperparameters, and confidence\nquantification methods, as well as the underlying mechanism. Section 5 summarizes the findings and outlines future\nresearch directions.\n2. Related Work\n2.1. Uncertainty Quantification Methods for LLMs\nUncertainty quantification methods can be categorized into two main types depending on whether model training is\nnecessary: training-required methods and training-free methods. Training-required methods improve the uncertainty\nexpression capabilities of large language models (LLMs) by employing fine-tuning or other learning processes. In\ncontrast, training-free methods directly leverage the modelâ€™s pre-existing capabilities to extract uncertainty information.\n2.1.1. Training-Required Methods\nTraining-required methods improve LLMsâ€™ ability to accurately express uncertainty through model adjustment or\noptimization, primarily following three technical approaches:\nSupervised Fine-tuning Supervised fine-tuning aims to enhance LLMsâ€™ uncertainty expression through training. For\nexample, Lin et al. (2022) enabled models to express uncertainty in natural language via fine-tuning. A key development\nis the P(IK) method, proposed by Kadavath et al. (2022), which quantifies uncertainty by training language models to\npredict their own probability of correctly answering questions. To enhance the modelâ€™s transparency and explainability\nregarding uncertainty, Y. Yang et al. (2024) further explored the possibility of embedding explicit confidence in\nthe modelâ€™s output. This was achieved by training the model to use language such as â€œIâ€™m absolutely certainâ€ or\nexpress numerical confidence (e.g., â€œabout 90% confidentâ€), allowing this confidence to be explicitly presented to the\nuser. In subsequent research, scholars began to focus on whether the decisiveness of language in model generations\nfaithfully reflects their intrinsic confidence. Yona et al. (2024) formalized faithful response uncertainty based on the gap\nbetween linguistic decisiveness and intrinsic confidence, evaluating modelsâ€™ ability to faithfully express uncertainty in\nwords.Manggala et al. (2025) systematically explores the discrepancy between confidence scores and actual accuracy,\nproposing QA-calibration as a generalized, principled calibration notion, which provides a reference direction for\nimproving uncertainty expression in generative QA.\nReinforcement Learning â€‹This task is implemented by training LLMs with reinforcement learning to identify and\ndecline unknown questions. For instance, T. Xu et al. (2024) present the SaySelf training framework, which enhances\nthe modelâ€™s ability to express fine-grained confidence estimates by generating self-reflective rationales. Similarly,\nto enable models to express uncertainty in natural language when beyond their knowledge boundaries, Cheng et al.\n(2024) constructed the â€œI donâ€™t knowâ€ (Idk) dataset, and achieved this through alignment training. H. Xu et al. (2024)\nproposed the Reinforcement Learning with Knowledge Feedback (RLKF) method, helping models identify knowledge\nboundaries and reject out-of-scope questions, thereby implicitly quantifying uncertainty and improving reliability. To\nidentify and address the systematic bias in reward models towards high confidence scores in RLHF training, Leng et\nal. (2025) proposed calibrated reward methods such as PPO-M and PPO-C, thereby effectively reducing calibration\nerror in LLMs.\nSong et al.: Preprint submitted to Elsevier\nPage 3 of 21\n"}, {"page": 4, "text": "LLM-Confidence Reranker\nProbing Probing methods quantify uncertainty by analyzing internal model representations. For example, Azaria &\nMitchell (2023) introduced the SAPLMA method, which predicts statement truth probabilities by analyzing hidden\nlayer activations, providing a quantitative approach to assess LLMsâ€™ internal confidence. Marks & Tegmark (2024)\nproposed mass-mean probing to identify and intervene in linear representations of factual truth within models, opening\nnew avenues for quantifying confidence in factual claims.\n2.1.2. Training-Free Methods\nTraining-free methods estimate uncertainty without additional optimization, leveraging existing model outputs or\nbehaviors through two main approaches:\nPrediction Probability These methods estimate uncertainty by analyzing output probability distributions. A com-\nmon method for measuring uncertainty is Predictive Entropy (Settles & Craven, 2008). To enable comparison across\ndifferent length outputs, Malinin & Gales (2021) systematically applied length-normalization to various information-\ntheoretic uncertainty measures, enhancing their practical utility. Xiao & Wang (2021) further applied entropy values to\nthe hallucination problem in conditional language generation tasks, revealing the key relationship between uncertainty\nand hallucination. One method is to prompt the extraction of uncertainty information through specially designed\ninputs. The P(True) method (Kadavath et al., 2022), for example, asks models to evaluate the probability of their\nanswers being correct, with higher probabilities indicating lower uncertainty. This approach relies on modelsâ€™ self-\nassessment capabilities. Addressing the â€œgenerative inequalityâ€ problem in LLMs free-form output, where irrelevant\ntokens and sentences are over-valued when estimating uncertainty, Duan et al. (2024) proposed Shifting Attention to\nRelevance (SAR), a method that mitigates these biases by reassigning attention based on the jointly examined relevance\nof components during uncertainty quantification. To address the bias of Predictive Entropy when handling irrelevant\ninformation, Z. Wang et al. (2025) proposed Word-Sequence Entropy (WSE). WSE enhances the accuracy and stability\nof uncertainty quantification by incorporating semantic relevance at both word and sequence levels, utilizing off-\nthe-shelf LLMs and multi-sample generation. This approach also significantly improves LLMsâ€™ accuracy in medical\nquestion-answering applications.\nSampling & Aggregation These methods estimate uncertainty by generating and analyzing multiple outputs. For\nexample,Farquhar et al. (2024) introduced Semantic Entropy to quantify uncertainty in generation tasks by considering\nsemantic equivalence.To address the insufficiency and unreliability of entropy as a confidence metric, particularly under\ndistribution shifts and biased scenarios, Lee et al. (2024) introduced the Pseudo-Label Probability Difference (PLPD)\nas a newly proposed confidence metric, allowing it to identify more reliable samples by leveraging information that\nentropy cannot capture.Meanwhile, Xiong et al. (2024) further systematically proposed a general black-box confidence\nelicitation framework, combining human-inspired prompting strategies, diverse sampling methods, and confidence\naggregation mechanisms, which can significantly improve LLMsâ€™ performance in tasks like confidence calibration\nand failure prediction, even without internal access. Aichberger et al. (2025) introduced the Semantically Diverse\nLanguage Generation (SDLG) method, which steers LLMs to generate semantically diverse yet likely alternative texts,\nsignificantly improving the estimation accuracy of predictive uncertainty. Qing et al. (2025) evaluated consistency-\nbased metrics for post-hoc uncertainty quantification.\n2.2. Reranking Methods in RAG\nInitial retrieval in RAG still struggles with issues like irrelevant or suboptimal results, missing key documents, and\ndata quality concernsâ€”highlighting the importance of reranking optimization. These reranking methods fall into three\ncategories: pointwise, pairwise, and listwise.\n2.2.1. Pointwise Methods\nPointwise reranking ranks documents or items by independently scoring their relevance and sorting them. Sachan\net al. (2022) achieved unsupervised Top-20 accuracy improvements on BEIR benchmarks via pre-trained model-based\nprobabilistic inference, which established zero-shot probabilistic ranking paradigms. Bonifacio et al. (2022) leveraged\nfew-shot generation capabilities to build synthetic query-document pairs via monoT5. Boytsov et al. (2024) extended\nthis to industrial-grade InPars-Light through model compression and toolchain integration.\nSong et al.: Preprint submitted to Elsevier\nPage 4 of 21\n"}, {"page": 5, "text": "LLM-Confidence Reranker\n2.2.2. Pairwise Methods\nPairwise reranking predicts the relative order of document pairs to achieve overall document ranking. Its advantage\nlies in closely aligning with rankingâ€™s core by focusing on relative document order, effectively minimizing inversions\n(Joachims, 2002). Recent progress addresses computational bottlenecks and probabilistic modeling. Khattab & Zaharia\n(2020) improved efficiency via precomputed BERT document representations and late interaction. To address the order\nsensitivity of traditional methods, Jian et al. (2024) introduced the PRP-Graph framework, integrating probabilistic\nrelevance propagation, dynamic graph aggregation, and weighted PageRank to enhance ranking model stability.\nSimilarly, R. Li et al. (2024) proposed the PRD framework, introducing dynamic weighting mechanisms and multi-\nturn discussion strategies, which effectively mitigated the limitations of single-model evaluation and enhanced the\nadaptability and robustness of ranking systems. As generative retrieval (GR) develops, researchers began considering\nhow to extend it to accommodate multi-graded relevance scenarios. In this context, Tang et al. (2024a) introduced\na multi-graded constrained contrastive (MGCC) loss which incorporates grade penalty and constraint mechanisms.\nConcurrently, Maximilian et al. (2025) defined pairwise preferences based on the similarity between argumentative\nunits and the query, aggregated these preference signals in the reranking phase, significantly enhancing argument\nretrieval effectiveness. Addressing the effectiveness-efficiency trade-off optimization for retrieval using multiple\nprediction models, Harrie et al. (2025) introduced compound retrieval systems. These systems, via a selection policy,\nlearn to acquire BM25 and LLM pointwise and pairwise predictions and aggregate them for final ranking construction,\nenhancing retrieval efficiency.\n2.2.3. Listwise Methods\nListwise reranking optimizes the entire document lists to enhance retrieval effectiveness. To account for varying\nnumbers of document pairs per query and more accurately capture ranking metrics, Cao et al. (2007) proposed the\nlistwise learning-to-rank approach. This approach uses document lists as instances in learning, contrasting with the\npairwise approach which uses document pairs. By assigning different weights to training instances during optimization,\nListMAP significantly improved document ranking effectiveness (Keshvari et al., 2022). To address issues like the\ndiscrepancy between LLM pre-training objectives and the ranking objective and the lack of direct passage ranking\ncapability, Sun et al. (2023) proposed the instructional permutation generation approach to directly output passage\nrankings. They then leveraged the permutation outputs generated by ChatGPT through a permutation distillation\ntechnique to transfer its ranking capability to smaller, efficient specialized models, which significantly improved\npassage re-ranking performance. Furthermore, research has advanced in incorporating listwise principles into the\nGR paradigm. Tang et al. (2024b) proposed ListGR, which views the retrieval task as a sequential learning process\nfor generating a list of docids. Considering the sensitivity of LLMs to the order of input passages, Zhang et al.\n(2024) proposed a simple listwise sampling approach that effectively mitigates dependence on the position of ground\ntruth evidence by shuffling the list of input passages multiple times and aggregating results. Efficiency was further\naddressed by Chen et al. (2025), who implemented tournament-style dynamic grouping in their TourRank system.\nFurthermore, Suresh et al. (2025) curated CORNSTACKâ€”a high-quality dataset filtered by dual consistencyâ€”for\ncontrastive training, yielding significant performance gains in embedding models and code rerankers on code retrieval\ntasks. Subsequently, Qi et al. (2025) proposes a label formulation integrating content-based relevance and engagement-\nbased relevance, leveraging sigmoid transformations to enhance the ranking systemâ€™s ability to differentiate content\nquality and improve controllability in ranking. Chowdhury et al. (2025) developed RankSHAP, a Shapley value-based\nfeature attribution method, to improve ranking model explainability. It significantly enhances feature attribution fidelity\nand explainability for information retrieval reranking models. Furthermore , R. Ren, Wang, et al. (2025) proposed the\nSCaLR method, which introduces explicit list-view relevance scores for global ranking and uses self-generated point-\nview relevance assessments to calibrate the list-view relevance, enhancing global comparability on large candidate\nsets.\n3. Methodology\nThis section delineates the proposed LLM-Confidence Reranker algorithm. We first elaborate on the Maximum\nSemantic Cluster Proportion, a confidence modeling technique tailored for black-box large language models (LLMs),\nas detailed in Â§3.1, with an emphasis on a semantic consistency approach. Subsequently, we outline the comprehensive\nprocedure of the LCR algorithm in Â§3.2.\nSong et al.: Preprint submitted to Elsevier\nPage 5 of 21\n"}, {"page": 6, "text": "LLM-Confidence Reranker\n3.1. Maximum Semantic Cluster Proportion\nConfidence represents a language modelâ€™s assurance in its generated output, whereas uncertainty reflects the lack\nof such assurance. To quantify confidence in black-box LLMs, we employ a method based on semantic consistency\nassessment. Drawing inspiration from Semantic Entropy (SE) (Farquhar et al., 2024), which measures uncertainty via\nthe entropy of semantically clustered outputs, we introduce the Maximum Semantic Cluster Proportion (MSCP) as\na straightforward and efficient confidence metric for black-box LLMs. This metric leverages the inherent semantic\ncomprehension of LLMs to evaluate agreement across multiple generated outputs, serving as a reliable indicator of\nrelevance in retrieval-augmented generation (RAG) systems.\nLet ğœ™denote the parameters of a pre-trained LLM, treated as a black-box system accessible solely through input-\noutput interactions. For a given input ğ‘¥(e.g., a query or query-document pair), the LLM ğœ™produces outputs by sampling\nfrom its predictive distribution. To assess confidence, we apply multinomial sampling at temperature ğ‘‡= 1 to generate\nğ¾independent output sequences, denoted as {ğ‘¡ğ‘˜}ğ¾\nğ‘˜=1, where each ğ‘¡ğ‘˜is autoregressively sampled as follows:\nğ‘¡ğ‘˜âˆ¼ğ‘ğœ™(â‹…âˆ£ğ‘¥),\nwith ğ‘ğœ™(ğ‘¡âˆ£ğ‘¥) representing the probability distribution over sequences induced by the LLM ğœ™.\nThese ğ¾sequences are clustered according to semantic equivalence, forming a partition of semantically similar\noutputs. Clustering utilizes the same LLM ğœ™to assess pairwise semantic relations, ensuring alignment within the\nmodelâ€™s semantic space without external dependencies. For each pair of sequences (ğ‘¡ğ‘–, ğ‘¡ğ‘—) where ğ‘–â‰ ğ‘—, ğ‘¡ğ‘–âˆ¼ğ‘ğœ™(â‹…âˆ£ğ‘¥),\nand ğ‘¡ğ‘—âˆ¼ğ‘ğœ™(â‹…âˆ£ğ‘¥), we prompt the LLM ğœ™with a natural language inference (NLI)-style query to classify their semantic\nrelation. This is formalized by a function ğ‘“ğœ™(ğ‘¡ğ‘–, ğ‘¡ğ‘—) that outputs one of: â€œentailmentâ€, â€œcontradictionâ€, or â€œneutralâ€,\nindicating whether ğ‘¡ğ‘–semantically entails ğ‘¡ğ‘—.\nThis pairwise assessment constructs an undirected similarity graph ğº= (ğ‘‰, ğ¸), where the vertices ğ‘‰= {ğ‘¡ğ‘˜}ğ¾\nğ‘˜=1\ncomprise the sampled sequences, and an edge (ğ‘¡ğ‘–, ğ‘¡ğ‘—) âˆˆğ¸exists if and only if bidirectional entailment holds:\n(ğ‘¡ğ‘–, ğ‘¡ğ‘—) âˆˆğ¸âŸºğ‘“ğœ™(ğ‘¡ğ‘–, ğ‘¡ğ‘—) = â€œentailmentâ€ âˆ§ğ‘“ğœ™(ğ‘¡ğ‘—, ğ‘¡ğ‘–) = â€œentailmentâ€.\nThe connected subgraphs in graph ğºare defined as node subsets where a pathâ€”a sequence of edgesâ€”exists\nbetween every pair of nodes, and no additional nodes can be included while preserving this connectivity. Such maximal\nsubgraphs form the connected components of ğº, partitioning the graph into disjoint sets that represent distinct semantic\nequivalence classes. These classes aggregate responses sharing the same underlying meaning, with bidirectional\nentailment ensuring transitivity and symmetry within each component, thus propagating equivalence across connected\nnodes.\nDirect computation of these connected components via a complete graph and standard algorithms (e.g., depth-first\nsearch or union-find) can be computationally demanding for large ğ¾, requiring îˆ»(ğ¾2) pairwise entailment evaluations.\nTo address this, we adopt a greedy clustering algorithm that approximates the graph structure without materializing\nall edges. The algorithm initializes an empty cluster set ğ‘†= âˆ…. For each sample ğ‘¡ğ‘–(processed sequentially from ğ‘–= 1\nto ğ¾):\nâ€¢ Assess whether ğ‘¡ğ‘–can be assigned to an existing cluster ğ‘ âˆˆğ‘†. For each such cluster ğ‘ , select a representative\nresponse ğ‘¡(ğ‘ ) from ğ‘ , such as the initial sample added or an embedding-derived centroid for efficiency.\nâ€¢ If ğ‘“ğœ™(ğ‘¡ğ‘–, ğ‘¡(ğ‘ )) = â€œentailmentâ€ âˆ§ğ‘“ğœ™(ğ‘¡(ğ‘ ), ğ‘¡ğ‘–) = â€œentailmentâ€, incorporate ğ‘¡ğ‘–into ğ‘ .\nâ€¢ If ğ‘¡ğ‘–aligns with no existing cluster, initialize a new cluster {ğ‘¡ğ‘–} and append it to ğ‘†.\nThis greedy approach efficiently identifies connected components by iteratively merging samples based on\nentailment links, ensuring each resulting cluster corresponds to a maximal connected subgraph where all responses\nare semantically equivalent via transitive entailment paths. The algorithm reduces NLI evaluations (via LLM ğœ™) to\nîˆ»(ğ¾â‹…ğ‘€), where ğ‘€is the number of clusters (typically much smaller than ğ¾), rendering it suitable for practical\ndeployment. The final semantic equivalence classes are {ğ‘ 1, ğ‘ 2, â€¦ , ğ‘ ğ‘€}, with ğ‘€denoting the number of distinct\nmeanings identified, and cluster sizes satisfying âˆ‘ğ‘€\nğ‘š=1 |ğ‘ ğ‘š| = ğ¾, as each sample is assigned to exactly one class.\nFollowing cluster formation, MSCP is formally defined as:\nğ¶(ğ‘¥) = MSCP(ğ‘¥; ğœ™, ğ¾) =\nmax\nğ‘š=1,â€¦,ğ‘€\n|ğ‘ ğ‘š|\nğ¾,\n(1)\nSong et al.: Preprint submitted to Elsevier\nPage 6 of 21\n"}, {"page": 7, "text": "LLM-Confidence Reranker\nwhere |ğ‘ ğ‘š| is the cardinality of the ğ‘š-th cluster.\nThis metric quantifies confidence as the proportion of samples in the largest semantic cluster, with values near 1\nindicating high semantic consistency and elevated confidence, and lower values reflecting greater dispersion across\nclusters, signifying uncertainty. Compared to SE, which computes entropy over all cluster proportions and may be\nsensitive to minor distributional variations, MSCP offers a more direct and interpretable measure by focusing solely\non the dominant semantic mode. This simplicity facilitates faster computation and aligns well with reranking objectives\nin RAG systems, where prioritizing documents that elicit strongly consistent responses is essential.\nBy employing the same LLM for sampling and clustering, MSCP ensures internal consistency, reducing discrep-\nancies from model mismatches and enhancing its utility in black-box scenarios. Empirical evaluations, detailed in\nsubsequent sections, confirm that MSCP captures confidence signals correlated with document relevance, supporting\nthe LCR algorithmâ€™s ranking improvements.\nSemantic Clustering\nResponses\nFrequency\nQuery\nâ€œWho is the \nPresident of \nthe U.S.?â€\nLLM\nTrump.\nDonald Trump.\nDonald Trump served as president. \nThe U.S. President is elected.\n1\n5\nPresident Biden leads the nation.\nLLM\n+\nQuery\nâ€œWho is the \nPresident of \nthe U.S.?â€\nDoc\nâ€œTrump was sworn in as \nthe 47th U.S. President \non Jan. 20. 2025.â€\nLLM\nDonald Trump served as president. \nThe president is not Trump.\nThe President of the U.S. is not Musk.\nMusk is not the president.\nJoe Biden.\n+\nQuery\nâ€œWho is the \nPresident of \nthe U.S.?â€\nDoc\nâ€œElon Musk becomes the \n47th President of the \nUnited States.â€\nTrump sworn in as 47th president.\nDonald Trump.\nTrump.\nDonald Trump leads the U.S. as President.\nDonald Trump served as president. \n3\n5\n1\n5\n1\n5\n5\n5\n1\n5\n2\n5\n1\n5\n1\n5\nFigure 2: Illustration of Maximum Semantic Cluster Proportion. As illustrated in the figure, the question ğ‘is â€œWho is the\nPresident of the U.S.?â€ We instruct a specific LLM with parameters ğœ™to sample ğ¾times (where ğ¾= 5 in this example)\nat a high temperature (typically ğ‘‡= 1). Through clustering, three semantic clusters are derived, with the largest semantic\ncluster being â€œTrumpâ€, which accounts for 3âˆ•5 of the responses, denoted as MSCP(ğ‘; ğœ™, ğ¾) = 3âˆ•5. When we provide both\nthe question ğ‘and the document ğ‘‘1, which states, â€œTrump was sworn in as the 47th U.S. President on Jan. 20. 2025â€,\nall five sampled responses consistently point to â€œTrumpâ€, resulting in MSCP(ğ‘, ğ‘‘1; ğœ™, ğ¾) = 5âˆ•5. Compared to the scenario\nwhere only ğ‘is provided, the MSCP increases, indicating that ğ‘‘1 is a helpful document for ğ‘. In contrast, when we supply\nboth the question ğ‘and the document ğ‘‘2, which claims, â€œElon Musk becomes the 47th President of the United Statesâ€,\nthe largest semantic cluster after sampling and clustering only constitutes 2âˆ•5, denoted as MSCP(ğ‘, ğ‘‘2; ğœ™, ğ¾) = 2âˆ•5. This\nrepresents a decrease in MSCP compared to when only ğ‘is provided, suggesting that ğ‘‘2 is a harmful document for ğ‘.\n3.2. LLM-Confidence Reranker Algorithm\nThe LLM-Confidence Reranker (LCR) algorithm enhances document ranking via confidence interval binning\nand multi-level sorting. It defines a query confidence threshold ğ‘‡query, a high confidence threshold ğ‘‡upper, and a low\nconfidence threshold ğ‘‡lower, with its core process detailed in Algorithm 1 and Figure 1. In the algorithm, confidence for\ndocuments and queries is denoted by ğ¶(â‹…), prior relevance scores (e.g., from a retriever or reranker) by ğ‘ƒğ‘Ÿğ‘’ğ‘£ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’(â‹…),\nand the document set by îˆ°= {ğ‘‘ğ‘–}ğ‘›\nğ‘–=1.\nThe algorithm operates through two integrated stages:\nSong et al.: Preprint submitted to Elsevier\nPage 7 of 21\n"}, {"page": 8, "text": "LLM-Confidence Reranker\nAlgorithm 1 The LLM-Confidence Reranker Algorithm\n1: function BINNEDCONFIDENCESCORE(ğ‘, ğ‘‘)\n2:\nif ğ¶(ğ‘, ğ‘‘) â‰¥ğ‘‡upper then\n3:\nreturn 1\nâŠ³High confidence bin\n4:\nelse if ğ¶(ğ‘, ğ‘‘) â‰¤ğ‘‡lower then\n5:\nreturn -1\nâŠ³Low confidence bin\n6:\nelse\n7:\nreturn 0\nâŠ³Medium confidence bin\n8:\nend if\n9: end function\n10: function LCR_SORT(ğ‘, îˆ°)\n11:\nGenerate joint features {(ğ‘, ğ‘‘)}ğ‘‘âˆˆîˆ°\n12:\nif ğ¶(ğ‘) < ğ‘‡query then\n13:\nîˆ°â€² â†StableSort(îˆ°, [ğµğ‘–ğ‘›ğ‘›ğ‘’ğ‘‘ğ¶ğ‘œğ‘›ğ‘“ğ‘–ğ‘‘ğ‘’ğ‘›ğ‘ğ‘’ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’(ğ‘, ğ‘‘) â†“, ğ‘ƒğ‘Ÿğ‘’ğ‘£ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’(ğ‘, ğ‘‘) â†“])\n14:\nelse\n15:\nîˆ°â€² â†Sort(îˆ°, ğ‘ƒğ‘Ÿğ‘’ğ‘£ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’(ğ‘, ğ‘‘) â†“)\n16:\nend if\n17:\nreturn îˆ°â€²\n18: end function\n1. Confidence Assessment and Binning: It first computes the query confidence ğ¶(ğ‘) and compares it to ğ‘‡query.\nConcurrently, it calculates joint confidence scores ğ¶(ğ‘, ğ‘‘) for each document ğ‘‘in îˆ°. Documents are then\ncategorized into three bins using ğ‘‡upper and ğ‘‡lower:\nâ€¢ High confidence: if ğ¶(ğ‘, ğ‘‘) â‰¥ğ‘‡upper\nâ€¢ Medium confidence: if ğ‘‡lower < ğ¶(ğ‘, ğ‘‘) < ğ‘‡upper\nâ€¢ Low confidence: if ğ¶(ğ‘, ğ‘‘) â‰¤ğ‘‡lower\n2. Ranking Strategy: If ğ¶(ğ‘) < ğ‘‡query (low confidence), documents are sorted first by confidence bins in\ndescending order (high â†’medium â†’low), then by ğ‘ƒğ‘Ÿğ‘’ğ‘£ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’(ğ‘, ğ‘‘) within each bin. If ğ¶(ğ‘) â‰¥ğ‘‡query (high\nconfidence), documents are sorted directly by ğ‘ƒğ‘Ÿğ‘’ğ‘£ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’(ğ‘, ğ‘‘) in descending order.\nBy discretizing confidence into three intervals, LCR reduces noise and sharpens distinctions between documents.\n4. Evaluation and Discussion\nThis section provides a thorough evaluation of the LLM-Confidence Reranker (LCR) algorithm, assessing its\nperformance, robustness, and underlying mechanisms. We start with the experimental setup in Â§4.1, outlining the\ndatasets, retrievers, rerankers, confidence quantification methods, and evaluation metrics employed. Â§ 4.2 then presents\nthe primary experimental results, comparing NDCG@5 scores across different configurations with BM25 as the\ninitial retriever. The subsequent subsection analyzes the impact of different retrievers, incorporating Contriever\nto evaluate compatibility. Additional analyses examine the effects of the query threshold, sensitivity to document\nthresholds, variations in language models, and different confidence quantification approaches. Finally, we investigate\nthe underlying mechanism of the LCR algorithm, as detailed in Â§4.8.\n4.1. Experiment Setup\n4.1.1. Datasets\nWe evaluate our approach on datasets from two prominent information retrieval benchmarks: BEIR (Thakur et\nal., 2021) and TREC (Voorhees & Harman, 2005). BEIR (Benchmarking IR) is a heterogeneous zero-shot evaluation\nbenchmark comprising datasets across diverse domains, designed to assess the generalization of retrieval models in out-\nof-domain settings. TREC (Text REtrieval Conference) is an annual series organized by NIST, providing standardized\ntasks and judgments for advancing retrieval research; we specifically use the Deep Learning tracks from 2019 and\n2020, which focus on passage ranking with graded relevance annotations. From BEIR, we select six datasets spanning\nSong et al.: Preprint submitted to Elsevier\nPage 8 of 21\n"}, {"page": 9, "text": "LLM-Confidence Reranker\nTable 1\nComparison of Reranking Methods.\nReranker\nRequires Internal Param.\nBase Model\nArchitecture Type\nFine-tuned\nLCR (ours)\nNo\nQwen7B\nDecoder-Only\nNo\nQLM\nYes\nQwen7B\nDecoder-Only\nNo\nRankGPT\nNo\nQwen7B\nDecoder-Only\nNo\nYesNo\nYes\nQwen7B\nDecoder-Only\nNo\nCross-Encoder\nNo\nBERT-base\nEncoder-Only\nYes\nColBERT\nNo\nBERT-base\nEncoder-Only\nYes\nRankT5\nNo\nT5-base\nEncoder-Decoder\nYes\nvarious query types and relevance challenges, ideal for testing real-world retrieval performance in knowledge-intensive\ntasks:\nâ€¢ NaturalQuestions (NQ) (Kwiatkowski et al., 2019): An open-domain question-answering dataset with real user\nqueries from Google search, annotated with answers from Wikipedia passages.\nâ€¢ DBpedia-Entity (DBPE) (Hasibi et al., 2017): An entity-centric retrieval dataset emphasizing entity linking and\nknowledge graph queries, with relevance based on DBpedia entity relationships.\nâ€¢ FEVER (FEVE) (Thorne et al., 2018): A fact verification dataset where queries are claims verified against\nWikipedia documents; relevance labels denote support, refutation, or neutrality.\nâ€¢ SciDocs (SCID) (Cohan et al., 2020): A citation prediction dataset using scientific paper abstracts as queries,\nwith relevance determined by citation links.\nâ€¢ TouchÃ© (TOUC) (Bondarenko et al., 2020): An argument retrieval dataset featuring debate topics as queries,\nwith relevance tied to supporting or opposing arguments in web documents.\nâ€¢ NFCorpus (NFCO) (Boteva et al., 2016): A biomedical information retrieval dataset with medical queries and\nscientific articles, where expert-assigned labels indicate document relevance.\nFrom TREC, we incorporate two datasets:\nâ€¢ TREC DL19 (DL19) (Craswell et al., 2020): Passage ranking task from TREC 2019 Deep Learning track, with\nqueries and graded relevance judgments on a large corpus.\nâ€¢ TREC DL20 (DL20) (Craswell et al., 2021): Similar to DL19 but from the 2020 track, emphasizing neural\nretrieval methods with diverse query-document pairs.\nWe utilize the test sets and relevance annotations provided by these benchmarks.\n4.1.2. Retrievers and Rerankers\nWe employ BM25 (Jones et al., 2000) as a classic sparse retriever based on term frequency and inverse document\nfrequency, and Contriever (Izacard et al., 2022) as a dense retriever enhanced by contrastive learning. These\nretrievers are selected to evaluate LCRâ€™s compatibility across both sparse and dense retrieval paradigms, ensuring\na comprehensive assessment of its plug-and-play nature in diverse RAG settings.\nFor rerankers, we select a diverse set including pre-trained LLM-based and fine-tuned Transformer-based methods\nto benchmark LCRâ€™s performance, as summarized in Table 1. These rerankers are:\nâ€¢ QLM (Sachan et al., 2022): A point-wise reranking approach that prompts pre-trained language models to\ngenerate a relevant query for each candidate document, then ranks based on the likelihood of the actual query,\nwithout fine-tuning.\nSong et al.: Preprint submitted to Elsevier\nPage 9 of 21\n"}, {"page": 10, "text": "LLM-Confidence Reranker\nâ€¢ RankGPT (Sun et al., 2023): A generative list-wise reranking method that prompts pre-trained language models\nto output a ranked list of document labels by relevance, using sliding windows, without fine-tuning.\nâ€¢ YesNo (Qin et al., 2024): A point-wise reranking technique that prompts pre-trained language models to generate\nâ€œyesâ€ or â€œnoâ€ indicating document relevance to the query, then ranks based on normalized â€œyesâ€ likelihood,\nwithout fine-tuning.\nâ€¢ Cross-Encoder (Reimers & Gurevych, 2019): A cross-encoder method that computes relevance scores from\njoint query-document representations.\nâ€¢ ColBERT (Khattab & Zaharia, 2020): A context embedding-based reranking model that enhances precision\nthrough token-level interactions.\nâ€¢ RankT5 (Zhuang et al., 2023): A Transformer-based sequence-to-sequence model designed for reranking tasks.\nThese rerankers are chosen to compare LCRâ€”a training-free, confidence-based methodâ€”against both similar pre-\ntrained LLM-based approaches (e.g., QLM, RankGPT, YesNo) that underutilize semantic understanding, and fine-\ntuned Transformer models that represent optimized, domain-specific baselines, thereby highlighting LCRâ€™s advantages\nin generalization and efficiency.\nFor each query, the retriever fetches top-10 documents, reranked by the specified method, including LCR. For\nLLM-based rerankers, we use Qwen2.5-7B-Instruct (Qwen7B) (A. Yang et al., 2024). We employ MSCP, as detailed\nin Equation 1, for confidence quantification.\n4.1.3. Confidence Quantification Setup\nMultinomial sampling (ğ‘‡= 1) generates ğ¾= 10 samples per query-document pair. Sampling prompts:\nâ€¢ Without document:\nAnswer the following question as briefly as possible.\nQuestion: {query}\nAnswer:\nâ€¢ With document:\nAnswer the following question as briefly as possible.\nContext: {document}\nQuestion: {query}\nAnswer:\nClustering evaluates semantic relationships:\nWe are evaluating answers to the question â€œ{query}â€\nPossible Answer 1: {answer1}\nPossible Answer 2: {answer2}\nDoes Possible Answer 1 semantically entail Possible Answer 2? Respond with only one of the following words:\nentailment, contradiction, or neutral. Do not provide any additional explanation.\nResponse:\n4.1.4. Evaluation Metrics\nWe use Normalized Discounted Cumulative Gain (NDCG) (JÃ¤rvelin & KekÃ¤lÃ¤inen, 2002) at ğ‘˜= 5 as the primary\nmetric, prioritizing relevant documents early for RAG systems.\nNDCG@k evaluates ranking quality by accounting for document relevance and position. It is computed as\nDiscounted Cumulative Gain (DCG) up to position ğ‘˜, normalized by the Ideal DCG (IDCG) for the optimal ranking:\nNDCG@k = DCG@k\nIDCG@k,\nDCG@k =\nğ‘˜\nâˆ‘\nğ‘–=1\nrelğ‘–\nlog2(ğ‘–+ 1),\nSong et al.: Preprint submitted to Elsevier\nPage 10 of 21\n"}, {"page": 11, "text": "LLM-Confidence Reranker\nwhere relğ‘–denotes the relevance of the document at position ğ‘–. Higher NDCG@k values indicate superior performance,\nprioritizing relevant documents early.\n4.2. Experiment Results\nTable 2 presents the NDCG@5 performance comparison when using BM25 as the initial retriever, combined\nwith various rerankers, and further enhanced by LCR across datasets. As a plug-and-play algorithm based on LLM\nconfidence signals, LCR ensures a safe performance lower bound: when the query confidence threshold ğ‘‡query = 0,\nthe algorithm reverts to the original ranking, maintaining performance at least at the baseline level in the worst case.\nThis design provides high robustness for LCR in practical deployment, avoiding potential risks. The values in the table\nrepresent the best performance after tuning the three hyperparameters (ğ‘‡query, ğ‘‡upper, ğ‘‡lower), aimed at demonstrating\nLCRâ€™s upper potential; subsequent sensitivity analysis in Sections 4.4 and 4.5 will further validate its generalization\nability.\nThe improvements from LCR exhibit high consistency: across all reranker and dataset combinations, adding LCR\nresults in NDCG@5 gains or ties, with no instances of decline. This arises from LCRâ€™s core mechanism: through\nconfidence binning, it prioritizes high-confidence documents at the top, while retaining the original ranking when query\nconfidence is high to avoid unnecessary interference. The averages across BEIR and TREC datasets indicate relative\ngains of up to 20.6% (e.g., YesNo on BEIR: 0.1737 to 0.2095) from LCR, with no declines. This stable enhancement\nconfirms the hypothesis that LLM confidence correlates positively with document relevance (detailed in Section 4.8).\nFrom the perspective of dataset heterogeneity, LCRâ€™s gains are particularly notable on factual or argumentative\ndatasets (e.g., NaturalQuestions, TouchÃ©, FEVER), such as RankGPT on NaturalQuestions improving from 0.0489\nto 0.0587 (a 20% relative increase). This reflects that such queries heavily rely on semantic consistency from\nexternal documents, where LCRâ€™s confidence signals effectively amplify relevance differences. On domain-specific\ndatasets with already high baseline performance (e.g., FEVER + fine-tuned Transformer-based rerankers), LCR\nmaintains stability without degradation, demonstrating its adaptability. For TREC datasets (DL19 and DL20), LCRâ€™s\nimprovements are equally reliable, for instance, from 0.5172 to 0.5271 (a 1.9% relative increase) when applying LCR\ndirectly without any reranker. The document diversity and long-tail query characteristics of TREC datasets further\nhighlight LCRâ€™s generalization advantage in handling complex retrieval scenarios.\nBreaking down by reranker type reveals LCRâ€™s strong compatibility. First, in the pure BM25 Retriever-Only\nscenario, LCR yields average gains of 3.0% (BEIR) and 1.9% (TREC), with slight optimizations across all datasets,\nproving it can independently improve sparse retrieval results without relying on additional rerankers. This makes it\nespecially suitable for resource-constrained settings. Second, for pre-trained LLM-based rerankers (YesNo, QLM,\nRankGPT, using 7B-parameter models), baseline performance is often below or close to Retriever-Only (BEIR average\n0.1737â€“0.2391), reflecting limitations in ranking ability for small-scale models; however, LCR significantly reverses\nthis disadvantage, such as a 20.6% average gain on BEIR for YesNo. This suggests that even with limited model scale,\nthe core semantic understanding can capture document â€œhelpfulnessâ€ through confidence signals, thereby amplifying\nranking effects. Finally, for fine-tuned Transformer-based rerankers (ColBERT, Cross-Encoder, RankT5), LCRâ€™s gains\nare smaller (about 1%), but highly consistent. This verifies LCRâ€™s good compatibility with domain-specific training,\nallowing further refinement of document relevance on high-performance baselines.\nIn summary, as a training-free and lightweight (7B-parameter) algorithm, LCR reliably enhances document\nrelevance in RAG systems, with an average gain of about 3% across methods and datasets, thereby reducing\nhallucination risks. Its lower-bound guarantee and plug-and-play nature make it particularly suitable for production-\nlevel knowledge-intensive tasks.\n4.3. Impact of Different Retrievers\nTo assess LCRâ€™s compatibility with diverse retrievers, we employ Contriever (Izacard et al., 2022) as an additional\ninitial retriever, which leverages contrastive learning to improve dense retrieval. Table 3 presents the NDCG@5 scores\nfor Contriever combined with various rerankers, both with and without LCR enhancement (where â€œ+LCR w/o QTâ€\ndenotes LCR applied without the query threshold, and â€œ+LCRâ€ includes the query threshold; the impact of QT is\ndiscussed in Â§4.4).\nThe results indicate that LCR delivers consistent improvements over the Contriever baseline: across all reranker-\ndataset combinations, LCR achieves NDCG@5 gains or maintains equivalence, with no degradation. LCR achieves\nrelative gains of up to 32.4% on BEIR and TREC datasets, e.g., from 0.2281 to 0.3021 in the YesNo group (BEIR).\nRelative to BM25, Contriever exhibits a stronger baseline (BEIR average: 0.3939 vs. 0.2392); nevertheless, LCRâ€™s\nSong et al.: Preprint submitted to Elsevier\nPage 11 of 21\n"}, {"page": 12, "text": "LLM-Confidence Reranker\nTable 2\nComparative Performance of BM25 with Various Rerankers and LCR Enhancement. NDCG@5 scores for the BM25\nretriever combined with various rerankers, with and without the LCR (LLM-Confidence Reranker) enhancement, across\nBEIR datasets (NQ: NaturalQuestions, TOUC: TouchÃ©, SCID: SciDocs, NFCO: NFCorpus, DBPE: DBpedia-Entity, FEVE:\nFEVER, AVG: average across BEIR datasets) and TREC datasets (DL19, DL20, AVG: average across TREC datasets).\nBold values indicate the best performance within each reranker group, and underlined values indicate the best performance\nbetween the same reranker with and without LCR.\nBEIR\nTREC\nMethod\nNQ\nTOUC\nSCID\nNFCO\nDBPE\nFEVE\nAVG\nDL19\nDL20\nAVG\nRetriever-Only\n-\n.0488\n.4911\n.1144\n.3640\n.1059\n.3111\n.2392\n.5278\n.5067\n.5172\n+LCR\n.0585\n.5015\n.1149\n.3659\n.1078\n.3294\n.2463\n.5431\n.5112\n.5271\nPre-trained LLM Based Rerankers\nYesNo\n.0321\n.4388\n.0685\n.2941\n.0777\n.1310\n.1737\n.5925\n.5485\n.5705\n+LCR\n.0516\n.4600\n.0872\n.3087\n.0912\n.2581\n.2095\n.5974\n.5515\n.5744\nQLM\n.0610\n.4090\n.1215\n.3415\n.1003\n.3595\n.2321\n.5341\n.4815\n.5078\n+LCR\n.0630\n.4456\n.1228\n.3427\n.1037\n.3608\n.2397\n.5563\n.4898\n.5230\nRankGPT\n.0489\n.4914\n.1144\n.3630\n.1058\n.3111\n.2391\n.5278\n.5067\n.5172\n+LCR\n.0587\n.5018\n.1149\n.3649\n.1078\n.3295\n.2463\n.5431\n.5103\n.5267\nFine-tuned Transformer Based Rerankers\nColBERT\n.0791\n.4778\n.1204\n.3832\n.1410\n.4745\n.2793\n.6377\n.6074\n.6226\n+LCR\n.0805\n.4936\n.1205\n.3839\n.1413\n.4745\n.2824\n.6377\n.6074\n.6226\nCross-Encoder\n.0812\n.4664\n.1266\n.3921\n.1465\n.4779\n.2818\n.6508\n.5983\n.6245\n+LCR\n.0817\n.4972\n.1266\n.3936\n.1467\n.4779\n.2873\n.6508\n.5986\n.6247\nRankT5\n.0831\n.5165\n.1376\n.4041\n.1479\n.4864\n.2959\n.6548\n.6065\n.6306\n+LCR\n.0839\n.5322\n.1378\n.4049\n.1482\n.4864\n.2989\n.6548\n.6078\n.6313\nadvantages are more pronounced for weaker rerankers such as YesNo, underscoring its capacity to amplify semantic\nsignals and mitigate biases in dense retrieval.\nAnalysis across datasets reveals amplified gains on factual-oriented tasks (e.g., NQ, FEVER), as evidenced by\nRankGPT on NQ (1.1% relative gain), which highlights the efficacy of confidence binning in elevating document\nrelevance. On datasets with high baselines, such as FEVER, LCR preserves stability without excessive intervention.\nIn conclusion, LCR performs robustly with both BM25 and Contriever, yielding an average 3.6% gain and confirming\nits plug-and-play adaptability across sparse and dense retrieval paradigms.\n4.4. Impact of Query Threshold\nTo assess the impact of the query threshold (QT) on LCR performance, we first examine the results in Table 3,\nwhich contrasts â€œ+LCR w/o QTâ€ and â€œ+LCRâ€ (with QT) across rerankers using Contriever as the retriever. On average,\nâ€œ+LCRâ€ achieves higher scores on both BEIR and TREC (e.g., 0.3998 vs. 0.3962 for Retriever-Only on BEIR, 0.5845\nvs. 0.5842 on TREC). These patterns indicate that QT further enhances LCRâ€™s ranking performance across various\nrerankers. Specifically, when the LLM exhibits low confidence in a query, indicating limited internal knowledge of\nthe answer, it can more effectively distinguish helpful documents, leading to stronger confidence signals and greater\ngains from LCR. Conversely, high query confidence suggests the LLM already knows the answer, resulting in weaker\nsignals for document helpfulness differentiation. Thus, QT enables selective application of LCR to queries where it\nprovides the most benefit.\nSong et al.: Preprint submitted to Elsevier\nPage 12 of 21\n"}, {"page": 13, "text": "LLM-Confidence Reranker\nTable 3\nComparative Performance of Contriever with Various Rerankers and LCR Enhancement. NDCG@5 scores for the\nContriever retriever combined with various rerankers, with and without LCR enhancement, across datasets (as defined in\nTable 2). Here, â€œ+LCR w/o QTâ€ denotes LCR without the query threshold, and â€œ+LCRâ€ includes it. Bold and underlined\nvalues follow the conventions in Table 2, with AVG denoting the average across datasets.\nBEIR\nTREC\nMethod\nNQ\nTOUC\nSCID\nNFCO\nDBPE\nFEVE\nAVG\nDL19\nDL20\nAVG\nRetriever-Only\n-\n.4554\n.2612\n.1180\n.3580\n.4285\n.7425\n.3939\n.6858\n.4575\n.5717\n+LCR w/o QT\n.4607\n.2675\n.1185\n.3580\n.4294\n.7431\n.3962\n.6974\n.4710\n.5842\n+LCR\n.4607\n.2804\n.1195\n.3589\n.4364\n.7431\n.3998\n.6979\n.4710\n.5845\nPre-trained LLM Based Rerankers\nYesNo\n.2312\n.2476\n.0778\n.2645\n.2928\n.2546\n.2281\n.6990\n.5285\n.6137\n+LCR w/o QT\n.3515\n.2577\n.0937\n.2882\n.3512\n.4689\n.3019\n.7088\n.5317\n.6202\n+LCR\n.3515\n.2590\n.0937\n.2882\n.3512\n.4689\n.3021\n.7089\n.5373\n.6231\nQLM\n.3486\n.2269\n.1218\n.3143\n.3314\n.5569\n.3166\n.6577\n.4460\n.5519\n+LCR w/o QT\n.3985\n.2599\n.1224\n.3143\n.3708\n.5871\n.3422\n.6821\n.4783\n.5802\n+LCR\n.3985\n.2599\n.1224\n.3153\n.3708\n.5871\n.3423\n.6848\n.4783\n.5815\nRankGPT\n.4563\n.2612\n.1180\n.3569\n.4286\n.7427\n.3939\n.6858\n.4575\n.5717\n+LCR w/o QT\n.4613\n.2675\n.1185\n.3569\n.4295\n.7432\n.3962\n.6974\n.4710\n.5842\n+LCR\n.4613\n.2804\n.1195\n.3579\n.4366\n.7432\n.3998\n.6979\n.4710\n.5845\nFine-tuned Transformer Based Rerankers\nColBERT\n.4778\n.3570\n.1247\n.3574\n.4376\n.7617\n.4194\n.7193\n.6030\n.6612\n+LCR w/o QT\n.4775\n.3570\n.1249\n.3574\n.4375\n.7619\n.4193\n.7278\n.6030\n.6654\n+LCR\n.4808\n.3651\n.1254\n.3579\n.4376\n.7619\n.4214\n.7347\n.6039\n.6693\nCross-Encoder\n.4870\n.3172\n.1306\n.3659\n.4595\n.7846\n.4241\n.7296\n.6089\n.6692\n+LCR w/o QT\n.4867\n.3172\n.1308\n.3659\n.4599\n.7846\n.4242\n.7373\n.6101\n.6737\n+LCR\n.4893\n.3244\n.1312\n.3665\n.4599\n.7846\n.4260\n.7445\n.6129\n.6787\nRankT5\n.5097\n.3592\n.1391\n.3769\n.4679\n.8156\n.4447\n.7166\n.6103\n.6634\n+LCR w/o QT\n.5096\n.3578\n.1389\n.3757\n.4682\n.8156\n.4443\n.7286\n.6115\n.6700\n+LCR\n.5106\n.3615\n.1391\n.3782\n.4682\n.8156\n.4455\n.7336\n.6130\n.6733\nWe further evaluate QTâ€™s influence on the NaturalQuestions dataset using BM25 as the retriever, with rerankers\nincluding Retriever-Only, RankGPT, Cross-Encoder, and RankT5. Figure 3 shows NDCG@5 scores for QT values from\n0.1 to 1.0, with QT=0 as the baseline (no LCR). For Retriever-Only and RankGPT, which rely on pre-trained LLMs and\nhave weaker baselines, NDCG@5 rises progressively with QT, peaking at QT=1.0, as higher QT applies LCR to more\nqueries for amplified gains. In contrast, RankT5 and Cross-Encoder, as fine-tuned rerankers with stronger baselines,\nexhibit an initial increase followed by a slight decline, requiring only slight QT adjustments. This suggests that higher\nQT benefits simpler rerankers by broadening confidence utilization, while advanced rerankers need minimal tuning to\navoid unnecessary interference. Overall, optimal QT selection can significantly improve ranking in RAG systems.\n4.5. Sensitivity Analysis of Document Thresholds\nTo assess the sensitivity of the document thresholds in the LCR algorithm, we employed the BM25 retriever\ncombined with the RankGPT reranker, without the query threshold, and produced a heatmap illustrating NDCG@5\nimprovement percentages as a function of the lower threshold (LT) and upper threshold (UT). As shown in Figure 4,\nranking performance exhibits consistent enhancements across valid combinations of LT (0.1 to 0.9) and UT (0.2\nto 1.0). Improvements intensify with higher UT values, peaking at UT=0.9. Gains are relatively modest when LT\nSong et al.: Preprint submitted to Elsevier\nPage 13 of 21\n"}, {"page": 14, "text": "LLM-Confidence Reranker\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nQuery Threshold\n0.049\n0.050\n0.051\n0.052\n0.053\n0.054\n0.055\n0.056\n0.057\nNDCG@5\nw/o LCR (QT=0)\n(a) Retriever-Only\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nQuery Threshold\n0.050\n0.052\n0.054\n0.056\nNDCG@5\nw/o LCR (QT=0)\n(b) RankGPT\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nQuery Threshold\n0.0831\n0.0832\n0.0833\n0.0834\n0.0835\n0.0836\n0.0837\n0.0838\nNDCG@5\nw/o LCR (QT=0)\n(c) RankT5\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nQuery Threshold\n0.0812\n0.0813\n0.0814\n0.0815\n0.0816\nNDCG@5\nw/o LCR (QT=0)\n(d) Cross-Encoder\nFigure 3: Query Threshold Impact on NDCG@5 for NaturalQuestions with BM25 Retriever. These plots illustrate the\nimpact of varying query threshold (QT) values on performance for different rerankers. The red dashed line indicates the\nbaseline without LCR (QT=0).\nranges from 0.5 to 0.7. Based on the heatmap, optimal configurations involve a high UT (âˆ¼0.9) coupled with a low\nLT (âˆ¼0.1â€“0.4). This approach enforces rigorous categorization: high-confidence documents advance to the top only\nunder exceptionally strong confidence, low-confidence documents descend to the bottom only when confidence is\nnotably weak, and medium-confidence cases preserve their initial positions amid uncertainty, thereby maximizing\noverall ranking effectiveness.\n4.6. Impact of Different Language Models\nTo evaluate the effect of various large language models (LLMs) on the performance of the LCR algorithm, we tested\nfour lightweight pre-trained models: Qwen2.5-7B-Instruct (Qwen7B) (A. Yang et al., 2024), Llama3.1-8B-Instruct\n(Llama8B) (Dubey et al., 2024), GLM-4-9B-Chat (GLMChat9B) (Zeng et al., 2024), and InternLM2.5-7B-Chat\n(InternLM7B) (Cai et al., 2024). These models were selected due to their parameter sizes ranging from 7 to 9 billion,\nrepresenting diverse architectures and training corpora, which allows us to assess the generalizability of LCR across\ndifferent LLM families. We employed the MSCP method for confidence quantification. Experiments were conducted\non the NaturalQuestions dataset, employing BM25 and Contriever as retrievers, consistent with the main experimental\nsetup. As shown in Figure 5, InternLM7B yields the highest NDCG@5 improvements across all configurations, such\nas 24.5% for BM25 + RankGPT and 9.6% for Contriever + RankGPT. GLMChat9B follows closely, while Qwen7B\nshows the least gains. These results indicate that model selection substantially influences confidence signal quality, with\nInternLM7B providing the strongest semantic understanding for reranking enhancement. Notably, all tested 7â€“9B-scale\nmodels consistently yield performance improvements, demonstrating that LCR is robust and generalizes well across\nspecific model choices.\n4.7. Impact of Different Confidence Quantification Methods\nTo examine the effects of diverse confidence quantification approaches on the LCR algorithm, we performed\nexperiments on the NaturalQuestions dataset, utilizing BM25 and Contriever as initial retrievers. We integrated the\nLCR method with both Maximum Semantic Cluster Proportion (MSCP) and Semantic Entropy (SE) (Farquhar et al.,\nSong et al.: Preprint submitted to Elsevier\nPage 14 of 21\n"}, {"page": 15, "text": "LLM-Confidence Reranker\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nUpper Threshold\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nLower Threshold\n0.8\n3.1\n8.0\n9.3\n10.3\n9.7\n13.9\n18.2\n18.0\n0.8\n3.4\n8.3\n9.6\n10.6\n10.5\n14.4\n18.8\n18.6\n3.4\n8.3\n9.8\n10.8\n10.7\n15.0\n20.1\n19.7\n8.3\n9.5\n10.8\n10.4\n14.6\n19.1\n18.5\n9.5\n10.5\n9.8\n14.0\n17.7\n17.6\n10.5\n9.9\n13.5\n16.6\n16.0\n9.9\n14.1\n16.6\n16.4\n14.1\n18.3\n17.9\n18.3\n18.1\n30\n20\n10\n0\n10\n20\n30\nFigure 4: Heatmap of NDCG@5 Improvement Percentages for Document Thresholds. This heatmap shows the percentage\ndifferences in NDCG@5 scores for various combinations of the lower threshold (LT, y-axis) and upper threshold (UT, x-\naxis) in the LCR algorithm, applied to the NaturalQuestions dataset with BM25 as the initial retriever and RankGPT\nas the reranker, without the query threshold. Red shades indicate positive improvements relative to the baseline, blue\nshades signify negative changes, and white denotes no change. Color intensities correspond to the magnitude of variations,\nrevealing optimal threshold settings for improved ranking performance.\nRetriever-Only\nRankGPT\nRankT5\nReranker\n0\n5\n10\n15\n20\n25\nImprovement (%)\n20.0\n20.1\n0.9\n18.5\n18.8\n0.1\n21.6\n21.7\n0.2\n24.0\n24.5\n0.3\nQwen7B\nLlama8B\nGLMChat9B\nInternLM7B\n(a) BM25\nRetriever-Only\nRankGPT\nRankT5\nReranker\n0\n2\n4\n6\n8\n10\nImprovement (%)\n1.2\n1.1\n0.2\n5.4\n5.2\n1.4\n7.2\n7.1\n1.9\n9.9\n9.6\n3.9\nQwen7B\nLlama8B\nGLMChat9B\nInternLM7B\n(b) Contriever\nFigure 5: NDCG@5 Improvements Across Different Language Models. Results are derived from the Natural Questions\ndataset.\nSong et al.: Preprint submitted to Elsevier\nPage 15 of 21\n"}, {"page": 16, "text": "LLM-Confidence Reranker\n2024) applied to the outputs of various rerankers. Bar charts were generated to contrast the performance enhancements\nachieved by each method. As illustrated in Figure 6, while SE yields improvements, it generally underperforms\ncompared to MSCP. This disparity may arise because MSCP directly measures the dominance of the primary semantic\ncluster, thereby more robustly capturing semantic consistency, whereas SE, being an entropy-based metric, is more\nvulnerable to distributional noise in the sampled outputs.\nRetriever-Only\nYesNo\nQLM\nRankGPT\nColBERT\nCross-Encoder\nRankT5\nReranker\n0\n10\n20\n30\n40\n50\n60\nImprovement (%)\n19.9\n60.7\n3.3\n20.0\n1.8\n0.6\n1.0\n13.7\n47.4\n0.7\n13.7\n0.0\n0.0\n0.0\nQuantification Method\nMSCP\nSE\n(a) BM25\nRetriever-Only\nYesNo\nQLM\nRankGPT\nColBERT\nCross-Encoder\nRankT5\nReranker\n0\n10\n20\n30\n40\n50\nImprovement (%)\n1.2\n52.0\n14.3\n1.1\n0.6\n0.5\n0.2\n0.1\n41.1\n10.7\n0.2\n0.1\n0.0\n0.0\nQuantification Method\nMSCP\nSE\n(b) Contriever\nFigure 6: Impact of Confidence Quantification Methods on Performance Improvements. Bar charts comparing NDCG@5\nenhancements from MSCP and SE across rerankers, based on the NaturalQuestions dataset.\n4.8. Underlying Mechanism\nTo elucidate the effectiveness of the LCR algorithm, we hypothesize that the confidence exhibited by LLMs\nin their generated responses positively correlates with the relevance of the input documents. This hypothesis is\nempirically validated through experiments conducted on six diverse datasets. We employ the MSCP for confidence\nquantification. For each query-document pair, confidence scores are computed and uniformly divided into 10 bins.\nSubsequently, we calculate the proportion of relevant documents within each bin to reveal the confidence-relevance\nassociation. To ensure consistent comparison, relevance scores are binarized across all datasets: scores greater than 0\nare classified as relevant (1), while 0 denotes irrelevance (0). This binarization applies directly to datasets with binary\nrelevance (NaturalQuestions, FEVER, SciDocs) and requires converting graded scoresâ€”treating values greater than 0\nas relevantâ€”for those with multi-level relevance (DBpedia-Entity, TouchÃ©, NFCorpus). As illustrated in Figure 7, the\nmajority of datasets demonstrate a clear positive correlation, wherein bins with higher confidence scores encompass\nlarger proportions of relevant documents. This indicates that LLMs exhibit greater semantic consistency in responses\ninformed by relevant documents, thereby generating more robust confidence signals that bolster LCRâ€™s ranking\nenhancements through confidence binning.\nIn summary, this empirical validation highlights the utility of LLMsâ€™ intrinsic semantic capabilities in document\nranking, providing a theoretical foundation for the application of LCR in knowledge-intensive tasks.\n5. Conclusion\nIn this paper, we addressed the persistent challenge of hallucinations in large language models (LLMs) for\nknowledge-intensive tasks by introducing the LLM-Confidence Reranker (LCR), a training-free, plug-and-play\nalgorithm that harnesses LLMsâ€™ semantic understanding and question-answering capabilities to enhance document\nreranking in retrieval-augmented generation (RAG) systems. Unlike conventional rerankers that directly evaluate\nquery-document relevance, LCR leverages black-box LLM confidence signalsâ€”quantified via the Maximum Semantic\nCluster Proportion (MSCP)â€”as a proxy for relevance, employing a two-stage process of confidence assessment and\nmulti-level sorting to prioritize relevant documents.\nLCR demonstrates remarkable robustness across diverse settings, including various retrievers (sparse like BM25\nand dense like Contriever), rerankers (pre-trained LLM-based and fine-tuned Transformer-based), and LLMs from\ndifferent families. Relying solely on lightweight pre-trained models with 7â€“9B parameters, it ensures computational\nSong et al.: Preprint submitted to Elsevier\nPage 16 of 21\n"}, {"page": 17, "text": "LLM-Confidence Reranker\n0.0-0.1\n0.1-0.2\n0.2-0.3\n0.3-0.4\n0.4-0.5\n0.5-0.6\n0.6-0.7\n0.7-0.8\n0.8-0.9\n0.9-1.0\n0.00\n0.01\n0.02\nNQ\n0.0-0.1\n0.1-0.2\n0.2-0.3\n0.3-0.4\n0.4-0.5\n0.5-0.6\n0.6-0.7\n0.7-0.8\n0.8-0.9\n0.9-1.0\n0.02\n0.04\n0.06\n0.08\nFEVER\n0.0-0.1\n0.1-0.2\n0.2-0.3\n0.3-0.4\n0.4-0.5\n0.5-0.6\n0.6-0.7\n0.7-0.8\n0.8-0.9\n0.9-1.0\n0.06\n0.08\n0.10\n0.12\nDBpedia-Entity\n0.0-0.1\n0.1-0.2\n0.2-0.3\n0.3-0.4\n0.4-0.5\n0.5-0.6\n0.6-0.7\n0.7-0.8\n0.8-0.9\n0.9-1.0\n0.0\n0.1\n0.2\n0.3\n0.4\nTouchÃ©\n0.0-0.1\n0.1-0.2\n0.2-0.3\n0.3-0.4\n0.4-0.5\n0.5-0.6\n0.6-0.7\n0.7-0.8\n0.8-0.9\n0.9-1.0\n0.00\n0.02\n0.04\n0.06\n0.08\nSciDocs\n0.0-0.1\n0.1-0.2\n0.2-0.3\n0.3-0.4\n0.4-0.5\n0.5-0.6\n0.6-0.7\n0.7-0.8\n0.8-0.9\n0.9-1.0\n0.0\n0.1\n0.2\n0.3\nNFCorpus\nConfidence Score Bins\nProportion of Relevant Samples\nFigure 7: Confidence-Relevance Calibration Curve. This figure depicts the relationship between confidence scores (derived\nfrom MSCP) and document relevance. Each subplot corresponds to a specific dataset, with confidence score bins along the\nx-axis and the proportion of relevant samples along the y-axis. The sizes of scatter points reflect the logarithmic sample\npercentage per bin, enhancing visibility amid varying distributions. Results are obtained using the BM25 retriever and the\nQwen7B model.\nefficiency, pointwise independent scoring for parallelism, and scalability, all while maintaining black-box accessibility\nthat enhances its practical utility in real-world deployments.\nComprehensive evaluations on BEIR and TREC benchmarks reveal consistent NDCG@5 enhancements of up to\n20.6% over baselines, without any degradation. Ablation studies elucidate the influence of key factors, and empirical\nvalidations affirm the hypothesis that LLM confidence positively correlates with document relevance, furnishing a\nrobust theoretical foundation for LCRâ€™s efficacy.\nBy delivering strong generalization, minimal computational overhead, and effective hallucination mitigation, LCR\nsignificantly advances RAG systems. Future directions may explore adaptive thresholding, multi-LLM ensembles, and\nfusions with cutting-edge uncertainty quantification techniques to further elevate retrieval precision and overall RAG\nperformance.\nSong et al.: Preprint submitted to Elsevier\nPage 17 of 21\n"}, {"page": 18, "text": "LLM-Confidence Reranker\nReferences\nAichberger, L., Schweighofer, K., Ielanskyi, M., & Hochreiter, S. (2025). Improving uncertainty estimation through semantically diverse language\ngeneration. In The thirteenth international conference on learning representations,ICLR 2025, singapore, april 24-28, 2025. Retrieved from\nhttps://openreview.net/forum?id=HSi4VetQLj\nAzaria, A., & Mitchell, T. M. (2023). The internal state of an LLM knows when itâ€™s lying. In Findings of the association for computational linguistics:\nEMNLP 2023, singapore, december 6-10, 2023 (pp. 967â€“976). Retrieved from https://doi.org/10.18653/v1/2023.findings-emnlp\n.68 doi: 10.18653/V1/2023.FINDINGS-EMNLP.68\nBondarenko, A., FrÃ¶be, M., Beloucif, M., Gienapp, L., Ajjour, Y., Panchenko, A., ... Hagen, M. (2020). Overview of touchÃ© 2020: Argument\nretrieval - extended abstract.\nIn Experimental IR meets multilinguality, multimodality, and interaction - 11th international conference of\nthe CLEF association, CLEF 2020, thessaloniki, greece, september 22-25, 2020, proceedings (Vol. 12260, pp. 384â€“395).\nRetrieved from\nhttps://doi.org/10.1007/978-3-030-58219-7_26 doi: 10.1007/978-3-030-58219-7_26\nBonifacio, L. H., Abonizio, H. Q., Fadaee, M., & Nogueira, R. (2022). Inpars: Unsupervised dataset generation for information retrieval. In\nProceedings of the 45th international ACM SIGIR conference on research and development in information retrieval, SIGIR 2022, madrid, spain,\njuly 11-15, 2022 (pp. 2387â€“2392). Retrieved from https://doi.org/10.1145/3477495.3531863 doi: 10.1145/3477495.3531863\nBoteva, V., Ghalandari, D. G., Sokolov, A., & Riezler, S.\n(2016).\nA full-text learning to rank dataset for medical information retrieval.\nIn\nAdvances in information retrieval (Vol. 9626, pp. 716â€“722). Retrieved from https://doi.org/10.1007/978-3-319-30671-1_58\ndoi:\n10.1007/978-3-319-30671-1_58\nBoytsov, L., Patel, P., Sourabh, V., Nisar, R., Kundu, S., Ramanathan, R., & Nyberg, E. (2024). Inpars-light: Cost-effective unsupervised training\nof efficient rankers.\nTransactions on Machine Learning Research.\nRetrieved from https://openreview.net/forum?id=sHSKFYyINO\n(Reproducibility Certification)\nCai, Z., Cao, M., Chen, H., Chen, K., Chen, K., Chen, X., ... Zhao, X. (2024). Internlm2 technical report. arXiv, abs/2403.17297. Retrieved from\nhttps://doi.org/10.48550/arXiv.2403.17297 doi: 10.48550/ARXIV.2403.17297\nCao, Z., Qin, T., Liu, T.-Y., Tsai, M.-F., & Li, H. (2007). Learning to rank: from pairwise approach to listwise approach. In Machine learning,\nproceedings of the twenty-fourth international conference (ICML 2007), corvallis, oregon, usa, june 20-24, 2007 (Vol. 227, pp. 129â€“136).\nRetrieved from https://doi.org/10.1145/1273496.1273513 doi: 10.1145/1273496.1273513\nChen, Y., Liu, Q., Zhang, Y., Sun, W., Ma, X., Yang, W., ... Yin, D. (2025). Tourrank: Utilizing large language models for documents ranking with\na tournament-inspired strategy. In Proceedings of the ACM on web conference 2025, WWW 2025, sydney, nsw, australia, 28 april 2025- 2 may\n2025 (pp. 1638â€“1652). Retrieved from https://doi.org/10.1145/3696410.3714863 doi: 10.1145/3696410.3714863\nCheng, Q., Sun, T., Liu, X., Zhang, W., Yin, Z., Li, S., ... Qiu, X.\n(2024).\nCan AI assistants know what they donâ€™t know?\nIn Forty-first\ninternational conference on machine learning, ICML 2024, vienna, austria, july 21-27, 2024 (Vol. 235, pp. 8184â€“8202).\nRetrieved from\nhttps://openreview.net/forum?id=girxGkdECL\nChi, M., Pang, W., Wu, X., Zhao, P., Li, Y., Wang, T., ... Zhou, Y.\n(2026).\nA generalized neural solver based on llm-guided heuristic\nevoluation framework for solving diverse variants of vehicle routing problems. Expert Systems with Applications, 296, 128876. Retrieved from\nhttps://www.sciencedirect.com/science/article/pii/S0957417425024935 doi: https://doi.org/10.1016/j.eswa.2025.128876\nChowdhury, T., Zick, Y., & Allan, J.\n(2025).\nRankshap: Shapley value based feature attributions for learning to rank.\nIn The thirteenth\ninternational conference on learning representations, ICLR 2025, singapore, april 24-28, 2025. Retrieved from https://openreview.net/\nforum?id=4011PUI9vm\nCohan, A., Feldman, S., Beltagy, I., Downey, D., & Weld, D. S. (2020). SPECTER: document-level representation learning using citation-informed\ntransformers. In Proceedings of the 58th annual meeting of the association for computational linguistics (pp. 2270â€“2282). Retrieved from\nhttps://doi.org/10.18653/v1/2020.acl-main.207 doi: 10.18653/V1/2020.ACL-MAIN.207\nCraswell, N., Mitra, B., Yilmaz, E., & Campos, D. (2021). Overview of the trec 2020 deep learning track. arXiv preprint arXiv:2102.07662.\nCraswell, N., Mitra, B., Yilmaz, E., Campos, D., & Voorhees, E. M. (2020). Overview of the trec 2019 deep learning track. arXiv e-prints.\nDeepSeek-AI, Guo, D., Yang, D., Zhang, H., Song, J., Zhang, R., ... Li, S. S.\n(2025).\nDeepseek-r1: Incentivizing reasoning capability\nin llms via reinforcement learning.\narXiv, abs/2501.12948.\nRetrieved from https://doi.org/10.48550/arXiv.2501.12948\ndoi:\n10.48550/ARXIV.2501.12948\nDong, J., Fatemi, B., Perozzi, B., Yang, L. F., & Tsitsulin, A. (2024). Donâ€™t forget to connect! improving RAG with graph-based reranking. arXiv,\nabs/2405.18414. Retrieved from https://doi.org/10.48550/arXiv.2405.18414 doi: 10.48550/ARXIV.2405.18414\nDuan, J., Cheng, H., Wang, S., Zavalny, A., Wang, C., Xu, R., ... Xu, K. (2024). Shifting attention to relevance: Towards the predictive uncertainty\nquantification of free-form large language models. In Proceedings of the 62nd annual meeting of the association for computational linguistics\n(volume 1: Long papers), ACL 2024, bangkok, thailand, august 11-16, 2024 (pp. 5050â€“5063). Retrieved from https://doi.org/10.18653/\nv1/2024.acl-long.276 doi: 10.18653/V1/2024.ACL-LONG.276\nDubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle, A., Letman, A., ... Stone, K. (2024). The llama 3 herd of models. arXiv, abs/2407.21783.\nRetrieved from https://doi.org/10.48550/arXiv.2407.21783 doi: 10.48550/ARXIV.2407.21783\nEhsan, K., Nandan, T., Carlos, L., Xueguang, M., Jheng-Hong, Y., & Jimmy, L. (2024). Resources for brewing BEIR: reproducible reference models\nand statistical analyses. In Proceedings of the 47th international ACM SIGIR conference on research and development in information retrieval,\nSIGIR 2024, washington dc, usa, july 14-18, 2024 (pp. 1431â€“1440). Retrieved from https://doi.org/10.1145/3626772.3657862 doi:\n10.1145/3626772.3657862\nFarquhar, S., Kossen, J., Kuhn, L., & Gal, Y. (2024). Detecting hallucinations in large language models using semantic entropy. Nature, 630,\n625â€“630. Retrieved from https://doi.org/10.1038/s41586-024-07421-0 doi: 10.1038/S41586-024-07421-0\nHarrie, O., Rolf, J., Zhen, Q., & Xuanhui, W. (2025). Optimizing compound retrieval systems. International ACM SIGIR Conference on Research\nand Development in Information Retrieval.\nHasibi, F., Nikolaev, F., Xiong, C., Balog, K., Bratsberg, S. E., Kotov, A., & Callan, J. (2017). Dbpedia-entity v2: A test collection for entity search.\nIn Proceedings of the 40th international ACM SIGIR conference on research and development in information retrieval, shinjuku, tokyo, japan,\nSong et al.: Preprint submitted to Elsevier\nPage 18 of 21\n"}, {"page": 19, "text": "LLM-Confidence Reranker\naugust 7-11, 2017 (pp. 1265â€“1268). Retrieved from https://doi.org/10.1145/3077136.3080751 doi: 10.1145/3077136.3080751\nHuang, L., Yu, W., Ma, W., Zhong, W., Feng, Z., Wang, H., ... Liu, T. (2025). A survey on hallucination in large language models: Principles,\ntaxonomy, challenges, and open questions. ACM Transactions on Information Systems, 43(2), 42:1â€“42:55. Retrieved from https://doi.org/\n10.1145/3703155 doi: 10.1145/3703155\nIzacard, G., Caron, M., Hosseini, L., Riedel, S., Bojanowski, P., Joulin, A., & Grave, E. (2022). Unsupervised dense information retrieval with\ncontrastive learning. Transactions on Machine Learning Research. Retrieved from https://openreview.net/forum?id=jKN1pXi7b0\nJÃ¤rvelin, K., & KekÃ¤lÃ¤inen, J. (2002). Cumulated gain-based evaluation of IR techniques. ACM Transactions on Information Systems, 20(4),\n422â€“446. Retrieved from http://doi.acm.org/10.1145/582415.582418 doi: 10.1145/582415.582418\nJi, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., ... Fung, P. (2023). Survey of hallucination in natural language generation. ACM Computing\nSurveys, 55(12), 248:1â€“248:38. Retrieved from https://doi.org/10.1145/3571730 doi: 10.1145/3571730\nJian, L., Xuanang, C., Ben, H., & Le, S. (2024, aug). Prp-graph: Pairwise ranking prompting to LLMs with graph aggregation for effective text\nre-ranking. In Proceedings of the 62nd annual meeting of the association for computational linguistics (volume 1: Long papers) (pp. 5766â€“5776).\nBangkok, Thailand. Retrieved from https://aclanthology.org/2024.acl-long.313/ doi: 10.18653/v1/2024.acl-long.313\nJoachims, T. (2002). Optimizing search engines using clickthrough data. In Proceedings of the eighth ACM SIGKDD international conference\non knowledge discovery and data mining, july 23-26, 2002, edmonton, alberta, canada (pp. 133â€“142). Retrieved from https://doi.org/\n10.1145/775047.775067 doi: 10.1145/775047.775067\nJones, K. S., Walker, S., & Robertson, S. E. (2000). A probabilistic model of information retrieval: development and comparative experiments - part\n2. Information Processing & Management, 36(6), 809â€“840. Retrieved from https://doi.org/10.1016/S0306-4573(00)00016-9 doi:\n10.1016/S0306-4573(00)00016-9\nKadavath, S., Conerly, T., Askell, A., Henighan, T., Drain, D., Perez, E., ... Kaplan, J. (2022). Language models (mostly) know what they know.\narXiv, abs/2207.05221. Retrieved from https://doi.org/10.48550/arXiv.2207.05221 doi: 10.48550/ARXIV.2207.05221\nKeshvari, S., Ensan, F., & Yazdi, H. S. (2022). Listmap: Listwise learning to rank as maximum a posteriori estimation. Information Processing &\nManagement, 59(4), 102962. Retrieved from https://doi.org/10.1016/j.ipm.2022.102962 doi: 10.1016/J.IPM.2022.102962\nKhattab, O., & Zaharia, M. (2020). Colbert: Efficient and effective passage search via contextualized late interaction over BERT. In Proceedings\nof the 43rd international ACM SIGIR conference on research and development in information retrieval, SIGIR 2020, virtual event, china, july\n25-30, 2020 (pp. 39â€“48). Retrieved from https://doi.org/10.1145/3397271.3401075 doi: 10.1145/3397271.3401075\nKwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A. P., Alberti, C., ... Petrov, S. (2019). Natural questions: a benchmark for question\nanswering research. Transactions of the Association for Computational Linguistics, 7, 452â€“466. Retrieved from https://doi.org/10.1162/\ntacl_a_00276 doi: 10.1162/TACL_A_00276\nLee, J., Jung, D., Lee, S., Park, J., Shin, J., Hwang, U., & Yoon, S. (2024). Entropy is not enough for test-time adaptation: From the perspective of\ndisentangled factors. In The twelfth international conference on learning representations,ICLR 2024, vienna, austria, may 7-11, 2024. Retrieved\nfrom https://openreview.net/forum?id=9w3iw8wDuE\nLeng, J., Huang, C., Zhu, B., & Huang, J. (2025). Taming overconfidence in llms: Reward calibration in RLHF. In The thirteenth international\nconference on learning representations,ICLR 2025, singapore, april 24-28, 2025. Retrieved from https://openreview.net/forum?id=\nl0tg0jzsdL\nLewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., ... Kiela, D. (2020). Retrieval-augmented generation for knowledge-intensive\nNLP tasks. In Advances in neural information processing systems 33: Annual conference on neural information processing systems 2020,\nneurips 2020, december 6-12, 2020, virtual (Vol. 33, pp. 9459â€“9474). Retrieved from https://proceedings.neurips.cc/paper/2020/\nhash/6b493230205f780e1bc26945df7481e5-Abstract.html\nLi, L., Tan, R., Fang, J., Xue, J., & Lv, C. (2025). Llm-augmented hierarchical reinforcement learning for human-like decision-making of autonomous\ndriving. Expert Systems with Applications, 294, 128736. Retrieved from https://www.sciencedirect.com/science/article/pii/\nS0957417425023541 doi: https://doi.org/10.1016/j.eswa.2025.128736\nLi, R., Patel, T., & Du, X. (2024). PRD: peer rank and discussion improve large language model based evaluations. Transactions on Machine\nLearning Research. Retrieved from https://openreview.net/forum?id=YVD1QqWRaj\nLin, S., Hilton, J., & Evans, O. (2022). Teaching models to express their uncertainty in words. Transactions on Machine Learning Research.\nRetrieved from https://openreview.net/forum?id=8s8K2UZGTZ\nLiu, N. F., Lin, K., Hewitt, J., Paranjape, A., Bevilacqua, M., Petroni, F., & Liang, P. (2024). Lost in the middle: How language models use\nlong contexts. Transactions of the Association for Computational Linguistics, 12, 157â€“173. Retrieved from https://aclanthology.org/\n2024.tacl-1.9/ doi: 10.1162/tacl_a_00638\nLuo, S., Xu, J., Zhang, X., Wang, L., Liu, S., Hou, H., & Song, L. (2026). Rallrec+: Retrieval augmented large language model recommendation\nwith reasoning. Expert Systems with Applications, 297, 129508. Retrieved from https://www.sciencedirect.com/science/article/\npii/S0957417425031239 doi: https://doi.org/10.1016/j.eswa.2025.129508\nMa, X., Zhang, X., Pradeep, R., & Lin, J. (2023). Zero-shot listwise document reranking with a large language model. arXiv, abs/2305.02156.\nRetrieved from https://doi.org/10.48550/arXiv.2305.02156 doi: 10.48550/ARXIV.2305.02156\nMalinin, A., & Gales, M. J. F. (2021). Uncertainty estimation in autoregressive structured prediction. In 9th international conference on learning\nrepresentations, ICLR 2021, virtual event, austria, may 3-7, 2021. Retrieved from https://openreview.net/forum?id=jN5y-zb5Q7m\nManggala, P., Mastakouri, A.-A., Kirschbaum, E., Kasiviswanathan, S. P., & Ramdas, A. (2025). Qa-calibration of language model confidence\nscores.\nIn The thirteenth international conference on learning representations,ICLR 2025, singapore, april 24-28, 2025.\nRetrieved from\nhttps://openreview.net/forum?id=D2hhkU5O48\nMarks, S., & Tegmark, M. (2024). The geometry of truth: Emergent linear structure in large language model representations of true/false datasets.\nIn First conference on language modeling. Retrieved from https://openreview.net/forum?id=aajyHYjjsk\nMaximilian, H., Marvin, V., Alexander, B., Matthias, H., & Benno, S. (2025). Axiomatic re-ranking for argument retrieval. International ACM\nSIGIR Conference on Research and Development in Information Retrieval.\nSong et al.: Preprint submitted to Elsevier\nPage 19 of 21\n"}, {"page": 20, "text": "LLM-Confidence Reranker\nPÅ‚onka, M., Kocot, K., HoÅ‚da, K., Daniec, K., & Nawrat, A. (2025). A comparative evaluation of the effectiveness of document splitters for large\nlanguage models in legal contexts. Expert Systems with Applications, 272, 126711. Retrieved from https://www.sciencedirect.com/\nscience/article/pii/S0957417425003331 doi: https://doi.org/10.1016/j.eswa.2025.126711\nQi, L., Atul, S., Jingbo, L., Cun, M., & Zheng, Y. (2025). Towards more relevant product search ranking via large language models: An empirical\nstudy. International ACM SIGIR Conference on Research and Development in Information Retrieval.\nQin, Z., Jagerman, R., Hui, K., Zhuang, H., Wu, J., Yan, L., ... Bendersky, M. (2024). Large language models are effective text rankers with pairwise\nranking prompting. In Findings of the association for computational linguistics: NAACL 2024, mexico city, mexico, june 16-21, 2024 (pp. 1504â€“\n1518). Retrieved from https://doi.org/10.18653/v1/2024.findings-naacl.97 doi: 10.18653/V1/2024.FINDINGS-NAACL.97\nQing, L., Kumar, S., Chaitanya, M., Li, Z., Yanai, E., Niket, T., ... Chris, C.-B.\n(2025).\nCalibrating large language models with sample\nconsistency. In Proceedings of the aaai conference on artificial intelligence (pp. 19260â€“19268). Retrieved from https://doi.org/10.1609/\naaai.v39i18.34120 doi: 10.1609/AAAI.V39I18.34120\nReimers, N., & Gurevych, I. (2019). Sentence-bert: Sentence embeddings using siamese bert-networks. In Proceedings of the 2019 conference\non empirical methods in natural language processing and the 9th international joint conference on natural language processing, EMNLP-\nIJCNLP 2019, hong kong, china, november 3-7, 2019 (pp. 3980â€“3990). Retrieved from https://doi.org/10.18653/v1/D19-1410 doi:\n10.18653/V1/D19-1410\nRen, R., Ma, J., & Zheng, Z. (2025). Large language model for interpreting research policy using adaptive two-stage retrieval augmented fine-\ntuning method. Expert Systems with Applications, 278, 127330. Retrieved from https://www.sciencedirect.com/science/article/\npii/S0957417425009522 doi: https://doi.org/10.1016/j.eswa.2025.127330\nRen, R., Wang, Y., Zhou, K., Zhao, W. X., Wang, W., Liu, J., ... Chua, T.-S. (2025). Self-calibrated listwise reranking with large language models.\nIn Proceedings of the ACM on web conference 2025, WWW 2025, sydney, nsw, australia, 28 april 2025- 2 may 2025 (pp. 3692â€“3701). Retrieved\nfrom https://doi.org/10.1145/3696410.3714658 doi: 10.1145/3696410.3714658\nRen, T., Zhang, Z., Jia, B., & Zhang, S.\n(2025).\nRetrieval-augmented generation-aided causal identification of aviation accidents: A large\nlanguage model methodology. Expert Systems with Applications, 278, 127306. Retrieved from https://www.sciencedirect.com/science/\narticle/pii/S0957417425009285 doi: https://doi.org/10.1016/j.eswa.2025.127306\nSachan, D. S., Lewis, M., Joshi, M., Aghajanyan, A., Yih, W., Pineau, J., & Zettlemoyer, L. (2022). Improving passage retrieval with zero-shot\nquestion generation. In Proceedings of the 2022 conference on empirical methods in natural language processing, EMNLP 2022, abu dhabi,\nunited arab emirates, december 7-11, 2022 (pp. 3781â€“3797). Retrieved from https://doi.org/10.18653/v1/2022.emnlp-main.249 doi:\n10.18653/V1/2022.EMNLP-MAIN.249\nSalemi, A., & Zamani, H. (2024). Evaluating retrieval quality in retrieval-augmented generation. In Proceedings of the 47th international ACM\nSIGIR conference on research and development in information retrieval, SIGIR 2024, washington dc, usa, july 14-18, 2024 (pp. 2395â€“2400).\nRetrieved from https://doi.org/10.1145/3626772.3657957 doi: 10.1145/3626772.3657957\nSettles, B., & Craven, M. (2008). An analysis of active learning strategies for sequence labeling tasks. In Proceedings of the 2008 conference on\nempirical methods in natural language processing (pp. 1070â€“1079). Retrieved from https://aclanthology.org/D08-1112/\nSun, W., Yan, L., Ma, X., Wang, S., Ren, P., Chen, Z., ... Ren, Z. (2023). Is chatgpt good at search? investigating large language models as\nre-ranking agents. In Proceedings of the 2023 conference on empirical methods in natural language processing, EMNLP 2023, singapore,\ndecember 6-10, 2023 (pp. 14918â€“14937). Retrieved from https://doi.org/10.18653/v1/2023.emnlp-main.923\ndoi: 10.18653/V1/\n2023.EMNLP-MAIN.923\nSuresh, T., Reddy, R. G., Xu, Y., Nussbaum, Z., Mulyar, A., Duderstadt, B., & Ji, H. (2025). Cornstack: High-quality contrastive data for better\ncode retrieval and reranking. In The thirteenth international conference on learning representations, ICLR 2025, singapore, april 24-28, 2025.\nRetrieved from https://openreview.net/forum?id=iyJOUELYir\nTang, Y., Zhang, R., Guo, J., de Rijke, M., Chen, W., & Cheng, X. (2024a). Generative retrieval meets multi-graded relevance. In Advances\nin neural information processing systems 38: Annual conference on neural information processing systems 2024, neurips 2024, vancouver, bc,\ncanada, december 10-15, 2024 (Vol. 37, pp. 72790â€“72817). Retrieved from http://papers.nips.cc/paper_files/paper/2024/hash/\n853e781cb2af58956ed5c89aa59da3fc-Abstract-Conference.html\nTang, Y., Zhang, R., Guo, J., de Rijke, M., Chen, W., & Cheng, X.\n(2024b).\nListwise generative retrieval models via a sequential learning\nprocess. ACM Transactions on Information Systems, 42(5), 133:1â€“133:31. Retrieved from https://doi.org/10.1145/3653712\ndoi:\n10.1145/3653712\nThakur, N., Reimers, N., RÃ¼cklÃ©, A., Srivastava, A., & Gurevych, I. (2021). BEIR: A heterogeneous benchmark for zero-shot evaluation of\ninformation retrieval models. In Proceedings of the neural information processing systems track on datasets and benchmarks 1, neurips datasets\nand benchmarks 2021, december 2021, virtual (Vol. 1). Retrieved from https://datasets-benchmarks-proceedings.neurips.cc/\npaper/2021/hash/65b9eea6e1cc6bb9f0cd2a47751a186f-Abstract-round2.html\nThorne, J., Vlachos, A., Christodoulopoulos, C., & Mittal, A. (2018). FEVER: a large-scale dataset for fact extraction and verification. In Proceedings\nof the 2018 conference of the north american chapter of the association for computational linguistics: Human language technologies, NAACL-\nHLT 2018, new orleans, louisiana, usa, june 1-6, 2018, volume 1 (long papers) (pp. 809â€“819). Retrieved from https://doi.org/10.18653/\nv1/n18-1074 doi: 10.18653/V1/N18-1074\nVoorhees, E. M., & Harman, D. K. (2005). Trec: Experiment and evaluation in information retrieval (digital libraries and electronic publishing).\nThe MIT Press.\nWang, X., Gao, R., Jain, A., Edge, G., & Ahuja, S. (2023). How well do offline metrics predict online performance of product ranking models? In\nProceedings of the 46th international ACM SIGIR conference on research and development in information retrieval, SIGIR 2023, taipei, taiwan,\njuly 23-27, 2023 (pp. 3415â€“3420). Retrieved from https://doi.org/10.1145/3539618.3591865 doi: 10.1145/3539618.3591865\nWang, Z., Duan, J., Yuan, C., Chen, Q., Chen, T., Zhang, Y., ... Xu, K. (2025). Word-sequence entropy: Towards uncertainty estimation in\nfree-form medical question answering applications and beyond. Engineering Applications of Artificial Intelligence, 139, 109553. Retrieved from\nhttps://doi.org/10.1016/j.engappai.2024.109553 doi: 10.1016/J.ENGAPPAI.2024.109553\nSong et al.: Preprint submitted to Elsevier\nPage 20 of 21\n"}, {"page": 21, "text": "LLM-Confidence Reranker\nXiao, Y., & Wang, W. Y. (2021). On hallucination and predictive uncertainty in conditional language generation. In Proceedings of the 16th\nconference of the european chapter of the ssociation for computational linguistics: Main volume, EACL 2021, online, april 19-23, 2021 (pp.\n2734â€“2744). Retrieved from https://doi.org/10.18653/v1/2021.eacl-main.236 doi: 10.18653/V1/2021.EACL-MAIN.236\nXiong, M., Hu, Z., Lu, X., Li, Y., Fu, J., He, J., & Hooi, B. (2024). Can llms express their uncertainty? an empirical evaluation of confidence\nelicitation in llms. In The twelfth international conference on learning representations,ICLR 2024, vienna, austria, may 7-11, 2024. Retrieved\nfrom https://openreview.net/forum?id=gjeQKFxFpZ\nXu, H., Zhu, Z., Zhang, S., Ma, D., Fan, S., Chen, L., & Yu, K.\n(2024).\nRejection improves reliability: Training llms to refuse unknown\nquestions using RL from knowledge feedback.\nIn First conference on language modeling.\nRetrieved from https://openreview.net/\nforum?id=lJMioZBoR8\nXu, S., Pang, L., Xu, J., Shen, H., & Cheng, X.\n(2024).\nList-aware reranking-truncation joint model for search and retrieval-augmented\ngeneration. In Proceedings of the ACM on web conference 2024, WWW 2024, singapore, may 13-17, 2024 (pp. 1330â€“1340). Retrieved from\nhttps://doi.org/10.1145/3589334.3645336 doi: 10.1145/3589334.3645336\nXu, T., Wu, S., Diao, S., Liu, X., Wang, X., Chen, Y., & Gao, J. (2024). Sayself: Teaching llms to express confidence with self-reflective rationales.\nIn Proceedings of the 2024 conference on empirical methods in natural language processing, EMNLP 2024, miami, fl, usa, november 12-16, 2024\n(pp. 5985â€“5998). Retrieved from https://doi.org/10.18653/v1/2024.emnlp-main.343 doi: 10.18653/V1/2024.EMNLP-MAIN.343\nYang, A., Yang, B., Zhang, B., Hui, B., Zheng, B., Yu, B., ... Qiu, Z. (2024). Qwen2.5 technical report. arXiv, abs/2412.15115. Retrieved from\nhttps://doi.org/10.48550/arXiv.2412.15115 doi: 10.48550/ARXIV.2412.15115\nYang, Y., Chern, E., Qiu, X., Neubig, G., & Liu, P. (2024). Alignment for honesty. In Advances in neural information processing systems 38:\nAnnual conference on neural information processing systems 2024, neurips 2024, vancouver, bc, canada, december 10-15, 2024 (Vol. 37, pp.\n63565â€“63598).\nRetrieved from http://papers.nips.cc/paper_files/paper/2024/hash/7428e6db752171d6b832c53b2ed297ab\n-Abstract-Conference.html\nYao, J., He, G., & Xu, X.\n(2026).\nA collaborative reasoning framework for large language models in long-context q&a.\nExpert Systems\nwith Applications, 299, 129960. Retrieved from https://www.sciencedirect.com/science/article/pii/S0957417425035754 doi:\nhttps://doi.org/10.1016/j.eswa.2025.129960\nYona, G., Aharoni, R., & Geva, M. (2024). Can large language models faithfully express their intrinsic uncertainty in words? In Proceedings of the\n2024 conference on empirical methods in natural language processing, EMNLP 2024, miami, fl, usa, november 12-16, 2024 (pp. 7752â€“7764).\nRetrieved from https://aclanthology.org/2024.emnlp-main.443 doi: 10.18653/V1/2024.EMNLP-MAIN.443\nYu, W. (2022). Retrieval-augmented generation across heterogeneous knowledge. In Proceedings of the 2022 conference of the north american\nchapter of the association for computational linguistics: Human language technologies: Student research workshop, NAACL-HLT 2022, hybrid\nevent / seattle, wa, usa, july 10-15, 2022 (pp. 52â€“58).\nRetrieved from https://doi.org/10.18653/v1/2022.naacl-srw.7\ndoi:\n10.18653/V1/2022.NAACL-SRW.7\nYu, Y., Ping, W., Liu, Z., Wang, B., You, J., Zhang, C., ... Catanzaro, B. (2024). Rankrag: Unifying context ranking with retrieval-augmented\ngeneration in llms. In Advances in neural information processing systems 38: Annual conference on neural information processing systems\n2024, neurips 2024, vancouver, bc, canada, december 10-15, 2024 (Vol. 37, pp. 121156â€“121184). Retrieved from http://papers.nips.cc/\npaper_files/paper/2024/hash/db93ccb6cf392f352570dd5af0a223d3-Abstract-Conference.html\nZeng, A., Xu, B., Wang, B., Zhang, C., Yin, D., Rojas, D., ... Wang, Z. (2024). Chatglm: A family of large language models from GLM-\n130B to GLM-4 all tools.\narXiv, abs/2406.12793.\nRetrieved from https://doi.org/10.48550/arXiv.2406.12793\ndoi: 10.48550/\nARXIV.2406.12793\nZhang, H., Zhang, R., Guo, J., de Rijke, M., Fan, Y., & Cheng, X. (2024). Are large language models good at utility judgments? In Proceedings\nof the 47th international ACM SIGIR conference on research and development in information retrieval, SIGIR 2024, washington dc, usa, july\n14-18, 2024 (pp. 1941â€“1951). Retrieved from https://doi.org/10.1145/3626772.3657784 doi: 10.1145/3626772.3657784\nZhuang, H., Qin, Z., Jagerman, R., Hui, K., Ma, J., Lu, J., ... Bendersky, M. (2023). Rankt5: Fine-tuning T5 for text ranking with ranking losses. In\nProceedings of the 46th international ACM SIGIR conference on research and development in information retrieval, SIGIR 2023, taipei, taiwan,\njuly 23-27, 2023 (pp. 2308â€“2313). Retrieved from https://doi.org/10.1145/3539618.3592047 doi: 10.1145/3539618.3592047\nSong et al.: Preprint submitted to Elsevier\nPage 21 of 21\n"}]}