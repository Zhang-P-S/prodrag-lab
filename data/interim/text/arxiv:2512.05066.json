{"doc_id": "arxiv:2512.05066", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2512.05066.pdf", "meta": {"doc_id": "arxiv:2512.05066", "source": "arxiv", "arxiv_id": "2512.05066", "title": "Multi-LLM Collaboration for Medication Recommendation", "authors": ["Huascar Sanchez", "Briland Hitaj", "Jules Bergmann", "Linda Briesemeister"], "published": "2025-12-04T18:25:15Z", "updated": "2025-12-04T18:25:15Z", "summary": "As healthcare increasingly turns to AI for scalable and trustworthy clinical decision support, ensuring reliability in model reasoning remains a critical challenge. Individual large language models (LLMs) are susceptible to hallucinations and inconsistency, whereas naive ensembles of models often fail to deliver stable and credible recommendations. Building on our previous work on LLM Chemistry, which quantifies the collaborative compatibility among LLMs, we apply this framework to improve the reliability in medication recommendation from brief clinical vignettes. Our approach leverages multi-LLM collaboration guided by Chemistry-inspired interaction modeling, enabling ensembles that are effective (exploiting complementary strengths), stable (producing consistent quality), and calibrated (minimizing interference and error amplification). We evaluate our Chemistry-based Multi-LLM collaboration strategy on real-world clinical scenarios to investigate whether such interaction-aware ensembles can generate credible, patient-specific medication recommendations. Preliminary results are encouraging, suggesting that LLM Chemistry-guided collaboration may offer a promising path toward reliable and trustworthy AI assistants in clinical practice.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2512.05066v1", "url_pdf": "https://arxiv.org/pdf/2512.05066.pdf", "meta_path": "data/raw/arxiv/meta/2512.05066.json", "sha256": "b5d1ea186ba02c229f3788b4262868ee9b40dcaa02c2e57e3e025c9e187d3f8f", "status": "ok", "fetched_at": "2026-02-18T02:25:24.103488+00:00"}, "pages": [{"page": 1, "text": "Multi-LLM Collaboration for Medication Recommendation\nHuascar Sanchez1* and Briland Hitaj1* and Jules Bergmann1,2 and Linda Briesemeister1\n1Computer Science Laboratory, SRI International\n{huascar.sanchez, briland.hitaj, jules.bergmann, linda.briesemeister}@sri.com\n2University of Maryland St. Joseph Medical Center\nAbstract\nAs healthcare increasingly turns to AI for scal-\nable and trustworthy clinical decision support,\nensuring reliability in model reasoning remains\na critical challenge. Individual large language\nmodels (LLMs) are susceptible to hallucina-\ntions and inconsistency, whereas naive ensem-\nbles of models often fail to deliver stable and\ncredible recommendations. Building on our\nprevious work on LLM Chemistry, which quan-\ntifies the collaborative compatibility among\nLLMs, we apply this framework to improve\nthe reliability in medication recommendation\nfrom brief clinical vignettes. Our approach\nleverages multi-LLM collaboration guided by\nChemistry-inspired interaction modeling, en-\nabling ensembles that are effective (exploiting\ncomplementary strengths), stable (producing\nconsistent quality), and calibrated (minimizing\ninterference and error amplification). We evalu-\nate our Chemistry-based Multi-LLM collabora-\ntion strategy on real-world clinical scenarios to\ninvestigate whether such interaction-aware en-\nsembles can generate credible, patient-specific\nmedication recommendations. Preliminary re-\nsults are encouraging, suggesting that LLM\nChemistry-guided collaboration may offer a\npromising path toward reliable and trustworthy\nAI assistants in clinical practice.\n1\nIntroduction\nMedication recommendation from unstructured\nclinical notes remains a challenging task due to\nthe high variability and ambiguity of patient narra-\ntives (Eslami et al., 2025). While large language\nmodels (LLMs) have demonstrated remarkable suc-\ncess across many clinical and biomedical appli-\ncations, their performance is uneven—no single\nmodel consistently excels across reasoning, gener-\nation, and domain-specific understanding (Chang\net al., 2024). This inconsistency makes medica-\n**Equal contribution\ntion recommendation error-prone, especially when\nrelying on a single model’s inductive biases.\nRecent efforts to improve reliability through\nmodel ensembling and routing (Hu et al., 2024; Liu\net al., 2024; Cloud et al., 2025) have focused pri-\nmarily on selecting the best-performing individual\nmodels. However, these approaches often overlook\nthe interaction dynamics between models — how\ntheir reasoning processes reinforce or interfere with\neach other. As a result, ensembles can exhibit un-\nreliable synergy, where collaboration amplifies not\nonly strengths but also errors and biases.\nTo address this limitation, we introduce a Multi-\nLLM Collaboration approach that leverages the no-\ntion of LLM Chemistry (Sanchez and Hitaj, 2025)—\na quantitative measure of collaborative compatibil-\nity among LLMs. Our approach explicitly models\nthe synergistic and antagonistic relationships that\nemerge when multiple models reason together, en-\nabling the formation of ensembles that are: (1) Ef-\nfective: leveraging complementary strengths to im-\nprove recommendation accuracy; (2) Stable: main-\ntaining consistent performance across diverse clini-\ncal inputs; and (3) Calibrated: minimizing interfer-\nence and error amplification during collaboration,\nwhich translates to better task latency.\nBuilding on this formulation, we evaluate how\noptimal multi-LLM collaboration can enhance re-\nliability in clinical medication recommendation.\nSpecifically, we investigate the following research\nquestion: Does our approach ensure efficient, effec-\ntive, stable, and calibrated multi-LLM collabora-\ntion for the medication recommendation use-case?\nIf so, which LLM sampling strategy yields the most\naccurate results?\nWhile prior work has explored mixtures of\nLLMs — by sequentially feeding one model’s out-\nput into another to converge on a single aggregated\nresult through majority voting (Wang et al., 2024),\nby employing cascades to reduce costs where\nstronger models are invoked only when weaker\n1\narXiv:2512.05066v1  [cs.LG]  4 Dec 2025\n"}, {"page": 2, "text": "ones fail (Yue et al., 2024), by compensating for\nmodel deficiencies through meta-learning (Zhou\net al., 2024), or by debating which model in a group\nis correct (Chen et al., 2025a)—we take a differ-\nent approach. We introduce an inclusive and less\nrestrictive collaboration framework in which any\nLLM, open-weight or proprietary, can participate.\nBy leveraging diverse perspectives and comple-\nmentary knowledge across models, our approach\nenhances answer consistency and mitigates individ-\nual model blind spots. This framework follows the\nintuition that LLMs should defend and refine their\nreasoning in group settings, where peer scrutiny\nfosters consensus on the quality and reliability of\ngenerated answers.\nContributions. In this paper, we build upon and ex-\ntend our previous work (Sanchez and Hitaj, 2025)\nto explore applications of multi-LLM collaboration\nin healthcare, leading to the following contribu-\ntions:\n• Optimal Multi-LLM Collaboration. We leverage\nthe concept of LLM Chemistry to enable struc-\ntured, interaction-aware, and optimal collabora-\ntion among multiple LLMs.\n• Two-stage Collaboration Mechanism. We build\non an existing multi-LLM collaboration setup\nand extend its evaluation step with a consensus\nstep, transforming diverse, sometimes conflict-\ning, model outputs into a unified, and reliable\ndecision.\n• Application to Medication Recommendation. We\nevaluate the proposed approach on the clinical\ntask of medication recommendation from patient\nnotes, demonstrating improved accuracy and sta-\nbility over the other ensemble baselines.\n2\nBackground and Related Work\nMulti-LLM collaboration has emerged as a\npromising strategy for improving robustness, rea-\nsoning diversity, and interpretability in LLM-based\nsystems. Instead of relying on a single model,\ncollaborative frameworks such as LLM ensem-\nbles (Du et al., 2023; Yang et al., 2023; Chen\net al., 2025b), Mixture-of-Agents (MoA) (Wang\net al., 2024; Jang et al., 2025), Mixture-of-Domain\nExperts (MoDEM), and Mixture-of-Multimodal-\nAgents (MoMA) (Gao et al., 2025) combine multi-\nple LLMs that exchange, critique, and refine out-\nputs through structured interactions. Each model\ncontributes distinct strengths—ranging from do-\nmain knowledge and factual precision to reasoning\nstyle and linguistic nuance—allowing the ensemble\nto achieve broader domain coverage and reliability\nthan any individual component. Prior work has\nshown that multi-agent coordination enhances fac-\ntuality and cross-domain reasoning through layered\naggregation and verification mechanisms.\nHowever, these collaborative strategies still ex-\nhibit key limitations (Kassem et al., 2025; Badawi\net al., 2025; Li et al., 2025; Chen et al., 2025b;\nJain et al., 2025). Most existing frameworks ex-\nhibit strong positive bias and rely on heuristic or\ntask-specific aggregation without explicitly model-\ning the interaction dynamics between participating\nmodels (Hu et al., 2024). As a result, collaboration\noutcomes often depend on implicit voting or aver-\naging schemes that fail to distinguish when models\nreinforce versus contradict each other. This lack\nof interpretability makes it difficult to understand\nwhether observed gains stem from genuine syn-\nergy or from redundancy among similar reasoning\npaths. Furthermore, multi-LLM ensembles tend to\nincrease computational cost (Ruiz et al., 2025), suf-\nfer from unstable scaling behavior across domains,\nand offer limited guidance on how to optimally pair\nor weight models during inference.\nIn the context of healthcare, where decisions\nrequire transparency, accuracy, and domain di-\nversity, these weaknesses become critical. Tasks\nsuch as clinical summarization, diagnosis, multi-\nmodal data interpretation, or medicine recommen-\ndation demand fine-grained integration of hetero-\ngeneous expertise—from medical language under-\nstanding to quantitative reasoning over laboratory\nor imaging data. Existing multi-LLM systems like\nMoMA (Gao et al., 2025) address this partially by\ncombining modality-specialized agents, yet they\nstill rely on static ensembling mechanisms that\noverlook how model outputs interact or influence\none another during joint reasoning. Without an\nexplicit mechanism to assess these interactions,\nsuch systems risk inconsistent, unreliable outcomes\nacross patient subgroups.\nOur\nChemistry-based\nMulti-LLM\nap-\nproach (Sanchez and Hitaj, 2025) aims to\novercome these limitations through a novel\nmulti-LLM recommendation approach.\nThis\napproach explicitly models the synergistic and\nantagonistic relationships among collaborating\nLLMs. By quantifying and regulating these “bond-\ning” effects, our framework captures how models\ncomplement or counteract each other, leading to\nmore synergistic and reliable collaboration. This\n2\n"}, {"page": 3, "text": "chemistry-inspired formulation provides a princi-\npled way to balance cooperation among LLMs,\nimproving both computation efficiency, reasoning\nfidelity, and domain coverage—an especially\nvital property for healthcare applications where\nthe cost of error is high and trustworthiness is\nparamount. This framework models collaboration\nas a two-stage process of response generation\nand evaluation, a common setup in multi-LLM\ncollaboration frameworks (Du et al., 2023; Madaan\net al., 2023; Zhang et al., 2024).\n2.1\nApproach\nOur multi-LLM collaboration framework operates\nin two stages: (1) Generation and (2) Evaluation.\nThese stages harness the complementary capabili-\nties and independence of multiple LLMs to produce\nand verify medication recommendations from clin-\nical notes. In the generation stage, a user request\nis distributed to a set of response generators, se-\nlected according to one of the sampling strategies\ndescribed in Section 3.3. The number of participat-\ning models N is user-specified; in this work, we\nuse N = 3, the minimum required for majority\nagreement. Each LLM independently generates a\nmedication recommendation, providing distinct rea-\nsoning paths that capture different linguistic, con-\ntextual, and domain biases. This variation forms\nthe basis for cross-model evaluation and consensus\nformation in the next stage.\nThe evaluation stage performs quality control on\nthe generated responses through a combination of\nreview and grading. Each response is anonymously\nreviewed by other LLMs, ensuring balanced and\nindependent assessment without contextual carry-\nover. Every review produces a grade in [0.0, 1.0]\nreflecting the perceived accuracy, relevance, and\ncompleteness of the output.\nWe reinterpret re-\nsponse generation as implicit evaluation, since each\ngenerated output implicitly endorses its own valid-\nity. This unobtrusive mechanism reinforces quality\nassurance without additional overhead. By grad-\ning one another’s outputs, models collectively es-\ntablish a measure of confidence in their recom-\nmendations. To compute aggregate quality and\naccuracy, we adopt a consensus-based estimation\nmethod inspired by the Vancouver crowdsourcing\nalgorithm (de Alfaro and Shavlovsky, 2014) and de-\ntailed in our prior work (Sanchez and Hitaj, 2025).\nTogether, these mechanisms identify high-quality,\nconsensus-backed recommendations and quantify\nthe reliability of each participating model, yielding\nconsistent and trustworthy multi-LLM collabora-\ntion outcomes.\n3\nExperimental Setup\n3.1\nDataset Creation\nOur experiments use a dataset of brief clinical vi-\ngnettes paired with corresponding medication rec-\nommendations. Each vignette is an unstructured\nnote that concisely captures key information from\na patient’s medical record to facilitate communica-\ntion among healthcare providers. In this paper,\nwe use the terms clinical notes and clinical vi-\ngnettes interchangeably. Each recommendation\nincludes labeled fields describing the medication\nname, dosage, route of administration, frequency,\ntiming (e.g., with meals), and the indication or con-\ndition treated. The fields for a single medication\nare linked to form a medication entry, and each rec-\nommendation contains multiple such entries. All\nmedication entries were reviewed and validated by\nour team’s domain expert; entries that could not\nbe confirmed were excluded from the dataset.\nThe dataset comprises 20 records synthesized\nby prompting LLMs to perform a synthesis task in\nreverse—generating plausible clinical vignettes for\ngiven sets of medications. Following the approach\nof Josifoski et al. (Josifoski et al., 2023), we ex-\nploit this asymmetry in task difficulty to produce\nhigh-quality pairs of clinical notes and medication\nrecommendations. This strategy is particularly ef-\nfective for our closed information task, where ob-\ntaining ground truth data is difficult, often inacces-\nsible, or restricted by procedural barriers.\n3.2\nLLMs Considered\nTable 1 lists the LLMs used in this study: ten\nproprietary models—OpenAI’s GPT (OpenAI,\n2025), Anthropic’s Claude (Anthropic, 2025),\nand Google’s Gemini (Google, 2025)—accessed\nthrough their APIs, and four open-source models\naccessed via Ollama (Ollama, 2025). The selection\nspans diverse architectures, resource demands, and\ncapabilities to enrich the resulting ensembles.\n3.3\nLLM Sampling Strategies\nIn line with prior work considering the topic of\nmulti-LLM collaboration, we consider the follow-\ning LLM sampling strategies, i.e., mechanisms for\ndefining the composition of an LLM ensemble:\n(1) REMOTE - closed-source models (e.g., GPT,\nClaude, and Gemini model families), (2) LOCAL -\n3\n"}, {"page": 4, "text": "Table 1 Large Language Models (LLMs) Used\nClosed Source LLMs\nclaude-3-7-sonnet-20250219,\nclaude-opus-4-1,\nclaude-sonnet-4-5, gemini-2.0-flash, gemini-2.5-\nflash, gpt-4o, gpt-5, o1-mini, o3-mini, and o4-mini,\nOpen Source LLMs\nfirefunction-v2, gpt-oss:20b, qwen3:32b, and\nqwen2.5:32b\nopen-weights models, (3) RANDOM - randomly\nselected models (sampled from both REMOTE and\nLOCAL sets), and (4) CHEMISTRY (ours) - mod-\nels recommended by our LLM Chemistry frame-\nwork.\nThe first three strategies follow common prac-\ntices in the literature and approximate realistic de-\nployment scenarios for multi-LLM systems. In\ncontrast, the CHEMISTRY-based strategy aims\nto identify the optimal subset of LLMs that exhibit\nstrong collaborative compatibility (LLM Chem-\nistry) for the target task—recommending medi-\ncations from clinical notes for a specific patient.\nFurther details on the LLM Chemistry formulation\nare provided in our prior work (Sanchez and Hitaj,\n2025).\n3.4\nMetrics\nWe evaluate the proposed multi-LLM recommen-\ndation of medical prescriptions based on the fol-\nlowing set of metrics: (1) Efficiency: capturing\nthe elapsed processing time for each LLM in a hu-\nman readable format, (2) Effectiveness: capturing\nthe accuracy (i.e., effectiveness) of selection strate-\ngies in recommending medical prescriptions using\nthe input (synthetic) clinical notes, (3) Stability:\ncapturing the ability of the selection strategies to\nmaintain consistent performance across task, i.e.,\nquality of results, and (4) Calibration: capturing\nthe degree of alignment among LLMs within an en-\nsemble, i.e., the ability to avoid interference during\ncollaboration.\n3.5\nProtocol\nWe evaluate 4 sampling strategies using LLM con-\nfigurations (ensembles) composed of 3-models,\ni.e., N = 3. We execute each sampling strategy\n(LOCAL, REMOTE, and RANDOM) across 10-\nrecords of patient clinical notes, resulting in ≈90\nanswers, i.e., recommended prescriptions across all\nconfigurations. Note that the exact number varies\ndue to likely execution failures. This is primar-\nFigure 1 Efficiency comparison across sampling strategies.\nThe CHEMISTRY-based multi-LLM ensemble, comprised\nof Claude models achieved an average generation time of 11\nseconds, making it almost 9x faster than the nearest strategy\n(RANDOM), and nearly 49x faster than LOCAL-only ensem-\nbles when recommending medical prescriptions from brief\nclinical vignettes.\nily evident in REMOTE and RANDOM sampling\nstrategies, where communication with the remote\nmodels (e.g., GPT-*, or claude-*) may fail to com-\nplete. Using the results obtained from running LO-\nCAL, REMOTE, and RANDOM sampling strate-\ngies, we then feed such results to our proposed\nLLM-Chemistry approach obtaining recommenda-\ntions for LLM-ensembles of N = 3 exhibiting\nstrong chemistry for the task of medical prescrip-\ntion recommendations. Under the CHEMISTRY\nselection strategy, we then conduct 10 indepen-\ndent trials per LLM ensemble size, adding ≈300\nadditional answers. Performance metrics are aggre-\ngated across tasks within each trial.\n4\nExperimental Results\nAs part of our experimental evaluation syn-\nthetic clinical notes data, we evaluated our LLM\nChemistry-based multi-LLM collaboration ap-\nproach, within the medical prescription recommen-\ndation domain. The evaluation examined four di-\nmensions–efficiency, effectiveness, stability, and\ncalibration of multi-LLM (AI) collaboration–to as-\nsess the performance of the Chemistry-based multi-\nLLM strategy, 2.1. In this section, we present (and\ndescribe) the results for each metric.\n4.1\nEfficiency\nDuring our experiments, we recorded the elapsed\nprocessing time for each LLM execution in a\nhuman readable format. For example, the “o3-\nmini” model, executed using the REMOTE sam-\npling strategy, required 3 minutes and 37 seconds\n4\n"}, {"page": 5, "text": "to generate a medical prescription recommenda-\ntion for a given clinical note.\nAs a reminder,\nthe CHEMISTRY-based strategy (ours) aims to\nselect the most suitable ensemble of LLMs for\na given task, striving not only for high-quality\noutputs but also for efficiency in resource utiliza-\ntion–considering both the models employed and\nthe time required for generation. Such efficiency is\nessential for the practical adoption of multi-LLM\napproaches in medical contexts.\nFigure 1 illustrates the efficiency results. Us-\ning the information generated by the LOCAL, RE-\nMOTE, and RANDOM sampling strategies for the\ncurrent task, the LLM CHEMISTRY framework\nidentified a three-model ensemble as the most ef-\nfective configuration. The selected models were:\n1) claude-3-7-sonnet-20250219, 2) claude-opus-4-\n1, and 3) claude-sonnet-4-5. This ensemble, re-\nferred to as the CHEMISTRY ensemble in this\npaper, was evaluated across 10-clinical notes, each\nexecuted 10 times, and the mean elapsed genera-\ntion time was computed. On average, the CHEM-\nISTRY ensemble produced recommendations in 11\nseconds, which is approximately nine times faster\nthan the RANDOM (94.5s) and REMOTE (97.2s)\nstrategies, and nearly 49-times faster than ensem-\nbles composed exclusively of LOCAL LLMs. This\ndemonstrates a clear efficiency advantage of the\nCHEMISTRY-based multi-LLM approach in medi-\ncal recommendation use cases.\n4.2\nEffectiveness\nWe next evaluate the effectiveness (i.e., the accu-\nracy) of CHEMISTRY-based multi-LLM strategy\nin recommending medical prescriptions for a set of\nclinical notes.\nIn our experiments, the CHEMISTRY ensemble\nachieved an accuracy of 0.78, comparable to the\nREMOTE ensembles (0.84), while outperforming\nall other sampling strategies, Figure 2. Notably,\nthe CHEMISTRY ensemble consists of only re-\nmote models–specifically, Anthropic’s Claude mod-\nels–and incorporates additional factors such as effi-\nciency, as discussed earlier in this section. These re-\nsults indicate that CHEMISTRY-based multi-LLM\nensemble maintains competitive accuracy while\noptimizing for other key metrics such as efficiency.\n4.3\nStability\nStability refers to CHEMISTRY-based ensembles\nability to maintain consistent performance across\nmultiple tasks–in this case, its capacity to gener-\nFigure 2 Effectiveness comparison across sampling strategies.\nThe CHEMISTRY ensemble achieved an accuracy of 0.78,\nclosely matching the REMOTE strategy (0.84) while outper-\nforming other strategies. The ensemble, composed of Claude\nmodels from Anthropic, balances both accuracy and efficiency\nin medical prescription recommendations.\nFigure 3 Stability comparison across sampling strategies. The\nCHEMISTRY ensemble maintained stability comparable to\nREMOTE ensembles while surpassing LOCAL and RAN-\nDOM strategies. Unlike the REMOTE strategy, which exhib-\nited occasional execution failures, the CHEMISTRY strategy\nshowed no failures, providing evidence of its robustness and\nreliability.\nate high-quality medical prescription recommen-\ndations reliably. In our experiments, the CHEM-\nISTRY ensemble demonstrated stability compa-\nrable to multi-LLM ensembles composed of RE-\nMOTE models, while significantly outperforming\nboth LOCAL and RANDOM counterparts, Fig-\nure 3. While failures were observed in some RE-\nMOTE strategy executions, no such failures oc-\ncurred in the CHEMISTRY ensemble, further un-\nderscoring the stability and robustness of its per-\nformance. These findings highlight CHEMISTRY-\nbased multi-LLM ensemble’s ability to deliver con-\nsistent and dependable results across repeated med-\nical recommendation tasks.\n5\n"}, {"page": 6, "text": "Figure 4 Calibration comparison across sampling strategies.\nThe CHEMISTRY ensemble achieved the lowest variance\n(0.05), indicating high inter-model agreement and effective\ncalibration. By contrast, REMOTE and RANDOM ensembles\nexhibited moderate variance (0.11), while LOCAL ensembles\nshowed poor calibration (1.05), reflecting weak consensus\namong constituent LLMs.\n4.4\nCalibration\nCalibration refers to the degree of alignment among\nLLMs within a multi-LLM ensemble — that is, the\nability to avoid interference and error amplification\nduring collaboration. Well-calibrated ensembles\nmaintain consistent confidence and decision crite-\nria, ensuring that differences among models reflect\ngenuine informational diversity rather than noise\nor overconfidence.\nTo evaluate this property, we measured the mean\nvariance of agreement across sampling strategies\n(Figure 4). The CHEMISTRY ensemble achieved\na mean variance of 0.05, substantially lower than\nREMOTE (0.11) ensembles, and far below LO-\nCAL ensembles (1.05). This indicates that models\nselected via the CHEMISTRY strategy are highly\ncalibrated and maintain strong internal consensus\nwhen generating medical prescription recommen-\ndations.\nThese findings suggest that calibration — serv-\ning as a precondition for agreement — enables the\nCHEMISTRY strategy to reduce noise and error\npropagation, ensuring that consensus among LLMs\nemerges from reliable, evidence-aligned reasoning.\n4.5\nSample Outputs\nIn Figure 5, we provide snippets of recommen-\ndations generated by the multi-LLM ensembles\nformed under our CHEMISTRY strategy. All ex-\nperiments were conducted in a zero-shot setting us-\ning synthetic but domain expert–validated clinical\nnotes and recommendations to ensure methodolog-\nical rigor and reproducibility.\nClinical Vignette: Jane Doe is a 72yo female who has\ndiabetes, high cholesterol, heart disease, and chronic pain\nin her knees. She has trouble taking her medications and\nno other concerns.\nMedication Recommendation:\n• Metformin 500 mg PO BID with meals (diabetes).\n• Atorvastatin 20 mg PO daily in evening (high choles-\nterol).\n• Lisinopril 10 mg PO daily (heart disease, diabetes with\nrenal protection).\n• Acetaminophen 650 mg PO q6h PRN (chronic knee\npain).\n• Furosemide 20 mg PO daily in morning (heart disease).\nClinical Vignette: Patient is a 76-year-old white female\nwith a medical history of hypertension, osteoarthritis, os-\nteoporosis, hypothyroidism, allergic rhinitis, and kidney\nstones. She presents today for a refill of her blood pres-\nsure medication. She reports no new concerns, changes in\nher chronic conditions, or symptoms such as fever, chills,\ncough, congestion, nausea, vomiting, chest pain, or chest\npressure.\nMedication Recommendation:\n• Lisinopril 10 mg daily PO (hypertension).\n• Hydrochlorothiazide 25 mg daily PO (hypertension).\n• Amlodipine 5 mg daily PO (hypertension).\n• Levothyroxine 50 mcg daily PO (hypothyroidism).\n• Cetirizine 10 mg daily PO (allergic rhinitis).\nClinical Vignette: The 76-year-old white female patient\npresented for a blood pressure medication refill. She has\na documented history of hypertension, osteoarthritis, os-\nteoporosis, hypothyroidism, allergic rhinitis, and kidney\nstones, as noted during her previous consultation with Doc-\ntor Kumar. No new symptoms or changes in her condition\nwere reported at this visit.\nMedication Recommendation:\n• Lisinopril 10 mg PO daily (hypertension).\n• Levothyroxine 50 mcg PO daily (hypothyroidism).\n• Alendronate 70 mg PO weekly (osteoporosis).\n• Acetaminophen 500 mg PO every 6 hours as needed\n(osteoarthritis).\n• Cetirizine 10 mg PO daily (allergic rhinitis).\nFigure 5 Sample outputs produced by our CHEMISTRY-based\nMulti-LLM Recommendation approach addressing the follow-\ning task: “Recommend Necessary Medical Prescriptions”\n5\nConclusions and Future Work\nThis work demonstrated the feasibility of using\nChemistry-based multi-LLM collaboration to gen-\nerate and recommend medical prescriptions from\nbrief clinical notes.\nOur results show that our\napproach enables efficient, effective, stable, and\ncalibrated multi-AI collaboration. In our exper-\niments, CHEMISTRY-recommended ensembles\nyielded high-quality prescription recommendations\nand consistently matched or outperformed other\nLLM sampling strategies (LOCAL, REMOTE, and\nRANDOM) across these reliability dimensions.\nFuture Work. Our experiments were conducted\non synthetic, domain expert–validated data con-\ntaining limited patient information (e.g., brief clin-\nical notes without accompanying clinical prac-\n6\n"}, {"page": 7, "text": "tice guidelines) and used a zero-shot prompting\nsetup.\nFuture work will extend evaluation to\nlarger, real-world datasets that include richer pa-\ntient context—such as detailed notes, current med-\nications, dosages, and allergy information—to as-\nsess generalizability and clinical safety. Incorpo-\nrating retrieval-augmented generation (RAG) capa-\nbilities into the Chemistry-based multi-LLM Col-\nlaboration approach will further allow ensembles\nto access up-to-date medical knowledge from clini-\ncal practice guidelines and recent publications, im-\nproving grounding and transparency. Despite these\nlimitations, our findings indicate that multi-LLM\ncollaboration guided by LLM Chemistry is a prac-\ntical and reliable approach for healthcare-related\ntasks.\nAcknowledgments\nThis research is based upon work supported in\npart by the Advanced Research Projects Agency\nfor Health (ARPA-H), Defense Logistics Agency\n(DLA) under Contract Number SP4701-23-C-0073.\nAny opinions, findings and conclusions or recom-\nmendations expressed in this material are those of\nthe authors and do not necessarily reflect the views\nof Advanced Research Projects Agency for Health\n(ARPA-H), Defense Logistics Agency (DLA), or\nthe United States Government.\nThe U.S. Gov-\nernment is authorized to reproduce and distribute\nreprints for governmental purposes notwithstand-\ning any copyright annotation therein.\nReferences\nAnthropic. 2025. Models overview - claude docs.\nAbeer Badawi, Elahe Rahimi, Md Tahmid Rahman\nLaskar, Sheri Grach, Lindsay Bertrand, Lames\nDanok, Jimmy Huang, Frank Rudzicz, and Elham\nDolatabadi. 2025. When can we trust llms in men-\ntal health? large-scale benchmarks for reliable llm\nevaluation. arXiv preprint arXiv:2510.19032.\nYupeng Chang, Xu Wang, Jindong Wang, Yuan Wu,\nLinyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi,\nCunxiang Wang, Yidong Wang, and 1 others. 2024.\nA survey on evaluation of large language models.\nACM transactions on intelligent systems and technol-\nogy, 15(3):1–45.\nLingjiao Chen, Jared Quincy Davis, Boris Hanin, Peter\nBailis, Matei Zaharia, James Zou, and Ion Stoica.\n2025a. Optimizing model selection for compound ai\nsystems. arXiv preprint arXiv:2502.14815.\nZhijun Chen, Jingzheng Li, Pengpeng Chen, Zhuoran\nLi, Kai Sun, Yuankai Luo, Qianren Mao, Ming Li,\nLikang Xiao, Dingqi Yang, and 1 others. 2025b. Har-\nnessing multiple large language models: A survey on\nllm ensemble. arXiv preprint arXiv:2502.18036.\nAlex Cloud, Minh Le, James Chua, Jan Betley, Anna\nSztyber-Betley, Jacob Hilton, Samuel Marks, and\nOwain Evans. 2025. Subliminal learning: Language\nmodels transmit behavioral traits via hidden signals\nin data. arXiv preprint arXiv:2507.14805.\nLuca de Alfaro and Michael Shavlovsky. 2014. Crowd-\nGrader: A tool for crowdsourcing the evaluation of\nhomework assignments. In Proceedings of the 45th\nACM technical symposium on Computer science edu-\ncation, pages 415–420.\nYilun Du, Shuang Li, Antonio Torralba, Joshua B Tenen-\nbaum, and Igor Mordatch. 2023. Improving factual-\nity and reasoning in language models through multia-\ngent debate. In Forty-first International Conference\non Machine Learning.\nBehnaz Eslami, Majid Afshar, Samie Tootooni, Timo-\nthy A Miller, Matthew M Churpek, Yanjun Gao, and\nDmitriy Dligach. 2025. Toward digital twins in the\nintensive care unit: a medication management case\nstudy. Journal of the American Medical Informatics\nAssociation, page ocaf127.\nJifan Gao, Mahmudur Rahman, John Caskey, Made-\nline Oguss, Ann O’Rourke, Randy Brown, Anne\nStey, Anoop Mayampurath, Matthew M Churpek,\nGuanhua Chen, and 1 others. 2025.\nMoma: A\nmixture-of-multimodal-agents architecture for en-\nhancing clinical prediction modelling. arXiv preprint\narXiv:2508.05492.\nGoogle. 2025. Gemini models.\nQitian Jason Hu, Jacob Bieker, Xiuyu Li, Nan Jiang,\nBenjamin Keigwin, Gaurav Ranganath, Kurt Keutzer,\nand Shriyash Kaustubh Upadhyay. 2024. Router-\nbench: A benchmark for multi-LLM routing system.\nIn Agentic Markets Workshop at ICML 2024.\nSuryaansh Jain, Umair Z. Ahmed, Shubham Sahai, and\nBen Leong. 2025. Beyond consensus: Mitigating the\nagreeableness bias in llm judge evaluations. Preprint,\narXiv:2510.11822.\nDongsuk Jang, Alan Li, and Arman Cohan. 2025.\nYalenlp@ peranssumm 2025:\nMulti-perspective\nintegration via mixture-of-agents for enhanced\nhealthcare qa summarization.\narXiv preprint\narXiv:2504.03932.\nMartin Josifoski, Marija Sakota, Maxime Peyrard,\nand Robert West. 2023.\nExploiting asymmetry\nfor synthetic training data generation: Synthie and\nthe case of information extraction. arXiv preprint\narXiv:2303.04132.\nAly M Kassem, Bernhard Schölkopf, and Zhijing Jin.\n2025. How robust are router-llms? analysis of the\nfragility of llm routing capabilities. arXiv preprint\narXiv:2504.07113.\n7\n"}, {"page": 8, "text": "Wenzhe Li, Yong Lin, Mengzhou Xia, and Chi Jin. 2025.\nRethinking mixture-of-agents: Is mixing different\nlarge language models beneficial?\narXiv preprint\narXiv:2502.00674.\nZijun Liu, Yanzhe Zhang, Peng Li, Yang Liu, and Diyi\nYang. 2024. A dynamic llm-powered agent network\nfor task-oriented agent collaboration. In First Con-\nference on Language Modeling.\nAman Madaan, Niket Tandon, Prakhar Gupta, Skyler\nHallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon,\nNouha Dziri, Shrimai Prabhumoye, Yiming Yang,\nand 1 others. 2023. Self-refine: Iterative refinement\nwith self-feedback. Advances in Neural Information\nProcessing Systems, 36:46534–46594.\nOllama. 2025. Ollama library.\nOpenAI. 2025. Models - openai api.\nFernando Vallecillos Ruiz, Max Hort, and Leon Moo-\nnen. 2025.\nWisdom and delusion of llm ensem-\nbles for code generation and repair.\nPreprint,\narXiv:2510.21513.\nHuascar Sanchez and Briland Hitaj. 2025. LLM chem-\nistry estimation for multi-llm recommendation. arXiv\npreprint arXiv:2510.03930.\nJunlin Wang, Jue Wang, Ben Athiwaratkun, Ce Zhang,\nand James Zou. 2024. Mixture-of-agents enhances\nlarge language model capabilities. arXiv preprint\narXiv:2406.04692.\nHan Yang, Mingchen Li, Huixue Zhou, Yongkang Xiao,\nQian Fang, and Rui Zhang. 2023. One llm is not\nenough: Harnessing the power of ensemble learning\nfor medical question answering. medRxiv.\nMurong Yue, Jie Zhao, Min Zhang, Liang Du, and Ziyu\nYao. 2024. Large language model cascades with\nmixture of thoughts representations for cost-efficient\nreasoning. Preprint, arXiv:2310.03094.\nYusen Zhang, Ruoxi Sun, Yanfei Chen, Tomas Pfister,\nRui Zhang, and Sercan Arik. 2024. Chain of agents:\nLarge language models collaborating on long-context\ntasks. Advances in Neural Information Processing\nSystems, 37:132208–132237.\nYuyan Zhou, Liang Song, Bingning Wang, and Weipeng\nChen. 2024. Metagpt: Merging large language mod-\nels using model exclusive task arithmetic.\narXiv\npreprint arXiv:2406.11385.\n8\n"}]}