{"doc_id": "arxiv:2512.12868", "source": "arxiv", "lang": "en", "pdf_path": "data/raw/arxiv/pdf/2512.12868.pdf", "meta": {"doc_id": "arxiv:2512.12868", "source": "arxiv", "arxiv_id": "2512.12868", "title": "Counting Clues: A Lightweight Probabilistic Baseline Can Match an LLM", "authors": ["Furong Jia", "Yuan Pu", "Finn Guo", "Monica Agrawal"], "published": "2025-12-14T23:00:10Z", "updated": "2025-12-14T23:00:10Z", "summary": "Large language models (LLMs) excel on multiple-choice clinical diagnosis benchmarks, yet it is unclear how much of this performance reflects underlying probabilistic reasoning. We study this through questions from MedQA, where the task is to select the most likely diagnosis. We introduce the Frequency-Based Probabilistic Ranker (FBPR), a lightweight method that scores options with a smoothed Naive Bayes over concept-diagnosis co-occurrence statistics from a large corpus. When co-occurrence statistics were sourced from the pretraining corpora for OLMo and Llama, FBPR achieves comparable performance to the corresponding LLMs pretrained on that same corpus. Direct LLM inference and FBPR largely get different questions correct, with an overlap only slightly above random chance, indicating complementary strengths of each method. These findings highlight the continued value of explicit probabilistic baselines: they provide a meaningful performance reference point and a complementary signal for potential hybridization. While the performance of LLMs seems to be driven by a mechanism other than simple frequency aggregation, we show that an approach similar to the historically grounded, low-complexity expert systems still accounts for a substantial portion of benchmark performance.", "query": "(cat:cs.CL OR cat:cs.LG) AND (all:\"large language model\" OR all:LLM) AND (all:medical OR all:clinical OR all:healthcare)", "url_abs": "http://arxiv.org/abs/2512.12868v1", "url_pdf": "https://arxiv.org/pdf/2512.12868.pdf", "meta_path": "data/raw/arxiv/meta/2512.12868.json", "sha256": "b708e5d6fce2d98ae450ad07a806b876673773f143ce7eb16c376d2c87f8b24f", "status": "ok", "fetched_at": "2026-02-18T02:24:19.592784+00:00"}, "pages": [{"page": 1, "text": "Counting Clues:\nA Lightweight Probabilistic Baseline Can Match an LLM\nFurong Jia1\nYuan Pu1\nFinn Guo\nMonica Agrawal\nDuke University\nflora.jia@duke.edu\nyuan.pu@duke.edu\nxiaofeng.guo@duke.edu\nmonica.agrawal@duke.edu\nAbstract\nLarge language models (LLMs) excel on\nmultiple-choice clinical diagnosis benchmarks,\nyet it is unclear how much of this performance\nreflects underlying probabilistic reasoning. We\nstudy this through questions from MedQA,\nwhere the task is to select the most likely diag-\nnosis. We introduce the Frequency-Based Prob-\nabilistic Ranker (FBPR), a lightweight method\nthat scores options with a smoothed Naive\nBayes over concept-diagnosis co-occurrence\nstatistics from a large corpus.\nWhen co-\noccurrence statistics were sourced from the pre-\ntraining corpora for OLMo and Llama, FBPR\nachieves comparable performance to the corre-\nsponding LLMs pretrained on that same corpus.\nDirect LLM inference and FBPR largely get dif-\nferent questions correct, with an overlap only\nslightly above random chance, indicating com-\nplementary strengths of each method. These\nfindings highlight the continued value of ex-\nplicit probabilistic baselines: they provide a\nmeaningful performance reference point and a\ncomplementary signal for potential hybridiza-\ntion. While the performance of LLMs seems\nto be driven by a mechanism other than sim-\nple frequency aggregation, we show that an\napproach similar to the historically grounded,\nlow-complexity expert systems still accounts\nfor a substantial portion of benchmark perfor-\nmance.\n1\nIntroduction\nLarge Language models (LLMs) have been used for\ntasks requiring probabilistic reasoning, both direct\ninference and estimation of priors (Paruchuri et al.,\n2024; Feng et al., 2024; Nafar et al., 2025). How-\never, our understanding of probabilistic reasoning\nin LLMs is still nascent. In this work, we study the\nprobabilistic reasoning required to choose the most\nlikely medical diagnosis given a clinical scenario.\n1These authors contributed equally to this work.\nLLMs have achieved high performance across med-\nical benchmarks, leading to speculation that they\npossess advanced clinical reasoning capabilities\n(Kung et al., 2022; Singhal et al., 2022, 2025; Nori\net al., 2023). This narrative is reinforced by claims\nof LLMs achieving diagnostic performance on com-\nplex cases that surpass human experts (McDuff\net al., 2025; Nori et al., 2025). However, a grow-\ning number of works also reveal potential deficien-\ncies in the clinical reasoning and decision-making\nof current LLMs(Chen et al., 2024). For exam-\nple, expert systems such as DxPlain still surpass\nLLMs on unpublished clinical cases for diagnoses\n(Barnett et al., 1987; Berner et al., 1994; Feldman\net al., 2025). This suggests there may be a dis-\nconnect between performance on medical licensing\nexams and true probabilistic reasoning, with re-\nsearch highlighting LLM failures in meta-cognition\n(Griot et al., 2025a), processing new information\nunder uncertainty (McCoy et al., 2025), and align-\ning with the reasoning process of physicians on\nmedical question-answering (Hao et al., 2025).\nBuilding on these observations, a key evalua-\ntion gap is clarifying how much reported accu-\nracy on medical QA benchmarks reflects exploita-\ntion of corpus-level co-occurrence statistics ver-\nsus more structured clinical probabilistic reason-\ning. Widely used biomedical QA benchmarks are\npredominantly knowledge-heavy (67.2% of ques-\ntions across 11 datasets), with models performing\nworse on the reasoning-heavy subsets (Thapa et al.,\n2025). Complementary synthetic evidence shows\nthat LLMs can achieve 64% on a fictional bench-\nmark about an invented organ (Glianorex), while\nphysicians reach only 27% (Griot et al., 2025b),\nindicating that strong scores can arise from lin-\nguistic cues and test-taking heuristics over domain\nknowledge. These patterns suggest revisiting ear-\nlier paradigms that leveraged statistical associa-\ntion, such as earlier clinical decision-support sys-\ntems (CDSS) like DxPlain (Barnett et al., 1987;\n1\narXiv:2512.12868v1  [cs.CL]  14 Dec 2025\n"}, {"page": 2, "text": "Example Problem\nStep 1: Extract Concepts\nQuestion:  \nPatients appears to the hospital with  \nsymptoms A, B, C and a prior history of  D \nand E. What is the most likely diagnosis?\nAnswer choices: \nd1, d2, d3, d4, d5\nExtracted Concepts \nare: A, B, C, D, E\nDiagnosis Counts:\n(occurrence for keyword) \n d1: 43082\nd2: 5279\nd3: 6325\nd4: 361\nd5: 39\nConcept-Diagnosis Counts: \n(co-occurrence for keyword pairs)\n(A, d1): 3091\n(B, d1): 2054\n    ...\n\n(E, d1):2\nCalculate:\nP(di | A, B, C, D, E)\nselect the \nmost likely \ndiagnosis\n...   (A, d5): 13\n...   (B, d5): 20\n...       ...\n\n...       ...\nStep 2: Retrieve Counts from Corpora\nStep 3: Naïve-Bayes Scoring\nsearch in Dolma\n(Pretraining Corpora for OLMo)\nP(A|di) P(B|di) ... P(E|di) P(di)\n(assume independence)\nFigure 1: Frequency-Based Probabilistic Ranker: (1) concept extraction from the question, (2) corpus frequency\nretrieval, and (3) calculate a Naive-Bayes scoring to select the most likely diagnosis.\nBerner et al., 1994). DxPlain combines computer-\ninterpretable clinical guidelines with an expert-\ndesigned, data-refinable Bayesian network to pro-\nvide probabilistic, patient-specific decision support.\nAs previously mentioned, it could even surpass\nLLMs on unpublished clinical cases (Nee and Hein,\n2010; Elkin et al., 2010; Bauer et al., 2002; Feld-\nman et al., 2025).\nBeyond medicine, recent work leverages LLM-\nderived probabilities for Bayesian reasoning, either\naligning Bayesian networks with LLM-abduced\nfactors (BIRD) (Feng et al., 2024) or eliciting\nconditional probabilities to parameterize Bayesian\nNetworks (Nafar et al., 2025).Therefore, here we\nwould like to investigate how much a coarser,\nlow-complexity, and transparent, frequency-based\nmethod applied directly to an LLM’s pretraining\ncorpus can achieve on diagnosis questions. There-\nfore, we introduce a simple Frequency-Based\nProbabilistic Ranker (FBPR) that eschews com-\nplex reasoning (Figure 1). Our method models\ndiagnosis using a Naive Bayes-like probability de-\nrived from the co-occurrence frequency of diag-\nnosis and clinical concepts from large-scale pre-\ntraining corpora, Dolma (Soldaini et al., 2024)\nand RedPajama (Weber et al., 2024). We evaluate\nFBPR on a diagnostic subset of MEDQA-USMLE,\na dataset that consists of United States Medical\nLicensing Examination-style multiple-choice ques-\ntions (Jin et al., 2021). We also evaluate OLMo\nInstruct 7B(Groeneveld et al., 2024), an open-\nweight instruction-finetuned LLM pretrained on\nthe Dolma corpus, and LLaMA 65B(Touvron et al.,\n2023a), which is pretrained on the RedPajama cor-\npus, for performance comparison with FBPR ap-\nplied on their respective pretraining corpora. We\nfound that Dolma-based FBPR achieved an accu-\nracy (46.7%) substantially above random chance\n(20%) and closely matched OLMo Instruct (44.1%).\nSimilar results were obtained from FBPR based\non RedPajama (44.5%) and LLaMA 65B (47.0%).\nPredictions from FBPR and LLMs are found to\nbe complementary, highlighting the potential bene-\nfits of combining simple statistical and LLM-based\napproaches.\n2\nMethodology\n2.1\nData and Task Formulation\nWe evaluate on two transparent corpus-model pairs:\n(1) Dolma and OLMo Instruct 7B, and (2) Red-\nPajama and LLaMA 65B. OLMo Instruct 7B\nis pretrained on the Dolma corpus and further\ninstruction-tuned for instruction following abilities.\nLLaMA-65B is a substantially larger LLM pre-\ntrained on RedPajama and shows usable instruction-\nfollowing on MedQA. This transparency enables a\nfair, corpus-aligned comparison between our statis-\ntical method and the LLM baselines.\nWe focus on a diagnosis subset of the MEDQA\nbenchmark (n = 719; details in Appendix A),\nwhich was not included in Dolma, instruction-\ntuning dataset for OLMo Instruct, or RedPajama.\nEach question consists of a patient scenario fol-\nlowed by a prompt for the most likely diagnosis and\nfive candidate diagnoses D = {d1, d2, d3, d4, d5}.\nWe use the five-option version to match the setting\nof the actual US medical licensing exam, and the\ngoal is to predict the most likely diagnosis d⋆∈D\nfrom the scenario description.\nOut of these 719 questions, 256 are from the\nStep 1 domain of the US medical licensing exam,\nwhich focuses on basic science knowledge, and 463\nare from the Step 2&3, which emphasize clinical\nreasoning and patient management. It is widely\nrecognized that, while Step 1 emphasizes factual\nrecall, Steps 2&3 require an application of knowl-\nedge through clinical reasoning and therefore de-\nmand stronger reasoning ability (Jin et al., 2021).\n2.2\nFrequency-Based Probabilistic Ranker\nOur pipeline proceeds through the three stages de-\npicted in Fig. 1 and detailed below:\nStage 1: concept extraction\nFor each question,\nwe prompt the GPT-4o to extract k concise (each\n≤4 words) clinical concepts x = {x1, . . . , xk}\n2\n"}, {"page": 3, "text": "that were emphasized in the presented clinical sce-\nnario. The prompt omits any mention of diagnosis\nto avoid bias toward selectively “diagnostic\" fea-\ntures and instead aims to obtain an objective set of\nsymptoms mentioned. We further ask GPT-4o to\nlabel each extracted concept with whether it is men-\ntioned positively or negated. The prompt can be\nfound in Appendix B, with examples of extracted\nconcepts in Appendix F.3.\nStage 2: corpus frequency retrieval\nWe lever-\nage Infini-gram (Liu et al., 2024), an efficient tool\nfor querying token and phrase frequencies in mas-\nsive corpora, to obtain from Dolma or RedPajama\n• the number of occurrences of candidate diagnosis\nd as C(d), and\n• the number of co-occurrences of candidate di-\nagnosis d along with extracted concept xi as\nC(d, xi).\nWe also expand each candidate diagnosis and\nextracted concept by their variations in spacing\nand capitalized version to account for the fact that\nInfini-gram performs tokenization before searching.\nMore details are in Appendix C.\nStage 3: Naive-Bayes scoring\nAssuming con-\ncept independence and their conditional indepen-\ndence given each candidate diagnosis, we estimate\nthe posterior P(d | x1, . . . , xk) for each candidate\ndiagnosis and choose the one with the highest prob-\nability given the extracted concepts.\nLet d ∈D and abbreviate x = {x1, . . . , xk}.\nP(d | x) = P(x | d) P(d)\nP(x)\n(1)\n=\nhQk′\ni=1 P(xi | d)\ni\nP(d)\nP(x)\n(2)\n≈\nhQk′\ni=1\nC′(d,xi)\nC(d)\ni\nC(d)\nN\nP(x)\n(3)\n= C(d)−(k′−1)\nN · P(x)\n\" k′\nY\ni=1\nC′(d, xi)\n#\n.\n(4)\nStep (2) is based on the naive conditional-\nindependence assumption. Step (3) substitutes em-\npirical estimates P(xi | d) ≈C′(d, xi)/C(d) and\nP(d) ≈C(d)/N, where N is the total token count\nof the pre-training corpus.\nGiven the affirmation/negation label, we took\nC′(d, xi) = C(d, xi) for every (candidate diag-\nnosis, affirmed concept) pair and excluded the\nnegated concepts from the score calculation. k′\nthus equaled the number of affirmed concepts in\neach question.\nThe denominator N · P(x) does not depend on\nd and is dropped in the calculation of the score\nfor comparing candidate diagnoses. With Laplace\nsmoothing (δ > 0) and a logarithm, we have the\nscore for each candidate diagnosis as\nSd =\nk′\nX\ni=1\nlog\n\u0000C′(d, xi) + δ\n\u0001\n−(k′ −1) log (C(d) + δ)\nand the answer by FBPR is the candidate diagnosis\nwith the highest score within each question:\nˆd = argmaxd∈DSd.\n3\nResults\n3.1\nFBPR Performance\nMethod\nAccuracy\nRandom Chance\n20%\nFBPR on Dolma\n46.7%\nOLMo Instruct 7B\n44.1%\nFBPR on RedPajama\n44.5%\nLLaMA 65B\n47.0%\nTable 1: Prediction accuracy on five-option MEDQA\ndiagnosis subset (n = 719).\nk=5\nWe prompted GPT-4o to identify five con-\ncepts from each MEDQA question and assign each\nconcept an affirmation or negation label. 16 of the\n719 questions contained negated concepts (details\nsee Appendix B).\nWith k=5, Dolma-based FBPR ranked the cor-\nrect diagnosis highest ( ˆd = d⋆, i.e., made correct\npredictions) in 336 questions, corresponding to an\naccuracy of 46.7% while RedPajama-based FBPR\nachieved 44.5% accuracy (Table 1). The correct\ndiagnosis is most frequently assigned the highest\nrank by FBPR, with progressively fewer instances\nreceiving ranks 2 through 5 (Figure 2). The ob-\nserved monotonic pattern indicates that this simple\nfrequency-based method appears to capture clin-\nically meaningful links between presenting con-\ncepts and diagnoses. The same pattern holds for\nRedPajama-based FBPR (Figure 5.\nDolma-based FBPR correctly identified the most\nlikely diagnosis for 51% of Step 1 questions but\nonly 44.3% of Step 2&3 questions (Table 2 in Ap-\npendix). This difference likely reflects the heavier\nmulti-step reasoning demands of Step 2&3, where\nFBPR’s occurrence frequency-based reasoning is\n3\n"}, {"page": 4, "text": "less effective. However, the gap is modest, sug-\ngesting that even simple frequency-based Bayesian\nstrategies can account for a notable portion of per-\nformance often attributed to complex reasoning.\nWe further explored the relationship between\nFBPR’s internal certainty and its actual correct-\nness by using the top-1 scores softmaxed within\neach question as a proxy for certainty (Figure 6 in\nAppendix). For Dolma-based FBPR, correctly pre-\ndicted questions have higher softmaxed top scores\ncompared to incorrectly predicted ones (median\n0.94 vs. 0.86). 27.4% of questions are with a soft-\nmaxed highest score exceeding 0.99; the accuracy\nof FBPR on these questions is 59.4%, higher than\nthe general 46.7% achieved on the full dataset.\n1\n2\n3\n4\n5\nRank of the correct answer\n0\n100\n200\n300\nNumber of questions\n336\n170\n91\n80\n42\nd = d\nFigure 2: Distribution of the rank of the correct diagno-\nsis of each question by Dolma-based FBPR with k = 5.\nUnrestricted k\nWe also experimented prompt-\ning GPT-4o without a restriction on k (details see\nAppendix B). Under this setting, FBPR on Red-\nPajama achieved an accuracy of 40.9%. Its rank\ndistribution follows the same decreasing pattern\nas under k = 5 (Figure 5 in Appendix) and has a\nslightly higher performance on Step 2&3 than Step\n1 (Table 2 in Appendix).\n3.2\nAlignment with LLM Performance\nTo assess alignment with a model trained on the\nsame underlying distribution, we compare the\nDolma-based FBPR to OLMo Instruct 7B (pre-\ntrained on the Dolma corpora) and the RedPajam-\nbased FBPR to LLaMA 65B, both under a zero-\nshot setting (details in Appendix D).\nDolma-based FBPR and OLMo Instruct are both\ncorrect on 24.8% of questions. This observed joint\naccuracy is slightly higher than the expected joint\nsuccess of around 44.1% × 46.7% ≈20.6% under\nan independence assumption. This indicates that\nthe methods are only mildly correlated. FBPR\nalone is correct on 21.9% of questions, and OLMo\nalone on 19.3%.\nAcross the diagnostic subset, the two methods\ngive exactly the same answer to 38.3% of the ques-\ntions (shown as the diagonal in Figure 3). 64.7%\nof these agreed answers are correct. This indicates\nthat inter-method agreement is a helpful reliability\ncue. The same pattern appeared in the compari-\nson of RedPajama-based FBPR and LLaMA 65B\n(Appendix F.1).\nA\nB\nC\nD\nE\nOLMo Instruct 7B Predictions\nA\nB\nC\nD\nE\nFBPR Predictions\n77\n33\n22\n17\n7\n27\n65\n25\n18\n10\n21\n37\n59\n16\n9\n33\n33\n23\n45\n9\n37\n24\n22\n21\n29\nConfusion Matrix: FBPR vs OLMo Instruct 7B\n10\n20\n30\n40\n50\n60\n70\nFigure 3: Confusion matrix between the Dolma-based\nFBPR and OLMo Instruct 7B predictions on MEDQA\ndiagnosis subset.\nWhile the performance of LLMs appears to be\ndriven by mechanisms beyond simple frequency\naggregation, we show that a historically grounded,\nlow-complexity expert-system–style method based\non their pretraining corpora statistics accounts for\na substantial portion of benchmark performance.\nAs the two methods’ signals only partially overlap,\nFBPR has the potential to offer complementary\ndiagnostic information to LLMs, motivating hybrid\napproaches to provide better diagnosis, robustness,\nand more evidence-supported decision-making.\n4\nDiscussion and Future Work\nOur simple frequency-based concept–diagnosis\nco-occurrence method attains accuracy on MEDQA\ndiagnostic questions comparable to LLMs pre-\ntrained on the same corpora, indicating that surface\ndistributional priors can account for a substantial\nportion of benchmark performance. Despite simi-\nlar accuracy, the LLM appears to exploit different\nmechanisms over the same corpus and thus offers\ncomplementary signals.\nOur baseline in this work is quite naive: it per-\nforms no synonym or semantic normalization (e.g.,\n“high blood pressure,” “elevated blood pressure,”\nand “hypertension” remain separate), which could\nfurther improve its scores. Next steps also include\ndeveloping probes that can better distinguish mem-\norized pattern retrieval from genuine reasoning.\n4\n"}, {"page": 5, "text": "Limitations\nOur analysis targets a diagnosis-focused subset of\nMEDQA, and the concept set is extracted by an ex-\nternal LLM, making results sensitive to prompting\nand extraction choices. Frequency estimates are\nobtained via Infini-gram (Liu et al., 2024), which re-\nturns occurrence-level (rather than document-level)\ncounts and approximates very frequent strings; pre-\ncise document-level co-occurrence is deferred due\nto resource constraints. We further limit evaluation\nto two transparent corpus–model pairs: (1) Dolma\nand OLMo Instruct 7B, (2) RedPajama and LLaMA\n65B. Neither is state-of-the-art on this benchmark\nand thus may not reflect the frontier of LLM per-\nformance. Nonetheless, our aim is not to introduce\na high-performing system but to isolate how far an\nexplicit, low-complexity probabilistic baseline can\ngo using pretraining corpus statistics.\nEthics Statement\nIn writing this paper, we used an AI assistant to cor-\nrect grammatical errors. During the coding process,\nwe utilized AI tools for code completion.\nReferences\nG Octo Barnett, James J Cimino, Jon A Hupp, and Ed-\nward P Hoffer. 1987. Dxplain: an evolving diagnostic\ndecision-support system. Jama, 258(1):67–74.\nBrent A Bauer, Mark Lee, Larry Bergstrom, Dietlind L\nWahner-Roedler, John Bundrick, Scott Litin, Edward\nHoffer, Richard J Kim, Kathleen Famiglietti, G Octo\nBarnett, and 1 others. 2002. Internal medicine resi-\ndent satisfaction with a diagnostic decision support\nsystem (dxplain) introduced on a teaching hospital\nservice. In Proceedings of the AMIA Symposium,\npage 31.\nEta S Berner, George D Webster, Alwyn A Shugerman,\nJames R Jackson, James Algina, Alfred L Baker,\nEugene V Ball, C Glenn Cobbs, Vincent W Dennis,\nEugene P Frenkel, and 1 others. 1994. Performance\nof four computer-based diagnostic systems. New\nEngland Journal of Medicine, 330(25):1792–1796.\nCanyu Chen, Jian Yu, Shan Chen, Che Liu, Zhong-\nwei Wan, Danielle Bitterman, Fei Wang, and Kai\nShu. 2024. Clinicalbench: Can llms beat traditional\nml models in clinical prediction?\narXiv preprint\narXiv:2411.06469.\nPeter L Elkin, Mark Liebow, Brent A Bauer, Swarna\nChaliki, Dietlind Wahner-Roedler, John Bundrick,\nMark Lee, Steven H Brown, David Froehling, Kent\nBailey, and 1 others. 2010. The introduction of a di-\nagnostic decision support system (dxplain™) into the\nworkflow of a teaching hospital service can decrease\nthe cost of service for diagnostically challenging di-\nagnostic related groups (drgs). International journal\nof medical informatics, 79(11):772–777.\nMitchell J Feldman, Edward P Hoffer, Jared J Conley,\nJaime Chang, Jeanhee A Chung, Michael C Jernigan,\nWilliam T Lester, Zachary H Strasser, and Henry C\nChueh. 2025. Dedicated ai expert system vs gen-\nerative ai with large language model for clinical\ndiagnoses. JAMA Network Open, 8(5):e2512994–\ne2512994.\nYu Feng, Ben Zhou, Weidong Lin, and Dan Roth.\n2024. Bird: A trustworthy bayesian inference frame-\nwork for large language models.\narXiv preprint\narXiv:2404.12494.\nMaxime Griot, Coralie Hemptinne, Jean Vanderdonckt,\nand Demet Yuksel. 2025a. Large language models\nlack essential metacognition for reliable medical rea-\nsoning. Nature communications, 16(1):642.\nMaxime Griot, Jean Vanderdonckt, Demet Yuksel, and\nCoralie Hemptinne. 2025b. Pattern recognition or\nmedical knowledge?\nthe problem with multiple-\nchoice questions in medicine. In Proceedings of the\n63rd Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers), pages\n5321–5341.\nDirk Groeneveld, Iz Beltagy, Evan Walsh, Akshita\nBhagia, Rodney Kinney, Oyvind Tafjord, Ananya\n5\n"}, {"page": 6, "text": "Jha, Hamish Ivison, Ian Magnusson, Yizhong Wang,\nShane Arora, David Atkinson, Russell Authur, Khy-\nathi Chandu, Arman Cohan, Jennifer Dumas, Yanai\nElazar, Yuling Gu, Jack Hessel, and 24 others. 2024.\nOLMo: Accelerating the science of language mod-\nels. In Proceedings of the 62nd Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers), pages 15789–15809, Bangkok,\nThailand. Association for Computational Linguistics.\nYuexing Hao, Kumail Alhamoud, Hyewon Jeong, Hao-\nran Zhang, Isha Puri, Philip Torr, Mike Schaeker-\nmann, Ariel D Stern, and Marzyeh Ghassemi. 2025.\nMedpair: Measuring physicians and ai relevance\nalignment in medical question answering.\narXiv\npreprint arXiv:2505.24040.\nDaniel P Jeong, Saurabh Garg, Zachary C Lipton, and\nMichael Oberst. 2024. Medical adaptation of large\nlanguage and vision-language models: Are we mak-\ning progress? arXiv preprint arXiv:2411.04118.\nDi Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng,\nHanyi Fang, and Peter Szolovits. 2021. What disease\ndoes this patient have? a large-scale open domain\nquestion answering dataset from medical exams. Ap-\nplied Sciences, 11(14):6421.\nTiffany H. Kung, Morgan Cheatham, Arielle Medenilla,\nCzarina Sillos, Lorie De Leon, Camille Elepaño,\nMaria Madriaga, Rimel Aggabao, Giezel Diaz-\nCandido, James Maningo, and Victor Tseng. 2022.\nPerformance of chatgpt on usmle: Potential for ai-\nassisted medical education using large language mod-\nels. PLOS Digital Health, 2.\nJiacheng Liu, Sewon Min, Luke Zettlemoyer, Yejin\nChoi, and Hannaneh Hajishirzi. 2024. Infini-gram:\nScaling unbounded n-gram language models to a tril-\nlion tokens. arXiv preprint arXiv:2401.17377.\nLiam G McCoy, Rajiv Swamy, Nidhish Sagar, Min-\njia Wang, James Cao, Stephen Bacchi, Nigel Fong,\nNigel CK Tan, Kevin Tan, Thomas A Buckley, and 1\nothers. 2025. Do language models think like doctors?\nmedRxiv, pages 2025–02.\nDaniel McDuff, Mike Schaekermann, Tao Tu, Anil\nPalepu, Amy Wang, Jake Garrison, Karan Singhal,\nYash Sharma, Shekoofeh Azizi, Kavita Kulkarni, and\n1 others. 2025. Towards accurate differential diag-\nnosis with large language models. Nature, pages\n1–7.\nAliakbar Nafar, Kristen Brent Venable, Zijun Cui,\nand Parisa Kordjamshidi. 2025. Extracting proba-\nbilistic knowledge from large language models for\nbayesian network parameterization. arXiv preprint\narXiv:2505.15918.\nOliver Nee and Andreas Hein. 2010. Clinical decision\nsupport with guidelines and bayesian networks. De-\ncision Support Systems, Advances in, Book, editor\nGer Devlin, pages 117–137.\nHarsha Nori, Mayank Daswani, Christopher Kelly, Scott\nLundberg, Marco Tulio Ribeiro, Marc Wilson, Xi-\naoxuan Liu, Viknesh Sounderajah, Jonathan Carlson,\nMatthew P Lungren, and 1 others. 2025. Sequen-\ntial diagnosis with language models. arXiv preprint\narXiv:2506.22405.\nHarsha Nori, Nicholas King, S. McKinney, Dean Carig-\nnan, and E. Horvitz. 2023. Capabilities of gpt-4 on\nmedical challenge problems. ArXiv, abs/2303.13375.\nAkshay Paruchuri, Jake Garrison, Shun Liao, John Her-\nnandez, Jacob Sunshine, Tim Althoff, Xin Liu, and\nDaniel McDuff. 2024. What are the odds? language\nmodels are capable of probabilistic reasoning. arXiv\npreprint arXiv:2406.12830.\nK. Singhal, Shekoofeh Azizi, T. Tu, S. Mahdavi, Jason\nWei, Hyung Won Chung, Nathan Scales, A. Tan-\nwani, H. Cole-Lewis, S. Pfohl, P. Payne, Martin G.\nSeneviratne, P. Gamble, C. Kelly, Nathaneal Scharli,\nA. Chowdhery, P. A. Mansfield, B. A. Y. Arcas,\nD. Webster, and 11 others. 2022. Large language\nmodels encode clinical knowledge. Nature, 620:172\n– 180.\nKaran Singhal, Tao Tu, Juraj Gottweis, R. Sayres, Ellery\nWulczyn, Mohamed Amin, Le Hou, Kevin Clark,\nStephen R. Pfohl, Heather Cole-Lewis, Darlene Neal,\nQ. Rashid, Mike Schaekermann, Amy Wang, Dev\nDash, Jonathan H. Chen, Nigam H. Shah, Sami Lach-\ngar, P. Mansfield, and 16 others. 2025. Toward expert-\nlevel medical question answering with large language\nmodels. Nature Medicine, 31:943 – 950.\nLuca Soldaini, Rodney Kinney, Akshita Bhagia, Dustin\nSchwenk, David Atkinson, Russell Authur, Ben\nBogin, Khyathi Chandu, Jennifer Dumas, Yanai\nElazar, Valentin Hofmann, Ananya Jha, Sachin Ku-\nmar, Li Lucy, Xinxi Lyu, Nathan Lambert, Ian Mag-\nnusson, Jacob Morrison, Niklas Muennighoff, and 17\nothers. 2024. Dolma: an open corpus of three trillion\ntokens for language model pretraining research. In\nProceedings of the 62nd Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers), pages 15725–15788, Bangkok, Thai-\nland. Association for Computational Linguistics.\nRahul Thapa, Qingyang Wu, Kevin Wu, Harrison Zhang,\nAngela Zhang, Eric Wu, Haotian Ye, Suhana Bedi,\nNevin Aresh, Joseph Boen, and 1 others. 2025. Dis-\nentangling reasoning and knowledge in medical large\nlanguage models. arXiv preprint arXiv:2505.11462.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal\nAzhar, and 1 others. 2023a. Llama: Open and ef-\nficient foundation language models. arXiv preprint\narXiv:2302.13971.\nHugo Touvron, Louis Martin, Kevin Stone, Peter Al-\nbert, Amjad Almahairi, Yasmine Babaei, Nikolay\nBashlykov, Soumya Batra, Prajjwal Bhargava, Shruti\n6\n"}, {"page": 7, "text": "Bhosale, and 1 others. 2023b. Llama 2: Open foun-\ndation and fine-tuned chat models. arXiv preprint\narXiv:2307.09288.\nMaurice Weber, Daniel Y. Fu, Quentin Anthony,\nYonatan Oren, Shane Adams, Anton Alexandrov,\nXiaozhong Lyu, Huu Nguyen, Xiaozhe Yao, Vir-\nginia Adams, Ben Athiwaratkun, Rahul Chalamala,\nKezhen Chen, Max Ryabinin, Tri Dao, Percy Liang,\nChristopher Ré, Irina Rish, and Ce Zhang. 2024. Red-\npajama: an open dataset for training large language\nmodels. NeurIPS Datasets and Benchmarks Track.\n7\n"}, {"page": 8, "text": "A\nDiagnosis subset formation\nThe MEDQA benchmark is a collection of United States Medical Licensing Examination (USMLE)-style\nquestions. Each question stem consists of a clinical vignette describing a patient scenario, followed by a\nquery that typically requires identifying the most likely diagnosis, the appropriate next step in management,\nor a related clinical decision. We used the version where each question provides five candidate answer\noptions, exactly one of which is correct.\nWe focus on diagnosis-related questions in the MEDQA training set. We first identified questions in\nwhich the query (the last sentence of the question stem) explicitly contains the word “diagnosis”. After\nconverting all query text to lowercase, we found and kept questions with the top two most common\nphrasings: “which of the following is the most likely diagnosis?” (588 questions) and “what is the most\nlikely diagnosis?” (131 questions). This query sentence in each question was stripped before feeding the\nclinical scenario into GPT-4o for concept extraction and labeling.\nB\nConcept extraction and labeling\nFor both concept extraction and affirmation/negation labeling, we queried the GPT-4o API with\ntemperature set to 0.0 and top_logprobs set to 0, ensuring mostly deterministic outputs. Example\nextracted concepts and labels can be found in Appendix F.3.\nB.1\nk=5\nWe prompted GPT-4o for concept extraction with a system prompt\n\"You are a medical expert who extracts the five most informative clinical concepts from each\npassage.\"\nand a query prompt encodes both the number of concepts to extract (n=5) and the question stem\n(cleaned_question), excluding the trailing query such as “What is the most likely diagnosis?”.\nGiven the passage below, list exactly {n} canonical **clinical** concepts.\nRules for each concept:\n• Must be clinically relevant (symptom, physical sign, diagnosis, or treatment).\n• Prefer the passage’s wording **if** it is already ≤4 words; otherwise shorten or normalize to a\nstandard term ≤4 words (no numbers or strength grades).\n• Skip generic exam words and any term containing the stems: exam, test, lab, imaging, manage,\nwork-up.\n• The term itself must not contain a comma.\nOutput formatting:\nlower-case, comma-separated list of exactly {n} concepts, with no\nother text.\nPassage:\n{cleaned_question}\nThen the extracted concepts (keywords) along with the cleaned question stem (question_text) are\nsent to GPT-4o for affirmation/negation labeling in a query prompt\nQuestion:\nquestion_text\nKeywords (comma-separated, KEEP ORDER):\n8\n"}, {"page": 9, "text": "’, ’.join(keywords)\nReturn the single required line exactly as specified.\nalongside a system prompt\nYou are a precise medical NLP assistant tagging keyword polarity for MedQA-style prompts.\nTask:\nGiven a MedQA question text and an ordered, comma-separated list of keywords, decide for EACH\nkeyword whether it is affirmed/present/tested (“positive”) or explicitly denied/absent/ruled-out\n(“negative”) based ONLY on the question text.\nRules:\n- “positive” if the question affirms/treats the keyword as present/relevant/tested or as a correct/true\noption.\n- “negative” ONLY if the question explicitly negates or rules it out (e.g., “NOT”, “EXCEPT”,\n“absent”, “no evidence of”, “which is NOT”).\n- If merely mentioned (no explicit negation), label “positive”.\n- Be careful with NOT/EXCEPT questions: items asked for as NOT/EXCEPT are “negative”.\n- Judge strictly from the given text; do not add outside knowledge.\nOutput FORMAT (STRICT):\nReturn a SINGLE LINE string containing EXACTLY one item per keyword in the SAME ORDER,\nseparated by comma+space,\neach item in the form “<keyword>: positive” or “<keyword>: negative”.\nDo NOT add any extra text, quotes, explanations, or newlines.\n16 out of 719 MEDQA diagnosis subset questions contain negated concepts (15 with a single negation\nand 1 with two).\nB.2\nNo restriction on k\nWe also explored with prompting GPT-4o without restricting k for concept extraction. Specifically, “five”\nin the concept extraction system prompt and “exactly {n}” in the query prompt were omitted. GPT-4o\nreturned a varying k across questions with a median (IQR) of 9 (7, 11) (Figure 4). 44 questions had\nnegated concepts (30 with a single negated concept, 6 with two, 7 with three, and 1 with five).\nC\nInfini-gram usage\nInfini-gram provides a large-scale n-gram index that enables fast retrieval of occurrence and co-occurrence\nstatistics from web-scale corpora. It performs search at the token level, converting input words or phrases\ninto tokens before counting their occurrences. Variations such as the presence of a leading space and\nlowercase versus capitalized forms influence how tokens are generated and therefore affect the returned\ncounts. Our interest, however, lies in the frequency of candidate diagnoses or (candidate diagnosis,\nconcept) pairs in a case-agnostic and position-agnostic manner. To address this, we generated four\nsurface-form variations for each candidate diagnosis or concept (original, leading space, all lowercase,\n9\n"}, {"page": 10, "text": "2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n29\nNumber of Concepts (k)\n0\n20\n40\n60\n80\nNumber of Questions\nFigure 4: Distribution of the number of concepts per question extracted by GPT-4o when prompt contains no\nrestriction.\nand first-letter capitalized) and combined them using an OR clause, i.e.,\ntext_original OR\ntext_original_leading_space OR\ntext_all_lowercase OR\ntext_all_lowercase_leading_space OR\ntext_capitalized OR\ntext_capitalized_leading_space.\nOR clauses are supported by Infini-gram to obtain aggregated occurrence counts for the OR connected\ncomponents, and thus help return our desired occurrence frequency of candidate diagnoses.\nTo obtain co-occurrence of a candidate diagnosis and a concept, we feed Infini-gram with a clause\nconnecting their OR clauses with an AND operator, i.e.,\n(\ndiagnosis_original OR\ndiagnosis_original_leading_space OR\ndiagnosis_all_lowercase OR\ndiagnosis_all_lowercase_leading_space OR\ndiagnosis_capitalized OR\ndiagnosis_capitalized_leading_space\n) AND (\nconcept_original OR\nconcept_original_leading_space OR\nconcept_all_lowercase OR\nconcept_all_lowercase_leading_space OR\nconcept_capitalized OR\nconcept_capitalized_leading_space).\nNote that we de-duplicate the text variations before connecting them in OR clause. For most words\nor phrases, there are four unique variants: all-lowercase with and without a leading space, and initial-\ncapitalized with and without a leading space. Some text, for example the ones with internal capitalization,\n10\n"}, {"page": 11, "text": "have more than four variations created by our algorithm. A related complication is that Infini-gram\nsupports OR clauses with at most four components, which requires splitting the query into multiple OR\nclauses or OR–AND clauses. For the former, a summation of individual OR clause count is sufficient for\nthe overall count; for the latter, we apply inclusion–exclusion to compute the counts.\nBy Infini-gram design, the occurrences of clauses connected by AND can only be examined within a\nwindow of 1000 tokens at maximum. When any clause connected by AND has an occurrence frequency\nlarger than 500000, the returned co-occurrence frequency is an estimate.\nWe used two indices provided by Infini-gram:\n• v4_dolma-v1_7_llama: Dolma-v1.7 corpus tokenized by LLaMA-2 (Touvron et al., 2023b) consists\nof 3,403,336,408 documents and 2,604,642,372,173 tokens.\n• v4_rpj_llama_s4: Red Pajama corpus tokenized by LLaMA-2 consists of 931,361,530 documents\nand 1,385,942,948,192 tokens.\nD\nLarge language models evaluation\nWe performed zero-shot prompting to get LLM prediction of most-likely diagnosis. Below is an example\nquery for LLM:\nQuestion: A 70-year-old man comes to the physician for the evaluation of an 8-week history\nof blood in his stool. Two months ago, he had an episode of bronchitis and was treated with\namoxicillin. Since then, he has noticed blood in his stool and on the toilet paper occasionally.\nThe patient has had intermittent constipation for the past 5 years. Six months ago, he had\nsevere left lower quadrant pain and fever that resolved with antibiotic therapy. He underwent a\ncolonoscopy 3 years ago, which did not show any evidence of malignancy. He takes levothyroxine\nfor hypothyroidism. He had smoked one pack of cigarettes daily for 45 years, but quit smoking 10\nyears ago. He drinks one glass of red wine every night. He appears pale. He is 180 cm (5 ft 11\nin) tall and weighs 98 kg (216 lb); BMI is 32 kg/m2. His temperature is 36°C (96.8°F), pulse is\n85/min, and blood pressure is 135/80 mm Hg. Physical examination shows pale conjunctivae.\nCardiopulmonary examination shows no abnormalities. The abdomen is soft and nontender with\nno organomegaly. Digital rectal examination shows no masses. Test of the stool for occult blood is\npositive. Laboratory studies show:\nHemoglobin 11 g/dL\nMean corpuscular volume 76 µm3\nRed cell distribution width 17% (N = 13–15)\nLeukocyte count 5,000/mm3\nWhich of the following is the most likely diagnosis?\"\nOptions:\nA: Colorectal carcinoma\nB: Diverticulosis\nC: Ischemic colitis\nD: Hemorrhoids\nE: Pseudomembranous colitis\nAnswer:\nOLMo_Instruct_0724 generated the following output in response to the query above:\nB: Diverticulosis\nExplanation:\n11\n"}, {"page": 12, "text": "The patient’s history of intermittent constipation, positive occult blood test, and the ab-\nsence of any evidence of malignancy on previous colonoscopy make diverticulosis the most likely\ndiagnosis.\nAn extractor was created to extract the answer from LLM response. In the example above, the extracted\nanswer refers to option choice B. Our extractor operates in three tiers, mirroring the pipeline of Jeong\net al. (2024):\n1. It first applies a strict regex to find an exact, stand-alone option letter (A, B, C, ...). If exactly one\nsuch letter—or several copies of the same letter—appears, that letter is taken as the prediction.\n2. When multiple different letters are detected, the code falls back to a full-phrase check: it normalises\nthe text and accepts an answer only if one option’s phrase appears while all others are absent.\n3. If neither test succeeds (a situation that never arose with OLMo but did occur with Llama-2 65 B,\nwhich sometimes emits non-option tokens), no choice is selected and the response is automatically\nmarked incorrect.\nE\nAlternative Scoring settings\nIn addition to the scoring method presented in the main text (i.e., ignore negated concepts), we experi-\nmented with two additional scoring formulations:\n1. Affirmation/negation agnostic: affirmation and negation labels of concepts are disregarded, so\nC′(d, xi) = C(d, xi) for every candidate diagnosis–concept pair, and k′ = k.\n2. Reward absence of negated concepts: for a negated concept xi we consider the number of times\nthe candidate diagnosis d does not co-occur with xi, so\nC′(d, xi) =\n(\nC(d, xi)\nif xi is affirmed\nC(d) −C(d, xi)\nif xi is negated,\nwith k′ = k.\nThe three scoring methods yield highly consistent results on MEDQA diagnosis subset, largely due to the\nsmall number of negated concepts.\nF\nAdditional Results\nF.1\nRedPajama-based FBPR and LLaMA-65B alignment\nFor RedPajama-based FBPR and LLaMA-65B, their joint accuracy on is 24.2% on the MEDQA training\ndiagnosis set; LLaMA alone was correct in 22.8% questions, while FBPR alone has an accuracy of 20.3%.\nThey gave the same answer to 34.5% of the cases, among which 70.2% are correct.\nF.2\nAdditional table and graphs\nCorpus\nk\nall\nStep 1\nStep 2&3\nDolma\n5\n46.7%\n51.2%\n44.3%\nRed Pajama\n5\n44.5%\n46.1%\n43.6%\nRed Pajama\nunrestricted\n40.9%\n40.2%\n41.3%\nTable 2: Accuracy of FBPR on MEDQA diagnosis subset (n=719), based on occurrence frequency from different\ncorpora and with two settings of k, stratified on the medical licensing exam domain.\n12\n"}, {"page": 13, "text": "1\n2\n3\n4\n5\nRank\n0\n50\n100\n150\n200\n250\n300\nNumber of Questions\n320\n170\n105\n75\n49\nk=5\nd = d\n1\n2\n3\n4\n5\nRank\n294\n183\n111\n82\n49\nunrestricted k\nd = d\nFigure 5: Distribution of the rank of the correct diagnosis of each question by RedPajama-based FBPR with k = 5\nor unrestricted k.\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nTop-1 score softmaxed within each question\n100\n101\n102\nNumber of questions (log scale)\nd\nd\nd = d\nmedian of questions with d = d\nmedian of questions with d\nd\nFigure 6: Stacked histogram of per-question softmaxed top-1 scores calculated by Dolma-based FBPR with k = 5.\nA larger softmaxed top-1 score indicates that FBPR’s chosen diagnosis is much more strongly favored by frequency-\nbased Naive Bayes relative to the other candidates.\n13\n"}, {"page": 14, "text": "F.3\nFBPR pipeline examples\nA success ( ˆd = d⋆) and a failure ( ˆd ̸= d⋆) example of FBPR with are shown in Figure 7.\nSuccess Example\nQuestion: \nA 35-year-old woman comes to the physician because of a 1-month \nhistory of double vision, difficulty climbing stairs, and weakness when \ntrying to brush her hair. She reports that these symptoms are worse \nafter she exercises and disappear after she rests for a few hours. \nPhysical examination shows drooping of her right upper eyelid that \nworsens when the patient is asked to gaze at the ceiling for 2 minutes. \nThere is diminished motor strength in the upper extremities. The \nremainder of the examination shows no abnormalities. Which of the \nfollowing is the most likely diagnosis?\n\nA: Myasthenia gravis (correct answer)\nB: Polymyositis\nC: Amyotrophic lateral sclerosis\nD: Guillain-Barré syndrome \nE: Multiple sclerosis\nExtracted concepts and labels: \ndouble vision: positive \ndifficulty climbing stairs: positive\nmuscle weakness: positive\ndrooping eyelid: positive\ndiminished motor strength: positive\nExtracted concepts and labels: \nexcessive hair growth: positive\naxillary hair: positive\npubic hair: positive\novarian mass: positive\nelevated estrogen: positive\nFrequency-based scores and ranks: \nOccurrence and co-occurance frequency by Infini-gram: \nOccurrence and co-occurance frequency by Infini-gram: \nFrequency-based scores and ranks: \nFailure Example\nQuestion: \nA 5-year-old girl is brought to the clinic by her mother for excessive \nhair growth. Her mother reports that for the past 2 months she has \nnoticed hair at the axillary and pubic areas. She denies any family \nhistory of precocious puberty and reports that her daughter has been \nrelatively healthy with an uncomplicated birth history. She denies any \nrecent illnesses, weight change, fever, vaginal bleeding, pain, or \nmedication use. Physical examination demonstrates Tanner stage 4 \ndevelopment. A pelvic ultrasound shows an ovarian mass. Laboratory \nstudies demonstrates an elevated level of estrogen. What is the most \nlikely diagnosis?\n\nA: Congenital adrenal hyperplasia\nB: Granulosa cell tumor (correct answer)\nC: Idiopathic precocious puberty\nD: McCune-Albright syndrome\nE: Sertoli-Leydig tumor\nFigure 7: A success example (left) and a failure example (right) of FBPR on MEDQA diagnosis subset. The diagnosis\noccurrence and (diagnosis, concept) co-occurrence frequencies are retrieved by Infini-gram from v4_rpj_llama_s4\nindex, i.e., from the Red Pajama corpus. By Infini-gram design, some of these frequencies are estimates.\n14\n"}]}