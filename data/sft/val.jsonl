{"id": "q000374", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n根据资料，哪些文献提到了ICU患者数据共享或相关数据库？\n\n[检索证据]\n(1) chunk_id=arxiv:2602.03305_p11_c5\nristopher Warren Seymour, Manu Shankar-Hari, Djillali Annane,\nMichael Bauer, Rinaldo Bellomo, Gordon R Bernard, Jean-Daniel Chiche, Craig M Coopersmith, et al. The third\ninternational consensus definitions for sepsis and septic shock (sepsis-3). Jama, 315(8):801–810, 2016.\n[29] Tom J Pollard, Alistair EW Johnson, Jesse D Raffa, Leo A Celi, Roger G Mark, and Omar Badawi. The eicu\ncollaborative research database, a freely available multi-center database for critical care research. Scientific data,\n5(1):1–13, 2018.\n[30] Patrick J Thoral, Jan M Peppink, Ronald H Driessen, Eric JG Sijbrands, Erwin JO Kompanje, Lewis Kaplan,\nHeatherlee Bailey, Jozef Kesecioglu, Maurizio Cecconi, Matthew Churpek, et al. Sharing icu patient data\nresponsibly under the society of critical care medicine/european society of intensive care medicine joint data\nscience collaboration: the amsterdam university medical ce\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "资料中提到了《The eICU collaborative research database, a freely available multi-center database for critical care research》和《Sharing ICU patient data responsibly under the Society of Critical Care Medicine/European Society of Intensive Care Medicine joint data science collaboration: the Amsterdam University Medical ...》这两篇文献。\n\n[引用]\n- arxiv:2602.03305_p11_c5"}], "meta": {"source_doc_id": "arxiv:2602.03305", "source_page": 11, "source_chunk_id": "arxiv:2602.03305_p11_c5", "difficulty": "easy"}}
{"id": "q000130", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n根据资料，SelfAI框架在自动化科学实验中的整体架构是什么？\n\n[检索证据]\n(1) chunk_id=arxiv:2512.00403_p3_c2\ne\nStop-time\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nc\nGS (1.00)\nBS (1.00)\nLLM (1.00)\nLLM-ES (0.99)\nSelfAI (1.00)\nSolver (Best Result)\n0.0\n0.5\nDensity\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nd\nGS\n(n=417)\nBS\n(n=416)\nLLM\n(n=385)\nLLM-ES\n(n=180)\nSelfAI\n(n=131)\n0.167\n0.543\n0.212\n0.476\n0.229\n0.467\n0.245\n0.465\n0.172\n0.509\n0.318\n0.311\n0.323\n0.350\n0.294\nFig. 1: SelfAI Framework for Automated Scientific Experimentation. a,\nHolistic architecture of the multi-agent system, which transforms various experiments\nin the research process into a structured workflow. b, User intentions, comprising\nideas and experiment schemes, are transformed into structured configurations via a\npredefined prompt. These inputs are processed through successive stages: hypothesis\ngeneration, strategic planning, trial execution, and result collection. c, Performance\ndistribution across 11 tasks demonstrates the framework’s ability, when powered by\nGPT-4o-min\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "SelfAI框架是一个多智能体系统，它将研究过程中的各种实验转化为结构化的工作流程。\n\n[引用]\n- arxiv:2512.00403_p3_c2"}], "meta": {"source_doc_id": "arxiv:2512.00403", "source_page": 3, "source_chunk_id": "arxiv:2512.00403_p3_c2", "difficulty": "easy"}}
{"id": "q000042", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n为了缓解类别不平衡并更好地反映真实临床决策，研究者如何扩充了数据集中的阴性标签？\n\n[检索证据]\n(1) chunk_id=arxiv:2511.05696_p5_c1\nTo mitigate class imbalance and capture a broader range of ineligible cases that better\nreflect real clinical decision-making, we therefore augmented our dataset with additional\nnegative labels by leveraging mutually exclusive trials. Trials were classified as having\nmetastatic disease as either an inclusion criterion (18-486, 22-259) or an exclusion\ncriterion (16-323, 19-300, 19-410, 21-283), with patients eligible for a trial in one group\nbeing ineligible for the trials in the other group by definition. These cross-trial exclusions\nprovided additional negative labels for the patients in our cohort at the same standard of\nevidence. After adding 1564 cross-trial negative labels to the original dataset of 731\npatients, we obtained a total of 2295 {patient, trial} pairs (Table 1). The dataset was split\ninto 50% training and 50% testing sets according to stratified random sampling to\nmainta\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "研究者利用相互排斥的试验来扩充数据集中的阴性标签。具体而言，将试验分为以转移性疾病作为纳入标准或排除标准的两组，一组试验符合条件的患者根据定义在另一组试验中不符合条件。这些跨试验排除为队列中的患者提供了额外的阴性标签。\n\n[引用]\n- arxiv:2511.05696_p5_c1"}], "meta": {"source_doc_id": "arxiv:2511.05696", "source_page": 5, "source_chunk_id": "arxiv:2511.05696_p5_c1", "difficulty": "mid"}}
{"id": "q000046", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n在STEER方法中，用于过滤的最终连贯性分数C(j)是如何计算的？\n\n[检索证据]\n(1) chunk_id=arxiv:2602.02862_p15_c0\nSTEER: Inference-Time Risk Control via Constrained Quality-Diversity Search\nB.3.3. COHERENCE JUDGE PROMPTS\nHere, practitioners can customize important standards that personas must maintain as to not to sacrifice task competence in\nblind pursuit of diversity. As an example, we employ 2 LLM-as-a-Judges system (GPT-o4-mini) to score generated personas\non a 0–4 scale for clinical soundness and fact grounding. The final coherence score C(j) used for filtering is calculated as\nthe arithmetic mean of these two component scores.\nJudge 1: Clinical Soundness Rubric\n• Score 4 (Exceptional): Identifies key findings including important clinical details, demonstrates sophisticated medical\nreasoning with risk stratification, and considers differential diagnosis or complicating factors.\n• Score 3 (Strong): Identifies key findings with appropriate clinical detail, establishes a clear logical connection f\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "最终连贯性分数C(j)是临床合理性和事实基础这两个组成部分得分的算术平均值。\n\n[引用]\n- arxiv:2602.02862_p15_c0"}], "meta": {"source_doc_id": "arxiv:2602.02862", "source_page": 15, "source_chunk_id": "arxiv:2602.02862_p15_c0", "difficulty": "easy"}}
{"id": "q000232", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\nHALLUGUARD 是什么？\n\n[检索证据]\n(1) chunk_id=arxiv:2601.18753_p1_c1\nddress only one source and rely on task-specific heuristics, limiting their\ngeneralization to complex scenarios. To overcome these limitations, we introduce\nthe Hallucination Risk Bound, a unified theoretical framework that formally de-\ncomposes hallucination risk into data-driven and reasoning-driven components,\nlinked respectively to training-time mismatches and inference-time instabilities.\nThis provides a principled foundation for analyzing how hallucinations emerge\nand evolve. Building on this foundation, we introduce HALLUGUARD, a NTK-\nbased score that leverages the induced geometry and captured representations of\nthe NTK to jointly identify data-driven and reasoning-driven hallucinations. We\nevaluate HALLUGUARD on 10 diverse benchmarks, 11 competitive baselines, and\n9 popular LLM backbones, consistently achieving state-of-the-art performance in\ndetecting diverse forms of LLM hallu\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "HALLUGUARD 是一种基于 NTK 的分数，它利用 NTK 的诱导几何和捕获的表示来联合识别数据驱动和推理驱动的幻觉。\n\n[引用]\n- arxiv:2601.18753_p1_c1"}], "meta": {"source_doc_id": "arxiv:2601.18753", "source_page": 1, "source_chunk_id": "arxiv:2601.18753_p1_c1", "difficulty": "easy"}}
{"id": "q000095", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\nBLUM方法如何评估LLM错误行为是否反映了与人类语言组织一致的功能性结构？\n\n[检索证据]\n(1) chunk_id=arxiv:2602.04074_p6_c1\ned with human patients are\nadministered to the perturbed models, with outputs classified using an identical error\ntaxonomy. Third, LLM error profiles are projected into human lesion space using the\nhuman-trained models, and the resulting predicted lesions are evaluated by comparison to\nactual lesions observed in humans with similar error profiles. If lesion patterns inferred from\nLLM error profiles correspond to lesion patterns observed in behaviorally matched humans\nmore strongly than expected by chance, this provides evidence that LLM error behavior\nreflects functionally meaningful structure aligned with human language organization. In this\nway, BLUM establishes human clinical data as an external, causally grounded reference point\nfor evaluating which perturbations and components of LLMs are functionally consequential,\ncomplementing internal-model interpretability methods with an indep\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "通过比较从LLM错误概况推断出的病变模式与具有相似错误概况的人类实际观察到的病变模式，如果前者与后者的对应程度强于偶然预期，则提供证据表明LLM错误行为反映了与人类语言组织一致的功能性结构。\n\n[引用]\n- arxiv:2602.04074_p6_c1"}], "meta": {"source_doc_id": "arxiv:2602.04074", "source_page": 6, "source_chunk_id": "arxiv:2602.04074_p6_c1", "difficulty": "mid"}}
{"id": "q000199", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n根据资料，在女性健康领域，哪个医学专科的模型失败率最高？\n\n[检索证据]\n(1) chunk_id=arxiv:2512.17028_p8_c2\n[40.8%, 72.8%]\n91.7% (11/12) [64.6%, 98.5%]\nNote: Confidence intervals calculated using Wilson score method (95% CI).\nModel performance by medical specialty.\nFigure 4a shows how well LLMs perform across\ndifferent medical specialties in women’s health, with stacked bars showing correct (green) vs incorrect\n(red) cases across all 13 models. The overall failure rates by specialty are shown in the bar chart\nwith 95% confidence intervals. Failure rates are calculated as the percentage of incorrect cases to\ntotal cases. With 76.9%, neurology shows the highest failure rate across all models. However, this\nis based on the smallest sample size (39 cases total across all models). Oncology is the second\nmost challenging with 67.8% failure rate. Emergency medicine shows the third highest failure rate\nwith 59.9% failure rate. Primary care and obstetrics and gynecology show the lowest failure rates\nwi\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "神经病学（neurology）的失败率最高，为76.9%。\n\n[引用]\n- arxiv:2512.17028_p8_c2"}], "meta": {"source_doc_id": "arxiv:2512.17028", "source_page": 8, "source_chunk_id": "arxiv:2512.17028_p8_c2", "difficulty": "easy"}}
{"id": "q000388", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n索拉非尼可以用于肝功能Child-Pugh什么级别的患者？\n\n[检索证据]\n(1) chunk_id=pdf:01f2f97a8b58d461_p82_c0\n82 / 143\n都具有一定的生存获益\n[380-381]（证据等级1，推荐A）。索\n拉非尼可以用于肝功能Child-Pugh A/B 级的患者，但是\n相对于肝功能Child-Pugh B 级，Child-Pugh A 级的患者\n生存获益比较明显\n[382]。治疗过程中应定期评估疗效和监\n测毒性。常见的不良反应为腹泻、手足综合征、皮疹、高\n血压、纳差以及乏力等，一般发生在治疗开始后的2～6\n周内。治疗过程中需要密切监测血压，定期检查肝肾功能、\nHBV DNA、血常规、凝血功能以及尿蛋白等。在治疗过程\n中，还需要注意心肌缺血风险，特别高龄患者应给予必要\n的监测和相关检查。\n（8）系统化疗：FOLFOX4 方案在我国被批准用于一\n线治疗不适合手术切除或局部治疗的局部晚期和转移性\n肝癌\n[383-384]（证据等级1，推荐A）。另外，三氧化二砷对\n中晚期肝癌具有一定的姑息治疗作用\n[385]（证据等级3，推\n荐C），在临床应用时应注意监测和防止肝肾毒性。\n（9）其他一线系统抗肿瘤治疗进展：双免疫联合治疗\n在不可手术切除的中晚期肝癌一线治疗领域也取得了成功。\n全球Ⅲ期临床试验HIMALAYA 研究结果显示\n[386]，与索拉非尼\n对比，程序性死亡受体配体1 抑制剂度伐利尤单克隆抗体联\n合细胞毒性T 淋巴细胞相关抗原4 抑制剂替西木单克隆抗体\n（STRIDE 方案：单次给药300mg 替西木单克隆抗体+度伐利\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "索拉非尼可以用于肝功能Child-Pugh A/B级的患者。\n\n[引用]\n- pdf:01f2f97a8b58d461_p82_c0"}], "meta": {"source_doc_id": "pdf:01f2f97a8b58d461", "source_page": 82, "source_chunk_id": "pdf:01f2f97a8b58d461_p82_c0", "difficulty": "easy"}}
{"id": "q000465", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n在表格2中，MAMA-Memeia模型的Macro-F1和Weighted-F1分数分别是多少？\n\n[检索证据]\n(1) chunk_id=arxiv:2512.25015_p6_c0\nTable 2: Comparison of MAMA-Memeia with unimodal and\nmultimodal baselines along with previous state-of-the-art.\nModel\nMacro-F1\nWeighted-F1\nUnimodal Text\nOCR:\nBERT (Devlin et al. 2019)\n62.02\n62.63\nMentalBERT (Ji et al. 2022)\n63.77\n64.47\nBART (Lewis et al. 2020)\n44.71\n49.46\nMentalBART (Yang et al. 2023)\n61.76\n62.43\nExplanation:\nBERT\n63.39\n63.96\nMentalBERT\n64.62\n65.27\nBART\n55.81\n57.11\nMentalBART\n64.96\n64.30\nUnimodal Image\nViT (Dosovitskiy et al. 2021)\n34.96\n39.04\nResNet (He et al. 2015)\n27.14\n33.46\nEfficientNet (Tan and Le 2019)\n25.18\n31.61\nMultimodal\nImage + OCR\nCLIP (Radford et al. 2021)\n45.83\n48.09\nVisualBERT (Li et al. 2019)\n62.70\n63.67\nViT + BERT\n38.57\n42.24\nImage + Explanation\nCLIP\n39.23\n42.56\nVisualBERT\n62.37\n62.25\nViT + BERT\n37.78\n40.58\nPrevious SOTA\nYadav et al. (2023) †\n65.18\n64.67\nMAMA-Memeia\n72.73\n72.45\n∆MAMA-Memeia - †\n↑7.55%\n↑7.78%\nConsensus Resolution\nAt the end of N = R + 1\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "MAMA-Memeia的Macro-F1分数是72.73，Weighted-F1分数是72.45。\n\n[引用]\n- arxiv:2512.25015_p6_c0"}], "meta": {"source_doc_id": "arxiv:2512.25015", "source_page": 6, "source_chunk_id": "arxiv:2512.25015_p6_c0", "difficulty": "easy"}}
{"id": "q000155", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n根据资料，在信息不完整的场景中，大多数模型表现出什么倾向？\n\n[检索证据]\n(1) chunk_id=arxiv:2512.21849_p7_c4\ne needs for belonging. This interaction pattern, lacking\nboundary awareness and emotional insight, overlooks understanding and guiding users toward\ntheir authentic needs.\n• Curiosity: In scenarios with incomplete information, most models exhibit assumption-based comple-\ntion tendencies—directly providing abundant generic suggestions based on assumptions rather than\nseeking clarification through follow-up questions. This “rush to answer” pattern undermines the\nspecificity and effectiveness of conversations.\n• Warmth and Communication Style: A prevalent issue is didactic tone, specifically manifested in:\n– Excessive use of imperative sentences (“You should...”, “You must...”)\n– Lack of invitational or guiding expressions (“How do you feel about...?”, “Perhaps we could...”)\n– Predominance of unidirectional information delivery over bidirectional exploration\nThis communication pattern tends\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "在信息不完整的场景中，大多数模型表现出基于假设的完成倾向，即直接根据假设提供大量通用建议，而不是通过后续问题寻求澄清。\n\n[引用]\n- arxiv:2512.21849_p7_c4"}], "meta": {"source_doc_id": "arxiv:2512.21849", "source_page": 7, "source_chunk_id": "arxiv:2512.21849_p7_c4", "difficulty": "easy"}}
{"id": "q000005", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n根据资料，LLM-based transcript aligner在Structural Alignment Accuracy方面的表现如何？\n\n[检索证据]\n(1) chunk_id=arxiv:2511.16544_p7_c1\nDeep-\ngram, with similarly low counts for ASR results.\nFor Structural Alignment Accuracy, performance\nremained strong (96.4%). Minor discrepancies\nstemmed from boundary drift in long utterances or\nduplicated ASR fragments, none of which affected\nclinical meaning in downstream comparisons.\nOverall, these results confirm that the LLM-\nbased aligner is robust and accurate enough, pro-\nviding a reliable foundation for subsequent clinical\nimpact annotation.\nFigure 3: Performance of the LLM-based transcript\naligner across Google (Dora) and Deepgram (Primock)\nASR hypotheses. The figure shows high classification\naccuracy (> 98%) and low total error counts for both\ngolden and ASR utterances.\n5.2\nExisting Metric Evaluation\nExisting metrics correlate poorly with clinical la-\nbels for risk.\nAcross all metrics, the enrichment–\ndelta analysis (Figure 4) revealed that score differ-\nences between high–i\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "LLM-based transcript aligner在Structural Alignment Accuracy方面表现强劲，准确率为96.4%。\n\n[引用]\n- arxiv:2511.16544_p7_c1"}], "meta": {"source_doc_id": "arxiv:2511.16544", "source_page": 7, "source_chunk_id": "arxiv:2511.16544_p7_c1", "difficulty": "easy"}}
{"id": "q000323", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n根据资料，最终胆管造影的发现是什么？\n\n[检索证据]\n(1) chunk_id=arxiv:2601.12648_p48_c3\nburden. Contrast flows across the cystic duct\n,→into the duodenum.\nNew biliary drain: Cook internal/external biliary drain\nNew biliary drain diameter (French): 14\nNew biliary drain modifications: None\nFinal cholangiogram findings: Cholelithiasis. Internal/external biliary drain in place with\n,→contrast draining into the duodenum.\nExternal catheter securement:\nNon-absorbable suture\nContrast\nContrast agent: Omnipaque 300\nContrast volume (mL): 20\nRadiation Dose\nFluoroscopy time (minutes): 17.0\nReference air kerma (mGy): 185.1\nKerma area product (uGy-m2): 2685.2\n48\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "最终胆管造影的发现是胆石症，以及内外胆管引流管在位，造影剂流入十二指肠。\n\n[引用]\n- arxiv:2601.12648_p48_c3"}], "meta": {"source_doc_id": "arxiv:2601.12648", "source_page": 48, "source_chunk_id": "arxiv:2601.12648_p48_c3", "difficulty": "easy"}}
{"id": "q000176", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n在公式(4)中，如何参数化证据等级效应以确保等级顺序A≻B≻C≻D≻E？\n\n[检索证据]\n(1) chunk_id=arxiv:2601.00216_p18_c2\ntic relevance difference; t+ = Grade(d+)\nand t−= Grade(d−) denote evidence grades; ut is the grade bias; a > 0 is the\nscale parameter; and σ(·) is the sigmoid function. This formulation jointly considers\ntwo signals: (1) semantic relevance difference ∆s, and (2) evidence grade difference\nut+ −ut−. When semantic scores are comparable, windows with higher evidence grades\nreceive additional positive bias.\nOrdered hierarchical parameterization. To explicitly encode a pyramid-shaped evi-\ndence hierarchy and prevent grade inversion under noisy labels, we fix the grade\nordering as A ≻B ≻C ≻D ≻E and adopt monotonically constrained incremental\nparameterization for grade effects:\nuA = 0,\nuB = −δB,\nuC = −(δB + δC),\nuD = −(δB + δC + δD),\nuE = −(δB + δC + δD + δE).\n(4)\nwhere δB, δC, δD, δE ≥0. This form naturally guarantees uA ≥uB ≥uC ≥uD ≥\nuE, yielding an evidence-grade pyramid consistent with EBM.\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "采用单调约束的增量参数化：uA = 0，uB = -δB，uC = -(δB + δC)，uD = -(δB + δC + δD)，uE = -(δB + δC + δD + δE)，其中δB, δC, δD, δE ≥ 0。这保证了uA ≥ uB ≥ uC ≥ uD ≥ uE。\n\n[引用]\n- arxiv:2601.00216_p18_c2"}], "meta": {"source_doc_id": "arxiv:2601.00216", "source_page": 18, "source_chunk_id": "arxiv:2601.00216_p18_c2", "difficulty": "mid"}}
{"id": "q000321", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n根据资料，一个仅对输入标准脚本的人授予安全的系统会建立什么？\n\n[检索证据]\n(1) chunk_id=arxiv:2512.10780_p8_c7\nnce, but a critical safety\nliability. A system that grants safety only to those who type in stan-\ndard scripts inadvertently establishes a hidden digital hierarchy of\ncare, where the most vulnerable are left voiceless by the very tools\ndesigned to protect them.\nReferences\n[1] Asma Ben Abacha, Yassine Mrabet, Mark Sharp, Travis R Goodwin, Sonya E\nShooshan, and Dina Demner-Fushman. 2019. Bridging the gap between con-\nsumers’ medication questions and trusted answers. In MEDINFO 2019: Health\nand Wellbeing e-Networks for All. IOS Press, 25–29.\n[2] Gustavo Aguilar, Victor Soto, Fahad AlGhamdi, and Thamar Solorio. 2020. LinCE:\nA Benchmark for Linguistic Code-switching Evaluation. In Proceedings of the 12th\n8\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "一个隐藏的数字关怀等级制度，其中最脆弱的人被旨在保护他们的工具剥夺了发言权。\n\n[引用]\n- arxiv:2512.10780_p8_c7"}], "meta": {"source_doc_id": "arxiv:2512.10780", "source_page": 8, "source_chunk_id": "arxiv:2512.10780_p8_c7", "difficulty": "easy"}}
{"id": "q000359", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n在临床文档元数据研究中，哪些类型的发表场所最为常见？\n\n[检索证据]\n(1) chunk_id=arxiv:2601.09730_p17_c0\nBetween the six categories of application that we observed, computational phenotyping and\nsemantic processing tasks such as disease classification and coreference resolution, respectively,\nwere the most common. However, the distribution of these applications was distributed relatively\nevenly across the categories.\n\n3.4 Research/publication context\nFigure 5 displays the frequency of publication venue types by research topic. Informatics\njournals and conferences were the most common venues for clinical document metadata\nresearch, representing 25/67 (37.3%) and 16/67 (23.9%) of the publications, respectively, or\n41/67 (61.2%) of the publications overall included in our review. Computer science/AI/NLP\nvenues were also a relatively common destination, representing 20/67 (29.9%) of the\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "信息学期刊和会议是最常见的发表场所，分别占出版物的37.3%和23.9%，合计占61.2%。\n\n[引用]\n- arxiv:2601.09730_p17_c0"}], "meta": {"source_doc_id": "arxiv:2601.09730", "source_page": 17, "source_chunk_id": "arxiv:2601.09730_p17_c0", "difficulty": "easy"}}
{"id": "q000157", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n根据资料，阿尔茨海默病（AD）和2型糖尿病（T2DM）在全球范围内面临怎样的挑战？\n\n[检索证据]\n(1) chunk_id=arxiv:2601.15429_p1_c2\nl-\nscoped retrieval. Temperature plays a secondary role; higher\nvalues rarely help. We conclude that precision-first, scope-\nmatched KG-RAG is preferable to breadth-first unions, and\nwe outline practical guidelines for graph selection, model siz-\ning, and retrieval/reranking. Code and Data available here -\nhttps://github.com/sydneyanuyah/RAGComparison\nI. INTRODUCTION\nAlzheimer’s disease (AD) and type 2 diabetes mellitus\n(T2DM) represent two of the most pressing chronic health\nchallenges we face today [1], [2], each carrying its own\nsignificant public health burden while also sharing surprising\nconnections with one another [3]. Today, AD stands as the\nprimary cause of dementia in older adults [4], [5]. More than\n55 million people worldwide are living with dementia, and\nexperts predict this could surge to somewhere between 139\nand 150 million by 2050 [6], [7]. T2DM shows a similarly\nalarmi\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "阿尔茨海默病（AD）和2型糖尿病（T2DM）是当今面临的两个最紧迫的慢性健康挑战，各自带来重大的公共卫生负担，并且彼此之间存在令人惊讶的联系。\n\n[引用]\n- arxiv:2601.15429_p1_c2"}], "meta": {"source_doc_id": "arxiv:2601.15429", "source_page": 1, "source_chunk_id": "arxiv:2601.15429_p1_c2", "difficulty": "easy"}}
{"id": "q000391", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n根据资料，Mixtral 8x7B模型在共病预测任务中的表现如何？\n\n[检索证据]\n(1) chunk_id=arxiv:2512.04834_p9_c3\nnce between precision and recall for this comorbidity. Mistral 7B\nshows better generalization, but still has low scores across a few comorbidities.\nMixtral 8x7B has low scores in most cases and struggles to generalize across co-\nmorbidities, even though it is the most advanced among all the chosen models.\nBoth Qwen2.5 3B and Qwen2.5 7B models, despite their parameter differ-\nences, seem to produce classes that do not match the true positive class at all\nin most of the cases. The precision is 0 in most of the cases because there are\nno positive predictions. Similarly, recall is also 0 because the model does not\ncorrectly identify any of the actual positive samples in the data. In context with\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "Mixtral 8x7B在大多数情况下得分较低，并且在共病之间难以泛化，尽管它是所有选定模型中最先进的。\n\n[引用]\n- arxiv:2512.04834_p9_c3"}], "meta": {"source_doc_id": "arxiv:2512.04834", "source_page": 9, "source_chunk_id": "arxiv:2512.04834_p9_c3", "difficulty": "easy"}}
{"id": "q000189", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n自我引导生成、评估和优化的过程是如何开始的？\n\n[检索证据]\n(1) chunk_id=arxiv:2511.06222_p4_c4\ns with goals through self-guided generation, evaluation,\nand optimization, which has been demonstrated effective in many works on self-alignment (Sun\net al., 2023; Wu et al., 2024; Kim et al., 2024). As shown in Figure 2, it begins with diverse sam-\npling and self-refinement, where the targeted model generates multiple responses per prompt,\nevaluates them under dual-alignment objectives, and produces a refined output. A dual-criterion\n4\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "它从多样化采样和自我精炼开始，其中目标模型为每个提示生成多个响应，在双重对齐目标下评估它们，并产生一个精炼的输出。\n\n[引用]\n- arxiv:2511.06222_p4_c4"}], "meta": {"source_doc_id": "arxiv:2511.06222", "source_page": 4, "source_chunk_id": "arxiv:2511.06222_p4_c4", "difficulty": "easy"}}
{"id": "q000257", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n根据资料，Bellomo等人关于急性肾衰竭的共识会议论文发表在哪个期刊上？\n\n[检索证据]\n(1) chunk_id=arxiv:2601.22324_p9_c2\n0/jcm14176169. URL\nhttp://dx.doi.org/10.3390/jcm14176169.\nBalek, V., S´ykora, L., Sklen´ak, V., and Kliegr, T. Llm-\nbased feature generation from text for interpretable\nmachine learning.\nMachine Learning, 114(11), Oc-\ntober 2025.\nISSN 1573-0565.\ndoi:\n10.1007/\ns10994-025-06867-1. URL http://dx.doi.org/\n10.1007/s10994-025-06867-1.\nBellomo, R., Ronco, C., Kellum, J. A., Mehta, R. L., and\nPalevsky, P. Acute renal failure – definition, outcome\nmeasures, animal models, fluid therapy and information\ntechnology needs: the second international consensus\nconference of the acute dialysis quality initiative (adqi)\ngroup. Critical Care, 8(4), May 2004. ISSN 1364-8535.\ndoi: 10.1186/cc2872. URL http://dx.doi.org/\n10.1186/cc2872.\nBertsimas, D. and Stellato, B.\nThe voice of op-\ntimization.\nMachine Learning,\n110(2):249–277,\nJuly 2020.\nISSN 1573-0565.\ndoi:\n10.1007/\ns10994-020-05893-5. URL http://dx.doi.org\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "该论文发表在《Critical Care》期刊上。\n\n[引用]\n- arxiv:2601.22324_p9_c2"}], "meta": {"source_doc_id": "arxiv:2601.22324", "source_page": 9, "source_chunk_id": "arxiv:2601.22324_p9_c2", "difficulty": "easy"}}
{"id": "q000193", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\nDapo 的作者是谁？\n\n[检索证据]\n(1) chunk_id=arxiv:2601.06801_p13_c3\nYufeng Yuan,\nXiaochen Zuo, Yu Yue, Weinan Dai, Tiantian Fan,\nGaohong Liu, Lingjun Liu, Xin Liu, Haibin Lin,\nZhiqi Lin, Bole Ma, Guangming Sheng, Yuxuan\nTong, Chi Zhang, Mofan Zhang, Wang Zhang, and\n16 others. 2025.\nDapo: An open-source llm re-\ninforcement learning system at scale.\nPreprint,\narXiv:2503.14476.\nXiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng,\nRuoqi Liu, Ge Zhang, Samuel Stevens, Dongfu\nJiang, Weiming Ren, Yuxuan Sun, Cong Wei, Botao\nYu, Ruibin Yuan, Renliang Sun, Ming Yin, Boyuan\nZheng, Zhenzhu Yang, Yibo Liu, Wenhao Huang, and\n3 others. 2024a. Mmmu: A massive multi-discipline\nmultimodal understanding and reasoning benchmark\nfor expert agi. In Proceedings of CVPR.\nXiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng,\nRuoqi Liu, Ge Zhang, Samuel Stevens, Dongfu Jiang,\nWeiming Ren, Yuxuan Sun, and 1 others. 2024b.\nMmmu: A massive multi-discipline multimodal un-\nderstanding and\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "Dapo 的作者是 Yufeng Yuan, Xiaochen Zuo, Yu Yue, Weinan Dai, Tiantian Fan, Gaohong Liu, Lingjun Liu, Xin Liu, Haibin Lin, Zhiqi Lin, Bole Ma, Guangming Sheng, Yuxuan Tong, Chi Zhang, Mofan Zhang, Wang Zhang 以及另外 16 人。\n\n[引用]\n- arxiv:2601.06801_p13_c3"}], "meta": {"source_doc_id": "arxiv:2601.06801", "source_page": 13, "source_chunk_id": "arxiv:2601.06801_p13_c3", "difficulty": "easy"}}
{"id": "q000441", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n对于有乙型肝炎或丙型肝炎或任何原因引起肝硬化者，随访发现肝内直径≤2 cm的结节，如果影像学检查无或只有1项有典型的肝癌特征，应如何处理？\n\n[检索证据]\n(1) chunk_id=pdf:22a4edadf64de8e2_p3_c2\n作出临床诊\n断( 参见附录四) 。( 1) 有乙型肝炎或丙型肝炎，或者\n有任何原因引起肝硬化者，至少每隔6 个月进行一次\n超声及AFP 检测，发现肝内直径≤2 cm 结节，动态增\n强MＲI、动态增强CT、超声造影及普美显动态增强\nMＲI 4 项检查中至少有2 项显示有动脉期病灶明显强\n化、门脉或延迟期强化下降的“快进快出”的肝癌典型\n特征，则可作出肝癌的临床诊断; 对于发现肝内直径＞2\ncm 的结节，则上述4 种影像学检查中只要有1 项有典\n型的肝癌特征，即可临床诊断为肝癌。( 2) 有乙型肝\n炎或丙型肝炎，或者有任何原因引起肝硬化者，随访\n发现肝内直径≤2 cm 结节，若上述4 种影像学检查中\n无或只有1 项检查有典型的肝癌特征，可进行肝穿刺\n活检或每2 ～3 个月密切的影像学随访以确立诊断;\n1\n2\n4\n1\n中华人民共和国国家卫生和计划生育委员会．原发性肝癌诊疗规范(2017 年版)\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "可进行肝穿刺活检或每2～3个月密切的影像学随访以确立诊断。\n\n[引用]\n- pdf:22a4edadf64de8e2_p3_c2"}], "meta": {"source_doc_id": "pdf:22a4edadf64de8e2", "source_page": 3, "source_chunk_id": "pdf:22a4edadf64de8e2_p3_c2", "difficulty": "mid"}}
{"id": "q000210", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n在复杂的医疗场景中，LLMs要有效工作，必须能够处理哪些类型的信息？\n\n[检索证据]\n(1) chunk_id=arxiv:2602.14158_p2_c7\ng levels of agreement among annotators. This is especially problematic in complex medical scenarios where\ninterpretations may vary based on context. Additionally, healthcare data often includes both structured formats (like\nlaboratory results) and unstructured formats (like clinical notes). For LLMs to be effective, they must be capable of\nmanaging and integrating both types of information seamlessly.\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "LLMs必须能够无缝地管理和整合结构化和非结构化两种类型的信息。\n\n[引用]\n- arxiv:2602.14158_p2_c7"}], "meta": {"source_doc_id": "arxiv:2602.14158", "source_page": 2, "source_chunk_id": "arxiv:2602.14158_p2_c7", "difficulty": "easy"}}
{"id": "q000008", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n在优化主题识别参数和选择嵌入后，如何使用两个神经主题模型生成关键词列表？\n\n[检索证据]\n(1) chunk_id=arxiv:2601.12154_p5_c4\ne parameters of each model, as well as the parameters that\ncontrol the clustering and dimensionality reduction processes, are experimented with and modified\nacross several runs to determine which settings yield the best results.\nSubsequently, the optimized topic identification parameters and selected embeddings (available\nwithin the two neural models) will be used for both neural topic models to produce keyword lists.\nWe use an LLM to summarize topics from the keyword list into a descriptive label. Then human\nevaluations will be carried out on topic model selection by looking into features of coherence, fidelity,\nand interpretability.\n2. available at https://github.com/MaartenGr/BERTopic\n3. available at https://github.com/ddangelov/Top2Vec\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "使用优化后的主题识别参数和两个神经模型内可用的选定嵌入，为两个神经主题模型生成关键词列表。\n\n[引用]\n- arxiv:2601.12154_p5_c4"}], "meta": {"source_doc_id": "arxiv:2601.12154", "source_page": 5, "source_chunk_id": "arxiv:2601.12154_p5_c4", "difficulty": "easy"}}
{"id": "q000244", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n在构建语义图 G = (V, E) 时，节点 V 和边 E 分别代表什么？\n\n[检索证据]\n(1) chunk_id=arxiv:2512.20822_p4_c1\nross-\nsystem integration. Formally,\nf : z 7→CUI(z), Ua = {f(z) | z ∈Sa}.\n(3)\nHere, z denotes a raw code that is being mapped\nto a CUI(z), and Ua is the set of normalized CUIs\nfor admission a. This normalization ensures that\ndiagnoses, procedures, and medications from dif-\nferent coding systems can be compared, linked, and\nreasoned over in a unified space.\nStep 3: Ontology Graph Construction and Rela-\ntion Extraction.\nFrom the normalized concepts\nacross the cohort, we construct a semantic graph\nG = (V, E), where V are CUIs and E are relations\ndrawn from the UMLS Metathesaurus, including\ntreated_by, has_associated_procedure, and is_a\netc. A dictionary mapping synonyms and abbrevi-\nations to CUIs supports robust entity matching in\ntext. Many clinically valid associations are not en-\ncoded as direct links but instead mediated through\nintermediate nodes such as therapeutic classes,\nanatomical\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "节点 V 是归一化的 CUI（统一医学语言系统概念唯一标识符），边 E 是从 UMLS Metathesaurus 中提取的关系，例如 treated_by、has_associated_procedure 和 is_a 等。\n\n[引用]\n- arxiv:2512.20822_p4_c1"}], "meta": {"source_doc_id": "arxiv:2512.20822", "source_page": 4, "source_chunk_id": "arxiv:2512.20822_p4_c1", "difficulty": "easy"}}
{"id": "q000022", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\nAlfonso Semeraro 等人于 2021 年发表的关于可视化情感标注语料库的论文标题是什么？\n\n[检索证据]\n(1) chunk_id=arxiv:2512.14604_p21_c1\nl Linguistics, pages\n4061–4071, 2019.\nAmandine Schmutz, Julien Jacques, Charles Bouveyron, Laurence Cheze, and Pauline Martin.\nClustering multivariate functional data in group-specific functional subspaces. Computational\nStatistics, 35(3):1101–1131, 2020.\nSix Seconds. Plutchik’s wheel of emotions: Feelings wheel, 2025. URL https://www.6seconds.\norg/2025/02/06/plutchik-wheel-emotions/. Accessed 2025-05-21.\nAlfonso Semeraro, Salvatore Vilella, and Giancarlo Ruffo. Pyplutchik: Visualising and comparing\nemotion-annotated corpora. PLOS ONE, 16(9):e0256503, September 2021. ISSN 1932-6203. doi:\n10.1371/journal.pone.0256503. URL http://dx.doi.org/10.1371/journal.pone.0256503.\nAlvin Subakti, Hendri Murfi, and Nora Hariadi. The performance of bert as data representation\nof text clustering. Journal of big Data, 9(1):15, 2022.\nYing Sun and Marc G Genton.\nFunctional boxplots.\nJournal of computational\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "Pyplutchik: Visualising and comparing emotion-annotated corpora。\n\n[引用]\n- arxiv:2512.14604_p21_c1"}], "meta": {"source_doc_id": "arxiv:2512.14604", "source_page": 21, "source_chunk_id": "arxiv:2512.14604_p21_c1", "difficulty": "easy"}}
{"id": "q000051", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n根据资料，术中放疗（IORT）的定义是什么？\n\n[检索证据]\n(1) chunk_id=pdf:56f8c47855be5a75_p6_c1\n巴\n转移无显著改善。\n2.3.7\n术中放疗（IORT）是指在开放性手术过程\n中，针对高危瘤床或孤立无法切除残余病灶给予\n表5-2\n二维腔内治疗小结\n表5-3\n三维后装计划记录单\n表5-4\n三维后装总结单\nHRCTV D90（cGy）\nIRCTV D90（cGy）\n膀胱D2cc（cGy）\n直肠D2cc（cGy）\n乙状结肠D2cc（cGy）\nEBRT\nBT1\nBT2\nBT3\nBT4\nBT5\n合计\n·\n·618\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "术中放疗（IORT）是指在开放性手术过程中，针对高危瘤床或孤立无法切除残余病灶给予的放疗。\n\n[引用]\n- pdf:56f8c47855be5a75_p6_c1"}], "meta": {"source_doc_id": "pdf:56f8c47855be5a75", "source_page": 6, "source_chunk_id": "pdf:56f8c47855be5a75_p6_c1", "difficulty": "easy"}}
{"id": "q000097", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\nMedTutor系统在混合证据检索阶段，针对每个搜索查询并行执行的第一步本地检索是什么？\n\n[检索证据]\n(1) chunk_id=arxiv:2601.06979_p3_c4\no MedTutor is a case report, which\nwill be processed through a sequence of automated\nstages, each designed for parallel execution.\nCase decomposition into search queries: The\nprocess begins with a source radiology report. Then\nwe use an Llama-3.3-70B-Instruct(Meta, 2024) to\nprocess the radiology report and decompose it into\nmultiple keyword based queries that will be used\nfor retrieval. These queries are key diagnostic terms\nand findings. Prompts for case decomposition into\nsearch queries are shown in Appendix D.1.\nHybrid Evidence Retrieval: For each search\nquery, the system performs a hybrid retrieval\nprocess in parallel described below: (1) Local\nretrieval for textbook material: Textbooks and\nnotes are essential resources for medical educa-\ntion.\nIn our MedTutor system, we first apply\nOCR to a radiology textbook (Dähnert, 2017) us-\ning the mistral-ocr-2503 model, then segment\nand index\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "第一步本地检索是针对教材材料的检索，具体包括对放射学教材（Dähnert, 2017）应用OCR，然后进行分割和索引。\n\n[引用]\n- arxiv:2601.06979_p3_c4"}], "meta": {"source_doc_id": "arxiv:2601.06979", "source_page": 3, "source_chunk_id": "arxiv:2601.06979_p3_c4", "difficulty": "easy"}}
{"id": "q000197", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\nRegCheck的研究开发部分具体关注哪些方面？\n\n[检索证据]\n(1) chunk_id=arxiv:2601.13330_p12_c1\nblication\nauditing. Its modularity allows adaptation across disciplines and integration\ninto larger ecosystems for research integrity. The research arm of RegCheck’s\ndevelopment focuses on concretely addressing:\n1. The accuracy of RegCheck’s text extraction, and whether this accuracy\nvaries across domains, disciplines, and model hyperparameters;\n2. Whether providing RegCheck to authors can improve the quality of registration-\npaper comparisons upon submission of papers to journals;\n3. Whether RegCheck improves in the efficiency and frequency of registration-\npaper comparisons.\nWe welcome engagement and input from researchers, journals, and funders in-\nterested in using RegCheck in diverse research areas. We are currently working\nto develop extensions of RegCheck, including the capacity to (i) assess multiple\npapers at once for use in meta-science or meta-analysis research, and (ii) asses\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "RegCheck的研究开发部分具体关注三个方面：1. RegCheck文本提取的准确性，以及这种准确性是否因领域、学科和模型超参数而异；2. 向作者提供RegCheck是否能在论文提交给期刊时提高注册-论文比较的质量；3. RegCheck是否提高了注册-论文比较的效率和频率。\n\n[引用]\n- arxiv:2601.13330_p12_c1"}], "meta": {"source_doc_id": "arxiv:2601.13330", "source_page": 12, "source_chunk_id": "arxiv:2601.13330_p12_c1", "difficulty": "easy"}}
{"id": "q000289", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n该研究得到了哪个国家科技重大专项的支持？\n\n[检索证据]\n(1) chunk_id=pdf:83bdf109824fc1bc_p2_c3\nIDS）；\nhuman immunodeficiency virus （HIV）；\ntumor；\nviral infection；\nimmunity；\nmetabolism\n* This work was supported by the National Science and Technology Major Project of China (2018ZX10302103-003).\n 国家科技重大专项（2018zx10302103-003）\n△△Corresponding author\nE-mail： wjincityu@yahoo.com\n1\n网络首发时间：2026-01-04 16:34:22       网络首发地址：https://link.cnki.net/urlid/31.1885.r.20251231.1812.002\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "该研究得到了中国国家科技重大专项（项目编号：2018ZX10302103-003）的支持。\n\n[引用]\n- pdf:83bdf109824fc1bc_p2_c3"}], "meta": {"source_doc_id": "pdf:83bdf109824fc1bc", "source_page": 2, "source_chunk_id": "pdf:83bdf109824fc1bc_p2_c3", "difficulty": "easy"}}
{"id": "q000366", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n在评估解释方法时，研究人员如何利用大型语言模型进行外部评估？\n\n[检索证据]\n(1) chunk_id=arxiv:2601.17952_p9_c3\nSAE\nlayer in producing monosemantic and diagnostically coherent explanations, we performed an auxiliary evaluation\nacross three cohorts (Binary ADNI, Binary BrainLAT, and three-class ADNI). For each test sample, we extracted the\ntop 50% most influential token attributions from TEO without SAE, TEO with SAE, and TEO-UMAP, and constructed\nclass-specific CSV files in which highlighted characters for each attribution method were arranged column-wise,\nwith the full character sequence (including the CLS token) provided in the first column to ensure clear sample-\nlevel distinction. These CSVs were then presented to a large language model (ChatGPT-5.1 [35]) under a fixed\nprompting protocol to yield an external, model-agnostic assessment of the interpretability structure encoded by\neach explanation space.\nResults. Across both binary tasks, all three attribution methods correctly identified the p\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "研究人员将每种归因方法的前50%最具影响力的token归因构建成特定类别的CSV文件，并将这些文件提交给大型语言模型（ChatGPT-5.1），在固定的提示协议下进行外部、模型无关的评估。\n\n[引用]\n- arxiv:2601.17952_p9_c3"}], "meta": {"source_doc_id": "arxiv:2601.17952", "source_page": 9, "source_chunk_id": "arxiv:2601.17952_p9_c3", "difficulty": "mid"}}
{"id": "q000204", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n根据给定资料，期望检测任务包含哪两个子任务？\n\n[检索证据]\n(1) chunk_id=arxiv:2602.15504_p3_c5\ns linked to a treatment and thus constitute\nExpectation Events. By contrast, “I expect to see\nmy doctor next week” expresses an expectation but\nnot one about a treatment outcome and therefore\nfalls outside our scope.\nFormally, given a text span T, the Expectation\nDetection task in this study involves two subtasks:\n1. Expectation\nIdentification:\ndetermine\nwhether T contains one or more Expectation\nEvents; and\n2. Treatment-Expectation-Outcome annota-\ntion: if so, identify their key components: (a)\nthe treatment or intervention about which the\nexpectation is expressed), (b) the expectation\n(what is expected to occur) and (c) the actual\noutcome (what actually occurred).\n4.\nExpectation Corpus\n4.1.\nCorpus Creation\nTo systematically study how patients express ex-\npectations about medical treatments on social\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "期望检测任务包含两个子任务：1. 期望识别：确定文本跨度是否包含一个或多个期望事件；2. 治疗-期望-结果标注：如果包含，则识别其关键组成部分，包括（a）表达期望所针对的治疗或干预，（b）期望（预期会发生什么），以及（c）实际结果（实际发生了什么）。\n\n[引用]\n- arxiv:2602.15504_p3_c5"}], "meta": {"source_doc_id": "arxiv:2602.15504", "source_page": 3, "source_chunk_id": "arxiv:2602.15504_p3_c5", "difficulty": "easy"}}
{"id": "q000060", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n什么是领域自适应预训练？\n\n[检索证据]\n(1) chunk_id=arxiv:2602.14158_p6_c4\n’s general capa-\nbilities. Domain-adaptive pre-training employs an intermediate pre-training phase on domain-specific data before\ntask-specific fine-tuning, showing impressive results with models like LLaMA on specialised medical tasks. Finally,\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "领域自适应预训练是在任务特定微调之前，使用领域特定数据进行中间预训练的阶段。\n\n[引用]\n- arxiv:2602.14158_p6_c4"}], "meta": {"source_doc_id": "arxiv:2602.14158", "source_page": 6, "source_chunk_id": "arxiv:2602.14158_p6_c4", "difficulty": "easy"}}
{"id": "q000427", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n根据资料，Lead II 的 P 波持续时间是多少？\n\n[检索证据]\n(1) chunk_id=arxiv:2602.15677_p22_c2\non is measured globally at 164 ms with an amplitude of 0.08 mV.\nSpecifically looking at Lead II, the P-wave duration is 113 ms with an amplitude of 0.12 mV. The PR interval\nis 193 ms, which is within the upper limits of normal (less than 200 ms). These findings, alongside the 160\nms QRS duration, confirm the diagnosis of a significant ventricular conduction delay without a primary AV\nblock.\nFindings:\n• Global P-duration: 164 ms\n• Lead II P-duration: 113 ms\n• PR interval: 193 ms\n• QRS duration: 160 ms\nImpression: Left Bundle Branch Block.\nC.3\nStage 5\nThe Stage 5 dataset contains 17K samples, with ECGs sourced from the Icentia11k dataset. Like Stage 4, we use\nECGDeli-computed statistics to generate conversations with gemini-3-flash-preview. However, in Stage 5\nwe focus on single-ECG, single-turn conversations (one question and one response). We first compile a rubric\nconsisting of the most\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "Lead II 的 P 波持续时间是 113 ms。\n\n[引用]\n- arxiv:2602.15677_p22_c2"}], "meta": {"source_doc_id": "arxiv:2602.15677", "source_page": 22, "source_chunk_id": "arxiv:2602.15677_p22_c2", "difficulty": "easy"}}
{"id": "q000401", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n根据资料，Yan等人于2025年发表的论文标题是什么？\n\n[检索证据]\n(1) chunk_id=arxiv:2601.15160_p13_c3\npPath: A Reinforcement Learning Method for Knowledge Graph Reasoning.\narXiv preprint arXiv:1707.06690, 2017.\nYan, L., Tang, C., Guan, Y., Wang, H., Wang, S., Liu, H., Yang, Y., and Jiang, J. RLKGF: Reinforcement Learning\nfrom Knowledge Graph Feedback without Human Annotations. In Findings of the Association for Computational\nLinguistics: ACL 2025, pp. 6619–6633, 2025.\nYang, A., Li, A., Yang, B., Zhang, B., Hui, B., Zheng, B., Yu, B., Gao, C., Huang, C., Lv, C., et al. Qwen3 Technical\nReport. arXiv preprint arXiv:2505.09388, 2025.\nYasunaga, M., Ren, H., Bosselut, A., Liang, P., and Leskovec, J. QA-GNN: Reasoning with Language Models and\nKnowledge Graphs for Question Answering. arXiv preprint arXiv:2104.06378, 2021.\nYin, M., Qu, Y., Yang, L., Cong, L., and Wang, M. Toward Scientific Reasoning in LLMs: Training from Expert\nDiscussions via Reinforcement Learning. arXiv preprint arXiv:2505.19\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "RLKGF: Reinforcement Learning from Knowledge Graph Feedback without Human Annotations。\n\n[引用]\n- arxiv:2601.15160_p13_c3"}], "meta": {"source_doc_id": "arxiv:2601.15160", "source_page": 13, "source_chunk_id": "arxiv:2601.15160_p13_c3", "difficulty": "easy"}}
{"id": "q000133", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n根据资料，Llama-3.1-8B-instruct模型在few-shot学习和QLoRA微调实验中，相比零样本基线的准确率提升分别是多少？\n\n[检索证据]\n(1) chunk_id=arxiv:2602.01714_p9_c1\nialized reinforcement learning pipelines that proprietary models undergo relative to their\nopen-source counterparts. Additionally, our results show significantly higher performance\nby reasoning models (gpt-5 and gpt-o3) relative to other models, showing the promise and\nimportance of incorporating reasoning and explainability into medical NLP as a whole and\nArabic medical NLP specifically.\nThe few-shot learning and QLoRA experiments in Table 5 above revealed substantial im-\nprovements over the baseline zero-shot performance for Llama-3.1-8B-instruct, though with\nnotable differences in effectiveness between the two approaches. Few-shot learning provided\na modest gain of 12.4% (from 0.170 to 0.191), suggesting that in-context examples helped\nthe model better understand the medical question format and reasoning patterns. Addition-\nally, QLoRA fine-tuning, boosted accuracy by 88.2% to 0.320,\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "few-shot学习相比零样本基线准确率提升了12.4%（从0.170到0.191），QLoRA微调相比零样本基线准确率提升了88.2%（达到0.320）。\n\n[引用]\n- arxiv:2602.01714_p9_c1"}], "meta": {"source_doc_id": "arxiv:2602.01714", "source_page": 9, "source_chunk_id": "arxiv:2602.01714_p9_c1", "difficulty": "easy"}}
{"id": "q000145", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\nJen Kim、Stefan Leijnen和Lisa Beinborn在2024年发表的关于文本简化的论文标题是什么？\n\n[检索证据]\n(1) chunk_id=arxiv:2602.11982_p7_c1\nn.\nIn Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors, Proceedings of the 60th Annual Meeting\nof the Association for Computational Linguistics (Volume 1: Long Papers), pages 7331–7345, Dublin, Ireland,\nMay 2022. Association for Computational Linguistics.\n[9] Jenia Kim, Stefan Leijnen, and Lisa Beinborn. Considering Human Interaction and Variability in Automatic Text\nSimplification. In Proceedings of the Third Workshop on Text Simplification, Accessibility and Readability (TSAR\n2024), pages 52–60, Miami, Florida, USA, 2024. Association for Computational Linguistics.\n[10] Gemma Team, Aishwarya Kamath, Johan Ferret, Shreya Pathak, Nino Vieillard, Ramona Merhej, Sarah Perrin,\nTatiana Matejovicova, Alexandre Ramé, Morgane Rivière, Louis Rouillard, Thomas Mesnard, Geoffrey Cideron,\nJean-bastien Grill, Sabela Ramos, Edouard Yvinec, Michelle Casbon, Etienne Pot, Ivo Penchev, Ga\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "标题是“Considering Human Interaction and Variability in Automatic Text Simplification”。\n\n[引用]\n- arxiv:2602.11982_p7_c1"}], "meta": {"source_doc_id": "arxiv:2602.11982", "source_page": 7, "source_chunk_id": "arxiv:2602.11982_p7_c1", "difficulty": "easy"}}
{"id": "q000456", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n根据表格3，在SAT-M领域，饱和率（Saturated）和专家率（Savant）分别是多少？\n\n[检索证据]\n(1) chunk_id=arxiv:2512.18880_p6_c4\nbound for alignment capability that is strictly gov-\nerned by the density of high-quality models within\nDomain\nIRT\nCapacity\nCognitive Divergence\nGlobal\nSaturated\nSavant\nBrittle\n(ρ)\n(90% M ✓)\n(H⇑M⇓)\n(H⇓M⇑)\nUSMLE\n0.134\n75.6%\n70.4%\n0.0%\nCambridge\n0.309\n35.6%\n22.1%\n0.4%\nSAT-R\n0.304\n45.5%\n25.5%\n0.0%\nSAT-M\n0.386\n54.6%\n32.2%\n1.3%\nTable 3: Analysis of implicit difficulty alignment based\non Machine IRT. H: Human difficulty; M: Model diffi-\nculty. Saturated represents the total ratio of items that\n90% of the model can solve correctly. Savant represents\nthe ratio of items that are hard for humans (difficulty top\n33%) but trivial for most models (correct for 90% of the\nmodels). Brittleness represents the ratio of items that\nare easy for humans, where most of the models fail. The\nsaturated rate and savant rate present the diagnosis\nof Human-LLM Difficulty Misalignment.\nthe pool. In domains with a de\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "SAT-M领域的饱和率是54.6%，专家率是32.2%。\n\n[引用]\n- arxiv:2512.18880_p6_c4"}], "meta": {"source_doc_id": "arxiv:2512.18880", "source_page": 6, "source_chunk_id": "arxiv:2512.18880_p6_c4", "difficulty": "easy"}}
{"id": "q000410", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n根据资料，Wang, J. 等人在2025年发表的关于使用EEG进行重度抑郁症诊断的多任务深度学习框架的论文标题是什么？\n\n[检索证据]\n(1) chunk_id=arxiv:2511.09947_p8_c6\n–332.\nWang, G.; Xie, Y.; Jiang, Y.; Mandlekar, A.; Xiao, C.;\nZhu, Y.; Fan, L.; and Anandkumar, A. 2023. Voyager: An\nOpen-Ended Embodied Agent with Large Language Mod-\nels. In NeurIPS 2023 Foundation Models for Decision Mak-\ning Workshop.\nWang, J.; Zhao, S.; Jiang, H.; Li, S.; Li, T.; and Pan, G. 2024.\nGeneralizable Sleep Staging via Multi-Level Domain Align-\nment. Proceedings of the AAAI Conference on Artificial In-\ntelligence, 38(1): 265–273.\nWang, J.; Zhao, S.; Luo, Z.; Zhou, Y.; Jiang, H.; Li, S.; Li, T.;\nand Pan, G. 2025a. CBraMod: A Criss-Cross Brain Founda-\ntion Model for EEG Decoding. arXiv:2412.07236.\nWang, Y.; Zhao, S.; Jiang, H.; Li, S.; Li, T.; and Pan, G.\n2025b. M-MDD: A multi-task deep learning framework for\nmajor depressive disorder diagnosis using EEG. Neurocom-\nputing, 636: 130008.\nWei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; ichter, b.;\nXia, F.; Chi, E.; Le, Q. V.; and\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "M-MDD: A multi-task deep learning framework for major depressive disorder diagnosis using EEG。\n\n[引用]\n- arxiv:2511.09947_p8_c6"}], "meta": {"source_doc_id": "arxiv:2511.09947", "source_page": 8, "source_chunk_id": "arxiv:2511.09947_p8_c6", "difficulty": "easy"}}
{"id": "q000185", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n根据研究，在零样本设置下，大型语言模型在从意大利语电子健康记录中提取合并症时表现如何？\n\n[检索证据]\n(1) chunk_id=arxiv:2512.04834_p14_c2\nons.\n7\nConclusion\nIn this paper, we explored the potential of six multilingual general-purpose open-\nsource large language models (LLMs) in understanding and extracting valuable\ninformation from Electronic Health Records (EHRs) in Italian. Our study, fo-\ncused on the real-time retrieval of comorbidities from EHRs, shows important\ninsights into the LLMs ability to handle non-English language understanding\nand processing. Our findings show how LLMs struggle in extracting comorbidi-\nties and their difficulty in understanding Italian language EHR when used in a\nzero-shot approach. LLMs in the zero-shot setting cannot be used as a substitute\nfor traditional pattern matching in the extraction pipelines. In the future, we will\nexplore In-Context learning (ICL) approaches and will also consider fine-tuning\nan LLM model for IR from EHRs to improve its language processing capabilities\nand enhance\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "在零样本设置下，大型语言模型在从意大利语电子健康记录中提取合并症时表现不佳，无法替代提取流程中的传统模式匹配方法。\n\n[引用]\n- arxiv:2512.04834_p14_c2"}], "meta": {"source_doc_id": "arxiv:2512.04834", "source_page": 14, "source_chunk_id": "arxiv:2512.04834_p14_c2", "difficulty": "easy"}}
{"id": "q000219", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\nWhat are potential diagnoses for chronic cystitis symptoms with reduced bladder capacity and frequent urination?\n\n[检索证据]\n(1) chunk_id=arxiv:2601.09280_p17_c3\n(index=49): Evidence is correctly accumulated,\nbut the final decision is inconsistent.\nQuery. What are potential diagnoses for chronic cystitis\nsymptoms with reduced bladder capacity and frequent\nurination?\nOptions (MCQ). (A) cystitis cystica (B) chronic cystitis\n(C) cystitis (D) interstitial cystitis. Gold: D\nStep 0: Hop decomposition (Adaptive_MultiHop).\n• Hop 1: candidate diagnoses for chronic cystitis symp-\ntoms\n• Hop 2: diagnoses linked to reduced capacity and fre-\nquent urination\n• Hop 3: final diagnosis matching the combined profile\nStep 1: Region evidence (verified triplets; subset).\n• (interstitial\ncystitis, phenotype\npresent,\nFunctional abnormality of the bladder)\n• (interstitial\ncystitis, phenotype\npresent,\nPollakisuria)\n• (interstitial\ncystitis, phenotype\npresent,\nNocturia)\n• (interstitial\ncystitis, phenotype\npresent,\nUrinary bladder inflammation)\nStep 2: Hop-level sub-answer\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "Interstitial cystitis.\n\n[引用]\n- arxiv:2601.09280_p17_c3"}], "meta": {"source_doc_id": "arxiv:2601.09280", "source_page": 17, "source_chunk_id": "arxiv:2601.09280_p17_c3", "difficulty": "easy"}}
{"id": "q000270", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n对于有乙型肝炎或丙型肝炎或任何原因引起肝硬化者，随访发现肝内直径≤2 cm的结节，若动态增强MRI、动态增强CT、超声造影及普美显动态增强MRI这4项检查中无或只有1项显示典型的肝癌特征，应如何处理？\n\n[检索证据]\n(1) chunk_id=pdf:22a4edadf64de8e2_p3_c2\n作出临床诊\n断( 参见附录四) 。( 1) 有乙型肝炎或丙型肝炎，或者\n有任何原因引起肝硬化者，至少每隔6 个月进行一次\n超声及AFP 检测，发现肝内直径≤2 cm 结节，动态增\n强MＲI、动态增强CT、超声造影及普美显动态增强\nMＲI 4 项检查中至少有2 项显示有动脉期病灶明显强\n化、门脉或延迟期强化下降的“快进快出”的肝癌典型\n特征，则可作出肝癌的临床诊断; 对于发现肝内直径＞2\ncm 的结节，则上述4 种影像学检查中只要有1 项有典\n型的肝癌特征，即可临床诊断为肝癌。( 2) 有乙型肝\n炎或丙型肝炎，或者有任何原因引起肝硬化者，随访\n发现肝内直径≤2 cm 结节，若上述4 种影像学检查中\n无或只有1 项检查有典型的肝癌特征，可进行肝穿刺\n活检或每2 ～3 个月密切的影像学随访以确立诊断;\n1\n2\n4\n1\n中华人民共和国国家卫生和计划生育委员会．原发性肝癌诊疗规范(2017 年版)\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "可进行肝穿刺活检或每2～3个月密切的影像学随访以确立诊断。\n\n[引用]\n- pdf:22a4edadf64de8e2_p3_c2"}], "meta": {"source_doc_id": "pdf:22a4edadf64de8e2", "source_page": 3, "source_chunk_id": "pdf:22a4edadf64de8e2_p3_c2", "difficulty": "mid"}}
{"id": "q000214", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n根据资料，哪篇论文提出了一个名为 GUI-R1 的通用 R1 风格视觉语言动作模型用于 GUI 智能体？\n\n[检索证据]\n(1) chunk_id=arxiv:2601.12538_p120_c3\nr gui agents with experience replay. arXiv preprint arXiv:2505.16282, 2025. URL https://www.\narxiv.org/abs/2505.16282.\n[621] Hanyu Lai, Xiao Liu, Yanxiao Zhao, Han Xu, Hanchen Zhang, Bohao Jing, Yanyu Ren, Shuntian\nYao, Yuxiao Dong, and Jie Tang. Computerrl: Scaling end-to-end online reinforcement learning for\ncomputer use agents. arXiv preprint arXiv:2508.14040, 2025. URL https://www.arxiv.org/abs/\n2508.14040.\n[622] Zhengxi Lu, Yuxiang Chai, Yaxuan Guo, Xi Yin, Liang Liu, Hao Wang, Han Xiao, Shuai Ren, Guanjing\nXiong, and Hongsheng Li. Ui-r1: Enhancing action prediction of gui agents by reinforcement learning.\narXiv preprint arXiv:2503.21620, 2025. URL https://www.arxiv.org/abs/2503.21620.\n[623] Run Luo, Lu Wang, Wanwei He, Longze Chen, Jiaming Li, and Xiaobo Xia. Gui-r1: A generalist\nr1-style vision-language action model for gui agents. arXiv preprint arXiv:2504.10458, 2025.\n[624] Yuha\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "论文《GUI-R1: A generalist R1-style vision-language action model for GUI agents》提出了一个名为 GUI-R1 的通用 R1 风格视觉语言动作模型用于 GUI 智能体。\n\n[引用]\n- arxiv:2601.12538_p120_c3"}], "meta": {"source_doc_id": "arxiv:2601.12538", "source_page": 120, "source_chunk_id": "arxiv:2601.12538_p120_c3", "difficulty": "easy"}}
{"id": "q000165", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n根据给定的资料，评估模型在临床推理和问答任务中的核心目标是什么？\n\n[检索证据]\n(1) chunk_id=arxiv:2511.14439_p15_c0\nTask type: Evaluate the model's ability to perform complex clinical reasoning and QA\nbased on medical images and textual information.\n,→\nRole definition: You are an experienced senior attending physician. Your evaluation\nprioritizes accuracy, logical reasoning, and patient safety. You focus not only on\ncorrect diagnosis but also on the reasonableness and practicality of subsequent\ntreatment and management suggestions.\n,→\n,→\n,→\nEvaluation objective: Comprehensively assess the model's integration of visual\nperception, text understanding, and clinical knowledge reasoning. Core evaluation\ndimensions include:\n,→\n,→\n1. Accuracy of visual information recognition: Can the model correctly identify and\ninterpret key findings in the images?\n,→\n2. Image-text integration: Can it effectively combine imaging findings with patient\ninformation (age, sex, etc.) provided in the question?\n,→\n3. Logical and\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "评估模型整合视觉感知、文本理解和临床知识推理的能力。\n\n[引用]\n- arxiv:2511.14439_p15_c0"}], "meta": {"source_doc_id": "arxiv:2511.14439", "source_page": 15, "source_chunk_id": "arxiv:2511.14439_p15_c0", "difficulty": "easy"}}
{"id": "q000440", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\nGPT-4技术报告的作者列表中包括哪些姓为Wang的人？\n\n[检索证据]\n(1) chunk_id=arxiv:2511.03441_p11_c4\nJordan Sitkin, Katarina Slama, Ian\nSohl, Benjamin Sokolowsky, Yang Song, Na-\ntalie Staudacher, Felipe Petroski Such, Na-\ntalie Summers, Ilya Sutskever, Jie Tang, Niko-\nlas Tezak, Madeleine B. Thompson, Phil Tillet,\nAmin Tootoonchian, Elizabeth Tseng, Preston\nTuggle, Nick Turley, Jerry Tworek, Juan Fe-\nlipe Cerón Uribe, Andrea Vallone, Arun Vi-\njayvergiya, Chelsea Voss, Carroll Wainwright,\nJustin Jay Wang, Alvin Wang, Ben Wang,\nJonathan Ward, Jason Wei, CJ Weinmann, Ak-\nila Welihinda, Peter Welinder, Jiayi Weng, Lil-\nian Weng, Matt Wiethoff, Dave Willner, Clemens\nWinter, Samuel Wolrich, Hannah Wong, Lauren\nWorkman, Sherwin Wu, Jeff Wu, Michael Wu,\nKai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qiming\nYuan, Wojciech Zaremba, Rowan Zellers, Chong\nZhang, Marvin Zhang, Shengjia Zhao, Tianhao\nZheng, Juntang Zhuang, William Zhuk, and Bar-\nret Zoph. 2024. Gpt-4 technical report.\nAmandine Quercia, Jamil\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "作者列表中包括Justin Jay Wang、Alvin Wang和Ben Wang。\n\n[引用]\n- arxiv:2511.03441_p11_c4"}], "meta": {"source_doc_id": "arxiv:2511.03441", "source_page": 11, "source_chunk_id": "arxiv:2511.03441_p11_c4", "difficulty": "easy"}}
{"id": "q000434", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n在研究中，高毒力肺炎克雷伯菌（hvKP）和经典肺炎克雷伯菌（cKP）的感染数量分别是多少？\n\n[检索证据]\n(1) chunk_id=pdf:ef3b9e1098fbbd30_p1_c3\nfections （82.12%），of which 135 were hvKP （79.41%） and 35 were cKP （20.59%）. And 37 hospital-associated\n  \n \n收稿日期： 2025-09-10\n基金项目： 成都市医学科研课题（2024013）\n通信作者： 刘永芳， E-mail：liuyongfang@163.com\n作者简介： 张培林（1997－）， 女， 硕士， 研究方向：细菌耐药机制\n引用本文： 张培林，何俊凝，尹艺杰，等. 高毒力肺炎克雷伯菌感染临床及分子流行病学特征[J]. 中华医院感\n染学杂志，2026，36（4）：610-614. DOI：10.11816/cn.ni.2026-252206\nCitation： ZHANG Peilin,  HE Junning,  YIN Yijie,  et  al.  Clinical  and  molecular  epidemiological  characteristics  of  hypervirulent  Klebsiella\npneumoniae[J]. Chin J Nosocomiol, 2026, 36(4): 610-614. DOI: 10.11816/cn.ni.2026-252206\n \n· 610 ·\n中华医院感染学杂志 2026 年第 36 卷第 4 期　Chin J Nosocomiol Vol. 36 No. 4 2026\n网络首发时间：2026-01-28 18:39:00       网络首发地址：https://link.cnki.net/urlid/11.3436.R.20260128.1128.002\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "高毒力肺炎克雷伯菌（hvKP）感染数量为135例，经典肺炎克雷伯菌（cKP）感染数量为35例。\n\n[引用]\n- pdf:ef3b9e1098fbbd30_p1_c3"}], "meta": {"source_doc_id": "pdf:ef3b9e1098fbbd30", "source_page": 1, "source_chunk_id": "pdf:ef3b9e1098fbbd30_p1_c3", "difficulty": "easy"}}
{"id": "q000171", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\nProToken 如何通过监控不同数量的 transformer 层来平衡开销和归因准确性？\n\n[检索证据]\n(1) chunk_id=arxiv:2601.19672_p10_c1\nt y-axis).\nProToken addresses this by monitoring only the last N\ntransformer blocks, where task-specific knowledge concen-\ntrates (Olah et al., 2018; Yu et al., 2022). We measure\nProToken’s overhead and attribution accuracy as we vary\nthe number of monitored layers, from the last 3 layers up\nto nearly all layers, across four model architectures. Ex-\nperiments use 5 test samples per global LLM at round 10.\nFigure 5 shows that ProToken achieves 100% attribu-\ntion accuracy for all models and layer counts, confirm-\ning that provenance signals are concentrated in later trans-\nformer blocks. For Gemma-3-270M-it (18 total layers),\nProToken’s overhead ranges from 1.10s with 3 layers\nto 1.42s with last layers, representing a 29% increase. In-\ncreasing the number of monitored layers increases overhead\nlinearly (up to 1.87s for the deepest model), allowing flexi-\nble trade-offs between latency and\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "ProToken 通过仅监控最后 N 个 transformer 层来平衡开销和归因准确性，其中任务特定知识集中。实验表明，对于所有模型和层数，ProToken 都能实现 100% 的归因准确性，证明来源信号集中在后面的 transformer 块中。随着监控层数的增加，开销线性增加（最深模型可达 1.87 秒），允许在延迟和准确性之间进行灵活的权衡。\n\n[引用]\n- arxiv:2601.19672_p10_c1"}], "meta": {"source_doc_id": "arxiv:2601.19672", "source_page": 10, "source_chunk_id": "arxiv:2601.19672_p10_c1", "difficulty": "mid"}}
{"id": "q000140", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n在 MMLU-Pro 的零样本性能比较中，GlobMed-Qwen3-4B 模型在西班牙语上的得分是多少？\n\n[检索证据]\n(1) chunk_id=arxiv:2601.02186_p181_c154\nLLMs\nChinese English French German Japanese Korean Portuguese Spanish Swahili Wolof Yoruba Zulu\nMedGemma-4B\n33.16\n48.13\n37.43\n37.43\n31.55\n28.34\n35.29\n37.43\n21.93\n14.44\n10.16\n13.90\nGlobMed-MedGemma-4B\n32.62\n41.18\n38.50\n40.64\n34.22\n31.02\n36.36\n35.29\n31.02\n16.58\n19.25\n23.53\nQwen3-1.7B\n29.95\n35.83\n30.48\n22.46\n20.86\n24.60\n24.60\n25.67\n18.72\n14.97\n11.76\n14.44\nGlobMed-Qwen3-1.7B\n34.76\n40.11\n38.50\n36.36\n24.06\n19.79\n37.43\n31.55\n19.25\n16.04\n12.83\n15.51\nQwen3-4B\n54.55\n59.36\n54.01\n49.73\n42.78\n37.97\n49.20\n51.34\n11.23\n11.76\n13.37\n9.63\nGlobMed-Qwen3-4B\n50.27\n55.08\n52.41\n56.15\n44.92\n41.18\n52.94\n57.22\n27.27\n23.53\n24.06\n19.25\nQwen3-8B\n59.36\n68.45\n55.08\n52.41\n49.73\n45.45\n58.29\n55.61\n19.79\n9.63\n12.83\n9.63\nGlobMed-Qwen3-8B\n58.29\n61.50\n58.29\n54.01\n54.55\n50.27\n55.61\n55.61\n26.20\n21.93\n26.20\n24.06\nSTab. 154: Zero-Shot performance comparison across 12 languages on MMLU-Pro (Run 1).\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "GlobMed-Qwen3-4B 模型在西班牙语上的得分是 57.22。\n\n[引用]\n- arxiv:2601.02186_p181_c154"}], "meta": {"source_doc_id": "arxiv:2601.02186", "source_page": 181, "source_chunk_id": "arxiv:2601.02186_p181_c154", "difficulty": "easy"}}
{"id": "q000090", "conversations": [{"from": "human", "value": "你是一个严格遵循证据的学术助手。\n\n[问题]\n哪篇论文讨论了大型语言模型在医学中的可解释性？\n\n[检索证据]\n(1) chunk_id=arxiv:2511.04720_p5_c2\nthe Thirty-Eighth AAAI Conference\non Artificial Intelligence and Thirty-Sixth Conference\non Innovative Applications of Artificial Intelligence and\nFourteenth Symposium on Educational Advances in Ar-\ntificial Intelligence. 2024, AAAI’24/IAAI’24/EAAI’24,\nAAAI Press.\n[3] Thomas Savage, Ashwin Nayak, Robert Gallo, Ekanath\nRangan, and Jonathan H. Chen, “Diagnostic reasoning\nprompts reveal the potential for large language model\ninterpretability in medicine,” npj Digital Medicine, vol.\n7, no. 1, pp. 20, Jan. 2024.\n[4] Zhihong Zhu, Yunyan Zhang, Xianwei Zhuang, Fan\nZhang, et al., “Can we trust AI doctors? a survey of\nmedical hallucination in large language and large vision-\nlanguage models,” in Findings of the Association for\nComputational Linguistics: ACL 2025, Wanxiang Che\net al., Eds., Vienna, Austria, July 2025, pp. 6748–6769,\nAssociation for Computational Linguistics.\n[5] Fnu Neha, Deepshik\n\n[规则]\n- 只能基于【检索证据】回答\n- 若证据不足以回答，请输出：资料不足以回答该问题。\n- 不要编造、不要引入常识推测\n\n[输出要求]\n- 先给答案正文\n- 末尾给出引用列表（每行一个 chunk_id），格式：\n  [引用]\n  - chunk_id"}, {"from": "gpt", "value": "Thomas Savage等人于2024年发表在npj Digital Medicine上的论文“Diagnostic reasoning prompts reveal the potential for large language model interpretability in medicine”讨论了大型语言模型在医学中的可解释性。\n\n[引用]\n- arxiv:2511.04720_p5_c2"}], "meta": {"source_doc_id": "arxiv:2511.04720", "source_page": 5, "source_chunk_id": "arxiv:2511.04720_p5_c2", "difficulty": "easy"}}
